\section{A Pitfall of DPO-style Algorithms}
%DPO-style Algorithms Solve an Under-specified Problem}
\label{sec:DPO-Pitfall}

We now leverage the classification framework developed in Section~\ref{sec:PO-C} to explain a peculiar behavior of several DPO-style algorithms, namely the decrease, or even the collapse (to $0$), of the winner response probability. We then use this insight to derive algorithms that address this phenomenon in Section~\ref{sec:algos}. Several prior work~\cite{nemotron,ppo_vs_dpo,smaug,distilled_DPO,xiao2024caldpo} reported this undesirable behavior, empirically showed that it could result in suboptimal alignment, and proposed loss functions (algorithms) to address it.

Reinspecting the classification framework allows us to clearly identify the root-cause of this behavior as the underlying problem solved in these algorithms is {\em under-specified}. In practice, the under-specified nature of the problem often manifests itself in the form of collapsing the winner-loser probabilities to $0$. 

To understand this phenomenon, recall from Section~\ref{sec:PO-C} that the original problem can be reformulated as: $\min_{\theta} \sum_{\mathcal{D}}{\mathcal L}(p_{\theta},p)$. 
%$\min_{\theta} \sum_{\langle x, y_w, y_l\rangle\in \mathcal{D}}{\mathcal L}\big(p_{\theta}(x, y_w, y_l),\ p\big)\ .$ 
For simplicity, we use the soft labels $p = (1 - \varepsilon , \varepsilon)$ for some $0 < \varepsilon < 1/2$. An optimal parameter $\theta$ is one that achieves $0$ loss for all samples in $\mathcal D$, which means that $p_{\theta}(x,y_w,y_l) = p$, for all $(x,y_w,y_l)\in\mathcal D$. Setting $p_{\theta}^w(x,y_w,y_l)$ in~\eqref{pthetaw} equal to $p^w=1-\varepsilon$, we obtain
% Using the definition of $p_{\theta}^w$ in~\eqref{pthetaw}, for the optimal parameter $\theta^{*}$, we have
% %
% \begin{equation*}
% p_{\theta}^w(x,y_w,y_l) = \frac{\big(\frac{\pi_{\theta^{*}}(y_w \mid x)}{\piRef(y_w \mid x)}\big)^{\beta}}{\big(\frac{\pi_{\theta^{*}}(y_{w} \mid x)}{\piRef(y_{w} \mid x)}\big)^{\beta} + \big(\frac{\pi_{\theta^{*}}(y_{l} \mid x)}{\piRef(y_{l} \mid x)}\big)^{\beta}} = 1 - \varepsilon\ .   
% \end{equation*}
% %
% Rearranging this equality, we obtain
%
\begin{equation} \label{DPO_solution_characterization}
    \pi_{\theta^{*}}(y_w | x) = \eta\cdot \pi_{\theta^{*}}(y_l | x)\ ,
\end{equation}
%
with $\eta \assign \sqrt[\beta]{(1 - \varepsilon)/\varepsilon}\cdot\frac{\piRef(y_w | x)}{\piRef(y_l | x)}$. Note that the derivation using $y_l$ yields the same result. Thus, we have two probabilities, $\pi_{\theta^{*}}(y_w | x)$ and $\pi_{\theta^{*}}(y_l | x)$, that we aim to learn, but minimizing the loss only gives us one constraint specified in~\eqref{DPO_solution_characterization}. This means that the original problem is under-specified. %\footnote{Note that for any $\theta$, we have $\pi_\theta(y_w|x)+\pi_\theta(y_l|x)+\sum_{y\in\mathcal Y-\{y_w,y_l\}}\pi_\theta(y|x)=1$, where $\mathcal Y$ is the set of all responses.} 
In Figure~\ref{fig:solution_set}, we provide an illustration, and below we give a concrete example further highlighting that the two probabilities can move in arbitrary directions.

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{figures/prelim.png}
    \caption{An illustration of the set of solutions that achieve $0$ loss in DPO-style algorithms. The shaded gray is the set of feasible solutions. The red line passing the feasible set is defined by~\eqref{DPO_solution_characterization} and indicates the optimal set of solutions. All points on this line achieve $0$ loss. Note that the case where the probabilities collapse to 0, i.e.,~$p_{\theta}(x, y_w, y_l)=( 0^{+}, 0^{+} )$ also lies on this line.}
    \label{fig:solution_set}
\end{figure}

\begin{remark}[A Concrete Example]
Suppose we have $\varepsilon=1/11$ and for simplicity we set $\beta=1$, $\piRef(y_w|x) = 0.02$, and $\piRef(y_l|x) = 0.01$, which result in $\eta = 20$. We identify two pairs of probabilities that satisfy~\eqref{DPO_solution_characterization}: 
%$(\pi_{\theta^{*}}(y_w|x),\pi_{\theta^{*}}(y_l|x)) = (0.4,0.02)$ and %$(\pi_{\theta^{*}}(y_w|x),\pi_{\theta^{*}}(y_l|x)) = (0.001,0.00005)$. 
\begin{enumerate}
    \item $\big(\pi_{\theta^{*}}(y_w|x),\ \pi_{\theta^{*}}(y_l|x)\big) = (0.4,\ 0.02) \ .$
    \item $\big(\pi_{\theta^{*}}(y_w|x),\ \pi_{\theta^{*}}(y_l|x)\big) = (0.001,\ 0.0002)\ .$
\end{enumerate}
In the first case both probabilities (including the loser) increase under $\pi_{\theta^{*}}$ relative to $\piRef$. In sharp contrast, both probabilities (including the winner) decrease under $\pi_{\theta^{*}}$ relative to $\piRef$. Note that the increase is bounded as the two probabilities can go up until they hit $\pi_{\theta^{*}}(y_w|x) + \pi_{\theta^{*}}(y_l|x) = (1 + \eta) \pi_{\theta^{*}}(y_l | x) = 1$. Perhaps more concerning is the observation that the two probabilities can decrease arbitrarily and even collapse to $0$ while still maintaining ${\mathcal L}\big(p_{\theta^{*}},p\big) = 0$.
\end{remark}

Note that for simplicity we worked with soft labels ($\varepsilon > 0$). However, notice that with hard labels we often use early stopping, which in effect prevents the model from overfitting to the hard labels. Therefore, the problem remains under-specified even when working with hard labels.  