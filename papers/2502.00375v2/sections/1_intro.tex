\section{Introduction}
The proliferation of generative artificial intelligence (AI) technologies has introduced new societal challenges, particularly in distinguishing between human-generated and AI-generated content \cite{wang2023survey}. The increasing sophistication of these models allows them to produce text and images that are often indistinguishable from human creations, raising concerns over their misuse in spreading misinformation, generating fake news, and creating deceptive media. Beyond this, the diversity of generative AI models, each employing distinct architectures and techniques highlights the importance of not only identifying AI-generated content but also classifying it by its source. Such classifications enable deeper forensic insights and are critical for trust-building in applications like content moderation, digital forensics, and fact-checking.

A critical aspect of this challenge is the need to differentiate between the various generative methods themselves. This distinction is essential for assessing the relative difficulty of detecting different approaches and understanding which models are more or less susceptible to detection. Without this understanding, it would be difficult to evaluate the effectiveness of detection systems and their ability to keep pace with emerging AI technologies \cite{ojha2023towards}.

Compounding these challenges is the relentless growth in the number and variety of generative models. The landscape of generative AI is far from static, with new methods continually emerging and pushing the boundaries of realism and creativity. This rapid evolution necessitates the development of adaptable classification frameworks capable of integrating new generative models without requiring costly and exhaustive retraining \cite{lin2024detecting}. Addressing this issue is crucial for building sustainable and scalable detection systems.

To address these challenges, this paper proposes a novel approach tailored for classifying and detecting AI-generated content in both text and image domains. The key contributions of this work are:  
\begin{itemize}  
    \item A method that adapts to new generative models by incorporating their features into the classification pipeline without retraining
    \item The evaluation of contrastive learning for incremental learning, particularly in classifying AI, human-generated, and various generative methods
    \item The use of pseudo-labeling to familiarize the model with augmentations in the test set, to enrich the training data, and to enable long-term learning that allows adaptation to small changes in generative models in real-world scenarios
\end{itemize}  


In recent years, advancements in generative models have significantly enhanced the capabilities of AI in creating text and images. Large language models (LLMs) such as GPT-3 \cite{brown2020language}, GPT-4 \cite{achiam2023gpt}, and Mistral \cite{jiang2023mistral} have revolutionized text generation, enabling coherent and contextually rich outputs across diverse applications, but also raising challenges in detecting AI-generated text. Similarly, generative models like Stable Diffusion \cite{rombach2022high}, DALL-E \cite{ramesh2021zero}, Midjourney \cite{midjourney} have achieved remarkable success in producing high-quality, photorealistic images. However, the increasing realism of such outputs poses risks for misinformation and underscores the need for robust detection systems. Recent studies have explored ensemble methods combining multiple models \cite{mohamed2024proposed, abburi2023generative} or treating fake content as anomalies \cite{khalidOCFakeDectClassifyingDeepfakes2020}, achieving notable success in feature separability. However, these approaches often fall short in scalability when faced with the addition of new labels. Techniques like ArcFace have addressed some of these limitations, offering improved adaptability and performance in scenarios with evolving generative models. The remaining details and related works are provided in Appendix~\ref{sec:appendix_related_work}.


This paper is organized to provide a comprehensive overview of the proposed method and its evaluation. Section~\ref{sec:method} introduces the method, detailing its key components, including perceptual hashing, similarity measurement, and pseudo-labeling, while Section~\ref{sec:exp} presents the experimental setup, datasets, implementation details, and results to highlight the method's effectiveness. The paper concludes in Section~\ref{sec:conclude} with insights and future directions, with additional materials, including detailed related work, dataset descriptions, and supplementary experiments, provided in the Appendix (Sec.~\ref{sec:appendix}).
