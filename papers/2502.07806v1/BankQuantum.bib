@article{Shi2022,
	author = {Shi, Si and Tse, Rita and Luo, Wuman and D'Addona, Stefano and Pau, Giovanni},
	title = {Machine learning-driven credit risk: a systemic review},
	journal = {Neural Computing and Applications},
	year = {2022},
	volume = {34},
	number = {17},
	pages = {14327--14339},
	month = sep,
	doi = {10.1007/s00521-022-07472-2},
	url = {https://doi.org/10.1007/s00521-022-07472-2},
	issn = {1433-3058},
	abstract = {Credit risk assessment is at the core of modern economies. Traditionally, it is measured by statistical methods and manual auditing. Recent advances in financial artificial intelligence stemmed from a new wave of machine learning (ML)-driven credit risk models that gained tremendous attention from both industry and academia. In this paper, we systematically review a series of major research contributions (76 papers) over the past eight years using statistical, machine learning and deep learning techniques to address the problems of credit risk. Specifically, we propose a novel classification methodology for ML-driven credit risk algorithms and their performance ranking using public datasets. We further discuss the challenges including data imbalance, dataset inconsistency, model transparency, and inadequate utilization of deep learning models. The results of our review show that: 1) most deep learning models outperform classic machine learning and statistical algorithms in credit risk estimation, and 2) ensemble methods provide higher accuracy compared with single models. Finally, we present summary tables in terms of datasets and proposed models.},
}

@article{WANG2011223,
	title = {A comparative assessment of ensemble learning for credit scoring},
	journal = {Expert Systems with Applications},
	volume = {38},
	number = {1},
	pages = {223-230},
	year = {2011},
	issn = {0957-4174},
	doi = {https://doi.org/10.1016/j.eswa.2010.06.048},
	url = {https://www.sciencedirect.com/science/article/pii/S095741741000552X},
	author = {Gang Wang and Jinxing Hao and Jian Ma and Hongbing Jiang},
	keywords = {Credit scoring, Ensemble learning, Bagging, Boosting, Stacking},
	abstract = {Both statistical techniques and Artificial Intelligence (AI) techniques have been explored for credit scoring, an important finance activity. Although there are no consistent conclusions on which ones are better, recent studies suggest combining multiple classifiers, i.e., ensemble learning, may have a better performance. In this study, we conduct a comparative assessment of the performance of three popular ensemble methods, i.e., Bagging, Boosting, and Stacking, based on four base learners, i.e., Logistic Regression Analysis (LRA), Decision Tree (DT), Artificial Neural Network (ANN) and Support Vector Machine (SVM). Experimental results reveal that the three ensemble methods can substantially improve individual base learners. In particular, Bagging performs better than Boosting across all credit datasets. Stacking and Bagging DT in our experiments, get the best performance in terms of average accuracy, type I error and type II error.}
}

@article{GOLBAYANI2020101251,
	title = {A comparative study of forecasting corporate credit ratings using neural networks, support vector machines, and decision trees},
	journal = {The North American Journal of Economics and Finance},
	volume = {54},
	pages = {101251},
	year = {2020},
	issn = {1062-9408},
	doi = {https://doi.org/10.1016/j.najef.2020.101251},
	url = {https://www.sciencedirect.com/science/article/pii/S1062940820301480},
	author = {Parisa Golbayani and Ionuţ Florescu and Rupak Chatterjee},
	keywords = {Machine learning models, Support vector machine, Credit rating, Neural networks, Classification trees},
	abstract = {Credit ratings are one of the primary keys that reflect the level of riskiness and reliability of corporations to meet their financial obligations. Rating agencies tend to take extended periods of time to provide new ratings and update older ones. Therefore, credit scoring assessments using artificial intelligence has gained a lot of interest in recent years. Successful machine learning methods can provide rapid analysis of credit scores while updating older ones on a daily time scale. Related studies have shown that neural networks and support vector machines outperform other techniques by providing better prediction accuracy. The purpose of this paper is two fold. First, we provide a survey and a comparative analysis of results from literature applying machine learning techniques to predict credit rating. Second, we apply ourselves four machine learning techniques deemed useful from previous studies (Bagged Decision Trees, Random Forest, support vector machine and Multilayer Perceptron) to the same datasets. We evaluate the results using a 10-fold cross validation technique. The results of the experiment for the datasets chosen show superior performance for decision tree based models. In addition to the conventional accuracy measure of classifiers, we introduce a measure of accuracy based on notches called ”Notch Distance” to analyze the performance of the above classifiers in the specific context of credit rating. This measure tells us how far the predictions are from the true ratings. We further compare the performance of three major rating agencies, Standard & Poors, Moody’s and Fitch where we show that the difference in their ratings is comparable with the decision tree prediction versus the actual rating on the test dataset.}
}

@article{DUAN20194716,
	title = {Financial system modeling using deep neural networks (DNNs) for effective risk assessment and prediction},
	journal = {Journal of the Franklin Institute},
	volume = {356},
	number = {8},
	pages = {4716-4731},
	year = {2019},
	issn = {0016-0032},
	doi = {https://doi.org/10.1016/j.jfranklin.2019.01.046},
	url = {https://www.sciencedirect.com/science/article/pii/S0016003219301462},
	author = {Jing Duan},
	abstract = {Since the risk of loan defaulting in peer-to-peer (P2P) lending is notoriously difficult to evaluate, a deep neural network-based decision-making approach is proposed in this work for more effective assessment of P2P lending risks. Although normally a dozen features were used for neural network modeling in previous studies carried out by other researchers on similar topics, more comprehensive features including both numeric and categorical ones (e.g. home ownership and purpose of loan), are considered in this work for improved modeling. Since categorical data cannot be used directly as the input of neural networks, they are converted to numerical data using one-hot encoding function. The deep neural network (DNN) used in this work is a multilayer perceptron (MLP) with three hidden layers trained by the back-propagation algorithm. In empirical analysis, the loan data issued by the Lending Club through 2007–2015 are classified into three classes, i.e. safe loan, risky loan and bad loan using TensorFlow. The training and test data sets consist of 221,712 and 55,428 data observations, respectively. Since most of the data belong to the class of safe loan, Synthetic Minority Over-Sampling Technique (SMOTE) is used to improve the DNN prediction accuracy. It is shown that with the proposed approach the test data are classified at an accuracy of 93%, which is much higher than the predication accuracy of 75% obtained using MLP with only one hidden layer.}
}

@article{SHEN2021106852,
	title = {A new deep learning ensemble credit risk evaluation model with an improved synthetic minority oversampling technique},
	journal = {Applied Soft Computing},
	volume = {98},
	pages = {106852},
	year = {2021},
	issn = {1568-4946},
	doi = {https://doi.org/10.1016/j.asoc.2020.106852},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494620307900},
	author = {Feng Shen and Xingchao Zhao and Gang Kou and Fawaz E. Alsaadi},
}

@article{Mahbobi2023,
	author = {Mahbobi, Mohammad and Kimiagari, Salman and Vasudevan, Marriappan},
	title = {Credit risk classification: an integrated predictive accuracy algorithm using artificial and deep neural networks},
	journal = {Annals of Operations Research},
	year = {2023},
	volume = {330},
	number = {1},
	pages = {609--637},
	month = nov,
	doi = {10.1007/s10479-021-04114-z},
	url = {https://doi.org/10.1007/s10479-021-04114-z},
	issn = {1572-9338},
	abstract = {This study utilizes classification models to provide a robust algorithm for imbalanced data where the minority class is of the interest, that is, in the context of default payments. In developing an integrated predictive accuracy algorithm, this study proposes machine learning classifiers and applies DNN, SVM, KNN, and ANN. The proposed algorithm utilizes a 30,000 imbalanced dataset to improve the accuracy of the prediction of default payments by implementing oversampling and undersampling strategies, such as synthetic minority oversampling technique (SMOTE), SVM SMOTE, random undersampling, and ALL-KNN. The results indicate that the SVM under the ALL-KNN sampling technique is able to achieve an accuracy of 98.6%, with the lowest cross entropy loss measurement of 0.028. Through the accurate implementation of the neural networks and neurons used in the proposed algorithm, this paper presents better insights into the functioning of the neural networks when used in conjunction with the resampling techniques. Using the methodology and algorithm presented in this study, credit risk assessments can be more accurately predicted in practical applications where most of the clients are categorized as non-default payments.}
}


@article{ORUS2019100028,
	title = {Quantum computing for finance: Overview and prospects},
	journal = {Reviews in Physics},
	volume = {4},
	pages = {100028},
	year = {2019},
	issn = {2405-4283},
	doi = {https://doi.org/10.1016/j.revip.2019.100028},
	url = {https://www.sciencedirect.com/science/article/pii/S2405428318300571},
	author = {Román Orús and Samuel Mugel and Enrique Lizaso},
	abstract = {We discuss how quantum computation can be applied to financial problems, providing an overview of current approaches and potential prospects. We review quantum optimization algorithms, and expose how quantum annealers can be used to optimize portfolios, find arbitrage opportunities, and perform credit scoring. We also discuss deep-learning in finance, and suggestions to improve these methods through quantum machine learning. Finally, we consider quantum amplitude estimation, and how it can result in a quantum speed-up for Monte Carlo sampling. This has direct applications to many current financial methods, including pricing of derivatives and risk analysis. Perspectives are also discussed.}
}


@article{Wilkens2023,
	author = {Wilkens, Sascha and Moorhouse, Joe},
	title = {Quantum computing for financial risk measurement},
	journal = {Quantum Information Processing},
	year = {2023},
	volume = {22},
	number = {1},
	pages = {51},
	month = jan,
	doi = {10.1007/s11128-022-03777-2},
	url = {https://doi.org/10.1007/s11128-022-03777-2},
	issn = {1573-1332},
	abstract = {Quantum computing allows a significant speed-up over traditional CPU- and GPU-based algorithms when applied to particular mathematical challenges such as optimisation and simulation. Despite promising advances and extensive research in hard- and software developments, currently available quantum systems are still largely limited in their capability. In line with this, practical applications in quantitative finance are still in their infancy. This paper analyses requirements and concrete approaches for the application to risk management in a financial institution. On the examples of Value-at-Risk for market risk and Potential Future Exposure for counterparty credit risk, the main contribution lies in going beyond textbook illustrations and instead exploring must-have model features and their quantum implementations. While conceptual solutions and small-scale circuits are feasible at this stage, the leap needed for real-life applications is still significant. In order to build a usable risk measurement system, the hardware capacity—measured in number of qubits—would need to increase by several magnitudes from their current value of about $$10^2$$. Quantum noise poses an additional challenge, and research into its control and mitigation would need to advance in order to render risk measurement applications deployable in practice. Overall, given the maturity of established classical simulation-based approaches that allow risk computations in reasonable time and with sufficient accuracy, the business case for a move to quantum solutions is not very strong at this point.}
}

@article{Aboussalah2023,
	author = {Aboussalah, Amine Mohamed and Chi, Cheng and Lee, Chi-Guhn},
	title = {Quantum computing reduces systemic risk in financial networks},
	journal = {Scientific Reports},
	year = {2023},
	volume = {13},
	number = {1},
	pages = {3990},
	month = mar,
	doi = {10.1038/s41598-023-30710-z},
	url = {https://doi.org/10.1038/s41598-023-30710-z},
	issn = {2045-2322},
	abstract = {In highly connected financial networks, the failure of a single institution can cascade into additional bank failures. This systemic risk can be mitigated by adjusting the loans, holding shares, and other liabilities connecting institutions in a way that prevents cascading of failures. We are approaching the systemic risk problem by attempting to optimize the connections between the institutions. In order to provide a more realistic simulation environment, we have incorporated nonlinear/discontinuous losses in the value of the banks. To address scalability challenges, we have developed a two-stage algorithm where the networks are partitioned into modules of highly interconnected banks and then the modules are individually optimized. We developed a new algorithms for classical and quantum partitioning for directed and weighed graphs (first stage) and a new methodology for solving Mixed Integer Linear Programming problems with constraints for the systemic risk context (second stage). We compare classical and quantum algorithms for the partitioning problem. Experimental results demonstrate that our two-stage optimization with quantum partitioning is more resilient to financial shocks, delays the cascade failure phase transition, and reduces the total number of failures at convergence under systemic risks with reduced time complexity.}
}

@article{rath2024quantum,
	title={Quantum data encoding: a comparative analysis of classical-to-quantum mapping techniques and their impact on machine learning accuracy},
	author={Rath, Minati and Date, Hema},
	journal={EPJ Quantum Technology},
	volume={11},
	number={1},
	pages={72},
	year={2024},
	doi={10.1140/epjqt/s40507-024-00285-3},
	url={https://doi.org/10.1140/epjqt/s40507-024-00285-3}
}

@article{lloyd2013quantum,
	title={Quantum algorithms for supervised and unsupervised machine learning},
	author={Lloyd, Seth and Mohseni, Masoud and Rebentrost, Patrick},
	journal={arXiv preprint arXiv:1307.0411},
	year={2013}
}
@article{Schuld2019,
	abstract = {A basic idea of quantum computing is surprisingly similar to that of kernel methods in machine learning, namely, to efficiently perform computations in an intractably large Hilbert space. In this Letter we explore some theoretical foundations of this link and show how it opens up a new avenue for the design of quantum machine learning algorithms. We interpret the process of encoding inputs in a quantum state as a nonlinear feature map that maps data to quantum Hilbert space. A quantum computer can now analyze the input data in this feature space. Based on this link, we discuss two approaches for building a quantum model for classification. In the first approach, the quantum device estimates inner products of quantum states to compute a classically intractable kernel. The kernel can be fed into any classical kernel method such as a support vector machine. In the second approach, we use a variational quantum circuit as a linear model that classifies data explicitly in Hilbert space. We illustrate these ideas with a feature map based on squeezing in a continuous-variable system, and visualize the working principle with two-dimensional minibenchmark datasets.},
	archivePrefix = {arXiv},
	arxivId = {1803.07128},
	author = {Schuld, Maria and Killoran, Nathan},
	doi = {10.1103/PhysRevLett.122.040504},
	eprint = {1803.07128},
	issn = {10797114},
	journal = {Physical Review Letters},
	month = {feb},
	number = {4},
	pages = {040504},
	pmid = {30768345},
	publisher = {American Physical Society},
	title = {{Quantum Machine Learning in Feature Hilbert Spaces}},
	url = {https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.122.040504},
	volume = {122},
	year = {2019}
}

@inproceedings{Shor2002,
	author = {Shor, P.W.},
	title = {Algorithms for quantum computation: discrete logarithms and factoring},
	booktitle = {Proceedings of the 35th Annual ACM Symposium on Theory of Computing (STOC)},
	year = {2002},
	doi = {10.1109/sfcs.1994.365700},
	abstract = {A computer is generally considered to be a universal computational device; i.e., it is believed able to simulate any physical computational device with a cost in computation time of at most a polynomial factor: It is not clear whether this is still true when quantum mechanics is taken into consideration. Several researchers, starting with David Deutsch, have developed models for quantum mechanical computers and have investigated their computational properties. This paper gives Las Vegas algorithms for finding discrete logarithms and factoring integers on a quantum computer that take a number of steps which is polynomial in the input size, e.g., the number of digits of the integer to be factored. These two problems are generally considered hard on a classical computer and have been used as the basis of several proposed cryptosystems. We thus give the first examples of quantum cryptanalysis.}
}


@INPROCEEDINGS{9528698,
	author={Kwak, Yunseok and Yun, Won Joon and Jung, Soyi and Kim, Joongheon},
	booktitle={2021 Twelfth International Conference on Ubiquitous and Future Networks (ICUFN)}, 
	title={Quantum Neural Networks: Concepts, Applications, and Challenges}, 
	year={2021},
	volume={},
	number={},
	pages={413-416},
	keywords={Deep learning;Training;Artificial neural networks;Quantum circuit},
	doi={10.1109/ICUFN49451.2021.9528698}}

@inproceedings{Grover1996,
	abstract = {An unsorted database contains N records, of which just one satisfies a particular property. The problem is to identify that one record. Any classical algorithm, deterministic or probabilistic, will clearly take O (N) steps since on the average it will have to examine a large fraction of the N records. Quantum mechanical systems can do several operations simultaneously due to their wave like properties. This paper gives an O (√N) step quantum mechanical algorithm for identifying that record. It is within a constant factor of the fastest possible quantum mechanical algorithm.},
	archivePrefix = {arXiv},
	arxivId = {quant-ph/9605043},
	author = {Grover, Lov K.},
	booktitle = {Proceedings of the Annual ACM Symposium on Theory of Computing},
	doi = {10.1145/237814.237866},
	eprint = {9605043},
	isbn = {0897917855},
	issn = {07378017},
	month = {jul},
	pages = {212--219},
	primaryClass = {quant-ph},
	publisher = {Association for Computing Machinery},
	title = {{A fast quantum mechanical algorithm for database search}},
	volume = {Part F1294},
	year = {1996}
}

@misc{Nielsen2000,
	author = {Nielsen, MA and Chuang, IL},
	publisher = {Cambridge University Press},
	title = {{Quantum Computation and Quantum Information}},
	year = {2000}
}

@ARTICLE{rath2023quantumassistedsimulationframeworkdesigning,
	title={Quantum-Assisted Simulation: A Framework for Designing Machine Learning Models in the Quantum Computing Domain}, 
	author={Minati Rath and Hema Date},
	journal = {https://arxiv.org/abs/2311.10363},
	year={2023},
	eprint={2311.10363},
	archivePrefix={arXiv},
	primaryClass={quant-ph},
	url={https://arxiv.org/abs/2311.10363} 
}

@ARTICLE{rath2023adaptivemodellingapproachrowtype,
	title={Adaptive Modelling Approach for Row-Type Dependent Predictive Analysis (RTDPA): A Framework for Designing Machine Learning Models for Credit Risk Analysis in Banking Sector}, 
	author={Minati Rath and Hema Date},
	journal = {https://arxiv.org/abs/2311.10799},
	year={2023},
	eprint={2311.10799},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2311.10799}, 
}


@ARTICLE{Saberi2013100,
	author = {Saberi, Morteza and Mirtalaie, Monireh Sadat and Hussain, Farookh Khadeer and Azadeh, Ali and Hussain, Omar Khadeer and Ashjari, Behzad},
	title = {A granular computing-based approach to credit scoring modeling},
	year = {2013},
	journal = {Neurocomputing},
	volume = {122},
	pages = {100 – 115},
	doi = {10.1016/j.neucom.2013.05.020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884209840&doi=10.1016%2fj.neucom.2013.05.020&partnerID=40&md5=8231f1d58b1871d2ce907158b5484816},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29}
}


@article{Biamonte2017,
author    = {Jacob Biamonte and Peter Wittek and Nicola Pancotti and Patrick Rebentrost and Nathan Wiebe and Seth Lloyd},
title     = {Quantum machine learning},
journal   = {Nature},
year      = {2017},
volume    = {549},
number    = {7671},
pages     = {195--202},
month     = sep,
doi       = {10.1038/nature23474},
url       = {https://doi.org/10.1038/nature23474},
issn      = {1476-4687},
abstract  = {Fuelled by increasing computer power and algorithmic advances, machine learning techniques have become powerful tools for finding patterns in data. Quantum systems produce atypical patterns that classical systems are thought not to produce efficiently, so it is reasonable to postulate that quantum computers may outperform classical computers on machine learning tasks. The field of quantum machine learning explores how to devise and implement quantum software that could enable machine learning that is faster than that of classical computers. Recent work has produced quantum algorithms that could act as the building blocks of machine learning programs, but the hardware and software challenges are still considerable.}
}

@article{bravyi2016quantum,
  title={A Quantum-Inspired Classical Algorithm for Kernel Learning},
  author={Bravyi, Sergey and Kapourniotis, Theodoros and Kraus, Barbara},
  journal={arXiv preprint arXiv:1611.09347},
  year={2016}
}

@article{schuld2016quantum,
  title={Quantum machine learning with quantum-enhanced feature spaces},
  author={Schuld, Maria and Sinayskiy, Ilya and Petruccione, Francesco},
  journal={arXiv preprint arXiv:1603.04821},
  year={2016}
}

@article{havlicek2019supervised,
  title={Supervised learning with quantum-enhanced feature spaces},
  author={Havl{\'i}{\v{c}}ek, Vojt{\v{e}}ch and C{\'a}rdenas-Valencia, Andr{\'e}s M and Aspuru-Guzik, Al{\'a}n},
  journal={Nature},
  volume={567},
  number={7747},
  pages={209--212},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{biamonte2017quantum,
  title={Quantum Neural Networks},
  author={Biamonte, Jacob and Bergholm, Ville and Wittek, Peter and Pancotti, Nicola and Rebentrost, Patrick and Lloyd, Seth},
  journal={arXiv preprint arXiv:1711.11240},
  year={2017}
}


@article{thakkar2024improved,
	title={Improved financial forecasting via quantum machine learning},
	author={Thakkar, Sohum and Kazdaghli, Skander and Mathur, Natansh and Kerenidis, Iordanis and Ferreira--Martins, André J. and Brito, Samurai},
	journal={Quantum Machine Intelligence},
	volume={6},
	number={1},
	pages={27},
	year={2024},
	doi={10.1007/s42484-024-00157-0},
	url={https://doi.org/10.1007/s42484-024-00157-0}
}

@article{schuld2019quantum,
  title={Quantum Machine Learning for Finance},
  author={Schuld, Maria and Fingerhuth, Mark and Petruccione, Francesco},
  journal={arXiv preprint arXiv:1907.03044},
  year={2019}
}

@article{mitarai2018quantum,
	title={Quantum circuit learning},
	author={Mitarai, Kosuke and Negoro, Makoto and Kitagawa, Masahiro and Fujii, Keisuke},
	journal={Physical Review A},
	volume={98},
	number={3},
	pages={032309},
	year={2018},
	publisher={APS}
}

@article{schuld2019evaluating,
	title={Evaluating analytic gradients on quantum hardware},
	author={Schuld, Maria and Bergholm, Ville and Gogolin, Christian and Izaac, Josh and Killoran, Nathan},
	journal={Physical Review A},
	volume={99},
	number={3},
	pages={032331},
	year={2019},
	publisher={APS}
} 
@ARTICLE{Marqués20131384,
	author = {Marqués, A.I. and García, V. and Sánchez, J.S.},
	title = {A literature review on the application of evolutionary computing to credit scoring},
	year = {2013},
	journal = {Journal of the Operational Research Society},
	volume = {64},
	number = {9},
	pages = {1384 – 1399},
	doi = {10.1057/jors.2012.145},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881294492&doi=10.1057%2fjors.2012.145&partnerID=40&md5=cbec614f7da49b87a96b803b885aceca},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 69; All Open Access, Green Open Access}
}


@ARTICLE{Egger20212136,
	author = {Egger, Daniel J. and Garcia Gutierrez, Ricardo and Mestre, Jordi Cahue and Woerner, Stefan},
	title = {Credit Risk Analysis Using Quantum Computers},
	year = {2021},
	journal = {IEEE Transactions on Computers},
	volume = {70},
	number = {12},
	pages = {2136 – 2145},
	doi = {10.1109/TC.2020.3038063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097134114&doi=10.1109%2fTC.2020.3038063&partnerID=40&md5=479598827846ce2a43661130fb432dbf},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30; All Open Access, Green Open Access}
}


@article{lourens2023hierarchical,
	title={Hierarchical quantum circuit representations for neural architecture search},
	author={Lourens, Matt and Sinayskiy, Ilya and Park, Daniel K. and Blank, Carsten and Petruccione, Francesco},
	journal={npj Quantum Information},
	volume={9},
	number={1},
	pages={79},
	year={2023},
	doi={10.1038/s41534-023-00747-z},
	url={https://doi.org/10.1038/s41534-023-00747-z}
}


@article{lee2020,
	author = {Lee, S. Y. and Wang, C. H.},
	title = {The impact of data augmentation on machine learning performance in credit scoring},
	journal = {Journal of Financial Services Marketing},
	volume = {25},
	number = {4},
	pages = {213--225},
	year = {2020}
}

@article{li2021,
	author = {Li, Y. and others},
	title = {A new approach to data augmentation for credit risk modeling using machine learning},
	journal = {International Journal of Information Technology \& Decision Making},
	volume = {20},
	number = {4},
	pages = {1277--1296},
	year = {2021}
}

@article{kumar2022,
	author = {Kumar, A. and Singh, M.},
	title = {Addressing class imbalance in banking datasets: An empirical study on credit scoring},
	journal = {Expert Systems with Applications},
	volume = {193},
	pages = {116462},
	year = {2022}
}

@article{cai2019quantum,
	author = {Cai, K. and Zhang, Z. and Ye, X.},
	title = {Quantum Algorithms for Linear Algebra: Theoretical Insights and Practical Considerations},
	journal = {arXiv preprint arXiv:1901.10796},
	year = {2019}
}

@article{zhang2020quantum,
	author = {Zhang, H. and Wang, Z. and Zhang, S.},
	title = {Quantum Neural Networks: A Review},
	journal = {Entropy},
	volume = {22},
	number = {9},
	pages = {956},
	doi = {10.3390/e22090956},
	year = {2020}
}



@article{coyle2022quantum,
	author = {Coyle, B. and Leung, D.},
	title = {Quantum Machine Learning for Financial Applications},
	journal = {IEEE Transactions on Quantum Engineering},
	volume = {3},
	pages = {1--10},
	doi = {10.1109/TQE.2022.3141800},
	year = {2022}
}

@article{jha2020quantum,
	author = {Jha, A. and Cincio, L.},
	title = {Quantum Algorithms for Classical Machine Learning Tasks},
	journal = {Physical Review Letters},
	volume = {124},
	number = {12},
	pages = {120504},
	doi = {10.1103/PhysRevLett.124.120504},
	year = {2020}
}

@article{farhi2018classification,
	author = {Farhi, E. and Neven, H.},
	title = {Classification with Quantum Neural Networks on Near Term Processors},
	journal = {arXiv preprint arXiv:1802.06002},
	year = {2018}
}

@article{Chen2016,
	author = {Chen, Ning and Ribeiro, Bernardete and Chen, An},
	title = {Financial credit risk assessment: a recent review},
	journal = {Artificial Intelligence Review},
	year = {2016},
	volume = {45},
	number = {1},
	pages = {1--23},
	doi = {10.1007/s10462-015-9434-x},
	url = {https://doi.org/10.1007/s10462-015-9434-x},
	sn = {1573-7462}
}

@article{0bacd96f632b4c96923264bc498e3ad0,
	title = "A Novel Dynamic Neural System for Nonconvex Portfolio Optimization With Cardinality Restrictions",
	abstract = "The Markowitz model, a portfolio analysis model that won the Nobel Prize, lays the theoretical groundwork for modern finance. The transaction cost and the cardinality restriction, which were not covered in Markowitz model, are becoming increasingly important with the advent of high-frequency trading era. However, it remains a challenging problem to consider those constraints due to the nonconvex nature of the problem. A novel dynamic neural network, inspired by its successes in machine learning, is developed to tackle this difficult issue. Theoretical analysis is provided for the convergence of the designed neural network. Experimental results using real stock market data confirm the effectiveness of the proposed model. With the proposed model, the cost function characterizing the overall risks, and rewards is reduced by 123.6% from -4.549× 10-5 to -1.0173× 10-4. This indicates that the proposed strategy is successful in reducing risks and increasing rewards.",
	keywords = "Cardinality constraint, dynamic neural network, Markowitz model, nonconvex optimization, portfolio optimization",
	author = "Xinwei Cao and Shuai Li",
	year = "2023",
	month = nov,
	day = "1",
	doi = "10.1109/TSMC.2023.3288224",
	language = "English",
	volume = "53",
	pages = "6943--6952",
	journal = "IEEE Transactions on Systems, Man, and Cybernetics: Systems",
	issn = "2168-2216",
	publisher = "IEEE Advancing Technology for Humanity",
	number = "11",
}

@article{CAO2023120934,
	title = {A novel recurrent neural network based online portfolio analysis for high frequency trading},
	journal = {Expert Systems with Applications},
	volume = {233},
	pages = {120934},
	year = {2023},
	issn = {0957-4174},
	doi = {https://doi.org/10.1016/j.eswa.2023.120934},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417423014367},
	author = {Xinwei Cao and Adam Francis and Xujin Pu and Zenan Zhang and Vasilios Katsikis and Predrag Stanimirovic and Ivona Brajevic and Shuai Li},
	keywords = {Recurrent neural network, Pareto frontier, Portfolio analysis, Markowitz model, Time-varying problem},
	abstract = {The Markowitz model, a Nobel Prize winning model for portfolio analysis, paves the theoretical foundation in finance for modern investment. However, it remains a challenging problem in the high frequency trading (HFT) era to find a more time efficient solution for portfolio analysis, especially when considering circumstances with the dynamic fluctuation of stock prices and the desire to pursue contradictory objectives for less risk but more return. In this paper, we establish a recurrent neural network model to address this challenging problem in runtime. Rigorous theoretical analysis on the convergence and the optimality of portfolio optimization are presented. Numerical experiments are conducted based on real data from Dow Jones Industrial Average (DJIA) components and the results reveal that the proposed solution is superior to DJIA index in terms of higher investment returns and lower risks.}
}
