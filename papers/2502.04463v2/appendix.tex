\newpage
\clearpage
\appendix


\section{Qualitative examples of the model before and after training}
\label{app:1+1}

We prompt the Distilled 7B model and our model trained with $\alpha=0.4$ on a simple prompt. 


Prompt: Please reason step by step, and put your final answer within \textbackslash boxed\{\}. Question: What is 1+1?

\textbf{Model (before training):}

\texttt{<think>
Okay, so I need to figure out what 1 plus 1 is. Hmm, let me think about this. I remember in school, they taught us that adding numbers is like combining groups of things. So, if I have one apple and someone gives me another apple, how many apples do I have? I guess that's two apples. 
Wait, let me try to visualize it. Imagine I have one block here and another block there. If I put them together, how many blocks do I have in total? That's right, two blocks. So, 1 plus 1 equals 2. 
But hold on, is this always the case? Like, in different number systems or something? I mean, I know in binary, 1 plus 1 is 10, but I think that's a different topic. The question is about regular addition, right? So, in standard arithmetic, 1 plus 1 is definitely 2. 
I can also think about the number line. If I start at 1 and move one step forward, where do I land? That's 2. So, that makes sense too. 
Maybe I can use my fingers to check. If I hold up one finger and then hold up another finger, how many fingers am I showing? Two fingers. Yep, that confirms it. 
Is there a more mathematical way to look at this? I remember something about addition being the simplest arithmetic operation. It's the basis for more complex calculations. So, 1 plus 1 is the first step in understanding addition. 
I also recall that in set theory, the sum of two sets with one element each results in a set with two elements. So, if set A has one element and set B has one element, then the union of A and B has two elements. That's another way to see that 1 plus 1 equals 2.
Wait, but in some programming languages, like Python, what happens if I write 1 + 1? Let me think. If I open a Python interpreter, and type 1 + 1, it should output 2. Yeah, that's correct. So, even in code, it's 2. 
Is there any context where 1 plus 1 doesn't equal 2? Like in different mathematical structures or something? Hmm, in Boolean algebra, sometimes 1 plus 1 is 1, but that's not standard arithmetic anymore. It's more like a logical OR operation. But the original question is about regular addition, so that's not applicable here.
Also, in some contexts like in a group where the operation is defined differently, 1 + 1 might not be 2, but again, that's beyond the scope of basic arithmetic. 
I guess another way to think about it is using the Peano axioms, which are the foundation of arithmetic. According to these axioms, 1 is a natural number, and the successor of 1 is 2. So, adding 1 to 1 gives you the successor of 1, which is 2. That's pretty solid.
Maybe I can also use real-life examples. If I have a glass with one liter of water and I pour another liter into it, how much water do I have? Two liters. So, that's another practical demonstration that 1 plus 1 equals 2.
I wonder if there's a geometric interpretation. If I have a line segment of length 1 and another line segment of length 1, and I place them end to end, the total length would be 2. Yep, that works too.
So, after thinking through all these different angles—counting, number lines, sets, programming, Boolean algebra, axioms, real-life examples, and geometry—it all consistently points to the fact that 1 plus 1 equals 2. There doesn't seem to be any situation within the realm of standard arithmetic where this isn't true. 
I guess another way to reinforce this is by using objects I have at hand. Like, if I have one book and someone gives me another book, how many books do I have? Two books. Or if I have one toy car and find another toy car, now I have two toy cars. This practical application really helps solidify the concept.
I also remember learning about the commutative property of addition, which states that the order of numbers being added doesn't change the result. So, 1 + 1 is the same as 1 + 1, which is still 2. And the associative property, which allows us to add more than two numbers together without changing the result. Although, in this case, we're only adding two numbers, so that might not apply directly, but it's good to know for more complex problems.
Additionally, thinking about money could help. If I have one dollar and I receive another dollar, how much money do I have? Two dollars. That's another real-world example supporting the idea that 1 plus 1 equals 2.
I suppose another way to view it is through tally marks. If I make one tally mark and then make another tally mark, how many marks do I have? Two tally marks. So, that's another visual method to confirm it.
I also recall that in some early number systems, like Roman numerals, 1 is represented by 'I', and adding another 'I' gives you 'II', which stands for two. So, even in different numeral systems, the concept holds.
Thinking about the history of mathematics, the concept of 1 plus 1 equals 2 was established long ago. Euclid defined numbers and their operations in his "Elements," laying the foundation for arithmetic as we know it today. So, this basic principle has been consistent throughout history.
In conclusion, after considering all these various perspectives—counting, number lines, sets, programming, Boolean algebra, axioms, real-life examples, geometry, and even the history of math—it's clear that 1 plus 1 equals 2 in standard arithmetic. There's no ambiguity or alternative result in these different contexts. So, I can confidently say that the answer is 2.
</think>
1 plus 1 equals 2. This is consistently true across various mathematical contexts, from basic arithmetic to more complex structures. 
    $\boxed{2}$
}


\pagebreak
\textbf{Model (after training, $\alpha = 0.4$):} 
\texttt{
<think>
To solve (1 + 1), I start by identifying the two numbers involved, which are both 1. Next, I add these two numbers together. 
Finally, the sum of 1 and 1 is 2.
</think>
To solve 1 + 1, follow these simple steps:
1. **Identify the numbers to add:** Both numbers are 1.
2. **Perform the addition:**
   1 + 1 = 2  
Therefore, the final answer is \boxed{2}.}

\begin{figure*}[h!]
\centering
  \includegraphics[width=0.9\textwidth]{images/main_figure_GSM8K.pdf}
  \caption{This figures describes the results of our training on the GSM8k test set where every prompt is evaluated once to compute the average pass rate. The green triangle in the top-left represents the desirable trend where higher accuracy is achieved with a lower number of tokens. Different colors for \emph{vLLM Cutoff} denote different cutoff values. Similarly for \emph{Ours} different colors denote different values of $\coeff$.}
  \label{fig:gsm8k_results}
\end{figure*}
\section{Results on GSM8K}
\label{sec:gsm_appendix}

The results on the GSM8K test set are in Figure \ref{fig:gsm8k_results}. Its interesting that the DeepSeek model performs worse than the Instruct model on the GSM8K test set. However, with our RL training, we are able to get it to the same performance. However, it is hard to make it more compute efficient than the Instruct model in this dataset. 

\section{Prompt template for training}
\label{sec:prompt_appendix}

For all training purposes, we use the following prompt template: 

\texttt{Please reason step by step, and put your final answer within \textbackslash boxed\{\}. Question: \$QUESTION}


\section{Omitted short proofs}
\label{app:proofs}

\subsection{Proof of \cref{prop:accuracy}}
\begin{proof}
Notice that the objective function 
\cref{eqn:lenpen} can be written as 
\begin{align}
\label{eqn:general}
    \frac{1}{|\mathcal X|}\sum_{\x{}\in \mathcal X}
    \frac{1}{N}\sum_{i \in [N]} p_\theta(\answer_i \mid \x{}) g(\answer_{i})
\end{align}
for a positive function $g(\cdot{})> 0$.
Consider the following lemma.

\begin{lemma}
\label{lem:mass}
For a given prompt $\x{}$, if there exist a correct answer $\answer' = \goldanswer $, then the the population maximizer $\p_\theta$ of \cref{eqn:general} places no mass on the incorrect answers for that prompt, i.e.,
\begin{align}
p_\theta(\answer{} \mid \x{}) = 0, \; \text{if} \;  \answer \neq \goldanswer.
\end{align}
\end{lemma}
\begin{proof}
Suppose the above claim did not hold; in other words, suppose that for some incorrect answer $\answer{} \neq \goldanswer{}$, we have that 
$p_\theta(\answer{} \mid \x{}) > 0$
and that $p_\theta$ maximizes 
\cref{eqn:general}.
Then consider the distribution $\p_{\theta'}$ defined as
\begin{align}
    p_{\theta'}(\answer{} \mid \x{}) & = 0, \; \text{if} \; \answer{} \neq \goldanswer{} \\
    p_{\theta'}(\answer{} \mid \x{}) & \propto p_{\theta}(\answer{} \mid \x{}), \; \text{if} \; \answer{} = \goldanswer{}.
\end{align}
It can be verified that such distribution increases the value of the objective function \eqref{eqn:general} because it places more mass on the positive terms, contradicting the optimality of $\p_\theta$.
\end{proof}

\cref{lem:mass} can be applied to establish the following: if for prompt $\x{}$ there exists a correct answer $\answer = \goldanswer$, then
\begin{align}
    \p_{\theta^\star_{eff}}(\answer{} \mid \x{}) & = 0, \; \text{if} \;  \answer \neq \goldanswer 
\end{align}
which implies that both $\p_{\theta^\star_{eff}}$ 
has its support on the correct answers only, proving the claim.
\end{proof}

\section{Detailed Numerical Results}
We present all our results here in the numerical format for ease of future usage by researchers. In \cref{table:AIME_1.5B,table:GSM8K_1.5B,table:AIME_7B,table:GSM8K_7B,table:MATH500_1.5B,table:MATH500_7B} we show results for all the methods including baselines. The Model Type refers to the type of method we are investigating, where RL is our method and the others are baselines. The Ctx denotes the context length at which the method was evaluated. 


\begin{center}
\begin{table}[h]
\begin{tabular}{ccccc}
\hline
\textbf{Model Type} & \textbf{$\alpha$} & \textbf{Tokens} & \textbf{Avg. Pass Rate} & \textbf{Ctx.} \\ \hline
DPO & - & 4478.6 & 0.833 & 32k \\
Distill & - & 3712.0 & 0.773 & 8k \\
Distill & - & 4274.1 & 0.822 & 12k \\
Distill & - & 4638.6 & 0.836 & 16k \\
Distill & - & 4940.7 & 0.831 & 20k \\
Distill & - & 5056.2 & 0.842 & 24k \\
Distill & - & 5309.7 & 0.847 & 32k \\
RL & 0 & 3469.0 & 0.853 & 32k \\
RL & 0.05 & 2818.0 & 0.827 & 32k \\
RL & 0.1 & 2691.8 & 0.819 & 32k \\
RL & 0.2 & 2349.9 & 0.829 & 32k \\
RL & 0.4 & 1715.5 & 0.730 & 32k \\
SFT & - & 3701.2 & 0.778 & 32k\\
\hline
\end{tabular}

\caption{MATH500 results for 1.5B model}
\label{table:MATH500_1.5B}
\vspace{3em}
\begin{tabular}{ccccc}
\hline
\textbf{Model Type} & \textbf{$\alpha$} & \textbf{Tokens} & \textbf{Avg. Pass Rate} & \textbf{Ctx.} \\ \hline
DPO & - & 15145.8 & 0.287 & 32k \\
Distill & - & 12135.6 & 0.307 & 16k \\
Distill & - & 13706.7 & 0.320 & 20k \\
Distill & - & 14831.0 & 0.320 & 24k \\
Distill & - & 16067.4 & 0.320 & 32k \\
Distill & - & 7244.3 & 0.227 & 8k \\
Distill & - & 9996.3 & 0.287 & 12k \\
RL & 0 & 13097.2 & 0.297 & 32k \\
RL & 0.05 & 9399.1 & 0.317 & 32k \\
RL & 0.1 & 11570.1 & 0.320 & 32k \\
RL & 0.2 & 10429.1 & 0.283 & 32k \\
RL & 0.4 & 8879.4 & 0.263 & 32k \\
SFT & - & 13805.5 & 0.243 & 32k\\
\hline
\end{tabular}


\caption{AIME results for 1.5B model}
\label{table:AIME_1.5B}

\vspace{2.5em}
\begin{tabular}{ccccc}
\hline
\textbf{Model Type} & \textbf{$\alpha$} & \textbf{Tokens} & \textbf{Avg. Pass Rate} & \textbf{Ctx.} \\ \hline
DPO & - & 831.0 & 0.763 & 32k \\
Distill & - & 660.6 & 0.762 & 8k \\
Distill & - & 670.6 & 0.763 & 12k \\
Distill & - & 673.4 & 0.763 & 16k \\
Distill & - & 676.0 & 0.763 & 20k \\
Distill & - & 676.0 & 0.763 & 24k \\
Distill & - & 676.0 & 0.763 & 32k \\
RL & 0 & 1283.1 & 0.858 & 32k \\
RL & 0.05 & 773.9 & 0.852 & 32k \\
RL & 0.1 & 687.9 & 0.832 & 32k \\
RL & 0.2 & 295.6 & 0.795 & 32k \\
RL & 0.4 & 151.0 & 0.689 & 32k \\
SFT & - & 508.2 & 0.776 & 32k\\
\hline
\end{tabular}

\caption{GSM8K results for 1.5B model}
\label{table:GSM8K_1.5B}

\end{table}
\end{center}


\begin{center}
\begin{table}
\begin{tabular}{ccccc}
\hline
\textbf{Model Type} & \textbf{$\alpha$} & \textbf{Tokens} & \textbf{Avg. Pass Rate} & \textbf{Ctx.} \\ \hline
DPO & - & 3363.6 & 0.906 & 32k \\
Distill & - & 3321.1 & 0.886 & 8k \\
Distill & - & 3632.4 & 0.915 & 12k \\
Distill & - & 3824.2 & 0.921 & 16k \\
Distill & - & 3884.1 & 0.930 & 20k \\
Distill & - & 3999.8 & 0.928 & 24k \\
Distill & - & 4044.4 & 0.933 & 32k \\
RL & 0 & 3340.4 & 0.927 & 32k \\
RL & 0.05 & 3258.9 & 0.923 & 32k \\
RL & 0.1 & 2823.6 & 0.921 & 32k \\
RL & 0.2 & 1978.2 & 0.883 & 32k \\
RL & 0.4 & 1719.3 & 0.833 & 32k \\
SFT & - & 1429.8 & 0.782 & 32k\\
\hline
\end{tabular}

\caption{MATH500 results for 7B model}
\label{table:MATH500_7B}

\vspace{2.5em}

\begin{tabular}{ccccc}
\hline
\textbf{Model Type} & \textbf{$\alpha$} & \textbf{Tokens} & \textbf{Avg. Pass Rate} & \textbf{Ctx.} \\ \hline
DPO & - & 13161.8 & 0.513 & 32k \\
Distill & - & 10418.2 & 0.500 & 16k \\
Distill & - & 11670.9 & 0.507 & 20k \\
Distill & - & 12890.1 & 0.507 & 24k \\
Distill & - & 13173.0 & 0.557 & 32k \\
Distill & - & 6737.4 & 0.410 & 8k \\
Distill & - & 8910.5 & 0.480 & 12k \\
RL & 0 & 11725.1 & 0.537 & 32k \\
RL & 0.05 & 10768.4 & 0.560 & 32k \\
RL & 0.1 & 10893.3 & 0.513 & 32k \\
RL & 0.2 & 9209.3 & 0.533 & 32k \\
RL & 0.4 & 9831.7 & 0.513 & 32k \\
SFT & - & 5603.7 & 0.200 & 32k\\
\hline
\end{tabular}

\caption{AIME results for 7B model}
\label{table:AIME_7B}

\vspace{2.5em}

\begin{tabular}{ccccc}
\hline
\textbf{Model Type} & \textbf{$\alpha$} & \textbf{Tokens} & \textbf{Avg. Pass Rate} & \textbf{Ctx.} \\ \hline
DPO & - & 536.6 & 0.870 & 32k \\
Distill & - & 1576.0 & 0.923 & 8k \\
Distill & - & 1605.4 & 0.925 & 12k \\
Distill & - & 1615.0 & 0.926 & 16k \\
Distill & - & 1616.4 & 0.926 & 20k \\
Distill & - & 1619.4 & 0.926 & 24k \\
Distill & - & 1626.1 & 0.926 & 32k \\
RL & 0 & 1345.8 & 0.936 & 32k \\
RL & 0.05 & 942.9 & 0.927 & 32k \\
RL & 0.1 & 812.6 & 0.917 & 32k \\
RL & 0.2 & 248.8 & 0.889 & 32k \\
RL & 0.4 & 105.8 & 0.823 & 32k \\
SFT & - & 440.2 & 0.879 & 32k\\
\hline
\end{tabular}


\caption{GSM8K results for 7B model}
\label{table:GSM8K_7B}

\end{table}
\end{center}