[
  {
    "index": 0,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "white2023prompt",
        "author": "White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C",
        "title": "A prompt pattern catalog to enhance prompt engineering with chatgpt"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny",
        "title": "Self-consistency improves chain of thought reasoning in language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gao2023scaling",
        "author": "Gao, Leo and Schulman, John and Hilton, Jacob",
        "title": "Scaling laws for reward model overoptimization"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "silver2017mastering",
        "author": "Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others",
        "title": "Mastering the game of go without human knowledge"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "yao2024tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "gandhi2024stream",
        "author": "Gandhi, Kanishk and Lee, Denise and Grand, Gabriel and Liu, Muxin and Cheng, Winson and Sharma, Archit and Goodman, Noah D",
        "title": "Stream of Search (SoS): Learning to Search in Language"
      },
      {
        "key": "besta2024graph",
        "author": "Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others",
        "title": "Graph of thoughts: Solving elaborate problems with large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lightman2024lets",
        "author": "Hunter Lightman and Vineet Kosaraju and Yuri Burda and Harrison Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe",
        "title": "Let's Verify Step by Step"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "kumar2024training",
        "author": "Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others",
        "title": "Training language models to self-correct via reinforcement learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zhou2024surveyefficientinferencelarge",
        "author": "Zixuan Zhou and Xuefei Ning and Ke Hong and Tianyu Fu and Jiaming Xu and Shiyao Li and Yuming Lou and Luning Wang and Zhihang Yuan and Xiuhong Li and Shengen Yan and Guohao Dai and Xiao-Ping Zhang and Yuhan Dong and Yu Wang",
        "title": "A Survey on Efficient Inference for Large Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "leviathan2023fast",
        "author": "Leviathan, Yaniv and Kalman, Matan and Matias, Yossi",
        "title": "Fast inference from transformers via speculative decoding"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "kwon2023efficient",
        "author": "Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion",
        "title": "Efficient memory management for large language model serving with pagedattention"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liu2018rethinking",
        "author": "Liu, Zhuang and Sun, Mingjie and Zhou, Tinghui and Huang, Gao and Darrell, Trevor",
        "title": "Rethinking the value of network pruning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "lin2024awq",
        "author": "Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song",
        "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "chen2024think23overthinkingo1like",
        "author": "Xingyu Chen and Jiahao Xu and Tian Liang and Zhiwei He and Jianhui Pang and Dian Yu and Linfeng Song and Qiuzhi Liu and Mengfei Zhou and Zhuosheng Zhang and Rui Wang and Zhaopeng Tu and Haitao Mi and Dong Yu",
        "title": "Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "kimiteam2025kimik15scalingreinforcement",
        "author": "Kimi Team and Angang Du and Bofei Gao and Bowei Xing and Changjiu Jiang and Cheng Chen and Cheng Li and Chenjun Xiao and Chenzhuang Du and Chonghua Liao and Chuning Tang and Congcong Wang and Dehao Zhang and Enming Yuan and Enzhe Lu and Fengxiang Tang and Flood Sung and Guangda Wei and Guokun Lai and Haiqing Guo and Han Zhu and Hao Ding and Hao Hu and Hao Yang and Hao Zhang and Haotian Yao and Haotian Zhao and Haoyu Lu and Haoze Li and Haozhen Yu and Hongcheng Gao and Huabin Zheng and Huan Yuan and Jia Chen and Jianhang Guo and Jianlin Su and Jianzhou Wang and Jie Zhao and Jin Zhang and Jingyuan Liu and Junjie Yan and Junyan Wu and Lidong Shi and Ling Ye and Longhui Yu and Mengnan Dong and Neo Zhang and Ningchen Ma and Qiwei Pan and Qucheng Gong and Shaowei Liu and Shengling Ma and Shupeng Wei and Sihan Cao and Siying Huang and Tao Jiang and Weihao Gao and Weimin Xiong and Weiran He and Weixiao Huang and Wenhao Wu and Wenyang He and Xianghui Wei and Xianqing Jia and Xingzhe Wu and Xinran Xu and Xinxing Zu and Xinyu Zhou and Xuehai Pan and Y. Charles and Yang Li and Yangyang Hu and Yangyang Liu and Yanru Chen and Yejie Wang and Yibo Liu and Yidao Qin and Yifeng Liu and Ying Yang and Yiping Bao and Yulun Du and Yuxin Wu and Yuzhi Wang and Zaida Zhou and Zhaoji Wang and Zhaowei Li and Zhen Zhu and Zheng Zhang and Zhexu Wang and Zhilin Yang and Zhiqi Huang and Zihao Huang and Ziyao Xu and Zonghan Yang",
        "title": "Kimi k1.5: Scaling Reinforcement Learning with LLMs"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "luo2025o1prunerlengthharmonizingfinetuningo1like",
        "author": "Haotian Luo and Li Shen and Haiying He and Yibo Wang and Shiwei Liu and Wei Li and Naiqiang Tan and Xiaochun Cao and Dacheng Tao",
        "title": "O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "jin-etal-2024-impact",
        "author": "Jin, Mingyu  and\nYu, Qinkai  and\nShu, Dong  and\nZhao, Haiyan  and\nHua, Wenyue  and\nMeng, Yanda  and\nZhang, Yongfeng  and\nDu, Mengnan",
        "title": "The Impact of Reasoning Step Length on Large Language Models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "kang2024c3otgeneratingshorterchainofthought",
        "author": "Yu Kang and Xianghui Sun and Liangyu Chen and Wei Zou",
        "title": "C3oT: Generating Shorter Chain-of-Thought without Compromising Effectiveness"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "nayab2025concisethoughtsimpactoutput",
        "author": "Sania Nayab and Giulio Rossolini and Marco Simoni and Andrea Saracino and Giorgio Buttazzo and Nicolamaria Manes and Fabrizio Giacomelli",
        "title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "han2024tokenbudgetawarellmreasoning",
        "author": "Tingxu Han and Zhenting Wang and Chunrong Fang and Shiyu Zhao and Shiqing Ma and Zhenyu Chen",
        "title": "Token-Budget-Aware LLM Reasoning"
      }
    ]
  }
]