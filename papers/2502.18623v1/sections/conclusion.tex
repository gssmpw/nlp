\section{Conclusion}
\noindent
 The growing implementation of machine learning across sectors like healthcare, finance, and education has raised concerns about potential privacy breaches through inference attacks, particularly when models process sensitive data. Previous research examining privacy characteristics of neural networks has shown that SNNs exhibit better resilience against MIAs compared to traditional ANNs. This study explores how the privacy-preserving characteristics of SNNs can be further enhanced through quantization and by leveraging various surrogate gradient training methods. Our results show that while quantization reduces MIA vulnerability in both SNNs and ANNs,  the privacy advantage of SNNs remains inherent. Notably, even full-precision SNNs exhibit lower vulnerability than quantized ANNs at any bit width, reinforcing the fundamental privacy resilience of spike-based computation over traditional neural architectures. The training of SNNs with different surrogate gradients further highlights their impact on balancing accuracy and privacy. Spike Rate Escape provides the best privacy protection while maintaining strong performance, whereas Arctangent and Straight Through
Estimator (STE) exhibit higher vulnerability. 
Looking forward, we will investigate the energy efficiency of full-precision SNNs compared to quantized ANNs, as the privacy advantage of SNNs holds greater significance when evaluated alongside their energy savings. Additionally, future work will integrate Differentially Private Stochastic Gradient Descent (DPSGD) with quantized ANN and SNN models to explore the synergistic impact of these techniques on both model performance and privacy.
 
 
 
 
 
 
 
 
 % This study investigates how quantization affects privacy characteristics in both architectures while examining the impact of different surrogate gradients in SNNs through experiments on CIFAR-10, MNIST, FMNIST and Breast Cancer datasets. Our analysis shows that ANNs exhibit a clear trade off between quantization and privacy: lower precision improves privacy but reduces accuracy. SNNs displayed varied behavior: weight quantization followed similar trends to ANNs, while activation quantization improved privacy compared to full precision but lacked consistent patterns across bit widths. But interestingly, even full precision SNNs provided better privacy protection than quantized ANNs. Among surrogate gradients, spike rate escape achieved optimal balance between accuracy and privacy, while aTan increased vulnerability towards MIA. These results advance our understanding of how architectural choices and training methodologies in neuromorphic systems influence privacy characteristics. Future work will focus on integrating DPSGD with quantized ANN and SNN models to examine the combined impact of quantization and differential privacy on model performance and privacy.
 % \textcolor{blue}{Shay, can you help with the concluding line?}