\begin{abstract}

As machine learning models increasingly process sensitive data, understanding their vulnerability to privacy attacks is vital. Membership Inference Attack (MIA), which infer whether specific data points were used during training, is one such privacy risk. Previous work suggests that Spiking Neural Networks (SNNs), which rely on event-driven computation and discrete spike-based encoding, exhibit greater resilience to MIAs compared to Artificial Neural Networks (ANNs). This resilience is attributed to their non-differentiable activations and inherent stochasticity, which reduce the correlation between model responses and individual training samples. To further enhance privacy in SNNs, we explore two techniques: Quantization and Surrogate Gradients. Quantization, which reduces model precision to limit information leakage, has been shown to improve privacy resilience in ANNs. Since SNNs exhibit sparse and irregular activations, quantization may have an even stronger effect on disrupting the activation patterns exploited by MIAs. In this study, we compare the vulnerability of SNNs and ANNs to MIAs under \textit{weight} and \textit{activation} quantization across multiple datasets. We evaluate privacy vulnerability using the attack model’s Receiver Operating Characteristic (ROC) curve’s Area Under the Curve (AUC) metric, where lower values indicate stronger privacy protection, and assess model accuracy to quantify the privacy-accuracy trade-off. Our results show that quantization enhances privacy in both architectures with minimal performance degradation, but full-precision SNNs remain more resilient than even quantized ANNs.  Additionally, we examine the impact of surrogate gradients on privacy in SNNs. Among the five surrogate gradients evaluated, Spike Rate Escape provides the best privacy-accuracy trade-off, while Arctangent (aTan) increases vulnerability to MIAs. These findings reinforce SNNs’ inherent privacy advantages and demonstrate that both quantization and surrogate gradient selection can further influence privacy-accuracy trade-offs in SNNs. 


% These results suggest that while SNNs are inherently more privacy-preserving, their resilience can be further improved through appropriate surrogate gradient selection. Overall, this study shows that while quantization enhances privacy in both ANNs and SNNs, full precision SNNs remain more resilient than quantized ANNs, and surrogate gradients further influence privacy-accuracy trade-offs in SNNs














% Spiking Neural Networks (SNNs), designed for energy efficient and event driven computation in resource constrained environments, have shown inherent resilience to MIAs compared to Artificial Neural Networks (ANNs). With the increasing need to mitigate privacy attacks like MIAs, we explore whether quantization—a technique primarily used to reduce model size and computational cost, can also influence a model’s vulnerability to such attacks. By reducing parameter precision and altering the granularity of learned representations, quantization modifies the distribution and sensitivity of model outputs, which may impact the information leakage exploited in privacy attacks. In this study, we compare the vulnerability of SNNs and ANNs to MIAs, with a focus on the effects of \textit{weight} and \textit{activation} quantization on both models on multiple datasets. We assess privacy resilience using the Receiver Operating Characteristic (ROC) curve's Area Under the Curve (AUC) metric, where lower AUC values indicate reduced susceptibility to MIAs. Model accuracy is also evaluated to assess the trade-off between privacy and performance. Our findings show that quantization improves privacy resilience in both ANNs and SNNs, with only a slight reduction in model performance. However, full-precision SNNs still achieve lower attack AUC than even the quantized ANNs, demonstrating their superior privacy protection. The model accuracy levels remain largely comparable across both ANN and SNN models in their full precision and quantized states as well. These results emphasize that SNNs inherently provide stronger privacy protection than ANNs, even when quantization is applied to the latter. On the other hand, since training SNNs with surrogate gradients enables gradient based optimization for non-differentiable spike events, we also examine how different surrogate gradient functions influence privacy in SNNs against MIAs. Among the five surrogate gradients we experimented with, spike rate escape achieves the best accuracy-privacy trade off, while Arctangent (aTan) increases vulnerability to MIAs. This indicates that even though SNNs are naturally more resilient to MIAs, their privacy characteristics can be further influenced by selecting appropriate surrogate gradients. Overall, these findings reveal that while quantization improves privacy in both ANNs and SNNs, even full-precision SNNs remain more resilient than the quantized ANNs, and the privacy of SNNs can be further enhanced by appropriate surrogate gradients.





\end{abstract}