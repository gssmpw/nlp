\section{Related Work}
\subsection{Autoencoders for Visual Generation Models} 
Visual generation in high-resolution pixel space imposes prohibitive computational costs for diffusion and autoregressive models. To address this, \citet{rombach2022high} introduced latent diffusion models operating in compressed spaces via pretrained autoencoders~\cite{kingma2013auto}. The standard design employs an $8\times$ spatial compression ratio with four latent channels \citep{peebles2023scalable,li2024autoregressive,tian2024visual}. Recent works have focused on improving reconstruction quality through increased latent channels \citep{esser2024scaling} or enhanced decoders with task-specific priors \citep{zhu2023designing}.

In contrast, our work targets a different but equally important goal: dynamically increasing the spatial compression ratio of autoencoders while still maintaining acceptable reconstruction quality. \citet{chen2024deep} also address high compression ratios to enable efficient high-resolution diffusion models; however, their approach trains a specialized autoencoder. Our method, by comparison, is training-free, allowing us to obtain a more compressed latent space without retraining the original autoencoder. To our knowledge, this is the first study to explore higher compression ratios in this training-free manner. 

\begin{figure*}[!th]
    \centering
    \begin{minipage}{\textwidth}
    \centering
    \begin{subfigure}{0.57\textwidth}
    \includegraphics[width=\linewidth]{figures/Video_clips.png}
    \captionsetup{font=small}
    \caption{Example video segments in BVI-HFR~\cite{mackin2018study}. Each one is 10 seconds at 1080p/60Hz. The ``cyclist'' and ``books'' demonstrates rapid camera motion, while ``flowers'' and ``typing'' contain slower, more static content.}
    \label{fig:video_examples}
    \end{subfigure}
    \hspace{0.05in}
    \begin{subfigure}{0.41\textwidth}
    \centering
    \includegraphics[width=0.92\linewidth]{figures/frequency_analyse.pdf}
    \captionsetup{font=small}
    \vspace{-0.1in}
    \caption{Temporal frequency analysis comparing original video signals (top) and their latent space representations from HunyuanVideo VAE (bottom) \cite{kong2024hunyuanvideo}.}
    \label{fig:analysis_on_video_seg}
    \end{subfigure}
    \end{minipage}
    \vspace{-0.13in}
    \caption{\textbf{Analysis of temporal frequency characteristics in both pixel and latent spaces.} Key observations: (1) Fast-motion segments exhibit higher temporal frequency content in both domains, while static scenes show concentrated low frequency. (2) The latent space preserves the relative frequency patterns of the original signals, enabling content-adaptive frame rate compression in the latent domain.}
    \vspace{-0.2in}
\label{fig:motivation}
\end{figure*}

\subsection{Training-free Acceleration for Generative Models}
The computational intensity of generative models has spurred various acceleration strategies, with training-free methods gaining prominence due to the high training costs of modern architectures~\cite{ma2024efficient}. Key approaches include: (1) Reducing inference sampling steps through training-free few-step samplers~\cite{song2020denoising,lu2022dpm,lu2022dpmp,zhang2022fast};
(2) Model compression via sparsity~\cite{ma2024deepcache,yuan2024ditfastattn} or quantization~\cite{shang2023post,li2023q,wang2024quest,wu2024ptq4dit,li2024svdqunat}.

While these methods focus on optimizing diffusion or autoregressive backbones, they leave the autoencoder unchanged. Our approach introduces a novel direction: enhancing video generation efficiency by increasing video autoencoder compression ratios without additional training, thereby reducing overall computational demands.