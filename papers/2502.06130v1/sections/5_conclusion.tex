% \vspace{-4pt}
\section{Conclusion}
% \vspace{-3pt}
In this work, we present self-correcting Decoding with Generative Feedback (DeGF), a novel training-free approach that leverages feedback from text-to-image generative models to recursively improve the accuracy of generated responses. Specifically, we generate a new image based on the initial response given by LVLMs, which serves as a visual reference and provides token-level feedback for mitigating hallucinations. Building on this, we propose a corresponding self-correcting decoding algorithm that measures the discrepancy between next-token predictions conditioned on the original and generated images, selecting either contrastive or complementary decoding to reduce the likelihood of hallucinatory responses. Extensive experimental results across six benchmarks demonstrate that our DeGF consistently outperforms state-of-the-art methods in mitigating hallucinations in LVLMs.


\clearpage

\section*{Acknowledgements}
This work has been funded in part by the Army Research Laboratory (ARL) award W911NF-23-2-0007, DARPA award FA8750-23-2-1015, and ONR award N00014-23-1-2840. MM and LPM are partially supported by Meta and National Institutes of Health awards R01MH125740, R01MH132225, and R21MH130767. RS is supported in part by the ONR grant N00014-23-1-2368.

\section*{Ethics Statement}
Our work focuses on developing methods to mitigate hallucinations in large vision-language models, aiming to enhance the reliability of AI-generated content. Our research does not involve human subjects, sensitive data, or any practices that pose privacy or security concerns. Additionally, we discuss the broader ethical and societal implications of this work in Section~\ref{sec:limitation} of the Appendix.

\section*{Reproducibility Statement}
The large vision-language models utilized in our experiments, such as LLaVA and InstructBLIP, are open-source and publicly available. We have detailed our experimental setup, including hyperparameter configurations, prompts, and other key design choices, in Section~\ref{sec:experiment} of the main paper and Section~\ref{sec:detail} of the Appendix to ensure reproducibility. Code is publicly available at \url{https://github.com/zhangce01/DeGF}.