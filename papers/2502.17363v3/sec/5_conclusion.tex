\label{sec:conclusion}
\section{Conclusion}
In this paper, we introduce KV-Edit, a new training-free approach that achieves perfect background preservation in image editing by caching and reusing background key-value pairs. Our method effectively decouples foreground editing from background preservation through attention mechanisms in DiT, while optional enhancement strategies and memory-efficient implementation further improve its practical utility. Extensive experiments demonstrate that our approach surpasses both training-free methods and training-based inpainting models in terms of both background preservation and image quality. Moreover, we hope that this straightforward yet effective mechanism could inspire broader applications, such as video editing, multi-concept personalization, and other scenarios.
