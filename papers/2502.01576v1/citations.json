[
  {
    "index": 0,
    "papers": [
      {
        "key": "yin2023survey",
        "author": "Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong",
        "title": "A survey on multimodal large language models"
      },
      {
        "key": "li2024multimodal",
        "author": "Li, Chunyuan and Gan, Zhe and Yang, Zhengyuan and Yang, Jianwei and Li, Linjie and Wang, Lijuan and Gao, Jianfeng and others",
        "title": "Multimodal foundation models: From specialists to general-purpose assistants"
      },
      {
        "key": "caffagni2024r",
        "author": "Caffagni, Davide and Cocchi, Federico and Barsellotti, Luca and Moratelli, Nicholas and Sarto, Sara and Baraldi, Lorenzo and Cornia, Marcella and Cucchiara, Rita",
        "title": "The (r) evolution of multimodal large language models: A survey"
      },
      {
        "key": "awais2023foundational",
        "author": "Awais, Muhammad and Naseer, Muzammal and Khan, Salman and Anwer, Rao Muhammad and Cholakkal, Hisham and Shah, Mubarak and Yang, Ming-Hsuan and Khan, Fahad Shahbaz",
        "title": "Foundational models defining a new era in vision: A survey and outlook"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liu2024visual",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      },
      {
        "key": "liu2024improved",
        "author": "Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae",
        "title": "Improved baselines with visual instruction tuning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chiang2023vicuna",
        "author": "Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others",
        "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90\\%* chatgpt quality"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "szegedy2013intriguing",
        "author": "Szegedy, C",
        "title": "Intriguing properties of neural networks"
      },
      {
        "key": "goodfellow2014explaining",
        "author": "Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian",
        "title": "Explaining and harnessing adversarial examples"
      },
      {
        "key": "mkadry2017towards",
        "author": "M{\\k{a}}dry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian",
        "title": "Towards deep learning models resistant to adversarial attacks"
      },
      {
        "key": "zhang2019theoretically",
        "author": "Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael",
        "title": "Theoretically principled trade-off between robustness and accuracy"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "carlini2017towards",
        "author": "Carlini, Nicholas and Wagner, David",
        "title": "Towards evaluating the robustness of neural networks"
      },
      {
        "key": "ebrahimi2017hotflip",
        "author": "Ebrahimi, Javid and Rao, Anyi and Lowd, Daniel and Dou, Dejing",
        "title": "Hotflip: White-box adversarial examples for text classification"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "huang2024visual",
        "author": "Huang, Wen and Liu, Hongbin and Guo, Minxin and Gong, Neil Zhenqiang",
        "title": "Visual hallucinations of multi-modal large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2023survey",
        "author": "Wang, Cunxiang and Liu, Xiaoze and Yue, Yuanhao and Tang, Xiangru and Zhang, Tianhang and Jiayang, Cheng and Yao, Yunzhi and Gao, Wenyang and Hu, Xuming and Qi, Zehan and others",
        "title": "Survey on factuality in large language models: Knowledge, retrieval and domain-specificity"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2024exploring",
        "author": "Wang, Yiqi and Chen, Wentao and Han, Xiaotian and Lin, Xudong and Zhao, Haiteng and Liu, Yongfei and Zhai, Bohan and Yuan, Jianbo and You, Quanzeng and Yang, Hongxia",
        "title": "Exploring the reasoning abilities of multimodal large language models (mllms): A comprehensive survey on emerging trends in multimodal reasoning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "bai2024hallucination",
        "author": "Bai, Zechen and Wang, Pichao and Xiao, Tianjun and He, Tong and Han, Zongbo and Zhang, Zheng and Shou, Mike Zheng",
        "title": "Hallucination of multimodal large language models: A survey"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "jin2024jailbreakzoo",
        "author": "Jin, Haibo and Hu, Leyang and Li, Xinuo and Zhang, Peiyan and Chen, Chonghan and Zhuang, Jun and Wang, Haohan",
        "title": "Jailbreakzoo: Survey, landscapes, and horizons in jailbreaking large language and vision-language models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "niu2024jailbreaking",
        "author": "Niu, Zhenxing and Ren, Haodong and Gao, Xinbo and Hua, Gang and Jin, Rong",
        "title": "Jailbreaking attack against multimodal large language model"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "liu2025mm",
        "author": "Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Mm-safetybench: A benchmark for safety evaluation of multimodal large language models"
      },
      {
        "key": "liu2024safety",
        "author": "Liu, Xin and Zhu, Yichen and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Safety of Multimodal Large Language Models on Images and Text"
      },
      {
        "key": "zhang2024benchmarking",
        "author": "Zhang, Yichi and Huang, Yao and Sun, Yitong and Liu, Chang and Zhao, Zhe and Fang, Zhengwei and Wang, Yifan and Chen, Huanran and Yang, Xiao and Wei, Xingxing and others",
        "title": "Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "mao2022understanding",
        "author": "Mao, Chengzhi and Geng, Scott and Yang, Junfeng and Wang, Xin and Vondrick, Carl",
        "title": "Understanding zero-shot adversarial robustness for large-scale models"
      },
      {
        "key": "schlarmann2024robust",
        "author": "Schlarmann, Christian and Singh, Naman Deep and Croce, Francesco and Hein, Matthias",
        "title": "Robust clip: Unsupervised adversarial fine-tuning of vision embeddings for robust large vision-language models"
      },
      {
        "key": "hossain2024sim",
        "author": "Hossain, Md Zarif and Imteaj, Ahmed",
        "title": "Sim-clip: Unsupervised siamese adversarial fine-tuning for robust and semantically-rich vision-language models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "liu2024visual",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      },
      {
        "key": "liu2024improved",
        "author": "Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae",
        "title": "Improved baselines with visual instruction tuning"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "wang2024revisiting",
        "author": "Wang, Zeyu and Li, Xianhang and Zhu, Hongru and Xie, Cihang",
        "title": "Revisiting Adversarial Training at Scale"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "szegedy2013intriguing",
        "author": "Szegedy, C",
        "title": "Intriguing properties of neural networks"
      },
      {
        "key": "goodfellow2014explaining",
        "author": "Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian",
        "title": "Explaining and harnessing adversarial examples"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "mkadry2017towards",
        "author": "M{\\k{a}}dry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian",
        "title": "Towards deep learning models resistant to adversarial attacks"
      },
      {
        "key": "zhang2019theoretically",
        "author": "Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael",
        "title": "Theoretically principled trade-off between robustness and accuracy"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "carlini2017towards",
        "author": "Carlini, Nicholas and Wagner, David",
        "title": "Towards evaluating the robustness of neural networks"
      },
      {
        "key": "ebrahimi2017hotflip",
        "author": "Ebrahimi, Javid and Rao, Anyi and Lowd, Daniel and Dou, Dejing",
        "title": "Hotflip: White-box adversarial examples for text classification"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "huang2024visual",
        "author": "Huang, Wen and Liu, Hongbin and Guo, Minxin and Gong, Neil Zhenqiang",
        "title": "Visual hallucinations of multi-modal large language models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "wang2023survey",
        "author": "Wang, Cunxiang and Liu, Xiaoze and Yue, Yuanhao and Tang, Xiangru and Zhang, Tianhang and Jiayang, Cheng and Yao, Yunzhi and Gao, Wenyang and Hu, Xuming and Qi, Zehan and others",
        "title": "Survey on factuality in large language models: Knowledge, retrieval and domain-specificity"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wang2024exploring",
        "author": "Wang, Yiqi and Chen, Wentao and Han, Xiaotian and Lin, Xudong and Zhao, Haiteng and Liu, Yongfei and Zhai, Bohan and Yuan, Jianbo and You, Quanzeng and Yang, Hongxia",
        "title": "Exploring the reasoning abilities of multimodal large language models (mllms): A comprehensive survey on emerging trends in multimodal reasoning"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "bai2024hallucination",
        "author": "Bai, Zechen and Wang, Pichao and Xiao, Tianjun and He, Tong and Han, Zongbo and Zhang, Zheng and Shou, Mike Zheng",
        "title": "Hallucination of multimodal large language models: A survey"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "jin2024jailbreakzoo",
        "author": "Jin, Haibo and Hu, Leyang and Li, Xinuo and Zhang, Peiyan and Chen, Chonghan and Zhuang, Jun and Wang, Haohan",
        "title": "Jailbreakzoo: Survey, landscapes, and horizons in jailbreaking large language and vision-language models"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "niu2024jailbreaking",
        "author": "Niu, Zhenxing and Ren, Haodong and Gao, Xinbo and Hua, Gang and Jin, Rong",
        "title": "Jailbreaking attack against multimodal large language model"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "liu2025mm",
        "author": "Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Mm-safetybench: A benchmark for safety evaluation of multimodal large language models"
      },
      {
        "key": "liu2024safety",
        "author": "Liu, Xin and Zhu, Yichen and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Safety of Multimodal Large Language Models on Images and Text"
      },
      {
        "key": "zhang2024benchmarking",
        "author": "Zhang, Yichi and Huang, Yao and Sun, Yitong and Liu, Chang and Zhao, Zhe and Fang, Zhengwei and Wang, Yifan and Chen, Huanran and Yang, Xiao and Wei, Xingxing and others",
        "title": "Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "mao2022understanding",
        "author": "Mao, Chengzhi and Geng, Scott and Yang, Junfeng and Wang, Xin and Vondrick, Carl",
        "title": "Understanding zero-shot adversarial robustness for large-scale models"
      },
      {
        "key": "schlarmann2024robust",
        "author": "Schlarmann, Christian and Singh, Naman Deep and Croce, Francesco and Hein, Matthias",
        "title": "Robust clip: Unsupervised adversarial fine-tuning of vision embeddings for robust large vision-language models"
      },
      {
        "key": "hossain2024sim",
        "author": "Hossain, Md Zarif and Imteaj, Ahmed",
        "title": "Sim-clip: Unsupervised siamese adversarial fine-tuning for robust and semantically-rich vision-language models"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "liu2024visual",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      },
      {
        "key": "liu2024improved",
        "author": "Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae",
        "title": "Improved baselines with visual instruction tuning"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "wang2024revisiting",
        "author": "Wang, Zeyu and Li, Xianhang and Zhu, Hongru and Xie, Cihang",
        "title": "Revisiting Adversarial Training at Scale"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "jin2024jailbreakzoo",
        "author": "Jin, Haibo and Hu, Leyang and Li, Xinuo and Zhang, Peiyan and Chen, Chonghan and Zhuang, Jun and Wang, Haohan",
        "title": "Jailbreakzoo: Survey, landscapes, and horizons in jailbreaking large language and vision-language models"
      },
      {
        "key": "qi2024visual",
        "author": "Qi, Xiangyu and Huang, Kaixuan and Panda, Ashwinee and Henderson, Peter and Wang, Mengdi and Mittal, Prateek",
        "title": "Visual adversarial examples jailbreak aligned large language models"
      },
      {
        "key": "hossain2024securing",
        "author": "Hossain, Md Zarif and Imteaj, Ahmed",
        "title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks"
      },
      {
        "key": "niu2024jailbreaking",
        "author": "Niu, Zhenxing and Ren, Haodong and Gao, Xinbo and Hua, Gang and Jin, Rong",
        "title": "Jailbreaking attack against multimodal large language model"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "dong2023robust",
        "author": "Dong, Yinpeng and Chen, Huanran and Chen, Jiawei and Fang, Zhengwei and Yang, Xiao and Zhang, Yichi and Tian, Yu and Su, Hang and Zhu, Jun",
        "title": "How Robust is Google's Bard to Adversarial Image Attacks?"
      },
      {
        "key": "schlarmann2023adversarial",
        "author": "Schlarmann, Christian and Hein, Matthias",
        "title": "On the adversarial robustness of multi-modal foundation models"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "carlini2024aligned",
        "author": "Carlini, Nicholas and Nasr, Milad and Choquette-Choo, Christopher A and Jagielski, Matthew and Gao, Irena and Koh, Pang Wei W and Ippolito, Daphne and Tramer, Florian and Schmidt, Ludwig",
        "title": "Are aligned neural networks adversarially aligned?"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "shayegani2023jailbreak",
        "author": "Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael",
        "title": "Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "wu2023jailbreaking",
        "author": "Wu, Yuanwei and Li, Xiang and Liu, Yixin and Zhou, Pan and Sun, Lichao",
        "title": "Jailbreaking gpt-4v via self-adversarial attacks with system prompts"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "gong2023figstep",
        "author": "Gong, Yichen and Ran, Delong and Liu, Jinyuan and Wang, Conglei and Cong, Tianshuo and Wang, Anyu and Duan, Sisi and Wang, Xiaoyun",
        "title": "Figstep: Jailbreaking large vision-language models via typographic visual prompts"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "zhao2024evaluating",
        "author": "Zhao, Yunqing and Pang, Tianyu and Du, Chao and Yang, Xiao and Li, Chongxuan and Cheung, Ngai-Man Man and Lin, Min",
        "title": "On evaluating adversarial robustness of large vision-language models"
      }
    ]
  }
]