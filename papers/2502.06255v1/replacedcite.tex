\section{Related Work}
\subsection{Weed Datasets}
% Existing weed datasets focus on the tasks of weed recognition or detection____. We summarize the major public datasets with human annotations in Tab.~\ref{tab:weed_datasets}. DeepWeeds____ provides image-level annotations for eight types of Australian weeds but without any crops. Though DeepWeeds has 17,509 images, it does not contain any information for crops, making it less useful in practical intelligent weeding. Weed-Corn/Lettuce/Radish dataset____ contains 4 species (three crops and weed) and 7,200 images with image-level annotations total. Food Crop and Weed Dataset____ contains 7 species (six crops and weed) and 1,118 images with various resolution.
% CottonWeedID15____ consists of 5,187 weed images specifically collected in the cotton field. CottonWeedID15 only provides image-level annotations. To overcome these limitations, the CottonWeedDet12____ and the CottonWeedDet3____ datasets provide bounding box annotations, in addition to image-level annotations, respectively. CropAndWeed Dataset____ is the largest weed dataset with coarse machine-generated annotations, \emph{i.e.}~labeled by computer vision method. 
% However, laser weeding demands precise localization of the weed stem, and the laser transmitter's diameter must be small to deliver a high-energy beam. Therefore, the CropAndWeed dataset is not suitable for practical laser weeding.
% \textcolor{red}{There are also other datasets and methods focusing on laser weeding____, but they mainly address weed classification, detection, and segmentation, lacking the accuracy needed for precise weed stem localization.}
% To the best of our knowledge, WSD is the first dataset with human annotations for both crop and weed detection, as well as weed stem localization.

Existing weed datasets primarily address weed recognition or detection____. We summarize the key public datasets with human annotations in Tab.~\ref{tab:weed_datasets}. DeepWeeds____ includes 17,509 images of eight Australian weeds but lacks crop data, limiting its practical weeding applications. The Weed-Corn/Lettuce/Radish dataset____ contains 7,200 images with four species (three crops and one weed), while the Food Crop and Weed Dataset____ includes 1,118 images of seven species (six crops and one weed). CottonWeedID15____ consists of 5,187 weed images from cotton fields with image-level annotations only. CottonWeedDet12____ and CottonWeedDet3____ add bounding box annotations. The largest dataset, CropAndWeed____, has coarse machine-generated labels. However, precise weed stem localization is essential for laser weeding, requiring high-quality annotations in terms of localization. Although some laser-weeding datasets exist____, they focus on classification, detection, and segmentation rather than precise stem localization. To the best of our knowledge, WSD is the first dataset with human annotations for both crop and weed detection, as well as weed stem localization.

\subsection{Weed Recognition}
Existing studies on weed recognition can be broadly categorized into four tasks: weed classification, weed object detection, weed object segmentation, and weed instance segmentation____. Weed classification focuses on identifying weeds at the image level, determining whether an image contains non-crop plants. For instance, SVM classifiers have achieved about 95\% accuracy in relatively simple environments____, and by combining VGG with 
SVM____, a 99\% accuracy rate has been reached in distinguishing between weeds and grapevines. Weed object detection extends beyond classification by providing bounding boxes to locate weeds within images.____ Various models have been successfully applied to this task, including DetectNet____, Faster R-CNN____, and YOLOv3____, all showing promising results. Weed object segmentation and instance segmentation focus on pixel-level recognition____, offering more detailed analysis. For example, VGG-UNet has been used to segment sugar beets and weeds____. 
However, none of these methods can localize the weed stem, a crucial aspect of effective weed management. To address this gap, our work introduces an end-to-end framework that simultaneously detects crops and weeds while localizing the weed stem.

\begin{table*}[t!]
\centering
\setlength{\tabcolsep}{2.5mm}
\renewcommand{\arraystretch}{1.5}
% \resizebox{\linewidth}{!}{
\begin{tabular}{ccccccc}
\hline
Dataset & Stem & BBox & \# Img & \# Species & \# Inst & Res\\
\hline
DeepWeeds~\shortcite{olsen2019deepweeds} & \usym{2715} & \usym{2715} & 17509 & 1 & - & 256 $\times$ 256 \\ 
Weed-Corn/Lettuce/Radish~\shortcite{jiang2020cnn} & \usym{2715} & \usym{2715} & \phantom{0}7200 & 4 & - & 800 $\times$ 600  \\
Crops and Weed Dataset~\shortcite{sudars2020dataset} & \usym{2715} & \usym{2713} & \phantom{0}1118 & 7 & - & [480, 1000] $\times$ [384, 1280] \\
CottonWeedID15~\shortcite{chen2022performance} & \usym{2715} &  \usym{2715} & \phantom{0}5187 & 1 & - & 512 $\times$ 512 \\
CottonWeedDet3~\shortcite{rahman2023performance} & \usym{2715} & \usym{2713} & \phantom{0}\phantom{0}848 & 1 & \phantom{0}1.8 $\pm$ 1.5 & 4442 $\times$ 4335 \\
CottonWeedDet12~\shortcite{lu2023cottonweeddet12} & \usym{2715} & \usym{2713} & \phantom{0}5648 & 1 & \phantom{0}1.7 $\pm$ 1.4 & 3024 $\times$ 4032 \\
\hline
WSD (Ours) & \usym{2713} & \usym{2713} & \phantom{0}7161 & 4 & 12.5 $\pm$ 7.5  & 2048 $\times$ 2048 \\
\hline
\end{tabular}
% }
\caption{Comparison between WSD dataset and existing weed datasets with human annotations. ``Stem'' indicates whether stem annotations are provided. ``\#Img'' denotes the number of images. ``\# Species'' denotes the number of species. ``\# Inst'' denotes the average number of annotations per image, along with the standard deviation. ``Res'' denotes the image resolution.}
\label{tab:weed_datasets}
\end{table*}

\begin{figure}[ht]
\centering
\begin{minipage}[t]{0.45\linewidth}
\includegraphics[width=1\linewidth]{image/kind_example/weed_bbox.png}
\includegraphics[width=1\linewidth]{image/kind_example/maize_bbox.png}
\includegraphics[width=1\linewidth]{image/kind_example/soybean_bbox.png}
\includegraphics[width=1\linewidth]{image/kind_example/mungbean_new.png}
\centerline{(a) Raw Image}
\end{minipage}
\begin{minipage}[t]{0.45\linewidth}
\includegraphics[width=1\linewidth]{image/kind_example/weed_bbox_small_small.png}
\includegraphics[width=1\linewidth]{image/kind_example/maize_bbox_small_small.png}
\includegraphics[width=1\linewidth]{image/kind_example/soybean_bbox_small_small.png}
\includegraphics[width=1\linewidth]{image/kind_example/mungbean_bbox_small_small.png}
\centerline{(b) Zoomed-in View}
\end{minipage}
\caption{Image samples show raw images (left) and 16x zoomed sections (right), highlighting four different species.}
\label{fig:example}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{image/weed_dist.png}
\caption{Distribution of instance annotations per image: The X-axis shows the number of instances (including both bounding box and point annotations) per image, while the Y-axis indicates the corresponding image count.} 
\label{dist_weed}
\end{figure}

% The distribution of instance annotations per image is depicted. The X-axis shows the number of instances (including both bounding box and point annotations) per image, ranging from 0 to 55. The Y-axis indicates the number of images corresponding to each specific number of instances.