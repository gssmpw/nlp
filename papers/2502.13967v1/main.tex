\documentclass{article}

\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2025_modified}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} %
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{amssymb}%
\usepackage{pifont}%
\usepackage[output-decimal-marker={,},exponent-product=\cdot]{siunitx}
\usepackage{adjustbox}
\usepackage{makecell}
\usepackage{array}
\usepackage{placeins}
\usepackage{caption}
\usepackage{afterpage}
\usepackage{xspace}
\usepackage[capitalize,noabbrev]{cleveref}

\input{preamble}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


\icmltitlerunning{\ours: Resampling Images into 1D Token Sequences of Flexible Length}

\begin{document}

\twocolumn[
\icmltitle{\ours: Resampling Images into 1D Token Sequences of Flexible Length}



\icmlsetsymbol{equal}{*}
\icmlsetsymbol{internship}{\textdagger}

\newcounter{@affilapple}\setcounter{@affilapple}{1}
\newcounter{@affilepfl}\setcounter{@affilepfl}{2}

\expandafter\gdef\csname the@affilaffilapple\endcsname{1}
\expandafter\gdef\csname the@affilaffilepfl\endcsname{2}

\begin{icmlauthorlist}
\icmlauthor{Roman Bachmann}{equal,affilapple,affilepfl}
\icmlauthor{Jesse Allardice}{equal,affilapple}
\icmlauthor{David Mizrahi}{equal,affilapple}
\icmlauthor{Enrico Fini}{affilapple}
\icmlauthor{O\u{g}uzhan Fatih Kar}{affilepfl}
\icmlauthor{Elmira Amirloo}{affilapple}
\icmlauthor{Alaaeldin El-Nouby}{affilapple}
\icmlauthor{Amir Zamir}{affilepfl}
\icmlauthor{Afshin Dehghan}{affilapple}
\end{icmlauthorlist}

\icmlaffiliation{affilapple}{Apple}
\icmlaffiliation{affilepfl}{Swiss Federal Institute of Technology Lausanne (EPFL)}

\icmlcorrespondingauthor{Roman Bachmann}{roman.bachmann@epfl.ch}
\icmlcorrespondingauthor{Jesse Allardice}{jallardice@apple.com}
\icmlcorrespondingauthor{David Mizrahi}{d\_mizrahi@apple.com}

\begin{center}
\textsuperscript{1}Apple \quad
\textsuperscript{2}Swiss Federal Institute of Technology Lausanne (EPFL)
\end{center}

\icmlkeywords{Tokenization, Tokenizer, Generative Modeling, Autoregressive, Transformer, Rectified Flow, Image Generation, Machine Learning, Computer Vision}

\begin{center}
    \centering
    \weburl
    \vspace{1em}
    \captionsetup{type=figure}
    \includegraphics{resources/main/pull_figure.pdf}
    \captionof{figure}{
        \textbf{Comparison of partial sequence generation: Raster-scan 2D-grid tokenizer vs. \ours.}
        \ours resamples images into a 1D sequence of discrete tokens of flexible length, describing images in a coarse-to-fine manner. When training autoregressive (AR) models on \ours token sequences, the class conditioning (here \textit{``golden retriever''}) can be satisfied by generating as few as 8 tokens, whereas AR models trained on 2D tokenizer grids (here, LlamaGen~\cite{sun2024autoregressive}) need to always generate all tokens, no matter the complexity of the condition or image.
    }
    \label{fig:retok_pull}
\end{center}

\vskip 0.2in
]


\printAffiliationsAndNotice{\icmlEqualContribution} %

\input{sec/0_abstract}    
\input{sec/1_intro}
\input{sec/2_relatedwork}
\input{sec/3_method}
\input{sec/4_implementation}
\input{sec/5_experiments}
\input{sec/6_conclusion}
\input{sec/7_acknowledgments}
\pagebreak

\bibliography{references}
\bibliographystyle{icml2025}

\include{sec/X_suppl}

\end{document}
