\section{Introduction}
\label{sec:intro}

\begin{figure*}[ht!]
\centering
\includegraphics[width=\textwidth]{resources/main/flextok_reconst_dfn.pdf}
\vspace{-1.5em}
\caption{
\textbf{Reconstruction examples using \oursxlarge trained on DFN.} Notice how most of the images' semantic and geometric content is captured by fewer than 16 tokens. The first tokens already capture the high-level semantic concepts (e.g., \textit{gray bird, people in colorful garments, mountain scene, yellow flower}), while more tokens are required to reconstruct more intricate scene details (e.g., \textit{position and clothing of every person, brushstroke placement, etc.}). To showcase out-of-distribution reconstruction, we generated the original images using Midjourney v6.1~\cite{midjourneyv61}.
}
\label{fig:reconst_dfn}
\end{figure*}

Image generation has advanced significantly in both quality and inference speed. Tokenization plays a crucial role in reducing the computational cost of training generative models~\cite{van2017neural, esser2021taming}. Recently, autoregressive (AR) image generation has shown competitive performance when scaled to billions of parameters~\cite{sun2024autoregressive}. 

Generative models such as diffusion~\cite{rombach2022high, peebles2023scalable}, masked~\cite{Chang2022MaskGIT, Chang2023Muse}, and autoregressive~\cite{Chen2020iGPT,Yu2022Parti} models traditionally operate on 2D grids of continuous or discrete tokens. These representations maintain strong spatial alignment with the original pixel patches~\cite{esser2021taming, mentzer2023fsq}, but this means that the representation size is proportional to the image size, rather than dependent on the complexity of the image.
Recent work~\cite{yu2024titok} has demonstrated the benefits of 1D tokenization schemes for improving computational efficiency while maintaining competitive quality. Similar to existing 2D grid tokenization schemes, these 1D token sequences are fixed-length, \textit{regardless of the underlying image complexity}. In other words, no matter whether an image simply depicts a single object or a busy scene with intricate details, it is encoded into the same number of tokens. In turn, a conditional image generator trained to predict these tokens must always produce the full set of tokens, no matter the semantic complexity of the condition. 

In this paper, we present \ours, a novel variable-length 1D tokenizer that is able to encode images into an ordered and content-dependent sequence of tokens. As visualized in \cref{fig:reconst_dfn}, earlier tokens capture the most high-level semantic and geometric information, while additional tokens progressively add finer details. The variable-length sequences, i.e. truncated subsequences of length 1, 2, 4, ..., 256, can be decoded into plausible images using an end-to-end trained rectified flow decoder. \cref{fig:retok_pull} contrasts the rigid raster-scan ordering of traditional 2D tokenizers
(top) with our hierarchical 1D approach that enables coarse-to-fine generation (bottom).

Our contributions are as follows:

\paragraph{Flexible-length tokenization:} We present a 1D tokenization approach that can compress images into anywhere from 1 to 256 tokens. Through a combination of nested dropout and causal attention masking, our tokens are \textit{naturally ordered} from coarse to fine details, enabling high-quality reconstruction even with very few tokens while providing progressively more detailed representations as more tokens are used.


\paragraph{A new \textit{``visual vocabulary''} to describe images:} Unlike classical 2D tokenizers which describe image content at each x,y location, \ours uses a hierarchical approach in which high-level aspects such as semantic and geometric concepts naturally emerge to be ordered first, while subsequent tokens add finer details. This allows a coarse conditioning to be fulfilled with relatively few predicted tokens, while a more detailed condition requires generating a larger number of tokens. For example, as shown in \cref{fig:specificity_vs_num_tokens}, ImageNet-1k classes can be generated with as few as 8 tokens. In contrast, text conditions, which may involve more complex and varied prompts, can benefit from predicting up to 256 tokens.

\paragraph{End-to-end trained rectified flow decoder:} To enable high-quality image reconstruction across varying token lengths, we incorporate a rectified flow objective into our tokenizer decoder. This architecture proves essential for maintaining reconstruction quality even at extreme compression rates.
