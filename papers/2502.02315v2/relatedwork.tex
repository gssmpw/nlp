\section{Related Work}
\label{sec:related_work}
\subsection{Instruction-based LLM Deduction}
\label{sec:deduction_related_work}
Given an instruction, how to ask LLM to perform deduction based on it, i.e. instruction following, has been widely considered by researchers. Previous studies such as IFEval \cite{instruction-following-eval}, InfoBench \cite{qin2024infobench}, and RuleBench \cite{sun2024beyond} have been instrumental in evaluating the capacity of large models to follow the instructions, also demonstrating that instruction fine-tuning (IFT) can significantly bolster this capability. 

Different from the prompt-level instruction-following paradigm, Meta-Learning methods like Hint \cite{ivison-etal-2023-hint} and TAGI \cite{liao2024instance} have tried training a hyper-network to encode the instruction into some extra parameters of LLMs to execute the instruction. However, these Meta-Learning methods rely heavily on supervised training conducted in advance on each subtask to obtain (instruction, parameter) pairs as training data for the hyper-network.

VaiBot employs a similar hyper-network architecture that maps instructions to LLMs' parameters, but it further integrates a reconstruction process, enabling the training of this hyper-network to no longer depend on pre-prepared (parameter, instruction) pairs. Instead, it can be trained on general instruction-following datasets.

\subsection{Instruction-oriented LLM Induction}
\label{sec:induction_related_work}
For the sake of interpretability and generalization, some previous works also try to induce instruction from task observations through LLMs. Some evaluation studies \cite{eval1, eval2, mitchell2023comparing} have consistently demonstrated that current LLMs are poor at the task of induction. To improve LLMs' capability of induction, methods such as Hypothesis Search \cite{wang2023hypothesis} and ItD \cite{sun2024itd} have modeled induction as a sequence generation task, attempting to enhance the inductive abilities of large models through approaches like sampling-selecting and augmenting-finetuning.

However, these methods are confined to \emph{data-based induction} and overlook the fact that the parameters of neural networks, once trained to converge on task data, provide highly indicative cues for the objectives of induction. VaiBot introduces \emph{parameter-based induction}, and our experiments have demonstrated that this approach significantly outperforms the previous series of data-based induction methods.