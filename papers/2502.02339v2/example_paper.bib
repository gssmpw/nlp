% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").



@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}
@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}
@inproceedings{Sclar0TS24,
  author={Sclar, Melanie and Choi, Yejin and Tsvetkov, Yulia and Suhr, Alane},
  title={Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting},
  year={2024},
  cdate={1704067200000},
  booktitle={ICLR},
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}
@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}
@inproceedings{hao-etal-2023-reasoning,
    title = "Reasoning with Language Model is Planning with World Model",
    author = "Hao, Shibo  and
      Gu, Yi  and
      Ma, Haodi  and
      Hong, Joshua  and
      Wang, Zhen  and
      Wang, Daisy  and
      Hu, Zhiting",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    pages = "8154--8173",
}
@inproceedings{ge2024worldgpt,
  title={Worldgpt: Empowering llm as multimodal world model},
  author={Ge, Zhiqi and Huang, Hongzhe and Zhou, Mingze and Li, Juncheng and Wang, Guoming and Tang, Siliang and Zhuang, Yueting},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={7346--7355},
  year={2024}
}
@inproceedings{8099698,
  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Zitnick, C. Lawrence and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning}, 
  year={2017},
  pages={1988-1997}
}
@article{10.1016/j.inffus.2022.11.011,
author = {Ma\l{}ki\'{n}ski, Miko\l{}aj and Ma\'{n}dziuk, Jacek},
title = {A review of emerging research directions in Abstract Visual Reasoning},
year = {2023},
issue_date = {Mar 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {91},
number = {C},
issn = {1566-2535},
journal = {Inf. Fusion},
month = mar,
pages = {713â€“736},
numpages = {24},
}
@inproceedings{wang-etal-2024-math,
    title = "Math-Shepherd: Verify and Reinforce {LLM}s Step-by-step without Human Annotations",
    author = "Wang, Peiyi  and
      Li, Lei  and
      Shao, Zhihong  and
      Xu, Runxin  and
      Dai, Damai  and
      Li, Yifei  and
      Chen, Deli  and
      Wu, Yu  and
      Sui, Zhifang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "9426--9439"
}
@inproceedings{ahn-etal-2024-large,
    title = "Large Language Models for Mathematical Reasoning: Progresses and Challenges",
    author = "Ahn, Janice  and
      Verma, Rishu  and
      Lou, Renze  and
      Liu, Di  and
      Zhang, Rui  and
      Yin, Wenpeng",
    editor = "Falk, Neele  and
      Papi, Sara  and
      Zhang, Mike",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    pages = "225--237",
}
@inproceedings{
xi2024training,
title={Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning},
author={Zhiheng Xi and Wenxiang Chen and Boyang Hong and Senjie Jin and Rui Zheng and Wei He and Yiwen Ding and Shichun Liu and Xin Guo and Junzhe Wang and Honglin Guo and Wei Shen and Xiaoran Fan and Yuhao Zhou and Shihan Dou and Xiao Wang and Xinbo Zhang and peng sun and Tao Gui and Qi Zhang and Xuanjing Huang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}
@inproceedings{
havrilla2024glore,
title={{GL}oRe: When, Where, and How to Improve {LLM} Reasoning via Global and Local Refinements},
author={Alexander Havrilla and Sharath Chandra Raparthy and Christoforos Nalmpantis and Jane Dwivedi-Yu and Maksym Zhuravinskyi and Eric Hambro and Roberta Raileanu},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}
@article{qi2024mutual,
  title={Mutual reasoning makes smaller llms stronger problem-solvers},
  author={Qi, Zhenting and Ma, Mingyuan and Xu, Jiahang and Zhang, Li Lyna and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2408.06195},
  year={2024}
}
@inproceedings{zhao-etal-2024-unveiling,
    title = "Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism",
    author = "Zhao, Anhao  and
      Ye, Fanghua  and
      Fu, Jinlan  and
      Shen, Xiaoyu",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "12375--12400",
}
@inproceedings{zhou-etal-2024-mystery,
    title = "The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis",
    author = "Zhou, Yuxiang  and
      Li, Jiazheng  and
      Xiang, Yanzheng  and
      Yan, Hanqi  and
      Gui, Lin  and
      He, Yulan",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "14365--14378",
}
@inproceedings{dong-etal-2024-survey,
    title = "A Survey on In-context Learning",
    author = "Dong, Qingxiu  and
      Li, Lei  and
      Dai, Damai  and
      Zheng, Ce  and
      Ma, Jingyuan  and
      Li, Rui  and
      Xia, Heming  and
      Xu, Jingjing  and
      Wu, Zhiyong  and
      Chang, Baobao  and
      Sun, Xu  and
      Li, Lei  and
      Sui, Zhifang",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "1107--1128",
}
@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}
@inproceedings{wang-etal-2023-self-instruct,
    title = "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    author = "Wang, Yizhong  and
      Kordi, Yeganeh  and
      Mishra, Swaroop  and
      Liu, Alisa  and
      Smith, Noah A.  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "13484--13508",
}
@article{
luo2024incontext,
title={In-context Learning with Retrieved Demonstrations for Language Models: A Survey},
author={Man Luo and Xin Xu and Yue Liu and Panupong Pasupat and Mehran Kazemi},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
note={Survey Certification}
}
@article{yang2024buffer,
  title={Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models},
  author={Yang, Ling and Yu, Zhaochen and Zhang, Tianjun and Cao, Shiyi and Xu, Minkai and Zhang, Wentao and Gonzalez, Joseph E and Cui, Bin},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}
@article{sprague2024cot,
  title={To cot or not to cot? chain-of-thought helps mainly on math and symbolic reasoning},
  author={Sprague, Zayne and Yin, Fangcong and Rodriguez, Juan Diego and Jiang, Dongwei and Wadhwa, Manya and Singhal, Prasann and Zhao, Xinyu and Ye, Xi and Mahowald, Kyle and Durrett, Greg},
  journal={arXiv preprint arXiv:2409.12183},
  year={2024}
}
@inproceedings{wang-etal-2023-label,
    title = "Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning",
    author = "Wang, Lean  and
      Li, Lei  and
      Dai, Damai  and
      Chen, Deli  and
      Zhou, Hao  and
      Meng, Fandong  and
      Zhou, Jie  and
      Sun, Xu",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    pages = "9840--9855",
}
@article{cui2024theoretical,
  title={A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration},
  author={Cui, Yingqian and He, Pengfei and Tang, Xianfeng and He, Qi and Luo, Chen and Tang, Jiliang and Xing, Yue},
  journal={arXiv preprint arXiv:2410.16540},
  year={2024}
}
@inproceedings{wangmixture,
  title={Mixture of Demonstrations for In-Context Learning},
  author={Wang, Song and Chen, Zihan and Shi, Chengshuai and Shen, Cong and Li, Jundong},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}
@inproceedings{BENCHMARKS2021_be83ab3e,
 author = {Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
 booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
 editor = {J. Vanschoren and S. Yeung},
 title = {Measuring Mathematical Problem Solving With the MATH Dataset},
 volume = {1},
 year = {2021}
}
@inproceedings{fu2023specializing,
  title={Specializing smaller language models towards multi-step reasoning},
  author={Fu, Yao and Peng, Hao and Ou, Litu and Sabharwal, Ashish and Khot, Tushar},
  booktitle={International Conference on Machine Learning},
  pages={10421--10430},
  year={2023},
  organization={PMLR}
}
@article{plaat2024reasoning,
  title={Reasoning with large language models, a survey},
  author={Plaat, Aske and Wong, Annie and Verberne, Suzan and Broekens, Joost and van Stein, Niki and Back, Thomas},
  journal={arXiv preprint arXiv:2407.11511},
  year={2024}
}
@inproceedings{
chen2024toward,
title={Toward Adaptive Reasoning in Large Language Models with Thought Rollback},
author={Sijia Chen and Baochun Li},
booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}
@article{swiechowski2023monte,
  title={Monte Carlo tree search: A review of recent modifications and applications},
  author={{\'S}wiechowski, Maciej and Godlewski, Konrad and Sawicki, Bartosz and Ma{\'n}dziuk, Jacek},
  journal={Artificial Intelligence Review},
  volume={56},
  number={3},
  pages={2497--2562},
  year={2023},
  publisher={Springer}
}
@article{koh2024tree,
  title={Tree search for language model agents},
  author={Koh, Jing Yu and McAleer, Stephen and Fried, Daniel and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2407.01476},
  year={2024}
}
@article{wu2024comparative,
  title={A Comparative Study on Reasoning Patterns of OpenAI's o1 Model},
  author={Wu, Siwei and Peng, Zhongyuan and Du, Xinrun and Zheng, Tuney and Liu, Minghao and Wu, Jialong and Ma, Jiachen and Li, Yizhi and Yang, Jian and Zhou, Wangchunshu and others},
  journal={arXiv preprint arXiv:2410.13639},
  year={2024}
}
@article{qin2024o1,
  title={O1 Replication Journey: A Strategic Progress Report--Part 1},
  author={Qin, Yiwei and Li, Xuefeng and Zou, Haoyang and Liu, Yixiu and Xia, Shijie and Huang, Zhen and Ye, Yixin and Yuan, Weizhe and Liu, Hector and Li, Yuanzhi and others},
  journal={arXiv preprint arXiv:2410.18982},
  year={2024}
}
@article{sun2024beats,
  title={BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search},
  author={Sun, Linzhuang and Liang, Hao and Wei, Jingxuan and Yu, Bihui and He, Conghui and Zhou, Zenan and Zhang, Wentao},
  journal={arXiv preprint arXiv:2409.17972},
  year={2024}
}
@article{zeng2024scaling,
  title={Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective},
  author={Zeng, Zhiyuan and Cheng, Qinyuan and Yin, Zhangyue and Wang, Bo and Li, Shimin and Zhou, Yunhua and Guo, Qipeng and Huang, Xuanjing and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2412.14135},
  year={2024}
}
@article{zhang2024rest,
  title={Rest-mcts*: Llm self-training via process reward guided tree search},
  author={Zhang, Dan and Zhoubian, Sining and Hu, Ziniu and Yue, Yisong and Dong, Yuxiao and Tang, Jie},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}
@inproceedings{NEURIPS2023_271db992,
 author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {11809--11822},
 publisher = {Curran Associates, Inc.},
 title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
 volume = {36},
 year = {2023}
}
@inproceedings{
chen2024alphamath,
title={AlphaMath Almost Zero: Process Supervision without Process},
author={Guoxin Chen and Minpeng Liao and Chengxi Li and Kai Fan},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
}
@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}
@article{lu2023emergent,
  title={Are Emergent Abilities in Large Language Models just In-Context Learning?},
  author={Lu, Sheng and Bigoulaeva, Irina and Sachdeva, Rachneet and Madabushi, Harish Tayyar and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2309.01809},
  year={2023}
}
@article{tian2024toward,
  title={Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing},
  author={Tian, Ye and Peng, Baolin and Song, Linfeng and Jin, Lifeng and Yu, Dian and Mi, Haitao and Yu, Dong},
  journal={arXiv preprint arXiv:2404.12253},
  year={2024}
}
@article{kang2024mindstar,
  title={Mindstar: Enhancing math reasoning in pre-trained llms at inference time},
  author={Kang, Jikun and Li, Xin Zhe and Chen, Xi and Kazemi, Amirreza and Sun, Qianyi and Chen, Boxing and Li, Dong and He, Xu and He, Quan and Wen, Feng and others},
  journal={arXiv preprint arXiv:2405.16265},
  year={2024}
}
@inproceedings{
zhou2024language,
title={Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models},
author={Andy Zhou and Kai Yan and Michal Shlapentokh-Rothman and Haohan Wang and Yu-Xiong Wang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}
@article{zhang2024accessing,
  title={Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B},
  author={Zhang, Di and Li, Jiatong and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2406.07394},
  year={2024}
}
@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  pages={41--75},
  year={1997},
  publisher={Springer}
}
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@inproceedings{chaslot2008monte,
  title={Monte-carlo tree search: A new framework for game ai},
  author={Chaslot, Guillaume and Bakkes, Sander and Szita, Istvan and Spronck, Pieter},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={4},
  number={1},
  pages={216--217},
  year={2008}
}
@inproceedings{
feng2023alphazero,
title={Alphazero-like tree-search can guide large language model decoding and training},
author={Feng, Xidong and Wan, Ziyu and Wen, Muning and McAleer, Stephen Marcus and Wen, Ying and Zhang, Weinan and Wang, Jun},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}
@Article{Jaffe23,
  author = 	 "P. I. Jaffe and R. A. Poldrack and R. J. Schafer and et al.",
  title = 	 "Modelling human behaviour in cognitive tasks with latent dynamical systems",
  journal =	 "Nature Human Behaviour",
  year =	 "2023",
  volume =	 "7",
  number =	 "",
  pages =	 "986--1000"
}
@Book{Kahneman2011,
  author    = {Daniel Kahneman},
  title     = {Thinking, Fast and Slow},
  publisher = {Farrar, Straus and Giroux},
  year      = {2011},
  address   = {New York, NY},
  isbn      = {978-0374275631}
}
@article{da2023system,
  title={System 1 vs. System 2 Thinking},
  author={Da Silva, Sergio},
  journal={Psych},
  volume={5},
  number={4},
  pages={1057--1076},
  year={2023},
  publisher={MDPI}
}
@article{Hagendorff2023,
  author    = {Thilo Hagendorff and Sarah Fabi and Michal Kosinski},
  title     = {Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT},
  journal   = {Nature Computational Science},
  year      = {2023},
  volume    = {3},
  number    = {10},
  pages     = {833--838}
}
@article{fischer1977convergent,
  title={Convergent validation of decomposed multi-attribute utility assessment procedures for risky and riskless decisions},
  author={Fischer, Gregory W},
  journal={Organizational Behavior and Human Performance},
  volume={18},
  number={2},
  pages={295--315},
  year={1977},
  publisher={Elsevier}
}
@inproceedings{
zhou2023leasttomost,
title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
author={Denny Zhou and Nathanael Sch{\"a}rli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc V Le and Ed H. Chi},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}
@inproceedings{NEURIPS2021_d5eca8dc,
 author = {Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {25476--25488},
 publisher = {Curran Associates, Inc.},
 title = {Mastering Atari Games with Limited Data},
 volume = {34},
 year = {2021}
}
@inproceedings{
ZhouYSWW24,
title={Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models},
author={Andy Zhou and Kai Yan and Michal Shlapentokh-Rothman and Haohan Wang and Yu-Xiong Wang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}
@article{wang2024litesearch,
  title={Litesearch: Efficacious tree search for llm},
  author={Wang, Ante and Song, Linfeng and Tian, Ye and Peng, Baolin and Yu, Dian and Mi, Haitao and Su, Jinsong and Yu, Dong},
  journal={arXiv preprint arXiv:2407.00320},
  year={2024}
}
@InProceedings{11871842_29,
author="Kocsis, Levente
and Szepesv{\'a}ri, Csaba",
editor="F{\"u}rnkranz, Johannes
and Scheffer, Tobias
and Spiliopoulou, Myra",
title="Bandit Based Monte-Carlo Planning",
booktitle="Machine Learning: ECML 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="282--293",
isbn="978-3-540-46056-5"
}
@inproceedings{
wang2023selfconsistency,
title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}
@inproceedings{
fluri2023evaluating,
title={Evaluating Superhuman Models with Consistency Checks},
author={Lukas Fluri and Daniel Paleka and Florian Tram{\`e}r},
booktitle={Socially Responsible Language Modelling Research},
year={2023},
}
@article{de2024rational,
  title={Rational Metareasoning for Large Language Models},
  author={De Sabbata, C Nicol{\`o} and Sumers, Theodore R and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2410.05563},
  year={2024}
}
@article{RUSSELL1991361,
title = {Principles of metareasoning},
journal = {Artificial Intelligence},
volume = {49},
number = {1},
pages = {361-395},
year = {1991},
issn = {0004-3702},
author = {Stuart Russell and Eric Wefald}
}
@article{russek2022time,
  title={Time spent thinking in online chess reflects the value of computation},
  author={Russek, Evan and Acosta-Kane, Daniel and van Opheusden, Bas and Mattar, Marcelo G and Griffiths, Tom},
  year={2022},
  publisher={PsyArXiv}
}
@article{embretson2008understanding,
  title={Understanding and quantifying cognitive complexity level in mathematical problem solving items},
  author={Embretson, Susan E and Daniel, Robert C},
  journal={Psychology Science},
  volume={50},
  number={3},
  pages={328},
  year={2008}
}
@article{lee2000problem,
  title={Problem complexity: A measure of problem difficulty in algebra by using computer},
  author={Lee, Fong-Lok and Heyworth, Rex},
  journal={Education Journal},
  volume={28},
  number={1},
  pages={85--108},
  year={2000},
  publisher={Citeseer}
}
@inproceedings{
lightman2024lets,
title={Let's Verify Step by Step},
author={Hunter Lightman and Vineet Kosaraju and Yuri Burda and Harrison Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}
@inproceedings{li-etal-2023-making,
    title = "Making Language Models Better Reasoners with Step-Aware Verifier",
    author = "Li, Yifei  and
      Lin, Zeqi  and
      Zhang, Shizhuo  and
      Fu, Qiang  and
      Chen, Bei  and
      Lou, Jian-Guang  and
      Chen, Weizhu",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "5315--5333"
}
@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}
@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}
@inproceedings{Patel2021AreNM,
  title={Are NLP Models really able to Solve Simple Math Word Problems?},
  author={Arkil Patel and S. Bhattamishra and Navin Goyal},
  booktitle={North American Chapter of the Association for Computational Linguistics},
  year={2021}
}
@inproceedings{
hendrycks2021measuring,
title={Measuring Mathematical Problem Solving With the {MATH} Dataset},
author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
year={2021}
}
@article{geva2021did,
  title={Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies},
  author={Geva, Mor and Khashabi, Daniel and Segal, Elad and Khot, Tushar and Roth, Dan and Berant, Jonathan},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={346--361},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~â€¦}
}
@article{miyai2024generalized,
  title={Generalized out-of-distribution detection and beyond in vision language model era: A survey},
  author={Miyai, Atsuyuki and Yang, Jingkang and Zhang, Jingyang and Ming, Yifei and Lin, Yueqian and Yu, Qing and Irie, Go and Joty, Shafiq and Li, Yixuan and Li, Hai and others},
  journal={arXiv preprint arXiv:2407.21794},
  year={2024}
}
@inproceedings{
dong2024multiood,
title={Multi{OOD}: Scaling Out-of-Distribution Detection for Multiple Modalities},
author={Hao Dong and Yue Zhao and Eleni Chatzi and Olga Fink},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024}
}
@article{zhang2024out,
  title={On the out-of-distribution generalization of multimodal large language models},
  author={Zhang, Xingxuan and Li, Jiansheng and Chu, Wenjing and Hai, Junjia and Xu, Renzhe and Yang, Yuqing and Guan, Shikai and Xu, Jiazheng and Cui, Peng},
  journal={arXiv preprint arXiv:2402.06599},
  year={2024}
}
@inproceedings{
yang2023outofdistribution,
title={Out-of-Distribution Generalization in Natural Language Processing: Past, Present, and Future},
author={Linyi Yang and Yaoxian Song and Xuan Ren and Chenyang Lyu and Yidong Wang and Jingming Zhuo and Lingqiao Liu and Jindong Wang and Jennifer Foster and Yue Zhang},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=ivSJdhcuTi}
}
@article{zhang2024llama,
  title={Llama-berry: Pairwise optimization for o1-like olympiad-level mathematical reasoning},
  author={Zhang, Di and Wu, Jianbo and Lei, Jingdi and Che, Tong and Li, Jiatong and Xie, Tong and Huang, Xiaoshui and Zhang, Shufei and Pavone, Marco and Li, Yuqiang and others},
  journal={arXiv preprint arXiv:2410.02884},
  year={2024}
}
@misc{meta_llama_2023,
    title = {Llama: Latest models},
    url = {https://www.llama.com/},
    author = {{Meta AI}},
    year = {2024}
}

@article{young2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}
@misc{qwen25,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {{Qwen Team}},
    month = {September},
    year = {2024}
}
@misc{gpt4o,
    title = {Hello GPT-4o},
    url = {https://openai.com/index/hello-gpt-4o/},
    author = {{OpenAI}},
    month = {May},
    year = {2024}
}
@misc{gpt35,
    title = {Introducing ChatGPT},
    url = {https://openai.com/index/chatgpt/},
    author = {{OpenAI}},
    month = {November},
    year = {2022}
}
@misc{gemini,
    title = {Gemini Models},
    url = {https://deepmind.google/technologies/gemini/},
    author = {{Google DeepMind}},
    month = {May},
    year = {2024}
}
@misc{claude,
    title = {Introducing Claude 3.5 Sonnet},
    url = {https://www.anthropic.com/news/claude-3-5-sonnet},
    author = {{Anthropic}},
    month={June},
    year = {2024}
}
@misc{claude3,
    title = {Introducing the next generation of Claude},
    url = {https://www.anthropic.com/news/claude-3-family},
    author = {{Anthropic}},
    month={March},
    year = {2024}
}
@misc{o1,
    title = {Learning to Reason with LLMs},
    url = {https://openai.com/index/learning-to-reason-with-llms/},
    author = {{OpenAI}},
    month = {September},
    year = {2024}
}
@article{liu2024deepseek,
  title={Deepseek-v2: A strong, economical, and efficient mixture-of-experts language model},
  author={Liu, Aixin and Feng, Bei and Wang, Bin and Wang, Bingxuan and Liu, Bo and Zhao, Chenggang and Dengr, Chengqi and Ruan, Chong and Dai, Damai and Guo, Daya and others},
  journal={arXiv preprint arXiv:2405.04434},
  year={2024}
}
@article{adler2024nemotron,
  title={Nemotron-4 340B Technical Report},
  author={Adler, Bo and Agarwal, Niket and Aithal, Ashwath and Anh, Dong H and Bhattacharya, Pallab and Brundyn, Annika and Casper, Jared and Catanzaro, Bryan and Clay, Sharon and Cohen, Jonathan and others},
  journal={arXiv preprint arXiv:2406.11704},
  year={2024}
}
@misc{numina_math_7b,
  author = {Edward Beeching and Shengyi Costa Huang and Albert Jiang and Jia Li and Benjamin Lipkin and Zihan Qina and Kashif Rasul and Ziju Shen and Roman Soletskyi and Lewis Tunstall},
  title = {NuminaMath 72B CoT},
  year = {2024},
  publisher = {Numina & Hugging Face},
  journal = {Hugging Face repository},
  howpublished = {\url{https://huggingface.co/AI-MO/NuminaMath-72B-CoT}}
}
@misc{mixtral822,
    title = {Cheaper, Better, Faster, Stronger},
    url = {https://mistral.ai/news/mixtral-8x22b/},
    author = {{Mistral AI team}},
    month = {April},
    year = {2024}
}
@misc{mixtrallarge2,
    title = {Large Enough},
    url = {https://mistral.ai/news/mistral-large-2407/},
    author = {{Mistral AI team}},
    month = {July},
    year = {2024}
}
@inproceedings{masry-etal-2022-chartqa,
    title = "{C}hart{QA}: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning",
    author = "Masry, Ahmed  and
      Do, Xuan Long  and
      Tan, Jia Qing  and
      Joty, Shafiq  and
      Hoque, Enamul",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    pages = "2263--2279",
}
@inproceedings{zong-qiu-2024-gaokao,
    title = "{GAOKAO}-{MM}: A {C}hinese Human-Level Benchmark for Multimodal Models Evaluation",
    author = "Zong, Yi  and
      Qiu, Xipeng",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "8817--8825"
}
@article{bge_m3,
  author       = {Jianlv Chen and
                  Shitao Xiao and
                  Peitian Zhang and
                  Kun Luo and
                  Defu Lian and
                  Zheng Liu},
  title        = {{BGE} M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity
                  Text Embeddings Through Self-Knowledge Distillation},
  journal      = {CoRR},
  volume       = {abs/2402.03216},
  year         = {2024},
  eprinttype    = {arXiv},
  eprint       = {2402.03216}
}
@inproceedings{dbscan,
  author       = {Martin Ester and
                  Hans{-}Peter Kriegel and
                  J{\"{o}}rg Sander and
                  Xiaowei Xu},
  editor       = {Evangelos Simoudis and
                  Jiawei Han and
                  Usama M. Fayyad},
  title        = {A Density-Based Algorithm for Discovering Clusters in Large Spatial
                  Databases with Noise},
  booktitle    = {Proceedings of the Second International Conference on Knowledge Discovery
                  and Data Mining (KDD-96), Portland, Oregon, {USA}},
  pages        = {226--231},
  publisher    = {{AAAI} Press},
  year         = {1996}
}

@inproceedings{
chen2024we,
title={Are We on the Right Way for Evaluating Large Vision-Language Models?},
author={Lin Chen and Jinsong Li and Xiaoyi Dong and Pan Zhang and Yuhang Zang and Zehui Chen and Haodong Duan and Jiaqi Wang and Yu Qiao and Dahua Lin and Feng Zhao},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024}
}
@inproceedings{
wang2024measuring,
title={Measuring Multimodal Mathematical Reasoning with {MATH}-Vision Dataset},
author={Ke Wang and Junting Pan and Weikang Shi and Zimu Lu and Houxing Ren and Aojun Zhou and Mingjie Zhan and Hongsheng Li},
booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2024}
}
@article{roberts2024smart,
  title={Smart vision-language reasoners},
  author={Roberts, Denisa and Roberts, Lucas},
  journal={arXiv preprint arXiv:2407.04212},
  year={2024}
}
@article{yao2024mulberry,
  title={Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search},
  author={Yao, Huanjin and Huang, Jiaxing and Wu, Wenhao and Zhang, Jingyi and Wang, Yibo and Liu, Shunyu and Wang, Yingjie and Song, Yuxin and Feng, Haocheng and Shen, Li and others},
  journal={arXiv preprint arXiv:2412.18319},
  year={2024}
}
@article{dong2024progressive,
  title={Progressive multimodal reasoning via active retrieval},
  author={Dong, Guanting and Zhang, Chenghao and Deng, Mengjie and Zhu, Yutao and Dou, Zhicheng and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2412.14835},
  year={2024}
}
@article{du2025virgo,
  title={Virgo: A Preliminary Exploration on Reproducing o1-like MLLM},
  author={Du, Yifan and Liu, Zikang and Li, Yifan and Zhao, Wayne Xin and Huo, Yuqi and Wang, Bingning and Chen, Weipeng and Liu, Zheng and Wang, Zhongyuan and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2501.01904},
  year={2025}
}
@article{wu2024beyond,
  title={Beyond examples: High-level automated reasoning paradigm in in-context learning via mcts},
  author={Wu, Jinyang and Feng, Mingkuan and Zhang, Shuai and Che, Feihu and Wen, Zengqi and Tao, Jianhua},
  journal={arXiv preprint arXiv:2411.18478},
  year={2024}
}
@misc{qvq,
  author       = {Qwen Team},
  title        = {QVQ: To See the World with Wisdom},
  year         = {2024},
  month        = {December},
  url          = {https://qwenlm.github.io/blog/qvq-72b-preview/},
}
@article{bansal2024smaller,
  title={Smaller, weaker, yet better: Training llm reasoners via compute-optimal sampling},
  author={Bansal, Hritik and Hosseini, Arian and Agarwal, Rishabh and Tran, Vinh Q and Kazemi, Mehran},
  journal={arXiv preprint arXiv:2408.16737},
  year={2024}
}

@inproceedings{
berglund2024the,
title={The Reversal Curse: {LLM}s trained on {\textquotedblleft}A is B{\textquotedblright} fail to learn {\textquotedblleft}B is A{\textquotedblright}},
author={Lukas Berglund and Meg Tong and Maximilian Kaufmann and Mikita Balesni and Asa Cooper Stickland and Tomasz Korbak and Owain Evans},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=GPKTIktA0k}
}
@inproceedings{yang-etal-2024-unveiling,
    title = "Unveiling the Generalization Power of Fine-Tuned Large Language Models",
    author = "Yang, Haoran  and
      Zhang, Yumeng  and
      Xu, Jiaqi  and
      Lu, Hongyuan  and
      Heng, Pheng-Ann  and
      Lam, Wai",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    pages = "884--899"
}
@inproceedings{
shi2023specialist,
title={Specialist or Generalist? Instruction Tuning for Specific {NLP} Tasks},
author={Chufan Shi and Yixuan Su and Cheng Yang and Yujiu Yang and Deng Cai},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023}
}
@inproceedings{
yuan2023revisiting,
title={Revisiting Out-of-distribution Robustness in {NLP}: Benchmarks, Analysis, and {LLM}s Evaluations},
author={Lifan Yuan and Yangyi Chen and Ganqu Cui and Hongcheng Gao and FangYuan Zou and Xingyi Cheng and Heng Ji and Zhiyuan Liu and Maosong Sun},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023}
}
@article{0001HH0ZWY0HGJ024,
  author={Jindong Wang and Xixu Hu and Wenxin Hou and Hao Chen and Runkai Zheng and Yidong Wang and Linyi Yang and Wei Ye and Haojun Huang and Xiubo Geng and Binxing Jiao and Yue Zhang and Xing Xie},
  title={On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective},
  year={2024},
  cdate={1704067200000},
  journal={IEEE Data Eng. Bull.},
  volume={47},
  number={1},
  pages={48-62}
}
@inproceedings{yang-etal-2024-weak,
    title = "Weak-to-Strong Reasoning",
    author = "Yang, Yuqing  and
      Ma, Yan  and
      Liu, Pengfei",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "8350--8367"
}
@book{dong2020deep,
  title={Deep Reinforcement Learning: Fundamentals, Research and Applications},
  author={Dong, Hao and Ding, Zihan and Zhang, Shanghang},
  isbn={9789811540950},
  publisher={Springer Singapore},
  year={2020},
  series={eBook Packages: Mathematics and Statistics},
  edition={1},
  volume={1},
  pages={514},
}
@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

























































@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@misc{openai2024gpt4o,
  title={{GPT-4o} System Card},
  author={OpenAI},
  year={2024},
  url={https://openai.com/research/gpt-4o-system-card}
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}
@article{
zhang2024multimodal,
title={Multimodal Chain-of-Thought Reasoning in Language Models},
author={Zhuosheng Zhang and Aston Zhang and Mu Li and hai zhao and George Karypis and Alex Smola},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024}
}
@article{chen2024expanding,
  title={Expanding performance boundaries of open-source multimodal models with model, data, and test-time scaling},
  author={Chen, Zhe and Wang, Weiyun and Cao, Yue and Liu, Yangzhou and Gao, Zhangwei and Cui, Erfei and Zhu, Jinguo and Ye, Shenglong and Tian, Hao and Liu, Zhaoyang and others},
  journal={arXiv preprint arXiv:2412.05271},
  year={2024}
}
@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}
@article{yin2023survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023}
}
@article{hartsock2024vision,
  title={Vision-language models for medical report generation and visual question answering: A review},
  author={Hartsock, Iryna and Rasool, Ghulam},
  journal={Frontiers in Artificial Intelligence},
  volume={7},
  pages={1430984},
  year={2024},
  publisher={Frontiers Media SA}
}
@inproceedings{cui2024survey,
  title={A survey on multimodal large language models for autonomous driving},
  author={Cui, Can and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Zhou, Yang and Liang, Kaizhao and Chen, Jintai and Lu, Juanwu and Yang, Zichong and Liao, Kuei-Da and others},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={958--979},
  year={2024}
}

@misc{openai2023gpt4v,
  title={{GPT-4V(ision)} System Card},
  author={OpenAI},
  year={2023},
  url={https://openai.com/research/gpt-4v-system-card}
}
@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}
@article{zhang2024mavis,
  title={MAVIS: Mathematical Visual Instruction Tuning with an Automatic Data Engine},
  author={Zhang, Renrui and Wei, Xinyu and Jiang, Dongzhi and Guo, Ziyu and Li, Shicheng and Zhang, Yichi and Tong, Chengzhuo and Liu, Jiaming and Zhou, Aojun and Wei, Bin and others},
  journal={arXiv preprint arXiv:2407.08739},
  year={2024}
}
@article{zheng2024thinking,
  title={Thinking Before Looking: Improving Multimodal LLM Reasoning via Mitigating Visual Hallucination},
  author={Zheng, Haojie and Xu, Tianyang and Sun, Hanchi and Pu, Shu and Chen, Ruoxi and Sun, Lichao},
  journal={arXiv preprint arXiv:2411.12591},
  year={2024}
}
@article{lu2023machine,
  title={Machine learning for synthetic data generation: a review},
  author={Lu, Yingzhou and Shen, Minjie and Wang, Huazheng and Wang, Xiao and van Rechem, Capucine and Fu, Tianfan and Wei, Wenqi},
  journal={arXiv preprint arXiv:2302.04062},
  year={2023}
}
@article{huang2024key,
  title={Key-point-driven data synthesis with its enhancement on mathematical reasoning},
  author={Huang, Yiming and Liu, Xiao and Gong, Yeyun and Gou, Zhibin and Shen, Yelong and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2403.02333},
  year={2024}
}
@inproceedings{shi2023specialist,
  title={Specialist or Generalist? Instruction Tuning for Specific NLP Tasks},
  author={Shi, Chufan and Su, Yixuan and Yang, Cheng and Yang, Yujiu and Cai, Deng},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={15336--15348},
  year={2023}
}
@article{fu2024vita,
  title={Vita: Towards open-source interactive omni multimodal llm},
  author={Fu, Chaoyou and Lin, Haojia and Long, Zuwei and Shen, Yunhang and Zhao, Meng and Zhang, Yifan and Dong, Shaoqi and Wang, Xiong and Yin, Di and Ma, Long and others},
  journal={arXiv preprint arXiv:2408.05211},
  year={2024}
}
@ARTICLE{10445007,
  author={Zhang, Jingyi and Huang, Jiaxing and Jin, Sheng and Lu, Shijian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Vision-Language Models for Vision Tasks: A Survey}, 
  year={2024},
  volume={46},
  number={8},
  pages={5625-5644}
}

@inproceedings{shi2024math,
    title = "Math-{LL}a{VA}: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models",
    author = "Shi, Wenhao  and
      Hu, Zhiqiang  and
      Bin, Yi  and
      Liu, Junhua  and
      Yang, Yang  and
      Ng, See-Kiong  and
      Bing, Lidong  and
      Lee, Roy Ka-Wei",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "4663--4680",
}
@article{zelikman2022star,
  title={Star: Bootstrapping reasoning with reasoning},
  author={Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15476--15488},
  year={2022}
}
@article{browne2012survey,
  title={A survey of monte carlo tree search methods},
  author={Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={IEEE Transactions on Computational Intelligence and AI in games},
  volume={4},
  number={1},
  pages={1--43},
  year={2012},
  publisher={IEEE}
}
@inproceedings{yang2025octopus,
  title={Octopus: Embodied vision-language programmer from environmental feedback},
  author={Yang, Jingkang and Dong, Yuhao and Liu, Shuai and Li, Bo and Wang, Ziyue and Tan, Haoran and Jiang, Chencheng and Kang, Jiamu and Zhang, Yuanhan and Zhou, Kaiyang and others},
  booktitle={European Conference on Computer Vision},
  pages={20--38},
  year={2025},
  organization={Springer}
}
@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}
@inproceedings{chen2021geoqa,
  title={GeoQA: A Geometric Question Answering Benchmark Towards Multimodal Numerical Reasoning},
  author={Chen, Jiaqi and Tang, Jianheng and Qin, Jinghui and Liang, Xiaodan and Liu, Lingbo and Xing, Eric and Lin, Liang},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={513--523},
  year={2021}
}
@article{guo2024mammoth,
  title={MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale},
  author={Guo, Jarvis and Zheng, Tuney and Bai, Yuelin and Li, Bo and Wang, Yubo and Zhu, King and Li, Yizhi and Neubig, Graham and Chen, Wenhu and Yue, Xiang},
  journal={arXiv preprint arXiv:2412.05237},
  year={2024}
}
@inproceedings{liang2023unimath,
  title={Unimath: A foundational and multimodal mathematical reasoner},
  author={Liang, Zhenwen and Yang, Tianyu and Zhang, Jipeng and Zhang, Xiangliang},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={7126--7133},
  year={2023}
}
@inproceedings{han24infimm,
  title={InfiMM-WebMath-40B: Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning},
  author={Han, Xiaotian and Jian, Yiren and Hu, Xuefeng and Liu, Haogeng and Wang, Yiqi and Fan, Qihang and Ai, Yuang and Huang, Huaibo and He, Ran and Yang, Zhenheng and others},
  booktitle={The 4th Workshop on Mathematical Reasoning and AI at NeurIPS'24},
  year={2024}
}
@article{bai2023qwen,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  volume={1},
  number={2},
  pages={3},
  year={2023}
}
@article{peng2024multimath,
  title={Multimath: Bridging visual and mathematical reasoning for large language models},
  author={Peng, Shuai and Fu, Di and Gao, Liangcai and Zhong, Xiuqin and Fu, Hongguang and Tang, Zhi},
  journal={arXiv preprint arXiv:2409.00147},
  year={2024}
}

@article{gao2023g,
  title={G-llava: Solving geometric problem with multi-modal large language model},
  author={Gao, Jiahui and Pi, Renjie and Zhang, Jipeng and Ye, Jiacheng and Zhong, Wanjun and Wang, Yufei and Hong, Lanqing and Han, Jianhua and Xu, Hang and Li, Zhenguo and others},
  journal={arXiv preprint arXiv:2312.11370},
  year={2023}
}
@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}
@article{yu2023metamath,
  title={Metamath: Bootstrap your own mathematical questions for large language models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  journal={arXiv preprint arXiv:2309.12284},
  year={2023}
}
@article{trinh2024solving,
  title={Solving olympiad geometry without human demonstrations},
  author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
  journal={Nature},
  volume={625},
  number={7995},
  pages={476--482},
  year={2024},
  publisher={Nature Publishing Group UK London}
}
@article{li2024eagle,
  title={Eagle: Elevating geometric reasoning through llm-empowered visual instruction tuning},
  author={Li, Zhihao and Du, Yao and Liu, Yang and Zhang, Yan and Liu, Yufang and Zhang, Mengdi and Cai, Xunliang},
  journal={arXiv preprint arXiv:2408.11397},
  year={2024}
}
@article{xu2024llava,
  title={LLaVA-o1: Let Vision Language Models Reason Step-by-Step},
  author={Xu, Guowei and Jin, Peng and Hao, Li and Song, Yibing and Sun, Lichao and Yuan, Li},
  journal={arXiv preprint arXiv:2411.10440},
  year={2024}
}
@inproceedings{kwon2023efficient,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  pages={611--626},
  year={2023}
}
@article{kumar2024training,
  title={Training language models to self-correct via reinforcement learning},
  author={Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others},
  journal={arXiv preprint arXiv:2409.12917},
  year={2024}
}
@article{li2024llava,
  title={Llava-onevision: Easy visual task transfer},
  author={Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Zhang, Peiyuan and Li, Yanwei and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2408.03326},
  year={2024}
}
@article{dong2024insight,
  title={Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models},
  author={Dong, Yuhao and Liu, Zuyan and Sun, Hai-Long and Yang, Jingkang and Hu, Winston and Rao, Yongming and Liu, Ziwei},
  journal={arXiv preprint arXiv:2411.14432},
  year={2024}
}
@article{thawakar2025llamav,
  title={LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs},
  author={Thawakar, Omkar and Dissanayake, Dinura and More, Ketan and Thawkar, Ritesh and Heakl, Ahmed and Ahsan, Noor and Li, Yuhao and Zumri, Mohammed and Lahoud, Jean and Anwer, Rao Muhammad and others},
  journal={arXiv preprint arXiv:2501.06186},
  year={2025}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{luo2023wizardmath,
  title={Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2308.09583},
  year={2023}
}
@article{diederik2014adam,
  title={Adam: A method for stochastic optimization},
  author={Diederik, P Kingma},
  journal={(No Title)},
  year={2014}
}
@article{ye2023mplug,
  title={mplug-owl: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={arXiv preprint arXiv:2304.14178},
  year={2023}
}
@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}
@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}
@article{chu2023survey,
  title={A survey of chain of thought reasoning: Advances, frontiers and future},
  author={Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
  journal={arXiv preprint arXiv:2309.15402},
  year={2023}
}
@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022}
}
@inproceedings{luo2024ptd,
  title={PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL},
  author={Luo, Ruilin and Wang, Liyuan and Lin, Binghuai and Lin, Zicheng and Yang, Yujiu},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={3767--3799},
  year={2024}
}
@article{mu2024embodiedgpt,
  title={Embodiedgpt: Vision-language pre-training via embodied chain of thought},
  author={Mu, Yao and Zhang, Qinglong and Hu, Mengkang and Wang, Wenhai and Ding, Mingyu and Jin, Jun and Wang, Bin and Dai, Jifeng and Qiao, Yu and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{an2023skill,
  title={Skill-Based Few-Shot Selection for In-Context Learning},
  author={An, Shengnan and Zhou, Bo and Lin, Zeqi and Fu, Qiang and Chen, Bei and Zheng, Nanning and Chen, Weizhu and Lou, Jian-Guang},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={13472--13492},
  year={2023}
}
@article{sprague2024cot,
  title={To cot or not to cot? chain-of-thought helps mainly on math and symbolic reasoning},
  author={Sprague, Zayne and Yin, Fangcong and Rodriguez, Juan Diego and Jiang, Dongwei and Wadhwa, Manya and Singhal, Prasann and Zhao, Xinyu and Ye, Xi and Mahowald, Kyle and Durrett, Greg},
  journal={arXiv preprint arXiv:2409.12183},
  year={2024}
}
@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}
@article{fu2024tldr,
  title={Tldr: Token-level detective reward model for large vision language models},
  author={Fu, Deqing and Xiao, Tong and Wang, Rui and Zhu, Wang and Zhang, Pengchuan and Pang, Guan and Jia, Robin and Chen, Lawrence},
  journal={arXiv preprint arXiv:2410.04734},
  year={2024}
}
@inproceedings{wang2024math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9426--9439},
  year={2024}
}
@article{luo2024improve,
  title={Improve Mathematical Reasoning in Language Models by Automated Process Supervision},
  author={Luo, Liangchen and Liu, Yinxiao and Liu, Rosanne and Phatale, Samrat and Lara, Harsh and Li, Yunxuan and Shu, Lei and Zhu, Yun and Meng, Lei and Sun, Jiao and others},
  journal={arXiv preprint arXiv:2406.06592},
  year={2024}
}
@article{zhang2024improve,
  title={Improve vision language model chain-of-thought reasoning},
  author={Zhang, Ruohong and Zhang, Bowen and Li, Yanghao and Zhang, Haotian and Sun, Zhiqing and Gan, Zhe and Yang, Yinfei and Pang, Ruoming and Yang, Yiming},
  journal={arXiv preprint arXiv:2410.16198},
  year={2024}
}
@article{liang2024improving,
  title={Improving llm reasoning through scaling inference computation with collaborative verification},
  author={Liang, Zhenwen and Liu, Ye and Niu, Tong and Zhang, Xiangliang and Zhou, Yingbo and Yavuz, Semih},
  journal={arXiv preprint arXiv:2410.05318},
  year={2024}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}
@article{zhang2024generative,
  title={Generative verifiers: Reward modeling as next-token prediction},
  author={Zhang, Lunjun and Hosseini, Arian and Bansal, Hritik and Kazemi, Mehran and Kumar, Aviral and Agarwal, Rishabh},
  journal={arXiv preprint arXiv:2408.15240},
  year={2024}
}
@article{gou2023critic,
  title={Critic: Large language models can self-correct with tool-interactive critiquing},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.11738},
  year={2023}
}
@article{gao2024llm,
  title={LLM critics help catch bugs in mathematics: Towards a better mathematical verifier with natural language feedback},
  author={Gao, Bofei and Cai, Zefan and Xu, Runxin and Wang, Peiyi and Zheng, Ce and Lin, Runji and Lu, Keming and Lin, Junyang and Zhou, Chang and Xiao, Wen and others},
  journal={CoRR},
  year={2024}
}
@article{lu2024deepseek,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}
@article{setlur2024rewarding,
  title={Rewarding progress: Scaling automated process verifiers for llm reasoning},
  author={Setlur, Amrith and Nagpal, Chirag and Fisch, Adam and Geng, Xinyang and Eisenstein, Jacob and Agarwal, Rishabh and Agarwal, Alekh and Berant, Jonathan and Kumar, Aviral},
  journal={arXiv preprint arXiv:2410.08146},
  year={2024}
}
@article{yang2024qwen2math,
  title={Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement},
  author={Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2409.12122},
  year={2024}
}
@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24185--24198},
  year={2024}
}
@article{luo2025ursa,
  title={URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics},
  author={Luo, Ruilin and Zheng, Zhuofan and Wang, Yifan and Yu, Yiyao and Ni, Xinzhe and Lin, Zicheng and Zeng, Jin and Yang, Yujiu},
  journal={arXiv preprint arXiv:2501.04686},
  year={2025}
}
@article{searle1980minds,
	author = {Searle, John R},
	journal = {Behavioral and brain sciences},
	number = {3},
	pages = {417--424},
	publisher = {Cambridge University Press},
	title = {Minds, brains, and programs},
	volume = {3},
	year = {1980}
}
@book{goertzel2007artificial,
	title={Artificial general intelligence},
	author={Goertzel, Ben and Pennachin, Cassio},
	volume={2},
	year={2007},
	publisher={Springer}
}
@misc{claude3family,
  title        = {The Claude 3 Model Family: Opus, Sonnet, Haiku},
  author       = {Anthropic},
  year         = 2024,
  howpublished = {\url{https://www.anthropic.com/claude-3-model-card}},
  note         = {Claude-3 Model Card}
}
@article{wang2024exploring,
  title={Exploring the reasoning abilities of multimodal large language models (mllms): A comprehensive survey on emerging trends in multimodal reasoning},
  author={Wang, Yiqi and Chen, Wentao and Han, Xiaotian and Lin, Xudong and Zhao, Haiteng and Liu, Yongfei and Zhai, Bohan and Yuan, Jianbo and You, Quanzeng and Yang, Hongxia},
  journal={arXiv preprint arXiv:2401.06805},
  year={2024}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}
@article{yao2024minicpm,
  title={MiniCPM-V: A GPT-4V Level MLLM on Your Phone},
  author={Yao, Yuan and Yu, Tianyu and Zhang, Ao and Wang, Chongyi and Cui, Junbo and Zhu, Hongji and Cai, Tianchi and Li, Haoyu and Zhao, Weilin and He, Zhihui and others},
  journal={arXiv preprint arXiv:2408.01800},
  year={2024}
}
@article{chen2024far,
  title={How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}
@article{zhang2024longva,
  title={Long Context Transfer from Language to Vision},
  author={Peiyuan Zhang and Kaichen Zhang and Bo Li and Guangtao Zeng and Jingkang Yang and Yuanhan Zhang and Ziyue Wang and Haoran Tan and Chunyuan Li and Ziwei Liu},
  journal={arXiv preprint arXiv:2406.16852},
  year={2024},
  url = {https://arxiv.org/abs/2406.16852}
}
@misc{glm2024chatglm,
      title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools}, 
      author={Team GLM and Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},
      year={2024},
      eprint={2406.12793},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}
@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}
@article{liu2024sphinx,
  title={Sphinx-x: Scaling data and parameters for a family of multi-modal large language models},
  author={Liu, Dongyang and Zhang, Renrui and Qiu, Longtian and Huang, Siyuan and Lin, Weifeng and Zhao, Shitian and Geng, Shijie and Lin, Ziyi and Jin, Peng and Zhang, Kaipeng and others},
  journal={arXiv preprint arXiv:2402.05935},
  year={2024}
}
@article{lin2023sphinx,
  title={Sphinx: The joint mixing of weights, tasks, and visual embeddings for multi-modal large language models},
  author={Lin, Ziyi and Liu, Chris and Zhang, Renrui and Gao, Peng and Qiu, Longtian and Xiao, Han and Qiu, Han and Lin, Chen and Shao, Wenqi and Chen, Keqin and others},
  journal={arXiv preprint arXiv:2311.07575},
  year={2023}
}
@article{dong2024internlm,
  title={Internlm-xcomposer2: Mastering free-form text-image composition and comprehension in vision-language large model},
  author={Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Cao, Yuhang and Wang, Bin and Ouyang, Linke and Wei, Xilin and Zhang, Songyang and Duan, Haodong and Cao, Maosong and others},
  journal={arXiv preprint arXiv:2401.16420},
  year={2024}
}
@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}
@misc{liu2024llava,
  title={Llava-next: Improved reasoning, ocr, and world knowledge},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
  year={2024}
}
@inproceedings{zhang2025mathverse,
  title={Mathverse: Does your multi-modal llm truly see the diagrams in visual math problems?},
  author={Zhang, Renrui and Jiang, Dongzhi and Zhang, Yichi and Lin, Haokun and Guo, Ziyu and Qiu, Pengshuo and Zhou, Aojun and Lu, Pan and Chang, Kai-Wei and Qiao, Yu and others},
  booktitle={European Conference on Computer Vision},
  pages={169--186},
  year={2025},
  organization={Springer}
}
@article{yan2024errorradar,
  title={ErrorRadar: Benchmarking Complex Mathematical Reasoning of Multimodal Large Language Models Via Error Detection},
  author={Yan, Yibo and Wang, Shen and Huo, Jiahao and Li, Hang and Li, Boyan and Su, Jiamin and Gao, Xiong and Zhang, Yi-Fan and Xu, Tianlong and Chu, Zhendong and others},
  journal={arXiv preprint arXiv:2410.04509},
  year={2024}
}
@article{wang2024enhancing,
  title={Enhancing the reasoning ability of multimodal large language models via mixed preference optimization},
  author={Wang, Weiyun and Chen, Zhe and Wang, Wenhai and Cao, Yue and Liu, Yangzhou and Gao, Zhangwei and Zhu, Jinguo and Zhu, Xizhou and Lu, Lewei and Qiao, Yu and others},
  journal={arXiv preprint arXiv:2411.10442},
  year={2024}
}
@article{6809191,
  author={Muja, Marius and Lowe, David G.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Scalable Nearest Neighbor Algorithms for High Dimensional Data}, 
  year={2014},
  volume={36},
  number={11},
  pages={2227-2240}
}
@article{zou2024dynamath,
  title={DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models},
  author={Zou, Chengke and Guo, Xingang and Yang, Rui and Zhang, Junyu and Hu, Bin and Zhang, Huan},
  journal={arXiv preprint arXiv:2411.00836},
  year={2024}
}

@article{zhuang2024math,
  title={Math-puma: Progressive upward multimodal alignment to enhance mathematical reasoning},
  author={Zhuang, Wenwen and Huang, Xin and Zhang, Xiantao and Zeng, Jin},
  journal={arXiv preprint arXiv:2408.08640},
  year={2024}
}
@article{chen2023minigpt,
  title={MiniGPT-V2: Large Language Model as a Unified Interface for Vision-Language Multi-task Learning},
  author={Chen, Jun and Li, Deyao Zhu1 Xiaoqian Shen1 Xiang and Zhang, Zechun Liu2 Pengchuan and Xiong, Raghuraman Krishnamoorthi2 Vikas Chandra2 Yunyang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2310.09478},
  year={2023}
}
@article{hu2024visual,
  title={Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models},
  author={Hu, Yushi and Shi, Weijia and Fu, Xingyu and Roth, Dan and Ostendorf, Mari and Zettlemoyer, Luke and Smith, Noah A and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2406.09403},
  year={2024}
}
@article{yang2024mathglm,
  title={MathGLM-Vision: Solving Mathematical Problems with Multi-Modal Large Language Model},
  author={Yang, Zhen and Chen, Jinhao and Du, Zhengxiao and Yu, Wenmeng and Wang, Weihan and Hong, Wenyi and Jiang, Zhihuan and Xu, Bin and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2409.13729},
  year={2024}
}
@article{zhang2024critic,
  title={Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning},
  author={Zhang, Di and Lei, Jingdi and Li, Junxian and Wang, Xunzhi and Liu, Yujie and Yang, Zonglin and Li, Jiatong and Wang, Weida and Yang, Suorong and Wu, Jianbo and others},
  journal={arXiv preprint arXiv:2411.18203},
  year={2024}
}
@inproceedings{lin-etal-2024-criticbench,
    title = "{C}ritic{B}ench: Benchmarking {LLM}s for Critique-Correct Reasoning",
    author = "Lin, Zicheng  and
      Gou, Zhibin  and
      Liang, Tian  and
      Luo, Ruilin  and
      Liu, Haowei  and
      Yang, Yujiu",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "1552--1587",
}
@article{lu2023mathvista,
  title={Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.02255},
  year={2023}
}

@article{qiao2024we,
  title={We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?},
  author={Qiao, Runqi and Tan, Qiuna and Dong, Guanting and Wu, Minhui and Sun, Chong and Song, Xiaoshuai and GongQue, Zhuoma and Lei, Shanglin and Wei, Zhe and Zhang, Miaoxuan and others},
  journal={arXiv preprint arXiv:2407.01284},
  year={2024}
}

@article{cai2024geogpt4v,
  title={GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation},
  author={Cai, Shihao and Bao, Keqin and Guo, Hangyu and Zhang, Jizhi and Song, Jun and Zheng, Bo},
  journal={arXiv preprint arXiv:2406.11503},
  year={2024}
}

@article{deng2024r,
  title={R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models},
  author={Deng, Linger and Liu, Yuliang and Li, Bohan and Luo, Dongliang and Wu, Liang and Zhang, Chengquan and Lyu, Pengyuan and Zhang, Ziyang and Zhang, Gang and Ding, Errui and others},
  journal={arXiv preprint arXiv:2410.17885},
  year={2024}
}









































