\section{Related Work}
\label{sec:related}

\textbf{ILP.}
% Many ILP systems \cite{progol,tilde,aleph,quickfoil,probfoil} struggle to learn recursive programs \cite{ilpintro}.
% By contrast, \name{} can learn recursive programs.
Many ILP systems, such as \ale{} \cite{aleph}, use bottom clauses \cite{progol} or variants, such as Kernel sets \cite{xhail} to restrict the hypothesis space \cite{progol}. 
The bottom clause of an example is the most specific clause that entails that example.
Building a bottom clause can be expensive \cite{progol} and, in the worst case, a learner needs to build a bottom clause for every positive example.
Moreover, approaches that use bottom clauses struggle to learn programs with recursion or predicate invention.
By contrast, \name{} does not use bottom clauses and does not have these limitations.

\textbf{Redundancy in ILP.}
% Most work in ILP focuses on methods to improve search efficiency for a fixed hypothesis space.
% There is little work on hypothesis space reduction.
\citeA{DBLP:conf/ilp/FonsecaCSC04} define \emph{self-redundant} clauses, similar to our definition of a reducible rule (Definition \ref{def:breducible}).
Their definition does not guarantee that all the refinements (specialisations) of a redundant clause are redundant.
By contrast, we prove that specialisations of a reducible rule are reducible (Proposition \ref{prop:redu_specs}).
Moreover, the authors do not propose a way to detect such rules; instead, they expect users to provide information about them.
By contrast, we introduce \name{}, which automatically finds reducible and indiscriminate rules.
\citeA{RaedtR04} check whether a rule has a redundant atom before testing it on examples.
If so, it avoids the coverage check.
This approach requires \textit{anti-monotonic} constraints, where if a constraint holds for a rule then it holds for all its generalisations, but not necessarily its specialisations.
By contrast, we find properties which allow us to prune specialisations of a rule.
Moreover, the approach of \citeA{RaedtR04} does not explicitly identify implications between literals and thus could keep building rules with the same implied literals.
By contrast, \name{} explicitly finds implications between literals to prune the hypothesis space.
\citeA{quickfoil} prune rules with simple forms of syntactic redundancy.
For instance, for the rule \emph{h(X) $\leftarrow$ p(X,Y), p(X,Z)}, the authors detect that \emph{p(X,Z)} is duplicate to the literal \emph{p(X,Y)} under the renaming $Z \mapsto Y$, where $Z$ and $Y$ are not in other literals.
By contrast, we detect semantic redundancy by finding reducible and indiscriminate rules.
\citeA{DBLP:conf/ilp/SrinivasanK05} introduce methods to reduce the dimensionality of bottom clauses using statistical methods to compress bottom clauses. 
As the authors state, the resulting lower dimensional space translates directly to a smaller hypothesis space. 
We differ by not using bottom clauses.


\textbf{Rule selection.}
Many recent systems formulate the ILP problem as a rule selection problem \cite{aspal,hexmil,prosynth,aspsynth,ilasp4}.
These approaches precompute every possible rule in the hypothesis space and then search for a subset that generalises the examples.
Because they precompute all possible rules, they cannot learn rules with many literals.
Moreover, because they precompute all possible rules, they can build pointless rules. 
For instance, if allowed to use the relations \emph{int/1} and \emph{even/1}, \textsc{ilasp4} \cite{ilasp4} will precompute all possible rules with \emph{int(A)} and \emph{even(A)} in the body.
By contrast, \name{} does not precompute all rules and instead builds constraints from pointless rules to restrict the generation of rules. 
For instance, if \name{} sees a rule with \emph{int(A)} \emph{even(A)}, it will identify that \emph{even(A)} implies \emph{int(A)} and will henceforth never build a rule with both literals. 
% constrain the generation of rules



% (ii) does not address computational efficiency of  constraint checking, and 


\textbf{Constraints.}
Many recent ILP systems frame the ILP problem as a constraint satisfaction problem \cite{aspal,atom,inspire,hexmil,aspsynth}.
\textsc{MUSPer} \cite{musper} finds minimal unsatisfiable sub-hypotheses, i.e. sub-hypotheses that can never be true, and builds constraints from them to prune the hypothesis space.
For instance, given the rule 
\emph{f(A) $\leftarrow$ succ(A,B),odd(B),even(B)},
\textsc{MUSPer} can identify that a number cannot be both odd and even, i.e. that \emph{odd(B)} and \emph{even(B)} form an unsatisfiable core, and then prunes the hypothesis space accordingly.
By contrast, \name{} finds pointless rules, which are rules with redundancy.

\textbf{Rule induction.}
ILP approaches induce rules from data, similar to rule learning methods \cite{DBLP:conf/ruleml/FurnkranzK15}.
It is difficult to compare ILP methods with recent rule mining techniques, such as AMIE+ \cite{DBLP:journals/vldb/GalarragaTHS15} and RDFRules \cite{rdfrules}.
Most rule-mining methods are limited to unary and binary relations and require facts as input. Additionally, they typically operate under an open-world assumption. 
By contrast, \name{} operates under a closed-world assumption, supports relations of any arity, and can learn from definite programs as background knowledge.

\textbf{Redundancy in AI.}
Preprocessing techniques for eliminating redundancies have received much attention from the theorem-proving community.  Early investigations in this area include~\cite{HoderKKV12} and~\cite{KhasidashviliK16}, and recent investigations include~\cite{VukmirovicBH23}. 
In the SAT community, redundancy elimination techniques, such as \emph{blocked clause elimination}~\cite{Kullmann99}, play an integral role in modern solvers. There is even a chapter in the \emph{Handbook of Satisfiability} dedicated to the topic~\cite{BiereJK21} including several generalisations of earlier concepts, e.g. \emph{covered clauses} \cite{HeuleJB10a,BarnettCB20} and \emph{super-blocked clauses}~\cite{KieslSTB16}. Similar to the concepts presented in this paper, the goal of redundancy elimination methods listed above is to soundly identify derivationally irrelevant input, i.e. clauses in SAT input containing literals that always resolve to tautologies.