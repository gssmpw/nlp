\section{Related work}
\vspace{-1.5mm}
\textbf{Federated Bandits.}
%A number of recent works have extended the classic $K$-armed bandits to the federated setting. ____ and ____ focused on incorporating privacy guarantees into federated $K$-armed bandits in both centralized and decentralized settings. ____ proposed a setting where the goal is to minimize the regret of a global bandit whose reward of an arm is the average of the rewards of the corresponding arm from all agents, which was later extended by adding personalization such that every agent aims to maximize a weighted combination between the global and local rewards ____. Subsequent works on federated $K$-armed bandits have focused on other important aspects such as decentralized communication via the gossip algorithm____, the security aspect via cryptographic techniques____. Regarding federated linear contextual bandits, ____ proposed a distributed linear contextual bandit algorithm which allows every agent to use the observations from the other agents by only exchanging the sufficient statistics to calculate the Linear UCB policy. Subsequently, ____ extended the method from ____ to consider differential privacy and decentralized communication, ____ considered a setting where every agent is associated with a unique context vector, ____ focused on asynchronous communication. Federated kernelized/GP bandits (also named federated Bayesian optimization) have been explored by ____, which focused on the practical problem of hyperparameter tuning in the federated setting. The recent works of ____ have, respectively, focused on deriving communication-efficient algorithms for federated kernelized and generalized linear bandits. In addition to federated bandits, other similar sequential decision-making problems have also been extended to the federated setting, such as federated neural bandits ____, federated reinforcement learning ____ and federated hyperparameter tuning ____.
Recent studies have extended the classical $K$-armed bandit problem to the federated setting. 
____ introduced privacy-preserving federated $K$-armed bandits in centralized and decentralized settings, respectively. ____ formulated a global bandit model where arm rewards are averaged across agents, which was later extended to incorporate personalization ____. 
% Other works addressed decentralized communication via gossip algorithms ____ and security via cryptographic methods ____. 
For federated linear contextual bandits, ____ proposed a distributed algorithm using sufficient statistics to compute the Linear UCB policy, which was later extended to incorporate differential privacy ____, agent-specific contexts ____, and asynchronous communication ____. 
Federated kernelized 
% and Gaussian process 
and neural bandits have been developed for hyperparameter tuning ____.
% , with recent work improving the communication efficiency of kernelized and generalized linear bandits ____.
In addition, many recent works have extended federated bandits to various settings and applied them to solve real-world problems ____.
% However, to the best of our knowledge, none of these previous works are able to handle preference feedback.

% Beyond bandits, federated extensions exist for neural bandits ____, reinforcement learning ____, and hyperparameter tuning ____.

\textbf{Dueling Bandits.}
%Learning from pairwise or $K$-wise comparisons has been thoroughly explored in the literature. In the context of dueling bandits, the focus is on minimizing regret using preference feedback ____. There are also lots of work such as ____, which they only consider the linear reward function. However, ____ extends to the non-linear reward functions.
% Learning from pairwise or $K$-wise comparisons has been extensively studied. In dueling bandits, the goal is to minimize regret using preference feedback
Thanks to its ability to learn from pairwise preference feedback, dueling bandits have received considerable attention in recent years
____. 
To account for complicated real-world scenarios, a number of contextual dueling bandits have been developed which model the reward function using either a linear function
% Many works focus on the linear reward function 
____ or a neural network ____.
% , while ____ extends this framework to non-linear reward functions.

\vspace{-1.2mm}