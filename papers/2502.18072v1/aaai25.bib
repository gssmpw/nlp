@article{chen2021codesigning,
  title = {Co-Designing Hardware and Control for Robot Hands},
  author = {Chen, Tianjian and He, Zhanpeng and Ciocarlie, Matei},
  year = {2021},
  journal = {Science Robotics},
  volume = {6},
  number = {54},
  pages = {eabg2133},
  doi = {10.1126/scirobotics.abg2133},
  abstract = {Policy gradient methods can be used for mechanical and computational co-design of robot manipulators. Policy gradient methods can be used for mechanical and computational co-design of robot manipulators.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2021codesigning-Co-designing hardware and control for robot hands.pdf}
}

@incollection{ben-ari2018finite,
  title = {Finite {{State Machines}}},
  booktitle = {Elements of {{Robotics}}},
  author = {{Ben-Ari}, Mordechai and Mondada, Francesco},
  year = {2018},
  pages = {55--61},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-62533-1_4},
  abstract = {Robots have embedded computers with memory that can be used to store the current state of an algorithm. Finite state machines specify the conditions under which the state of the robot changes and the actions taken when the state changes. Finite state machines are demonstrated first by Braitenberg vehicles and then by an algorithm that causes the robot to search for an object and then approach it.},
  isbn = {978-3-319-62533-1},
  file = {C:\Users\lenovo\Zotero\storage\2W5FUS4S\Ben-Ari_Mondada_2018_Finite State Machines.pdf}
}

@inproceedings{banerjee2018autonomous,
  title = {Autonomous {{Acquisition}} of {{Behavior Trees}} for {{Robot Control}}},
  booktitle = IROS,
  author = {Banerjee, Bikramjit},
  year = {2018},
  pages = {3460--3467},
  doi = {10.1109/IROS.2018.8594083},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@banerjee2018autonomous-Autonomous Acquisition of Behavior Trees for Robot Control.pdf}
}

@inproceedings{gauci2017error,
  title = {Error {{Cascades}} in {{Collective Behavior}}: {{A Case Study}} of the {{Gradient Algorithm}} on 1000 {{Physical Agents}}},
  booktitle = {Proceedings of the 16th {{Conference}} on {{Autonomous Agents}} and {{MultiAgent Systems}}, {{AAMAS}} 2017, {{S{\~a}o Paulo}}, {{Brazil}}, {{May}} 8-12, 2017},
  author = {Gauci, Melvin and Ortiz, Monica E. and Rubenstein, Michael and Nagpal, Radhika},
  year = {2017},
  pages = {1404--1412},
  publisher = {ACM}
}

@article{rusu2008robots,
  title = {Robots in the Kitchen: {{Exploiting}} Ubiquitous Sensing and Actuation},
  author = {Rusu, Radu Bogdan and Gerkey, Brian and Beetz, Michael},
  year = {2008},
  journal = {Robotics and Autonomous Systems},
  volume = {56},
  number = {10},
  pages = {844--856}
}

@inproceedings{faina2021evolving,
  title = {Evolving {{Modular Robots}}: {{Challenges}} and {{Opportunities}}},
  booktitle = ALIFE,
  author = {Fai{\~n}a, Andres},
  year = {2021},
  publisher = {MIT Press}
}

@inproceedings{veenstra2020how,
  title = {How Different Encodings Affect Performance and Diversification When Evolving the Morphology and Control of {{2D}} Virtual Creatures},
  booktitle = ALIFE,
  author = {Veenstra, Frank and Glette, Kyrre},
  year = {2020},
  pages = {592--601},
  publisher = {MIT Press}
}

@article{cheney2018scalable,
  title = {Scalable Co-Optimization of Morphology and Control in Embodied Machines},
  author = {Cheney, Nick and Bongard, Josh and SunSpiral, Vytas and Lipson, Hod},
  year = {2018},
  journal = {Journal of The Royal Society Interface},
  volume = {15},
  number = {143},
  pages = {20170937},
  publisher = {The Royal Society},
  keywords = {evolution}
}

@article{stanley2007compositional,
  title = {Compositional Pattern Producing Networks: {{A}} Novel Abstraction of Development},
  author = {Stanley, Kenneth O},
  year = {2007},
  journal = {Genetic programming and evolvable machines},
  volume = {8},
  number = {2},
  pages = {131--162},
  publisher = {Springer}
}

@incollection{lindenmayer1992grammars,
  title = {Grammars of Development: Discrete-State Models for Growth, Differentiation, and Gene Expression in Modular Organisms},
  booktitle = {Lindenmayer Systems},
  author = {Lindenmayer, Aristid and J{\"u}rgensen, Hans},
  year = {1992},
  pages = {3--21},
  publisher = {Springer}
}

@inproceedings{marbach2005online,
  title = {Online Optimization of Modular Robot Locomotion},
  booktitle = {{{IEEE International Conference Mechatronics}} and {{Automation}}, 2005},
  author = {Marbach, Daniel and Ijspeert, Auke Jan},
  year = {2005},
  volume = {1},
  pages = {248--253},
  publisher = {IEEE}
}

@inproceedings{velde2019body,
  title = {Body Symmetry in Morphologically Evolving Modular Robots},
  booktitle = {International {{Conference}} on the {{Applications}} of {{Evolutionary Computation}} ({{Part}} of {{EvoStar}})},
  author = {Velde, T and Rossi, Claudio and Eiben, {\relax AE}},
  year = {2019},
  pages = {583--598},
  publisher = {Springer}
}

@inproceedings{bongard2009impact,
  title = {The Impact of Jointly Evolving Robot Morphology and Control on Adaptation Rate},
  booktitle = GECCO,
  author = {Bongard, Josh C},
  year = {2009},
  pages = {1769--1770}
}

@article{hiller2011automatic,
  title = {Automatic Design and Manufacture of Soft Robots},
  author = {Hiller, Jonathan and Lipson, Hod},
  year = {2011},
  journal = {IEEE Transactions on Robotics},
  volume = {28},
  number = {2},
  pages = {457--466},
  publisher = {IEEE}
}

@inproceedings{auerbach2014robogen,
  title = {Robogen: {{Robot}} Generation through Artificial Evolution},
  booktitle = {{{ALIFE}} 14: {{The Fourteenth International Conference}} on the {{Synthesis}} and {{Simulation}} of {{Living Systems}}},
  author = {Auerbach, Joshua and Aydin, Deniz and Maesani, Andrea and Kornatowski, Przemyslaw and Cieslewski, Titus and Heitz, Gr{\'e}goire and Fernando, Pradeep and Loshchilov, Ilya and Daler, Ludovic and Floreano, Dario},
  year = {2014},
  pages = {136--137},
  publisher = {MIT Press}
}

@article{pastor2021genetic,
  title = {Genetic {{Optimization}} of a {{Manipulator}}: {{Comparison}} between {{Straight}}, {{Rounded}}, and {{Curved Mechanism Links}}},
  author = {Pastor, Robert and Bobovsk{\`y}, Zdenko and Huczala, Daniel and Grushko, Stefan},
  year = {2021},
  journal = {Applied Sciences},
  volume = {11},
  number = {6},
  pages = {2471},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@inproceedings{moreno2020using,
  title = {Using Evolution to Design Modular Robots: {{An}} Empirical Approach to Select Module Designs},
  booktitle = {International {{Conference}} on the {{Applications}} of {{Evolutionary Computation}} ({{Part}} of {{EvoStar}})},
  author = {Moreno, Rodrigo and Faina, Andres},
  year = {2020},
  pages = {276--290},
  publisher = {Springer}
}

@inproceedings{liu2017impact,
  title = {The Impact of Module Morphologies on Modular Robots},
  booktitle = {2017 18th {{International Conference}} on {{Advanced Robotics}} ({{ICAR}})},
  author = {Liu, Ceyue and Liu, Jiangong and Moreno, Rodrigo and Veenstra, Frank and Faina, Andres},
  year = {2017},
  pages = {237--243},
  publisher = {IEEE}
}

@article{faina2013edhmor,
  title = {{{EDHMoR}}: {{Evolutionary}} Designer of Heterogeneous Modular Robots},
  author = {Fa{\'i}{\~n}a, Andr{\'e}s and Bellas, Francisco and {L{\'o}pez-Pe{\~n}a}, Fernando and Duro, Richard J},
  year = {2013},
  journal = {Engineering Applications of Artificial Intelligence},
  volume = {26},
  number = {10},
  pages = {2408--2423},
  publisher = {Elsevier}
}

@article{hauser2012role,
  title = {The Role of Feedback in Morphological Computation with Compliant Bodies},
  author = {Hauser, Helmut and Ijspeert, Auke J and F{\"u}chslin, Rudolf M and Pfeifer, Rolf and Maass, Wolfgang},
  year = {2012},
  journal = {Biological cybernetics},
  volume = {106},
  number = {10},
  pages = {595--613},
  publisher = {Springer}
}

@article{hauser2011theoretical,
  title = {Towards a Theoretical Foundation for Morphological Computation with Compliant Bodies},
  author = {Hauser, Helmut and Ijspeert, Auke J and F{\"u}chslin, Rudolf M and Pfeifer, Rolf and Maass, Wolfgang},
  year = {2011},
  journal = {Biological cybernetics},
  volume = {105},
  number = {5},
  pages = {355--370},
  publisher = {Springer}
}

@article{lukosevicius2009reservoir,
  title = {Reservoir Computing Approaches to Recurrent Neural Network Training},
  author = {Luko{\v s}evi{\v c}ius, Mantas and Jaeger, Herbert},
  year = {2009},
  journal = {Computer Science Review},
  volume = {3},
  number = {3},
  pages = {127--149},
  publisher = {Elsevier}
}

@article{floreano2013miniature,
  title = {Miniature Curved Artificial Compound Eyes},
  author = {Floreano, Dario and {Pericet-Camara}, Ramon and Viollet, St{\'e}phane and Ruffier, Franck and Br{\"u}ckner, Andreas and Leitel, Robert and Buss, Wolfgang and Menouni, Mohsine and Expert, Fabien and Juston, Rapha{\"e}l and others},
  year = {2013},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {23},
  pages = {9267--9272},
  publisher = {National Acad Sciences}
}

@article{collins2001threedimensional,
  title = {A Three-Dimensional Passive-Dynamic Walking Robot with Two Legs and Knees},
  author = {Collins, Steven H and Wisse, Martijn and Ruina, Andy},
  year = {2001},
  journal = {The International Journal of Robotics Research},
  volume = {20},
  number = {7},
  pages = {607--615},
  publisher = {SAGE Publications}
}

@article{muller2017what,
  title = {What Is Morphological Computation? {{On}} How the Body Contributes to Cognition and Control},
  author = {M{\"u}ller, Vincent C and Hoffmann, Matej},
  year = {2017},
  journal = {Artificial life},
  volume = {23},
  number = {1},
  pages = {1--24},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info {\dots}}
}

@article{brooks1991intelligence,
  title = {Intelligence without Reason},
  author = {Brooks, Rodney A and others},
  year = {1991},
  journal = {Artificial intelligence: critical concepts},
  volume = {3},
  pages = {107--63}
}

@article{wilson2011embodied,
  title = {Embodied Cognition},
  author = {Wilson, Robert A and Foglia, Lucia},
  year = {2011}
}

@book{shapiro2010embodied,
  title = {Embodied Cognition},
  author = {Shapiro, Lawrence},
  year = {2010},
  publisher = {Routledge}
}

@article{shapiro2014routledge,
  title = {The {{Routledge}} Handbook of Embodied Cognition},
  author = {Shapiro, Lawrence A},
  year = {2014},
  publisher = {Routledge New York}
}

@article{kuniyoshi2019fusing,
  title = {Fusing Autonomy and Sociality via Embodied Emergence and Development of Behaviour and Cognition from Fetal Period},
  author = {Kuniyoshi, Yasuo},
  year = {2019},
  journal = {Philosophical Transactions of the Royal Society B},
  volume = {374},
  number = {1771},
  pages = {20180031},
  publisher = {The Royal Society}
}

@article{weigmann2012does,
  title = {Does Intelligence Require a Body? {{The}} Growing Discipline of Embodied Cognition Suggests That to Understand the World, We Must Experience the World},
  author = {Weigmann, Katrin},
  year = {2012},
  journal = {EMBO reports},
  volume = {13},
  number = {12},
  pages = {1066--1069},
  publisher = {John Wiley \& Sons, Ltd Chichester, UK}
}

@inproceedings{lee2011intrinsic,
  title = {Intrinsic Activitity: From Motor Babbling to Play},
  booktitle = {{{IEEE International Conference}} on {{Development}} and {{Learning}} ({{ICDL}})},
  author = {Lee, Mark H},
  year = {2011},
  volume = {2},
  pages = {1--6},
  publisher = {IEEE}
}

@article{sternberg1997concept,
  title = {The Concept of Intelligence and Its Role in Lifelong Learning and Success.},
  author = {Sternberg, Robert J},
  year = {1997},
  journal = {American psychologist},
  volume = {52},
  number = {10},
  pages = {1030},
  publisher = {American Psychological Association}
}

@inproceedings{colledanchise2019blended,
  title = {Towards {{Blended Reactive Planning}} and {{Acting}} Using {{Behavior Trees}}},
  booktitle = ICRA,
  author = {Colledanchise, Michele and Almeida, Diogo and Ogren, Petter},
  year = {2019},
  month = may,
  pages = {8839--8845},
  publisher = {IEEE},
  address = {Montreal, QC, Canada},
  doi = {10.1109/ICRA.2019.8794128},
  urldate = {2022-05-22},
  abstract = {In this paper, we show how a planning algorithm can be used to automatically create and update a Behavior Tree (BT), controlling a robot in a dynamic environment. The planning part of the algorithm is based on the idea of back chaining. Starting from a goal condition we iteratively select actions to achieve that goal, and if those actions have unmet preconditions, they are extended with actions to achieve them in the same way. The fact that BTs are inherently modular and reactive makes the proposed solution blend acting and planning in a way that enables the robot to effectively react to external disturbances. If an external agent undoes an action the robot reexecutes it without re-planning, and if an external agent helps the robot, it skips the corresponding actions, again without replanning. We illustrate our approach in two different robotics scenarios.},
  isbn = {978-1-5386-6027-0},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2019blended-Towards Blended Reactive Planning and Acting using Behavior Trees.pdf}
}

@article{nunemacher2002where,
  title = {Where {{Mathematics Comes From}}: {{How}} the {{Embodied Mind Brings Mathematics}} into {{Being}}},
  shorttitle = {Where {{Mathematics Comes From}}},
  author = {Nunemacher, Jeffrey and Lakoff, George and Nunez, Rafael},
  year = {2002},
  month = aug,
  journal = {The American Mathematical Monthly},
  volume = {109},
  number = {7},
  eprint = {3072449},
  eprinttype = {jstor},
  pages = {672},
  issn = {00029890},
  doi = {10.2307/3072449},
  urldate = {2022-05-23},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@nunemacher2002where-Where Mathematics Comes From - How the Embodied Mind Brings Mathematics into.pdf}
}

@book{carroll2013dna,
  title = {From {{DNA}} to Diversity: Molecular Genetics and the Evolution of Animal Design},
  author = {Carroll, Sean B and Grenier, Jennifer K and Weatherbee, Scott D},
  year = {2013},
  publisher = {John Wiley \& Sons}
}

@book{darwin1859origin,
  title = {On the Origin of Species by Means of Natural Selection},
  author = {Darwin, Charles},
  year = {1859},
  publisher = {John Murray},
  address = {London}
}

@article{russellprinciples,
  title = {The {{Principles}} of {{Mathematics}}},
  author = {Russell, Bertrand},
  journal = {Bertrand Russell},
  pages = {832},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@russellprinciples-The Principles of Mathematics.pdf}
}

@book{reflections,
  title = {Reflections on the {{Foundations}} of {{Mathematics}}}
}

@inproceedings{neupane2018geese,
  title = {{{GEESE}}: Grammatical Evolution Algorithm for Evolution of Swarm Behaviors},
  booktitle = GECCO,
  author = {Neupane, Aadesh and Goodrich, Michael A and Mercer, Eric G},
  year = {2018},
  pages = {999--1006},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@neupane2018geese-GEESE - grammatical evolution algorithm for evolution of swarm behaviors.pdf}
}

@article{wang2019redmax,
  title = {{{RedMax}}: Efficient \& Flexible Approach for Articulated Dynamics},
  shorttitle = {{{RedMax}}},
  author = {Wang, Ying and Weidner, Nicholas J. and Baxter, Margaret A. and Hwang, Yura and Kaufman, Danny M. and Sueda, Shinjiro},
  year = {2019},
  month = aug,
  journal = TOG,
  volume = {38},
  number = {4},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3306346.3322952},
  urldate = {2022-05-11},
  abstract = {It is well known that the dynamics of articulated rigid bodies can be solved in O (n) time using a recursive method, where n is the number of joints. However, when elasticity is added between the bodies (e.g., damped springs), with linearly implicit integration, the sti{\dbend}ness matrix in the equations of motion breaks the tree topology of the system, making the recursive O (n) method inapplicable. In such cases, the only alternative has been to form and solve the system matrix, which takes O (n3) time. We propose a new approach that is capable of solving the linearly implicit equations of motion in near linear time. Our method, which we call R{\dbend}{\dbend}M{\dbend}{\dbend}, is built using a combined reduced/maximal coordinate formulation. This hybrid model enables direct {\dbend}exibility to apply arbitrary combinations of constraints and contact modeling in both reduced and maximal coordinates, as well as mixtures of implicit and explicit forces in either coordinate representation. We highlight R{\dbend}{\dbend}M{\dbend}{\dbend}'s {\dbend}exibility with seamless integration of deformable objects with two-way coupling, at a standard additional cost. We further highlight its {\dbend}exibility by constructing an e{\dbend}cient internal (joint) and external (environment) frictional contact solver that can leverage bilateral joint constraints for rapid evaluation of frictional articulated dynamics. CCS Concepts: {$\bullet$} Computing methodologies {$\rightarrow$} Physical simulation.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2019redmax-RedMax - efficient & flexible approach for articulated dynamics.pdf}
}

@inproceedings{suarez2021neural,
  title = {The {{Neural MMO Platform}} for {{Massively Multiagent Research}}},
  booktitle = NeurIPS,
  author = {Suarez, Joseph and Du, Yilun and Zhu, Clare and Mordatch, Igor and Isola, Phillip},
  year = {2021},
  pages = {14},
  abstract = {Neural MMO is a computationally accessible research platform that combines large agent populations, long time horizons, open-ended tasks, and modular game systems. Existing environments feature subsets of these properties, but Neural MMO is the first to combine them all. We present Neural MMO as free and open source software with active support, ongoing development, documentation, and additional training, logging, and visualization tools to help users adapt to this new setting. Initial baselines on the platform demonstrate that agents trained in large populations explore more and learn a progression of skills. We raise other more difficult problems such as many-team cooperation as open research questions which Neural MMO is well-suited to answer. Finally, we discuss current limitations of the platform, potential mitigations, and plans for continued development.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\2TRYA7Y6\Suarez_2021_The Neural MMO Platform for Massively Multiagent Research.pdf}
}

@inproceedings{scheide2021behavior,
  title = {Behavior {{Tree Learning}} for {{Robotic Task Planning}} through {{Monte Carlo DAG Search}} over a {{Formal Grammar}}},
  booktitle = ICRA,
  author = {Scheide, Emily and Best, Graeme and Hollinger, Geoffrey A.},
  year = {2021},
  month = may,
  pages = {4837--4843},
  publisher = {IEEE},
  address = {Xi'an, China},
  doi = {10.1109/ICRA48506.2021.9561027},
  urldate = {2022-03-03},
  abstract = {We present an algorithm for learning behavior trees for robotic task planning, which alleviates the need for time-intensive or infeasible manual design of control architectures. Our method involves representing the search space of behavior trees as a formal grammar and searching over this grammar by means of a new generalization of Monte Carlo tree search (MCTS) for directed acyclic graphs (DAGs), named MCDAGS. Additionally, our method employs simulated annealing to expedite the aggregation of the most functional subtrees. We present simulated experiments for a marine target search and response scenario, and an abstract task selection problem. Our results demonstrate that the learned behavior trees compare favorably with a manually-designed tree, and outperform baseline learning methods. Overall, these results show that our method is a viable technique for the automatic design of behavior trees for robotic task planning.},
  isbn = {978-1-72819-077-8},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@scheide2021behavior-Behavior Tree Learning for Robotic Task Planning through Monte Carlo DAG Search.pdf}
}

@article{peng2019advantageweighted,
  title = {Advantage-{{Weighted Regression}}: {{Simple}} and {{Scalable Off-Policy Reinforcement Learning}}},
  author = {Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  year = {2019},
  journal = {arXiv},
  pages = {18},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2019advantageweighted-Advantage-Weighted Regression - Simple and Scalable Off-Policy Reinforcement.pdf}
}

@inproceedings{peng2019mcp,
  title = {{{MCP}}: {{Learning Composable Hierarchical Control}} with {{Multiplicative Compositional Policies}}},
  booktitle = NeurIPS,
  author = {Peng, Xue Bin and Chang, Michael and Zhang, Grace and Abbeel, Pieter and Levine, Sergey},
  year = {2019},
  pages = {21},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2019mcp-MCP - Learning Composable Hierarchical Control with Multiplicative Compositional.pdf}
}

@inproceedings{neuman2021robomorphic,
  title = {Robomorphic Computing: A Design Methodology for Domain-Specific Accelerators Parameterized by Robot Morphology},
  shorttitle = {Robomorphic Computing},
  booktitle = {Proceedings of the {{ACM International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}} ({{ASPLOS}})},
  author = {Neuman, Sabrina M. and Plancher, Brian and Bourgeat, Thomas and Tambe, Thierry and Devadas, Srinivas and Reddi, Vijay Janapa},
  year = {2021},
  month = apr,
  pages = {674--686},
  publisher = {ACM},
  address = {Virtual USA},
  doi = {10.1145/3445814.3446746},
  urldate = {2022-02-18},
  abstract = {Robotics applications have hard time constraints and heavy computational burdens that can greatly benefit from domain-specific hardware accelerators. For the latency-critical problem of robot motion planning and control, there exists a performance gap of at least an order of magnitude between joint actuator response rates and state-of-the-art software solutions. Hardware acceleration can close this gap, but it is essential to define automated hardware design flows to keep the design process agile as applications and robot platforms evolve. To address this challenge, we introduce robomorphic computing: a methodology to transform robot morphology into a customized hardware accelerator morphology. We (i) present this design methodology, using robot topology and structure to exploit parallelism and matrix sparsity patterns in accelerator hardware; (ii) use the methodology to generate a parameterized accelerator design for the gradient of rigid body dynamics, a key kernel in motion planning; (iii) evaluate FPGA and synthesized ASIC implementations of this accelerator for an industrial manipulator robot; and (iv) describe how the design can be automatically customized for other robot models. Our FPGA accelerator achieves speedups of 8{\texttimes} and 86{\texttimes} over CPU and GPU when executing a single dynamics gradient computation. It maintains speedups of 1.9{\texttimes} to 2.9{\texttimes} over CPU and GPU, including computation and I/O round-trip latency, when deployed as a coprocessor to a host CPU for processing multiple dynamics gradient computations. ASIC synthesis indicates an additional 7.2{\texttimes} speedup for single computation latency. We describe how this principled approach generalizes to more complex robot platforms, such as quadrupeds and humanoids, as well as to other computational kernels in robotics, outlining a path forward for future robomorphic computing accelerators.},
  isbn = {978-1-4503-8317-2},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\29AUS7K9\Neuman_2021_Robomorphic computing.pdf}
}

@article{lan2020semionline,
  title = {Semi-Online {{Multi-people Tracking}} by {{Re-identification}}},
  author = {Lan, Long and Wang, Xinchao and Hua, Gang and Huang, Thomas S. and Tao, Dacheng},
  year = {2020},
  journal = {IJCV},
  volume = {128},
  number = {7},
  pages = {1937--1955},
  doi = {10.1007/s11263-020-01314-1}
}

@article{jin2020embodied,
  title = {Embodied Intelligence Weaves a Better Future},
  author = {Jin, Dongdong and Zhang, Li},
  year = {2020},
  month = nov,
  journal = NMI,
  volume = {2},
  number = {11},
  pages = {663--664},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-00250-6},
  abstract = {Microrobots can interact intelligently with their environment and complete specific tasks by well-designed incorporation of responsive materials. Recent work demonstrates how swarms of microbots with specifically tuned surface chemistry can remove a hormone pollutant from a solution by coalescing it into a web.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jin2020embodied-Embodied intelligence weaves a better future.pdf}
}

@article{hu2020decentralized,
  title = {Decentralized Runtime Enforcement for Robotic Swarms},
  author = {Hu, C. and Dong, W. and Yang, Y. H. and Shi, H. and Deng, F.},
  year = {2020},
  journal = {Frontiers of Information Technology \& Electronic Engineering},
  volume = {21},
  number = {11},
  pages = {16}
}

@article{hart2021artificial,
  title = {Artificial Evolution of Robot Bodies and Control: On the Interaction between Evolution, Individual and Cultural Learning},
  author = {Hart, Emma and Goff, L{\'e}ni K Le},
  year = {2021},
  journal = {Phil. Trans. Roy. Soc. B},
  pages = {13},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hart2021artificial-Artificial evolution of robot bodies and control - on the interaction between.pdf}
}

@article{goyal2021neural,
  title = {Neural Production Systems},
  author = {Goyal, A. and Didolkar, A. and Ke, N. R. and Blundell, C. and Bengio, Y.},
  year = {2021},
  journal = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@goyal2021neural-Neural production systems.pdf}
}

@incollection{floreano2008evolutionary,
  title = {Evolutionary Robotics},
  booktitle = {Evolutionary {{Intelligence}}},
  author = {Floreano, Dario and Husbands, Phil and Nolfi, Stefano},
  year = {2008},
  publisher = {Springer Verlag},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@floreano2008evolutionary-Evolutionary robotics.pdf}
}

@article{elsken2021neural,
  title = {Neural {{Architecture Search}}: {{A Survey}}},
  author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  year = {2021},
  journal = {arXiv},
  pages = {21},
  abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and errorprone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@elsken2021neural-Neural Architecture Search - A Survey.pdf}
}

@article{saberifar2020hardness,
  title = {The {{Hardness}} of {{Minimizing Design Cost Subject}} to {{Planning Problems}}},
  author = {Saberifar, Fatemeh Zahra and O'Kane, Jason M. and Shell, Dylan A.},
  editor = {Morales, Marco and Tapia, Lydia and {S{\'a}nchez-Ante}, Gildardo and Hutchinson, Seth},
  year = {2020},
  journal = WAFR,
  volume = {14},
  pages = {868--883},
  doi = {10.1007/978-3-030-44051-0_50},
  urldate = {2022-03-03},
  abstract = {Assuming one wants to design the most cost-effective robot for some task, how difficult is it to choose the robot's actuators? This paper addresses that question in algorithmic terms, considering the problem of identifying optimal sets of actuation capabilities to allow a robot to complete a given task. We consider various cost functions which model the cost needed to equip a robot with some capabilities, and show that the general form of this problem is NP-hard, confirming what many perhaps have suspected about this sort of design-time optimization. As a result, several questions of interest having both optimality and efficiency of solution is unlikely. However, we also show that, for some specific types of cost functions, the problem is either polynomial time solvable or fixed-parameter tractable.},
  langid = {english},
  keywords = {embodied intelligence,modularity},
  annotation = {WAFR},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@saberifar2020hardness-The Hardness of Minimizing Design Cost Subject to Planning Problems.pdf}
}

@article{zhang2018modeadaptive,
  title = {Mode-Adaptive Neural Networks for Quadruped Motion Control},
  author = {Zhang, He and Starke, Sebastian and Komura, Taku and Saito, Jun},
  year = {2018},
  month = aug,
  journal = TOG,
  volume = {37},
  number = {4},
  pages = {1--11},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3197517.3201366},
  urldate = {2022-02-28},
  langid = {english},
  keywords = {neural network},
  annotation = {TOG},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2018modeadaptive-Mode-adaptive neural networks for quadruped motion control.pdf}
}

@article{starke2019neural,
  title = {Neural State Machine for Character-Scene Interactions},
  author = {Starke, Sebastian and Zhang, He and Komura, Taku and Saito, Jun},
  year = {2019},
  month = dec,
  journal = TOG,
  volume = {38},
  number = {6},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3355089.3356505},
  urldate = {2022-02-28},
  abstract = {We propose               Neural State Machine               , a novel data-driven framework to guide characters to achieve goal-driven actions with precise scene interactions. Even a seemingly simple task such as sitting on a chair is notoriously hard to model with supervised learning. This difficulty is because such a task involves complex planning with periodic and non-periodic motions reacting to the scene geometry to precisely position and orient the character. Our proposed deep auto-regressive framework enables modeling of multi-modal scene interaction behaviors purely from data. Given high-level instructions such as the goal location and the action to be launched there, our system computes a series of movements and transitions to reach the goal in the desired state. To allow characters to adapt to a wide range of geometry such as different shapes of furniture and obstacles, we incorporate an efficient data augmentation scheme to randomly switch the 3D geometry while maintaining the context of the original motion. To increase the precision to reach the goal during runtime, we introduce a control scheme that combines egocentric inference and goal-centric inference. We demonstrate the versatility of our model with various scene interaction tasks such as sitting on a chair, avoiding obstacles, opening and entering through a door, and picking and carrying objects generated in real-time just from a single model.},
  langid = {english},
  keywords = {neural network},
  annotation = {TOG},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@starke2019neural-Neural state machine for character-scene interactions.pdf}
}

@article{peng2018sfv,
  title = {{{SFV}}: Reinforcement Learning of Physical Skills from Videos},
  shorttitle = {{{SFV}}},
  author = {Peng, Xue Bin and Kanazawa, Angjoo and Malik, Jitendra and Abbeel, Pieter and Levine, Sergey},
  year = {2018},
  month = dec,
  journal = TOG,
  volume = {37},
  number = {6},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3272127.3275014},
  urldate = {2022-02-28},
  abstract = {Data-driven character animation based on motion capture can produce highly naturalistic behaviors and, when combined with physics simulation, can provide for natural procedural responses to physical perturbations, environmental changes, and morphological discrepancies. Motion capture remains the most popular source of motion data, but collecting mocap data typically requires heavily instrumented environments and actors. In this paper, we propose a method that enables physically simulated characters to learn skills from videos (SFV). Our approach, based on deep pose estimation and deep reinforcement learning, allows data-driven animation to leverage the abundance of publicly available video clips from the web, such as those from YouTube. This has the potential to enable fast and easy design of character controllers simply by querying for video recordings of the desired behavior. The resulting controllers are robust to perturbations, can be adapted to new settings, can perform basic object interactions, and can be retargeted to new morphologies via reinforcement learning. We further demonstrate that our method can predict potential human motions from still images, by forward simulation of learned controllers initialized from the observed pose. Our framework is able to learn a broad range of dynamic skills, including locomotion, acrobatics, and martial arts. (Video               1               )},
  langid = {english},
  annotation = {TOG},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2018sfv-SFV - reinforcement learning of physical skills from videos.pdf}
}

@article{ling2020character,
  title = {Character Controllers Using Motion {{VAEs}}},
  author = {Ling, Hung Yu and Zinno, Fabio and Cheng, George and Van De Panne, Michiel},
  year = {2020},
  month = aug,
  journal = TOG,
  volume = {39},
  number = {4},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3386569.3392422},
  urldate = {2022-02-28},
  abstract = {A fundamental problem in computer animation is that of realizing purposeful and realistic human movement given a sufficiently-rich set of motion capture clips. We learn data-driven generative models of human movement using autoregressive conditional variational autoencoders, or Motion VAEs. The latent variables of the learned autoencoder define the action space for the movement and thereby govern its evolution over time. Planning or control algorithms can then use this action space to generate desired motions. In particular, we use deep reinforcement learning to learn controllers that achieve goal-directed movements. We demonstrate the effectiveness of the approach on multiple tasks. We further evaluate system-design choices and describe the current limitations of Motion VAEs. CCS Concepts: {$\bullet$} Computing methodologies {$\rightarrow$} Motion capture; Reinforcement learning.},
  langid = {english},
  keywords = {neural network},
  annotation = {TOG},
  file = {C:\Users\lenovo\Zotero\storage\2J4IRPFU\Ling_2020_Character controllers using motion VAEs.pdf}
}

@article{holden2017phasefunctioned,
  title = {Phase-Functioned Neural Networks for Character Control},
  author = {Holden, Daniel and Komura, Taku and Saito, Jun},
  year = {2017},
  month = jul,
  journal = TOG,
  volume = {36},
  number = {4},
  pages = {1--13},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3072959.3073663},
  urldate = {2022-02-28},
  langid = {english},
  keywords = {neural network},
  annotation = {TOG},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@holden2017phasefunctioned-Phase-functioned neural networks for character control.pdf}
}

@article{zhang2021data,
  title = {{{DATA}}: {{Differentiable ArchiTecture Approximation With Distribution Guided Sampling}}.},
  author = {Zhang, Xinbang and Chang, Jianlong and Guo, Yiwen and Meng, Gaofeng and Xiang, Shiming and Lin, Zhouchen and Pan, Chunhong},
  year = {2021},
  month = sep,
  journal = TPAMI,
  volume = {43},
  number = {9},
  pages = {2905--2920},
  address = {United States},
  issn = {1939-3539 0098-5589},
  doi = {10.1109/TPAMI.2020.3020315},
  langid = {english},
  pmid = {32866094},
  keywords = {differentiable},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\4NA3T429\\Zhang_2021_DATA.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\N9QYCCEJ\\2021 - TPAMI - DATA.pptx}
}

@inproceedings{2021speedy,
  title = {Speedy {{Performance Estimation}} for {{Neural Architecture Search}}},
  booktitle = NeurIPS,
  year = {2021},
  keywords = {traning trajectory},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@2021speedy-Speedy Performance Estimation for Neural Architecture Search.pdf}
}

@inproceedings{white2021how,
  title = {How Powerful Are Performance Predictors in Neural Architecture Search?},
  booktitle = NeurIPS,
  author = {White, Colin and Zela, Arber and Ru, Binxin and Liu, Yang and Hutter, Frank},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {understanding},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@white2021how-How powerful are performance predictors in neural architecture search.pdf}
}

@inproceedings{tamar2016value,
  title = {Value {{Iteration Networks}}},
  booktitle = NeurIPS,
  author = {Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
  year = {2016},
  urldate = {2022-04-19},
  abstract = {We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.},
  langid = {english},
  annotation = {NeurIPS}
}

@inproceedings{puri2021cofrnets,
  title = {{{CoFrNets}}: {{Interpretable}} Neural Architecture Inspired by Continued Fractions},
  booktitle = NeurIPS,
  author = {Puri, Isha and Dhurandhar, Amit and Pedapati, Tejaswini and Shanmugam, Karthikeyan and Wei, Dennis and Varshney, Kush R.},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {architecture},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@puri2021cofrnets-CoFrNets - Interpretable neural architecture inspired by continued fractions.pdf}
}

@inproceedings{ning2021evaluating,
  title = {Evaluating Efficient Performance Estimators of Neural Architecture},
  booktitle = NeurIPS,
  author = {Ning, Xuefei and Tang, Changcheng and Li, Wenshuo and Zhou, Zixuan and Liang, Shuang and Yang, Huazhong and Wang, Yu},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {one-shot,understanding,zero-shot},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ning2021evaluating-Evaluating efficient performance estimators of neural architecture.pdf}
}

@inproceedings{luo2018neural,
  title = {Neural {{Architecture Optimization}}},
  booktitle = NeurIPS,
  author = {Luo, Renqian and Tian, Fei and Qin, Tao and Chen, Enhong and Liu, Tie-Yan},
  year = {2018},
  pages = {12},
  abstract = {Automatic neural architecture design has shown its potential in discovering powerful neural network architectures. Existing methods, no matter based on reinforcement learning or evolutionary algorithms (EA), conduct architecture search in a discrete space, which is highly inefficient. In this paper, we propose a simple and efficient method to automatic neural architecture design based on continuous optimization. We call this new approach neural architecture optimization (NAO). There are three key components in our proposed approach: (1) An encoder embeds/maps neural network architectures into a continuous space. (2) A predictor takes the continuous representation of a network as input and predicts its accuracy. (3) A decoder maps a continuous representation of a network back to its architecture. The performance predictor and the encoder enable us to perform gradient based optimization in the continuous space to find the embedding of a new architecture with potentially better accuracy. Such a better embedding is then decoded to a network by the decoder. Experiments show that the architecture discovered by our method is very competitive for image classification task on CIFAR-10 and language modeling task on PTB, outperforming or on par with the best results of previous architecture search methods with a significantly reduction of computational resources. Specifically we obtain 2.11\% test set error rate for CIFAR-10 image classification task and 56.0 test set perplexity of PTB language modeling task. The best discovered architectures on both tasks are successfully transferred to other tasks such as CIFAR-100 and WikiText-2. Furthermore, combined with the recent proposed weight sharing mechanism, we discover powerful architecture on CIFAR-10 (with error rate 3.53\%) and on PTB (with test set perplexity 56.6), with very limited computational resources (less than 10 GPU hours) for both tasks.},
  langid = {english},
  keywords = {differentiable,embedding,gradient},
  annotation = {NeurIPS},
  file = {C:\Users\lenovo\Zotero\storage\2UCSCKT7\Luo_2018_Neural Architecture Optimization.pdf}
}

@inproceedings{li2021generic,
  title = {Generic Neural Architecture Search via Regression},
  booktitle = NeurIPS,
  author = {Li, Yuhong and Hao, Cong and Li, Pan and Xiong, Jinjun and Chen, Deming},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {regression},
  annotation = {NeurIPS},
  file = {D:\Cloud\BaiduSyncdisk\CXL_Big\SoftwareData\zotfile\NeurIPS2021_Generic neural architecture search via regression @li2021GenericNeuralArchitecture.pdf}
}

@inproceedings{li2021neural,
  title = {Neural Architecture Dilation for Adversarial Robustness},
  booktitle = NeurIPS,
  author = {Li, Yanxi and Yang, Zhaohui and Wang, Yunhe and Xu, Chang},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {adversarial},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2021neural-Neural architecture dilation for adversarial robustness.pdf}
}

@inproceedings{brown2020language,
  title = {Language Models Are Few-Shot Learners},
  booktitle = NeurIPS,
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  editor = {Larochelle, Hugo and Ranzato, Marc'Aurelio and Hadsell, Raia and Balcan, Maria-Florina and Lin, Hsuan-Tien},
  year = {2020},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@brown2020language-Language models are few-shot learners.pdf}
}

@article{goyal2018graph,
  title = {Graph Embedding Techniques, Applications, and Performance: {{A}} Survey},
  author = {Goyal, Palash and Ferrara, Emilio},
  year = {2018},
  journal = KBS,
  volume = {151},
  pages = {78--94},
  issn = {0950-7051},
  doi = {10.1016/j.knosys.2018.03.022},
  abstract = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and different patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We first introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We finally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a unified interface to foster and facilitate research on the topic.},
  keywords = {graph embedding},
  annotation = {KBS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@goyal2018graph-Graph embedding techniques, applications, and performance - A survey.pdf}
}

@article{shervashidze2011weisfeilerlehman,
  title = {Weisfeiler-Lehman Graph Kernels},
  author = {Shervashidze, Nino and Schweitzer, Pascal and {van Leeuwen}, Erik Jan and Mehlhorn, Kurt and Borgwardt, Karsten M.},
  year = {2011},
  journal = JMLR,
  volume = {12},
  pages = {2539--2561},
  annotation = {JMLR},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@shervashidze2011weisfeilerlehman-Weisfeiler-lehman graph kernels.pdf}
}

@article{kroemer2021review,
  title = {A Review of Robot Learning for Manipulation: {{Challenges}}, Representations, and Algorithms},
  author = {Kroemer, Oliver and Niekum, Scott and Konidaris, George},
  year = {2021},
  journal = JMLR,
  volume = {22},
  number = {30},
  pages = {1--82},
  keywords = {learning},
  annotation = {JMLR},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kroemer2021review-A review of robot learning for manipulation - Challenges, representations, and.pdf}
}

@inproceedings{li2019integrating,
  title = {Integrating {{Decision Sharing}} with {{Prediction}} in {{Decentralized Planning}} for {{Multi-Agent Coordination}} under {{Uncertainty}}},
  booktitle = IJCAI,
  author = {Li, Minglong and Yang, Wenjing and Cai, Zhongxuan and Yang, Shaowu and Wang, Ji},
  year = {2019},
  month = aug,
  pages = {450--456},
  publisher = {IJCAI Organization},
  address = {Macao, China},
  doi = {10.24963/ijcai.2019/64},
  urldate = {2022-02-28},
  isbn = {978-0-9992411-4-1},
  langid = {english},
  keywords = {team paper},
  annotation = {IJCAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2019integrating-Integrating Decision Sharing with Prediction in Decentralized Planning for.pdf}
}

@inproceedings{gao2020graph,
  title = {Graph {{Neural Architecture Search}}},
  booktitle = IJCAI,
  author = {Gao, Yang and Yang, Hong and Zhang, Peng and Zhou, Chuan and Hu, Yue},
  year = {2020},
  month = jul,
  pages = {1403--1409},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  address = {Yokohama, Japan},
  doi = {10.24963/ijcai.2020/195},
  urldate = {2022-04-11},
  abstract = {Graph neural networks (GNNs) emerged recently as a powerful tool for analyzing non-Euclidean data such as social network data. Despite their success, the design of graph neural networks requires heavy manual work and domain knowledge. In this paper, we present a graph neural architecture search method (GraphNAS) that enables automatic design of the best graph neural architecture based on reinforcement learning. Specifically, GraphNAS uses a recurrent network to generate variable-length strings that describe the architectures of graph neural networks, and trains the recurrent network with policy gradient to maximize the expected accuracy of the generated architectures on a validation data set. Furthermore, to improve the search efficiency of GraphNAS on big networks, GraphNAS restricts the search space from an entire architecture space to a sequential concatenation of the best search results built on each single architecture layer. Experiments on real-world datasets demonstrate that GraphNAS can design a novel network architecture that rivals the best human-invented architecture in terms of validation set accuracy. Moreover, in a transfer learning task we observe that graph neural architectures designed by GraphNAS, when transferred to new datasets, still gain improvement in terms of prediction accuracy.},
  isbn = {978-0-9992411-6-5},
  langid = {english},
  keywords = {graph},
  annotation = {IJCAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2020graph-Graph Neural Architecture Search.pdf}
}

@inproceedings{rosser2020sim2real,
  title = {Sim2real Gap Is Non-Monotonic with Robot Complexity for Morphology-in-the-Loop Flapping Wing Design},
  booktitle = ICRA,
  author = {Rosser, Kent and Kok, Jia and Chahl, Javaan and Bongard, Josh},
  year = {2020},
  month = may,
  pages = {7001--7007},
  publisher = {IEEE},
  address = {Paris, France},
  doi = {10.1109/ICRA40945.2020.9196539},
  urldate = {2022-02-18},
  abstract = {Morphology of a robot design is important to its ability to achieve a stated goal and therefore applying machine learning approaches that incorporate morphology in the design space can provide scope for significant advantage. Our study is set in a domain known to be reliant on morphology: flapping wing flight. We developed a parameterised morphology design space that draws features from biological exemplars and apply automated design to produce a set of high performance robot morphologies in simulation. By performing sim2real transfer on a selection, for the first time we measured the shape of the reality gap for variations in design complexity. We found for the flapping wing that the reality gap changes non-monotonically with complexity, suggesting that certain morphology details narrow the gap more than others, and that such details could be identified and further optimised in a future end-to-end automated morphology design process.},
  isbn = {978-1-72817-395-5},
  langid = {english},
  keywords = {embodied intelligence},
  annotation = {ICRA},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@rosser2020sim2real-Sim2real gap is non-monotonic with robot complexity for morphology-in-the-loop.pdf}
}

@inproceedings{nair2015massively,
  title = {Massively {{Parallel Methods}} for {{Deep Reinforcement Learning}}},
  booktitle = ICML,
  author = {Nair, Arun and Srinivasan, Praveen and Blackwell, Sam and Alcicek, Cagdas and Fearon, Rory and De Maria, Alessandro and Panneershelvam, Vedavyas and Suleyman, Mustafa and Beattie, Charles and Petersen, Stig and Legg, Shane and Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David},
  year = {2015},
  month = jul,
  series = {Deep {{Learning Workshop}}},
  urldate = {2022-04-18},
  abstract = {We present the first massively distributed architecture for deep reinforcement learning. This architecture uses four main components: parallel actors that generate new behaviour; parallel learners that are trained from stored experience; a distributed neural network to represent the value function or behaviour policy; and a distributed store of experience. We used our architecture to implement the Deep Q-Network algorithm (DQN) (Mnih et al., 2013). Our distributed algorithm was applied to 49 games from Atari 2600 games from the Arcade Learning Environment, using identical hyperparameters. Our performance surpassed non-distributed DQN in 41 of the 49 games and also reduced the wall-time required to achieve these results by an order of magnitude on most games.},
  langid = {english},
  annotation = {ICML Workshop},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@nair2015massively-Massively Parallel Methods for Deep Reinforcement Learning.pdf}
}

@inproceedings{lee2018gated,
  title = {Gated {{Path Planning Networks}}},
  booktitle = ICLR,
  author = {Lee, Lisa and Parisotto, Emilio and Chaplot, Devendra Singh and Xing, Eric and Salakhutdinov, Ruslan},
  year = {2018},
  month = jun,
  urldate = {2022-04-19},
  abstract = {Value Iteration Networks (VINs) are effective differentiable path planning modules that can be used by agents to perform navigation while still maintaining end-to-end differentiability of the entire architecture. Despite their effectiveness, they suffer from several disadvantages including training instability, random seed sensitivity, and other optimization problems. In this work, we reframe VINs as recurrent-convolutional networks which demonstrates that VINs couple recurrent convolutions with an unconventional max-pooling activation. From this perspective, we argue that standard gated recurrent update equations could potentially alleviate the optimization issues plaguing VIN. The resulting architecture, which we call the Gated Path Planning Network, is shown to empirically outperform VIN on a variety of metrics such as learning speed, hyperparameter sensitivity, iteration count, and even generalization. Furthermore, we show that this performance gap is consistent across different maze transition types, maze sizes and even show success on a challenging 3D environment, where the planner is only provided with first-person RGB images.},
  langid = {english},
  annotation = {ICML},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lee2018gated-Gated Path Planning Networks.pdf}
}

@inproceedings{yang2021delving,
  title = {Delving into {{Deep Imbalanced Regression}}},
  booktitle = ICLR,
  author = {Yang, Yuzhe and Zha, Kaiwen and Chen, Ying-Cong and Wang, Hao and Katabi, Dina},
  year = {2021},
  month = may,
  urldate = {2022-04-05},
  abstract = {Real-world data often exhibit imbalanced distributions, where certain target values have significantly fewer observations. Existing techniques for dealing with imbalanced data focus on targets with categorical indices, i.e., different classes. However, many tasks involve continuous targets, where hard boundaries between classes do not exist. We define Deep Imbalanced Regression (DIR) as learning from such imbalanced data with continuous targets, dealing with potential missing data for certain target values, and generalizing to the entire target range. Motivated by the intrinsic difference between categorical and continuous label space, we propose distribution smoothing for both labels and features, which explicitly acknowledges the effects of nearby targets, and calibrates both label and learned feature distributions. We curate and benchmark large-scale DIR datasets from common real-world tasks in computer vision, natural language processing, and healthcare domains. Extensive experiments verify the superior performance of our strategies. Our work fills the gap in benchmarks and techniques for practical imbalanced regression problems. Code and data are available at: https://github.com/ YyzHarry/imbalanced-regression.},
  langid = {english},
  keywords = {inbalanced,neural network},
  annotation = {ICML},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2021delving-Delving into Deep Imbalanced Regression.pdf}
}

@inproceedings{2020understanding,
  title = {Understanding {{Architectures Learnt}} by {{Cell-based Neural Architecture Search}}},
  booktitle = ICLR,
  year = {2020},
  keywords = {cell-based,understanding},
  annotation = {ICLR},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\UK7VS8VJ\\2020 - ICLR - Understanding Architectures Learnt by Cell-based Neural Architecture Search.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@2020understanding-Understanding Architectures Learnt by Cell-based Neural Architecture Search.pdf}
}

@inproceedings{zoph2017neural,
  title = {Neural Architecture Search with Reinforcement Learning},
  booktitle = ICLR,
  author = {Zoph, Barret and Le, Quoc V},
  year = {2017},
  pages = {16},
  abstract = {Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214.},
  langid = {english},
  keywords = {reinforcement learning},
  annotation = {ICLR},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\MJ4IFN2C\\2017 - ICLR - Neural architecture search with reinforcement learning.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@zoph2017neural-Neural architecture search with reinforcement learning.pdf}
}

@inproceedings{xu2019how,
  title = {How Powerful Are Graph Neural Networks?},
  booktitle = ICLR,
  author = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  year = {2019},
  publisher = {OpenReview.net},
  annotation = {ICLR},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2019how-How powerful are graph neural networks.pdf}
}

@inproceedings{baker2018accelerating,
  title = {Accelerating {{Neural Architecture Search}} Using {{Performance Prediction}}},
  booktitle = ICLR,
  author = {Baker, Bowen and Gupta, Otkrist and Raskar, Ramesh and Naik, Nikhil},
  year = {2018},
  pages = {7},
  abstract = {Methods for neural network meta-modeling are computationally expensive due to the need to train a large number of model configurations. In this paper, we propose a method for accelerating meta-modeling using a method for predicting final performance of neural networks using a frequentist regression models trained using features based on network architectures, hyperparameters, and time-series validation performance data of partially-trained networks. Our method obtains state-of-the-art performance in predicting the final accuracy of models in both visual classification and language modeling domains, is effective for predicting performance of drastically varying model architectures, and even generalizes between model classes. Our early stopping scheme, based on this prediction method, obtains a speedup of up to 6x on reinforcement learning-based neural architecture search, while still identifying the optimal model configurations.},
  langid = {english},
  annotation = {ICLR},
  file = {D:\Workspace\BaiduSyncdisk\CXL_Storage\SoftwareData\zotfile\ICLR2018_Accelerating Neural Architecture Search using Performance Prediction @baker2018accelerating2.pdf}
}

@book{bronshtein2015handbook,
  title = {Handbook of {{Mathematics}}},
  author = {Bronshtein, I.N. and Semendyayev, K.A. and Musiol, Gerhard and M{\"u}hlig, Heiner},
  year = {2015},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-46221-8},
  urldate = {2022-04-30},
  isbn = {978-3-662-46220-1 978-3-662-46221-8},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bronshtein2015handbook-Handbook of Mathematics.pdf}
}

@incollection{perez-liebana2018evolving,
  title = {Evolving Behaviour Tree Structures Using Grammatical Evolution},
  booktitle = {Handbook of {{Grammatical Evolution}}},
  author = {{Perez-Liebana}, Diego and Nicolau, Miguel},
  editor = {Ryan, Conor and O'Neill, Michael and Collins, {\relax JJ}},
  year = {2018},
  pages = {433--460},
  publisher = {Springer International Publishing},
  address = {Cham},
  abstract = {Behaviour Trees are control structures with many applications in computer science, including robotics, control systems, and computer games. They allow the specification of controllers from very broad behaviour definitions (close to the root of the tree) down to very specific technical implementations (near the leaves); this allows them to be understood and extended by both behaviour designers and technical programmers. This chapter describes the process of applying Grammatical Evolution (GE) to evolve Behaviour Trees for a real-time video-game: the Mario AI Benchmark. The results obtained show that these structures are quite amenable to artificial evolution using GE, and can provide a good balance between long-term (pathfinding) and short-term (reactiveness to hazards and power-ups) planning within the same structure.},
  isbn = {978-3-319-78717-6},
  annotation = {Handbook}
}

@inproceedings{wen2020neural,
  title = {Neural {{Predictor}} for {{Neural Architecture Search}}},
  booktitle = ECCV,
  author = {Wen, Wei and Liu, Hanxiao and Chen, Yiran and Li, Hai and Bender, Gabriel and Kindermans, Pieter-Jan},
  year = {2020},
  pages = {16},
  abstract = {Neural Architecture Search methods are effective but often use complex algorithms to come up with the best architecture. We propose an approach with three basic steps that is conceptually much simpler. First we train N random architectures to generate N (architecture, validation accuracy) pairs and use them to train a regression model that predicts accuracies for architectures. Next, we use this regression model to predict the validation accuracies of a large number of random architectures. Finally, we train the top-K predicted architectures and deploy the model with the best validation result. While this approach seems simple, it is more than 20{\texttimes} as sample efficient as Regularized Evolution on the NASBench-101 benchmark. On ImageNet, it approaches the efficiency of more complex and restrictive approaches based on weight sharing such as ProxylessNAS while being fully (embarrassingly) parallelizable and friendly to hyper-parameter tuning.},
  langid = {english},
  annotation = {ECCV},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wen2020neural-Neural Predictor for Neural Architecture Search.pdf}
}

@inproceedings{ryan2003grammatical,
  title = {Grammatical Evolution: {{Evolving}} Programs for an Arbitrary Language},
  booktitle = GP,
  author = {Ryan, Conor and Collins, {\relax JJ} and Neill, Michael O.},
  year = {2003},
  pages = {83--96},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  isbn = {978-3-540-69758-9},
  annotation = {GP}
}

@inproceedings{li2020gpnas,
  title = {{{GP-NAS}}: {{Gaussian Process Based Neural Architecture Search}}},
  booktitle = CVPR,
  author = {Li, Zhihang and Xi, Teng and Deng, Jiankang and Zhang, Gang and Wen, Shengzhao and He, Ran},
  year = {2020},
  pages = {10},
  abstract = {Neural architecture search (NAS) advances beyond the state-of-the-art in various computer vision tasks by automating the designs of deep neural networks. In this paper, we aim to address three important questions in NAS: (1) How to measure the correlation between architectures and their performances? (2) How to evaluate the correlation between different architectures? (3) How to learn these correlations with a small number of samples? To this end, we first model these correlations from a Bayesian perspective. Specifically, by introducing a novel Gaussian Process based NAS (GP-NAS) method, the correlations are modeled by the kernel function and mean function. The kernel function is also learnable to enable adaptive modeling for complex correlations in different search spaces. Furthermore, by incorporating a mutual information based sampling method, we can theoretically ensure the high-performance architecture with only a small set of samples. After addressing these problems, training GP-NAS once enables direct performance prediction of any architecture in different scenarios and may obtain efficient networks for different deployment platforms. Extensive experiments on both image classification and face recognition tasks verify the effectiveness of our algorithm.},
  langid = {english},
  keywords = {gaussion},
  annotation = {CVPR},
  file = {C:\Users\lenovo\Zotero\storage\2THQVGQJ\Li_2020_GP-NAS.pdf}
}

@article{song2021flightmare,
  title = {Flightmare: {{A Flexible Quadrotor Simulator}}},
  shorttitle = {Flightmare},
  author = {Song, Yunlong and Naji, Selim and Kaufmann, Elia and Loquercio, Antonio and Scaramuzza, Davide},
  year = {2021},
  month = may,
  journal = CoRL,
  urldate = {2022-04-24},
  abstract = {State-of-the-art quadrotor simulators have a rigid and highly-specialized structure: either are they really fast, physically accurate, or photo-realistic. In this work, we propose a novel quadrotor simulator: Flightmare. Flightmare is composed of two main components: a configurable rendering engine built on Unity and a flexible physics engine for dynamics simulation. Those two components are totally decoupled and can run independently of each other. This makes our simulator extremely fast: rendering achieves speeds of up to 230 Hz, while physics simulation of up to 200,000 Hz on a laptop. In addition, Flightmare comes with several desirable features: (i) a large multi-modal sensor suite, including an interface to extract the 3D point-cloud of the scene; (ii) an API for reinforcement learning which can simulate hundreds of quadrotors in parallel; and (iii) integration with a virtual-reality headset for interaction with the simulated environment. We demonstrate the flexibility of Flightmare by using it for two different robotic tasks: quadrotor control using deep reinforcement learning and collision-free path planning in a complex 3D environment.},
  langid = {english},
  annotation = {CoRL},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@song2021flightmare-Flightmare - A Flexible Quadrotor Simulator.pdf}
}

@inproceedings{rommerman2009robot,
  title = {Robot Design for Space Missions Using Evolutionary Computation},
  booktitle = CEC,
  author = {Rommerman, Malte and Kuhn, Daniel and Kirchner, Frank},
  year = {2009},
  month = may,
  pages = {2098--2105},
  publisher = {IEEE},
  address = {Trondheim, Norway},
  doi = {10.1109/CEC.2009.4983200},
  urldate = {2022-02-18},
  abstract = {In this work, we describe a learning system that uses the CMA-ES method from evolutionary computation to optimize the morphology and the walking patterns for a complex legged robot simultaneously.},
  isbn = {978-1-4244-2958-5 978-1-4244-2959-2},
  langid = {english},
  keywords = {evolution},
  annotation = {CEC},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@rommerman2009robot-Robot design for space missions using evolutionary computation.pdf}
}

@article{luck2021what,
  title = {What {{Robot}} Do {{I Need}}? {{Fast Co-Adaptation}} of {{Morphology}} and {{Control}} Using {{Graph Neural Networks}}},
  shorttitle = {What {{Robot}} Do {{I Need}}?},
  author = {Luck, Kevin Sebastian and Calandra, Roberto and Mistry, Michael},
  year = {2021},
  month = nov,
  journal = {arXiv},
  eprint = {2111.02371},
  urldate = {2022-02-16},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {embodied intelligence},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\YSPMHGFL\\2021 - arXiv - What Robot do I Need.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@luck2021what-What Robot do I Need - Fast Co-Adaptation of Morphology and Control using Graph.pdf}
}

@article{tucker2021emergent,
  title = {Emergent {{Discrete Communication}} in {{Semantic Spaces}}},
  author = {Tucker, Mycal and Li, Huao and Agrawal, Siddharth and Hughes, Dana and Sycara, Katia and Lewis, Michael and Shah, Julie},
  year = {2021},
  month = nov,
  journal = {arXiv},
  eprint = {2108.01828},
  urldate = {2022-03-24},
  abstract = {Neural agents trained in reinforcement learning settings can learn to communicate among themselves via discrete tokens, accomplishing as a team what agents would be unable to do alone. However, the current standard of using one-hot vectors as discrete communication tokens prevents agents from acquiring more desirable aspects of communication such as zero-shot understanding. Inspired by word embedding techniques from natural language processing, we propose neural agent architectures that enables them to communicate via discrete tokens derived from a learned, continuous space. We show in a decision theoretic framework that our technique optimizes communication over a wide range of scenarios, whereas one-hot tokens are only optimal under restrictive assumptions. In self-play experiments, we validate that our trained agents learn to cluster tokens in semantically-meaningful ways, allowing them communicate in noisy environments where other techniques fail. Lastly, we demonstrate both that agents using our method can effectively respond to novel human communication and that humans can understand unlabeled emergent agent communication, outperforming the use of one-hot communication.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@tucker2021emergent-Emergent Discrete Communication in Semantic Spaces.pdf}
}

@article{stensby2021cooptimising,
  title = {Co-Optimising {{Robot Morphology}} and {{Controller}} in a {{Simulated Open-Ended Environment}}},
  author = {Stensby, Emma Hjellbrekke and Ellefsen, Kai Olav and Glette, Kyrre},
  year = {2021},
  journal = {arXiv},
  volume = {12694},
  eprint = {2104.03062},
  pages = {34--49},
  doi = {10.1007/978-3-030-72699-7_3},
  urldate = {2022-03-01},
  abstract = {Designing robots by hand can be costly and time consuming, especially if the robots have to be created with novel materials, or be robust to internal or external changes. In order to create robots automatically, without the need for human intervention, it is necessary to optimise both the behaviour and the body design of the robot. However, when co-optimising the morphology and controller of a locomoting agent the morphology tends to converge prematurely, reaching a local optimum. Approaches such as explicit protection of morphological innovation have been used to reduce this problem, but it might also be possible to increase exploration of morphologies using a more indirect approach. We explore how changing the environment, where the agent locomotes, affects the convergence of morphologies. The agents' morphologies and controllers are co-optimised, while the environments the agents locomote in are evolved open-endedly with the Paired OpenEnded Trailblazer (POET). We compare the diversity, fitness and robustness of agents evolving in environments generated by POET to agents evolved in handcrafted curricula of environments. Our agents each contain of a population of individuals being evolved with a genetic algorithm. This population is called the agent-population. We show that agent-populations evolving in open-endedly evolving environments exhibit larger morphological diversity than agent-populations evolving in hand crafted curricula of environments. POET proved capable of creating a curriculum of environments which encouraged both diversity and quality in the populations. This suggests that POET may be capable of reducing premature convergence in co-optimisation of morphology and controllers.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {embodied intelligence},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@stensby2021cooptimising-Co-optimising Robot Morphology and Controller in a Simulated Open-Ended.pdf}
}

@article{netanyahu2021phase,
  title = {{{PHASE}}: {{PHysically-grounded Abstract Social Events}} for {{Machine Social Perception}}},
  shorttitle = {{{PHASE}}},
  author = {Netanyahu, Aviv and Shu, Tianmin and Katz, Boris and Barbu, Andrei and Tenenbaum, Joshua B.},
  year = {2021},
  month = mar,
  journal = {arXiv},
  eprint = {2103.01933},
  urldate = {2022-03-24},
  abstract = {The ability to perceive and reason about social interactions in the context of physical environments is core to human social intelligence and human-machine cooperation. However, no prior dataset or benchmark has systematically evaluated physically grounded perception of complex social interactions that go beyond short actions, such as high-fiving, or simple group activities, such as gathering. In this work, we create a dataset of physically-grounded abstract social events, PHASE, that resemble a wide range of real-life social interactions by including social concepts such as helping another agent. PHASE consists of 2D animations of pairs of agents moving in a continuous space generated procedurally using a physics engine and a hierarchical planner. Agents have a limited field of view, and can interact with multiple objects, in an environment that has multiple landmarks and obstacles. Using PHASE, we design a social recognition task and a social prediction task. PHASE is validated with human experiments demonstrating that humans perceive rich interactions in the social events, and that the simulated agents behave similarly to humans. As a baseline model, we introduce a Bayesian inverse planning approach, SIMPLE (SIMulation, Planning and Local Estimation), which outperforms state-of-the-art feedforward neural networks. We hope that PHASE can serve as a difficult new challenge for developing new models that can recognize complex social interactions.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@netanyahu2021phase-PHASE - PHysically-grounded Abstract Social Events for Machine Social Perception.pdf}
}

@article{zardini2021codesign,
  title = {Co-{{Design}} of {{Embodied Intelligence}}: {{A Structured Approach}}},
  shorttitle = {Co-{{Design}} of {{Embodied Intelligence}}},
  author = {Zardini, Gioele and Milojevic, Dejan and Censi, Andrea and Frazzoli, Emilio},
  year = {2021},
  month = sep,
  journal = IROS,
  eprint = {2011.10756},
  pages = {7536--7543},
  doi = {10.1109/IROS51168.2021.9636513},
  urldate = {2022-05-06},
  abstract = {We consider the problem of co-designing embodied intelligence as a whole in a structured way, from hardware components such as propulsion systems and sensors to software modules such as control and perception pipelines. We propose a principled approach to formulate and solve complex embodied intelligence co-design problems, leveraging a monotone co-design theory. The methods we propose are intuitive and integrate heterogeneous engineering disciplines, allowing analytical and simulation-based modeling techniques and enabling interdisciplinarity. We illustrate through a case study how, given a set of desired behaviors, our framework is able to compute Pareto efficient solutions for the entire hardware and software stack of a self-driving vehicle.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zardini2021codesign-Co-Design of Embodied Intelligence - A Structured Approach.pdf}
}

@article{shi2019twostream,
  title = {Two-{{Stream Adaptive Graph Convolutional Networks}} for {{Skeleton-Based Action Recognition}}},
  author = {Shi, Lei and Zhang, Yifan and Cheng, Jian and Lu, Hanqing},
  year = {2019},
  month = jul,
  journal = {arXiv},
  eprint = {1805.07694},
  urldate = {2022-03-21},
  abstract = {In skeleton-based action recognition, graph convolutional networks (GCNs), which model the human body skeletons as spatiotemporal graphs, have achieved remarkable performance. However, in existing GCN-based methods, the topology of the graph is set manually, and it is fixed over all layers and input samples. This may not be optimal for the hierarchical GCN and diverse samples in action recognition tasks. In addition, the second-order information (the lengths and directions of bones) of the skeleton data, which is naturally more informative and discriminative for action recognition, is rarely investigated in existing methods. In this work, we propose a novel two-stream adaptive graph convolutional network (2s-AGCN) for skeletonbased action recognition. The topology of the graph in our model can be either uniformly or individually learned by the BP algorithm in an end-to-end manner. This data-driven method increases the flexibility of the model for graph construction and brings more generality to adapt to various data samples. Moreover, a two-stream framework is proposed to model both the first-order and the second-order information simultaneously, which shows notable improvement for the recognition accuracy. Extensive experiments on the two large-scale datasets, NTU-RGBD and KineticsSkeleton, demonstrate that the performance of our model exceeds the state-of-the-art with a significant margin.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\SARPSBSE\\2019 - arXiv - Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@shi2019twostream-Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action.pdf}
}

@article{yan2018spatial,
  title = {Spatial {{Temporal Graph Convolutional Networks}} for {{Skeleton-Based Action Recognition}}},
  author = {Yan, Sijie and Xiong, Yuanjun and Lin, Dahua},
  year = {2018},
  month = jan,
  journal = {arXiv},
  eprint = {1801.07455},
  urldate = {2022-03-21},
  abstract = {Dynamics of human body skeletons convey significant information for human action recognition. Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization. In this work, we propose a novel model of dynamic skeletons called SpatialTemporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data. This formulation not only leads to greater expressive power but also stronger generalization capability. On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yan2018spatial-Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action.pdf}
}

@article{mikolov2013efficient,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  journal = {arXiv},
  eprint = {1301.3781},
  urldate = {2022-03-23},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mikolov2013efficient-Efficient Estimation of Word Representations in Vector Space.pdf}
}

@inproceedings{feng2023memorybased,
  title = {Memory-Based {{Exploration-value Evaluation Model}} for {{Visual Navigation}}},
  booktitle = ICRA,
  author = {Feng, Yongquan},
  year = {2023},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@feng2023memorybased-Memory-based Exploration-value Evaluation Model for Visual Navigation.pdf}
}

@article{ren2023rmprt,
  title = {{{RM-PRT}}: {{Realistic Robotic Manipulation Simulator}} and {{Benchmark}} with {{Progressive Reasoning Tasks}}},
  author = {Ren, Pengzhen and Zhang, Kaidong and Zheng, Hetao and Li, Zixuan and Wen, Yuhang and Zhu, Fengda and Ma, Mas and Liang, Xiaodan},
  year = {2023},
  journal = {arXiv:},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ren2023rmprt-RM-PRT - Realistic Robotic Manipulation Simulator and Benchmark with Progressive.pdf}
}

@article{lykov2023llmbrain,
  title = {{{LLM-BRAIn}}: {{AI-driven Fast Generation}} of {{Robot Behaviour Tree}} Based on {{Large Language Model}}},
  author = {Lykov, Artem and Tsetserukou, Dzmitry},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.19352},
  eprint = {2305.19352},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lykov2023llmbrain-LLM-BRAIn - AI-driven Fast Generation of Robot Behaviour Tree based on Large.pdf}
}

@article{gur2023realworld,
  title = {A Real-World Webagent with Planning, Long Context Understanding, and Program Synthesis},
  author = {Gur, Izzeddin and Furuta, Hiroki and Huang, Austin and Safdari, Mustafa and Matsuo, Yutaka and Eck, Douglas and Faust, Aleksandra},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.12856},
  eprint = {2307.12856},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gur2023realworld-A real-world webagent with planning, long context understanding, and program.pdf}
}

@article{roziere2023code,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  author = {Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2308.12950},
  eprint = {2308.12950},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@roziere2023code-Code Llama - Open Foundation Models for Code.pdf}
}

@article{thakur2023verigen,
  title = {{{VeriGen}}: {{A Large Language Model}} for {{Verilog Code Generation}}},
  author = {Thakur, Shailja and Ahmad, Baleegh and Pearce, Hammond and Tan, Benjamin and {Dolan-Gavitt}, Brendan and Karri, Ramesh and Garg, Siddharth},
  year = {2023},
  journal = {arXiv preprint arXiv:2308.00708},
  eprint = {2308.00708},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@thakur2023verigen-VeriGen - A Large Language Model for Verilog Code Generation.pdf}
}

@article{mateas2002behavior,
  title = {A Behavior Language for Story-Based Believable Agents},
  author = {Mateas, M. and Stern, A.},
  year = {2002},
  month = jul,
  journal = {IEEE Intelligent Systems},
  volume = {17},
  number = {4},
  pages = {39--47},
  issn = {1541-1672},
  doi = {10.1109/MIS.2002.1024751},
  urldate = {2023-08-25},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mateas2002behavior-A behavior language for story-based believable agents.pdf}
}

@inproceedings{chen2023evolving,
  title = {Evolving {{Physical Instinct}} for  {{Morphology}} and {{Control Co-Adaption}}},
  booktitle = IROS,
  author = {Chen, Xinglin},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023evolving-Evolving Physical Instinct for Morphology and Control Co-Adaption.pdf}
}

@inproceedings{zan2023large,
  title = {Large {{Language Models Meet NL2Code}}: {{A Survey}}},
  booktitle = ACL,
  author = {Zan, Daoguang and Chen, Bei and Zhang, Fengji and Lu, Dianjie and Wu, Bingchao and Guan, Bei and Yongji, Wang and Lou, Jian-Guang},
  year = {2023},
  month = jul,
  pages = {7443--7464},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.acl-long.411},
  abstract = {The task of generating code from a natural language description, or NL2Code, is considered a pressing and significant challenge in code intelligence. Thanks to the rapid development of pre-training techniques, surging large language models are being proposed for code, sparking the advances in NL2Code. To facilitate further research and applications in this field, in this paper, we present a comprehensive survey of 27 existing large language models for NL2Code, and also review benchmarks and metrics. We provide an intuitive comparison of all existing models on the HumanEval benchmark. Through in-depth observation and analysis, we provide some insights and conclude that the key factors contributing to the success of large language models for NL2Code are ``Large Size, Premium Data, Expert Tuning''. In addition, we discuss challenges and opportunities regarding the gap between models and humans. We also create a website https://nl2code.github.io to track the latest progress through crowd-sourcing. To the best of our knowledge, this is the first survey of large language models for NL2Code, and we believe it will contribute to the ongoing development of the field.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zan2023large-Large Language Models Meet NL2Code - A Survey.pdf}
}

@article{minwang2022neural,
  title = {Neural Learning Control for Discrete-Time Nonlinear Systems in Pure-Feedback Form},
  author = {Min WANG, Haotian SHI, Cong WANG, Jun FU},
  year = {2022},
  journal = {SCIENCE CHINA Information Sciences},
  volume = {65},
  number = {2},
  pages = {122206-},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@minwang2022neural-Neural learning control for discrete-time nonlinear systems in pure-feedback.pdf}
}

@article{yuanwang2022adaptive,
  title = {Adaptive Output-Feedback Tracking for Nonlinear Systems with Unknown Control Direction and Generic Inverse Dynamics},
  author = {Yuan WANG, Yungang LIU},
  year = {2022},
  journal = {SCIENCE CHINA Information Sciences},
  volume = {65},
  number = {8},
  pages = {182204-},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yuanwang2022adaptive-Adaptive output-feedback tracking for nonlinear systems with unknown control.pdf}
}

@article{ameertamoorkhan2022human,
  title = {Human Guided Cooperative Robotic Agents in Smart Home Using Beetle Antennae Search},
  author = {Ameer Tamoor KHAN, Shuai LI, Xinwei CAO},
  year = {2022},
  journal = {SCIENCE CHINA Information Sciences},
  volume = {65},
  number = {2},
  pages = {122204-},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ameertamoorkhan2022human-Human guided cooperative robotic agents in smart home using beetle antennae.pdf}
}

@article{jain2023bring,
  title = {Bring {{Your Own Data}}! {{Self-Supervised Evaluation}} for {{Large Language Models}}},
  author = {Jain, Neel and Saifullah, Khalid and Wen, Yuxin and Kirchenbauer, John and Shu, Manli and Saha, Aniruddha and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  year = {2023},
  journal = {arXiv preprint arXiv:2306.13651},
  eprint = {2306.13651},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jain2023bring-Bring Your Own Data! Self-Supervised Evaluation for Large Language Models.pdf}
}

@article{chang2023survey,
  title = {A {{Survey}} on {{Evaluation}} of {{Large Language Models}}},
  author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Zhu, Kaijie and Chen, Hao and Yang, Linyi and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.03109},
  eprint = {2307.03109},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chang2023survey-A Survey on Evaluation of Large Language Models.pdf}
}

@article{peng2017deeploco,
  title = {{{DeepLoco}}: Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning},
  author = {Peng, Xue Bin and Berseth, Glen and Yin, KangKang and {van de Panne}, Michiel},
  year = {2017},
  journal = TOG,
  volume = {36},
  pages = {41:1-41:13},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\62V8WSZZ\\Peng_2017_DeepLoco.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\NC5I52C7\\2017 - TOG - DeepLoco.mp4}
}

@article{dubied2022simtoreal,
  title = {Sim-to-Real for Soft Robots Using Differentiable Fem: {{Recipes}} for Meshing, Damping, and Actuation},
  author = {Dubied, Mathieu and Michelis, Mike Yan and Spielberg, Andrew and Katzschmann, Robert Kevin},
  year = {2022},
  journal = RA-L,
  volume = {7},
  number = {2},
  pages = {5015--5022},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@dubied2022simtoreal-Sim-to-real for soft robots using differentiable fem - Recipes for meshing,.pdf}
}

@article{peng2016terrainadaptive,
  title = {Terrain-Adaptive Locomotion Skills Using Deep Reinforcement Learning},
  author = {Peng, Xue Bin and Berseth, Glen and {van de Panne}, Michiel},
  year = {2016},
  month = jul,
  journal = TOG,
  volume = {35},
  number = {4},
  pages = {1--12},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2897824.2925881},
  urldate = {2022-02-12},
  langid = {english},
  keywords = {animation,core,locomotion,ObsCite},
  annotation = {TOG},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2016terrainadaptive-Terrain-adaptive locomotion skills using deep reinforcement learning.pdf}
}

@article{ma2021diffaqua,
  title = {{{DiffAqua}}: {{A Differentiable Computational Design Pipeline}} for {{Soft Underwater Swimmers}} with {{Shape Interpolation}}},
  author = {Ma, Pingchuan and Du, Tao and Zhang, John Z and Wu, Kui and Spielberg, Andrew and Katzschmann, Robert K and Matusik, Wojciech},
  year = {2021},
  journal = TOG,
  volume = {40},
  number = {4},
  pages = {132},
  publisher = {ACM New York, NY, USA},
  keywords = {ObsCite}
}

@article{openai2023gpt4,
  title = {{{GPT-4 Technical Report}}},
  author = {{OpenAI}},
  year = {2023},
  journal = {ArXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@openai2023gpt4-GPT-4 Technical Report.pdf}
}

@article{howard2019evolving,
  title = {Evolving Embodied Intelligence from Materials to Machines},
  author = {Howard, David and Eiben, Agoston E. and Kennedy, Danielle Frances and Mouret, Jean-Baptiste and Valencia, Philip and Winkler, Dave},
  year = {2019},
  month = jan,
  journal = NMI,
  volume = {1},
  number = {1},
  pages = {12--19},
  issn = {2522-5839},
  doi = {10.1038/s42256-018-0009-9},
  abstract = {Natural lifeforms specialize to their environmental niches across many levels, from low-level features such as DNA and proteins, through to higher-level artefacts including eyes, limbs and overarching body plans. We propose `multi-level evolution', a bottom-up automatic process that designs robots across multiple levels and niches them to tasks and environmental conditions. Multi-level evolution concurrently explores constituent molecular and material building blocks, as well as their possible assemblies into specialized morphological and sensorimotor configurations. Multi-level evolution provides a route to fully harness a recent explosion in available candidate materials and ongoing advances in rapid manufacturing processes. We outline a feasible architecture that realizes this vision, highlight the main roadblocks and how they may be overcome, and show robotic applications to which multi-level evolution is particularly suited. By forming a research agenda to stimulate discussion between researchers in related fields, we hope to inspire the pursuit of multi-level robotic design all the way from material to machine.},
  keywords = {evolutionary,ObsCite,TBD},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@howard2019evolving-Evolving embodied intelligence from materials to machines.pdf}
}

@inproceedings{freeman2021brax,
  title = {Brax - {{A Differentiable Physics Engine}} for {{Large Scale Rigid Body Simulation}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems Track}} on {{Datasets}} and {{Benchmarks}}},
  author = {Freeman, C. Daniel and Frey, Erik and Raichuk, Anton and Girgin, Sertan and Mordatch, Igor and Bachem, Olivier},
  editor = {Vanschoren, Joaquin and Yeung, Sai-Kit},
  year = {2021},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@freeman2021brax-Brax - A Differentiable Physics Engine for Large Scale Rigid Body Simulation.pdf}
}

@article{zhang2023complete,
  title = {A {{Complete Survey}} on {{Generative AI}} ({{AIGC}}): {{Is ChatGPT}} from {{GPT-4}} to {{GPT-5 All You Need}}?},
  author = {Zhang, Chaoning and Zhang, Chenshuang and Zheng, Sheng and Qiao, Yu and Li, Chenghao and Zhang, Mengchun and Dam, Sumit Kumar and Thwal, Chu Myaet and Tun, Ye Lin and Huy, Le Luang and {kim}, Donguk and Bae, Sung-Ho and Lee, Lik-Hang and Yang, Yang and Shen, Heng Tao and Kweon, In So and Hong, Choong Seon},
  year = {2023},
  journal = {arXiv}
}

@article{ma2014strong,
  title = {Strong {{Simulation}}: {{Capturing Topology}} in {{Graph Pattern Matching}}},
  author = {Ma, Shuai and Cao, Yang and Fan, Wenfei and Huai, Jinpeng and Wo, Tianyu},
  year = {2014},
  month = jan,
  journal = {ACM Trans. Database Syst.},
  volume = {39},
  number = {1},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0362-5915},
  doi = {10.1145/2528937},
  abstract = {Graph pattern matching is finding all matches in a data graph for a given pattern graph and is often defined in terms of subgraph isomorphism, an NP-complete problem. To lower its complexity, various extensions of graph simulation have been considered instead. These extensions allow graph pattern matching to be conducted in cubic time. However, they fall short of capturing the topology of data graphs, that is, graphs may have a structure drastically different from pattern graphs they match, and the matches found are often too large to understand and analyze. To rectify these problems, this article proposes a notion of strong simulation, a revision of graph simulation for graph pattern matching. (1) We identify a set of criteria for preserving the topology of graphs matched. We show that strong simulation preserves the topology of data graphs and finds a bounded number of matches. (2) We show that strong simulation retains the same complexity as earlier extensions of graph simulation by providing a cubic-time algorithm for computing strong simulation. (3) We present the locality property of strong simulation which allows us to develop an effective distributed algorithm to conduct graph pattern matching on distributed graphs. (4) We experimentally verify the effectiveness and efficiency of these algorithms using both real-life and synthetic data.},
  keywords = {data locality,dual simulation,graph simulation,ObsCite,Strong simulation,subgraph isomorphism},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ma2014strong-Strong Simulation - Capturing Topology in Graph Pattern Matching.pdf}
}

@inproceedings{jing2020reinforcement,
  title = {Reinforcement Learning from Imperfect Demonstrations under Soft Expert Guidance},
  booktitle = AAAI,
  author = {Jing, Mingxuan and Ma, Xiaojian and Huang, Wenbing and Sun, Fuchun and Yang, Chao and Fang, Bin and Liu, Huaping},
  year = {2020},
  volume = {34},
  pages = {5109--5116},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jing2020reinforcement-Reinforcement learning from imperfect demonstrations under soft expert guidance.pdf}
}

@inproceedings{ning2023coimitation,
  title = {Co-{{Imitation Learning}} without {{Expert Demonstration}}},
  booktitle = {Workshop on {{Reincarnating Reinforcement Learning}} at {{ICLR}} 2023},
  author = {Ning, Kun-Peng and Xu, Hu and Zhu, Kun and Huang, Sheng-Jun},
  year = {2023},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ning2023coimitation-Co-Imitation Learning without Expert Demonstration.pdf}
}

@inproceedings{formanek2023reduce,
  title = {Reduce, {{Reuse}}, {{Recycle}}: {{Selective Reincarnation}} in {{Multi-Agent Reinforcement Learning}}},
  booktitle = {Workshop on {{Reincarnating Reinforcement Learning}} at {{ICLR}} 2023},
  author = {Formanek, Juan Claude and Tilbury, Callum Rhys and Shock, Jonathan Phillip and Tessera, Kale-ab and Pretorius, Arnu},
  year = {2023},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@formanek2023reduce-Reduce, Reuse, Recycle - Selective Reincarnation in Multi-Agent Reinforcement.pdf}
}

@inproceedings{sun2017deeply,
  title = {Deeply Aggrevated: {{Differentiable}} Imitation Learning for Sequential Prediction},
  booktitle = ICML,
  author = {Sun, Wen and Venkatraman, Arun and Gordon, Geoffrey J and Boots, Byron and Bagnell, J Andrew},
  year = {2017},
  pages = {3309--3318},
  publisher = {PMLR},
  keywords = {core,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2017deeply-Deeply aggrevated - Differentiable imitation learning for sequential prediction.pdf}
}

@article{ross2014reinforcement,
  title = {Reinforcement and Imitation Learning via Interactive No-Regret Learning},
  author = {Ross, Stephane and Bagnell, J Andrew},
  year = {2014},
  journal = {arXiv preprint arXiv:1406.5979},
  eprint = {1406.5979},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ross2014reinforcement-Reinforcement and imitation learning via interactive no-regret learning.pdf}
}

@article{liu2018reinforcement,
  title = {Reinforcement Learning on Web Interfaces Using Workflow-Guided Exploration},
  author = {Liu, Evan Zheran and Guu, Kelvin and Pasupat, Panupong and Shi, Tianlin and Liang, Percy},
  year = {2018},
  journal = {arXiv preprint arXiv:1802.08802},
  eprint = {1802.08802},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2018reinforcement-Reinforcement learning on web interfaces using workflow-guided exploration.pdf}
}

@article{ball2023efficient,
  title = {Efficient Online Reinforcement Learning with Offline Data},
  author = {Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  year = {2023},
  journal = {arXiv preprint arXiv:2302.02948},
  eprint = {2302.02948},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ball2023efficient-Efficient online reinforcement learning with offline data.pdf}
}

@inproceedings{emedom-nnamdi2023knowledge,
  title = {Knowledge {{Transfer}} from {{Teachers}} to {{Learners}} in {{Growing-Batch Reinforcement Learning}}},
  booktitle = {Workshop on {{Reincarnating Reinforcement Learning}} at {{ICLR}} 2023},
  author = {{Emedom-Nnamdi}, Patrick and Friesen, Abram L. and Shahriari, Bobak and de Freitas, Nando and Hoffman, Matthew},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@emedom-nnamdi2023knowledge-Knowledge Transfer from Teachers to Learners in Growing-Batch Reinforcement.pdf}
}

@article{wu2022prioritized,
  title = {Prioritized Experience-Based Reinforcement Learning with Human Guidance for Autonomous Driving},
  author = {Wu, Jingda and Huang, Zhiyu and Huang, Wenhui and Lv, Chen},
  year = {2022},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  publisher = {IEEE},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2022prioritized-Prioritized experience-based reinforcement learning with human guidance for.pdf}
}

@inproceedings{fang2021adaptive,
  title = {Adaptive {{Procedural Task Generation}} for {{Hard-Exploration Problems}}},
  booktitle = ICLR,
  author = {Fang, Kuan and Zhu, Yuke and Savarese, Silvio and {Fei-Fei}, Li},
  year = {2021},
  publisher = {OpenReview.net},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@fang2021adaptive-Adaptive Procedural Task Generation for Hard-Exploration Problems.pdf}
}

@article{rengarajan2022reinforcement,
  title = {Reinforcement Learning with Sparse Rewards Using Guidance from Offline Demonstration},
  author = {Rengarajan, Desik and Vaidya, Gargi and Sarvesh, Akshay and Kalathil, Dileep and Shakkottai, Srinivas},
  year = {2022},
  journal = {arXiv preprint arXiv:2202.04628},
  eprint = {2202.04628},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@rengarajan2022reinforcement-Reinforcement learning with sparse rewards using guidance from offline.pdf}
}

@inproceedings{libardi2020guided,
  title = {Guided {{Exploration}} with {{Proximal Policy Optimization}} Using a {{Single Demonstration}}},
  booktitle = ICML,
  author = {Libardi, Gabriele and Fabritiis, Gianni De},
  year = {2020},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@libardi2020guided-Guided Exploration with Proximal Policy Optimization using a Single.pdf}
}

@inproceedings{gulcehre2020making,
  title = {Making {{Efficient Use}} of {{Demonstrations}} to {{Solve Hard Exploration Problems}}},
  booktitle = ICLR,
  author = {Gulcehre, Caglar and Paine, Tom Le and Shahriari, Bobak and Denil, Misha and Hoffman, Matt and Soyer, Hubert and Tanburn, Richard and Kapturowski, Steven and Rabinowitz, Neil and Williams, Duncan and {Barth-Maron}, Gabriel and Wang, Ziyu and de Freitas, Nando and Team, Worlds},
  year = {2020},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gulcehre2020making-Making Efficient Use of Demonstrations to Solve Hard Exploration Problems.pdf}
}

@inproceedings{nair2018overcoming,
  title = {Overcoming {{Exploration}} in {{Reinforcement Learning}} with {{Demonstrations}}},
  booktitle = ICRA,
  author = {Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  year = {2018},
  pages = {6292--6299},
  doi = {10.1109/ICRA.2018.8463162},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@nair2018overcoming-Overcoming Exploration in Reinforcement Learning with Demonstrations.pdf}
}

@article{ladosz2022exploration,
  title = {Exploration in Deep Reinforcement Learning: {{A}} Survey},
  author = {Ladosz, Pawel and Weng, Lilian and Kim, Minwoo and Oh, Hyondong},
  year = {2022},
  journal = {Information Fusion},
  publisher = {Elsevier},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ladosz2022exploration-Exploration in deep reinforcement learning - A survey.pdf}
}

@article{mcfarlane2018survey,
  title = {A Survey of Exploration Strategies in Reinforcement Learning},
  author = {McFarlane, Roger},
  year = {2018},
  journal = {McGill University},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mcfarlane2018survey-A survey of exploration strategies in reinforcement learning.pdf}
}

@inproceedings{cisneros-velarde2023one,
  title = {One {{Policy}} Is {{Enough}}: {{Parallel Exploration}} with a {{Single Policy}} Is {{Near-Optimal}} for {{Reward-Free Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {{Cisneros-Velarde}, Pedro and Lyu, Boxiang and Koyejo, Sanmi and Kolar, Mladen},
  year = {2023},
  pages = {1965--2001},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@cisneros-velarde2023one-One Policy is Enough - Parallel Exploration with a Single Policy is Near-Optimal.pdf}
}

@inproceedings{albrecht2022avalon,
  title = {Avalon: {{A Benchmark}} for {{RL Generalization Using Procedurally Generated Worlds}}},
  booktitle = NeurIPS,
  author = {Albrecht, Joshua and Fetterman, Abraham J. and Fogelman, Bryden and Kitanidis, Ellie and Wr{\'o}blewski, Bartosz and Seo, Nicole and Rosenthal, Michael and Knutins, Maksis and Polizzi, Zachary and Simon, James B. and Qiu, Kanjun},
  year = {2022},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@albrecht2022avalon-Avalon - A Benchmark for RL Generalization Using Procedurally Generated Worlds.pdf}
}

@article{sorokin2023designing,
  title = {On {{Designing}} a {{Learning Robot}}: {{Improving Morphology}} for {{Enhanced Task Performance}} and {{Learning}}},
  author = {Sorokin, Maks and Fu, Chuyuan and Tan, Jie and Liu, C Karen and Bai, Yunfei and Lu, Wenlong and Ha, Sehoon and Khansari, Mohi},
  year = {2023},
  journal = {arXiv preprint arXiv:2303.13390},
  eprint = {2303.13390},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sorokin2023designing-On Designing a Learning Robot - Improving Morphology for Enhanced Task.pdf}
}

@inproceedings{shridhar2023perceiveractor,
  title = {Perceiver-{{Actor}}: {{A Multi-Task Transformer}} for {{Robotic Manipulation}}},
  booktitle = CoRL,
  author = {Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  editor = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
  year = {2023},
  month = dec,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {205},
  pages = {785--799},
  publisher = {PMLR},
  abstract = {Transformers have revolutionized vision and natural language processing with their ability to scale with large datasets. But in robotic manipulation, data is both limited and expensive. Can manipulation still benefit from Transformers with the right problem formulation? We investigate this question with PerAct, a language-conditioned behavior-cloning agent for multi-task 6-DoF manipulation. PerAct encodes language goals and RGB-D voxel observations with a Perceiver Transformer, and outputs discretized actions by ``detecting the next best voxel action''. Unlike frameworks that operate on 2D images, the voxelized 3D observation and action space provides a strong structural prior for efficiently learning 6-DoF actions. With this formulation, we train a single multi-task Transformer for 18 RLBench tasks (with 249 variations) and 7 real-world tasks (with 18 variations) from just a few demonstrations per task. Our results show that PerAct significantly outperforms unstructured image-to-action agents and 3D ConvNet baselines for a wide range of tabletop tasks.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@shridhar2023perceiveractor-Perceiver-Actor - A Multi-Task Transformer for Robotic Manipulation.pdf}
}

@article{vecerik2017leveraging,
  title = {Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards},
  author = {Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  year = {2017},
  journal = {arXiv},
  volume = {preprint arXiv:1707.08817},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@vecerik2017leveraging-Leveraging demonstrations for deep reinforcement learning on robotics problems.pdf}
}

@article{wang2022codesign,
  title = {Co-Design of {{Embodied Neural Intelligence}} via {{Constrained Evolution}}},
  author = {Wang, Zhiquan and Benes, Bedrich and Qureshi, Ahmed Hussain and Mousas, Christos},
  year = {2022},
  journal = {arXiv},
  volume = {abs/2205.10688},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2022codesign-Co-design of Embodied Neural Intelligence via Constrained Evolution.pdf}
}

@article{wang2023softzoo,
  title = {{{SoftZoo}}: {{A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments}}},
  author = {Wang, Tsun-Hsuan and Ma, Pingchuan and Spielberg, Andrew and Xian, Zhou and Zhang, Hao and Tenenbaum, Joshua B. and Rus, Daniela and Gan, Chuang},
  year = {2023},
  journal = {arXiv},
  volume = {abs/2303.09555},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023softzoo-SoftZoo - A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments.pdf}
}

@article{xiong2023universal,
  title = {Universal {{Morphology Control}} via {{Contextual Modulation}}},
  author = {Xiong, Zheng and Beck, Jacob and Whiteson, Shimon},
  year = {2023},
  journal = {arXiv},
  volume = {abs/2302.11070},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xiong2023universal-Universal Morphology Control via Contextual Modulation.pdf}
}

@inproceedings{yu2022multiembodiment,
  title = {Multi-Embodiment {{Legged Robot Control}} as a {{Sequence Modeling Problem}}},
  booktitle = ICRA,
  author = {Yu, Chen and Zhang, Weinan and Lai, Hang and Tian, Zheng and Kneip, Laurent and Wang, Jun},
  year = {2022},
  month = dec,
  eprint = {2212.09078},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-02-28},
  abstract = {Robots are traditionally bounded by a fixed embodiment during their operational lifetime, which limits their ability to adapt to their surroundings. Co-optimizing control and morphology of a robot, however, is often inefficient due to the complex interplay between the controller and morphology. In this paper, we propose a learning-based control method that can inherently take morphology into consideration such that once the control policy is trained in the simulator, it can be easily deployed to robots with different embodiments in the real world. In particular, we present the Embodiment-aware Transformer (EAT), an architecture that casts this control problem as conditional sequence modeling. EAT outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired robot embodiment, past states, and actions, our EAT model can generate future actions that best fit the current robot embodiment. Experimental results show that EAT can outperform all other alternatives in embodiment-varying tasks, and succeed in an example of real-world evolution tasks: stepping down a stair through updating the morphology alone. We hope that EAT will inspire a new push toward real-world evolution across many domains, where algorithms like EAT can blaze a trail by bridging the field of evolutionary robotics and big data sequence modeling.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2022multiembodiment-Multi-embodiment Legged Robot Control as a Sequence Modeling Problem.pdf}
}

@article{jiang2022vima,
  title = {Vima: {{General}} Robot Manipulation with Multimodal Prompts},
  author = {Jiang, Yunfan and Gupta, Agrim and Zhang, Zichen and Wang, Guanzhi and Dou, Yongqiang and Chen, Yanjun and {Fei-Fei}, Li and Anandkumar, Anima and Zhu, Yuke and Fan, Linxi},
  year = {2022},
  journal = {arXiv},
  volume = {2210.03094},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jiang2022vima-Vima - General robot manipulation with multimodal prompts.pdf}
}

@article{schubert2023generalist,
  title = {A {{Generalist Dynamics Model}} for {{Control}}},
  author = {Schubert, Ingmar and Zhang, Jingwei and Bruce, Jake and Bechtle, Sarah and Parisotto, Emilio and Riedmiller, Martin and Springenberg, Jost Tobias and Byravan, Arunkumar and Hasenclever, Leonard and Heess, Nicolas},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.10912},
  eprint = {2305.10912},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@schubert2023generalist-A Generalist Dynamics Model for Control.pdf}
}

@article{schulman2017proximal,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  year = {2017},
  month = aug,
  journal = {arXiv},
  number = {arXiv:1707.06347},
  eprint = {1707.06347},
  primaryclass = {cs},
  urldate = {2022-05-27},
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a ``surrogate'' objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@schulman2017proximal-Proximal Policy Optimization Algorithms.pdf}
}

@inproceedings{furuta2023system,
  title = {A {{System}} for {{Morphology-Task Generalization}} via {{Unified Representation}} and {{Behavior Distillation}}},
  booktitle = ICLR,
  author = {Furuta, Hiroki and Iwasawa, Yusuke and Matsuo, Yutaka and Gu, Shixiang Shane},
  year = {2023},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@furuta2023system-A System for Morphology-Task Generalization via Unified Representation and.pdf}
}

@inproceedings{chentanez2018physicsbased,
  title = {Physics-Based Motion Capture Imitation with Deep Reinforcement Learning},
  booktitle = SIGGRAPH,
  author = {Chentanez, Nuttapong and M{\"u}ller, Matthias and Macklin, Miles and Makoviychuk, Viktor and Jeschke, Stefan},
  year = {2018},
  pages = {1--10},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chentanez2018physicsbased-Physics-based motion capture imitation with deep reinforcement learning.pdf}
}

@inproceedings{parisotto2016actormimic,
  title = {Actor-{{Mimic}}: {{Deep Multitask}} and {{Transfer Reinforcement Learning}}},
  booktitle = ICLR,
  author = {Parisotto, Emilio and Ba, Lei Jimmy and Salakhutdinov, Ruslan},
  editor = {Bengio, Yoshua and LeCun, Yann},
  year = {2016},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@parisotto2016actormimic-Actor-Mimic - Deep Multitask and Transfer Reinforcement Learning.pdf}
}

@inproceedings{huang2022adarl,
  title = {{{AdaRL}}: {{What}}, {{Where}}, and {{How}} to {{Adapt}} in {{Transfer Reinforcement Learning}}},
  booktitle = ICLR,
  author = {Huang, Biwei and Feng, Fan and Lu, Chaochao and Magliacane, Sara and Zhang, Kun},
  year = {2022},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2022adarl-AdaRL - What, Where, and How to Adapt in Transfer Reinforcement Learning.pdf}
}

@article{laroche2017transfer,
  title = {Transfer {{Reinforcement Learning}} with {{Shared Dynamics}}},
  author = {Laroche, Romain and Barlier, Merwan},
  year = {2017},
  month = feb,
  journal = AAAI,
  volume = {31},
  number = {1},
  doi = {10.1609/aaai.v31i1.10796},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@laroche2017transfer-Transfer Reinforcement Learning with Shared Dynamics.pdf}
}

@article{gou2021knowledge,
  title = {Knowledge {{Distillation}}: {{A Survey}}},
  author = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen J. and Tao, Dacheng},
  year = {2021},
  month = jun,
  journal = {IJCV},
  volume = {129},
  number = {6},
  pages = {1789--1819},
  issn = {1573-1405},
  doi = {10.1007/s11263-021-01453-z},
  abstract = {In recent years, deep neural networks have been successful in both industry and academia, especially for computer vision tasks. The great success of deep learning is mainly due to its scalability to encode large-scale data and to maneuver billions of model parameters. However, it is a challenge to deploy these cumbersome deep models on devices with limited resources, e.g., mobile phones and embedded devices, not only because of the high computational complexity but also the large storage requirements. To this end, a variety of model compression and acceleration techniques have been developed. As a representative type of model compression and acceleration, knowledge distillation effectively learns a small student model from a large teacher model. It has received rapid increasing attention from the community. This paper provides a comprehensive survey of knowledge distillation from the perspectives of knowledge categories, training schemes, teachertudent architecture, distillation algorithms, performance comparison and applications. Furthermore, challenges in knowledge distillation are briefly reviewed and comments on future research are discussed and forwarded.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gou2021knowledge-Knowledge Distillation - A Survey.pdf}
}

@inproceedings{you2017learning,
  title = {Learning from {{Multiple Teacher Networks}}},
  booktitle = {Proceedings of the {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {You, Shan and Xu, Chang and Xu, Chao and Tao, Dacheng},
  year = {2017},
  series = {{{KDD}} '17},
  pages = {1285--1294},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3097983.3098135},
  abstract = {Training thin deep networks following the student-teacher learning paradigm has received intensive attention because of its excellent performance. However, to the best of our knowledge, most existing work mainly considers one single teacher network. In practice, a student may access multiple teachers, and multiple teacher networks together provide comprehensive guidance that is beneficial for training the student network. In this paper, we present a method to train a thin deep network by incorporating multiple teacher networks not only in output layer by averaging the softened outputs (dark knowledge) from different networks, but also in the intermediate layers by imposing a constraint about the dissimilarity among examples. We suggest that the relative dissimilarity between intermediate representations of different examples serves as a more flexible and appropriate guidance from teacher networks. Then triplets are utilized to encourage the consistence of these relative dissimilarity relationships between the student network and teacher networks. Moreover, we leverage a voting strategy to unify multiple relative dissimilarity information provided by multiple teacher networks, which realizes their incorporation in the intermediate layers. Extensive experimental results demonstrated that our method is capable of generating a well-performed student network, with the classification accuracy comparable or even superior to all teacher networks, yet having much fewer parameters and being much faster in running.},
  isbn = {978-1-4503-4887-4},
  keywords = {deep learning,knowledge transfer,multiple teacher networks,ObsCite,triplet loss},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@you2017learning-Learning from Multiple Teacher Networks.pdf}
}

@article{silver2017mastering,
  title = {Mastering the Game of {{Go}} without Human Knowledge},
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy P. and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
  year = {2017},
  journal = {Nature},
  volume = {550},
  number = {7676},
  pages = {354--359},
  doi = {10.1038/nature24270},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@silver2017mastering-Mastering the game of Go without human knowledge.pdf}
}

@inproceedings{kurin2021my,
  title = {My {{Body}} Is a {{Cage}}: The {{Role}} of {{Morphology}} in {{Graph-Based Incompatible Control}}},
  booktitle = ICLR,
  author = {Kurin, Vitaly and Igl, Maximilian and Rockt{\"a}schel, Tim and Boehmer, Wendelin and Whiteson, Shimon},
  year = {2021},
  publisher = {OpenReview.net},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kurin2021my-My Body is a Cage - the Role of Morphology in Graph-Based Incompatible Control.pdf}
}

@article{wang2019paired,
  title = {Paired Open-Ended Trailblazer (Poet): {{Endlessly}} Generating Increasingly Complex and Diverse Learning Environments and Their Solutions},
  author = {Wang, Rui and Lehman, Joel and Clune, Jeff and Stanley, Kenneth O},
  year = {2019},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2019paired-Paired open-ended trailblazer (poet) - Endlessly generating increasingly complex.pdf}
}

@article{wang2017learning,
  title = {Learning to Reinforcement Learn},
  author = {Wang, Jane X. and {Kurth-Nelson}, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z. and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
  year = {2017},
  month = jan,
  journal = {arXiv},
  eprint = {1611.05763},
  primaryclass = {cs, stat},
  urldate = {2023-02-03},
  abstract = {In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2017learning-Learning to reinforcement learn.pdf}
}

@article{vinyals2019grandmaster,
  title = {Grandmaster Level in {{StarCraft II}} Using Multi-Agent Reinforcement Learning},
  author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, R{\'e}mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W{\"u}nsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
  year = {2019},
  month = nov,
  journal = {Nature},
  volume = {575},
  number = {7782},
  pages = {350--354},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1724-z},
  abstract = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1--3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8\% of officially ranked human players.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@vinyals2019grandmaster-Grandmaster level in StarCraft II using multi-agent reinforcement learning.pdf}
}

@article{spielberg2021colearning,
  title = {Co-Learning of Task and Sensor Placement for Soft Robotics},
  author = {Spielberg, Andrew and Amini, Alexander and Chin, Lillian and Matusik, Wojciech and Rus, Daniela},
  year = {2021},
  journal = RA-L,
  volume = {6},
  number = {2},
  pages = {1208--1215},
  publisher = {IEEE},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@spielberg2021colearning-Co-learning of task and sensor placement for soft robotics.pdf}
}

@article{varghese2020survey,
  title = {A {{Survey}} of {{Multi-Task Deep Reinforcement Learning}}},
  author = {Varghese, Nelson Vithayathil and Mahmoud, Qusay H.},
  year = {2020},
  month = aug,
  journal = {Electronics},
  volume = {9},
  number = {9},
  pages = {1363},
  issn = {2079-9292},
  doi = {10.3390/electronics9091363},
  urldate = {2023-02-03},
  abstract = {Driven by the recent technological advancements within the field of artificial intelligence research, deep learning has emerged as a promising representation learning technique across all of the machine learning classes, especially within the reinforcement learning arena. This new direction has given rise to the evolution of a new technological domain named deep reinforcement learning, which combines the representational learning power of deep learning with existing reinforcement learning methods. Undoubtedly, the inception of deep reinforcement learning has played a vital role in optimizing the performance of reinforcement learning-based intelligent agents with model-free based approaches. Although these methods could improve the performance of agents to a greater extent, they were mainly limited to systems that adopted reinforcement learning algorithms focused on learning a single task. At the same moment, the aforementioned approach was found to be relatively data-inefficient, particularly when reinforcement learning agents needed to interact with more complex and rich data environments. This is primarily due to the limited applicability of deep reinforcement learning algorithms to many scenarios across related tasks from the same environment. The objective of this paper is to survey the research challenges associated with multi-tasking within the deep reinforcement arena and present the state-of-the-art approaches by comparing and contrasting recent solutions, namely DISTRAL (DIStill \& TRAnsfer Learning), IMPALA(Importance Weighted Actor-Learner Architecture) and PopArt that aim to address core challenges such as scalability, distraction dilemma, partial observability, catastrophic forgetting and negative knowledge transfer.},
  langid = {english},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@varghese2020survey-A Survey of Multi-Task Deep Reinforcement Learning.pdf}
}

@inproceedings{trabucco2022anymorph,
  title = {{{AnyMorph}}: {{Learning}} Transferable Polices by Inferring Agent Morphology},
  booktitle = ICML,
  author = {Trabucco, Brandon and Phielipp, Mariano and Berseth, Glen},
  editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  year = {2022-07-17/2022-07-23},
  series = {Proceedings of Machine Learning Research},
  volume = {162},
  pages = {21677--21691},
  publisher = {PMLR},
  abstract = {The prototypical approach to reinforcement learning involves training policies tailored to a particular agent from scratch for every new morphology. Recent work aims to eliminate the re-training of policies by investigating whether a morphology-agnostic policy, trained on a diverse set of agents with similar task objectives, can be transferred to new agents with unseen morphologies without re-training. This is a challenging problem that required previous approaches to use hand-designed descriptions of the new agent's morphology. Instead of hand-designing this description, we propose a data-driven method that learns a representation of morphology directly from the reinforcement learning objective. Ours is the first reinforcement learning algorithm that can train a policy to generalize to new agent morphologies without requiring a description of the agent's morphology in advance. We evaluate our approach on the standard benchmark for agent-agnostic control, and improve over the current state of the art in zero-shot generalization to new agents. Importantly, our method attains good performance without an explicit description of morphology.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@trabucco2022anymorph-AnyMorph - Learning transferable polices by inferring agent morphology.pdf}
}

@article{tunyasuvunakool2021highly,
  title = {Highly Accurate Protein Structure Prediction for the Human Proteome},
  author = {Tunyasuvunakool, Kathryn and Adler, Jonas and Wu, Zachary and Green, Tim and Zielinski, Michal and {\v Z}{\'i}dek, Augustin and Bridgland, Alex and Cowie, Andrew and Meyer, Clemens and Laydon, Agata and Velankar, Sameer and Kleywegt, Gerard J. and Bateman, Alex and Evans, Richard and Pritzel, Alexander and Figurnov, Michael and Ronneberger, Olaf and Bates, Russ and Kohl, Simon A. A. and Potapenko, Anna and Ballard, Andrew J. and {Romera-Paredes}, Bernardino and Nikolov, Stanislav and Jain, Rishub and Clancy, Ellen and Reiman, David and Petersen, Stig and Senior, Andrew W. and Kavukcuoglu, Koray and Birney, Ewan and Kohli, Pushmeet and Jumper, John and Hassabis, Demis},
  year = {2021},
  month = aug,
  journal = {Nature},
  volume = {596},
  number = {7873},
  pages = {590--596},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03828-1},
  abstract = {Protein structures can provide invaluable information, both for reasoning about biological processes and for enabling interventions such as structure-based drug development or targeted mutagenesis. After decades of effort, 17\% of the total residues in human protein sequences are covered by an experimentally determined structure1. Here we markedly expand the structural coverage of the proteome by applying the state-of-the-art machine learning method, AlphaFold2, at a scale that covers almost the entire human proteome (98.5\% of human proteins). The resulting dataset covers 58\% of residues with a confident prediction, of which a subset (36\% of all residues) have very high confidence. We introduce several metrics developed by building on the AlphaFold model and use them to interpret the dataset, identifying strong multi-domain predictions as well as regions that are likely to be disordered. Finally, we provide some case studies to illustrate how high-quality predictions could be used to generate biological hypotheses. We are making our predictions freely available to the community and anticipate that routine large-scale and high-accuracy structure prediction will become an important tool~that will allow new questions to be addressed from a structural perspective.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@tunyasuvunakool2021highly-Highly accurate protein structure prediction for the human proteome.pdf}
}

@article{senior2020improved,
  title = {Improved Protein Structure Prediction Using Potentials from Deep Learning},
  author = {Senior, Andrew W. and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and {\v Z}{\'i}dek, Augustin and Nelson, Alexander W. R. and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T. and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
  year = {2020},
  month = jan,
  journal = {Nature},
  volume = {577},
  number = {7792},
  pages = {706--710},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1923-7},
  abstract = {Protein structure prediction can be used to determine the three-dimensional shape of a protein from its amino acid sequence1. This problem is of fundamental importance as the structure of a protein largely determines its function2; however, protein structures can be difficult to determine experimentally. Considerable progress has recently been made by leveraging genetic information. It is possible to infer which amino acid residues are in contact by analysing covariation in homologous sequences, which aids in the prediction of protein structures3. Here we show that we can train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions. Using this information, we construct a potential of mean force4 that can accurately describe the shape of a protein. We find that the resulting potential can be optimized by a simple gradient descent algorithm to generate structures without complex sampling procedures. The resulting system, named AlphaFold, achieves high accuracy, even for sequences with fewer homologous sequences. In the recent Critical Assessment of Protein Structure Prediction5 (CASP13)---a blind assessment of the state of the field---AlphaFold created high-accuracy structures (with template modelling (TM) scores6 of 0.7 or higher) for 24 out of 43 free modelling domains, whereas the next best method, which used sampling and contact information, achieved such accuracy for only 14 out of 43 domains. AlphaFold represents a considerable advance in protein-structure prediction. We expect this increased accuracy to enable insights into the function and malfunction of proteins, especially in cases for which no structures for homologous proteins have been experimentally determined7.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@senior2020improved-Improved protein structure prediction using potentials from deep learning.pdf}
}

@article{schrittwieser2020mastering,
  title = {Mastering {{Atari}}, {{Go}}, Chess and Shogi by Planning with a Learned Model},
  author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
  year = {2020},
  month = dec,
  journal = {Nature},
  volume = {588},
  number = {7839},
  pages = {604--609},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-03051-4},
  abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess1 and Go2, where a perfect simulator is available. However, in real-world problems, the dynamics governing the environment are often complex and unknown. Here we present the MuZero algorithm, which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. The MuZero algorithm learns an iterable model that produces predictions relevant to planning: the action-selection policy, the value function and the reward. When evaluated on 57 different Atari games3---the canonical video game environment for testing artificial intelligence techniques, in which model-based planning approaches have historically struggled4---the MuZero algorithm achieved state-of-the-art performance. When evaluated on Go, chess and shogi---canonical environments for high-performance planning---the MuZero algorithm matched, without any knowledge of the game dynamics, the superhuman performance of the AlphaZero algorithm5 that was supplied with the rules of the game.},
  keywords = {alpha zero,mcts,ObsCite,planning},
  annotation = {Nature},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@schrittwieser2020mastering-Mastering Atari, Go, chess and shogi by planning with a learned model.pdf}
}

@inproceedings{spielberg2019learningintheloop,
  title = {Learning-{{In-The-Loop Optimization}}: {{End-To-End Control And Co-Design Of Soft Robots Through Learned Deep Latent Representations}}},
  booktitle = NeurIPS,
  author = {Spielberg, Andrew and Zhao, Allan and Hu, Yuanming and Du, Tao and Matusik, Wojciech and Rus, Daniela},
  year = {2019},
  pages = {11},
  publisher = {MIT Press},
  langid = {english},
  keywords = {embodied intelligence,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@spielberg2019learningintheloop-Learning-In-The-Loop Optimization - End-To-End Control And Co-Design Of Soft.pdf}
}

@article{robot2023metaevolve,
  title = {Meta-{{Evolve}}: {{Continuous Robot Evolution}} for {{One-to-many Policy Transfer}}},
  author = {Robot, Meta},
  year = {2023},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@robot2023metaevolve-Meta-Evolve - Continuous Robot Evolution for One-to-many Policy Transfer.pdf}
}

@inproceedings{pathak2019learning,
  title = {Learning to {{Control Self-Assembling Morphologies}}: {{A Study}} of {{Generalization}} via {{Modularity}}},
  booktitle = NeurIPS,
  author = {Pathak, Deepak and Lu, Christopher and Darrell, Trevor and Isola, Phillip and Efros, Alexei A.},
  editor = {Wallach, Hanna M. and Larochelle, Hugo and Beygelzimer, Alina and {d'Alch{\'e}-Buc}, Florence and Fox, Emily B. and Garnett, Roman},
  year = {2019},
  pages = {2292--2302},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@pathak2019learning-Learning to Control Self-Assembling Morphologies - A Study of Generalization via.pdf}
}

@inproceedings{neupane2019learning,
  title = {Learning {{Swarm Behaviors}} Using {{Grammatical Evolution}} and {{Behavior Trees}}},
  booktitle = IJCAI,
  author = {Neupane, Aadesh and Goodrich, Michael},
  year = {2019},
  pages = {513--520},
  publisher = {IJCAI Organization},
  keywords = {ObsCite},
  annotation = {IJCAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@neupane2019learning-Learning Swarm Behaviors using Grammatical Evolution and Behavior Trees.pdf}
}

@inproceedings{luck2019dataefficient,
  title = {Data-Efficient {{Co-Adaptation}} of {{Morphology}} and {{Behaviour}} with {{Deep Reinforcement Learning}}},
  booktitle = CoRL,
  author = {Luck, Kevin Sebastian and Amor, Heni Ben and Calandra, Roberto},
  year = {2019},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@luck2019dataefficient-Data-efficient Co-Adaptation of Morphology and Behaviour with Deep.pdf}
}

@book{pfeifer2006how,
  title = {How the {{Body Shapes}} the {{Way We Think}}: {{A New View}} of {{Intelligence}}},
  author = {Pfeifer, Rolf and Bongard, Josh},
  year = {2006},
  publisher = {MIT press},
  keywords = {embodied intelligence,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@pfeifer2006how-How the Body Shapes the Way We Think - A New View of Intelligence.pdf}
}

@article{nygaard2021realworld,
  title = {Real-World Embodied {{AI}} through a Morphologically Adaptive Quadruped Robot},
  author = {Nygaard, T{\o}nnes F. and Martin, Charles P. and Torresen, Jim and Glette, Kyrre and Howard, David},
  year = {2021},
  month = may,
  journal = NMI,
  volume = {3},
  number = {5},
  pages = {410--419},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00320-3},
  urldate = {2022-03-02},
  langid = {english},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@nygaard2021realworld-Real-world embodied AI through a morphologically adaptive quadruped robot.pdf}
}

@inproceedings{liu2022herd,
  title = {{{HERD}}: {{Continuous Human-to-Robot Evolution}} for {{Learning}} from {{Human Demonstration}}},
  booktitle = CoRL,
  author = {Liu, Xingyu and Pathak, Deepak and Kitani, Kris M},
  year = {2022},
  keywords = {ObsCite}
}

@article{li2022competitionlevel,
  title = {Competition-Level Code Generation with {{AlphaCode}}},
  author = {Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Lago, Agustin Dal and Hubert, Thomas and Choy, Peter and {d'Autume}, Cyprien de Masson and Babuschkin, Igor and Chen, Xinyun and Huang, Po-Sen and Welbl, Johannes and Gowal, Sven and Cherepanov, Alexey and Molloy, James and Mankowitz, Daniel J. and Robson, Esme Sutherland and Kohli, Pushmeet and de Freitas, Nando and Kavukcuoglu, Koray and Vinyals, Oriol},
  year = {2022},
  month = mar,
  journal = {Science},
  volume = {378},
  number = {6624},
  pages = {1092--1097},
  doi = {10.1126/science.abq1158},
  abstract = {Programming is a powerful and ubiquitous problem-solving tool. Systems that can assist programmers or even generate programs themselves could make programming more productive and accessible. Recent transformer-based neural network models show impressive code generation abilities yet still perform poorly on more complex tasks requiring problem-solving skills, such as competitive programming problems. Here, we introduce AlphaCode, a system for code generation that achieved an average ranking in the top 54.3\% in simulated evaluations on recent programming competitions on the Codeforces platform. AlphaCode solves problems by generating millions of diverse programs using specially trained transformer-based networks and then filtering and clustering those programs to a maximum of just 10 submissions. This result marks the first time an artificial intelligence system has performed competitively in programming competitions. Computer programming competitions are popular tests among programmers that require critical thinking informed by experience and creating solutions to unforeseen problems, both of which are key aspects of human intelligence but challenging to mimic by machine learning models. Using self-supervised learning and an encoder-decoder transformer architecture, Li et al. developed AlphaCode, a deep-learning model that can achieve approximately human-level performance on the Codeforces platform, which regularly hosts these competitions and attracts numerous participants worldwide (see the Perspective by Kolter). The development of such coding platforms could have a huge impact on programmers' productivity. It may even change the culture of programming by shifting human work to formulating problems, with machine learning being the main one responsible for generating and executing codes. ---YS Modern machine learning systems can achieve average human-level performance in popular competitive programming contests.},
  keywords = {ObsCite},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@li2022competitionlevel-Competition-level code generation with AlphaCode.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@li2022competitionlevel-Competition-level code generation with AlphaCode2.pdf}
}

@inproceedings{hubert2021learning,
  title = {Learning and {{Planning}} in {{Complex Action Spaces}}},
  booktitle = ICML,
  author = {Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Barekatain, Mohammadamin and Schmitt, Simon and Silver, David},
  editor = {Meila, Marina and Zhang, Tong},
  year = {2021},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {139},
  pages = {4476--4486},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@hubert2021learning-Learning and Planning in Complex Action Spaces.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@hubert2021learning-Learning and Planning in Complex Action Spaces2.pdf}
}

@article{iovino2020survey,
  title = {A Survey of Behavior Trees in Robotics and {{AI}}},
  author = {Iovino, Matteo and Scukins, Edvards and Styrud, Jonathan and {\"O}gren, Petter and Smith, Christian},
  year = {2020},
  journal = {arXiv},
  volume = {2005.05842 [cs]},
  keywords = {ObsCite},
  annotation = {ArXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@iovino2020survey-A survey of behavior trees in robotics and AI.pdf}
}

@article{liu2021survey,
  title = {A {{Survey}} on {{Evolutionary Neural Architecture Search}}.},
  author = {Liu, Yuqiao and Sun, Yanan and Xue, Bing and Zhang, Mengjie and Yen, Gary G. and Tan, Kay Chen},
  year = {2021},
  month = aug,
  journal = TPAMI,
  volume = {PP},
  address = {United States},
  issn = {2162-2388 2162-237X},
  doi = {10.1109/TNNLS.2021.3100554},
  abstract = {Deep neural networks (DNNs) have achieved great success in many applications. The architectures of DNNs play a crucial role in their performance, which is usually  manually designed with rich expertise. However, such a design process is  labor-intensive because of the trial-and-error process and also not easy to realize  due to the rare expertise in practice. Neural architecture search (NAS) is a type of  technology that can design the architectures automatically. Among different methods  to realize NAS, the evolutionary computation (EC) methods have recently gained much  attention and success. Unfortunately, there has not yet been a comprehensive summary  of the EC-based NAS algorithms. This article reviews over 200 articles of most  recent EC-based NAS methods in light of the core components, to systematically  discuss their design principles and justifications on the design. Furthermore,  current challenges and issues are also discussed to identify future research in this  emerging field.},
  langid = {english},
  pmid = {34357870},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2021survey-A Survey on Evolutionary Neural Architecture Search.pdf}
}

@article{hua2021learning,
  title = {Learning for a {{Robot}}: {{Deep Reinforcement Learning}}, {{Imitation Learning}}, {{Transfer Learning}}},
  author = {Hua, Jiang and Zeng, Liangcai and Li, Gongfa and Ju, Zhaojie},
  year = {2021},
  journal = {Sensors},
  volume = {21},
  number = {4},
  issn = {1424-8220},
  doi = {10.3390/s21041278},
  abstract = {Dexterous manipulation of the robot is an important part of realizing intelligence, but manipulators can only perform simple tasks such as sorting and packing in a structured environment. In view of the existing problem, this paper presents a state-of-the-art survey on an intelligent robot with the capability of autonomous deciding and learning. The paper first reviews the main achievements and research of the robot, which were mainly based on the breakthrough of automatic control and hardware in mechanics. With the evolution of artificial intelligence, many pieces of research have made further progresses in adaptive and robust control. The survey reveals that the latest research in deep learning and reinforcement learning has paved the way for highly complex tasks to be performed by robots. Furthermore, deep reinforcement learning, imitation learning, and transfer learning in robot control are discussed in detail. Finally, major achievements based on these methods are summarized and analyzed thoroughly, and future research challenges are proposed.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hua2021learning-Learning for a Robot - Deep Reinforcement Learning, Imitation Learning, Transfer.pdf}
}

@article{fenton2017ponyge2,
  title = {{{PonyGE2}}: Grammatical Evolution in {{Python}}},
  author = {Fenton, Michael and McDermott, James and Fagan, David and Forstenlechner, Stefan and Hemberg, Erik and O'Neill, Michael},
  year = {2017},
  journal = GECCO,
  pages = {1194--1201},
  keywords = {ObsCite},
  annotation = {GECCO},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@fenton2017ponyge2-PonyGE2 - grammatical evolution in Python.pdf}
}

@book{hara2003morphofunctional,
  title = {Morpho-Functional {{Machines}}: {{The New Species}}},
  shorttitle = {Morpho-Functional {{Machines}}},
  editor = {Hara, Fumio and Pfeifer, Rolf},
  year = {2003},
  publisher = {Springer Japan},
  address = {Tokyo},
  urldate = {2022-05-06},
  isbn = {978-4-431-68006-2 978-4-431-67869-4},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Users\lenovo\Zotero\storage\4S6YIXQG\Hara_Pfeifer_2003_Morpho-functional Machines.pdf}
}

@article{gupta2021embodied,
  title = {Embodied Intelligence via Learning and Evolution},
  author = {Gupta, Agrim and Savarese, Silvio and Ganguli, Surya and {Fei-Fei}, Li},
  year = {2021},
  month = dec,
  journal = NC,
  volume = {12},
  number = {1},
  pages = {5721},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-25874-z},
  urldate = {2022-02-16},
  langid = {english},
  keywords = {core,embodied intelligence,ObsCite,policy,reinforcement learning},
  annotation = {Nature},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@gupta2021embodied-Embodied intelligence via learning and evolution.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@gupta2021embodied-Embodied intelligence via learning and evolution2.pdf}
}

@article{bernstein1966coordination,
  title = {The Co-Ordination and Regulation of Movements},
  author = {Bernstein, Nikolai},
  year = {1966},
  journal = {The co-ordination and regulation of movements},
  publisher = {Pergamon press},
  keywords = {ObsCite}
}

@article{bongard2013evolutionary,
  title = {Evolutionary {{Robotics}}},
  author = {Bongard, Josh C.},
  year = {2013},
  month = aug,
  journal = {Commun. ACM},
  volume = {56},
  number = {8},
  pages = {74--83},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0001-0782},
  doi = {10.1145/2493883},
  abstract = {Taking a biologically inspired approach to the design of autonomous, adaptive machines.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bongard2013evolutionary-Evolutionary Robotics.pdf}
}

@article{gao2019graphnas,
  title = {{{GraphNAS}}: {{Graph Neural Architecture Search}} with {{Reinforcement Learning}}},
  shorttitle = {{{GraphNAS}}},
  author = {Gao, Yang and Yang, Hong and Zhang, Peng and Zhou, Chuan and Hu, Yue},
  year = {2019},
  month = aug,
  journal = {arXiv},
  urldate = {2022-04-04},
  abstract = {Graph Neural Networks (GNNs) have been popularly used for analyzing non-Euclidean data such as social network data and biological data. Despite their success, the design of graph neural networks requires a lot of manual work and domain knowledge. In this paper, we propose a Graph Neural Architecture Search method (GraphNAS for short) that enables automatic search of the best graph neural architecture based on reinforcement learning. Specifically, GraphNAS first uses a recurrent network to generate variable-length strings that describe the architectures of graph neural networks, and then trains the recurrent network with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation data set. Extensive experimental results on node classification tasks in both transductive and inductive learning settings demonstrate that GraphNAS can achieve consistently better performance on the Cora, Citeseer, Pubmed citation network, and protein-protein interaction network. On node classification tasks, GraphNAS can design a novel network architecture that rivals the best humaninvented architecture in terms of test set accuracy.},
  langid = {english},
  keywords = {GNN,reinforcement learning},
  annotation = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2019graphnas-GraphNAS - Graph Neural Architecture Search with Reinforcement Learning.pdf}
}

@article{roy2021machine,
  title = {From Machine Learning to Robotics: {{Challenges}} and Opportunities for Embodied Intelligence},
  author = {Roy, Nicholas and Posner, Ingmar and Barfoot, Tim D. and Beaudoin, Philippe and Bengio, Yoshua and Bohg, Jeannette and Brock, Oliver and Depatie, Isabelle and Fox, Dieter and Koditschek, Daniel E. and {Lozano-P{\'e}rez}, Tom{\'a}s and Mansinghka, Vikash and Pal, Christopher J. and Richards, Blake and Sadigh, Dorsa and Schaal, Stefan and Sukhatme, Gaurav S. and Th{\'e}rien, Denis and Toussaint, Marc and {van de Panne}, Michiel},
  year = {2021},
  journal = {arXiv},
  keywords = {core,embodied intelligence},
  annotation = {Arxiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@roy2021machine-From machine learning to robotics - Challenges and opportunities for embodied.pdf}
}

@article{mundhenk2021symbolic,
  title = {Symbolic Regression via Neural-Guided Genetic Programming Population Seeding},
  author = {Mundhenk, T. Nathan and Landajuela, Mikel and Glatt, Ruben and Santiago, Cl{\'a}udio P. and Faissol, Daniel M. and Petersen, Brenden K.},
  year = {2021},
  journal = {arXiv},
  volume = {abs/2111.00053},
  keywords = {TBD},
  annotation = {Arxiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mundhenk2021symbolic-Symbolic regression via neural-guided genetic programming population seeding.pdf}
}

@inproceedings{xue2021rethinking,
  title = {Rethinking {{Bi-Level Optimization}} in {{Neural Architecture Search}}: {{A Gibbs Sampling Perspective}}},
  booktitle = AAAI,
  author = {Xue, Chao and Wang, Xiaoxing and Yan, Junchi and Hu, Yonggang and Yang, Xiaokang and Sun, Kewei},
  year = {2021},
  pages = {9},
  abstract = {One-Shot architecture search, aiming to explore all possible operations jointly based on a single model, has been an active direction of Neural Architecture Search (NAS). As a wellknown one-shot solution, Differentiable Architecture Search (DARTS) performs continuous relaxation on the architecture's importance and results in a bi-level optimization problem. As many recent studies have shown, DARTS cannot always work robustly for new tasks, which is mainly due to the approximate solution of the bi-level optimization. In this paper, one-shot neural architecture search is addressed by adopting a directed probabilistic graphical model to represent the joint probability distribution over data and model. Then, neural architectures are searched for and optimized by Gibbs sampling. We rethink the bi-level optimization problem as the task of Gibbs sampling from the posterior distribution, which expresses the preferences for different models given the observed dataset. We evaluate our proposed NAS method -- GibbsNAS on the search space used in DARTS/ENAS as well as the search space of NAS-Bench-201. Experimental results on multiple search space show the efficacy and stability of our approach.},
  langid = {english},
  keywords = {differentiable,gibbs sampling,one-shot},
  annotation = {AAAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xue2021rethinking-Rethinking Bi-Level Optimization in Neural Architecture Search - A Gibbs.pdf}
}

@article{wu2021neural,
  title = {Neural {{Architecture Search}} as {{Sparse Supernet}}},
  author = {Wu, Yan and Liu, Aoming and Huang, Zhiwu and Zhang, Siwei and Gool, Luc Van},
  year = {2021},
  journal = AAAI,
  pages = {9},
  abstract = {This paper aims at enlarging the problem of Neural Architecture Search (NAS) from Single-Path and Multi-Path Search to automated Mixed-Path Search. In particular, we model the NAS problem as a sparse supernet using a new continuous architecture representation with a mixture of sparsity constraints. The sparse supernet enables us to automatically achieve sparsely-mixed paths upon a compact set of nodes. To optimize the proposed sparse supernet, we exploit a hierarchical accelerated proximal gradient algorithm within a bi-level optimization framework. Extensive experiments on Convolutional Neural Network and Recurrent Neural Network search demonstrate that the proposed method is capable of searching for compact, general and powerful neural architectures.},
  langid = {english},
  keywords = {differentiable,sparse},
  annotation = {AAAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2021neural-Neural Architecture Search as Sparse Supernet.pdf}
}

@article{white2021bananas,
  title = {{{BANANAS}}: {{Bayesian Optimization}} with {{Neural Architectures}} for {{Neural Architecture Search}}},
  author = {White, Colin and Neiswanger, Willie and Savani, Yash},
  year = {2021},
  journal = AAAI,
  pages = {9},
  langid = {english},
  keywords = {bayesian optimization},
  annotation = {AAAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@white2021bananas-BANANAS - Bayesian Optimization with Neural Architectures for Neural.pdf}
}

@article{sato2021advantagenas,
  title = {{{AdvantageNAS}}: {{Efficient Neural Architecture Search}} with {{Credit Assignment}}},
  author = {Sato, Rei and Sakuma, Jun and Akimoto, Youhei},
  year = {2021},
  journal = AAAI,
  pages = {8},
  abstract = {Neural architecture search (NAS) is an approach for automatically designing a neural network architecture without human effort or expert knowledge. However, the high computational cost of NAS limits its use in commercial applications. Two recent NAS paradigms, namely one-shot and sparse propagation, which reduce the time and space complexities, respectively, provide clues for solving this problem. In this paper, we propose a novel search strategy for one-shot and sparse propagation NAS, namely AdvantageNAS, which further reduces the time complexity of NAS by reducing the number of search iterations. AdvantageNAS is a gradientbased approach that improves the search efficiency by introducing credit assignment in gradient estimation for architecture updates. Experiments on the NAS-Bench-201 and PTB dataset show that AdvantageNAS discovers an architecture with higher performance under a limited time budget compared to existing sparse propagation NAS. To further reveal the reliabilities of AdvantageNAS, we investigate it theoretically and find that it monotonically improves the expected loss and thus converges.},
  langid = {english},
  keywords = {differentiable,one-shot,sparse},
  annotation = {AAAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sato2021advantagenas-AdvantageNAS - Efficient Neural Architecture Search with Credit Assignment.pdf}
}

@article{risi2021deep,
  title = {Deep {{Innovation Protection}}: {{Confronting}} the {{Credit Assignment Problem}} in {{Training Heterogeneous Neural Architectures}}},
  author = {Risi, Sebastian and Stanley, Kenneth O},
  year = {2021},
  journal = AAAI,
  pages = {9},
  langid = {english},
  keywords = {credit assignment,multiobjective optimization},
  annotation = {AAAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@risi2021deep-Deep Innovation Protection - Confronting the Credit Assignment Problem in.pdf}
}

@article{li2021oneshot,
  title = {One-Shot {{Graph Neural Architecture Search}} with {{Dynamic Search Space}}},
  author = {Li, Yanxi and Wen, Zean and Wang, Yunhe and Xu, Chang},
  year = {2021},
  journal = AAAI,
  pages = {8},
  langid = {english},
  keywords = {dynamic search space,one-shot},
  annotation = {AAAI},
  file = {C:\Users\lenovo\Zotero\storage\4EU3XYRR\Li_2021_One-shot Graph Neural Architecture Search with Dynamic Search Space.pdf}
}

@inproceedings{cheng2021nasgem,
  title = {{{NASGEM}}: {{Neural}} Architecture Search via Graph Embedding Method},
  booktitle = AAAI,
  author = {Cheng, Hsin-Pai and Zhang, Tunhou and Zhang, Yixing and Li, Shiyu and Liang, Feng and Yan, Feng and Li, Meng and Chandra, Vikas and Li, Hai and Chen, Yiran},
  year = {2021},
  pages = {7090--7098},
  publisher = {AAAI Press},
  keywords = {architecture encoding,graph embedding},
  annotation = {AAAI},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\MIFDZ2XL\\2021 - AAAI - NASGEM.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@cheng2021nasgem-NASGEM - Neural architecture search via graph embedding method.pdf}
}

@article{broering2021embodied,
  title = {Toward {{Embodied Intelligence}}: {{Smart Things}} on the {{Rise}}},
  shorttitle = {Toward {{Embodied Intelligence}}},
  author = {Broering, Arne and Niedermeier, Christoph and Olaru, Ioana and Schopp, Ulrich and Telschig, Kilian and Villnow, Michael},
  year = {2021},
  month = jul,
  journal = {Computer},
  volume = {54},
  number = {7},
  pages = {57--68},
  issn = {0018-9162, 1558-0814},
  doi = {10.1109/MC.2021.3074749},
  urldate = {2022-05-06},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\6VXI7EMU\Broering_2021_Toward Embodied Intelligence.pdf}
}

@book{starzyk2008motivation,
  title = {Motivation in Embodied Intelligence},
  author = {Starzyk, Janusz A},
  year = {2008},
  publisher = {Citeseer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@starzyk2008motivation-Motivation in embodied intelligence.pdf}
}

@article{fei-fei2022searching,
  title = {Searching for {{Computer Vision North Stars}}},
  author = {{Fei-Fei}, Li and Krishna, Ranjay},
  year = {2022},
  month = may,
  journal = {Daedalus},
  volume = {151},
  number = {2},
  pages = {85--99},
  issn = {0011-5266},
  doi = {10.1162/daed_a_01902},
  urldate = {2022-05-05},
  abstract = {Computer vision is one of the most fundamental areas of artificial intelligence research. It has contributed to the tremendous progress in the recent deep learning revolution in AI. In this essay, we provide a perspective of the recent evolution of object recognition in computer vision, a flagship research topic that led to the breakthrough data set of ImageNet and its ensuing algorithm developments. We argue that much of this progress is rooted in the pursuit of research ``north stars,'' wherein researchers focus on critical problems of a scientific discipline that can galvanize major efforts and groundbreaking progress. Following the success of ImageNet and object recognition, we observe a number of exciting areas of research and a growing list of north star problems to tackle. This essay recounts the brief history of ImageNet, its related work, and the follow-up progress. The goal is to inspire more north star work to advance the field, and AI at large.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@fei-fei2022searching-Searching for Computer Vision North Stars.pdf}
}

@article{liu2019efficient,
  title = {Efficient Batch-Mode Reinforcement Learning Using Extreme Learning Machines},
  author = {Liu, J. and Zuo, L. and Xu, X. and Zhang, X. and Liu, X.},
  year = {2019},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  volume = {PP},
  number = {99},
  pages = {1--14}
}

@book{ryan2018handbook,
  title = {Handbook of Grammatical Evolution},
  author = {Ryan, Conor and O'Neill, Michael and Collins, {\relax JJ}},
  year = {2018},
  publisher = {Springer},
  annotation = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ryan2018handbook-Handbook of grammatical evolution.pdf}
}

@incollection{nicolau2018understanding,
  title = {Understanding {{Grammatical Evolution}}: {{Grammar Design}}},
  shorttitle = {Understanding {{Grammatical Evolution}}},
  booktitle = {Handbook of {{Grammatical Evolution}}},
  author = {Nicolau, Miguel and Agapitos, Alexandros},
  editor = {Ryan, Conor and O'Neill, Michael and Collins, Jj},
  year = {2018},
  pages = {23--53},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2022-04-21},
  abstract = {A frequently overlooked consideration when using Grammatical Evolution (GE) is grammar design. This is because there is an infinite number of grammars that can specify the same syntax. There are, however, certain aspects of grammar design that greatly affect the speed of convergence and quality of solutions generated with GE. In this chapter, general guidelines for grammar design are presented. These are domain-independent, and can be used when applying GE to any problem. An extensive analysis of their effect and results across a large set of experiments are reported.},
  isbn = {978-3-319-78716-9 978-3-319-78717-6},
  langid = {english},
  annotation = {Handbook},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@nicolau2018understanding-Understanding Grammatical Evolution - Grammar Design.pdf}
}

@book{poli2008field,
  title = {A Field Guide to Genetic Programming},
  author = {Poli, Riccardo and Langdon, William and Mcphee, Nicholas},
  year = {2008},
  publisher = {Lulu Press}
}

@article{colledanchise2019learning,
  title = {Learning of {{Behavior Trees}} for {{Autonomous Agents}}},
  author = {Colledanchise, Michele and Parasuraman, Ramviyas and {\"O}gren, Petter},
  year = {2019},
  journal = {IEEE Transactions on Games},
  volume = {11},
  number = {2},
  pages = {183--189},
  doi = {10.1109/TG.2018.2816806},
  annotation = {TOGames},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2019learning-Learning of Behavior Trees for Autonomous Agents.pdf}
}

@article{lecun1998gradientbased,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  year = {Nov./1998},
  journal = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  issn = {00189219},
  doi = {10.1109/5.726791},
  urldate = {2022-03-31},
  langid = {english},
  keywords = {cnn},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lecun1998gradientbased-Gradient-based learning applied to document recognition.pdf}
}

@article{mautner2000evolving,
  title = {Evolving Robot Morphology and Control},
  author = {Mautner, Craig and Belew, Richard K.},
  year = {2000},
  month = sep,
  journal = {Artificial Life and Robotics},
  volume = {4},
  number = {3},
  pages = {130--136},
  issn = {1433-5298, 1614-7456},
  doi = {10.1007/BF02481333},
  urldate = {2022-03-01},
  abstract = {Most robotic approaches begin with a fixed robot hardware design and then experiment with control structures. We take a different approach that considers both the robot hardware and the control structure as variables in the evolutionary process. This paper reports the results of experiments which explore the placement of sensors and eflectors around the perimeter of a simulated agent's body, and the neural network (NNet) that controls them.},
  langid = {english},
  keywords = {embodied intelligence},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mautner2000evolving-Evolving robot morphology and control.pdf}
}

@incollection{cangelosi2015embodied,
  title = {Embodied Intelligence},
  booktitle = {Springer Handbook of Computational Intelligence},
  author = {Cangelosi, Angelo and Bongard, Josh and Fischer, Martin H. and Nolfi, Stefano},
  editor = {Kacprzyk, Janusz and Pedrycz, Witold},
  year = {2015},
  pages = {697--714},
  publisher = {Springer Berlin Heidelberg},
  keywords = {embodied intelligence},
  annotation = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@cangelosi2015embodied-Embodied intelligence.pdf}
}

@article{ren2022comprehensive,
  title = {A {{Comprehensive Survey}} of {{Neural Architecture Search}}: {{Challenges}} and {{Solutions}}},
  shorttitle = {A {{Comprehensive Survey}} of {{Neural Architecture Search}}},
  author = {Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-yao and Li, Zhihui and Chen, Xiaojiang and Wang, Xin},
  year = {2022},
  month = may,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {4},
  pages = {1--34},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3447582},
  urldate = {2022-03-10},
  abstract = {Deep learning has made substantial breakthroughs in many fields due to its powerful automatic representation capabilities. It has been proven that neural architecture design is crucial to the feature representation of data and the final performance. However, the design of the neural architecture heavily relies on the researchers' prior knowledge and experience. And due to the limitations of humans' inherent knowledge, it is difficult for people to jump out of their original thinking paradigm and design an optimal model. Therefore, an intuitive idea would be to reduce human intervention as much as possible and let the algorithm automatically design the neural architecture.                                Neural Architecture Search                              (               NAS               ) is just such a revolutionary algorithm, and the related research work is complicated and rich. Therefore, a comprehensive and systematic survey on the NAS is essential. Previously related surveys have begun to classify existing work mainly based on the key components of NAS: search space, search strategy, and evaluation strategy. While this classification method is more intuitive, it is difficult for readers to grasp the challenges and the landmark work involved. Therefore, in this survey, we provide a new perspective: beginning with an overview of the characteristics of the earliest NAS algorithms, summarizing the problems in these early NAS algorithms, and then providing solutions for subsequent related research work. In addition, we conduct a detailed and comprehensive analysis, comparison, and summary of these works. Finally, we provide some possible future research directions.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ren2022comprehensive-A Comprehensive Survey of Neural Architecture Search - Challenges and Solutions.pdf}
}

@book{colledanchise2018behavior,
  title = {Behavior {{Trees}} in {{Robotics}} and {{AI}}: {{An Introduction}}},
  author = {Colledanchise, Michele and {\"O}gren, Petter},
  year = {2018},
  publisher = {CRC Press},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2018behavior-Behavior Trees in Robotics and AI - An Introduction.pdf}
}

@inproceedings{huang2020cen,
  title = {{{CEN}}: {{Concept}} Evolution Network for Image Classification Tasks},
  booktitle = {Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence},
  author = {Huang, Da and Chen, Xinglin},
  year = {2020},
  series = {{{RICAI}} 2020},
  pages = {192--199},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3438872.3439080},
  abstract = {Image classification is a challenging but fundamental task for many computer vision applications, such as self-driving, face recognition, and object tracking. The deep neural network (DNN) is a modern, powerful model to tackle this task, whose representation ability mainly comes from hidden layers. The interpretability of DNN, however, drops rapidly as the inexplicable hidden part becomes deeper and deeper. To make neural networks more explainable, we propose a novel neural network named concept evolution network (CEN), learning explicit concepts of images to help classify. Concepts evolve during training with three stages: emergence, elevation, and elimination. We design three algorithms (one primary and two improved) to train CEN. The experiment results on MNIST show our methods' feasibility and that CEN has both interpretability and adaptive learning capacity for the image classification task. In the last section, we discuss the development prospects of CEN in the future.},
  isbn = {978-1-4503-8830-6},
  annotation = {RICAI}
}

@article{gong2016evolutionary,
  title = {Evolutionary Computation in {{China}}: {{A}} Literature Survey},
  shorttitle = {Evolutionary Computation in {{China}}},
  author = {Gong, Maoguo and Wang, Shanfeng and Liu, Wenfeng and Yan, Jianan and Jiao, Licheng},
  year = {2016},
  month = oct,
  journal = {CAAI Transactions on Intelligence Technology},
  volume = {1},
  number = {4},
  pages = {334--354},
  issn = {24682322},
  doi = {10.1016/j.trit.2016.11.002},
  urldate = {2022-02-28},
  abstract = {Evolutionary computation (EC) has received significant attention in China during the last two decades. In this paper, we present an overview of the current state of this rapidly growing field in China. Chinese research in theoretical foundations of EC, EC-based optimization, EC-based data mining, and EC-based real-world applications are summarized.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gong2016evolutionary-Evolutionary computation in China - A literature survey.pdf}
}

@article{yang2020multiexpert,
  title = {Multi-Expert Learning of Adaptive Legged Locomotion},
  author = {Yang, Chuanyu and Yuan, Kai and Zhu, Qiuguo and Yu, Wanming and Li, Zhibin},
  year = {2020},
  month = dec,
  journal = {Science Robotics},
  volume = {5},
  number = {49},
  pages = {eabb2174},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.abb2174},
  urldate = {2022-02-28},
  abstract = {A multi-expert learning architecture generates adaptive behaviors for the versatile locomotion of quadruped robots.           ,              Achieving versatile robot locomotion requires motor skills that can adapt to previously unseen situations. We propose a multi-expert learning architecture (MELA) that learns to generate adaptive skills from a group of representative expert skills. During training, MELA is first initialized by a distinct set of pretrained experts, each in a separate deep neural network (DNN). Then, by learning the combination of these DNNs using a gating neural network (GNN), MELA can acquire more specialized experts and transitional skills across various locomotion modes. During runtime, MELA constantly blends multiple DNNs and dynamically synthesizes a new DNN to produce adaptive behaviors in response to changing situations. This approach leverages the advantages of trained expert skills and the fast online synthesis of adaptive policies to generate responsive motor skills during the changing tasks. Using one unified MELA framework, we demonstrated successful multiskill locomotion on a real quadruped robot that performed coherent trotting, steering, and fall recovery autonomously and showed the merit of multi-expert learning generating behaviors that can adapt to unseen scenarios.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2020multiexpert-Multi-expert learning of adaptive legged locomotion.pdf}
}

@article{lian2010simple,
  title = {A Simple Method to Quantify the Morphological Similarity between Signals},
  author = {Lian, Jie and Garner, Garth and Muessig, Dirk and Lang, Volker},
  year = {2010},
  month = feb,
  journal = {Signal Processing},
  volume = {90},
  number = {2},
  pages = {684--688},
  issn = {01651684},
  doi = {10.1016/j.sigpro.2009.07.010},
  urldate = {2022-02-18},
  abstract = {We propose a simple index, termed adaptive signed correlation index (ASCI), to quantify the morphological similarity between signals. The ASCI between two signals is calculated by trichotomizing each signal based on predefined three signal subspaces, then calculating the signed correlation of the trichotomized vectors. Examples are shown to compare ASCI with conventional correlation coefficients with respect to the effects of signal perturbation and additive noise. The ASCI provides a robust and efficient measure of morphological similarity and has particular applications in embedded systems involving biological signal analysis.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lian2010simple-A simple method to quantify the morphological similarity between signals.pdf}
}

@article{fawzi2022discovering,
  title = {Discovering Faster Matrix Multiplication Algorithms with Reinforcement Learning},
  author = {Fawzi, Alhussein and Balog, Matej and Huang, Aja and Hubert, Thomas and {Romera-Paredes}, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and R. Ruiz, Francisco J. and Schrittwieser, Julian and Swirszcz, Grzegorz and Silver, David and Hassabis, Demis and Kohli, Pushmeet},
  year = {2022},
  month = oct,
  journal = {Nature},
  volume = {610},
  number = {7930},
  pages = {47--53},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-05172-4},
  abstract = {Improving the efficiency of algorithms for fundamental computations can have a widespread impact, as it can affect the overall speed of a large amount of computations. Matrix multiplication is one such primitive task, occurring in many systems---from neural networks to scientific computing routines. The automatic discovery of algorithms using machine learning offers the prospect of reaching beyond human intuition and outperforming the current best human-designed algorithms. However, automating the algorithm discovery procedure is intricate, as the space of possible algorithms is enormous. Here we report a deep reinforcement learning approach based on AlphaZero1 for discovering efficient and provably correct algorithms for the multiplication of arbitrary matrices. Our agent, AlphaTensor, is trained to play a single-player game where the objective is finding tensor decompositions within a finite factor space. AlphaTensor discovered algorithms that outperform the state-of-the-art complexity for many matrix sizes. Particularly relevant is the case of 4\,{\texttimes}\,4 matrices in a finite field, where AlphaTensor's algorithm improves on Strassen's two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago2. We further showcase the flexibility of AlphaTensor through different use-cases: algorithms with state-of-the-art complexity for structured matrix multiplication and improved practical efficiency by optimizing matrix multiplication for runtime on specific hardware. Our results highlight AlphaTensor's ability to accelerate the process of algorithmic discovery on a range of problems, and to optimize for different criteria.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@fawzi2022discovering-Discovering faster matrix multiplication algorithms with reinforcement learning.pdf}
}

@article{doncieux2015evolutionary,
  title = {Evolutionary Robotics: {{What}}, Why, and Where To},
  author = {Doncieux, Stephane and Bredeche, Nicolas and Mouret, Jean-Baptiste and Eiben, Agoston E. (Gusz)},
  year = {2015},
  journal = FRA,
  volume = {2},
  issn = {2296-9144},
  doi = {10.3389/frobt.2015.00004},
  abstract = {Evolutionary robotics applies the selection, variation, and heredity principles of natural evolution to the design of robots with embodied intelligence. It can be considered as a subfield of robotics that aims to create more robust and adaptive robots. A pivotal feature of the evolutionary approach is that it considers the whole robot at once, and enables the exploitation of robot features in a holistic manner. Evolutionary robotics can also be seen as an innovative approach to the study of evolution based on a new kind of experimentalism. The use of robots as a substrate can help to address questions that are difficult, if not impossible, to investigate through computer simulations or biological studies. In this paper, we consider the main achievements of evolutionary robotics, focusing particularly on its contributions to both engineering and biology. We briefly elaborate on methodological issues, review some of the most interesting findings, and discuss important open issues and promising avenues for future work.},
  keywords = {ObsCite}
}

@misc{coumans2016pybullet,
  title = {{{PyBullet}}, a {{Python}} Module for Physics Simulation for Games, Robotics and Machine Learning},
  author = {Coumans, Erwin and Bai, Yunfei},
  year = {2016},
  keywords = {ObsCite}
}

@inproceedings{lund2003coevolving,
  title = {Co-Evolving {{Control}} and {{Morphology}} with {{LEGO Robots}}},
  booktitle = {Morpho-Functional {{Machines}}: {{The New Species}}},
  author = {Lund, Henrik Hautop},
  editor = {Hara, Fumio and Pfeifer, Rolf},
  year = {2003},
  pages = {59--79},
  publisher = {Springer Japan},
  address = {Tokyo},
  abstract = {The Building Brains and Bodies approach to the design of task-fulfilling robots is introduced. In this approach, focus is on designing both controller and morphology of robots, and it thereby contrasts most research in adaptive robotics that puts emphasis on design of control exclusively. It is possible to co-evolve robot control and morphology in simulation, and this work suggests that there exists important correlations between different body parameters (e.g. wheel base diameter, body size, and sensory range) in order to achieve optimal performance on specific tasks. The evolved morphology can be constructed with LEGO, and the evolved controller can be downloaded to the LEGO MINDSTORMS RCX. Hence, the experiments suggest a path towards automatic building plans for LEGO MINDSTORMS robots. Further, it is possible to manipulate the morphology in a user-guided approach of building modular LEGO robots, which allow children to construct their own robots within 10 minutes. Finally, the experiments give suggestion to new research on building blocks with processing power.},
  isbn = {978-4-431-67869-4}
}

@article{peng2018deepmimic,
  title = {{{DeepMimic}}: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills},
  shorttitle = {{{DeepMimic}}},
  author = {Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and {van de Panne}, Michiel},
  year = {2018},
  month = aug,
  journal = TOG,
  volume = {37},
  number = {4},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3197517.3201311},
  urldate = {2022-02-16},
  langid = {english},
  keywords = {ObsCite},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\K5JSF8PD\\2018 - TOG - DeepMimic.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@peng2018deepmimic-DeepMimic - example-guided deep reinforcement learning of physics-based.pdf}
}

@article{LiMingLong2019mianxiangzainans,
  title = {},
  author = {{} and {} and {} and {} and {}},
  year = {2019},
  journal = {},
  number = {11},
  pages = {1--9},
  keywords = {ObsCite,team paper},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@LiMingLong2019mianxiangzainans-.pdf}
}

@inproceedings{2021evolving,
  title = {Evolving {{BT-Driven Embodied Intelligence}} with {{Morphology-Behavior Mapping}}},
  booktitle = {{{AAAI2022}}},
  year = {2021},
  keywords = {ObsCite},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\7Q2NDCNT\\Technical Appendix.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@2021evolving-Evolving BT-Driven Embodied Intelligence with Morphology-Behavior Mapping.pdf}
}

@inproceedings{cai2021bt,
  title = {{{BT Expansion}}: A {{Sound}} and {{Complete Algorithm}} for {{Behavior Planning}} of {{Intelligent Robots}} with {{Behavior Trees}}},
  booktitle = AAAI,
  author = {Cai, Zhongxuan and Li, Minglong and Huang, Wanrong and Yang, Wenjing},
  year = {2021},
  pages = {6058--6065},
  publisher = {AAAI Press},
  langid = {english},
  keywords = {ObsCite,team paper},
  annotation = {AAAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@cai2021bt-BT Expansion - a Sound and Complete Algorithm for Behavior Planning of.pdf}
}

@inproceedings{li2021decsgts,
  title = {Dec-{{SGTS}}: {{Decentralized Sub-Goal Tree Search}} for {{Multi-Agent Coordination}}},
  booktitle = AAAI,
  author = {Li, Minglong and Cai, Zhongxuan and Yang, Wenjing and Wu, Lixia and Xu, Yinghui and Wang, Ji},
  year = {2021},
  pages = {8},
  langid = {english},
  keywords = {ObsCite,team paper},
  annotation = {AAAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2021decsgts-Dec-SGTS - Decentralized Sub-Goal Tree Search for Multi-Agent Coordination.pdf}
}

@article{guo2018allianceros,
  title = {{{ALLIANCE-ROS}}: {{A Software Framework}} on {{ROS}} for {{Fault-Tolerant}} and {{Cooperative Mobile Robots}}},
  author = {Guo, Zhongyuan and Yang, Wenjing and Li, Minglong and Yi, Xiaodong and Cai, Zhongxuan and Wang, Yanzhen},
  year = {2018},
  journal = {Chinese Journal of Electronics},
  volume = {27},
  number = {3},
  pages = {467--475},
  publisher = {Wiley Online Library},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@guo2018allianceros-ALLIANCE-ROS - A Software Framework on ROS for Fault-Tolerant and Cooperative.pdf}
}

@article{won2019learning,
  title = {Learning {{Body Shape Variation}} in {{Physics-Based Characters}}},
  author = {Won, Jungdam and Lee, Jehee},
  year = {2019},
  month = nov,
  journal = TOG,
  volume = {38},
  number = {6},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0730-0301},
  doi = {10.1145/3355089.3356499},
  abstract = {Recently, deep reinforcement learning (DRL) has attracted great attention in designing controllers for physics-based characters. Despite the recent success of DRL, the learned controller is viable for a single character. Changes in body size and proportions require learning controllers from scratch. In this paper, we present a new method of learning parametric controllers for body shape variation. A single parametric controller enables us to simulate and control various characters having different heights, weights, and body proportions. The users are allowed to create new characters through body shape parameters, and they can control the characters immediately. Our characters can also change their body shapes on the fly during simulation. The key to the success of our approach includes the adaptive sampling of body shapes that tackles the challenges in learning parametric controllers, which relies on the marginal value function that measures control capabilities of body shapes. We demonstrate parametric controllers for various physically simulated characters such as bipeds, quadrupeds, and underwater animals.},
  keywords = {character animation,deep learning,locomotion control,neural network,physics-based simulation and control,reinforcement learning},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@won2019learning-Learning Body Shape Variation in Physics-Based Characters.pdf}
}

@inproceedings{radosavovic2021stateonly,
  title = {State-{{Only Imitation Learning}} for {{Dexterous Manipulation}}},
  booktitle = IROS,
  author = {Radosavovic, Ilija and Wang, Xiaolong and Pinto, Lerrel and Malik, Jitendra},
  year = {2021},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@radosavovic2021stateonly-State-Only Imitation Learning for Dexterous Manipulation.pdf}
}

@book{zai2020deep,
  title = {Deep Reinforcement Learning in Action},
  author = {Zai, Alexander and Brown, Brandon},
  year = {2020},
  publisher = {Manning Publications},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zai2020deep-Deep reinforcement learning in action.pdf}
}

@book{sutton2018reinforcement,
  title = {Reinforcement Learning: {{An}} Introduction},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {2018},
  publisher = {MIT press},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sutton2018reinforcement-Reinforcement learning - An introduction.pdf}
}

@article{reed2022generalist,
  title = {A Generalist Agent},
  author = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and {Barth-Maron}, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  year = {2022},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@reed2022generalist-A generalist agent.pdf}
}

@inproceedings{spielberg2017functional,
  title = {Functional Co-Optimization of Articulated Robots},
  booktitle = ICRA,
  author = {Spielberg, Andrew and Araki, Brandon and Sung, Cynthia and Tedrake, Russ and Rus, Daniela},
  year = {2017},
  pages = {5035--5042},
  publisher = {IEEE},
  keywords = {ObsCite}
}

@article{silver2021reward,
  title = {Reward Is Enough},
  author = {Silver, David and Singh, Satinder and Precup, Doina and Sutton, Richard S},
  year = {2021},
  journal = AI,
  volume = {299},
  pages = {103535},
  publisher = {Elsevier},
  keywords = {ObsCite}
}

@article{silver2016mastering,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Vedavyas and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy P. and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  year = {2016},
  journal = {Nature},
  volume = {529},
  number = {7587},
  pages = {484--489},
  doi = {10.1038/nature16961},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@silver2016mastering-Mastering the game of Go with deep neural networks and tree search.pdf}
}

@inproceedings{sun2019learning,
  title = {Learning {{Sparse Sharing Architectures}} for {{Multiple Tasks}}},
  booktitle = AAAI,
  author = {Sun, Tianxiang and Shao, Yunfan and Li, Xiaonan and Liu, Pengfei and Yan, Hang and Qiu, Xipeng and Huang, Xuanjing},
  year = {2019},
  month = nov,
  eprint = {1911.05034},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2022-12-01},
  abstract = {Most existing deep multi-task learning models are based on parameter sharing, such as hard sharing, hierarchical sharing, and soft sharing. How choosing a suitable sharing mechanism depends on the relations among the tasks, which is not easy since it is difficult to understand the underlying shared factors among these tasks. In this paper, we propose a novel parameter sharing mechanism, named Sparse Sharing. Given multiple tasks, our approach automatically finds a sparse sharing structure. We start with an over-parameterized base network, from which each task extracts a subnetwork. The subnetworks of multiple tasks are partially overlapped and trained in parallel. We show that both hard sharing and hierarchical sharing can be formulated as particular instances of the sparse sharing framework. We conduct extensive experiments on three sequence labeling tasks. Compared with single-task models and three typical multi-task learning baselines, our proposed approach achieves consistent improvement while requiring fewer parameters.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2019learning-Learning Sparse Sharing Architectures for Multiple Tasks.pdf}
}

@phdthesis{schaff2022neural,
  title = {Neural {{Approaches}} to {{Co-Optimization}} in {{Robotics}}},
  author = {Schaff, Charles},
  year = {2022},
  month = sep,
  eprint = {2209.00579},
  primaryclass = {cs},
  urldate = {2022-10-24},
  abstract = {Robots and intelligent systems that sense or interact with the world are increasingly being used to automate a wide array of tasks. The ability of these systems to complete these tasks depends on a large range of technologies such as the mechanical and electrical parts that make up the physical body of the robot and its sensors, perception algorithms to perceive the environment, and planning and control algorithms to produce meaningful actions. Therefore, it is often necessary to consider the interactions between these components when designing an embodied system. This thesis explores work on the task-driven co-optimization of robotics systems in an end-to-end manner, simultaneously optimizing the physical components of the system with inference or control algorithms directly for task performance. We start by considering the problem of optimizing a beacon-based localization system directly for localization accuracy. Designing such a system involves placing beacons throughout the environment and inferring location from sensor readings. In our work, we develop a deep learning approach to optimize both beacon placement and location inference directly for localization accuracy. We then turn our attention to the related problem of task-driven optimization of robots and their controllers. In our work, we start by proposing a data-efficient algorithm based on multi-task reinforcement learning. Our approach efficiently optimizes both physical design and control parameters directly for task performance by leveraging a design-conditioned controller capable of generalizing over the space of physical designs. We then follow this up with an extension to allow for the optimization over discrete morphological parameters such as the number and configuration of limbs. Finally, we conclude by exploring the fabrication and deployment of optimized soft robots.},
  archiveprefix = {arXiv},
  langid = {english},
  school = {toyota technological institute at chicago},
  keywords = {Computer Science - Robotics,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@schaff2022neural-Neural Approaches to Co-Optimization in Robotics.pdf}
}

@article{piloto2022intuitive,
  title = {Intuitive Physics Learning in a Deep-Learning Model Inspired by Developmental Psychology},
  author = {Piloto, Luis S. and Weinstein, Ari and Battaglia, Peter and Botvinick, Matthew},
  year = {2022},
  month = jul,
  journal = {Nature Human Behaviour},
  volume = {6},
  number = {9},
  pages = {1257--1267},
  issn = {2397-3374},
  doi = {10.1038/s41562-022-01394-8},
  urldate = {2022-10-22},
  abstract = {Abstract             `Intuitive physics' enables our pragmatic engagement with the physical world and forms a key component of `common sense' aspects of thought. Current artificial intelligence systems pale in their understanding of intuitive physics, in comparison to even very young children. Here we address this gap between humans and machines by drawing on the field of developmental psychology. First, we introduce and open-source a machine-learning dataset designed to evaluate conceptual understanding of intuitive physics, adopting the violation-of-expectation (VoE) paradigm from developmental psychology. Second, we build a deep-learning system that learns intuitive physics directly from visual data, inspired by studies of visual cognition in children. We demonstrate that our model can learn a diverse set of physical concepts, which depends critically on object-level representations, consistent with findings from developmental psychology. We consider the implications of these results both for AI and for research on human cognition.},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Users\lenovo\Zotero\storage\6FVKESF8\Piloto_2022_Intuitive physics learning in a deep-learning model inspired by developmental.pdf}
}

@article{schaff2022nlimb,
  title = {N-{{LIMB}}: {{Neural Limb Optimization}} for {{Efficient Morphological Design}}},
  shorttitle = {N-{{LIMB}}},
  author = {Schaff, Charles and Walter, Matthew R.},
  year = {2022},
  month = sep,
  journal = {arXiv},
  eprint = {2207.11773},
  primaryclass = {cs},
  urldate = {2022-10-06},
  abstract = {A robot's ability to complete a task is heavily dependent on its physical design. However, identifying an optimal physical design and its corresponding control policy is inherently challenging. The freedom to choose the number of links, their type, and how they are connected results in a combinatorial design space, and the evaluation of any design in that space requires deriving its optimal controller. In this work, we present N-LIMB, an efficient approach to optimizing the design and control of a robot over large sets of morphologies. Central to our framework is a universal, design-conditioned control policy capable of controlling a diverse sets of designs. This policy greatly improves the sample efficiency of our approach by allowing the transfer of experience across designs and reducing the cost to evaluate new designs. We train this policy to maximize expected return over a distribution of designs, which is simultaneously updated towards higher performing designs under the universal policy. In this way, our approach converges towards a design distribution peaked around high-performing designs and a controller that is effectively fine-tuned for those designs. We demonstrate the potential of our approach on a series of locomotion tasks across varying terrains and show the discovery novel and high-performing design-control pairs.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@schaff2022nlimb-N-LIMB - Neural Limb Optimization for Efficient Morphological Design.pdf}
}

@inproceedings{rudin2021learning,
  title = {Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning},
  booktitle = {Conference on {{Robot Learning}} ({{CoRL}})},
  author = {Rudin, Nikita and Hoeller, David and Reist, Philipp and Hutter, Marco},
  year = {2021},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@rudin2021learning-Learning to walk in minutes using massively parallel deep reinforcement learning.pdf}
}

@inproceedings{todorov2012mujoco,
  title = {{{MuJoCo}}: {{A}} Physics Engine for Model-Based Control},
  booktitle = IROS,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  year = {2012},
  pages = {5026--5033},
  doi = {10.1109/IROS.2012.6386109},
  keywords = {ObsCite}
}

@inproceedings{xie2021dynamics,
  title = {Dynamics Randomization Revisited: {{A}} Case Study for Quadrupedal Locomotion},
  booktitle = ICRA,
  author = {Xie, Zhaoming and Da, Xingye and {van de Panne}, Michiel and Babich, Buck and Garg, Animesh},
  year = {2021},
  pages = {4955--4961},
  publisher = {IEEE},
  doi = {10.1109/ICRA48506.2021.9560837},
  keywords = {ObsCite}
}

@inproceedings{togninalli2019wasserstein,
  title = {Wasserstein {{Weisfeiler}}--{{Lehman}} Graph Kernels},
  booktitle = NeurIPS,
  author = {Togninalli, Matteo and Ghisu, Elisabetta and {Llinares-L{\'o}pez}, Felipe and Rieck, Bastian and Borgwardt, Karsten},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and {d'Alch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  pages = {6436--6446},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@togninalli2019wasserstein-Wasserstein WeisfeilerLehman graph kernels.pdf}
}

@inproceedings{xu2021endtoend,
  title = {An End-to-End Differentiable Framework for Contact-Aware Robot Design},
  booktitle = RSS,
  author = {Xu, Jie and Chen, Tao and Zlokapa, Lara and Foshey, Michael and Matusik, Wojciech and Sueda, Shinjiro and Agrawal, Pulkit},
  editor = {Shell, Dylan A. and Toussaint, Marc and Hsieh, M. Ani},
  year = {2021},
  doi = {10.15607/RSS.2021.XVII.008},
  keywords = {embodied intelligence,ObsCite},
  annotation = {RSS},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\7Q4VGHWY\\Xu_2021_An end-to-end differentiable framework for contact-aware robot design3.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@xu2021endtoend-An end-to-end differentiable framework for contact-aware robot design.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@xu2021endtoend-An end-to-end differentiable framework for contact-aware robot design2.pdf}
}

@article{yu2018learning,
  title = {Learning Symmetric and Low-Energy Locomotion},
  author = {Yu, Wenhao and Turk, Greg and Liu, C. Karen},
  year = {2018},
  month = aug,
  journal = TOG,
  volume = {37},
  number = {4},
  pages = {1--12},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3197517.3201397},
  urldate = {2022-02-28},
  abstract = {Learning locomotion skills is a challenging problem. To generate realistic and smooth locomotion, existing methods use motion capture, finite state machines or morphology-specific knowledge to guide the motion generation algorithms. Deep reinforcement learning (DRL) is a promising approach for the automatic creation of locomotion control. Indeed, a standard benchmark for DRL is to automatically create a running controller for a biped character from a simple reward function [Duan et al. 2016]. Although several different DRL algorithms can successfully create a running controller, the resulting motions usually look nothing like a real runner. This paper takes a minimalist learning approach to the locomotion problem, without the use of motion examples, finite state machines, or morphology-specific knowledge. We introduce two modifications to the DRL approach that, when used together, produce locomotion behaviors that are symmetric, low-energy, and much closer to that of a real person. First, we introduce a new term to the loss function (not the reward function) that encourages symmetric actions. Second, we introduce a new curriculum learning method that provides modulated physical assistance to help the character with left/right balance and forward movement. The algorithm automatically computes appropriate assistance to the character and gradually relaxes this assistance, so that eventually the character learns to move entirely without help. Because our method does not make use of motion capture data, it can be applied to a variety of character morphologies. We demonstrate locomotion controllers for the lower half of a biped, a full humanoid, a quadruped, and a hexapod. Our results show that learned policies are able to produce symmetric, low-energy gaits. In addition, speed-appropriate gait patterns emerge without any guidance from motion examples or contact planning.},
  langid = {english},
  keywords = {ObsCite},
  annotation = {TOG},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2018learning-Learning symmetric and low-energy locomotion.pdf}
}

@article{zhao2020robogrammar,
  title = {{{RoboGrammar}}: Graph Grammar for Terrain-Optimized Robot Design},
  shorttitle = {{{RoboGrammar}}},
  author = {Zhao, Allan and Xu, Jie and {Konakovi{\'c}-Lukovi{\'c}}, Mina and Hughes, Josephine and Spielberg, Andrew and Rus, Daniela and Matusik, Wojciech},
  year = {2020},
  month = dec,
  journal = TOG,
  volume = {39},
  number = {6},
  pages = {1--16},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3414685.3417831},
  urldate = {2022-02-16},
  langid = {english},
  keywords = {core,embodied intelligence,ObsCite},
  annotation = {TOG},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhao2020robogrammar-RoboGrammar - graph grammar for terrain-optimized robot design.pdf}
}

@inproceedings{peng2017learning,
  title = {Learning {{Locomotion Skills Using DeepRL}}: {{Does}} the {{Choice}} of {{Action Space Matter}}?},
  booktitle = SIGGRAPH,
  author = {Peng, Xue Bin and {van de Panne}, Michiel},
  year = {2017},
  series = {{{SCA}} '17},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3099564.3099567},
  abstract = {The use of deep reinforcement learning allows for high-dimensional state descriptors, but little is known about how the choice of action representation impacts learning and the resulting performance. We compare the impact of four different action parameterizations (torques, muscle-activations, target joint angles, and target joint-angle velocities) in terms of learning time, policy robustness, motion quality, and policy query rates. Our results are evaluated on a gait-cycle imitation task for multiple planar articulated figures and multiple gaits. We demonstrate that the local feedback provided by higher-level action parameterizations can significantly impact the learning, robustness, and motion quality of the resulting policies.},
  isbn = {978-1-4503-5091-4},
  keywords = {locomotion skills,motion control,ObsCite,physics-based character animation},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2017learning-Learning Locomotion Skills Using DeepRL - Does the Choice of Action Space Matter.pdf}
}

@article{pateria2021hierarchical,
  title = {Hierarchical Reinforcement Learning: {{A}} Comprehensive Survey},
  author = {Pateria, Shubham and Subagdja, Budhitama and Tan, Ah-hwee and Quek, Chai},
  year = {2021},
  journal = {ACM Computing Surveys (CSUR)},
  volume = {54},
  number = {5},
  pages = {1--35},
  publisher = {ACM New York, NY, USA},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@pateria2021hierarchical-Hierarchical reinforcement learning - A comprehensive survey.pdf}
}

@article{sutton1999mdps,
  title = {Between {{MDPs}} and Semi-{{MDPs}}: {{A}} Framework for Temporal Abstraction in Reinforcement Learning},
  author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
  year = {1999},
  journal = AI,
  volume = {112},
  number = {1},
  pages = {181--211},
  keywords = {ObsCite},
  annotation = {AI},
  file = {C:\Users\lenovo\Zotero\storage\22EB8M79\Sutton_1999_Between MDPs and semi-MDPs.pdf}
}

@article{silver2018general,
  title = {A General Reinforcement Learning Algorithm That Masters Chess, Shogi, and {{Go}} through Self-Play},
  author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
  year = {2018},
  month = dec,
  journal = {Science},
  volume = {362},
  number = {6419},
  pages = {1140--1144},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aar6404},
  urldate = {2022-04-19},
  langid = {english},
  keywords = {ObsCite},
  annotation = {Science},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@silver2018general-A general reinforcement learning algorithm that masters chess, shogi, and Go.pdf}
}

@article{rahwan2019machine,
  title = {Machine Behaviour},
  author = {Rahwan, Iyad and Cebrian, Manuel and Obradovich, Nick and Bongard, Josh and Bonnefon, Jean-Fran{\c c}ois and Breazeal, Cynthia and Crandall, Jacob W. and Christakis, Nicholas A. and Couzin, Iain D. and Jackson, Matthew O. and Jennings, Nicholas R. and Kamar, Ece and Kloumann, Isabel M. and Larochelle, Hugo and Lazer, David and McElreath, Richard and Mislove, Alan and Parkes, David C. and Pentland, Alex `Sandy' and Roberts, Margaret E. and Shariff, Azim and Tenenbaum, Joshua B. and Wellman, Michael},
  year = {2019},
  month = apr,
  journal = {Nature},
  volume = {568},
  number = {7753},
  pages = {477--486},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-1138-y},
  urldate = {2022-03-03},
  langid = {english},
  keywords = {behavior,ObsCite},
  annotation = {Nature},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@rahwan2019machine-Machine behaviour.pdf}
}

@inproceedings{chiappa2022dmap,
  title = {{{DMAP}}: A {{Distributed Morphological Attention Policy}} for Learning to Locomote with a Changing Body},
  booktitle = NeurIPS,
  author = {Chiappa, Alberto and Vargas, Alessandro Marin and Mathis, Alexander},
  editor = {Oh, Alice H. and Agarwal, Alekh and Belgrave, Danielle and Cho, Kyunghyun},
  year = {2022},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chiappa2022dmap-DMAP - a Distributed Morphological Attention Policy for learning to locomote.pdf}
}

@inproceedings{hu2022glso,
  title = {{{GLSO}}: {{Grammar-guided Latent Space Optimization}} for {{Sample-efficient Robot Design Automation}}},
  booktitle = CoRL,
  author = {Hu, Jiaheng and Whitman, Julian and Choset, Howie},
  year = {2022},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hu2022glso-GLSO - Grammar-guided Latent Space Optimization for Sample-efficient Robot.pdf}
}

@inproceedings{martin-martin2019variable,
  title = {Variable Impedance Control in End-Effector Space: {{An}} Action Space for Reinforcement Learning in Contact-Rich Tasks},
  booktitle = IROS,
  author = {{Mart{\'i}n-Mart{\'i}n}, Roberto and Lee, Michelle A and Gardner, Rachel and Savarese, Silvio and Bohg, Jeannette and Garg, Animesh},
  year = {2019},
  pages = {1010--1017},
  publisher = {IEEE},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@martin-martin2019variable-Variable impedance control in end-effector space - An action space for.pdf}
}

@article{ibarz2021how,
  title = {How to Train Your Robot with Deep Reinforcement Learning: Lessons We Have Learned},
  author = {Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
  year = {2021},
  journal = {The International Journal of Robotics Research},
  volume = {40},
  number = {4-5},
  pages = {698--721},
  publisher = {SAGE Publications Sage UK: London, England},
  keywords = {ObsCite},
  file = {D:\Cloud\BaiduSyncdisk\CXL_Big\SoftwareData\zotfile\The International Journal of Robotics Research2021_How to train your robot with deep reinforcement learning - lessons we have @ibarz2021how.pdf}
}

@article{lecun2022path,
  title = {A Path towards Autonomous Machine Intelligence},
  author = {LeCun, Yann},
  year = {2022},
  journal = {preprint posted on openreview},
  keywords = {ObsCite},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@lecun2022path-A path towards autonomous machine intelligence.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@lecun2022path-A path towards autonomous machine intelligence2.pdf}
}

@inproceedings{gupta2017cooperative,
  title = {Cooperative {{Multi-agent Control Using Deep Reinforcement Learning}}},
  booktitle = AAMAS,
  author = {Gupta, Jayesh K. and Egorov, Maxim and Kochenderfer, Mykel},
  editor = {Sukthankar, Gita and {Rodriguez-Aguilar}, Juan A.},
  year = {2017},
  volume = {10642},
  pages = {66--83},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-71682-4_5},
  urldate = {2022-12-01},
  abstract = {This work considers the problem of learning cooperative policies in complex, partially observable domains without explicit communication. We extend three classes of single-agent deep reinforcement learning algorithms based on policy gradient, temporal-difference error, and actor-critic methods to cooperative multi-agent systems. We introduce a set of cooperative control tasks that includes tasks with discrete and continuous actions, as well as tasks that involve hundreds of agents. The three approaches are evaluated against each other using different neural architectures, training procedures, and reward structures. Using deep reinforcement learning with a curriculum learning scheme, our approach can solve problems that were previously considered intractable by most multi-agent reinforcement learning algorithms. We show that policy gradient methods tend to outperform both temporal-difference and actor-critic methods when using feed-forward neural architectures. We also show that recurrent policies, while more difficult to train, outperform feed-forward policies on our evaluation tasks.},
  isbn = {978-3-319-71681-7 978-3-319-71682-4},
  langid = {english},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2017cooperative-Cooperative Multi-agent Control Using Deep Reinforcement Learning.pdf}
}

@article{liu2022goalconditioned,
  title = {Goal-{{Conditioned Reinforcement Learning}}: {{Problems}} and {{Solutions}}},
  shorttitle = {Goal-{{Conditioned Reinforcement Learning}}},
  author = {Liu, Minghuan and Zhu, Menghui and Zhang, Weinan},
  year = {2022},
  month = sep,
  journal = {arXiv},
  eprint = {2201.08299},
  primaryclass = {cs},
  urldate = {2022-11-07},
  abstract = {Goal-conditioned reinforcement learning (GCRL), related to a set of complex RL problems, trains an agent to achieve different goals under particular scenarios. Compared to the standard RL solutions that learn a policy solely depending on the states or observations, GCRL additionally requires the agent to make decisions according to different goals. In this survey, we provide a comprehensive overview of the challenges and algorithms for GCRL. Firstly, we answer what the basic problems are studied in this field. Then, we explain how goals are represented and present how existing solutions are designed from different points of view. Finally, we make the conclusion and discuss potential future prospects that recent researches focus on.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2022goalconditioned-Goal-Conditioned Reinforcement Learning - Problems and Solutions.pdf}
}

@inproceedings{ha2017joint,
  title = {{Joint optimization of robot design and motion parameters using the implicit function theorem}},
  booktitle = RSS,
  author = {Ha, Sehoon and Coros, Stelian and Alspach, Alexander and Kim, Joohyung and Yamane, Katsu},
  editor = {Srinivasa, Siddhartha and Ayanian, Nora and Amato, Nancy and Kuindersma, Scott},
  year = {2017},
  month = jan,
  series = {{Robotics: Science and Systems}},
  publisher = {MIT Press Journals},
  address = {United States},
  doi = {10.15607/rss.2017.xiii.003},
  abstract = {We present a novel computational approach to optimizing the morphological design of robots. Our framework takes as input a parameterized robot design and a motion plan consisting of trajectories for end-effectors, as well as optionally, for its body. The algorithm we propose is used to optimize design parameters, namely link lengths and the placement of actuators, while concurrently adjusting motion parameters such as joint trajectories, actuator inputs, and contact forces. Our key insight is that the complex relationship between design and motion parameters can be established via sensitivity analysis if the robot's movements are modeled as spatio-temporal solutions to optimal control problems. This relationship between form and function allows us to automatically optimize robot designs based on specifications expressed as a function of range of motion or actuator forces. We evaluate our model by computationally optimizing two simulated robots that employ linear actuators: a manipulator and a large quadruped. We further validate our framework by optimizing the design of a small quadrupedal robot and testing its performance using a hardware implementation.},
  langid = {English (US)},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ha2017joint-Joint optimization of robot design and motion parameters using the implicit.pdf}
}

@inproceedings{jain2019hierarchical,
  title = {Hierarchical {{Reinforcement Learning}} for {{Quadruped Locomotion}}},
  booktitle = IROS,
  author = {Jain, Deepali and Iscen, Atil and Caluwaerts, Ken},
  year = {2019},
  month = nov,
  pages = {7551--7557},
  publisher = {IEEE},
  address = {Macau, China},
  doi = {10.1109/IROS40897.2019.8967913},
  urldate = {2022-02-28},
  isbn = {978-1-72814-004-9},
  langid = {english},
  keywords = {ObsCite},
  annotation = {IROS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jain2019hierarchical-Hierarchical Reinforcement Learning for Quadruped Locomotion.pdf}
}

@inproceedings{li2020learning,
  title = {Learning {{Generalizable Locomotion Skills}} with {{Hierarchical Reinforcement Learning}}},
  booktitle = ICRA,
  author = {Li, Tianyu and Lambert, Nathan and Calandra, Roberto and Meier, Franziska and Rai, Akshara},
  year = {2020},
  month = may,
  pages = {413--419},
  publisher = {IEEE},
  address = {Paris, France},
  doi = {10.1109/ICRA40945.2020.9196642},
  urldate = {2022-02-28},
  abstract = {Learning to locomote to arbitrary goals on hardware remains a challenging problem for reinforcement learning. In this paper, we present a hierarchical framework that improves sample-efficiency and generalizability of learned locomotion skills on real-world robots. Our approach divides the problem of goal-oriented locomotion into two sub-problems: learning diverse primitives skills, and using model-based planning to sequence these skills. We parametrize our primitives as cyclic movements, improving sample-efficiency of learning from scratch on a 18 degrees of freedom robot. Then, we learn coarse dynamics models over primitive cycles and use them in a model predictive control framework. This allows us to learn to walk to arbitrary goals up to 12m away, after about two hours of training from scratch on hardware. Our results on a Daisy hexapod hardware and simulation demonstrate the efficacy of our approach at reaching distant targets, in different environments, and with sensory noise.},
  isbn = {978-1-72817-395-5},
  langid = {english},
  keywords = {ObsCite},
  annotation = {ICRA},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2020learning-Learning Generalizable Locomotion Skills with Hierarchical Reinforcement.pdf}
}

@article{dietterich2000hierarchical,
  title = {Hierarchical Reinforcement Learning with the {{MAXQ}} Value Function Decomposition},
  author = {Dietterich, Thomas G.},
  year = {2000},
  month = nov,
  journal = JAIR,
  volume = {13},
  number = {1},
  pages = {227--303},
  issn = {1076-9757},
  keywords = {ObsCite}
}

@article{bartolozzi2022embodied,
  title = {Embodied Neuromorphic Intelligence},
  author = {Bartolozzi, Chiara and Indiveri, Giacomo and Donati, Elisa},
  year = {2022},
  month = dec,
  journal = NC,
  volume = {13},
  number = {1},
  pages = {1024},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-28487-2},
  urldate = {2022-05-03},
  abstract = {Abstract             The design of robots that interact autonomously with the environment and exhibit complex behaviours is an open challenge that can benefit from understanding what makes living beings fit to act in the world. Neuromorphic engineering studies neural computational principles to develop technologies that can provide a computing substrate for building compact and low-power processing systems. We discuss why endowing robots with neuromorphic technologies -- from perception to motor control -- represents a promising approach for the creation of robots which can seamlessly integrate in society. We present initial attempts in this direction, highlight open challenges, and propose actions required to overcome current limitations.},
  langid = {english},
  keywords = {ObsCite},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@bartolozzi2022embodied-Embodied neuromorphic intelligence.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@bartolozzi2022embodied-Embodied neuromorphic intelligence2.pdf}
}

@inproceedings{chiang2020factor,
  title = {Factor Graph Grammars},
  booktitle = NeurIPS,
  author = {Chiang, David and Riley, Darcey},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.},
  year = {2020},
  volume = {33},
  pages = {6648--6658},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite,TBD},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chiang2020factor-Factor graph grammars.pdf}
}

@inproceedings{chi2021tohan,
  title = {{{TOHAN}}: {{A One-step Approach}} towards {{Few-shot Hypothesis Adaptation}}},
  shorttitle = {{{TOHAN}}},
  booktitle = NeurIPS,
  author = {Chi, Haoang and Liu, Feng and Yang, Wenjing and Lan, Long and Liu, Tongliang and Han, Bo and Cheung, William K. and Kwok, James T.},
  year = {2021},
  month = jun,
  urldate = {2022-03-03},
  langid = {english},
  keywords = {ObsCite,team paper},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chi2021tohan-TOHAN - A One-step Approach towards Few-shot Hypothesis Adaptation.pdf}
}

@inproceedings{bhatia2021evolution,
  title = {Evolution {{Gym}}: {{A Large-Scale Benchmark}} for {{Evolving Soft Robots}}},
  booktitle = NeurIPS,
  author = {Bhatia, Jagdeep Singh and Jackson, Holly and Tian, Yunsheng and Xu, Jie and Matusik, Wojciech},
  year = {2021},
  pages = {14},
  abstract = {Both the design and control of a robot play equally important roles in its task performance. However, while optimal control is well studied in the machine learning and robotics community, less attention is placed on finding the optimal robot design. This is mainly because co-optimizing design and control in robotics is characterized as a challenging problem, and more importantly, a comprehensive evaluation benchmark for co-optimization does not exist. In this paper, we propose Evolution Gym, the first large-scale benchmark for co-optimizing the design and control of soft robots. In our benchmark, each robot is composed of different types of voxels (e.g., soft, rigid, actuators), resulting in a modular and expressive robot design space. Our benchmark environments span a wide range of tasks, including locomotion on various types of terrains and manipulation. Furthermore, we develop several robot co-evolution algorithms by combining state-of-the-art design optimization methods and deep reinforcement learning techniques. Evaluating the algorithms on our benchmark platform, we observe robots exhibiting increasingly complex behaviors as evolution progresses, with the best evolved designs solving many of our proposed tasks. Additionally, even though robot designs are evolved autonomously from scratch without prior knowledge, they often grow to resemble existing natural creatures while outperforming hand-designed robots. Nevertheless, all tested algorithms fail to find robots that succeed in our hardest environments. This suggests that more advanced algorithms are required to explore the high-dimensional design space and evolve increasingly intelligent robots -- an area of research in which we hope Evolution Gym will accelerate progress. Our website with code, environments, documentation, and tutorials is available at http://evogym.csail.mit.edu.},
  langid = {english},
  keywords = {ObsCite},
  annotation = {NeurIPS},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bhatia2021evolution-Evolution Gym - A Large-Scale Benchmark for Evolving Soft Robots.pdf}
}

@article{fikes1971strips,
  title = {{{STRIPS}}: {{A}} New Approach to the Application of Theorem Proving to Problem Solving},
  shorttitle = {Strips},
  author = {Fikes, Richard E. and Nilsson, Nils J.},
  year = {1971},
  month = dec,
  journal = AI,
  volume = {2},
  number = {3-4},
  pages = {189--208},
  issn = {00043702},
  doi = {10.1016/0004-3702(71)90010-5},
  urldate = {2022-03-03},
  abstract = {We describe a newproblem solver called STRIPS that attempts to find a sequence of operators in a spcce o f world models to transform a given initial world model into a model in which a given goal formula can be proven to be true. STRIPS represents a world n,{\textasciitilde}del as an arbitrary collection o f first-order predicate calculus formulas and is designed to work with .models consisting of large numbers o f formulas. It employs a resolution theorem prover to answer questions o fparticular models and uses means-ends analysis to guide it to the desired goal-satisfying model.},
  langid = {english},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@fikes1971strips-STRIPS - A new approach to the application of theorem proving to problem solving.pdf}
}

@inproceedings{parr1997reinforcement,
  title = {Reinforcement {{Learning}} with {{Hierarchies}} of {{Machines}}},
  booktitle = NeurIPS,
  author = {Parr, Ronald and Russell, Stuart},
  editor = {Jordan, M. and Kearns, M. and Solla, S.},
  year = {1997},
  volume = {10},
  publisher = {MIT Press},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@parr1997reinforcement-Reinforcement Learning with Hierarchies of Machines.pdf}
}

@inproceedings{makoviychuk2021isaac,
  title = {Isaac {{Gym}}: {{High Performance GPU Based Physics Simulation For Robot Learning}}},
  booktitle = NeurIPS,
  author = {Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and State, Gavriel},
  year = {2021},
  pages = {12},
  abstract = {Isaac Gym offers a high performance learning platform to train policies for a wide variety of robotics tasks entirely on GPU. Both physics simulation and neural network policy training reside on GPU and communicate by directly passing data from physics buffers to PyTorch tensors without ever going through CPU bottlenecks. This leads to blazing fast training times for complex robotics tasks on a single GPU with 2-3 orders of magnitude improvements compared to conventional RL training that uses a CPU based simulator and GPUs for neural networks. We host the results and videos at https://sites.google. com/view/isaacgym-nvidia and Isaac Gym can be downloaded at https: //developer.nvidia.com/isaac-gym. The benchmark and environments are available at https://github.com/NVIDIA-Omniverse/IsaacGymEnvs.},
  langid = {english},
  keywords = {ObsCite},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@makoviychuk2021isaac-Isaac Gym - High Performance GPU Based Physics Simulation For Robot Learning.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@makoviychuk2021isaac-Isaac Gym - High Performance GPU Based Physics Simulation For Robot Learning2.pdf}
}

@inproceedings{panda2021nastransfer,
  title = {{{NASTransfer}}: {{Analyzing Architecture Transferability}} in {{Large Scale Neural Architecture Search}}},
  booktitle = AAAI,
  author = {Panda, Rameswar and Merler, Michele and Jaiswal, Mayoore S and Wu, Hui and Ramakrishnan, Kandan and Finkler, Ulrich and Chen, Chun-Fu Richard and Cho, Minsik and Feris, Rogerio and Kung, David and Bhattacharjee, Bishwaranjan},
  year = {2021},
  pages = {9},
  langid = {english},
  keywords = {ObsCite,transfer},
  annotation = {AAAI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@panda2021nastransfer-NASTransfer - Analyzing Architecture Transferability in Large Scale Neural.pdf}
}

@inproceedings{bai2017efficient,
  title = {Efficient {{Reinforcement Learning}} with {{Hierarchies}} of {{Machines}} by {{Leveraging Internal Transitions}}},
  booktitle = IJCAI,
  author = {Bai, Aijun and Russell, Stuart},
  year = {2017},
  pages = {1418--1424},
  doi = {10.24963/ijcai.2017/196},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bai2017efficient-Efficient Reinforcement Learning with Hierarchies of Machines by Leveraging.pdf}
}

@article{auerbach2014environmental,
  title = {Environmental Influence on the Evolution of Morphological Complexity in Machines},
  author = {Auerbach, Joshua E and Bongard, Josh C},
  year = {2014},
  journal = {PLoS computational biology},
  volume = {10},
  number = {1},
  pages = {e1003399},
  publisher = {Public Library of Science San Francisco, USA},
  keywords = {ObsCite}
}

@article{honerkamp2021learning,
  title = {Learning {{Kinematic Feasibility}} for {{Mobile Manipulation Through Deep Reinforcement Learning}}},
  author = {Honerkamp, Daniel and Welschehold, Tim and Valada, Abhinav},
  year = {2021},
  month = oct,
  journal = RA-L,
  volume = {6},
  number = {4},
  pages = {6289--6296},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3092685},
  abstract = {Mobile manipulation tasks remain one of the critical challenges for the widespread adoption of autonomous robots in both service and industrial scenarios. While planning approaches are good at generating feasible whole-body robot trajectories, they struggle with dynamic environments as well as the incorporation of constraints given by the task and the environment. On the other hand, dynamic motion models in the action space struggle with generating kinematically feasible trajectories for mobile manipulation actions. We propose a deep reinforcement learning approach to learn feasible dynamic motions for a mobile base while the end-effector follows a trajectory in task space generated by an arbitrary system to fulfill the task at hand. This modular formulation has several benefits: it enables us to readily transform a broad range of end-effector motions into mobile applications, it allows us to use the kinematic feasibility of the end-effector trajectory as a dense reward signal and its modular formulation allows it to generalise to unseen end-effector motions at test time. We demonstrate the capabilities of our approach on multiple mobile robot platforms with different kinematic abilities and different types of wheeled platforms in extensive simulated as well as real-world experiments.},
  keywords = {Collision avoidance,End effectors,Kinematics,Mobile manipulation,Planning,reinforcement learning,Robots,Task analysis,Trajectory},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@honerkamp2021learning-Learning Kinematic Feasibility for Mobile Manipulation Through Deep.pdf}
}

@inproceedings{huang2020one,
  title = {One Policy to Control Them All: {{Shared}} Modular Policies for Agent-Agnostic Control},
  booktitle = ICML,
  author = {Huang, Wenlong and Mordatch, Igor and Pathak, Deepak},
  year = {2020},
  pages = {4455--4464},
  keywords = {core,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2020one-One policy to control them all - Shared modular policies for agent-agnostic.pdf}
}

@article{whitman2021learning,
  title = {Learning Modular Robot Control Policies},
  author = {Whitman, Julian and Travers, Matthew and Choset, Howie},
  year = {2021},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@whitman2021learning-Learning modular robot control policies.pdf}
}

@article{wu2017posture,
  title = {Posture Self-Stabilizer of a Biped Robot Based on Training Platform and Reinforcement Learning},
  author = {Wu, Weiguo and Gao, Liyang},
  year = {2017},
  month = dec,
  journal = {Robotics and Autonomous Systems},
  volume = {98},
  pages = {42--55},
  issn = {0921-8890},
  doi = {10.1016/j.robot.2017.09.001},
  urldate = {2023-05-24},
  abstract = {In order to solve the problem of stability control for biped robots, the concept of stability training is proposed by using a training platform to exert random disturbance with amplitude limitation on robots that are to be trained. In this work, an approach to achieve a posture stabilizing capability based on stability training and reinforcement learning is explored and verified by simulations. An automatic abstraction method for state space is proposed by using the Gauss basis function and inner evaluation indexes to speed up the learning process. Hierarchical structure stabilizer using the Monte Carlo method is designed according to the concept of variable ZMP. Training samples are extracted from the state transition of the stability training process using balance controllers based on the robot dynamic model. The stabilizers are trained with and without applying the automatic abstraction of state space. Then simulation tests of them are conducted under conditions where the training platform exerts amplitude-limited random disturbances on the robot. Also, the influence of the model errors is studied by introducing deviations of the CoM position during the simulation tests. By comparing the simulation results of two learning stabilizers and the model-based balance controller, it is demonstrated that the designed stabilizer can achieve approximate success rate of the ideal model-based balance controller and exert all the driving ability of the robot under the large disturbance condition of {\textpm}30{$^\circ$} inclination of the platform. Also, the effects of the model error can be overcome by retraining using state transition data with the model error.},
  langid = {english},
  keywords = {Evolutionary robotics,Learning and adaptive systems,Legged robots,Self-stabilizer,Stability training,State space automatic abstraction},
  file = {C:\Users\lenovo\Zotero\storage\WDLKNQHV\S0921889017301550.html}
}

@article{yang2018learning,
  title = {Learning {{Flexible}} and {{Reusable Locomotion Primitives}} for a {{Microrobot}}},
  author = {Yang, Brian and Wang, Grant and Calandra, Roberto and Contreras, Daniel and Levine, Sergey and Pister, Kristofer},
  year = {2018},
  month = jul,
  journal = RA-L,
  volume = {3},
  number = {3},
  pages = {1904--1911},
  issn = {2377-3766},
  doi = {10.1109/LRA.2018.2806083},
  abstract = {The design of gaits for robot locomotion can be a daunting process, which requires significant expert knowledge and engineering. This process is even more challenging for robots that do not have an accurate physical model, such as compliant or micro-scale robots. Data-driven gait optimization provides an automated alternative to analytical gait design. In this letter, we propose a novel approach to efficiently learn a wide range of locomotion tasks with walking robots. This approach formalizes locomotion as a contextual policy search task to collect data, and subsequently uses that data to learn multiobjective locomotion primitives that can be used for planning. As a proof-of-concept we consider a simulated hexapod modeled after a recently developed microrobot, and we thoroughly evaluate the performance of this microrobot on different tasks and gaits. Our results validate the proposed controller and learning scheme on single and multiobjective locomotion tasks. Moreover, the experimental simulations show that without any prior knowledge about the robot used (e.g., dynamics model), our approach is capable of learning locomotion primitives within 250 trials and subsequently using them to successfully navigate through a maze.},
  keywords = {Bayes methods,Learning and adaptive systems,Legged locomotion,legged robots,micro/nano robots,Optimization,Oscillators,Solid modeling,Task analysis},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2018learning-Learning Flexible and Reusable Locomotion Primitives for a Microrobot.pdf}
}

@inproceedings{cao2021more,
  title = {Towards a More Practical Data-Driven Biped Walking Control},
  booktitle = {International {{Conference}} on {{Robotics}} and {{Biomimetics}} ({{ROBIO}})},
  author = {Cao, Zhiyan and Bao, Tianxu and Jia, Wenchuan and Ma, Shugen and Yuan, Jianjun},
  year = {2021},
  month = dec,
  pages = {1058--1064},
  doi = {10.1109/ROBIO54168.2021.9739501},
  abstract = {Walking motion is a fundamental skill involved in daily bipedal activities. Generating the walking motion from mocap data requires a controllable and responsive character in both animation and robotics. The physic-based data-driven technologies nowadays have shown great value in the motion imitation of captured walking data. In this paper, we propose a new data-driven bipedal control framework by adjusting the mocap data with physics-based model to achieve a robust and natural performance while keeps the style of the data as complete as possible. In our framework, the desired bipedal action is designed from the balance strategy and a cascaded position-velocity control with gravity compensation is proposed for joint tracking control of the desired action. We demonstrate the effectiveness of this framework through different external perturbation tests. This framework more fully integrates the original data into desired-action design while keeps a robust and stable performance in the simulation.},
  keywords = {Animation,Data models,Humanoid robots,Legged locomotion,Perturbation methods,Simulation,Tracking}
}

@article{walter2007ground,
  title = {Ground Forces Applied by Galloping Dogs},
  author = {Walter, Rebecca M and Carrier, David R},
  year = {2007},
  journal = {Journal of Experimental Biology},
  volume = {210},
  number = {2},
  pages = {208--216},
  publisher = {Company of Biologists},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@walter2007ground-Ground forces applied by galloping dogs.pdf}
}

@inproceedings{sunada1994coordinated,
  title = {A Coordinated {{Jacobian}} Transpose Control for Mobile Multi-Limbed Robotic Systems},
  booktitle = ICRA,
  author = {Sunada, C. and Argaez, D. and Dubowsky, S. and Mavroidis, C.},
  year = {1994},
  month = may,
  pages = {1910-1915 vol.3},
  doi = {10.1109/ROBOT.1994.351182},
  abstract = {This analytic and experimental study proposes a control algorithm based on Jacobian control for coordinated position and force control for autonomous multi-limbed mobile robotic systems. The technique is called coordinated Jacobian transpose control, or CJTC. Such position/force control algorithms will be required if future robotic systems are to operate effectively in unstructured environments. Generalized control variables, GCV's, express in a consistent and coordinated manner the desired behavior of the forces exerted by the multi-limbed robot on the environment and a system's motions. The effectiveness of this algorithm is demonstrated in simulation and laboratory experiments on a climbing system.{$<>$}},
  keywords = {Control systems,Displacement control,Force control,Impedance,Jacobian matrices,Manipulators,Mechanical variables control,Mobile robots,Motion control,ObsCite,Robot kinematics},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sunada1994coordinated-A coordinated Jacobian transpose control for mobile multi-limbed robotic systems.pdf}
}

@inproceedings{shang2020active,
  title = {Active {{Impact Motion}} for a {{Quadruped Robot}}},
  booktitle = {International {{Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Shang, Linlin and Wang, Wei and Yi, Jianqiang},
  year = {2020},
  pages = {1049--1055},
  doi = {10.1109/CASE48305.2020.9216772},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@shang2020active-Active Impact Motion for a Quadruped Robot.pdf}
}

@article{pratt2001virtual,
  title = {Virtual Model Control: {{An}} Intuitive Approach for Bipedal Locomotion},
  author = {Pratt, Jerry and Chew, Chee-Meng and Torres, Ann and Dilworth, Peter and Pratt, Gill},
  year = {2001},
  journal = {The International Journal of Robotics Research},
  volume = {20},
  number = {2},
  pages = {129--143},
  publisher = {SAGE Publications},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@pratt2001virtual-Virtual model control - An intuitive approach for bipedal locomotion.pdf}
}

@book{paul1981robot,
  title = {Robot Manipulators: Mathematics, Programming, and Control: The Computer Control of Robot Manipulators},
  author = {Paul, Richard P},
  year = {1981},
  publisher = {Richard Paul},
  keywords = {ObsCite}
}

@phdthesis{peng2017developing,
  title = {Developing Locomotion Skills with Deep Reinforcement Learning},
  author = {Peng, Xue Bin},
  year = {2017},
  school = {University of British Columbia},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2017developing-Developing locomotion skills with deep reinforcement learning.pdf}
}

@article{khan2023review,
  title = {A Review on Gait Generation of the Biped Robot on Various Terrains},
  author = {Khan, Moh Shahid and Mandava, Ravi Kumar},
  year = {2023},
  month = jun,
  journal = {Robotica},
  volume = {41},
  number = {6},
  pages = {1888--1930},
  publisher = {Cambridge University Press},
  issn = {0263-5747, 1469-8668},
  doi = {10.1017/S0263574723000097},
  urldate = {2023-05-23},
  abstract = {Day by day, biped robots' usage is increasing enormously in all industrial and non-industrial applications due to their ability to move in any unstructured environment compared to wheeled robots. Keeping this in mind, worldwide, many researchers are working on various aspects of biped robots, such as gait generation, dynamic balance margin, and the design of controllers. The main aim of this review article is to discuss the main challenges encountered in the biped gait generation and design of various controllers while moving on different terrain conditions such as flat, ascending and descending slopes or stairs, avoiding obstacles/ditches, uneven terrain, and an unknown environment. As per the authors' knowledge, no single study has been carried out in one place related to the gait generation and design of controllers for each joint of the biped robot on various terrains. This review will help researchers working in this field better understand the concepts of gait generation, dynamic balance margin, and the design of controllers while moving on various terrains. Moreover, the current article will also cover the different soft computing techniques used to tune the gains of the controllers. In this article, the authors have reviewed a vast compilation of research work on the gait generation of the biped robot on various terrains. Further, the authors have proposed taxonomies on various design issues identified while generating the gait in different aspects. The authors reviewed approximately 296 articles and discovered that all researchers attempted to generate the dynamically balanced biped gait on various terrains.},
  langid = {english},
  keywords = {biped robot,controllers,DBM,gait generation,ObsCite,review,soft computing techniques,ZMP},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@khan2023review-A review on gait generation of the biped robot on various terrains.pdf}
}

@inproceedings{liu2023biped,
  title = {A {{Biped Robot Learning}} to {{Walk}} like {{Human}} by {{Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Advanced Information Science}} and {{System}}},
  author = {Liu, Yi and An, Honglei and Ma, Hongxu},
  year = {2023},
  month = jan,
  series = {{{AISS}} '22},
  pages = {1--5},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3573834.3574484},
  urldate = {2023-05-23},
  abstract = {It's challenging to make a biped robot walk like a human. Many researches have been made such as gait planning, stable walking controller and so on and achieve great progress. Reinforcement learning methods are used in biped robots recently due to their powerful ability to deal with high-dimensional computing problem. However, it's hard to design good reward function to guide the robot to walk and behavior like human. This paper builds a biped robot model and presents a control framework of reinforcement learning based on Isaac Gym simulation platform. The designed reward function considers the velocity tracking, the symmetry of hip angle and leg lifting to simulate human motion. The training process only lasts for 2 hours from the very beginning. The results show that after training the biped robot has a good performance of velocity tracking and attitude control and shows good symmetries in joint angles especially in hip. The results also prove the designed reward function is effective and hopeful to be available on other applications.},
  isbn = {978-1-4503-9793-3},
  keywords = {biped robot,ObsCite,reinforcement learning,reword function,symmetry}
}

@inproceedings{levine2014learning,
  title = {Learning {{Neural Network Policies}} with {{Guided Policy Search}} under {{Unknown Dynamics}}},
  booktitle = NeurIPS,
  author = {Levine, Sergey and Abbeel, Pieter},
  editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K. Q.},
  year = {2014},
  volume = {27},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@levine2014learning-Learning Neural Network Policies with Guided Policy Search under Unknown.pdf}
}

@inproceedings{ng1999policy,
  title = {Policy Invariance under Reward Transformations: {{Theory}} and Application to Reward Shaping},
  booktitle = ICML,
  author = {Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  year = {1999},
  volume = {99},
  pages = {278--287},
  publisher = {Citeseer},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ng1999policy-Policy invariance under reward transformations - Theory and application to.pdf}
}

@article{coros2011locomotion,
  title = {Locomotion {{Skills}} for {{Simulated Quadrupeds}}},
  author = {Coros, Stelian and Karpathy, Andrej and Jones, Ben and Reveret, Lionel and Panne, Michiel},
  year = {2011},
  month = jul,
  journal = TOG,
  volume = {30},
  pages = {59},
  doi = {10.1145/2010324.1964954},
  abstract = {We develop an integrated set of gaits and skills for a physics-based simulation of a quadruped. The motion repertoire for our simulated dog includes walk, trot, pace, canter, transverse gallop, rotary gallop, leaps capable of jumping on-and-off platforms and over obstacles, sitting, lying down, standing up, and getting up from a fall. The controllers use a representation based on gait graphs, a dual leg frame model, a flexible spine model, and the extensive use of internal virtual forces applied via the Jacobian transpose. Optimizations are applied to these control abstractions in order to achieve robust gaits and leaps with desired motion styles. The resulting gaits are evaluated for robustness with respect to push disturbances and the traversal of variable terrain. The simulated motions are also compared to motion data captured from a filmed dog.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@coros2011locomotion-Locomotion Skills for Simulated Quadrupeds.pdf}
}

@inproceedings{cheng2021heuristicguided,
  title = {Heuristic-{{Guided Reinforcement Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Cheng, Ching-An and Kolobov, Andrey and Swaminathan, Adith},
  editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P. S. and Vaughan, J. Wortman},
  year = {2021},
  volume = {34},
  pages = {13550--13563},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@cheng2021heuristicguided-Heuristic-Guided Reinforcement Learning.pdf}
}

@inproceedings{roos2019explainable,
  title = {Explainable {{Robotics Applied}} to {{Bipedal Walking Gait Development}}.},
  booktitle = {{{BNAIC}}/{{BENELEARN}}},
  author = {Roos, Nico and Sun, Zhenglong},
  year = {2019},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@roos2019explainable-Explainable Robotics Applied to Bipedal Walking Gait Development.pdf}
}

@article{power2021keep,
  title = {Keep It Simple: {{Data-efficient}} Learning for Controlling Complex Systems with Simple Models},
  author = {Power, Thomas and Berenson, Dmitry},
  year = {2021},
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {1184--1191},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@power2021keep-Keep it simple - Data-efficient learning for controlling complex systems with.pdf}
}

@inproceedings{yin2007simbicon,
  title = {{{SIMBICON}}: Simple Biped Locomotion Control},
  shorttitle = {{{SIMBICON}}},
  booktitle = SIGGRAPH,
  author = {Yin, KangKang and Loken, Kevin and {van de Panne}, Michiel},
  year = {2007},
  month = jul,
  series = {{{SIGGRAPH}} '07},
  pages = {105--es},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1275808.1276509},
  urldate = {2023-05-18},
  abstract = {Physics-based simulation and control of biped locomotion is difficult because bipeds are unstable, underactuated, high-dimensional dynamical systems. We develop a simple control strategy that can be used to generate a large variety of gaits and styles in real-time, including walking in all directions (forwards, backwards, sideways, turning), running, skipping, and hopping. Controllers can be authored using a small number of parameters, or their construction can be informed by motion capture data. The controllers are applied to 2D and 3D physically-simulated character models. Their robustness is demonstrated with respect to pushes in all directions, unexpected steps and slopes, and unexpected variations in kinematic and dynamic parameters. Direct transitions between controllers are demonstrated as well as parameterized control of changes in direction and speed. Feedback-error learning is applied to learn predictive torque models, which allows for the low-gain control that typifies many natural motions as well as producing smoother simulated motion.},
  isbn = {978-1-4503-7836-9},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yin2007simbicon-SIMBICON - simple biped locomotion control.pdf}
}

@article{peng2022ase,
  title = {{{ASE}}: {{Large-Scale Reusable Adversarial Skill Embeddings}} for {{Physically Simulated Characters}}},
  author = {Peng, Xue Bin and Guo, Yunrong and Halper, Lina and Levine, Sergey and Fidler, Sanja},
  year = {2022},
  month = jul,
  journal = TOG,
  volume = {41},
  number = {4},
  issn = {0730-0301},
  doi = {10.1145/3528223.3530110},
  abstract = {The incredible feats of athleticism demonstrated by humans are made possible in part by a vast repertoire of general-purpose motor skills, acquired through years of practice and experience. These skills not only enable humans to perform complex tasks, but also provide powerful priors for guiding their behaviors when learning new tasks. This is in stark contrast to what is common practice in physics-based character animation, where control policies are most typically trained from scratch for each task. In this work, we present a large-scale data-driven framework for learning versatile and reusable skill embeddings for physically simulated characters. Our approach combines techniques from adversarial imitation learning and unsupervised reinforcement learning to develop skill embeddings that produce life-like behaviors, while also providing an easy to control representation for use on new downstream tasks. Our models can be trained using large datasets of unstructured motion clips, without requiring any task-specific annotation or segmentation of the motion data. By leveraging a massively parallel GPU-based simulator, we are able to train skill embeddings using over a decade of simulated experiences, enabling our model to learn a rich and versatile repertoire of skills. We show that a single pre-trained model can be effectively applied to perform a diverse set of new tasks. Our system also allows users to specify tasks through simple reward functions, and the skill embedding then enables the character to automatically synthesize complex and naturalistic strategies in order to achieve the task objectives.},
  keywords = {adversarial imitation learning,character animation,ObsCite,reinforcement learning,unsupervised reinforcement learning},
  annotation = {},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2022ase-ASE - Large-Scale Reusable Adversarial Skill Embeddings for Physically Simulated.pdf}
}

@inproceedings{levine2013guided,
  title = {Guided {{Policy Search}}},
  booktitle = ICML,
  author = {Levine, Sergey and Koltun, Vladlen},
  year = {2013},
  month = jun,
  abstract = {Direct policy search can effectively scale to high-dimensional systems, but complex policies with hundreds of parameters often present a challenge for such methods, requiring numerous samples and often falling into poor local optima. We present a guided policy search algorithm that uses trajectory optimization to direct policy learning and avoid poor local optima. We show how differential dynamic programming can be used to generate suitable guiding samples, and describe a regularized importance sampled policy optimization that incorporates these samples into the policy search. We evaluate the method by learning neural network controllers for planar swimming, hopping, and walking, as well as simulated 3D humanoid running.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@levine2013guided-Guided Policy Search.pdf}
}

@inproceedings{li2019offline,
  title = {Offline Policy Iteration Based Reinforcement Learning Controller for Online Robotic Knee Prosthesis Parameter Tuning},
  booktitle = ICRA,
  author = {Li, Minhan and Gao, Xiang and Wen, Yue and Si, Jennie and Huang, He Helen},
  year = {2019},
  pages = {2831--2837},
  doi = {10.1109/ICRA.2019.8794212},
  keywords = {ObsCite},
  annotation = { FSM  RL },
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2019offline-Offline policy iteration based reinforcement learning controller for online.pdf}
}

@inproceedings{park2022generative,
  title = {Generative {{GaitNet}}},
  booktitle = SIGGRAPH,
  author = {Park, Jungnam and Min, Sehee and Chang, Phil Sik and Lee, Jaedong and Park, Moon Seok and Lee, Jehee},
  year = {2022},
  series = {{{SIGGRAPH}} '22},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3528233.3530717},
  abstract = {Understanding the relation between anatomy and gait is key to successful predictive gait simulation. In this paper, we present Generative GaitNet, which is a novel network architecture based on deep reinforcement learning for controlling a comprehensive, full-body, musculoskeletal model with 304 Hill-type musculotendons. The Generative GaitNet is a pre-trained, integrated system of artificial neural networks learned in a 618-dimensional continuous domain of anatomy conditions (e.g., mass distribution, body proportion, bone deformity, and muscle deficits) and gait conditions (e.g., stride and cadence). The pre-trained GaitNet takes anatomy and gait conditions as input and generates a series of gait cycles appropriate to the conditions through physics-based simulation. We will demonstrate the efficacy and expressive power of Generative GaitNet to generate a variety of healthy and pathological human gaits in real-time physics-based simulation.},
  isbn = {978-1-4503-9337-9},
  keywords = {Clinical Gait Analysis,GaitNet,Musculoskeletal Simulation,ObsCite,Predictive Gait Simulation},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@park2022generative-Generative GaitNet.pdf}
}

@article{bonyadi2017particle,
  title = {Particle {{Swarm Optimization}} for {{Single Objective Continuous Space Problems}}: {{A Review}}},
  author = {Bonyadi, Mohammad Reza and Michalewicz, Zbigniew},
  year = {2017},
  journal = {Evolutionary Computation},
  volume = {25},
  number = {1},
  pages = {1--54},
  doi = {10.1162/EVCO_r_00180},
  keywords = {ObsCite}
}

@article{li2015reinforcement,
  title = {Reinforcement Learning Control for Coordinated Manipulation of Multi-Robots},
  author = {Li, Yanan and Chen, Long and Tee, Keng Peng and Li, Qingquan},
  year = {2015},
  month = dec,
  journal = {Neurocomputing},
  series = {Advances on {{Biological Rhythmic Pattern Generation}}: {{Experiments}}, {{Algorithms}} and {{Applications}}},
  volume = {170},
  pages = {168--175},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2015.02.091},
  urldate = {2023-05-19},
  abstract = {In this paper, coordination control is investigated for multi-robots to manipulate an object with a common desired trajectory. Both trajectory tracking and control input minimization are considered for each individual robot manipulator, such that possible disagreement between different manipulators can be handled. Reinforcement learning is employed to cope with the problem of unknown dynamics of both robots and the manipulated object. It is rigorously proven that the proposed method guarantees the coordination control of the multi-robots system under study. The validity of the proposed method is verified through simulation studies.},
  langid = {english},
  keywords = {Multi-robots coordination,Reinforcement learning,Robot control},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@li2015reinforcement-Reinforcement learning control for coordinated manipulation of multi-robots.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\YP3BLZWU\\S0925231215009339.html}
}

@article{kim2017robust,
  title = {Robust {{Dynamic Locomotion}} via {{Reinforcement Learning}} and {{Novel Whole Body Controller}}},
  author = {Kim, Donghyun and Lee, Jaemin and Sentis, L.},
  year = {2017},
  month = aug,
  journal = {ArXiv},
  urldate = {2023-05-19},
  abstract = {We propose a robust dynamic walking controller consisting of a dynamic locomotion planner, a reinforcement learning process for robustness, and a novel whole-body locomotion controller (WBLC). Previous approaches specify either the position or the timing of steps, however, the proposed locomotion planner simultaneously computes both of these parameters as locomotion outputs. Our locomotion strategy relies on devising a reinforcement learning (RL) approach for robust walking. The learned policy generates multi step walking patterns, and the process is quick enough to be suitable for real-time controls. For learning, we devise an RL strategy that uses a phase space planner (PSP) and a linear inverted pendulum model to make the problem tractable and very fast. Then, the learned policy is used to provide goal-based commands to the WBLC, which calculates the torque commands to be executed in full-humanoid robots. The WBLC combines multiple prioritized tasks and calculates the associated reaction forces based on practical inequality constraints. The novel formulation includes efficient calculation of the time derivatives of various Jacobians. This provides high-fidelity dynamic control of fast motions. More specifically, we compute the time derivative of the Jacobian for various tasks and the Jacobian of the centroidal momentum task by utilizing Lie group operators and operational space dynamics respectively. The integration of RL-PSP and the WBLC provides highly robust, versatile, and practical locomotion including steering while walking and handling push disturbances of up to 520 N during an interval of 0.1 sec. Theoretical and numerical results are tested through a 3D physics-based simulation of the humanoid robot Valkyrie.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kim2017robust-Robust Dynamic Locomotion via Reinforcement Learning and Novel Whole Body.pdf}
}

@article{tao2023reinforcement,
  title = {A {{Reinforcement Learning-based Approach}} to {{Testing GUI}} of {{Moblie Applications}}},
  author = {Tao, Chuanqi and Gao, Yuemeng and Guo, Hongjing and Gao, Jerry},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@tao2023reinforcement-A Reinforcement Learning-based Approach to Testing GUI of Moblie Applications.pdf}
}

@article{liu2016guided,
  title = {Guided {{Learning}} of {{Control Graphs}} for {{Physics-Based Characters}}},
  author = {Liu, Libin and Panne, Michiel Van De and Yin, Kangkang},
  year = {2016},
  month = may,
  journal = TOG,
  volume = {35},
  number = {3},
  issn = {0730-0301},
  doi = {10.1145/2893476},
  abstract = {The difficulty of developing control strategies has been a primary bottleneck in the adoption of physics-based simulations of human motion. We present a method for learning robust feedback strategies around given motion capture clips as well as the transition paths between clips. The output is a control graph that supports real-time physics-based simulation of multiple characters, each capable of a diverse range of robust movement skills, such as walking, running, sharp turns, cartwheels, spin-kicks, and flips. The control fragments that compose the control graph are developed using guided learning. This leverages the results of open-loop sampling-based reconstruction in order to produce state-action pairs that are then transformed into a linear feedback policy for each control fragment using linear regression. Our synthesis framework allows for the development of robust controllers with a minimal amount of prior knowledge.},
  keywords = {control graphs,guided policy search,human simulation,Motion control,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2016guided-Guided Learning of Control Graphs for Physics-Based Characters.pdf}
}

@article{kober2013reinforcement,
  title = {Reinforcement Learning in Robotics: {{A}} Survey},
  author = {Kober, Jens and Bagnell, J. Andrew and Peters, Jan},
  year = {2013},
  journal = {The International Journal of Robotics Research},
  volume = {32},
  pages = {1238--1274},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kober2013reinforcement-Reinforcement learning in robotics - A survey.pdf}
}

@inproceedings{chen2022humanlevel,
  title = {Towards {{Human-Level Bimanual Dexterous Manipulation}} with {{Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Chen, Yuanpei and Wu, Tianhao and Wang, Shengjie and Feng, Xidong and Jiang, Jiechuan and Lu, Zongqing and McAleer, Stephen Marcus and Dong, Hao and Zhu, Song-Chun and Yang, Yaodong},
  year = {2022},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2022humanlevel-Towards Human-Level Bimanual Dexterous Manipulation with Reinforcement Learning.pdf}
}

@inproceedings{baykal2017asymptotically,
  title = {Asymptotically {{Optimal Design}} of {{Piecewise Cylindrical Robots}} Using {{Motion Planning}}.},
  booktitle = {Robotics: {{Science}} and {{Systems}}},
  author = {Baykal, Cenk and Alterovitz, Ron},
  year = {2017},
  volume = {2017},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@baykal2017asymptotically-Asymptotically Optimal Design of Piecewise Cylindrical Robots using Motion.pdf}
}

@article{noguchi2021tool,
  title = {Tool as {{Embodiment}} for {{Recursive Manipulation}}},
  author = {Noguchi, Yuki and Matsushima, Tatsuya and Matsuo, Yutaka and Gu, Shixiang Shane},
  year = {2021},
  journal = {arXiv},
  keywords = {ObsCite},
  annotation = {},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@noguchi2021tool-Tool as Embodiment for Recursive Manipulation.pdf}
}

@inproceedings{liu2022revolver,
  title = {{{REvolveR}}: {{Continuous}} Evolutionary Models for Robot-to-Robot Policy Transfer},
  booktitle = ICML,
  author = {Liu, Xingyu and Pathak, Deepak and Kitani, Kris},
  editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesv{\'a}ri, Csaba and Niu, Gang and Sabato, Sivan},
  year = {2022},
  series = {Proceedings of Machine Learning Research},
  volume = {162},
  pages = {13995--14007},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\MTIM64AM\\revolver_supp.mp4;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@liu2022revolver-REvolveR - Continuous evolutionary models for robot-to-robot policy transfer.pdf}
}

@inproceedings{yuan2022transform2act,
  title = {{{Transform2Act}}: {{Learning}} a {{Transform-and-Control Policy}} for {{Efficient Agent Design}}},
  booktitle = ICLR,
  author = {Yuan, Ye and Song, Yuda and Luo, Zhengyi and Sun, Wen and Kitani, Kris M.},
  year = {2022},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yuan2022transform2act-Transform2Act - Learning a Transform-and-Control Policy for Efficient Agent.pdf}
}

@inproceedings{wang2019neural,
  title = {Neural {{Graph Evolution}}: {{Towards Efficient Automatic Robot Design}}},
  shorttitle = {Neural {{Graph Evolution}}},
  booktitle = ICLR,
  author = {Wang, Tingwu and Zhou, Yuhao and Fidler, Sanja and Ba, Jimmy},
  year = {2019},
  month = jun,
  urldate = {2022-02-16},
  langid = {english},
  keywords = {embodied intelligence,ObsCite},
  annotation = {an ES-based method that uses GNNs to enable weight sharing between an agent and\\
its offspring},
  file = {C:\Users\lenovo\Zotero\storage\2BPNLEJP\Wang_2019_Neural Graph Evolution.pdf}
}

@inproceedings{wang2018nervenet,
  title = {Nervenet: {{Learning}} Structured Policy with Graph Neural Networks},
  booktitle = ICLR,
  author = {Wang, Tingwu and Liao, Renjie and Ba, Jimmy and Fidler, Sanja},
  year = {2018},
  volume = {30},
  keywords = {ObsCite},
  annotation = {using graph neural network to model structural information of the agents to improve policy and transferability},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2018nervenet-Nervenet - Learning structured policy with graph neural networks.pdf}
}

@inproceedings{vaswani2017attention,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = NeurIPS,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@vaswani2017attention-Attention is All you Need.pdf}
}

@article{scarselli2008graph,
  title = {The Graph Neural Network Model},
  author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  year = {2008},
  journal = {IEEE transactions on neural networks},
  volume = {20},
  number = {1},
  pages = {61--80},
  publisher = {IEEE},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@scarselli2008graph-The graph neural network model.pdf}
}

@inproceedings{schaff2019jointly,
  title = {Jointly {{Learning}} to {{Construct}} and {{Control Agents}} Using {{Deep Reinforcement Learning}}},
  booktitle = ICRA,
  author = {Schaff, Charles and Yunis, David and Chakrabarti, Ayan and Walter, Matthew R.},
  year = {2019},
  month = may,
  pages = {9798--9805},
  publisher = {IEEE},
  address = {Montreal, QC, Canada},
  doi = {10.1109/ICRA.2019.8793537},
  urldate = {2022-03-01},
  abstract = {The physical design of a robot and the policy that controls its motion are inherently coupled, and should be determined according to the task and environment. In an increasing number of applications, data-driven and learningbased approaches, such as deep reinforcement learning, have proven effective at designing control policies. For most tasks, the only way to evaluate a physical design with respect to such control policies is empirical---i.e., by picking a design and training a control policy for it. Since training these policies is timeconsuming, it is computationally infeasible to train separate policies for all possible designs as a means to identify the best one. In this work, we address this limitation by introducing a method that performs simultaneous joint optimization of the physical design and control network. Our approach maintains a distribution over designs and uses reinforcement learning to optimize a control policy to maximize expected reward over the design distribution. We give the controller access to design parameters to allow it to tailor its policy to each design in the distribution. Throughout training, we shift the distribution towards higher-performing designs, eventually converging to a design and control policy that are jointly optimal. We evaluate our approach in the context of legged locomotion, and demonstrate that it discovers novel designs and walking gaits, outperforming baselines in both performance and efficiency.},
  isbn = {978-1-5386-6027-0},
  langid = {english},
  keywords = {embodied intelligence,ObsCite,reinforcement learning},
  annotation = {ICRA},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@schaff2019jointly-Jointly Learning to Construct and Control Agents using Deep Reinforcement.pdf}
}

@inproceedings{sanchez-gonzalez2018graph,
  title = {Graph Networks as Learnable Physics Engines for Inference and Control},
  booktitle = ICML,
  author = {{Sanchez-Gonzalez}, Alvaro and Heess, Nicolas and Springenberg, Jost Tobias and Merel, Josh and Riedmiller, Martin and Hadsell, Raia and Battaglia, Peter},
  year = {2018},
  pages = {4470--4479},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@sanchez-gonzalez2018graph-Graph networks as learnable physics engines for inference and control.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@sanchez-gonzalez2018graph-Graph networks as learnable physics engines for inference and control2.pdf}
}

@article{shoeleh2017graph,
  title = {Graph Based Skill Acquisition and Transfer {{Learning}} for Continuous Reinforcement Learning Domains},
  author = {Shoeleh, Farzaneh and Asadpour, Masoud},
  year = {2017},
  month = feb,
  journal = {Pattern Recognition Letters},
  volume = {87},
  pages = {104--116},
  issn = {01678655},
  doi = {10.1016/j.patrec.2016.08.009},
  urldate = {2023-05-04},
  langid = {english},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@shoeleh2017graph-Graph based skill acquisition and transfer Learning for continuous.pdf}
}

@article{sims1994evolving,
  title = {Evolving {{3D Morphology}} and {{Behavior}} by {{Competition}}},
  author = {Sims, Karl},
  year = {1994},
  journal = {Artificial Life IV},
  volume = {1},
  number = {4},
  pages = {353--372},
  keywords = {ObsCite},
  annotation = {},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sims1994evolving-Evolving 3D Morphology and Behavior by Competition.pdf}
}

@inproceedings{gupta2022metamorph,
  title = {{{MetaMorph}}: {{Learning Universal Controllers}} with {{Transformers}}},
  shorttitle = {{{MetaMorph}}},
  booktitle = ICLR,
  author = {Gupta, Agrim and Fan, Linxi and Ganguli, Surya and {Fei-Fei}, Li},
  year = {2022},
  month = mar,
  publisher = {arXiv},
  urldate = {2022-10-06},
  abstract = {Multiple domains like vision, natural language, and audio are witnessing tremendous progress by leveraging Transformers for large scale pre-training followed by task specific fine tuning. In contrast, in robotics we primarily train a single robot for a single task. However, modular robot systems now allow for the flexible combination of general-purpose building blocks into task optimized morphologies. However, given the exponentially large number of possible robot morphologies, training a controller for each new design is impractical. In this work, we propose MetaMorph, a Transformer based approach to learn a universal controller over a modular robot design space. MetaMorph is based on the insight that robot morphology is just another modality on which we can condition the output of a Transformer. Through extensive experiments we demonstrate that large scale pretraining on a variety of robot morphologies results in policies with combinatorial generalization capabilities, including zero shot generalization to unseen robot morphologies. We further demonstrate that our pre-trained policy can be used for sample-efficient transfer to completely new robot morphologies and tasks.},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics,core,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2022metamorph-MetaMorph - Learning Universal Controllers with Transformers.pdf}
}

@inproceedings{hong2021structureaware,
  title = {Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning},
  booktitle = ICLR,
  author = {Hong, Sunghoon and Yoon, Deunsol and Kim, Kee-Eung},
  year = {2021},
  keywords = {ObsCite},
  annotation = {We present a modular Multi-task Reinforcement Learning method for inhomogeneous control tasks incorporating structural embedding of morphology.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hong2021structureaware-Structure-aware transformer policy for inhomogeneous multi-task reinforcement.pdf}
}

@article{harvey1997evolutionary,
  title = {Evolutionary Robotics: The {{Sussex}} Approach},
  author = {Harvey, Inman and Husbands, Phil and Cliff, Dave and Thompson, Adrian and Jakobi, Nick},
  year = {1997},
  journal = {Robotics and Autonomous Systems},
  volume = {20},
  number = {2-4},
  pages = {205--224},
  publisher = {Elsevier},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@harvey1997evolutionary-Evolutionary robotics - the Sussex approach.pdf}
}

@article{lipson2000automatic,
  title = {Automatic Design and Manufacture of Robotic Lifeforms},
  author = {Lipson, Hod and Pollack, Jordan B.},
  year = {2000},
  journal = {Nature},
  volume = {406},
  number = {6799},
  pages = {974--978},
  issn = {1476-4687},
  keywords = {ObsCite},
  annotation = {},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lipson2000automatic-Automatic design and manufacture of robotic lifeforms.pdf}
}

@article{blake2021snowflake,
  title = {Snowflake: {{Scaling GNNs}} to High-Dimensional Continuous Control via Parameter Freezing},
  author = {Blake, Charles and Kurin, Vitaly and Igl, Maximilian and Whiteson, Shimon},
  year = {2021},
  journal = NeurIPS,
  volume = {34},
  pages = {23983--23992},
  keywords = {ObsCite},
  annotation = { NerveNet },
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@blake2021snowflake-Snowflake - Scaling GNNs to high-dimensional continuous control via parameter.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@blake2021snowflake-Snowflake - Scaling GNNs to high-dimensional continuous control via parameter2.pdf}
}

@inproceedings{auerbach2012relationship,
  title = {On the Relationship between Environmental and Morphological Complexity in Evolved Robots},
  booktitle = GECCO,
  author = {Auerbach, Joshua E and Bongard, Joshua C},
  year = {2012},
  pages = {521--528},
  keywords = {ObsCite},
  annotation = {, , },
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@auerbach2012relationship-On the relationship between environmental and morphological complexity in.pdf}
}

@inproceedings{auerbach2010dynamic,
  title = {Dynamic Resolution in the Co-Evolution of Morphology and Control},
  booktitle = {Artificial {{Life XII}}},
  author = {Auerbach, Joshua E and Bongard, Josh C},
  year = {2010},
  pages = {451--458},
  publisher = {MIT Press},
  keywords = {ObsCite},
  annotation = { CPPN , },
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@auerbach2010dynamic-Dynamic resolution in the co-evolution of morphology and control.pdf}
}

@inproceedings{hejna2020hierarchically,
  title = {Hierarchically {{Decoupled Imitation For Morphological Transfer}}},
  booktitle = ICML,
  author = {Hejna, Donald and Pinto, Lerrel and Abbeel, Pieter},
  editor = {III, Hal Daum{\'e} and Singh, Aarti},
  year = {2020},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {119},
  pages = {4159--4171},
  publisher = {PMLR},
  abstract = {Learning long-range behaviors on complex high-dimensional agents is a fundamental problem in robot learning. For such tasks, we argue that transferring learned information from a morphologically simpler agent can massively improve the sample efficiency of a more complex one. To this end, we propose a hierarchical decoupling of policies into two parts: an independently learned low-level policy and a transferable high-level policy. To remedy poor transfer performance due to mismatch in morphologies, we contribute two key ideas. First, we show that incentivizing a complex agent's low-level to imitate a simpler agent's low-level significantly improves zero-shot high-level transfer. Second, we show that KL-regularized training of the high level stabilizes learning and prevents mode-collapse. Finally, on a suite of publicly released navigation and manipulation environments, we demonstrate the applicability of hierarchical transfer on long-range tasks across morphologies. Our code and videos can be found at https://sites.google.com/berkeley.edu/morphology-transfer.},
  keywords = {ObsCite},
  annotation = {},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hejna2020hierarchically-Hierarchically Decoupled Imitation For Morphological Transfer.pdf}
}

@inproceedings{gupta2017learning,
  title = {Learning {{Invariant Feature Spaces}} to {{Transfer Skills}} with {{Reinforcement Learning}}},
  booktitle = ICLR,
  author = {Gupta, Abhishek and Devin, Coline and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  year = {2017},
  keywords = {ObsCite},
  annotation = {Learning a common feature space between robots with different morphology or actuation to transfer skills.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2017learning-Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning.pdf}
}

@inproceedings{chen2018hardware,
  title = {Hardware {{Conditioned Policies}} for {{Multi-Robot Transfer Learning}}},
  booktitle = NeurIPS,
  author = {Chen, Tao and Murali, Adithyavairavan and Gupta, Abhinav},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  annotation = {},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2018hardware-Hardware Conditioned Policies for Multi-Robot Transfer Learning.pdf}
}

@article{luck2021whata,
  title = {What Robot Do {{I}} Need? {{Fast}} Co-Adaptation of Morphology and Control Using Graph Neural Networks},
  author = {Luck, Kevin Sebastian and Calandra, Roberto and Mistry, Michael N.},
  year = {2021},
  journal = {CoRR},
  volume = {abs/2111.02371},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@luck2021whata-What robot do I need - Fast co-adaptation of morphology and control using graph.pdf}
}

@inproceedings{li2022hyar,
  title = {{{HyAR}}: {{Addressing Discrete-Continuous Action Reinforcement Learning}} via {{Hybrid Action Representation}}},
  booktitle = ICLR,
  author = {Li, Boyan and Tang, Hongyao and ZHENG, {\relax YAN} and HAO, Jianye and Li, Pengyi and Wang, Zhen and Meng, Zhaopeng and Wang, L. I.},
  year = {2022}
}

@inproceedings{sims1994evolvinga,
  title = {Evolving Virtual Creatures},
  booktitle = {Conference on {{Computer Graphics}} \& {{Interactive Techniques}}},
  author = {{Sims} and {Karl}},
  year = {1994},
  pages = {15--22},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sims1994evolvinga-Evolving virtual creatures.pdf}
}

@article{hinton2022forwardforward,
  title = {The Forward-Forward Algorithm: {{Some}} Preliminary Investigations},
  author = {Hinton, Geoffrey},
  year = {2022},
  journal = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hinton2022forwardforward-The forward-forward algorithm - Some preliminary investigations.pdf}
}

@article{rosendo2017tradeoff,
  title = {The Trade-off between Morphology and Control in the Co-Optimized Design of Robots},
  author = {Rosendo, Andre and Von Atzigen, Marco and Iida, Fumiya},
  year = {2017},
  journal = {PloS one},
  volume = {12},
  number = {10},
  pages = {e0186107},
  publisher = {Public Library of Science San Francisco, CA USA}
}

@article{joachimczak2016artificial,
  title = {Artificial Metamorphosis: {{Evolutionary}} Design of Transforming, Soft-Bodied Robots},
  author = {Joachimczak, Micha{\textbackslash}l and Suzuki, Reiji and Arita, Takaya},
  year = {2016},
  journal = {Artificial life},
  volume = {22},
  number = {3},
  pages = {271--298},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info {\dots}}
}

@inproceedings{finn2017modelagnostic,
  title = {Model-{{Agnostic Meta-Learning}} for {{Fast Adaptation}} of {{Deep Networks}}},
  booktitle = ICML,
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  editor = {Precup, Doina and Teh, Yee Whye},
  year = {2017},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {70},
  pages = {1126--1135},
  publisher = {PMLR},
  file = {D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@finn2017modelagnostic-Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@finn2017modelagnostic-Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks2.pdf}
}

@inproceedings{fan2022minedojo,
  title = {{{MineDojo}}: {{Building Open-Ended Embodied Agents}} with {{Internet-Scale Knowledge}}},
  booktitle = NeurIPS,
  author = {Fan, Linxi and Wang, Guanzhi and Jiang, Yunfan and Mandlekar, Ajay and Yang, Yuncong and Zhu, Haoyi and Tang, Andrew and Huang, De-An and Zhu, Yuke and Anandkumar, Anima},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@fan2022minedojo-MineDojo - Building Open-Ended Embodied Agents with Internet-Scale Knowledge.pdf}
}

@inproceedings{hambro2022dungeons,
  title = {Dungeons and {{Data}}: {{A Large-Scale NetHack Dataset}}},
  booktitle = NeurIPS,
  author = {Hambro, Eric and Raileanu, Roberta and Rothermel, Danielle and Mella, Vegard and Rockt{\"a}schel, Tim and Kuttler, Heinrich and Murray, Naila},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hambro2022dungeons-Dungeons and Data - A Large-Scale NetHack Dataset.pdf}
}

@inproceedings{xu2022safebench,
  title = {{{SafeBench}}: {{A Benchmarking Platform}} for {{Safety Evaluation}} of {{Autonomous Vehicles}}},
  booktitle = NeurIPS,
  author = {Xu, Chejian and Ding, Wenhao and Lyu, Weijie and Liu, Zuxin and Wang, Shuai and He, Yihan and Hu, Hanjiang and Zhao, Ding and Li, Bo},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2022safebench-SafeBench - A Benchmarking Platform for Safety Evaluation of Autonomous Vehicles.pdf}
}

@inproceedings{wagener2022mocapact,
  title = {{{MoCapAct}}: {{A Multi-Task Dataset}} for {{Simulated Humanoid Control}}},
  booktitle = NeurIPS,
  author = {Wagener, Nolan and Kolobov, Andrey and Frujeri, Felipe Vieira and Loynd, Ricky and Cheng, Ching-An and Hausknecht, Matthew},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wagener2022mocapact-MoCapAct - A Multi-Task Dataset for Simulated Humanoid Control.pdf}
}

@inproceedings{wan2022handmethat,
  title = {{{HandMeThat}}: {{Human-Robot Communication}} in {{Physical}} and {{Social Environments}}},
  booktitle = NeurIPS,
  author = {Wan, Yanming and Mao, Jiayuan and Tenenbaum, Joshua B.},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wan2022handmethat-HandMeThat - Human-Robot Communication in Physical and Social Environments.pdf}
}

@inproceedings{vinitsky2022nocturne,
  title = {Nocturne: A Scalable Driving Benchmark for Bringing Multi-Agent Learning One Step Closer to the Real World},
  booktitle = NeurIPS,
  author = {Vinitsky, Eugene and Lichtl{\'e}, Nathan and Yang, Xiaomeng and Amos, Brandon and Foerster, Jakob Nicolaus},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@vinitsky2022nocturne-Nocturne - a scalable driving benchmark for bringing multi-agent learning one.pdf}
}

@inproceedings{yu2022surprising,
  title = {The {{Surprising Effectiveness}} of {{PPO}} in {{Cooperative Multi-Agent Games}}},
  booktitle = NeurIPS,
  author = {Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2022surprising-The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games.pdf}
}

@inproceedings{qin2022neorl,
  title = {{{NeoRL}}: {{A Near Real-World Benchmark}} for {{Offline Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Qin, Rong-Jun and Zhang, Xingyuan and Gao, Songyi and Chen, Xiong-Hui and Li, Zewen and Zhang, Weinan and Yu, Yang},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@qin2022neorl-NeoRL - A Near Real-World Benchmark for Offline Reinforcement Learning.pdf}
}

@inproceedings{howe2022myriad,
  title = {Myriad: A Real-World Testbed to Bridge Trajectory Optimization and Deep Learning},
  booktitle = NeurIPS,
  author = {Howe, Nikolaus H. R. and {Dufort-Labb{\'e}}, Simon and Rajkumar, Nitarshan and Bacon, Pierre-Luc},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@howe2022myriad-Myriad - a real-world testbed to bridge trajectory optimization and deep learning.pdf}
}

@inproceedings{pan2022mate,
  title = {{{MATE}}: {{Benchmarking Multi-Agent Reinforcement Learning}} in {{Distributed Target Coverage Control}}},
  booktitle = NeurIPS,
  author = {Pan, Xuehai and Liu, Mickel and {zhong}, fangwei and Yang, Yaodong and Zhu, Song-Chun and Wang, Yizhou},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@pan2022mate-MATE - Benchmarking Multi-Agent Reinforcement Learning in Distributed Target.pdf}
}

@inproceedings{turchetta2022learning,
  title = {Learning {{Long-Term Crop Management Strategies}} with {{CyclesGym}}},
  booktitle = NeurIPS,
  author = {Turchetta, Matteo and Corinzia, Luca and Sussex, Scott and Burton, Amanda and Herrera, Juan and Athanasiadis, Ioannis N. and Buhmann, Joachim M. and Krause, Andreas},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@turchetta2022learning-Learning Long-Term Crop Management Strategies with CyclesGym.pdf}
}

@inproceedings{wei2022honor,
  title = {Honor of {{Kings Arena}}: An {{Environment}} for {{Generalization}} in {{Competitive Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Wei, Hua and Chen, Jingxiao and Ji, Xiyang and Qin, Hongyang and Deng, Minwen and Li, Siqin and Wang, Liang and Zhang, Weinan and Yu, Yong and Linc, Liu and Huang, Lanxiao and Ye, Deheng and FU, {\relax QIANG} and Wei, Yang},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wei2022honor-Honor of Kings Arena - an Environment for Generalization in Competitive.pdf}
}

@inproceedings{liu2022finrlmeta,
  title = {{{FinRL-Meta}}: {{Market Environments}} and {{Benchmarks}} for {{Data-Driven Financial Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Liu, Xiao-Yang and Xia, Ziyi and Rui, Jingyang and Gao, Jiechao and Yang, Hongyang and Zhu, Ming and Wang, Christina Dan and Wang, Zhaoran and Guo, Jian},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2022finrlmeta-FinRL-Meta - Market Environments and Benchmarks for Data-Driven Financial.pdf}
}

@inproceedings{bamford2022griddlyjs,
  title = {{{GriddlyJS}}: {{A Web IDE}} for {{Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Bamford, Christopher and Jiang, Minqi and Samvelyan, Mikayel and Rockt{\"a}schel, Tim},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bamford2022griddlyjs-GriddlyJS - A Web IDE for Reinforcement Learning.pdf}
}

@inproceedings{weng2022envpool,
  title = {{{EnvPool}}: {{A Highly Parallel Reinforcement Learning Environment Execution Engine}}},
  booktitle = NeurIPS,
  author = {Weng, Jiayi and Lin, Min and Huang, Shengyi and Liu, Bo and Makoviichuk, Denys and Makoviychuk, Viktor and Liu, Zichen and Song, Yufan and Luo, Ting and Jiang, Yukun and Xu, Zhongwen and YAN, Shuicheng},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@weng2022envpool-EnvPool - A Highly Parallel Reinforcement Learning Environment Execution Engine.pdf}
}

@inproceedings{2022mapping,
  title = {Mapping {{Componentized Body}} to {{Modular Behaviors}}: {{Embodied Intelligence}} via {{Hierarchical Grammatical Evolution}}},
  booktitle = {{{IJCAI2022}}},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@2022mapping-Mapping Componentized Body to Modular Behaviors - Embodied Intelligence via.pdf}
}

@inproceedings{2022enhancing,
  title = {Enhancing {{Joint Adaption}} of {{Morphology}} and {{Control}} by {{Instinct-driven Reinforcement Learning}}},
  booktitle = {{{ICRA2023}}},
  year = {2022},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\AH55F75U\\ICRA23_2354_VI_i.mp4;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@2022enhancing-Enhancing Joint Adaption of Morphology and Control by Instinct-driven.pdf}
}

@book{kahneman2011thinking,
  title = {Thinking, Fast and Slow},
  author = {Kahneman, Daniel},
  year = {2011},
  publisher = {Macmillan},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kahneman2011thinking-Thinking, fast and slow.pdf}
}

@article{kahneman2003maps,
  title = {Maps of {{Bounded Rationality}}: {{Psychology}} for {{Behavioral Economics}}},
  author = {Kahneman, Daniel},
  year = {2003},
  month = dec,
  journal = {American Economic Review},
  volume = {93},
  number = {5},
  pages = {1449--1475},
  doi = {10.1257/000282803322655392},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kahneman2003maps-Maps of Bounded Rationality - Psychology for Behavioral Economics.pdf}
}

@article{mnih2015humanlevel,
  title = {Human-Level Control through Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  year = {2015},
  journal = {Nature},
  volume = {518},
  number = {7540},
  pages = {529--533},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mnih2015humanlevel-Human-level control through deep reinforcement learning.pdf}
}

@article{zadornextgeneration,
  title = {Toward {{Next-Generation Artificial Intelligence}}: {{Catalyzing}} the {{NeuroAI Revolution}}},
  author = {Zador, Anthony and Richards, Blake and {\"O}lveczky, Bence and Escola, Sean and Bengio, Yoshua and Botvinick, Matthew and Chklovskii, Dmitri and Churchland, Anne and Clopath, Claudia and Ganguli, Surya and Hawkins, Jeff and Koerding, Konrad and Koulakov, Alexei and LeCun, Yann and Marblestone, Adam and Olshausen, Bruno and Pouget, Alexandre and Savin, Cristina and Simoncelli, Eero and Solla, Sara and Sussillo, David and Tolias, Andreas S and Tsao, Doris},
  pages = {11},
  abstract = {Neuroscience has long been an important driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\5MAYV68P\Zador_Toward Next-Generation Artificial Intelligence.pdf}
}

@book{murphy2019introduction,
  title = {Introduction to {{AI}} Robotics},
  author = {Murphy, Robin R},
  year = {2019},
  publisher = {MIT press}
}

@inproceedings{mazurek2020string,
  title = {String {{Plucking}} and {{Touching Sensing}} Using {{Transmissive Optical Sensors}} for {{Guzheng}}},
  booktitle = {2020 16th {{International Conference}} on {{Control}}, {{Automation}}, {{Robotics}} and {{Vision}} ({{ICARCV}})},
  author = {Mazurek, Przemyslaw and {Oszutowska-Mazurek}, Dorota},
  year = {2020},
  month = dec,
  pages = {1143--1149},
  publisher = {IEEE},
  address = {Shenzhen, China},
  doi = {10.1109/ICARCV50220.2020.9305480},
  urldate = {2022-10-31},
  abstract = {The article presents a solution for recording individual vibrations of the string for the guzheng zither. An optical transmission sensor was used inside which the string vibrates. The analytical solution is presented to describe the string in this type of sensor. The classification of sensors is proposed, which classes are characterized by different properties of vibration conversion into an optical signal. A prototype solution for guzheng is presented. The measuring method allows to register the touch of the string, which is important for further estimation of the string's state.},
  isbn = {978-1-72817-709-0},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mazurek2020string-String Plucking and Touching Sensing using Transmissive Optical Sensors for.pdf}
}

@article{bretan2016survey,
  title = {A Survey of Robotic Musicianship},
  author = {Bretan, Mason and Weinberg, Gil},
  year = {2016},
  month = apr,
  journal = {Communications of the ACM},
  volume = {59},
  number = {5},
  pages = {100--109},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/2818994},
  urldate = {2022-10-31},
  abstract = {Reviewing the technologies that enable robot musicians to jam.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bretan2016survey-A survey of robotic musicianship.pdf}
}

@inproceedings{gorner2023plucking,
  title = {Plucking {{Chordophones}} through {{Kinesthetic Teaching}} and {{Audio-Tactile Feedback}}},
  booktitle = ICRA,
  author = {G{\"o}rner, Michael},
  year = {2023},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\2YAAWIWZ\\Grner_2023_Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.docx;C\:\\Users\\lenovo\\Zotero\\storage\\GKJ2ELBK\\Grner_2023_Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.md;C\:\\Users\\lenovo\\Zotero\\storage\\PYS4HPCV\\Grner_2023_Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.mp4;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@gorner2023plucking-Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.docx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@gorner2023plucking-Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.pdf}
}

@book{johnson20body,
  title = {The Body in the Mind: The Bodily Basis of Meaning, Imagination, and Reason},
  shorttitle = {The Body in the Mind},
  author = {Johnson, Mark},
  year = {20},
  edition = {Paperback ed., [9. print.]},
  publisher = {University of Chicago Press},
  address = {Chicago},
  isbn = {978-0-226-40318-2},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@johnson20body-The body in the mind - the bodily basis of meaning, imagination, and reason.pdf}
}

@article{censi2019class,
  title = {A Class of Co-Design Problems with Cyclic Constraints and Their Solution},
  author = {Censi, A.},
  year = {2019},
  journal = RA-L,
  volume = {2},
  number = {1},
  pages = {96--103},
  abstract = {Co-design problems in the field of robotics involve the tradeoff of "resources" usage, such as cost, execution time, and energy, with mission performance, under recursive constraints that involve energetics, mechanics, computation, and communication. This letter shows that a large class of codesign problems have a common structure, as they are described by two posets, representing functionality, and resources. The codesign constraints can be expressed as two maps in opposite directions between the two posets. Finding the most resource-economical feasible solution is equivalent to finding the least fixed point of the composition of those two maps. If the two maps are monotone, results from order theory allow concluding uniqueness and systematically deriving an optimal design or a certificate for infeasibility.}
}

@article{kubricht2017intuitive,
  title = {Intuitive {{Physics}}: {{Current Research}} and {{Controversies}}},
  shorttitle = {Intuitive {{Physics}}},
  author = {Kubricht, James R. and Holyoak, Keith J. and Lu, Hongjing},
  year = {2017},
  month = oct,
  journal = {Trends in Cognitive Sciences},
  volume = {21},
  number = {10},
  pages = {749--759},
  issn = {13646613},
  doi = {10.1016/j.tics.2017.06.002},
  urldate = {2022-10-22},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kubricht2017intuitive-Intuitive Physics - Current Research and Controversies.pdf}
}

@article{spelke2007core,
  title = {Core Knowledge},
  author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
  year = {2007},
  month = jan,
  journal = {Developmental Science},
  volume = {10},
  number = {1},
  pages = {89--96},
  issn = {1363755X, 14677687},
  doi = {10.1111/j.1467-7687.2007.00569.x},
  urldate = {2022-10-22},
  abstract = {Human cognition is founded, in part, on four systems for representing objects, actions, number, and space. It may be based, as well, on a fifth system for representing social partners. Each system has deep roots in human phylogeny and ontogeny, and it guides and shapes the mental lives of adults. Converging research on human infants, non-human primates, children and adults in diverse cultures can aid both understanding of these systems and attempts to overcome their limits.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@spelke2007core-Core knowledge.pdf}
}

@article{yang2021efficient,
  title = {Efficient Hyperparameter Optimization for Physics-Based Character Animation},
  author = {Yang, Zeshi and Yin, Zhiqi},
  year = {2021},
  month = apr,
  journal = TOG,
  volume = {4},
  number = {1},
  doi = {10.1145/3451254},
  abstract = {Physics-based character animation has seen significant advances in recent years with the adoption of Deep Reinforcement Learning (DRL). However, DRL-based learning methods are usually computationally expensive and their performance crucially depends on the choice of hyperparameters. Tuning hyperparameters for these methods often requires repetitive training of control policies, which is even more computationally prohibitive. In this work, we propose a novel Curriculum-based Multi-Fidelity Bayesian Optimization framework (CMFBO) for efficient hyperparameter optimization of DRL-based character control systems. Using curriculum-based task difficulty as fidelity criterion, our method improves searching efficiency by gradually pruning search space through evaluation on easier motor skill tasks. We evaluate our method on two physics-based character control tasks: character morphology optimization and hyperparameter tuning of DeepMimic. Our algorithm significantly outperforms state-of-the-art hyperparameter optimization methods applicable for physics-based character animation. In particular, we show that hyperparameters optimized through our algorithm result in at least 5x efficiency gain comparing to author-released settings in DeepMimic.},
  keywords = {Bayesian Optimization,Curriculum Learning,Physics-based Character Animation,Reinforcement Learning},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2021efficient-Efficient hyperparameter optimization for physics-based character animation.pdf}
}

@inproceedings{park1994concurrent,
  title = {Concurrent Design Optimization of Mechanical Structure and Control for High Speed Robots},
  booktitle = {American Control Conference},
  author = {Park, J. H. and Asada, H.},
  year = {1994}
}

@techreport{stout2005intrinsically,
  title = {Intrinsically Motivated Reinforcement Learning: {{A}} Promising Framework for Developmental Robot Learning},
  author = {Stout, Andrew and Konidaris, George D and Barto, Andrew G},
  year = {2005},
  institution = {Massachusetts Univ Amherst Dept of Computer Science}
}

@inproceedings{paul2002road,
  title = {The Road Less Travelled: Morphology in the Optimization of Biped Robot Locomotion},
  booktitle = IROS,
  author = {Paul, C. and Bongard, J. C.},
  year = {2002}
}

@inproceedings{peng2020learning,
  title = {Learning Agile Robotic Locomotion Skills by Imitating Animals},
  booktitle = RSS,
  author = {Peng, Xue Bin and Coumans, Erwin and Zhang, Tingnan and Lee, Tsang-Wei Edward and Tan, Jie and Levine, Sergey},
  year = {2020},
  month = jul,
  doi = {10.15607/RSS.2020.XVI.064},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2020learning-Learning agile robotic locomotion skills by imitating animals.pdf}
}

@article{wang2015design,
  title = {Design Principles for Energy-Efficient Legged Locomotion and Implementation on the {{MIT}} Cheetah Robot},
  author = {{Wang} and {Albert} and {Michael} and {Chuah} and {Meng} and {Yee} and {Hyun} and {Dong} and {Jin} and {Otten}},
  year = {2015},
  journal = {IEEE/ASME transactions on mechatronics: A joint publication of the IEEE Industrial Electronics Society and the ASME Dynamic Systems and Control Division},
  volume = {20},
  number = {3},
  pages = {1117--1129}
}

@article{ha2019reinforcement,
  title = {Reinforcement {{Learning}} for {{Improving Agent Design}}},
  author = {Ha, David},
  year = {2019},
  month = nov,
  journal = {Artificial Life},
  volume = {25},
  number = {4},
  pages = {352--365},
  issn = {1064-5462},
  doi = {10.1162/artl_a_00301},
  urldate = {2022-08-09},
  abstract = {In many reinforcement learning tasks, the goal is to learn a policy to manipulate an agent, whose design is fixed, to maximize some notion of cumulative reward. The design of the agent's physical structure is rarely optimized for the task at hand. In this work, we explore the possibility of learning a version of the agent's design that is better suited for its task, jointly with the policy. We propose an alteration to the popular OpenAI Gym framework, where we parameterize parts of an environment, and allow an agent to jointly learn to modify these environment parameters along with its policy. We demonstrate that an agent can learn a better structure of its body that is not only better suited for the task, but also facilitates policy learning. Joint learning of policy and structure may even uncover design principles that are useful for assisted-design applications.}
}

@article{tan2011stable,
  title = {Stable {{Proportional-Derivative Controllers}}},
  author = {Tan, Jie and Liu, Karen and Turk, Greg},
  year = {2011},
  journal = {IEEE Computer Graphics and Applications},
  volume = {31},
  number = {4},
  pages = {34--44},
  doi = {10.1109/MCG.2011.30},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@tan2011stable-Stable Proportional-Derivative Controllers.pdf}
}

@article{geijtenbeek2012interactive,
  title = {Interactive {{Character Animation Using Simulated Physics}}: {{A State-of-the-Art Review}}},
  shorttitle = {Interactive {{Character Animation Using Simulated Physics}}},
  author = {Geijtenbeek, T. and Pronost, N.},
  year = {2012},
  month = dec,
  journal = {Computer Graphics Forum},
  volume = {31},
  number = {8},
  pages = {2492--2515},
  issn = {01677055},
  doi = {10.1111/j.1467-8659.2012.03189.x},
  urldate = {2022-06-10},
  abstract = {Physics simulation offers the possibility of truly responsive and realistic animation. Despite wide adoption of physics simulation for the animation of passive phenomena, such as fluids, cloths and rag-doll characters, commercial applications still resort to kinematics-based approaches for the animation of actively controlled characters. However, following a renewed interest in the use of physics simulation for interactive character animation, many recent publications demonstrate tremendous improvements in robustness, visual quality and usability. We present a structured review of over two decades of research on physics-based character animation, as well as point out various open research areas and possible future directions.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@geijtenbeek2012interactive-Interactive Character Animation Using Simulated Physics - A State-of-the-Art.pdf}
}

@article{liu2012terrain,
  title = {Terrain Runner: Control, Parameterization, Composition, and Planning for Highly Dynamic Motions},
  shorttitle = {Terrain Runner},
  author = {Liu, Libin and Yin, KangKang and {van de Panne}, Michiel and Guo, Baining},
  year = {2012},
  month = nov,
  journal = TOG,
  volume = {31},
  number = {6},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2366145.2366173},
  urldate = {2022-06-10},
  abstract = {In this paper we learn the skills required by real-time physics-based avatars to perform parkour-style fast terrain crossing using a mix of running, jumping, speed-vaulting, and drop-rolling. We begin with a single motion capture example of each skill and then learn reduced-order linear feedback control laws that provide robust execution of the motions during forward dynamic simulation. We then parameterize each skill with respect to the environment, such as the height of obstacles, or with respect to the task parameters, such as running speed and direction. We employ a continuation process to achieve the required parameterization of the motions and their affine feedback laws. The continuation method uses a predictor-corrector method based on radial basis functions. Lastly, we build control laws specific to the sequential composition of different skills, so that the simulated character can robustly transition to obstacle clearing maneuvers from running whenever obstacles are encountered. The learned transition skills work in tandem with a simple online step-based planning algorithm, and together they robustly guide the character to achieve a state that is well-suited for the chosen obstacle-clearing motion.},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\7NVJ9HBW\\2012 - TOG - Terrain runner.mov;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@liu2012terrain-Terrain runner - control, parameterization, composition, and planning for highly.pdf}
}

@article{peng2021amp,
  title = {{{AMP}}: Adversarial Motion Priors for Stylized Physics-Based Character Control},
  shorttitle = {{{AMP}}},
  author = {Peng, Xue Bin and Ma, Ze and Abbeel, Pieter and Levine, Sergey and Kanazawa, Angjoo},
  year = {2021},
  month = aug,
  journal = TOG,
  volume = {40},
  number = {4},
  pages = {1--20},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3450626.3459670},
  urldate = {2022-02-15},
  abstract = {Synthesizing graceful and life-like behaviors for physically simulated characters has been a fundamental challenge in computer animation. Data-driven methods that leverage motion tracking are a prominent class of techniques for producing high fidelity motions for a wide range of behaviors. However, the effectiveness of these tracking-based methods often hinges on carefully designed objective functions, and when applied to large and diverse motion datasets, these methods require significant additional machinery to select the appropriate motion for the character to track in a given scenario. In this work, we propose to obviate the need to manually design imitation objectives and mechanisms for motion selection by utilizing a fully automated approach based on adversarial imitation learning. High-level task objectives that the character should perform can be specified by relatively simple reward functions, while the low-level style of the character's behaviors can be specified by a dataset of unstructured motion clips, without any explicit clip selection or sequencing. For example, a character traversing an obstacle course might utilize a task-reward that only considers forward progress, while the dataset contains clips of relevant behaviors such as running, jumping, and rolling. These motion clips are used to train an adversarial motion prior, which specifies style-rewards for training the character through reinforcement learning (RL). The adversarial RL procedure automatically selects which motion to perform, dynamically interpolating and generalizing from the dataset. Our system produces high-quality motions that are comparable to those achieved by state-of-the-art tracking-based techniques, while also being able to easily accommodate large datasets of unstructured motion clips. Composition of disparate skills emerges automatically from the motion prior, without requiring a high-level motion planner or other task-specific annotations of the motion clips. We demonstrate the effectiveness of our framework on a diverse cast of complex simulated characters and a challenging suite of motor control tasks.},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\HTPM3VXH\\2021 - TOG - AMP.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@peng2021amp-AMP - adversarial motion priors for stylized physics-based character control.pdf}
}

@inproceedings{raibert1991animation,
  title = {Animation of {{Dynamic Legged Locomotion}}},
  booktitle = SIGGRAPH,
  author = {Raibert, Marc H. and Hodgins, Jessica K.},
  year = {1991},
  series = {{{SIGGRAPH}} '91},
  pages = {349--358},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/122718.122755},
  abstract = {This paper is about the use of control algorithms to animate dynamic legged locomotion. Control could free the animator from specifying the details of joint and limb motion while producing both physically realistic and natural looking results. We implemented computer animations of a biped robot, a quadruped robot, and a kangaroo. Each creature was modeled as a linked set of rigid bodies with compliant actuators at its joints. Control algorithms regulated the running speed, organized use of the legs, and maintained balance. All motions were generated by numerically integrating equations of motion derived from the physical models. The resulting behavior included running at various speeds, traveling with several gaits (run, trot, bound, gallop, and hop), jumping, and traversing simple paths. Whereas the use of control permitted a variety of physically realistic animated behavior to be generated with limited human intervention, the process of designing the control algorithms was not automated: the algorithms were "tweaked" and adjusted for each new creature.},
  isbn = {0-89791-436-8},
  keywords = {computer animation,dynamical simulation,legged locomotion,motion control,physically realistic modeling,robotics},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@raibert1991animation-Animation of Dynamic Legged Locomotion.pdf}
}

@article{peng2015dynamic,
  title = {Dynamic {{Terrain Traversal Skills Using Reinforcement Learning}}},
  author = {Peng, Xue Bin and Berseth, Glen and {van de Panne}, Michiel},
  year = {2015},
  journal = TOG,
  volume = {34},
  number = {4},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0730-0301},
  doi = {10.1145/2766910},
  abstract = {The locomotion skills developed for physics-based characters most often target flat terrain. However, much of their potential lies with the creation of dynamic, momentum-based motions across more complex terrains. In this paper, we learn controllers that allow simulated characters to traverse terrains with gaps, steps, and walls using highly dynamic gaits. This is achieved using reinforcement learning, with careful attention given to the action representation, non-parametric approximation of both the value function and the policy; epsilon-greedy exploration; and the learning of a good state distance metric. The methods enable a 21-link planar dog and a 7-link planar biped to navigate challenging sequences of terrain using bounding and running gaits. We evaluate the impact of the key features of our skill learning pipeline on the resulting performance.},
  keywords = {computer animation,physics simulation},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\5PQJHD46\\2015 - TOG - Dynamic Terrain Traversal Skills Using Reinforcement Learning.zip;C\:\\Users\\lenovo\\Zotero\\storage\\CSFVZG2M\\2015 - TOG - Dynamic Terrain Traversal Skills Using Reinforcement Learning.mp4;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@peng2015dynamic-Dynamic Terrain Traversal Skills Using Reinforcement Learning.pdf}
}

@article{watkins1992qlearning,
  title = {Q-Learning},
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  year = {1992},
  month = may,
  journal = {Machine Learning},
  volume = {8},
  number = {3},
  pages = {279--292},
  issn = {1573-0565},
  doi = {10.1007/BF00992698},
  abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@watkins1992qlearning-Q-learning.pdf}
}

@inproceedings{silver2014deterministic,
  title = {Deterministic {{Policy Gradient Algorithms}}},
  booktitle = ICML,
  author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year = {2014},
  series = {{{ICML}}'14},
  pages = {I--387--I--395},
  publisher = {JMLR.org},
  address = {Beijing, China},
  abstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counterparts in high-dimensional action spaces.},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\5ZWWMZ88\\Silver_2014_Deterministic Policy Gradient Algorithms2.pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@silver2014deterministic-Deterministic Policy Gradient Algorithms.pdf}
}

@inproceedings{lillicrap2016continuous,
  title = {Continuous Control with Deep Reinforcement Learning},
  booktitle = ICLR,
  author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  year = {2016},
  pages = {14},
  abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies ``end-to-end'': directly from raw pixel inputs.},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lillicrap2016continuous-Continuous control with deep reinforcement learning.pdf}
}

@inproceedings{mnih2016asynchronous,
  title = {Asynchronous {{Methods}} for {{Deep Reinforcement Learning}}},
  booktitle = ICML,
  author = {Mnih, Volodymyr and Badia, Adri{\`a} Puigdom{\`e}nech and Mirza, Mehdi and Graves, Alex and Harley, Tim and Lillicrap, Timothy P. and Silver, David and Kavukcuoglu, Koray},
  year = {2016},
  series = {{{ICML}}'16},
  pages = {1928--1937},
  publisher = {JMLR.org},
  address = {New York, NY, USA},
  abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mnih2016asynchronous-Asynchronous Methods for Deep Reinforcement Learning.pdf}
}

@inproceedings{degris2012modelfree,
  title = {Model-{{Free}} Reinforcement Learning with Continuous Action in Practice},
  booktitle = {American {{Control Conference}} ({{ACC}})},
  author = {Degris, Thomas and Pilarski, Patrick M. and Sutton, Richard S.},
  year = {2012},
  pages = {2177--2182},
  doi = {10.1109/ACC.2012.6315022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@degris2012modelfree-Model-Free reinforcement learning with continuous action in practice.pdf}
}

@inproceedings{sutton1999policy,
  title = {Policy {{Gradient Methods}} for {{Reinforcement Learning}} with {{Function Approximation}}},
  booktitle = NeurIPS,
  author = {Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
  year = {1999},
  series = {{{NIPS}}'99},
  pages = {1057--1063},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sutton1999policy-Policy Gradient Methods for Reinforcement Learning with Function Approximation.pdf}
}

@inproceedings{haarnoja2018soft,
  title = {Soft {{Actor-Critic}}: {{Off-Policy Maximum Entropy Deep Reinforcement Learning}} with a {{Stochastic Actor}}},
  shorttitle = {Soft {{Actor-Critic}}},
  booktitle = ICML,
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  year = {2018},
  month = aug,
  number = {arXiv:1801.01290},
  eprint = {1801.01290},
  primaryclass = {cs, stat},
  urldate = {2022-05-25},
  abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an offpolicy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@haarnoja2018soft-Soft Actor-Critic - Off-Policy Maximum Entropy Deep Reinforcement Learning with.pdf}
}

@inproceedings{li2021mfeshb,
  title = {{{MFES-HB}}: {{Efficient Hyperband}} with {{Multi-Fidelity Quality Measurements}}},
  shorttitle = {{{MFES-HB}}},
  booktitle = AAAI,
  author = {Li, Yang and Shen, Yu and Jiang, Jiawei and Gao, Jinyang and Zhang, Ce and Cui, Bin},
  year = {2021},
  month = aug,
  number = {arXiv:2012.03011},
  eprint = {2012.03011},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2022-05-24},
  abstract = {Hyperparameter optimization (HPO) is a fundamental problem in automatic machine learning (AutoML). However, due to the expensive evaluation cost of models (e.g., training deep learning models or training models on large datasets), vanilla Bayesian optimization (BO) is typically computationally infeasible. To alleviate this issue, Hyperband (HB) utilizes the early stopping mechanism to speed up configuration evaluations by terminating those badly-performing configurations in advance. This leads to two kinds of quality measurements: (1) many low-fidelity measurements for configurations that get early-stopped, and (2) few high-fidelity measurements for configurations that are evaluated without being early stopped. The state-of-the-art HB-style method, BOHB, aims to combine the benefits of both BO and HB. Instead of sampling configurations randomly in HB, BOHB samples configurations based on a BO surrogate model, which is constructed with the high-fidelity measurements only. However, the scarcity of high-fidelity measurements greatly hampers the efficiency of BO to guide the configuration search.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2021mfeshb-MFES-HB - Efficient Hyperband with Multi-Fidelity Quality Measurements.pdf}
}

@inproceedings{hu2021neural,
  title = {Neural Fidelity Warping for Efficient Robot Morphology Design},
  booktitle = ICRA,
  author = {Hu, Sha and Yang, Zeshi and Mori, Greg},
  year = {2021},
  pages = {7079--7086},
  publisher = {IEEE},
  doi = {10.1109/ICRA48506.2021.9561733},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hu2021neural-Neural fidelity warping for efficient robot morphology design.pdf}
}

@article{li2017hyperband,
  title = {Hyperband: {{A Novel Bandit-Based Approach}} to {{Hyperparameter Optimization}}},
  author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year = {2017},
  journal = JMLR,
  volume = {18},
  number = {1},
  pages = {6765--6816},
  publisher = {JMLR.org},
  issn = {1532-4435},
  abstract = {Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration nonstochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.},
  keywords = {deep learning,hyperparameter optimization,infinite-armed bandits,model selection,online optimization},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2017hyperband-Hyperband - A Novel Bandit-Based Approach to Hyperparameter Optimization.pdf}
}

@misc{yao2019taking,
  title = {Taking {{Human}} out of {{Learning Applications}}: {{A Survey}} on {{Automated Machine Learning}}},
  shorttitle = {Taking {{Human}} out of {{Learning Applications}}},
  author = {Yao, Quanming and Wang, Mengshuo and Chen, Yuqiang and Dai, Wenyuan and Li, Yu-Feng and Tu, Wei-Wei and Yang, Qiang and Yu, Yang},
  year = {2019},
  month = dec,
  number = {arXiv:1810.13306},
  eprint = {1810.13306},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2022-05-24},
  abstract = {Machine learning techniques have deeply rooted in our everyday life. However, since it is knowledge- and labor-intensive to pursue good learning performance, humans are heavily involved in every aspect of machine learning. To make machine learning techniques easier to apply and reduce the demand for experienced human experts, automated machine learning (AutoML) has emerged as a hot topic with both industrial and academic interest. In this paper, we provide an up to date survey on AutoML. First, we introduce and define the AutoML problem, with inspiration from both realms of automation and machine learning. Then, we propose a general AutoML framework that not only covers most existing approaches to date, but also can guide the design for new methods.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yao2019taking-Taking Human out of Learning Applications - A Survey on Automated Machine.pdf}
}

@inproceedings{li2020neural,
  title = {Neural {{Graph Embedding}} for {{Neural Architecture Search}}},
  booktitle = AAAI,
  author = {Li, Wei and Gong, Shaogang and Zhu, Xiatian},
  year = {2020},
  month = apr,
  volume = {34},
  pages = {4707--4714},
  doi = {10.1609/aaai.v34i04.5903},
  urldate = {2022-03-12},
  abstract = {Existing neural architecture search (NAS) methods often operate in discrete or continuous spaces directly, which ignores the graphical topology knowledge of neural networks. This leads to suboptimal search performance and efficiency, given the factor that neural networks are essentially directed acyclic graphs (DAG). In this work, we address this limitation by introducing a novel idea of neural graph embedding (NGE). Specifically, we represent the building block (i.e. the cell) of neural networks with a neural DAG, and learn it by leveraging a Graph Convolutional Network to propagate and model the intrinsic topology information of network architectures. This results in a generic neural network representation integrable with different existing NAS frameworks. Extensive experiments show the superiority of NGE over the state-of-the-art methods on image classification and semantic segmentation.},
  langid = {english},
  keywords = {architecture encoding,graph embedding},
  annotation = {AAAI},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\BKNTEYBG\\2020 - AAAI - Neural Graph Embedding for Neural Architecture Search.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@li2020neural-Neural Graph Embedding for Neural Architecture Search.pdf}
}

@article{wang2020transfer,
  title = {Transfer Stacking from Low-to High-Fidelity: {{A}} Surrogate-Assisted Bi-Fidelity Evolutionary Algorithm},
  shorttitle = {Transfer Stacking from Low-to High-Fidelity},
  author = {Wang, Handing and Jin, Yaochu and Yang, Cuie and Jiao, Licheng},
  year = {2020},
  month = jul,
  journal = {Applied Soft Computing},
  volume = {92},
  pages = {106276},
  issn = {15684946},
  doi = {10.1016/j.asoc.2020.106276},
  urldate = {2022-03-01},
  abstract = {Optimization of many real-world optimization problems relies on numerical simulations for function evaluations. In some cases, both high- and low-fidelity simulations are available, where the high fidelity evaluation is accurate but time-consuming, whereas the low-fidelity evaluation is less accurate but computationally cheap. To find an acceptable optimum within a limited budget, it is economical for evolutionary algorithms to use both high- and low-fidelity evaluations in a single optimization search. This paper proposes a novel surrogate-assisted evolutionary algorithm using the transfer stacking technique for bi-fidelity optimization. To this end, a radial basis function network is firstly built to approximate the high-fidelity fitness function as additional low-fidelity evaluation, then a surrogate model transferring the original and additional low-fidelity evaluations to the expensive high-fidelity evaluation is adapted to guide the search. The simulation results on a series of bi-fidelity optimization benchmark problems with resolution, stochastic, and instability errors and a beneficiation processes optimization problem show that the proposed algorithm is both effective and efficient for solving bi-fidelity optimization problems, when their low-fidelity evaluations have resolution and stochastic errors.},
  langid = {english},
  file = {D\:\\Study\\Data\\zotfile\\Applied Soft Computing2020_Transfer stacking from low-to high-fidelity - A surrogate-assisted bi-fidelity @wang2020transfer.docx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@wang2020transfer-Transfer stacking from low-to high-fidelity - A surrogate-assisted bi-fidelity.pdf}
}

@inproceedings{ning2020generic,
  title = {A {{Generic Graph-Based Neural Architecture Encoding Scheme}} for {{Predictor-Based NAS}}},
  booktitle = ECCV,
  author = {Ning, Xuefei and Zheng, Yin and Zhao, Tianchen and Wang, Yu and Yang, Huazhong},
  editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  year = {2020},
  volume = {12358},
  pages = {189--204},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2022-03-12},
  abstract = {This work proposes a novel Graph-based neural ArchiTecture Encoding Scheme, a.k.a. GATES, to improve the predictor-based neural architecture search. Specifically, different from existing graphbased schemes, GATES models the operations as the transformation of the propagating information, which mimics the actual data processing of neural architecture. GATES is a more reasonable modeling of the neural architectures, and can encode architectures from both the ``operation on node'' and ``operation on edge'' cell search spaces consistently. Experimental results on various search spaces confirm GATES's effectiveness in improving the performance predictor. Furthermore, equipped with the improved performance predictor, the sample efficiency of the predictorbased neural architecture search (NAS) flow is boosted.},
  isbn = {978-3-030-58600-3 978-3-030-58601-0},
  langid = {english},
  keywords = {architecture encoding},
  annotation = {ECCV},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\IEBA6QKT\\2020 - ECCV - A Generic Graph-Based Neural Architecture Encoding Scheme for Predictor-Based.pptx;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@ning2020generic-A Generic Graph-Based Neural Architecture Encoding Scheme for Predictor-Based.pdf}
}

@inproceedings{chen2020hardware,
  title = {Hardware as {{Policy}}: {{Mechanical}} and {{Computational Co-Optimization}} Using {{Deep Reinforcement Learning}}},
  shorttitle = {Hardware as {{Policy}}},
  booktitle = CoRL,
  author = {Chen, Tianjian and He, Zhanpeng and Ciocarlie, Matei},
  year = {2020},
  month = nov,
  number = {arXiv:2008.04460},
  eprint = {2008.04460},
  primaryclass = {cs},
  urldate = {2022-05-24},
  abstract = {Deep Reinforcement Learning (RL) has shown great success in learning complex control policies for a variety of applications in robotics. However, in most such cases, the hardware of the robot has been considered immutable, modeled as part of the environment. In this study, we explore the problem of learning hardware and control parameters together in a unified RL framework. To achieve this, we propose to model the robot body as a ``hardware policy'', analogous to and optimized jointly with its computational counterpart. We show that, by modeling such hardware policies as auto-differentiable computational graphs, the ensuing optimization problem can be solved efficiently by gradient-based algorithms from the Policy Optimization family. We present two such design examples: a toy mass-spring problem, and a real-world problem of designing an underactuated hand. We compare our method against traditional co-optimization approaches, and also demonstrate its effectiveness by building a physical prototype based on the learned hardware parameters. Videos and more details are available at https://roamlab.github.io/hwasp/ .},
  archiveprefix = {arXiv},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2020hardware-Hardware as Policy - Mechanical and Computational Co-Optimization using Deep.pdf}
}

@article{morphgrower,
  title = {{{MORPHGROWER}}: {{A SYNCHRONIZED LAYER-BY-LAYER GROWING APPROACH FOR PLAUSIBLE AND DIVERSE NEURONAL MORPHOLOGY GENERATION}}},
  journal = {ArXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@morphgrower-MORPHGROWER - A SYNCHRONIZED LAYER-BY-LAYER GROWING APPROACH FOR PLAUSIBLE AND.pdf}
}

@article{morphological,
  title = {{{MORPHOLOGICAL MAZE}}: {{CONTROL RECONFIGURABLE SOFT ROBOTS WITH FINE-GRAINED MORPHOLOGY CHANGE}}},
  journal = {ArXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@morphological-MORPHOLOGICAL MAZE - CONTROL RECONFIGURABLE SOFT ROBOTS WITH FINE-GRAINED.pdf}
}

@inproceedings{singh2022progprompt,
  title = {{{ProgPrompt}}: {{Generating Situated Robot Task Plans}} Using {{Large Language Models}}},
  shorttitle = {{{ProgPrompt}}},
  booktitle = ICRA,
  author = {Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  year = {2022},
  month = sep,
  eprint = {2209.11302},
  primaryclass = {cs},
  publisher = ICRA,
  urldate = {2023-10-18},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Robotics,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@singh2022progprompt-ProgPrompt - Generating Situated Robot Task Plans using Large Language Models.pdf}
}

@article{xu2023wizardlm,
  title = {{{WizardLM}}: {{Empowering Large Language Models}} to {{Follow Complex Instructions}}},
  shorttitle = {{{WizardLM}}},
  author = {Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  year = {2023},
  month = jun,
  journal = {arXiv},
  eprint = {2304.12244},
  primaryclass = {cs},
  urldate = {2023-10-28},
  abstract = {Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM model are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation, WizardLM achieves more than 90\% capacity of ChatGPT on 17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing LLMs. Our code and data are public at https://github.com/nlpxucan/WizardLM.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2023wizardlm-WizardLM - Empowering Large Language Models to Follow Complex Instructions.pdf}
}

@article{zhu2023large,
  title = {Large {{Language Models}} Can {{Learn Rules}}},
  author = {Zhu, Zhaocheng and Xue, Yuan and Chen, Xinyun and Zhou, Denny and Tang, Jian and Schuurmans, Dale and Dai, Hanjun},
  year = {2023},
  month = oct,
  journal = {arXiv},
  eprint = {2310.07064},
  primaryclass = {cs},
  urldate = {2023-10-28},
  abstract = {When prompted with a few examples and intermediate steps, large language models (LLMs) have demonstrated impressive performance in various reasoning tasks. However, prompting methods that rely on implicit knowledge in an LLM often hallucinate incorrect answers when the implicit knowledge is wrong or inconsistent with the task. To tackle this problem, we present Hypotheses-to-Theories (HtT), a framework that learns a rule library for reasoning with LLMs. HtT contains two stages, an induction stage and a deduction stage. In the induction stage, an LLM is first asked to generate and verify rules over a set of training examples. Rules that appear and lead to correct answers sufficiently often are collected to form a rule library. In the deduction stage, the LLM is then prompted to employ the learned rule library to perform reasoning to answer test questions. Experiments on both numerical reasoning and relational reasoning problems show that HtT improves existing prompting methods, with an absolute gain of 11-27\% in accuracy. The learned rules are also transferable to different models and to different forms of the same problem.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhu2023large-Large Language Models can Learn Rules.pdf}
}

@inproceedings{yao2023tree,
  title = {Tree of {{Thoughts}}: {{Deliberate Problem Solving}} with {{Large Language Models}}},
  shorttitle = {Tree of {{Thoughts}}},
  booktitle = NeurIPS,
  author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
  year = {2023},
  month = may,
  eprint = {2305.10601},
  primaryclass = {cs},
  urldate = {2023-10-28},
  abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, ``Tree of Thoughts'' (ToT), which generalizes over the popular ``Chain of Thought'' approach to prompting language models, and enables exploration over coherent units of text (``thoughts'') that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yao2023tree-Tree of Thoughts - Deliberate Problem Solving with Large Language Models.pdf}
}

@article{wang2023survey,
  title = {A {{Survey}} on {{Large Language Model}} Based {{Autonomous Agents}}},
  author = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Ji-Rong},
  year = {2023},
  month = sep,
  journal = {arxiv},
  eprint = {2308.11432},
  primaryclass = {cs},
  urldate = {2023-10-28},
  abstract = {Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023survey-A Survey on Large Language Model based Autonomous Agents.pdf}
}

@article{liu2023llm,
  title = {{{LLM}}+{{P}}: {{Empowering Large Language Models}} with {{Optimal Planning Proficiency}}},
  author = {Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  year = {2023},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2023llm-LLM+P - Empowering Large Language Models with Optimal Planning Proficiency.pdf}
}

@article{packer2023memgpt,
  title = {{{MemGPT}}: {{Towards LLMs}} as {{Operating Systems}}},
  author = {Packer, Charles and Fang, Vivian and Patil, Shishir G and Lin, Kevin and Wooders, Sarah and Gonzalez, Joseph E},
  year = {2023},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@packer2023memgpt-MemGPT - Towards LLMs as Operating Systems.pdf}
}

@article{tang2023graphgpt,
  title = {{{GraphGPT}}: {{Graph Instruction Tuning}} for {{Large Language Models}}},
  author = {Tang, Jiabin and Yang, Yuhao and Wei, Wei and Shi, Lei and Su, Lixin and Cheng, Suqi and Yin, Dawei and Huang, Chao},
  year = {2023},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@tang2023graphgpt-GraphGPT - Graph Instruction Tuning for Large Language Models.pdf}
}

@article{xin2023legoprover,
  title = {{{LEGO-Prover}}: {{Neural Theorem Proving}} with {{Growing Libraries}}},
  author = {Xin, Huajian and Wang, Haiming and Zheng, Chuanyang and Li, Lin and Liu, Zhengying and Cao, Qingxing and Huang, Yinya and Xiong, Jing and Shi, Han and Xie, Enze and others},
  year = {2023},
  journal = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xin2023legoprover-LEGO-Prover - Neural Theorem Proving with Growing Libraries.pdf}
}

@article{dijkstra1959note,
  title = {A Note on Two Problems in Connexion with Graphs},
  author = {Dijkstra, E. W.},
  year = {1959},
  journal = {Numerische Mathematik},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@dijkstra1959note-A note on two problems in connexion with graphs.pdf}
}

@article{liang2023movln,
  title = {{{MO-VLN}}: {{A Multi-Task Benchmark}} for {{Open-set Zero-Shot Vision-and-Language Navigation}}},
  author = {Liang, Xiwen and Ma, Liang and Guo, Shanshan and Han, Jianhua and Xu, Hang and Ma, Shikui and Liang, Xiaodan},
  year = {2023},
  journal = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liang2023movln-MO-VLN - A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language.pdf}
}

@article{park2023generative,
  title = {Generative Agents: {{Interactive}} Simulacra of Human Behavior},
  author = {Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  year = {2023},
  journal = {arXiv preprint arXiv:2304.03442},
  eprint = {2304.03442},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@park2023generative-Generative agents - Interactive simulacra of human behavior.pdf}
}

@article{shen2023hugginggpt,
  title = {Hugginggpt: {{Solving}} Ai Tasks with Chatgpt and Its Friends in Huggingface},
  author = {Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  year = {2023},
  journal = {arXiv preprint arXiv:2303.17580},
  eprint = {2303.17580},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@shen2023hugginggpt-Hugginggpt - Solving ai tasks with chatgpt and its friends in huggingface.pdf}
}

@article{schick2023toolformer,
  title = {Toolformer: {{Language}} Models Can Teach Themselves to Use Tools},
  author = {Schick, Timo and {Dwivedi-Yu}, Jane and Dess{\`i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  year = {2023},
  journal = {arXiv preprint arXiv:2302.04761},
  eprint = {2302.04761},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@schick2023toolformer-Toolformer - Language models can teach themselves to use tools.pdf}
}

@article{brohan2022rt1,
  title = {Rt-1: {{Robotics}} Transformer for Real-World Control at Scale},
  author = {Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2212.06817},
  eprint = {2212.06817},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@brohan2022rt1-Rt-1 - Robotics transformer for real-world control at scale.pdf}
}

@inproceedings{wu2021micros,
  title = {{{micROS}}.{{BT}}: {{An Event-Driven Behavior Tree Framework}} for {{Swarm Robots}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Wu, Yunlong and Li, Jinghua and Dai, Huadong and Yi, Xiaodong and Wang, Yanzhen and Yang, Xuejun},
  year = {2021},
  pages = {9146--9153},
  doi = {10.1109/IROS51168.2021.9636460},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2021micros-micROS.BT - An Event-Driven Behavior Tree Framework for Swarm Robots.pdf}
}

@article{ahn2022can,
  title = {Do as i Can, Not as i Say: {{Grounding}} Language in Robotic Affordances},
  author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2204.01691},
  eprint = {2204.01691},
  abstract = {Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's ``hands and eyes,'' while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website, the video, and open sourced code in a tabletop domain can be found at say-can.github.io.},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ahn2022can-Do as i can, not as i say - Grounding language in robotic affordances.pdf}
}

@article{huang2022inner,
  title = {Inner Monologue: {{Embodied}} Reasoning through Planning with Language Models},
  author = {Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2207.05608},
  eprint = {2207.05608},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2022inner-Inner monologue - Embodied reasoning through planning with language models.pdf}
}

@article{zeng2022socratic,
  title = {Socratic Models: {{Composing}} Zero-Shot Multimodal Reasoning with Language},
  author = {Zeng, Andy and Attarian, Maria and Ichter, Brian and Choromanski, Krzysztof and Wong, Adrian and Welker, Stefan and Tombari, Federico and Purohit, Aveek and Ryoo, Michael and Sindhwani, Vikas and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2204.00598},
  eprint = {2204.00598},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zeng2022socratic-Socratic models - Composing zero-shot multimodal reasoning with language.pdf}
}

@article{chen2023robogpt,
  title = {{{RoboGPT}}: An Intelligent Agent of Making Embodied Long-Term Decisions for Daily Instruction Tasks},
  author = {Chen, Yaran and Cui, Wenbo and Chen, Yuanwen and Tan, Mining and Zhang, Xinyao and Zhao, Dongbin and Wang, He},
  year = {2023},
  journal = {arXiv preprint arXiv:2311.15649},
  eprint = {2311.15649},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023robogpt-RoboGPT - an intelligent agent of making embodied long-term decisions for daily.pdf}
}

@article{chaudhuri2021neurosymbolic,
  title = {Neurosymbolic Programming},
  author = {Chaudhuri, Swarat and Ellis, Kevin and Polozov, Oleksandr and Singh, Rishabh and {Solar-Lezama}, Armando and Yue, Yisong and others},
  year = {2021},
  journal = {Foundations and Trends{\textregistered} in Programming Languages},
  volume = {7},
  number = {3},
  pages = {158--243},
  publisher = {Now Publishers, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chaudhuri2021neurosymbolic-Neurosymbolic programming.pdf}
}

@article{daniele2022deep,
  title = {Deep Symbolic Learning: {{Discovering}} Symbols and Rules from Perceptions},
  author = {Daniele, Alessandro and Campari, Tommaso and Malhotra, Sagar and Serafini, Luciano},
  year = {2022},
  journal = {arXiv preprint arXiv:2208.11561},
  eprint = {2208.11561},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@daniele2022deep-Deep symbolic learning - Discovering symbols and rules from perceptions.pdf}
}

@article{liu2023fimo,
  title = {Fimo: {{A}} Challenge Formal Dataset for Automated Theorem Proving},
  author = {Liu, Chengwu and Shen, Jianhao and Xin, Huajian and Liu, Zhengying and Yuan, Ye and Wang, Haiming and Ju, Wei and Zheng, Chuanyang and Yin, Yichun and Li, Lin and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.04295},
  eprint = {2309.04295},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2023fimo-Fimo - A challenge formal dataset for automated theorem proving.pdf}
}

@book{hodel2013introduction,
  title = {An Introduction to Mathematical Logic},
  author = {Hodel, Richard E},
  year = {2013},
  publisher = {Courier Corporation},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hodel2013introduction-An introduction to mathematical logic.pdf}
}

@article{jiang2019task,
  title = {Task Planning in Robotics: An Empirical Comparison of Pddl-and Asp-Based Systems},
  author = {Jiang, Yu-qian and Zhang, Shi-qi and Khandelwal, Piyush and Stone, Peter},
  year = {2019},
  journal = {Frontiers of Information Technology \& Electronic Engineering},
  volume = {20},
  pages = {363--373},
  publisher = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jiang2019task-Task planning in robotics - an empirical comparison of pddl-and asp-based systems.pdf}
}

@article{xi2023rise,
  title = {The Rise and Potential of Large Language Model Based Agents: {{A}} Survey},
  author = {Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.07864},
  eprint = {2309.07864},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xi2023rise-The rise and potential of large language model based agents - A survey.pdf}
}

@article{akakzia2020grounding,
  title = {Grounding Language to Autonomously-Acquired Skills via Goal Generation},
  author = {Akakzia, Ahmed and Colas, C{\'e}dric and Oudeyer, Pierre-Yves and Chetouani, Mohamed and Sigaud, Olivier},
  year = {2020},
  journal = {arXiv preprint arXiv:2006.07185},
  eprint = {2006.07185},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@akakzia2020grounding-Grounding language to autonomously-acquired skills via goal generation.pdf}
}

@article{pan2023logiclm,
  title = {Logic-Lm: {{Empowering}} Large Language Models with Symbolic Solvers for Faithful Logical Reasoning},
  author = {Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William Yang},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.12295},
  eprint = {2305.12295},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@pan2023logiclm-Logic-lm - Empowering large language models with symbolic solvers for faithful.pdf}
}

@article{gaur2023reasoning,
  title = {Reasoning in Large Language Models through Symbolic Math Word Problems},
  author = {Gaur, Vedant and Saunshi, Nikunj},
  year = {2023},
  journal = {arXiv preprint arXiv:2308.01906},
  eprint = {2308.01906},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gaur2023reasoning-Reasoning in large language models through symbolic math word problems.pdf}
}

@article{webb2023emergent,
  title = {Emergent Analogical Reasoning in Large Language Models},
  author = {Webb, Taylor and Holyoak, Keith J and Lu, Hongjing},
  year = {2023},
  journal = {Nature Human Behaviour},
  volume = {7},
  number = {9},
  pages = {1526--1541},
  publisher = {Nature Publishing Group UK London},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@webb2023emergent-Emergent analogical reasoning in large language models.pdf}
}

@inproceedings{kojima2022large,
  title = {Large {{Language Models}} Are {{Zero-Shot Reasoners}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kojima, Takeshi and Gu, Shixiang (Shane) and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {22199--22213},
  publisher = {Curran Associates, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kojima2022large-Large Language Models are Zero-Shot Reasoners.pdf}
}

@article{francis2022core,
  title = {Core Challenges in Embodied Vision-Language Planning},
  author = {Francis, Jonathan and Kitamura, Nariaki and Labelle, Felix and Lu, Xiaopeng and Navarro, Ingrid and Oh, Jean},
  year = {2022},
  journal = {Journal of Artificial Intelligence Research},
  volume = {74},
  pages = {459--515},
  urldate = {2024-01-02},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@francis2022core-Core challenges in embodied vision-language planning.pdf}
}

@inproceedings{lin2023grounded,
  title = {On Grounded Planning for Embodied Tasks with Language Models},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Lin, Bill Yuchen and Huang, Chengsong and Liu, Qian and Gu, Wenda and Sommerer, Sam and Ren, Xiang},
  year = {2023},
  volume = {37},
  pages = {13192--13200},
  urldate = {2024-01-02},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lin2023grounded-On grounded planning for embodied tasks with language models.pdf}
}

@article{zeng2023large,
  title = {Large Language Models for Robotics: {{A}} Survey},
  shorttitle = {Large Language Models for Robotics},
  author = {Zeng, Fanlong and Gan, Wensheng and Wang, Yongheng and Liu, Ning and Yu, Philip S.},
  year = {2023},
  journal = {arXiv preprint arXiv:2311.07226},
  eprint = {2311.07226},
  urldate = {2024-01-02},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zeng2023large-Large language models for robotics - A survey.pdf}
}

@inproceedings{shah2023lmnav,
  title = {Lm-Nav: {{Robotic}} Navigation with Large Pre-Trained Models of Language, Vision, and Action},
  booktitle = {Conference on {{Robot Learning}}},
  author = {Shah, Dhruv and Osi{\'n}ski, B{\textbackslash}la{\.z}ej and Levine, Sergey and others},
  year = {2023},
  pages = {492--504},
  publisher = {PMLR},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@shah2023lmnav-Lm-nav - Robotic navigation with large pre-trained models of language, vision,.pdf}
}

@inproceedings{song2023llmplanner,
  title = {{{LLM-Planner}}: {{Few-Shot Grounded Planning}} for {{Embodied Agents}} with {{Large Language Models}}},
  shorttitle = {{{LLM-Planner}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M. and Chao, Wei-Lun and Su, Yu},
  year = {2023},
  pages = {2998--3009},
  urldate = {2024-01-02},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@song2023llmplanner-LLM-Planner - Few-Shot Grounded Planning for Embodied Agents with Large Language.pdf}
}

@article{jansen2020visuallygrounded,
  title = {Visually-Grounded Planning without Vision: {{Language}} Models Infer Detailed Plans from High-Level Instructions},
  author = {Jansen, Peter A},
  year = {2020},
  journal = {arXiv preprint arXiv:2009.14259},
  eprint = {2009.14259},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jansen2020visuallygrounded-Visually-grounded planning without vision - Language models infer detailed plans.pdf}
}

@article{driess2023palme,
  title = {Palm-e: {{An}} Embodied Multimodal Language Model},
  author = {Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2303.03378},
  eprint = {2303.03378},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@driess2023palme-Palm-e - An embodied multimodal language model.pdf}
}

@inproceedings{shridhar2020alfred,
  title = {Alfred: {{A}} Benchmark for Interpreting Grounded Instructions for Everyday Tasks},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition},
  author = {Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  year = {2020},
  pages = {10740--10749},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@shridhar2020alfred-Alfred - A benchmark for interpreting grounded instructions for everyday tasks.pdf}
}

@article{duan2022survey,
  title = {A Survey of Embodied Ai: {{From}} Simulators to Research Tasks},
  author = {Duan, Jiafei and Yu, Samson and Tan, Hui Li and Zhu, Hongyuan and Tan, Cheston},
  year = {2022},
  journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume = {6},
  number = {2},
  pages = {230--244},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@duan2022survey-A survey of embodied ai - From simulators to research tasks.pdf}
}

@inproceedings{puig2018virtualhome,
  title = {Virtualhome: {{Simulating}} Household Activities via Programs},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Puig, Xavier and Ra, Kevin and Boben, Marko and Li, Jiaman and Wang, Tingwu and Fidler, Sanja and Torralba, Antonio},
  year = {2018},
  pages = {8494--8502},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@puig2018virtualhome-Virtualhome - Simulating household activities via programs.pdf}
}

@inproceedings{cao2023robot,
  title = {Robot {{Behavior-Tree-Based Task Generation}} with {{Large Language Models}}},
  booktitle = {Proceedings of {{AAAI Spring Symp}}. {{Challenges Requiring}} the {{Combination}} of {{Machine Learning}} and {{Knowledge Engineering}}},
  author = {Cao, Yue and Lee, {\relax CS}},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@cao2023robot-Robot Behavior-Tree-Based Task Generation with Large Language Models.pdf}
}

@inproceedings{wang2023learning,
  title = {Learning {{Hierarchical Robot Skills Represented}} by {{Behavior Trees}} from {{Natural Language}}},
  booktitle = {International {{Conference}} on {{Cooperative Information Systems}}},
  author = {Wang, Kaiyi and Zhao, Yongjia and Dai, Shuling and Yang, Minghao and He, Yichen and Zhang, Ning},
  year = {2023},
  pages = {366--383},
  publisher = {Springer},
  abstract = {Learning from natural language is a programming-free and user friendly teaching method that allows users without programming knowledge or demonstration capabilities to instruct robots, which has great value in industry and daily life. The manipulation skills of robots are often hierarchical skills composed of low-level primitive skills, so they can be conveniently represented by behavior trees (BTs). Based on this idea, we propose NL2BT, a framework for generating behavior trees from natural language and controlling robots to complete hierarchical tasks in real time. The framework consists of two language processing stages, an initial behavior tree library composed of primitive skill subtrees, and a BT-Generation algorithm. To validate the effectiveness of NL2BT, we use it to build a Chinese natural language system for instructing robots in performing 3C assembly tasks, which is a significant application of Industry 4.0. We also discuss the positive impact of real-time teaching, visual student models, and the synonymous skill module in the framework. In addition to the demonstrated application, NL2BT can be easily migrated to other languages and hierarchical task learning scenarios.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023learning-Learning Hierarchical Robot Skills Represented by Behavior Trees from Natural.pdf}
}

@article{lykov2023llmmars,
  title = {{{LLM-MARS}}: {{Large Language Model}} for {{Behavior Tree Generation}} and {{NLP-enhanced Dialogue}} in {{Multi-Agent Robot Systems}}},
  author = {Lykov, Artem and Dronova, Maria and Naglov, Nikolay and Litvinov, Mikhail and Satsevich, Sergei and Bazhenov, Artem and Berman, Vladimir and Shcherbak, Aleksei and Tsetserukou, Dzmitry},
  year = {2023},
  journal = {arXiv preprint arXiv:2312.09348},
  eprint = {2312.09348},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lykov2023llmmars-LLM-MARS - Large Language Model for Behavior Tree Generation and NLP-enhanced.pdf}
}

@article{ogren2022behavior,
  title = {Behavior Trees in Robot Control Systems},
  author = {{\"O}gren, Petter and Sprague, Christopher I},
  year = {2022},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {5},
  pages = {81--107},
  publisher = {Annual Reviews},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ogren2022behavior-Behavior trees in robot control systems.pdf}
}

@article{dortmans2022behavior,
  title = {Behavior {{Trees}} for {{Smart Robots Practical Guidelines}} for {{Robot Software Development}}.},
  author = {Dortmans, Eric and Punter, Teade},
  year = {2022},
  journal = {Journal of Robotics},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@dortmans2022behavior-Behavior Trees for Smart Robots Practical Guidelines for Robot Software.pdf}
}

@inproceedings{liang2022code,
  title = {Code as {{Policies}}: {{Language Model Programs}} for {{Embodied Control}}},
  booktitle = {{{arXiv}} Preprint {{arXiv}}:2209.07753},
  author = {Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  year = {2022},
  eprint = {2209.07753},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liang2022code-Code as Policies - Language Model Programs for Embodied Control.pdf}
}

@inproceedings{french2019learning,
  title = {Learning Behavior Trees from Demonstration},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {French, Kevin and Wu, Shiyu and Pan, Tianyang and Zhou, Zheming and Jenkins, Odest Chadwicke},
  year = {2019},
  pages = {7791--7797},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@french2019learning-Learning behavior trees from demonstration.pdf}
}

@article{iovino2022survey,
  title = {A Survey of Behavior Trees in Robotics and Ai},
  author = {Iovino, Matteo and Scukins, Edvards and Styrud, Jonathan and {\"O}gren, Petter and Smith, Christian},
  year = {2022},
  journal = {Robotics and Autonomous Systems},
  volume = {154},
  pages = {104096},
  publisher = {Elsevier}
}

@inproceedings{li2021reactive,
  title = {Reactive Task and Motion Planning under Temporal Logic Specifications},
  booktitle = ICRA,
  author = {Li, Shen and Park, Daehyung and Sung, Yoonchang and Shah, Julie A and Roy, Nicholas},
  year = {2021},
  pages = {12618--12624},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2021reactive-Reactive task and motion planning under temporal logic specifications.pdf}
}

@inproceedings{styrud2022combining,
  title = {Combining Planning and Learning of Behavior Trees for Robotic Assembly},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Styrud, Jonathan and Iovino, Matteo and Norrl{\"o}f, Mikael and Bj{\"o}rkman, M{\aa}rten and Smith, Christian},
  year = {2022},
  pages = {11511--11517},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@styrud2022combining-Combining planning and learning of behavior trees for robotic assembly.pdf}
}

@article{tadewos2022specificationguided,
  title = {Specification-Guided Behavior Tree Synthesis and Execution for Coordination of Autonomous Systems},
  author = {Tadewos, Tadewos G and Newaz, Abdullah Al Redwan and Karimoddini, Ali},
  year = {2022},
  journal = {Expert Systems with Applications},
  volume = {201},
  pages = {117022},
  publisher = {Elsevier},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@tadewos2022specificationguided-Specification-guided behavior tree synthesis and execution for coordination of.pdf}
}

@article{neupane2023designing,
  title = {Designing {{Behavior Trees}} from {{Goal-Oriented LTLf Formulas}}},
  author = {Neupane, Aadesh and Goodrich, Michael A},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.06399},
  eprint = {2307.06399},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@neupane2023designing-Designing Behavior Trees from Goal-Oriented LTLf Formulas.pdf}
}

@inproceedings{lim2010evolving,
  title = {Evolving Behaviour Trees for the Commercial Game {{DEFCON}}},
  booktitle = {Applications of {{Evolutionary Computation}}: {{EvoApplicatons}} 2010: {{EvoCOMPLEX}}, {{EvoGAMES}}, {{EvoIASP}}, {{EvoIN}}TEL{{LIGENCE}}, {{EvoNUM}}, and {{EvoSTOC}}, {{Istanbul}}, {{Turkey}}, {{April}} 7-9, 2010, {{Proceedings}}, {{Part I}}},
  author = {Lim, Chong-U and Baumgarten, Robin and Colton, Simon},
  year = {2010},
  pages = {100--110},
  publisher = {Springer}
}

@article{pereira2015framework,
  title = {A Framework for Constrained and Adaptive Behavior-Based Agents},
  author = {Pereira, Renato de Pontes and Engel, Paulo Martins},
  year = {2015},
  journal = {arXiv preprint arXiv:1506.02312},
  eprint = {1506.02312},
  archiveprefix = {arXiv}
}

@article{kannan2023smartllm,
  title = {Smart-Llm: {{Smart}} Multi-Agent Robot Task Planning Using Large Language Models},
  author = {Kannan, Shyam Sundar and Venkatesh, Vishnunandan LN and Min, Byung-Cheol},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.10062},
  eprint = {2309.10062},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kannan2023smartllm-Smart-llm - Smart multi-agent robot task planning using large language models.pdf}
}

@article{zhao2023erra,
  title = {{{ERRA}}: {{An Embodied Representation}} and {{Reasoning Architecture}} for {{Long-Horizon Language-Conditioned Manipulation Tasks}}},
  author = {Zhao, Chao and Yuan, Shuai and Jiang, Chunli and Cai, Junhao and Yu, Hongyu and Wang, Michael Yu and Chen, Qifeng},
  year = {2023},
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {6},
  pages = {3230--3237},
  doi = {10.1109/LRA.2023.3265893},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhao2023erra-ERRA - An Embodied Representation and Reasoning Architecture for Long-Horizon.pdf}
}

@inproceedings{ouyang2022training,
  title = {Training Language Models to Follow Instructions with Human Feedback},
  booktitle = NeurIPS,
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {27730--27744},
  publisher = {Curran Associates, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ouyang2022training-Training language models to follow instructions with human feedback.pdf}
}

@inproceedings{tran2023neurosymbolic,
  title = {Neurosymbolic Reasoning and Learning with Restricted Boltzmann Machines},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Tran, Son N and d'Avila Garcez, Artur},
  year = {2023},
  volume = {37},
  pages = {6558--6565}
}

@inproceedings{su2023webtr,
  title = {{{WE-BTR}}: {{A Behavior Tree Recommendation Method Based}} on {{Word Embedding}}},
  booktitle = {2023 {{IEEE}} 35th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}} ({{ICTAI}})},
  author = {Su, Hang and Li, Fu and Wang, Xueying and Li, Jinghua and Wu, Yunlong and Wang, Yanzhen},
  year = {2023},
  pages = {978--985},
  doi = {10.1109/ICTAI59109.2023.00146},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@su2023webtr-WE-BTR - A Behavior Tree Recommendation Method Based on Word Embedding.pdf}
}

@inproceedings{wang2020tcts,
  title = {{{TCTS}}: {{A Task-Consistent Two-Stage Framework}} for {{Person Search}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Wang, Cheng and Ma, Bingpeng and Chang, Hong and Shan, Shiguang and Chen, Xilin},
  year = {2020},
  month = jun,
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2020tcts-TCTS - A Task-Consistent Two-Stage Framework for Person Search.pdf}
}

@article{khan2023natural,
  title = {Natural {{Language Robot Programming}}: {{NLP}} Integrated with Autonomous Robotic Grasping},
  author = {Khan, Muhammad Arshad and Kenney, Max and Painter, Jack and Kamale, Disha and {Batista-Navarro}, Riza and {Ghalamzan-E}, Amir},
  year = {2023},
  journal = {arXiv preprint arXiv:2304.02993},
  eprint = {2304.02993},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@khan2023natural-Natural Language Robot Programming - NLP integrated with autonomous robotic.pdf}
}

@article{sun2021ernie,
  title = {Ernie 3.0: {{Large-scale}} Knowledge Enhanced Pre-Training for Language Understanding and Generation},
  author = {Sun, Yu and Wang, Shuohuan and Feng, Shikun and Ding, Siyu and Pang, Chao and Shang, Junyuan and Liu, Jiaxiang and Chen, Xuyi and Zhao, Yanbin and Lu, Yuxiang and others},
  year = {2021},
  journal = {arXiv preprint arXiv:2107.02137},
  eprint = {2107.02137},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2021ernie-Ernie 3.0 - Large-scale knowledge enhanced pre-training for language.pdf}
}

@article{colledanchise2016how,
  title = {How Behavior Trees Modularize Hybrid Control Systems and Generalize Sequential Behavior Compositions, the Subsumption Architecture, and Decision Trees},
  author = {Colledanchise, Michele and {\"O}gren, Petter},
  year = {2016},
  journal = {IEEE Transactions on robotics},
  volume = {33},
  number = {2},
  pages = {372--389},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2016how-How behavior trees modularize hybrid control systems and generalize sequential.pdf}
}

@article{ionescu2023are,
  title = {Are {{TikTok Algorithms Influencing Users}}' {{Self-Perceived Identities}} and {{Personal Values}}? {{A Mini Review}}},
  author = {Ionescu, Claudiu Gabriel and Licu, Monica},
  year = {2023},
  journal = {Social Sciences},
  volume = {12},
  number = {8},
  pages = {465},
  publisher = {MDPI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ionescu2023are-Are TikTok Algorithms Influencing Users Self-Perceived Identities and Personal.pdf}
}

@article{wang2022recommendation,
  title = {Recommendation Algorithm in {{TikTok}}: {{Strengths}}, Dilemmas, and Possible Directions},
  author = {Wang, Pengda},
  year = {2022},
  journal = {Int'l J. Soc. Sci. Stud.},
  volume = {10},
  pages = {60},
  publisher = {HeinOnline},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2022recommendation-Recommendation algorithm in TikTok - Strengths, dilemmas, and possible directions.pdf}
}

@article{zhu2024knowagent,
  title = {{{KnowAgent}}: {{Knowledge-Augmented Planning}} for {{LLM-Based Agents}}},
  author = {Zhu, Yuqi and Qiao, Shuofei and Ou, Yixin and Deng, Shumin and Zhang, Ningyu and Lyu, Shiwei and Shen, Yue and Liang, Lei and Gu, Jinjie and Chen, Huajun},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.03101},
  eprint = {2403.03101},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhu2024knowagent-KnowAgent - Knowledge-Augmented Planning for LLM-Based Agents.pdf}
}

@article{zhu2023ghost,
  title = {Ghost in the Minecraft: {{Generally}} Capable Agents for Open-World Enviroments via Large Language Models with Text-Based Knowledge and Memory},
  author = {Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.17144},
  eprint = {2305.17144},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhu2023ghost-Ghost in the minecraft - Generally capable agents for open-world enviroments via.pdf}
}

@inproceedings{liao2019synthesizing,
  title = {Synthesizing Environment-Aware Activities via Activity Sketches},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Liao, Yuan-Hong and Puig, Xavier and Boben, Marko and Torralba, Antonio and Fidler, Sanja},
  year = {2019},
  pages = {6291--6299},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@liao2019synthesizing-Synthesizing environment-aware activities via activity sketches.pdf}
}

@article{li2022pretrained,
  title = {Pre-Trained Language Models for Interactive Decision-Making},
  author = {Li, Shuang and Puig, Xavier and Paxton, Chris and Du, Yilun and Wang, Clinton and Fan, Linxi and Chen, Tao and Huang, De-An and Aky{\"u}rek, Ekin and Anandkumar, Anima and others},
  year = {2022},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {31199--31212},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2022pretrained-Pre-trained language models for interactive decision-making.pdf}
}

@inproceedings{siu2023stl,
  title = {{{STL}}: {{Surprisingly Tricky Logic}} (for {{System Validation}})},
  booktitle = IROS,
  author = {Siu, Ho Chit and Leahy, Kevin and Mann, Makai},
  year = {2023},
  pages = {8613--8620},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@siu2023stl-STL - Surprisingly Tricky Logic (for System Validation).pdf}
}

@article{gao2023retrievalaugmented,
  title = {Retrieval-Augmented Generation for Large Language Models: {{A}} Survey},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  year = {2023},
  journal = {arXiv preprint arXiv:2312.10997},
  eprint = {2312.10997},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2023retrievalaugmented-Retrieval-augmented generation for large language models - A survey.pdf}
}

@article{han2022folio,
  title = {Folio: {{Natural}} Language Reasoning with First-Order Logic},
  author = {Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Benson, Luke and Sun, Lucy and Zubova, Ekaterina and Qiao, Yujie and Burtell, Matthew and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2209.00840},
  eprint = {2209.00840},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@han2022folio-Folio - Natural language reasoning with first-order logic.pdf}
}

@inproceedings{bisson1992learning,
  title = {Learning in {{FOL}} with a Similarity Measure},
  booktitle = {Proceedings of the {{National Conference}} on {{Artificial Intelligence}}},
  author = {Bisson, Gilles},
  year = {1992},
  pages = {82--82},
  publisher = {JOHN WILEY \& SONS LTD},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bisson1992learning-Learning in FOL with a similarity measure.pdf}
}

@article{michelioudakis2024online,
  title = {Online Semi-Supervised Learning of Composite Event Rules by Combining Structure and Mass-Based Predicate Similarity},
  author = {Michelioudakis, Evangelos and Artikis, Alexander and Paliouras, Georgios},
  year = {2024},
  journal = {Machine Learning},
  volume = {113},
  number = {3},
  pages = {1445--1481},
  publisher = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@michelioudakis2024online-Online semi-supervised learning of composite event rules by combining structure.pdf}
}

@article{ontanon2020overview,
  title = {An Overview of Distance and Similarity Functions for Structured Data},
  author = {Onta{\~n}{\'o}n, Santiago},
  year = {2020},
  month = oct,
  journal = {Artificial Intelligence Review},
  volume = {53},
  number = {7},
  pages = {5309--5351},
  issn = {1573-7462},
  doi = {10.1007/s10462-020-09821-w},
  abstract = {The notions of distance and similarity play a key role in many machine learning approaches, and artificial intelligence in general, since they can serve as an organizing principle by which individuals classify objects, form concepts and make generalizations. While distance functions for propositional representations have been thoroughly studied, work on distance functions for structured representations, such as graphs, frames or logical clauses, has been carried out in different communities and is much less understood. Specifically, a significant amount of work that requires the use of a distance or similarity function for structured representations of data usually employs ad-hoc functions for specific applications. Therefore, the goal of this paper is to provide an overview of this work to identify connections between the work carried out in different areas and point out directions for future work.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ontanon2020overview-An overview of distance and similarity functions for structured data.pdf}
}

@article{ren2020query2box,
  title = {Query2box: {{Reasoning}} over Knowledge Graphs in Vector Space Using Box Embeddings},
  author = {Ren, Hongyu and Hu, Weihua and Leskovec, Jure},
  year = {2020},
  journal = {arXiv preprint arXiv:2002.05969},
  eprint = {2002.05969},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ren2020query2box-Query2box - Reasoning over knowledge graphs in vector space using box embeddings.pdf}
}

@article{wu2024neurosymbolic,
  title = {Neuro-Symbolic Recommendation Model Based on Logic Query},
  author = {Wu, Maonian and Chen, Bang and Zhu, Shaojun and Zheng, Bo and Peng, Wei and Zhang, Mingyi},
  year = {2024},
  journal = {Knowledge-Based Systems},
  volume = {284},
  pages = {111311},
  publisher = {Elsevier},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2024neurosymbolic-Neuro-symbolic recommendation model based on logic query.pdf}
}

@inproceedings{wang2023voyager,
  title = {Voyager: {{An Open-Ended Embodied Agent}} with {{Large Language Models}}},
  booktitle = {{{NeurIPS}} 2023 {{Workshop IMOL}}},
  author = {Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023voyager-Voyager - An Open-Ended Embodied Agent with Large Language Models.pdf}
}

@article{hu2023treeplanner,
  title = {Tree-Planner: {{Efficient}} Close-Loop Task Planning with Large Language Models},
  author = {Hu, Mengkang and Mu, Yao and Yu, Xinmiao and Ding, Mingyu and Wu, Shiguang and Shao, Wenqi and Chen, Qiguang and Wang, Bin and Qiao, Yu and Luo, Ping},
  year = {2023},
  journal = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hu2023treeplanner-Tree-planner - Efficient close-loop task planning with large language models.pdf}
}

@inproceedings{shah2023navigation,
  title = {Navigation with Large Language Models: {{Semantic}} Guesswork as a Heuristic for Planning},
  booktitle = CoRL,
  author = {Shah, Dhruv and Equi, Michael Robert and Osi{\'n}ski, B{\l}a{\.z}ej and Xia, Fei and Ichter, Brian and Levine, Sergey},
  year = {2023},
  pages = {2683--2699},
  publisher = {PMLR},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@shah2023navigation-Navigation with large language models - Semantic guesswork as a heuristic for.pdf}
}

@inproceedings{gutierrez2021meta,
  title = {Meta {{Reinforcement Learning}} for {{Heuristic Planing}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Gutierrez, Ricardo Luna and Leonetti, Matteo},
  year = {2021},
  volume = {31},
  pages = {551--559},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gutierrez2021meta-Meta Reinforcement Learning for Heuristic Planing.pdf}
}

@article{hazra2023saycanpay,
  title = {{{SayCanPay}}: {{Heuristic Planning}} with {{Large Language Models}} Using {{Learnable Domain Knowledge}}},
  author = {Hazra, Rishi and Martires, Pedro Zuidberg Dos and De Raedt, Luc},
  year = {2023},
  journal = {arXiv preprint arXiv:2308.12682},
  eprint = {2308.12682},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hazra2023saycanpay-SayCanPay - Heuristic Planning with Large Language Models using Learnable Domain.pdf}
}

@article{hoffmann2006conformant,
  title = {Conformant Planning via Heuristic Forward Search: {{A}} New Approach},
  author = {Hoffmann, J{\"o}rg and Brafman, Ronen I},
  year = {2006},
  journal = {Artificial Intelligence},
  volume = {170},
  number = {6-7},
  pages = {507--541},
  publisher = {Elsevier},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hoffmann2006conformant-Conformant planning via heuristic forward search - A new approach.pdf}
}

@article{yahia2023path,
  title = {Path Planning Optimization in Unmanned Aerial Vehicles Using Meta-Heuristic Algorithms: A Systematic Review},
  shorttitle = {Path Planning Optimization in Unmanned Aerial Vehicles Using Meta-Heuristic Algorithms},
  author = {Yahia, Hazha Saeed and Mohammed, Amin Salih},
  year = {2023},
  month = jan,
  journal = {Environmental Monitoring and Assessment},
  volume = {195},
  number = {1},
  pages = {30},
  issn = {0167-6369, 1573-2959},
  doi = {10.1007/s10661-022-10590-y},
  urldate = {2024-03-26},
  langid = {english},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yahia2023path-Path planning optimization in unmanned aerial vehicles using meta-heuristic.pdf}
}

@inproceedings{wu2022task,
  title = {Task Allocation with Load Management in Multi-Agent Teams},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wu, Haochen and Ghadami, Amin and Bayrak, Alparslan Emrah and Smereka, Jonathon M and Epureanu, Bogdan I},
  year = {2022},
  pages = {8823--8830},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2022task-Task allocation with load management in multi-agent teams.pdf}
}

@article{seenu2020review,
  title = {Review on State-of-the-Art Dynamic Task Allocation Strategies for Multiple-Robot Systems},
  author = {Seenu, N and RM, Kuppan Chetty and Ramya, {\relax MM} and Janardhanan, Mukund Nilakantan},
  year = {2020},
  journal = {Industrial Robot: the international journal of robotics research and application},
  volume = {47},
  number = {6},
  pages = {929--942},
  publisher = {Emerald Publishing Limited},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@seenu2020review-Review on state-of-the-art dynamic task allocation strategies for.pdf}
}

@article{skaltsis2023review,
  title = {A {{Review}} of {{Task Allocation Methods}} for {{UAVs}}},
  author = {Skaltsis, George Marios and Shin, Hyo-Sang and Tsourdos, Antonios},
  year = {2023},
  journal = {Journal of Intelligent \& Robotic Systems},
  volume = {109},
  number = {4},
  pages = {76},
  publisher = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@skaltsis2023review-A Review of Task Allocation Methods for UAVs.pdf}
}

@inproceedings{zhang2024coalition,
  title = {Coalition {{Formation Game Approach}} for {{Task Allocation}} in {{Heterogeneous Multi-Robot Systems}} under {{Resource Constraints}}},
  booktitle = IROS,
  author = {Zhang, Liwang},
  year = {2024},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024coalition-Coalition Formation Game Approach for Task Allocation in Heterogeneous.pdf}
}

@article{torreno2017cooperative,
  title = {Cooperative Multi-Agent Planning: {{A}} Survey},
  author = {Torreno, Alejandro and Onaindia, Eva and Komenda, Anton{\'i}n and {\v S}tolba, Michal},
  year = {2017},
  journal = {ACM Computing Surveys (CSUR)},
  volume = {50},
  number = {6},
  pages = {1--32},
  publisher = {ACM New York, NY, USA},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@torreno2017cooperative-Cooperative multi-agent planning - A survey.pdf}
}

@article{ramirez2016heuristics,
  title = {Heuristics for Planning, Plan Recognition and Parsing},
  author = {Ramirez, Miquel and Geffner, Hector},
  year = {2016},
  journal = {arXiv preprint arXiv:1605.05807},
  eprint = {1605.05807},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ramirez2016heuristics-Heuristics for planning, plan recognition and parsing.pdf}
}

@inproceedings{aineto2018learning,
  title = {Learning {{STRIPS}} Action Models with Classical Planning},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Aineto, Diego and Jim{\'e}nez, Sergio and Onaindia, Eva},
  year = {2018},
  volume = {28},
  pages = {399--407},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@aineto2018learning-Learning STRIPS action models with classical planning.pdf}
}

@inproceedings{chen2024learning,
  title = {Learning {{Domain-Independent Heuristics}} for {{Grounded}} and {{Lifted Planning}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Chen, Dillon Z and Thi{\'e}baux, Sylvie and Trevizan, Felipe},
  year = {2024},
  volume = {38},
  pages = {20078--20086},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2024learning-Learning Domain-Independent Heuristics for Grounded and Lifted Planning.pdf}
}

@inproceedings{gigante2023compilability,
  title = {On the Compilability of Bounded Numeric Planning},
  booktitle = {Proceedings of the 32nd {{International Joint Conference}} on {{Artificial Intelligence}}, {{IJCAI}}},
  author = {Gigante, Nicola and Scala, Enrico},
  year = {2023},
  volume = {23},
  pages = {5341--5349},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gigante2023compilability-On the compilability of bounded numeric planning.pdf}
}

@inproceedings{lauer2021polynomialtime,
  title = {Polynomial-Time in {{PDDL}} Input Size: {{Making}} the Delete Relaxation Feasible for Lifted Planning},
  booktitle = {{{ICAPS}} 2021 {{Workshop}} on {{Heuristics}} and {{Search}} for {{Domain-independent Planning}}},
  author = {Lauer, Pascal and Torralba, Alvaro and Fi{\v s}er, Daniel and H{\"o}ller, Daniel and Wichlacz, Julia and Hoffmann, J{\"o}rg},
  year = {2021},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lauer2021polynomialtime-Polynomial-time in PDDL input size - Making the delete relaxation feasible for.pdf}
}

@article{oyediran2024integration,
  title = {Integration of {{4D BIM}} and {{Robot Task Planning}}: {{Creation}} and {{Flow}} of {{Construction-Related Information}} for {{Action-Level Simulation}} of {{Indoor Wall Frame Installation}}},
  author = {Oyediran, Hafiz and Turner, William and Kim, Kyungki and Barrows, Matthew},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.03602},
  eprint = {2402.03602},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@oyediran2024integration-Integration of 4D BIM and Robot Task Planning - Creation and Flow of.pdf}
}

@article{dai2023optimal,
  title = {Optimal Scene Graph Planning with Large Language Model Guidance},
  author = {Dai, Zhirui and Asgharivaskasi, Arash and Duong, Thai and Lin, Shusen and Tzes, Maria-Elizabeth and Pappas, George and Atanasov, Nikolay},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.09182},
  eprint = {2309.09182},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@dai2023optimal-Optimal scene graph planning with large language model guidance.pdf}
}

@article{wang2023prompt,
  title = {Prompt Learning for Action Recognition},
  author = {Wang, Xijun and Xian, Ruiqi and Guan, Tianrui and Manocha, Dinesh},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.12437},
  eprint = {2305.12437},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023prompt-Prompt learning for action recognition.pdf}
}

@article{poole2013framework,
  title = {A Framework for Decision-Theoretic Planning {{I}}: {{Combining}} the Situation Calculus, Conditional Plans, Probability and Utility},
  author = {Poole, David L},
  year = {2013},
  journal = {arXiv preprint arXiv:1302.3597},
  eprint = {1302.3597},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@poole2013framework-A framework for decision-theoretic planning I - Combining the situation.pdf}
}

@article{zhang2024building,
  title = {Building Cooperative Embodied Agents Modularly with Large Language Models},
  author = {Zhang, Hongxin and Du, Weihua and Shan, Jiaming and Zhou, Qinhong and Du, Yilun and Tenenbaum, Joshua B and Shu, Tianmin and Gan, Chuang},
  year = {2024},
  journal = ICLR,
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024building-Building cooperative embodied agents modularly with large language models.pdf}
}

@article{yang2022graphblast,
  title = {{{GraphBLAST}}: {{A}} High-Performance Linear Algebra-Based Graph Framework on the {{GPU}}},
  author = {Yang, Carl and Bulu{\c c}, Ayd{\i}n and Owens, John D},
  year = {2022},
  journal = {ACM Transactions on Mathematical Software (TOMS)},
  volume = {48},
  number = {1},
  pages = {1--51},
  publisher = {ACM New York, NY},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2022graphblast-GraphBLAST - A high-performance linear algebra-based graph framework on the GPU.pdf}
}

@inproceedings{burfoot2006rrtplan,
  title = {{{RRT-Plan}}: {{A Randomized Algorithm}} for {{STRIPS Planning}}.},
  booktitle = {{{ICAPS}}},
  author = {Burfoot, Daniel and Pineau, Joelle and Dudek, Gregory},
  year = {2006},
  pages = {362--365},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@burfoot2006rrtplan-RRT-Plan - A Randomized Algorithm for STRIPS Planning.pdf}
}

@article{garrett2017strips,
  title = {Strips Planning in Infinite Domains},
  author = {Garrett, Caelan Reed and {Lozano-P{\'e}rez}, Tom{\'a}s and Kaelbling, Leslie Pack},
  year = {2017},
  journal = {arXiv preprint arXiv:1701.00287},
  eprint = {1701.00287},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@garrett2017strips-Strips planning in infinite domains.pdf}
}

@article{bylander1994computational,
  title = {The Computational Complexity of Propositional {{STRIPS}} Planning},
  author = {Bylander, Tom},
  year = {1994},
  journal = {Artificial Intelligence},
  volume = {69},
  number = {1-2},
  pages = {165--204},
  publisher = {Elsevier},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bylander1994computational-The computational complexity of propositional STRIPS planning.pdf}
}

@inproceedings{guan2023leveraging,
  title = {Leveraging {{Pre-trained Large Language Models}} to {{Construct}} and {{Utilize World Models}} for {{Model-based Task Planning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  editor = {Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {79081--79094},
  publisher = {Curran Associates, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@guan2023leveraging-Leveraging Pre-trained Large Language Models to Construct and Utilize World.pdf}
}

@article{elahi2022planning,
  title = {Planning with {{Complex Data Types}} in {{PDDL}}},
  author = {Elahi, Mojtaba and Rintanen, Jussi},
  year = {2022},
  journal = {arXiv preprint arXiv:2212.14462},
  eprint = {2212.14462},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@elahi2022planning-Planning with Complex Data Types in PDDL.pdf}
}

@inproceedings{schulte2014balancing,
  title = {Balancing Exploration and Exploitation in Classical Planning},
  booktitle = {Proceedings of the {{International Symposium}} on {{Combinatorial Search}}},
  author = {Schulte, Tim and Keller, Thomas},
  year = {2014},
  volume = {5},
  pages = {139--147}
}

@article{wissow2023scaleadaptive,
  title = {Scale-{{Adaptive Balancing}} of {{Exploration}} and {{Exploitation}} in {{Classical Planning}}},
  author = {Wissow, Stephen and Asai, Masataro},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.09840},
  eprint = {2305.09840},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wissow2023scaleadaptive-Scale-Adaptive Balancing of Exploration and Exploitation in Classical Planning.pdf}
}

@inproceedings{paulino2022search,
  title = {Search Methods in Motion Planning for Mobile Robots},
  booktitle = {Intelligent {{Systems}} and {{Applications}}: {{Proceedings}} of the 2021 {{Intelligent Systems Conference}} ({{IntelliSys}}) {{Volume}} 3},
  author = {Paulino, Laura and Hannum, Correy and Varde, Aparna S and Conti, Christopher J},
  year = {2022},
  pages = {802--822},
  publisher = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@paulino2022search-Search methods in motion planning for mobile robots.pdf}
}

@inproceedings{stern2017efficient,
  type = {Conference Paper},
  title = {Efficient, Safe, and Probably Approximately Complete Learning of Action Models},
  booktitle = IJCAI,
  author = {Stern, Roni and Juba, Brendan},
  year = {2017},
  volume = {0},
  pages = {4405--4411},
  doi = {10.24963/ijcai.2017/615},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@stern2017efficient-Efficient, safe, and probably approximately complete learning of action models.pdf}
}

@inproceedings{ahmad2020marginal,
  title = {Marginal Utility for Planning in Continuous or Large Discrete Action Spaces},
  booktitle = NeurIPS,
  author = {Ahmad, Zaheen and Lelis, Levi and Bowling, Michael},
  year = {2020},
  volume = {33},
  pages = {1937--1946},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ahmad2020marginal-Marginal utility for planning in continuous or large discrete action spaces.pdf}
}

@article{sakib2024consolidating,
  title = {Consolidating {{Trees}} of {{Robotic Plans Generated Using Large Language Models}} to {{Improve Reliability}}},
  author = {Sakib, Md Sadman and Sun, Yu},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.07868},
  eprint = {2401.07868},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sakib2024consolidating-Consolidating Trees of Robotic Plans Generated Using Large Language Models to.pdf}
}

@inproceedings{huang2022language,
  title = {Language {{Models}} as {{Zero-Shot Planners}}: {{Extracting Actionable Knowledge}} for {{Embodied Agents}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  year = {2022},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {162},
  pages = {9118--9147},
  publisher = {PMLR},
  abstract = {Can world knowledge learned by large language models (LLMs) be used to act in interactive environments? In this paper, we investigate the possibility of grounding high-level tasks, expressed in natural language (e.g. ``make breakfast''), to a chosen set of actionable steps (e.g. ``open fridge''). While prior work focused on learning from explicit step-by-step examples of how to act, we surprisingly find that if pre-trained LMs are large enough and prompted appropriately, they can effectively decompose high-level tasks into mid-level plans without any further training. However, the plans produced naively by LLMs often cannot map precisely to admissible actions. We propose a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. Our evaluation in the recent VirtualHome environment shows that the resulting method substantially improves executability over the LLM baseline. The conducted human evaluation reveals a trade-off between executability and correctness but shows a promising sign towards extracting actionable knowledge from language models.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2022language-Language Models as Zero-Shot Planners - Extracting Actionable Knowledge for.pdf}
}

@inproceedings{zhao2024large,
  title = {Large Language Models as Commonsense Knowledge for Large-Scale Task Planning},
  booktitle = NeurIPS,
  author = {Zhao, Zirui and Lee, Wee Sun and Hsu, David},
  year = {2024},
  volume = {36},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhao2024large-Large language models as commonsense knowledge for large-scale task planning.pdf}
}

@article{li2024study,
  title = {A {{Study}} on {{Training}} and {{Developing Large Language Models}} for {{Behavior Tree Generation}}},
  author = {Li, Fu and Wang, Xueying and Li, Bin and Wu, Yunlong and Wang, Yanzhen and Yi, Xiaodong},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.08089},
  eprint = {2401.08089},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024study-A Study on Training and Developing Large Language Models for Behavior Tree.pdf}
}

@article{hao2023reasoning,
  title = {Reasoning with Language Model Is Planning with World Model},
  author = {Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.14992},
  eprint = {2305.14992},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hao2023reasoning-Reasoning with language model is planning with world model.pdf}
}

@inproceedings{ha2023scaling,
  title = {Scaling {{Up}} and {{Distilling Down}}: {{Language-Guided Robot Skill Acquisition}}},
  booktitle = {Proceedings of {{The}} 7th {{Conference}} on {{Robot Learning}}},
  author = {Ha, Huy and Florence, Pete and Song, Shuran},
  editor = {Tan, Jie and Toussaint, Marc and Darvish, Kourosh},
  year = {2023},
  month = nov,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {229},
  pages = {3766--3777},
  publisher = {PMLR},
  abstract = {We present a framework for robot skill acquisition, which 1) efficiently scale up data generation of language-labelled robot data and 2) effectively distills this data down into a robust multi-task language-conditioned visuo-motor policy. For (1), we use a large language model (LLM) to guide high-level planning, and sampling-based robot planners (e.g. motion or grasp samplers) for generating diverse and rich manipulation trajectories. To robustify this data-collection process, the LLM also infers a code-snippet for the success condition of each task, simultaneously enabling the data-collection process to detect failure and retry as well as the automatic labeling of trajectories with success/failure. For (2), we extend the diffusion policy single-task behavior-cloning approach to multi-task settings with language conditioning. Finally, we propose a new multi-task benchmark with 18 tasks across five domains to test long-horizon behavior, common-sense reasoning, tool-use, and intuitive physics. We find that our distilled policy successfully learned the robust retrying behavior in its data collection procedure, while improving absolute success rates by 33.2\% on average across five domains. Code, data, and additional qualitative results are available on https://www.cs.columbia.edu/\&nbsp;huy/scalingup/.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ha2023scaling-Scaling Up and Distilling Down - Language-Guided Robot Skill Acquisition.pdf}
}

@inproceedings{lin2023swiftsage,
  title = {{{SwiftSage}}: {{A Generative Agent}} with {{Fast}} and {{Slow Thinking}} for {{Complex Interactive Tasks}}},
  booktitle = NeurIPS,
  author = {Lin, Bill Yuchen and Fu, Yicheng and Yang, Karina and Brahman, Faeze and Huang, Shiyu and Bhagavatula, Chandra and Ammanabrolu, Prithviraj and Choi, Yejin and Ren, Xiang},
  editor = {Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {23813--23825},
  publisher = {Curran Associates, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lin2023swiftsage-SwiftSage - A Generative Agent with Fast and Slow Thinking for Complex.pdf}
}

@article{kambhampati2024llms,
  title = {{{LLMs Can}}'t {{Plan}}, {{But Can Help Planning}} in {{LLM-Modulo Frameworks}}},
  author = {Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Stechly, Kaya and Verma, Mudit and Bhambri, Siddhant and Saldyt, Lucas and Murthy, Anil},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.01817},
  eprint = {2402.01817},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kambhampati2024llms-LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks.pdf}
}

@inproceedings{valmeekam2023can,
  title = {Can {{Large Language Models Really Improve}} by {{Self-critiquing Their Own Plans}}?},
  booktitle = {{{NeurIPS}} 2023 {{Foundation Models}} for {{Decision Making Workshop}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Kambhampati, Subbarao},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@valmeekam2023can-Can Large Language Models Really Improve by Self-critiquing Their Own Plans.pdf}
}

@inproceedings{stechly2023gpt4,
  title = {{{GPT-4 Doesn}}'t {{Know It}}'s {{Wrong}}: {{An Analysis}} of {{Iterative Prompting}} for {{Reasoning Problems}}},
  booktitle = {{{NeurIPS}} 2023 {{Foundation Models}} for {{Decision Making Workshop}}},
  author = {Stechly, Kaya and Marquez, Matthew and Kambhampati, Subbarao},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@stechly2023gpt4-GPT-4 Doesn't Know It's Wrong - An Analysis of Iterative Prompting for Reasoning.pdf}
}

@article{qian2023communicative,
  title = {Communicative Agents for Software Development},
  author = {Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.07924},
  eprint = {2307.07924},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@qian2023communicative-Communicative agents for software development.pdf}
}

@inproceedings{gan2022threedworld,
  title = {The Threedworld Transport Challenge: {{A}} Visually Guided Task-and-Motion Planning Benchmark towards Physically Realistic Embodied Ai},
  booktitle = {2022 {{International}} Conference on Robotics and Automation ({{ICRA}})},
  author = {Gan, Chuang and Zhou, Siyuan and Schwartz, Jeremy and Alter, Seth and Bhandwaldar, Abhishek and Gutfreund, Dan and Yamins, Daniel LK and DiCarlo, James J and McDermott, Josh and Torralba, Antonio and others},
  year = {2022},
  pages = {8847--8854},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gan2022threedworld-The threedworld transport challenge - A visually guided task-and-motion planning.pdf}
}

@article{cavrel2022efficient,
  title = {An {{Efficient HTN}} to {{STRIPS Encoding}} for {{Concurrent Plans}}},
  author = {Cavrel, Nicolas and Pellier, Damien and Fiorino, Humbert},
  year = {2022},
  journal = {arXiv preprint arXiv:2206.07084},
  eprint = {2206.07084},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@cavrel2022efficient-An Efficient HTN to STRIPS Encoding for Concurrent Plans.pdf}
}

@inproceedings{gehring2022reinforcement,
  title = {Reinforcement Learning for Classical Planning: {{Viewing}} Heuristics as Dense Reward Generators},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Gehring, Clement and Asai, Masataro and Chitnis, Rohan and Silver, Tom and Kaelbling, Leslie and Sohrabi, Shirin and Katz, Michael},
  year = {2022},
  volume = {32},
  pages = {588--596},
  abstract = {Recent advances in reinforcement learning (RL) have led to a growing interest in applying RL to classical planning domains or applying classical planning methods to some complex RL domains. However, the long-horizon goal-based problems found in classical planning lead to sparse rewards for RL, making direct application inefficient. In this paper, we propose to leverage domain-independent heuristic functions commonly used in the classical planning literature to improve the sample efficiency of RL. These classical heuristics act as dense reward generators to alleviate the sparse-rewards issue and enable our RL agent to learn domain-specific value functions as residuals on these heuristics, making learning easier. Correct application of this technique requires consolidating the discounted metric used in RL and the non-discounted metric used in heuristics. We implement the value functions using Neural Logic Machines, a neural network architecture designed for grounded first-order logic inputs. We demonstrate on several classical planning domains that using classical heuristics for RL allows for good sample efficiency compared to sparse-reward RL. We further show that our learned value functions generalize to novel problem instances in the same domain. The source code and the appendix are available at github. com/ibm/pddlrl and arxiv. org/abs/2109.14830.}
}

@inproceedings{florez-puga2008dynamic,
  title = {Dynamic Expansion of Behaviour Trees},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence and Interactive Digital Entertainment},
  author = {{Fl{\'o}rez-Puga}, Gonzalo and {Gomez-Martin}, Marco and {Diaz-Agudo}, Belen and {Gonzalez-Calero}, Pedro},
  year = {2008},
  volume = {4},
  pages = {36--41}
}

@article{bonet2001planning,
  title = {Planning as Heuristic Search},
  author = {Bonet, Blai and Geffner, H{\'e}ctor},
  year = {2001},
  journal = {Artificial Intelligence},
  volume = {129},
  number = {1-2},
  pages = {5--33},
  publisher = {Elsevier},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bonet2001planning-Planning as heuristic search.pdf}
}

@inproceedings{valmeekam2023planning,
  title = {On the {{Planning Abilities}} of {{Large Language Models}} - {{A Critical Investigation}}},
  booktitle = NeurIPS,
  author = {Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@valmeekam2023planning-On the Planning Abilities of Large Language Models - A Critical Investigation.pdf}
}

@inproceedings{gerevini2002lpg,
  title = {{{LPG}}: {{A Planner Based}} on {{Local Search}} for {{Planning Graphs}} with {{Action Costs}}.},
  booktitle = {Aips},
  author = {Gerevini, Alfonso and Serina, Ivan and others},
  year = {2002},
  volume = {2},
  pages = {281--290},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gerevini2002lpg-LPG - A Planner Based on Local Search for Planning Graphs with Action Costs.pdf}
}

@inproceedings{yao2022react,
  title = {React: {{Synergizing}} Reasoning and Acting in Language Models},
  booktitle = ICLR,
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  year = {2022},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yao2022react-React - Synergizing reasoning and acting in language models.pdf}
}

@misc{yao2023react,
  title = {{{ReAct}}: {{Synergizing Reasoning}} and {{Acting}} in {{Language Models}}},
  shorttitle = {{{ReAct}}},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  year = {2023},
  month = mar,
  number = {arXiv:2210.03629},
  eprint = {2210.03629},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-25},
  abstract = {While large language models (LLMs) have demonstrated impressive performance across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from external sources such as knowledge bases or environments. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines in addition to improved human interpretability and trustworthiness. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes prevalent issues of hallucination and error propagation in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generating human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. Furthermore, on two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yao2023react-ReAct - Synergizing Reasoning and Acting in Language Models.pdf}
}

@article{berrueta2024maximum,
  title = {Maximum Diffusion Reinforcement Learning},
  author = {Berrueta, Thomas A and Pinosky, Allison and Murphey, Todd D},
  year = {2024},
  journal = {Nature Machine Intelligence},
  pages = {1--11},
  publisher = {Nature Publishing Group UK London},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@berrueta2024maximum-Maximum diffusion reinforcement learning.pdf}
}

@misc{xavierpuigrobothow,
  title = {{{RobotHow}}},
  author = {Xavier Puig, Kevin Ra, Marko Boben}
}

@article{zhou2024llmbt,
  title = {{{LLM-BT}}: {{Performing Robotic Adaptive Tasks}} Based on {{Large Language Models}} and {{Behavior Trees}}},
  author = {Zhou, Haotian and Lin, Yunhan and Yan, Longwu and Zhu, Jihong and Min, Huasong},
  year = {2024},
  journal = ICRA,
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2024llmbt-LLM-BT - Performing Robotic Adaptive Tasks based on Large Language Models and.pdf}
}

@inproceedings{chen2024integrating,
  title = {Integrating {{Intent Understanding}} and {{Optimal Behavior Planning}} for {{Behavior Tree Generation}} from {{Human Instructions}}},
  booktitle = IJCAI,
  author = {Chen, Xinglin and Cai, Yishuai and Mao, Yunxin and Li, Minglong and Yang, Wenjing and Xu, Weixia and Wang, Ji},
  year = {2024},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\SXHLVTUY\\_IJCAI_24____Appendix (1).pdf;D\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@chen2024integrating-Integrating Intent Understanding and Optimal Behavior Planning for Behavior2.pdf}
}

@inproceedings{liang2011pruning,
  title = {Pruning {{Search Space}} for {{Heuristic Planning}} through {{Action Utility Analysis}}},
  booktitle = {Advances in {{Information Technology}} and {{Education}}},
  author = {Liang, Ruishi and Ma, Hui and Huang, Min},
  editor = {Tan, Honghua and Zhou, Mark},
  year = {2011},
  pages = {78--86},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  abstract = {This paper studies how to prune search space under the Relaxed Planning Graph heuristic framework which is firstly proposed in FF. Based on the observation of relations between action and proposition layers, we present a new and high-quality domain-independent pruning strategy for forward-chaining heuristic planning through Action Utility Analysis. The proposed strategy extracts so-called directly-used actions from relaxed planning graph as promising successors. Its pruning result is in general better than the helpful actions strategy. Our strategy can be used in any progression state space search framework. Experiments in the STRIPS benchmarks of International Planning Competitions (IPC) show that our pruning strategy along with algorithms decreases the search space effectively, and can outperform helpful action strategy of FF.},
  isbn = {978-3-642-22418-8}
}

@inproceedings{ouessai2020improving,
  title = {Improving the Performance of Mcts-Based {$M$}rts Agents through Move Pruning},
  booktitle = {2020 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  author = {Ouessai, Abdessamed and Salem, Mohammed and Mora, Antonio M},
  year = {2020},
  pages = {708--715},
  publisher = {IEEE}
}

@article{papagiannis2022pruning,
  title = {Pruning {{Stochastic Game Trees Using Neural Networks}} for {{Reduced Action Space Approximation}}},
  author = {Papagiannis, Tasos and Alexandridis, Georgios and Stafylopatis, Andreas},
  year = {2022},
  journal = {Mathematics},
  volume = {10},
  number = {9},
  pages = {1509},
  publisher = {MDPI}
}

@article{russo2023measuring,
  title = {Measuring {{Performance}}: {{Metrics}} for {{Manipulator Design}}, {{Control}}, and {{Optimization}}},
  author = {Russo, Matteo},
  year = {2023},
  journal = {Robotics},
  volume = {12},
  number = {1},
  pages = {4},
  publisher = {MDPI},
  doi = {10.3390/robotics12010004},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@russo2023measuring-Measuring Performance - Metrics for Manipulator Design, Control, and Optimization.pdf}
}

@article{calli2015benchmarking,
  title = {Benchmarking in {{Manipulation Research}}: {{The YCB Object}} and {{Model Set}} and {{Benchmarking Protocols}}},
  author = {Calli, Berk and Singh, Arjun and Walsman, Aaron and Srinivasa, Siddhartha S. and Abbeel, Pieter and Dollar, Aaron M.},
  year = {2015},
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {22},
  pages = {36--52},
  doi = {10.1109/MRA.2015.2448951},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@calli2015benchmarking-Benchmarking in Manipulation Research - The YCB Object and Model Set and.pdf}
}

@article{izzo2024btgenbot,
  title = {{{BTGenBot}}: {{Behavior Tree Generation}} for {{Robotic Tasks}} with {{Lightweight LLMs}}},
  author = {Izzo, Riccardo Andrea and Bardaro, Gianluca and Matteucci, Matteo},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.12761},
  eprint = {2403.12761},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@izzo2024btgenbot-BTGenBot - Behavior Tree Generation for Robotic Tasks with Lightweight LLMs.pdf}
}

@inproceedings{cote2019textworld,
  title = {Textworld: {{A}} Learning Environment for Text-Based Games},
  booktitle = {Computer {{Games}}: 7th {{Workshop}}, {{CGW}} 2018, {{Held}} in {{Conjunction}} with the 27th {{International Conference}} on {{Artificial Intelligence}}, {{IJCAI}} 2018, {{Stockholm}}, {{Sweden}}, {{July}} 13, 2018, {{Revised Selected Papers}} 7},
  author = {C{\^o}t{\'e}, Marc-Alexandre and K{\'a}d{\'a}r, Akos and Yuan, Xingdi and Kybartas, Ben and Barnes, Tavian and Fine, Emery and Moore, James and Hausknecht, Matthew and El Asri, Layla and Adada, Mahmoud and others},
  year = {2019},
  pages = {41--75},
  publisher = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@cote2019textworld-Textworld - A learning environment for text-based games.pdf}
}

@article{gong2023mindagent,
  title = {Mindagent: {{Emergent}} Gaming Interaction},
  author = {Gong, Ran and Huang, Qiuyuan and Ma, Xiaojian and Vo, Hoi and Durante, Zane and Noda, Yusuke and Zheng, Zilong and Zhu, Song-Chun and Terzopoulos, Demetri and {Fei-Fei}, Li and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.09971},
  eprint = {2309.09971},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gong2023mindagent-Mindagent - Emergent gaming interaction.pdf}
}

@article{teamfair+2022humanlevel,
  title = {Human-Level Play in the Game of {{Diplomacy}} by Combining Language Models with Strategic Reasoning},
  author = {Team (FAIR){\dag}, Meta Fundamental AI Research Diplomacy and Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and others},
  year = {2022},
  journal = {Science},
  volume = {378},
  number = {6624},
  pages = {1067--1074},
  publisher = {American Association for the Advancement of Science},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@teamfair+2022humanlevel-Human-level play in the game of Diplomacy by combining language models with.pdf}
}

@inproceedings{wen2021mrpb,
  title = {{{MRPB}} 1.0: {{A}} Unified Benchmark for the Evaluation of Mobile Robot Local Planning Approaches},
  booktitle = {2021 {{IEEE}} International Conference on Robotics and Automation ({{ICRA}})},
  author = {Wen, Jian and Zhang, Xuebo and Bi, Qingchen and Pan, Zhangchao and Feng, Yanghe and Yuan, Jing and Fang, Yongchun},
  year = {2021},
  pages = {8238--8244},
  publisher = {IEEE}
}

@inproceedings{rocha2022plannie,
  title = {Plannie: {{A Benchmark Framework}} for {{Autonomous Robots Path Planning Algorithms Integrated}} to {{Simulated}} and {{Real Environments}}},
  booktitle = {2022 {{International Conference}} on {{Unmanned Aircraft Systems}} ({{ICUAS}})},
  author = {Rocha, Lidia and Vivaldini, Kelen},
  year = {2022},
  pages = {402--411},
  doi = {10.1109/ICUAS54217.2022.9836102},
  keywords = {Benchmark testing,Heuristic algorithms,Location awareness,Machine learning algorithms,Metaheuristics,Three-dimensional displays,Traveling salesman problems}
}

@article{chamzas2022motionbenchmaker,
  title = {{{MotionBenchMaker}}: {{A Tool}} to {{Generate}} and {{Benchmark Motion Planning Datasets}}},
  author = {Chamzas, Constantinos and {Quintero-Pe{\~n}a}, Carlos and Kingston, Zachary and Orthey, Andreas and Rakita, Daniel and Gleicher, Michael and Toussaint, Marc and Kavraki, Lydia E.},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {882--889},
  doi = {10.1109/LRA.2021.3133603},
  keywords = {Benchmark testing,Data sets for robot learning,Generators,manipulation planning,motion and path planning,Planning,Robot sensing systems,Robots,Task analysis,Tools}
}

@article{liu2022benchmarking,
  title = {Benchmarking and Optimization of Robot Motion Planning with Motion Planning Pipeline},
  author = {Liu, Shuai and Liu, Pengcheng},
  year = {2022},
  month = jan,
  journal = {The International Journal of Advanced Manufacturing Technology},
  volume = {118},
  number = {3},
  pages = {949--961},
  issn = {1433-3015},
  doi = {10.1007/s00170-021-07985-5},
  abstract = {Algorithms have been designed for robot motion planning with various adaptability to different problems. However, how to choose the most suitable planner in a scene has always been a problem worthy of research. This paper aims to find the most suitable motion planner for each query under three different scenes and six different queries. The work lies in optimization of sampling-based motion planning algorithms through motion planning pipeline and planning request adapter. The idea is to use the pre-processing of the planning request adapter, to run OMPL as a pre-processer for the optimized CHOMP or STOMP algorithm, and connect through the motion planning pipeline, to realize the optimization of the motion trajectory. The optimized trajectories are compared with original trajectories through benchmarking. The benchmarking determines the most suitable motion planning algorithm for different scenarios and different queries. Experimental results show that after optimization, the planning time of the algorithm is longer, but the efficiency is significantly improved. In the low-complexity scenes, STOMP optimizes the sampling algorithm very well, improves the trajectory quality greatly, and has a higher success rate. CHOMP also has a good optimization of the sampling algorithm, but it reduces the success rate of the original algorithm. However, in more complex scenes, optimization performance of the two optimization methods may not be as good as the original algorithm. In future work, we need to find better algorithms and better optimization algorithms to tackle with complex scenes.}
}

@article{heiden2021benchmr,
  title = {Bench-{{MR}}: {{A Motion Planning Benchmark}} for {{Wheeled Mobile Robots}}},
  author = {Heiden, Eric and Palmieri, Luigi and Bruns, Leonard and Arras, Kai O. and Sukhatme, Gaurav S. and Koenig, Sven},
  year = {2021},
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {4536--4543},
  doi = {10.1109/LRA.2021.3068913},
  keywords = {Benchmark testing,Collision avoidance,Mobile robots,Navigation,Nonholonomic motion planning,Open source software,Planning,Robot kinematics,software tools for benchmarking and reproducibility,wheeled robots}
}

@inproceedings{toma2021pathbench,
  title = {{{PathBench}}: {{A Benchmarking Platform}} for {{Classical}} and {{Learned Path Planning Algorithms}}},
  booktitle = {2021 18th {{Conference}} on {{Robots}} and {{Vision}} ({{CRV}})},
  author = {Toma, Alexandru-Iosif and Hsueh, Hao-Ya and Jaafar, Hussein Ali and Murai, Riku and Kelly, Paul H.J. and Saeedi, Sajad},
  year = {2021},
  pages = {79--86},
  doi = {10.1109/CRV52889.2021.00019},
  keywords = {Benchmark testing,Benchmarking,Machine Learning,Measurement,Path planning,Path Planning,Three-dimensional displays,Tools,Training,Visualization}
}

@article{bekiroglu2020benchmarking,
  title = {Benchmarking {{Protocol}} for {{Grasp Planning Algorithms}}},
  author = {Bekiroglu, Yasemin and Marturi, Naresh and Roa, M{\'a}ximo A. and Adjigble, Komlan Jean Maxime and Pardi, Tommaso and Grimm, Cindy and Balasubramanian, Ravi and Hang, Kaiyu and Stolkin, Rustam},
  year = {2020},
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {2},
  pages = {315--322},
  doi = {10.1109/LRA.2019.2956411},
  keywords = {Benchmark testing,grasping,Grasping,performance evaluation,Planning,Protocols,Robot kinematics,Task analysis}
}

@inproceedings{gurtler2023benchmarking,
  title = {Benchmarking Offline Reinforcement Learning on Real-Robot Hardware},
  booktitle = ICLR,
  author = {G{\"u}rtler, Nico and Blaes, Sebastian and Kolev, Pavel and Widmaier, Felix and W{\"u}thrich, Manuel and Bauer, Stefan and Sch{\"o}lkopf, Bernhard and Martius, Georg},
  year = {2023}
}

@inproceedings{ji2023safety,
  title = {Safety {{Gymnasium}}: {{A Unified Safe Reinforcement Learning Benchmark}}},
  booktitle = NeurIPS,
  author = {Ji, Jiaming and Zhang, Borong and Zhou, Jiayi and Pan, Xuehai and Huang, Weidong and Sun, Ruiyang and Geng, Yiran and Zhong, Yifan and Dai, Josef and Yang, Yaodong},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {18964--18993},
  publisher = {Curran Associates, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ji2023safety-Safety Gymnasium - A Unified Safe Reinforcement Learning Benchmark.pdf}
}

@article{tassa2018deepmind,
  title = {Deepmind Control Suite},
  author = {Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  year = {2018},
  journal = {arXiv preprint arXiv:1801.00690},
  eprint = {1801.00690},
  archiveprefix = {arXiv}
}

@article{li2024embedding,
  title = {Embedding Multi-Agent Reinforcement Learning into Behavior Trees with Unexpected Interruptions},
  author = {Li, Xianglong and Li, Yuan and Zhang, Jieyuan and Xu, Xinhai and Liu, Donghong},
  year = {2024},
  journal = {Complex \& Intelligent Systems},
  pages = {1--10},
  publisher = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024embedding-Embedding multi-agent reinforcement learning into behavior trees with.pdf}
}

@inproceedings{dahlquist2023reactive,
  title = {Reactive {{Multi-agent Coordination}} Using {{Auction-based Task Allocation}} and {{Behavior Trees}}},
  booktitle = {2023 {{IEEE Conference}} on {{Control Technology}} and {{Applications}} ({{CCTA}})},
  author = {Dahlquist, Niklas and Lindqvist, Bj{\"o}rn and Saradagi, Akshit and Nikolakopoulos, George},
  year = {2023},
  pages = {829--834},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@dahlquist2023reactive-Reactive Multi-agent Coordination using Auction-based Task Allocation and.pdf}
}

@inproceedings{wang2017object,
  title = {Object Behavior Simulation Based on Behavior Tree and Multi-Agent Model},
  booktitle = {2017 {{IEEE}} 2nd {{Information Technology}}, {{Networking}}, {{Electronic}} and {{Automation Control Conference}} ({{ITNEC}})},
  author = {Wang, Yiran and Wang, Lei and Liu, Jinghao},
  year = {2017},
  pages = {833--836},
  doi = {10.1109/ITNEC.2017.8284851},
  keywords = {behavior tree,multi-agent model,public security,steering,visualized presentation},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2017object-Object behavior simulation based on behavior tree and multi-agent model.pdf}
}

@article{agis2020eventdriven,
  title = {An Event-Driven Behavior Trees Extension to Facilitate Non-Player Multi-Agent Coordination in Video Games},
  author = {Agis, Ramiro A and Gottifredi, Sebastian and Garc{\'i}a, Alejandro J},
  year = {2020},
  journal = {Expert Systems with Applications},
  volume = {155},
  pages = {113457},
  publisher = {Elsevier},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@agis2020eventdriven-An event-driven behavior trees extension to facilitate non-player multi-agent.pdf}
}

@inproceedings{colledanchise2016advantages,
  title = {The Advantages of Using Behavior Trees in Mult-Robot Systems},
  booktitle = {Proceedings of {{ISR}} 2016: 47st {{International Symposium}} on {{Robotics}}},
  author = {Colledanchise, Michele and Marzinotto, Alejandro and Dimarogonas, Dimos V and Oegren, Petter},
  year = {2016},
  pages = {1--8},
  publisher = {VDE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2016advantages-The advantages of using behavior trees in mult-robot systems.pdf}
}

@phdthesis{tadewos2021automatic,
  title = {Automatic {{Tasking}} of {{Multi-Agent Systems Using Behavior Tree}}},
  author = {Tadewos, Tadewos G},
  year = {2021},
  school = {North Carolina Agricultural and Technical State University},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@tadewos2021automatic-Automatic Tasking of Multi-Agent Systems Using Behavior Tree.pdf}
}

@inproceedings{kuckling2018behavior,
  title = {Behavior Trees as a Control Architecture in the Automatic Modular Design of Robot Swarms},
  booktitle = {International Conference on Swarm Intelligence},
  author = {Kuckling, Jonas and Ligot, Antoine and Bozhinoski, Darko and Birattari, Mauro},
  year = {2018},
  pages = {30--43},
  publisher = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kuckling2018behavior-Behavior trees as a control architecture in the automatic modular design of.pdf}
}

@article{heppner2024behavior,
  title = {Behavior {{Tree Capabilities}} for {{Dynamic Multi-Robot Task Allocation}} with {{Heterogeneous Robot Teams}}},
  author = {Heppner, Georg and Oberacker, David and Roennau, Arne and Dillmann, R{\"u}diger},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.02833},
  eprint = {2402.02833},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@heppner2024behavior-Behavior Tree Capabilities for Dynamic Multi-Robot Task Allocation with.pdf}
}

@article{venkata2023ktbt,
  title = {Kt-Bt: {{A}} Framework for Knowledge Transfer through Behavior Trees in Multirobot Systems},
  author = {Venkata, Sanjay Sarma Oruganti and Parasuraman, Ramviyas and Pidaparti, Ramana},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@venkata2023ktbt-Kt-bt - A framework for knowledge transfer through behavior trees in multirobot.pdf}
}

@inproceedings{wijaya2023behavior,
  title = {Behavior {{Tree}} of {{Agents}} in {{Multi-Agent System}} on {{Action Video Game}}},
  booktitle = {2023 {{International Conference}} on {{Electrical Engineering}} and {{Informatics}} ({{ICEEI}})},
  author = {Wijaya, Danny Kusuma and Prihatmanto, Ary Setijadi and Yusuf, Rahadian},
  year = {2023},
  pages = {1--4},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wijaya2023behavior-Behavior Tree of Agents in Multi-Agent System on Action Video Game.pdf}
}

@article{tadewos2023automatic,
  title = {Automatic Decentralized Behavior Tree Synthesis and Execution for Coordination of Intelligent Vehicles},
  author = {Tadewos, Tadewos G and Shamgah, Laya and Karimoddini, Ali},
  year = {2023},
  journal = {Knowledge-Based Systems},
  volume = {260},
  pages = {110181},
  publisher = {Elsevier},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@tadewos2023automatic-Automatic decentralized behavior tree synthesis and execution for coordination.pdf}
}

@article{oruganti2023iktbt,
  title = {{{IKT-BT}}: {{Indirect Knowledge Transfer Behavior Tree Framework}} for {{Multi-Robot Systems Through Communication Eavesdropping}}},
  author = {Oruganti, Sanjay and Parasuraman, Ramviyas and Pidaparti, Ramana},
  year = {2023},
  journal = {arXiv preprint arXiv:2312.11802},
  eprint = {2312.11802},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@oruganti2023iktbt-IKT-BT - Indirect Knowledge Transfer Behavior Tree Framework for Multi-Robot.pdf}
}

@inproceedings{heppnerl2023distributed,
  title = {Distributed {{Behavior Trees}} for {{Heterogeneous Robot Teams}}},
  booktitle = {2023 {{IEEE}} 19th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Heppnerl, Georg and Berg, Nils and Oberacker, David and Spielbauer, Niklas and Roennau, Arne and Dillmann, R{\"u}diger},
  year = {2023},
  pages = {1--8},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@heppnerl2023distributed-Distributed Behavior Trees for Heterogeneous Robot Teams.pdf}
}

@article{yu2024enhancing,
  title = {Enhancing {{Autonomous Underwater Vehicle Decision Making}} through {{Intelligent Task Planning}} and {{Behavior Tree Optimization}}},
  author = {Yu, Dan and Wang, Hongjian and Cao, Xu and Wang, Zhao and Ren, Jingfei and Zhang, Kai},
  year = {2024},
  journal = {Journal of Marine Science and Engineering},
  volume = {12},
  number = {5},
  pages = {791},
  publisher = {MDPI},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2024enhancing-Enhancing Autonomous Underwater Vehicle Decision Making through Intelligent.pdf}
}

@phdthesis{ozkahraman2023multiagent,
  title = {Multi-{{Agent Mission Planning}} and {{Execution}} for {{Small Autonomous Underwater Vehicles}}},
  author = {{\"O}zkahraman, {\"O}zer},
  year = {2023},
  school = {KTH Royal Institute of Technology},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ozkahraman2023multiagent-Multi-Agent Mission Planning and Execution for Small Autonomous Underwater.pdf}
}

@inproceedings{handelman2023multiagent,
  title = {Multi-Agent Playbook for Human-Robot Teaming},
  booktitle = {Artificial {{Intelligence}} and {{Machine Learning}} for {{Multi-Domain Operations Applications V}}},
  author = {Handelman, David A and Holmes, Emma A and Badger, Andrew R and Rivera, Corban G and Rexwinkle, Joe T and Gremillion, Gregory M},
  year = {2023},
  volume = {12538},
  pages = {123--135},
  publisher = {SPIE}
}

@article{dellacqua2023empathetic,
  title = {Empathetic Human-Agent Interaction via Emotional Behavior Trees},
  author = {Dell'Acqua, Pierangelo and Costantini, Stefania},
  year = {2023},
  journal = {Intelligenza Artificiale},
  volume = {17},
  number = {1},
  pages = {89--100},
  publisher = {IOS Press}
}

@article{kokotinis2024behavior,
  title = {A {{Behavior Trees-based}} Architecture towards Operation Planning in Hybrid Manufacturing},
  author = {Kokotinis, George and Michalos, George and Arkouli, Zoi and Makris, Sotiris},
  year = {2024},
  journal = {International Journal of Computer Integrated Manufacturing},
  volume = {37},
  number = {3},
  pages = {324--349},
  publisher = {Taylor \& Francis},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kokotinis2024behavior-A Behavior Trees-based architecture towards operation planning in hybrid.pdf}
}

@inproceedings{antakli2023ajan,
  title = {{{AJAN}}: {{An Engineering Framework}} for {{Semantic Web-Enabled Agents}} and {{Multi-Agent Systems}}},
  booktitle = {International {{Conference}} on {{Practical Applications}} of {{Agents}} and {{Multi-Agent Systems}}},
  author = {Antakli, Andr{\'e} and Kazimov, Akbar and Spieldenner, Daniel and Rojas, Gloria Elena Jaramillo and Zinnikus, Ingo and Klusch, Matthias},
  year = {2023},
  pages = {15--27},
  publisher = {Springer},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@antakli2023ajan-AJAN - An Engineering Framework for Semantic Web-Enabled Agents and Multi-Agent.pdf}
}

@book{saler2023using,
  title = {Using {{Backward Chained Behavior Trees}} to {{Control Cooperative Minecraft Agents}}},
  author = {Sal{\'e}r, Justin},
  year = {2023},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@saler2023using-Using Backward Chained Behavior Trees to Control Cooperative Minecraft Agents.pdf}
}

@inproceedings{kockemann2023planning,
  title = {Planning for Automated Testing of Implicit Constraints in Behavior Trees},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {K{\"o}ckemann, Uwe and Calisi, Daniele and Gemignani, Guglielmo and Renoux, Jennifer and Saffiotti, Alessandro},
  year = {2023},
  volume = {33},
  pages = {649--658},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kockemann2023planning-Planning for automated testing of implicit constraints in behavior trees.pdf}
}

@article{newaz2023decentralized,
  title = {Decentralized Multi-Robot Information Gathering from Unknown Spatial Fields},
  author = {Newaz, Abdullah Al Redwan and Alsayegh, Murtadha and Alam, Tauhidul and Bobadilla, Leonardo},
  year = {2023},
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {5},
  pages = {3070--3077},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@newaz2023decentralized-Decentralized multi-robot information gathering from unknown spatial fields.pdf}
}

@article{chen2024efficient,
  title = {Efficient {{Behavior Tree Planning}} with {{Commonsense Pruning}} and {{Heuristic}}},
  author = {Chen, Xinglin and Cai, Yishuai and Mao, Yunxin and Li, Minglong and Yang, Zhou and Shanghua, Wen and Yang, Wenjing and Xu, Weixia and Wang, Ji},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.00965},
  eprint = {2406.00965},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2024efficient-Efficient Behavior Tree Planning with Commonsense Pruning and Heuristic.pdf}
}

@inproceedings{li2023behavior1k,
  title = {{{BEHAVIOR-1K}}: {{A Benchmark}} for {{Embodied AI}} with 1,000 {{Everyday Activities}} and {{Realistic Simulation}}},
  booktitle = {Proceedings of {{The}} 6th {{Conference}} on {{Robot Learning}}},
  author = {Li, Chengshu and Zhang, Ruohan and Wong, Josiah and Gokmen, Cem and Srivastava, Sanjana and {Mart{\'i}n-Mart{\'i}n}, Roberto and Wang, Chen and Levine, Gabrael and Lingelbach, Michael and Sun, Jiankai and Anvari, Mona and Hwang, Minjune and Sharma, Manasi and Aydin, Arman and Bansal, Dhruva and Hunter, Samuel and Kim, Kyu-Young and Lou, Alan and Matthews, Caleb R and {Villa-Renteria}, Ivan and Tang, Jerry Huayang and Tang, Claire and Xia, Fei and Savarese, Silvio and Gweon, Hyowon and Liu, Karen and Wu, Jiajun and {Fei-Fei}, Li},
  editor = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
  year = {2023},
  month = dec,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {205},
  pages = {80--93},
  publisher = {PMLR},
  abstract = {We present BEHAVIOR-1K, a comprehensive simulation benchmark for human-centered robotics. BEHAVIOR-1K includes two components, guided and motivated by the results of an extensive survey on "what do you want robots to do for you?". The first is the definition of 1,000 everyday activities, grounded in 50 scenes (houses, gardens, restaurants, offices, etc.) with more than 5,000 objects annotated with rich physical and semantic properties. The second is OmniGibson, a novel simulation environment that supports these activities via realistic physics simulation and rendering of rigid bodies, deformable bodies, and liquids. Our experiments indicate that the activities in BEHAVIOR-1K are long-horizon and dependent on complex manipulation skills, both of which remain a challenge for even state-of-the-art robot learning solutions. To calibrate the simulation-to-reality gap of BEHAVIOR-1K, we provide an initial study on transferring solutions learned with a mobile manipulator in a simulated apartment to its real-world counterpart. We hope that BEHAVIOR-1K's human-grounded nature, diversity, and realism make it valuable for embodied AI and robot learning research. Project website: https://behavior.stanford.edu.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2023behavior1k-BEHAVIOR-1K - A Benchmark for Embodied AI with 1,000 Everyday Activities and.pdf}
}

@inproceedings{wang2024embodiedscan,
  title = {Embodiedscan: {{A}} Holistic Multi-Modal 3d Perception Suite towards Embodied Ai},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Wang, Tai and Mao, Xiaohan and Zhu, Chenming and Xu, Runsen and Lyu, Ruiyuan and Li, Peisen and Chen, Xiao and Zhang, Wenwei and Chen, Kai and Xue, Tianfan and others},
  year = {2024},
  pages = {19757--19767},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024embodiedscan-Embodiedscan - A holistic multi-modal 3d perception suite towards embodied ai.pdf}
}

@article{jia2024sceneverse,
  title = {Sceneverse: {{Scaling}} 3d Vision-Language Learning for Grounded Scene Understanding},
  author = {Jia, Baoxiong and Chen, Yixin and Yu, Huangyue and Wang, Yan and Niu, Xuesong and Liu, Tengyu and Li, Qing and Huang, Siyuan},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.09340},
  eprint = {2401.09340},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jia2024sceneverse-Sceneverse - Scaling 3d vision-language learning for grounded scene understanding.pdf}
}

@article{helmert2006fast,
  title = {The Fast Downward Planning System},
  author = {Helmert, Malte},
  year = {2006},
  journal = {Journal of Artificial Intelligence Research},
  volume = {26},
  pages = {191--246},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@helmert2006fast-The fast downward planning system.pdf}
}

@inproceedings{yuan2024tasklama,
  title = {Tasklama: Probing the Complex Task Understanding of Language Models},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Yuan, Quan and Kazemi, Mehran and Xu, Xin and Noble, Isaac and Imbrasaite, Vaiva and Ramachandran, Deepak},
  year = {2024},
  volume = {38},
  pages = {19468--19476},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yuan2024tasklama-Tasklama - probing the complex task understanding of language models.pdf}
}

@article{gao2024dagplan,
  title = {{{DAG-Plan}}: {{Generating Directed Acyclic Dependency Graphs}} for {{Dual-Arm Cooperative Planning}}},
  author = {Gao, Zeyu and Mu, Yao and Qu, Jinye and Hu, Mengkang and Guo, Lingyue and Luo, Ping and Lu, Yanfeng},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.09953},
  eprint = {2406.09953},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2024dagplan-DAG-Plan - Generating Directed Acyclic Dependency Graphs for Dual-Arm.pdf}
}

@article{guo2024large,
  title = {Large Language Model Based Multi-Agents: {{A}} Survey of Progress and Challenges},
  author = {Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruidi and Pei, Shichao and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.01680},
  eprint = {2402.01680},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@guo2024large-Large language model based multi-agents - A survey of progress and challenges.pdf}
}

@article{zhang2024llm,
  title = {{{LLM}} as a {{Mastermind}}: {{A Survey}} of {{Strategic Reasoning}} with {{Large Language Models}}},
  author = {Zhang, Yadong and Mao, Shaoguang and Ge, Tao and Wang, Xun and {de Wynter}, Adrian and Xia, Yan and Wu, Wenshan and Song, Ting and Lan, Man and Wei, Furu},
  year = {2024},
  journal = {arXiv preprint arXiv:2404.01230},
  eprint = {2404.01230},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024llm-LLM as a Mastermind - A Survey of Strategic Reasoning with Large Language Models.pdf}
}

@article{xie2024humanlike,
  title = {A {{Human-Like Reasoning Framework}} for {{Multi-Phases Planning Task}} with {{Large Language Models}}},
  author = {Xie, Chengxing and Zou, Difan},
  year = {2024},
  journal = {arXiv preprint arXiv:2405.18208},
  eprint = {2405.18208},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xie2024humanlike-A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large.pdf}
}

@article{jiang2024multimodal,
  title = {Multi-{{Modal}} and {{Multi-Agent Systems Meet Rationality}}: {{A Survey}}},
  author = {Jiang, Bowen and Xie, Yangxinyu and Wang, Xiaomeng and Su, Weijie J and Taylor, Camillo J and Mallick, Tanwi},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.00252},
  eprint = {2406.00252},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@jiang2024multimodal-Multi-Modal and Multi-Agent Systems Meet Rationality - A Survey.pdf}
}

@article{chen2023scalable,
  title = {Scalable Multi-Robot Collaboration with Large Language Models: {{Centralized}} or Decentralized Systems?},
  author = {Chen, Yongchao and Arkin, Jacob and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.15943},
  eprint = {2309.15943},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023scalable-Scalable multi-robot collaboration with large language models - Centralized or.pdf}
}

@article{singh2024twostep,
  title = {Twostep: {{Multi-agent}} Task Planning Using Classical Planners and Large Language Models},
  author = {Singh, Ishika and Traum, David and Thomason, Jesse},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.17246},
  eprint = {2403.17246},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@singh2024twostep-Twostep - Multi-agent task planning using classical planners and large language2.pdf}
}

@article{mu2024robocodex,
  title = {{{RoboCodeX}}: {{Multimodal Code Generation}} for {{Robotic Behavior Synthesis}}},
  author = {Mu, Yao and Chen, Junting and Zhang, Qinglong and Chen, Shoufa and Yu, Qiaojun and Ge, Chongjian and Chen, Runjian and Liang, Zhixuan and Hu, Mengkang and Tao, Chaofan and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.16117},
  eprint = {2402.16117},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@mu2024robocodex-RoboCodeX - Multimodal Code Generation for Robotic Behavior Synthesis.pdf}
}

@article{brohan2023rt2,
  title = {Rt-2: {{Vision-language-action}} Models Transfer Web Knowledge to Robotic Control},
  author = {Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.15818},
  eprint = {2307.15818},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@brohan2023rt2-Rt-2 - Vision-language-action models transfer web knowledge to robotic control.pdf}
}

@book{lavalle2006planning,
  title = {Planning Algorithms},
  author = {LaValle, Steven M},
  year = {2006},
  publisher = {Cambridge university press},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@lavalle2006planning-Planning algorithms.pdf}
}

@inproceedings{sun2023adaplanner,
  title = {{{AdaPlanner}}: {{Adaptive Planning}} from {{Feedback}} with {{Language Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Sun, Haotian and Zhuang, Yuchen and Kong, Lingkai and Dai, Bo and Zhang, Chao},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {58202--58245},
  publisher = {Curran Associates, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2023adaplanner-AdaPlanner - Adaptive Planning from Feedback with Language Models.pdf}
}

@inproceedings{silver2024generalized,
  title = {Generalized Planning in Pddl Domains with Pretrained Large Language Models},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Silver, Tom and Dan, Soham and Srinivas, Kavitha and Tenenbaum, Joshua B and Kaelbling, Leslie and Katz, Michael},
  year = {2024},
  volume = {38},
  pages = {20256--20264},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@silver2024generalized-Generalized planning in pddl domains with pretrained large language models.pdf}
}

@inproceedings{ghzouli2020behavior,
  title = {Behavior Trees in Action: A Study of Robotics Applications},
  booktitle = {Proceedings of the 13th {{ACM SIGPLAN International Conference}} on {{Software Language Engineering}}},
  author = {Ghzouli, Razan and Berger, Thorsten and Johnsen, Einar Broch and Dragule, Swaib and W{\k a}sowski, Andrzej},
  year = {2020},
  series = {{{SLE}} 2020},
  pages = {196--209},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3426425.3426942},
  abstract = {Autonomous robots combine a variety of skills to form increasingly complex behaviors called missions. While the skills are often programmed at a relatively low level of abstraction, their coordination is architecturally separated and often expressed in higher-level languages or frameworks. Recently, the language of Behavior Trees gained attention among roboticists for this reason. Originally designed for computer games to model autonomous actors, Behavior Trees offer an extensible tree-based representation of missions. However, even though, several implementations of the language are in use, little is known about its usage and scope in the real world. How do behavior trees relate to traditional languages for describing behavior? How are behavior tree concepts used in applications? What are the benefits of using them? We present a study of the key language concepts in Behavior Trees and their use in real-world robotic applications. We identify behavior tree languages and compare their semantics to the most well-known behavior modeling languages: state and activity diagrams. We mine open source repositories for robotics applications that use the language and analyze this usage. We find that Behavior Trees are a pragmatic language, not fully specified, allowing projects to extend it even for just one model. Behavior trees clearly resemble the models-at-runtime paradigm. We contribute a dataset of real-world behavior models, hoping to inspire the community to use and further develop this language, associated tools, and analysis techniques.},
  isbn = {978-1-4503-8176-5},
  keywords = {behavior trees,empirical study,robotics applications},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@ghzouli2020behavior-Behavior trees in action - a study of robotics applications.pdf}
}

@inproceedings{berkenkamp2016safe,
  title = {Safe Learning of Regions of Attraction for Uncertain, Nonlinear Systems with Gaussian Processes},
  booktitle = {2016 {{IEEE}} 55th {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Berkenkamp, Felix and Moriconi, Riccardo and Schoellig, Angela P and Krause, Andreas},
  year = {2016},
  pages = {4661--4666},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@berkenkamp2016safe-Safe learning of regions of attraction for uncertain, nonlinear systems with.pdf}
}

@article{hoffmann2001ff,
  title = {The {{FF}} Planning System: {{Fast}} Plan Generation through Heuristic Search},
  author = {Hoffmann, J{\"o}rg and Nebel, Bernhard},
  year = {2001},
  journal = {Journal of Artificial Intelligence Research},
  volume = {14},
  pages = {253--302},
  abstract = {We describe and evaluate the algorithmic techniques that are used in the FF planning system. Like the HSP system, FF relies on forward state space search, using a heuristic that estimates goal distances by ignoring delete lists. Unlike HSP's heuristic, our method does not assume facts to be independent. We introduce a novel search strategy that combines hill-climbing with systematic search, and we show how other powerful heuristic information can be extracted and used to prune the search space. FF was the most successful automatic planner at the recent AIPS-2000 planning competition. We review the results of the competition, give data for other benchmark domains, and investigate the reasons for the runtime performance of FF compared to HSP.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@hoffmann2001ff-The FF planning system - Fast plan generation through heuristic search.pdf}
}

@article{hoffmann2004ordered,
  title = {Ordered Landmarks in Planning},
  author = {Hoffmann, J{\"o}rg and Porteous, Julie and Sebastia, Laura},
  year = {2004},
  journal = {Journal of Artificial Intelligence Research},
  volume = {22},
  pages = {215--278},
  abstract = {Many known planning tasks have inherent constraints concerning the best order in which to achieve the goals. A number of research efforts have been made to detect such constraints and to use them for guiding search, in the hope of speeding up the planning process. We go beyond the previous approaches by considering ordering constraints not only over the (top-level) goals, but also over the sub-goals that will necessarily arise during planning. Landmarks are facts that must be true at some point in every valid solution plan. We extend Koehler and Hoffmann's definition of reasonable orders between top level goals to the more general case of landmarks. We show how landmarks can be found, how their reasonable orders can be approximated, and how this information can be used to decompose a given planning task into several smaller sub-tasks. Our methodology is completely domain- and planner-independent. The implementation demonstrates that the approach can yield significant runtime performance improvements when used as a control loop around state-of-the-art sub-optimal planning systems, as exemplified by FF and LPG.}
}

@article{kim2024relevance,
  title = {Relevance {{Score}}: {{A Landmark-Like Heuristic}} for {{Planning}}},
  author = {Kim, Oliver and Sridharan, Mohan},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.07510},
  eprint = {2403.07510},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kim2024relevance-Relevance Score - A Landmark-Like Heuristic for Planning.pdf}
}

@article{sumers2023cognitive,
  title = {Cognitive Architectures for Language Agents},
  author = {Sumers, Theodore R and Yao, Shunyu and Narasimhan, Karthik and Griffiths, Thomas L},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.02427},
  eprint = {2309.02427},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sumers2023cognitive-Cognitive architectures for language agents.pdf}
}

@inproceedings{chouhan2016multiagent,
  title = {A {{Multiagent Planning Algorithm}} with {{Joint Actions}}},
  booktitle = {Proceedings of the 4th {{International Conference}} on {{Frontiers}} in {{Intelligent Computing}}: {{Theory}} and {{Applications}} ({{FICTA}}) 2015},
  author = {Chouhan, Satyendra Singh and Niyogi, Rajdeep},
  editor = {Das, Swagatam and Pal, Tandra and Kar, Samarjit and Satapathy, Suresh Chandra and Mandal, Jyotsna Kumar},
  year = {2016},
  pages = {691--699},
  publisher = {Springer India},
  address = {New Delhi},
  abstract = {In this paper, we consider multiagent planning with joint actions----that refer to the same action being performed concurrently by a group of agents. There are few works that study specification of joint actions by extending PDDL. Since there are no multiagent planners that can handle joint actions, we propose a multiagent planning algorithm, which is capable of handling joint actions. In a multiagent setting, each agent has a different capability. The proposed algorithm obtains the number of agents involved in a joint action based on the capability of the individual agents. We have implemented our algorithm and compared its efficiency with some state-of-the-art classical planners. The results show that when the problem size increases, our algorithm can solve such problems whereas it cannot be solved by the classical planners.},
  isbn = {978-81-322-2695-6},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chouhan2016multiagent-A Multiagent Planning Algorithm with Joint Actions2.pdf}
}

@article{borno2017domain,
  title = {Domain of {{Attraction Expansion}} for {{Physics-Based Character Control}}},
  author = {Borno, Mazen Al and Panne, Michiel Van De and Fiume, Eugene},
  year = {2017},
  month = mar,
  journal = {ACM Trans. Graph.},
  volume = {36},
  number = {2},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0730-0301},
  doi = {10.1145/3009907},
  abstract = {Determining effective control strategies and solutions for high-degree-of-freedom humanoid characters has been a difficult, ongoing problem. A controller is only valid for a subset of the states of the character, known as the domain of attraction (DOA). This article shows how many states that are initially outside the DOA can be brought inside it. Our first contribution is to show how DOA expansion can be performed for a high-dimensional simulated character. Our second contribution is to present an algorithm that efficiently increases the DOA using random trees that provide denser coverage than the trees produced by typical sampling-based motion-planning algorithms. The trees are constructed offline but can be queried fast enough for near-real-time control. We show the effect of DOA expansion on getting up, crouch-to-stand, jumping, and standing-twist controllers. We also show how DOA expansion can be used to connect controllers together.},
  keywords = {character animation,Computer animation,physics simulation},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@borno2017domain-Domain of Attraction Expansion for Physics-Based Character Control.pdf}
}

@inproceedings{sprague2022adding,
  title = {Adding Neural Network Controllers to Behavior Trees without Destroying Performance Guarantees},
  booktitle = {2022 {{IEEE}} 61st {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Sprague, Christopher Iliffe and {\"O}gren, Petter},
  year = {2022},
  pages = {3989--3996},
  publisher = {IEEE},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sprague2022adding-Adding neural network controllers to behavior trees without destroying.pdf}
}

@inproceedings{zhou2005beamstack,
  title = {Beam-{{Stack Search}}: {{Integrating Backtracking}} with {{Beam Search}}.},
  booktitle = {{{ICAPS}}},
  author = {Zhou, Rong and Hansen, Eric A},
  year = {2005},
  pages = {90--98},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2005beamstack-Beam-Stack Search - Integrating Backtracking with Beam Search.pdf}
}

@article{meister2020bestfirst,
  title = {Best-First Beam Search},
  author = {Meister, Clara and Vieira, Tim and Cotterell, Ryan},
  year = {2020},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {8},
  pages = {795--809},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info {\dots}},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@meister2020bestfirst-Best-first beam search.pdf}
}

@article{pallagani2022plansformer,
  title = {Plansformer: {{Generating}} Symbolic Plans Using Transformers},
  author = {Pallagani, Vishal and Muppasani, Bharath and Murugesan, Keerthiram and Rossi, Francesca and Horesh, Lior and Srivastava, Biplav and Fabiano, Francesco and Loreggia, Andrea},
  year = {2022},
  journal = {arXiv preprint arXiv:2212.08681},
  eprint = {2212.08681},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@pallagani2022plansformer-Plansformer - Generating symbolic plans using transformers.pdf}
}

@article{guo2023recent,
  title = {Recent Trends in Task and Motion Planning for Robotics: {{A}} Survey},
  author = {Guo, Huihui and Wu, Fan and Qin, Yunchuan and Li, Ruihui and Li, Keqin and Li, Kenli},
  year = {2023},
  journal = {ACM Computing Surveys},
  volume = {55},
  number = {13s},
  pages = {1--36},
  publisher = {ACM New York, NY},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@guo2023recent-Recent trends in task and motion planning for robotics - A survey.pdf}
}

@inproceedings{gupta2024goalnet,
  title = {{{GOALNET}}: {{Interleaving Neural Goal Predicate Inference}} with {{Classical Planning}} for {{Generalization}} in {{Robot Instruction Following}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Gupta, Jigyasa and Sharma, Shreya and Tuli, Shreshth and Paul, Rohan and others},
  year = {2024},
  volume = {38},
  pages = {20113--20122},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2024goalnet-GOALNET - Interleaving Neural Goal Predicate Inference with Classical Planning.pdf}
}

@inproceedings{misra2018mapping,
  title = {Mapping Instructions to Actions in 3d Environments with Visual Goal Prediction},
  booktitle = {Proceedings of the {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Misra, Dipendra and Bennett, Andrew and Blukis, Valts and Niklasson, Eyvind and Shatkhin, Max and Artzi, Yoav},
  year = {2018},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@misra2018mapping-Mapping instructions to actions in 3d environments with visual goal prediction2.pdf}
}

@inproceedings{xie2023selfevaluation,
  title = {Self-{{Evaluation Guided Beam Search}} for {{Reasoning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Xie, Yuxi and Kawaguchi, Kenji and Zhao, Yiran and Zhao, James Xu and Kan, Min-Yen and He, Junxian and Xie, Michael},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {41618--41650},
  publisher = {Curran Associates, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@xie2023selfevaluation-Self-Evaluation Guided Beam Search for Reasoning.pdf}
}

@article{roy2024flap,
  title = {Flap: {{Flow}} Adhering Planning with Constrained Decoding in Llms},
  author = {Roy, Shamik and Sengupta, Sailik and Bonadiman, Daniele and Mansour, Saab and Gupta, Arshit},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.05766},
  eprint = {2403.05766},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@roy2024flap-Flap - Flow adhering planning with constrained decoding in llms.pdf}
}

@incollection{sabbadin2020planning,
  title = {Planning in {{Artificial Intelligence}}},
  booktitle = {A {{Guided Tour}} of {{Artificial Intelligence Research}}: {{Volume II}}: {{AI Algorithms}}},
  author = {Sabbadin, R{\'e}gis and {Teichteil-K{\"o}nigsbuch}, Florent and Vidal, Vincent},
  editor = {Marquis, Pierre and Papini, Odile and Prade, Henri},
  year = {2020},
  pages = {285--312},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-06167-8_10},
  abstract = {In this chapter, we proposeSabbadin, R{\'e}gis a non-exhaustive review of past works of the AI community on classical planning and planning underTeichteil-K{\"o}nigsbuch, Florent uncertainty. We first present the classical propositional STRIPS planning language. Its extensions, based on the problem description language PDDL have become a standard in the community. We briefly deal with the structural analysis of planning problems, which has initiated theVidal, Vincent development of efficient planning algorithms and associated planners. Then, we describe the Markov Decision Processes framework (MDP), initially proposed in the Operations Research community before the AI community adopted it as a framework for planning under uncertainty. Eventually, we will describe innovative (approximate or exact) MDP solution algorithms as well as recent progresses in AI in terms of knowledge representation (logics, Bayesian networks) which have been used to increase the power of expression of the MDP framework.},
  isbn = {978-3-030-06167-8},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sabbadin2020planning-Planning in Artificial Intelligence.pdf}
}

@inproceedings{bonet1997robust,
  title = {A Robust and Fast Action Selection Mechanism for Planning},
  booktitle = AAAI,
  author = {Bonet, Blai and Loerincs, G{\'a}bor and Geffner, H{\'e}ctor},
  year = {1997},
  pages = {714--719},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@bonet1997robust-A robust and fast action selection mechanism for planning.pdf}
}

@incollection{keyder2008heuristics,
  title = {Heuristics for Planning with Action Costs Revisited},
  booktitle = {{{ECAI}} 2008},
  author = {Keyder, Emil and Geffner, H{\'e}ctor},
  year = {2008},
  pages = {588--592},
  publisher = {IOS Press},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@keyder2008heuristics-Heuristics for planning with action costs revisited.pdf}
}

@inproceedings{correa2021deleterelaxation,
  title = {Delete-Relaxation Heuristics for Lifted Classical Planning},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Corr{\^e}a, Augusto B and Franc{\`e}s, Guillem and Pommerening, Florian and Helmert, Malte},
  year = {2021},
  volume = {31},
  pages = {94--102},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@correa2021deleterelaxation-Delete-relaxation heuristics for lifted classical planning.pdf}
}

@inproceedings{correa2022ff,
  title = {The {{FF}} Heuristic for Lifted Classical Planning},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Corr{\^e}a, Augusto B and Pommerening, Florian and Helmert, Malte and Frances, Guillem},
  year = {2022},
  volume = {36},
  pages = {9716--9723},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@correa2022ff-The FF heuristic for lifted classical planning.pdf}
}

@article{wittner2024optimizations,
  title = {Optimizations for the {{Additive Heuristic}} in {{Fast Downward}}},
  author = {Wittner, Simona},
  year = {2024},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@wittner2024optimizations-Optimizations for the Additive Heuristic in Fast Downward2.pdf}
}

@article{meng2024llma,
  title = {{{LLM-A}}*: {{Large Language Model Enhanced Incremental Heuristic Search}} on {{Path Planning}}},
  author = {Meng, Silin and Wang, Yiwei and Yang, Cheng-Fu and Peng, Nanyun and Chang, Kai-Wei},
  year = {2024},
  journal = {arXiv preprint arXiv:2407.02511},
  eprint = {2407.02511},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@meng2024llma-LLM-A - Large Language Model Enhanced Incremental Heuristic Search on Path.pdf}
}

@inproceedings{schumann2024velma,
  title = {Velma: {{Verbalization}} Embodiment of Llm Agents for Vision and Language Navigation in Street View},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Schumann, Raphael and Zhu, Wanrong and Feng, Weixi and Fu, Tsu-Jui and Riezler, Stefan and Wang, William Yang},
  year = {2024},
  volume = {38},
  pages = {18924--18933},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@schumann2024velma-Velma - Verbalization embodiment of llm agents for vision and language.pdf}
}

@article{yang2023llmgrounder,
  title = {Llm-Grounder: {{Open-vocabulary}} 3d Visual Grounding with Large Language Model as an Agent},
  author = {Yang, Jianing and Chen, Xuweiyi and Qian, Shengyi and Madaan, Nikhil and Iyengar, Madhavan and Fouhey, David F and Chai, Joyce},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.12311},
  eprint = {2309.12311},
  archiveprefix = {arXiv},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2023llmgrounder-Llm-grounder - Open-vocabulary 3d visual grounding with large language model as.pdf}
}

@article{sridharan2019reba,
  title = {{{REBA}}: {{A}} Refinement-Based Architecture for Knowledge Representation and Reasoning in Robotics},
  author = {Sridharan, Mohan and Gelfond, Michael and Zhang, Shiqi and Wyatt, Jeremy},
  year = {2019},
  journal = {Journal of Artificial Intelligence Research},
  volume = {65},
  pages = {87--180},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@sridharan2019reba-REBA - A refinement-based architecture for knowledge representation and.pdf}
}

@inproceedings{kumar2023learning,
  title = {Learning Efficient Abstract Planning Models That Choose What to Predict},
  booktitle = {Conference on {{Robot Learning}}},
  author = {Kumar, Nishanth and McClinton, Willie and Chitnis, Rohan and Silver, Tom and {Lozano-P{\'e}rez}, Tom{\'a}s and Kaelbling, Leslie Pack},
  year = {2023},
  pages = {2070--2095},
  publisher = {PMLR},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@kumar2023learning-Learning efficient abstract planning models that choose what to predict.pdf}
}

@inproceedings{chen2024btpg,
  title = {{{BTPG}}: {{A Platform}} and {{Benchmark}} for {{Behavior Tree Planning}} in {{Everyday Service Robots}}},
  booktitle = NeurIPS,
  author = {Chen, Xinglin},
  year = {2024},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2024btpg-BTPG - A Platform and Benchmark for Behavior Tree Planning in Everyday Service.pdf}
}

@inproceedings{wei2022chainofthought,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and {ichter}, brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {24824--24837},
  publisher = {Curran Associates, Inc.}
}

@inproceedings{valmeekam2023planbench,
  title = {{{PlanBench}}: {{An Extensible Benchmark}} for {{Evaluating Large Language Models}} on {{Planning}} and {{Reasoning}} about {{Change}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {38975--38987},
  publisher = {Curran Associates, Inc.},
  file = {D:\Workspace\CXL_Storage\SoftwareData\zotfile\@valmeekam2023planbench-PlanBench - An Extensible Benchmark for Evaluating Large Language Models on2.pdf}
}

@article{chevalier-boisvert2023minigrid,
  title = {Minigrid \& {{Miniworld}}: {{Modular}} \& {{Customizable Reinforcement Learning Environments}} for {{Goal-Oriented Tasks}}},
  author = {{Chevalier-Boisvert}, Maxime and Dai, Bolun and Towers, Mark and de Lazcano, Rodrigo and Willems, Lucas and Lahlou, Salem and Pal, Suman and Castro, Pablo Samuel and Terry, Jordan},
  year = {2023},
  journal = {CoRR},
  volume = {abs/2306.13831}
}

@article{arora2018review,
  title={A review of learning planning action models},
  author={Arora, Ankuj and Fiorino, Humbert and Pellier, Damien and M{\'e}tivier, Marc and Pesty, Sylvie},
  journal={The Knowledge Engineering Review},
  volume={33},
  pages={e20},
  year={2018},
  publisher={Cambridge University Press}
}

@inproceedings{fu2016reinforcement,
  title={A reinforcement learning behavior tree framework for game AI},
  author={Fu, Yanchang and Qin, Long and Yin, Quanjun},
  booktitle={2016 International Conference on Economics, Social Science, Arts, Education and Management Engineering},
  pages={573--579},
  year={2016},
  organization={Atlantis Press}
}