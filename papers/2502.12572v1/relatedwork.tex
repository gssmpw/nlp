\section{Related Works}
\subsection{Singing Voice Synthesis}

Singing Voice Synthesis (SVS) has advanced significantly with deep learning, aiming to generate high-quality singing from musical scores and lyrics. Early models like XiaoiceSing \citep{lu2020xiaoicesing} and DeepSinger \citep{ren2020deepsinger} utilize non-autoregressive and feed-forward transformers to synthesize singing voice. VISinger \citep{zhang2022visinger} employs the VITS \citep{kim2021conditional} architecture for end-to-end SVS. GANs have also been used for high-fidelity voice synthesis \citep{wu2020adversarially, huang2022singgan}, and DiffSinger \citep{liu2022diffsinger} introduces diffusion for improved mel-spectrogram generation.
Despite these advancements, precise control over singing techniques remains a challenge, which is essential for enhancing artistic expressiveness. Controllable SVS focuses on managing aspects like timbre, emotion, style, and techniques. Existing works often target specific controls, such as Muse-SVS \citep{kim2023muse} for pitch and emotion, StyleSinger \citep{zhang2024stylesinger} and TCSinger \cite{zhang2024tcsinger} for style transfer, and models for vibrato control \citep{liu2021vibrato, song2022singing, ikemiya2014transferring}. However, we advance technique controllable SVS by enabling control over seven techniques across five languages.

\subsection{Prompt-guided Voice Generation}
In terms of voice generation, previous controls rely on texts, scores, and feature labels. Prompt-based control is emerging as a simpler, more intuitive alternative and has achieved great success in text, image, and audio generation tasks \cite{brown2020language, ramesh2021zero, kreuk2022audiogen}
In speech generation, PromptTTS \citep{guo2023prompttts} and InstructTTS \citep{yang2023instructtts} use text descriptions to guide synthesis, offering precise control over style and content.
In singing voice generation, Prompt-Singer \citep{wang2024prompt} uses natural language prompts to control attributes like the singer's gender and volume but lacks advanced technique control. This paper addresses this gap by integrating multiple techniques into prompt-based control, allowing for more sophisticated and expressive singing voice generation.

\subsection{Flow Matching Generative Models}

Flow matching \cite{lipman2022flow} is an advanced generative modeling technique that optimizes the mapping between noise distributions and data samples by ensuring a smooth transport path, reducing sampling complexity. It has significantly improved audio generation tasks.
Voicebox \citep{le2024voicebox} uses flow matching for high-quality text-to-speech synthesis, noise removal, and content editing.
Audiobox \citep{vyas2023audiobox} leverages flow matching to enhance multi-modal audio generation with better controllability and efficiency. 
Matcha-TTS \citep{mehta2024matcha} applies optimal-transport conditional flow matching for high-quality, fast, and memory-efficient text-to-speech synthesis. 
VoiceFlow \citep{guo2024voiceflow} utilizes rectified flow matching to generate superior mel-spectrograms with fewer steps.
Inspired by these successes, we use flow matching for controllable singing voice synthesis to boost quality and efficiency.