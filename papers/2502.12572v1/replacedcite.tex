\section{Related Works}
\subsection{Singing Voice Synthesis}

Singing Voice Synthesis (SVS) has advanced significantly with deep learning, aiming to generate high-quality singing from musical scores and lyrics. Early models like XiaoiceSing ____ and DeepSinger ____ utilize non-autoregressive and feed-forward transformers to synthesize singing voice. VISinger ____ employs the VITS ____ architecture for end-to-end SVS. GANs have also been used for high-fidelity voice synthesis ____, and DiffSinger ____ introduces diffusion for improved mel-spectrogram generation.
Despite these advancements, precise control over singing techniques remains a challenge, which is essential for enhancing artistic expressiveness. Controllable SVS focuses on managing aspects like timbre, emotion, style, and techniques. Existing works often target specific controls, such as Muse-SVS ____ for pitch and emotion, StyleSinger ____ and TCSinger ____ for style transfer, and models for vibrato control ____. However, we advance technique controllable SVS by enabling control over seven techniques across five languages.

\subsection{Prompt-guided Voice Generation}
In terms of voice generation, previous controls rely on texts, scores, and feature labels. Prompt-based control is emerging as a simpler, more intuitive alternative and has achieved great success in text, image, and audio generation tasks ____
In speech generation, PromptTTS ____ and InstructTTS ____ use text descriptions to guide synthesis, offering precise control over style and content.
In singing voice generation, Prompt-Singer ____ uses natural language prompts to control attributes like the singer's gender and volume but lacks advanced technique control. This paper addresses this gap by integrating multiple techniques into prompt-based control, allowing for more sophisticated and expressive singing voice generation.

\subsection{Flow Matching Generative Models}

Flow matching ____ is an advanced generative modeling technique that optimizes the mapping between noise distributions and data samples by ensuring a smooth transport path, reducing sampling complexity. It has significantly improved audio generation tasks.
Voicebox ____ uses flow matching for high-quality text-to-speech synthesis, noise removal, and content editing.
Audiobox ____ leverages flow matching to enhance multi-modal audio generation with better controllability and efficiency. 
Matcha-TTS ____ applies optimal-transport conditional flow matching for high-quality, fast, and memory-efficient text-to-speech synthesis. 
VoiceFlow ____ utilizes rectified flow matching to generate superior mel-spectrograms with fewer steps.
Inspired by these successes, we use flow matching for controllable singing voice synthesis to boost quality and efficiency.