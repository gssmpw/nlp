\documentclass[10pt,twocolumn,letterpaper]{article}

%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage[preprint]{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{color}
\usepackage{xcolor,array}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,citecolor=cvprblue,bookmarks=false]{hyperref}
\def\paperID{349} % *** Enter the Paper ID here
\def\confName{3DV\xspace}
\def\confYear{2024\xspace}
% \iccvfinalcopy % *** Uncomment this line for the final submission

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ificcvfinal\pagestyle{empty}\fi

\definecolor{mark1}{rgb}{0.2,0.2,0.8}
\definecolor{textcolor}{rgb}{0.42, 0.35, 0.8}
\definecolor{textcolor1}{rgb}{0.45,.42,.75}

\newcommand{\adnane}[1]{\textcolor{blue}{#1}}

\newcommand{\q}[1]{\textcolor{red}{#1}}

\input{preamble.tex}

\begin{document}

%%%%%%%%% TITLE
%\title{Multi-Human Implicit Surface and Volume Rendering from Sparse Views using Geometry Constraints}
%\title{Multi-Human Implicit Surface and Volume Rendering from Sparse Views using Geometry Constraints}

\title{Few-Shot Multi-Human Neural Rendering Using Geometry Constraints}
%\title{Volume Rendering of Multi-Human from Sparse Images Using Geometry Constraints}

\author{Qian li$^{1}$, Victoria Fern\`andez Abrevaya$^{2}$, Franck Multon$^{1}$, Adnane Boukhayma$^{1}$\\
$^{1}$Inria, University Rennes, IRISA, CNRS, France\\
$^{2}$Max Planck Institute for Intelligent Systems, Germany
}

% \author{First Author\\
% Institution1\\
% Institution1 address\\
% {\tt\small firstauthor@i1.org}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
% }

\maketitle
% Remove page # from the first page of camera-ready.
%\ificcvfinal\thispagestyle{empty}\fi


\input{sections/1_Abstract.tex}
% \textcolor{mark1}{1. #' reviewers pointed that there were no specific design choices to make the method work for the multi-human case, i.e., after defining bounding boxes for each human, the reconstruction was performed independently and individually per-person.'
% Additionally, the reviewer requested a comparison against single person methods. \\
% Different from STNeRF, our sampling and learning not performed on each box individually,  rendering performed on per bounding box. The optimization is perform on the hole scene, not individually person. (Note that the sig-asia paper using sparsity loss to regularize the occupancy
% values) Since we render the hole scene, the occupancy of points on the ray will be close to 1 after converge. also, maybe the  normalized weights in equa11 helps. . goes to sig-asia- Figure 5. \\
% 2. #'The authorâ€™s rebuttal pointed that these methods would fail, because the segmentation masks required by single-person methods would not be reliable in multi-person scenarios. This argument, however did not convince ZCeA, as one could compute the segmentation masks within the SMPL bounding box projected onto the image. '\\
% 3. BY ZCeA 'Unless the authors give concrete examples where static reconstruction of humans based on multi-view is needed, I have problems to follow this argumentation. '\\multiple person VS single person\\ 
% Static Scene VS video\\no existing methods to do static multi-human rendering?? More challenge than video. The meaning of static scene reconstruction rather than video.\\ 
% 4. #'The quantitative evaluation discussion provided simply says that our method is better than prior work (same for the InfoNerf comparisons) but does not provide some insights to the reader as to why this is the case. For example I'd expect this section to clearly outline the key components for the proposed method that make it outperform this prior works.'\\
% GeoNeus draw a fig(see-fig-3 in GeoNeus paper) explaining when ray reach surface the weights looks like, it might also helps explain multi-person works for us. Do we need do the same?\\
% 5. #What makes the proposed method outperform prior works even when one person is visible in the scene? How would the ablation study look like (Table 4) if all components were removed and then each one was added. From Table 4 currently it's a little hard to evaluate which contribution has the highest impact as when each module is removed the other 2 are still integrated.\\
% 6. NeuS adpoted L1 loss regularizing rgb rendering for more stable training, we followed this. That might be anther reason for blur results.\\ 
% }
%%%%%%%%% BODY TEXT-----------------------------------------------
\input{sections/2_Introduction.tex}
\input{sections/3_Related.tex}
\input{sections/4_Method.tex}
\input{sections/5_Results.tex}
\input{sections/6_Limitations_Conclusion.tex}

%----------------------------------------------------------------------

%\clearpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\input{sections/supp.tex}

\end{document}