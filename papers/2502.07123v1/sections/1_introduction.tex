\section{Introduction}\label{sec:intro}

In computational finance, Monte Carlo simulations are used extensively to estimate the expected value of financial payoffs based on the solution of stochastic differential equations (SDEs) which model the evolution of stock prices, interest rates, exchange rates and other quantities \cite{glasserman04}.  Monte Carlo methods are very general and flexible, but for high accuracy it requires generating a large number of costly SDE path approximations, which has motivated research into a number of variance reduction or, equivalently, cost reduction techniques. One such method is
Multilevel Monte Carlo (MLMC), which was proposed in \cite{GILES2008} and was adapted for various applications that are summarised in \cite{Giles_overview17} and successfully combined with other methods such as quasi-Monte Carlo methods. The main idea of MLMC is to approximate the payoff using different time stepping resolutions when numerically solving the underlying SDE and to generate an optimal number of samples on each level, such that the overall computational cost is minimised subject to the desired bound on the variance. %, such that the total computational cost is minimised. 
The computational savings come from the fact that most samples are computed on the coarser levels and hence are less expensive while only a few samples from the finest levels are required \cite{GILES2008}.


Among the directions in which the computational cost 
of MLMC methods could further be reduced, an important avenue is the use of lower precision calculations, especially for the first Monte Carlo levels where the targeted accuracy is relatively low. 
 An overview of the research on mixed precision for the standard Monte Carlo (MC) framework is provided in \cite{ChowMixedPrecisionStandardMC} but only a few references study the potential of low precision computation in the MLMC framework \cite{Rounding_error_oliver}. To the best of our knowledge, the only MLMC framework with customised precision in the literature is \cite{brugger2014mixed}, but they use a uniform precision for all operations on each Monte Carlo level instead of optimising 
 the precision of each intermediary variable to reduce as much as possible the cost of path generation.
 
An important motivation for an MLMC framework with variable precision would be performing the low precision computations on reconfigurable hardware devices such as Field Programmable Gate Arrays (FPGAs). FPGAs contain customizable logic blocks and connectors that make it easy to adapt the digital circuit architecture for a specific application, leading to a highly parallel and optimised implementation. Therefore they are successfully exploited in applications that require high speed and have high computational workload, such as signal processing \cite{woods2008fpga}, and real time applications like high frequency trading \cite{HFT1,HFT2}. That is why a number of previous works in hardware architecture design implemented the MLMC algorithm to price financial options using FPGAs as accelerators, which resulted in improved speed and power efficiency compared to full CPU architectures \cite{Schryver2013AMM}. The paper \cite{lindsey2016domain} also proposed 
a Domain Specific Language to automate the configuration of FPGAs for this specific application. However, only \cite{brugger2014mixed} proposed a heuristic to reduce the precision in calculations.

In addition, all aforementioned works considered that the random number generation (RNG) is performed in single or double precision. Yet in most cases an important portion of the workload in the overall MLMC simulation comes from the RNG and in \cite{brugger2014mixed} this limited the total computational savings.
To reduce the cost of MLMC simulations in particular those based on the Geometric Brownian Motion (GBM), \cite{approximateICDF_Oliver, NestedOliver} have proposed to use approximate random numbers that are generated by applying an approximation of the inverse CDF to uniform random numbers. In \cite{NestedOliver}, the authors proposed a way to integrate these lower precision random variables into a \textit{nested} MLMC framework and completed a numerical analysis to bound the resulting error at each MC level by a product of the time step and the error in the random number approximation. The same authors show in \cite{approximateICDF_Oliver} that using approximate random variables reduces the cost of path generation by a factor 7.


In this paper we propose a nested MLMC framework that combines the use of approximate random normal variables and lower precision calculations to reduce the computational cost of MLMC even further than \cite{brugger2014mixed,NestedOliver}. We illustrate the efficiency of our framework in Matlab, after making several assumptions on the cost of operations and size of the errors that we carefully justify. We focus on the case of GBM and use the approximate RNG methods presented in \cite{approximateICDF_Oliver} as well as a new slightly modified method that combines CDF inversion and the central limit theorem. To choose the precision of the variables in the low precision path generation, we introduce a novel method to optimise the bit-widths. This optimisation is performed before the main path generation loop is executed and is based on a linear model of the payoff error  
due to rounding when computing in low precision. The error model relies on algorithmic differentiation in a similar manner to \cite{unifying-bwoptim,bitwidth-AD,ADAPT}. The bit-width optimisation procedure can be performed off-line, so this stage can be excluded from the on-line time complexity of our framework. The user specified desired accuracy is then enforced by calculating on-line the number of samples that need to be generated.

In terms of hardware design, we suggest implementing the low precision path generation on FPGAs and the full-precision ones on a CPU or GPU. 
The FPGA offers enough flexibility to define a separate bit-width for every variable in the low precision path generation, and can be reconfigured periodically to update the bit-widths when the market parameters have changed considerably. 


The paper is organized as follows : \Cref{sec:MLMC} introduces MLMC and nested MLMC to make clear the estimator that is implemented in our framework. Then in \Cref{sec:RNG} we detail the methods that could be used to obtain approximate random normally distributed numbers very cheaply for the low precision path generation. In \Cref{sec:error_model} and \Cref{sec:costModel} we propose an error model and a cost model (resp.) that we then use to formulate the optimisation problem that is solved to obtain the optimal bit-widths of fixed point variables in \Cref{sec:optimisation}. Finally we summarise our results and future directions in \Cref{sec:conclusion}.


