@misc{SDXL,
      title={SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis}, 
      author={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas Müller and Joe Penna and Robin Rombach},
      year={2023},
      eprint={2307.01952},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.01952}, 
}

@misc{av1,
      title={Sound2Sight: Generating Visual Dynamics from Sound and Context}, 
      author={Anoop Cherian and Moitreya Chatterjee and Narendra Ahuja},
      year={2020},
      eprint={2007.12130},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2007.12130}, 
}

@misc{av2,
      title={The Power of Sound (TPoS): Audio Reactive Video Generation with Stable Diffusion}, 
      author={Yujin Jeong and Wonjeong Ryoo and Seunghyun Lee and Dabin Seo and Wonmin Byeon and Sangpil Kim and Jinkyu Kim},
      year={2023},
      eprint={2309.04509},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2309.04509}, 
}

@misc{av3,
      title={MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation}, 
      author={Ludan Ruan and Yiyang Ma and Huan Yang and Huiguo He and Bei Liu and Jianlong Fu and Nicholas Jing Yuan and Qin Jin and Baining Guo},
      year={2023},
      eprint={2212.09478},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.09478}, 
}

@inproceedings{captcha,
author = {Ahn, Luis Von and Blum, Manuel and Hopper, Nicholas J. and Langford, John},
title = {CAPTCHA: using hard AI problems for security},
year = {2003},
isbn = {3540140395},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We introduce captcha, an automated test that humans can pass, but current computer programs can't pass: any program that has high success over a captcha can be used to solve an unsolved Artificial Intelligence (AI) problem. We provide several novel constructions of captchas. Since captchas have many applications in practical security, our approach introduces a new class of hard problems that can be exploited for security purposes. Much like research in cryptography has had a positive impact on algorithms for factoring and discrete log, we hope that the use of hard AI problems for security purposes allows us to advance the field of Artificial Intelligence. We introduce two families of AI problems that can be used to construct captchas and we show that solutions to such problems can be used for steganographic communication. captchas based on these AI problem families, then, imply a win-win situation: either the problems remain unsolved and there is a way to differentiate humans from computers, or the problems are solved and there is a way to communicate covertly on some channels.},
booktitle = {Proceedings of the 22nd International Conference on Theory and Applications of Cryptographic Techniques},
pages = {294–311},
numpages = {18},
location = {Warsaw, Poland},
series = {EUROCRYPT'03}
}

@misc{celeblora, title={celebrity Stable Diffusion AI Models | Civitai}, url={https://civitai.com/tag/celebrity}, journal={Civitai.com}, author={civitai}, year={2024} }

@misc{dalle,
  doi = {10.48550/ARXIV.2204.13807},
  
  url = {https://arxiv.org/abs/2204.13807},
  
  author = {Marcus, Gary and Davis, Ernest and Aaronson, Scott},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A very preliminary analysis of DALL-E 2},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@article{deepfake,
   title={Deep learning for deepfakes creation and detection: A survey},
   volume={223},
   ISSN={1077-3142},
   url={http://dx.doi.org/10.1016/j.cviu.2022.103525},
   DOI={10.1016/j.cviu.2022.103525},
   journal={Computer Vision and Image Understanding},
   publisher={Elsevier BV},
   author={Nguyen, Thanh Thi and Nguyen, Quoc Viet Hung and Nguyen, Dung Tien and Nguyen, Duc Thanh and Huynh-The, Thien and Nahavandi, Saeid and Nguyen, Thanh Tam and Pham, Quoc-Viet and Nguyen, Cuong M.},
   year={2022},
   month=oct, pages={103525} }

@misc{delbouys2018music,
      title={Music Mood Detection Based On Audio And Lyrics With Deep Neural Net}, 
      author={Rémi Delbouys and Romain Hennequin and Francesco Piccoli and Jimena Royo-Letelier and Manuel Moussallam},
      year={2018},
      eprint={1809.07276},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{dit,
      title={Scalable Diffusion Models with Transformers}, 
      author={William Peebles and Saining Xie},
      year={2023},
      eprint={2212.09748},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.09748}, 
}

@misc{dreammachine, title={Luma Dream Machine}, url={https://lumalabs.ai/dream-machine}, journal={Luma Dream Machine}, author={AI, Luma} }

@misc{flux, title={GitHub - black-forest-labs/flux: Official inference repo for FLUX.1 models}, url={https://github.com/black-forest-labs/flux}, journal={GitHub}, author={black-forest-labs}, year={2024} }

@misc{gen3alpha, title={Runway Research | Introducing Gen-3 Alpha: A New Frontier for Video Generation}, url={https://runwayml.com/research/introducing-gen-3-alpha}, journal={Runwayml.com}, author={Runway ML}, year={2024} }

@misc{imagen,
  doi = {10.48550/ARXIV.2205.11487},
  
  url = {https://arxiv.org/abs/2205.11487},
  
  author = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S. Sara and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan and Fleet, David J and Norouzi, Mohammad},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{kaiber2023,
  author = {{Kaiber AI}},
  title = {Kaiber AI Product},
  year = {2023},
  url = {https://kaiber.ai/product},
  note = {Accessed: 2024-08-16}
}

@misc{neuralframes2023,
  author = {{NeuralFrames}},
  title = {AI Music Video Generator},
  year = {2023},
  url = {https://www.neuralframes.com/ai-music-video-generator},
  note = {Accessed: 2024-08-16}
}

@inproceedings{opensmile,
author = {Eyben, Florian and W\"{o}llmer, Martin and Schuller, Bj\"{o}rn},
title = {Opensmile: The Munich Versatile and Fast Open-Source Audio Feature Extractor},
year = {2010},
isbn = {9781605589336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1873951.1874246},
doi = {10.1145/1873951.1874246},
abstract = {We introduce the openSMILE feature extraction toolkit, which unites feature extraction algorithms from the speech processing and the Music Information Retrieval communities. Audio low-level descriptors such as CHROMA and CENS features, loudness, Mel-frequency cepstral coefficients, perceptual linear predictive cepstral coefficients, linear predictive coefficients, line spectral frequencies, fundamental frequency, and formant frequencies are supported. Delta regression and various statistical functionals can be applied to the low-level descriptors. openSMILE is implemented in C++ with no third-party dependencies for the core functionality. It is fast, runs on Unix and Windows platforms, and has a modular, component based architecture which makes extensions via plug-ins easy. It supports on-line incremental processing for all implemented features as well as off-line and batch processing. Numeric compatibility with future versions is ensured by means of unit tests. openSMILE can be downloaded from http://opensmile.sourceforge.net/.},
booktitle = {Proceedings of the 18th ACM International Conference on Multimedia},
pages = {1459–1462},
numpages = {4},
keywords = {music, speech, signal processing, emotion, audio feature extraction, statistical functionals},
location = {Firenze, Italy},
series = {MM '10}
}

@misc{opensora, title={Open-Sora/docs/report\_03.md at main · hpcaitech/Open-Sora}, url={https://github.com/hpcaitech/Open-Sora/blob/main/docs/report\_03.md}, journal={GitHub}, author={hpcaitech}, year={2024} }

@misc{pika, title={Pika}, url={https://pika.art/}, journal={pika.art}, author={Pika} }

@misc{recaptcha,
      title={An Empirical Study \& Evaluation of Modern CAPTCHAs}, 
      author={Andrew Searles and Yoshimichi Nakatsuka and Ercan Ozturk and Andrew Paverd and Gene Tsudik and Ai Enkoji},
      year={2023},
      eprint={2307.12108},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2307.12108}, 
}

@misc{sora,
      title={Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models}, 
      author={Yixin Liu and Kai Zhang and Yuan Li and Zhiling Yan and Chujie Gao and Ruoxi Chen and Zhengqing Yuan and Yue Huang and Hanchi Sun and Jianfeng Gao and Lifang He and Lichao Sun},
      year={2024},
      eprint={2402.17177},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.17177}, 
}

@misc{stablediff,
  doi = {10.48550/ARXIV.2112.10752},
  
  url = {https://arxiv.org/abs/2112.10752},
  
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {High-Resolution Image Synthesis with Latent Diffusion Models},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{svd,
      title={Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets}, 
      author={Andreas Blattmann and Tim Dockhorn and Sumith Kulal and Daniel Mendelevitch and Maciej Kilian and Dominik Lorenz and Yam Levi and Zion English and Vikram Voleti and Adam Letts and Varun Jampani and Robin Rombach},
      year={2023},
      eprint={2311.15127},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.15127}, 
}

