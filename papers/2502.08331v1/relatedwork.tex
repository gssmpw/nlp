\section{Related Work}
\label{sec:rel}

\parindent=0pt
\textbf{Hierarchical Storage}: Current research typically classifies data into two tiers based on hotness and coldness, focusing on mechanisms to differentiate between them. Hot data is frequently accessed, while cold data is accessed less often. Methods for classification fall into two groups: one relies on the characteristics of data structures, determining hotness or coldness based on the relative position of data within the data structure. Examples of this category include LRU~\cite{Chang2002AnAS}~\cite{ONeil1993TheLP} and ARC~\cite{MegiddoProceedingsOF}~\cite{Jiang2005DULOAE}~\cite{Cheng2015AMCAA}, commonly employed in cache management for operating systems. The other employs statistical methods to measure data hotness. By defining relevant metrics qualitatively or quantitatively, the heat of data is ascertained. ~\cite{Levandoski2013IdentifyingHA} adopts such approach, suggesting to use exponential smoothing algorithms on log access records to predict the likelihood of future data access.
In contrast, \textbf{Brame} classifies the data into three tiers to satisfy the diverse storage requirements of \textbf{CEDC}.

\parindent=0pt
\textbf{Data Migration and Scheduling}: Data migration can be categorized into real-time replacement and periodic migration scheduling. The former, known as cache replacement strategies, has been a long-standing focus, with classical methods such as LRU~\cite{Chang2002AnAS}, LFU~\cite{Karakostas2002ExploitationOD}~\cite{Jayarekha2010AnAD}, ARC~\cite{MegiddoProceedingsOF}, CLOCK~\cite{Jiang2005CLOCKProAE}~\cite{Lee2015MCLOCKMP}., have demonstrated significant success and widespread application over the past few decades. Recently, AI techniques like reinforcement learning (LeCaR~\cite{Vietri2018DrivingCR}) and GBDT-based methods (LRB~\cite{Song2020LearningRB}, MAT~\cite{Yang2023ALC}) have been explored for data eviction. Research on periodic migration is more limited , with relevant works include Gorilla~\cite{Pelkonen2015GorillaAF}, Xie's work~\cite{Xie2019}, and TS-Cabinet~\cite{Cui2023TSCabinetHS}. Gorilla retains data collected by the system over the last 26 hours as hot data in the cache and periodically removes outdated data to the disk. ~\cite{Xie2019} proposes quantitatively modeling the data temperature using Newton's cooling law and utilizes the high-low watermark method to eliminate cold data from hot storage media to cold media. TS-Cabinet, in the context of time-series databases, addresses the issue of hierarchical data placement. It suggests modeling data heat by combining Newton's cooling law and the Stefan-Boltzmann law and employs a method akin to ~\cite{Xie2019} to migrate data between the cold layer and the hot layer.
On the contrary, \textbf{Brame} uses $Blocks$ as the fundamental unit for data migration, provides a unified framework that supports both periodic migration scheduling between the cloud and edge and real-time cache replacement on the end.

%\vspace{-0.5em}