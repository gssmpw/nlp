\section{Related Work}
\label{sec:relatedwork}

% \textbf{Sparse-View Novel View Synthesis}: 
% Neural rendering-based methods, such as Neural Radiance Fields (NeRF) 
% and 3D Gaussian Splatting (3DGS), often encounter overfitting issues 
% when operating in a few-view setting.
% %
% Several approaches have been proposed to address this challenge.
% %
% Some works~\citep{jain2021putting, wynn2023diffusionerf, xiong2023sparsegs} 
% integrate large-scale models, such as CLIP and diffusion models, 
% into the training process to regulate and maintain consistency.
% %
% Others~\citep{xiong2023sparsegs, kim2022infonerf, niemeyer2022regnerf, yang2023freenerf, zhu2023fsgs} 
% focus on modifying the structure or introducing 
% regularization to the representations of NeRF and 
% 3D Gaussian Splatting:
% %
% InfoNeRF~\citep{kim2022infonerf} proposed an 
% information-theoretic regularization for neural 
% implicit representations.
% %
% Regulation of geometry and appearance on unobserved 
% viewpoints is addressed in~\citep{niemeyer2022regnerf}.
% %
% FreeNerf~\citep{yang2023freenerf} introduces free 
% frequency regularization for NeRF, while FSGS~\citep{zhu2023fsgs} 
% proposes Gaussian Unpooling to mitigate overfitting issues in 3DGS.
% %
% Geometry prior information is also incorporated 
% in~\citep{deng2022depth, roessle2022dense, song2024darf, wang2023sparsenerf, zhu2023fsgs, xiong2023sparsegs, paliwal2024coherentgs, fan2024instantsplat}.
% %
% Specifically, some works~\citep{deng2022depth, roessle2022dense, song2024darf, wang2023sparsenerf} 
% add depth supervision for NeRF-based representations, 
% while others~\citep{zhu2023fsgs, xiong2023sparsegs, paliwal2024coherentgs} 
% incorporate it for 3DGS.
% %
% The 3D point cloud prior provided by Dust3r~\cite{} is 
% also be utilized in ~\citep{fan2024instantsplat}.
% %
% Instantsplat~\citep{fan2024instantsplat} utilize
% 3D point cloud prior and pose prior 
% provided by Dust3r~\citep{dust3r_cvpr24} to initialize
% 3DGS points and refine the attributes of points
% and camera pose progressively.
% %
% Optical flow matching priors of training views are also considered 
% in CoherentGS~\citep{paliwal2024coherentgs}.
% %
% However, none of these approaches utilize unobserved 
% views for matching priors.
% %

\textbf{Geometry Reconstruction Based on 3DGS}: 
To enhance the geometry of 3DGS representations, 
some studies~\citep{gao2024mesh, waczynska2024games, lyu20243dgsr, chen2023neusg} 
focus on integrating mesh or SDF representations with 3DGS.
~\citep{gao2024mesh} improve the splitting of 3DGS under the guidance of
mesh representation and deformation gradients. 
%
A hybrid representation that integrates 3DGS with mesh, 
allowing 3DGS to be modified as a mesh, is introduced in 
~\citep{waczynska2024games}.
%
Mani-GS~\citep{gao2024mani} binds Gaussian and shape-aware triangular mesh to manipulate 3DGS directly.
%
3DGSR~\citep{lyu20243dgsr} combines a signed distance field (SDF) 
network with 3DGS to enhance geometry quality, 
aligning the SDF networkâ€™s geometry with that of 3DGS.
%
NeuSG~\citep{chen2023neusg} utilizes point clouds from 
3DGS to regulate NeuS, while its normals are also used 
to refine 3DGS. Additionally, NeuSG includes regularizers 
to ensure that 3DGS remains close to the surface.
%
Some work~\citep{guedon2023sugar, huang20242d, yu2024gaussian, chen2024pgsr} 
tends to extract geometry from 3DGS directly, benefiting from 
its fast training and rendering speed.
Sugar ~\citep{guedon2023sugar}
proposes an efficient mesh extraction method from 3DGS, aligned with
a regularization term during the training process and a refinement strategy.
%
2DGS~\citep{huang20242d} proposed a 2D surface modeling and two regularization 
losses which can preserve perspective-correct splatting and enchance geometry 
reconstruction.
%
A ray-tracing-based volume rendering is introduced in 
GOF~\citep{yu2024gaussian},
allowing the extraction of geometry from 3DGS directly.
%
PGSR~\citep{chen2024pgsr} proposes unbiased depth rendering
and single\& multi-view regularization loss to preserve 
geometric consistency.
%
However, in low-texture and less frequently observed areas, 
such as indoor scenes, 3DGS still tends to overfit to 
the limited input views, necessitating regulation 
through additional prior cues.

%

%
\textbf{Prior Regulation for Rendering}:
Prior information is usually incoporated in ill-posed problems,
including sparse view novel view synthesis, dynamic scene reconstruction,
and mesh reconstruction.
For sparse novel view synthesis tasks, most works utilize the prior depth information~\citep{deng2022depth, roessle2022dense, song2024darf, wang2023sparsenerf, zhu2023fsgs, xiong2023sparsegs, paliwal2024coherentgs}, semantic information~\citep{jain2021putting, wynn2023diffusionerf, xiong2023sparsegs}, and matching information~\citep{paliwal2024coherentgs, lao2024corresnerf} 
to constrain the optimization process of 3DGS.
Dynamic scene reconstruction is another challenging
task which requires reconstructing the scene geometry and object motion at the same
time. 
Therefore, optical flow priors are crucial as
they can help distinguish between camera motion 
and object motion~\citep{liu2023robust} 
while providing motion priors between frames~\citep{Liu_2023_CVPR, gao2021dynamic, li2023dynibar, 
wang2023flow, guo2023forward, tian2023mononerf}.
For the mesh reconstruction task,
geometry quality is also
enhanced by depth priors  
~\citep{wei2021nerfingmvs, yu2022monosdf, turkulainen2024dn} 
or normal priors ~\citep{yu2022monosdf, turkulainen2024dn}. 
%
However, using optical flow model priors to obtain metric depth priors 
to help geometric reconstruction, 
while leveraging unobserved regions to enhance the quality 
of limited view reconstruction, has not yet been explored.
%