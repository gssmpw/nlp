\section{Experiments}

\subsection{Setups}
\subsubsection{Implementation Details}
We apply our FDS method to two types of 3DGS: 
the original 3DGS, and 2DGS~\citep{huang20242d}. 
%
The number of iterations in our optimization 
process is 35,000.
We follow the default training configuration 
and apply our FDS method after 15,000 iterations,
then we add normal consistency loss for both
3DGS and 2DGS after 25000 iterations.
%
The weight for FDS, $\lambda_{fds}$, is set to 0.015,
the $\sigma$ is set to 23,
and the weight for normal consistency is set to 0.15
for all experiments. 
We removed the depth distortion loss in 2DGS 
because we found that it degrades its results in indoor scenes.
%
The Gaussian point cloud is initialized using Colmap
for all datasets.
%
%
We tested the impact of 
using Sea Raft~\citep{wang2025sea} and 
Raft\citep{teed2020raft} on FDS performance.
%
Due to the blurriness of the ScanNet dataset, 
additional prior constraints are required.
Thus, we incorporate normal prior supervision 
on the rendered normals 
in ScanNet (V2) dataset by default.
The normal prior is predicted by the Stable Normal 
model~\citep{ye2024stablenormal}
across all types of 3DGS.
%
The entire framework is implemented in 
PyTorch~\citep{paszke2019pytorch}, 
and all experiments are conducted on 
a single NVIDIA 4090D GPU.

\begin{figure}[t] \centering
    \makebox[0.16\textwidth]{\scriptsize Input}
    \makebox[0.16\textwidth]{\scriptsize 3DGS}
    \makebox[0.16\textwidth]{\scriptsize 2DGS}
    \makebox[0.16\textwidth]{\scriptsize 3DGS + FDS}
    \makebox[0.16\textwidth]{\scriptsize 2DGS + FDS}
    \makebox[0.16\textwidth]{\scriptsize GT (Depth)}

    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare3/gt_rgb/frame_00522.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare3/3DGS/frame_00522.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare3/2DGS/frame_00522.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare3/3DGS+FDS/frame_00522.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare3/2DGS+FDS/frame_00522.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare3/gt_depth/frame_00522.jpg} \\

    % \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare1/gt_rgb/frame_00137.jpg}
    % \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare1/3DGS/frame_00137.jpg}
    % \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare1/2DGS/frame_00137.jpg}
    % \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare1/3DGS+FDS/frame_00137.jpg}
    % \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare1/2DGS+FDS/frame_00137.jpg}
    % \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare1/gt_depth/frame_00137.jpg} \\

     \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare2/gt_rgb/frame_00262.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare2/3DGS/frame_00262.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare2/2DGS/frame_00262.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare2/3DGS+FDS/frame_00262.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare2/2DGS+FDS/frame_00262.jpg}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare2/gt_depth/frame_00262.jpg} \\

    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare4/gt_rgb/frame00000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare4/3DGS/frame00000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare4/2DGS/frame00000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare4/3DGS+FDS/frame00000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare4/2DGS+FDS/frame00000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare4/gt_depth/frame00000.png} \\

    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare5/gt_rgb/frame00080.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare5/3DGS/frame00080.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare5/2DGS/frame00080.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare5/3DGS+FDS/frame00080.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare5/2DGS+FDS/frame00080.png}
    \includegraphics[width=0.16\textwidth]{figure/fig3_img/compare5/gt_depth/frame00080.png} \\



    \caption{\textbf{Comparison of depth reconstruction on Mushroom and ScanNet datasets.} The original
    3DGS or 2DGS model equipped with FDS can remove unwanted floaters and reconstruct
    geometry more preciously.}
    \label{fig:compare}
\end{figure}


\subsubsection{Datasets and Metrics}

We evaluate our method for 3D reconstruction 
and novel view synthesis tasks on
\textbf{Mushroom}~\citep{ren2024mushroom},
\textbf{ScanNet (v2)}~\citep{dai2017scannet}, and 
\textbf{Replica}~\citep{replica19arxiv}
datasets,
which feature challenging indoor scenes with both 
sparse and dense image sampling.
%
The Mushroom dataset is an indoor dataset 
with sparse image sampling and two distinct 
camera trajectories. 
%
We train our model on the training split of 
the long capture sequence and evaluate 
novel view synthesis on the test split 
of the long capture sequences.
%
Five scenes are selected to evaluate our FDS, 
including "coffee room", "honka", "kokko", 
"sauna", and "vr room". 
%
ScanNet(V2)~\citep{dai2017scannet}  consists of 1,613 indoor scenes
with annotated camera poses and depth maps. 
%
We select 5 scenes from the ScanNet (V2) dataset, 
uniformly sampling one-tenth of the views,
following the approach in ~\citep{guo2022manhattan}.
To further improve the geometry rendering quality of 3DGS, 
%
Replica~\citep{replica19arxiv} contains small-scale 
real-world indoor scans. 
We evaluate our FDS on five scenes from 
Replica: office0, office1, office2, office3 and office4,
selecting one-tenth of the views for training.
%
The results for Replica are provided in the 
supplementary materials.
To evaluate the rendering quality and geometry 
of 3DGS, we report PSNR, SSIM, and LPIPS for 
rendering quality, along with Absolute Relative Distance 
(Abs Rel) as a depth quality metrics.
%
Additionally, for mesh evaluation, 
we use metrics including Accuracy, Completion, 
Chamfer-L1 distance, Normal Consistency, 
and F-scores.




\subsection{Results}
\subsubsection{Depth rendering and novel view synthesis}
The comparison results on Mushroom and 
ScanNet are presented in \tabref{tab:mushroom} 
and \tabref{tab:scannet}, respectively. 
%
Due to the sparsity of sampling 
in the Mushroom dataset,
challenges are posed for both GOF~\citep{yu2024gaussian} 
and PGSR~\citep{chen2024pgsr}, 
leading to their relative poor performance 
on the Mushroom dataset.
%
Our approach achieves the best performance 
with the FDS method applied during the training process.
The FDS significantly enhances the 
geometric quality of 3DGS on the Mushroom dataset, 
improving the "abs rel" metric by more than 50\%.
%
We found that Sea Raft~\citep{wang2025sea}
outperforms Raft~\citep{teed2020raft} on FDS, 
indicating that a better optical flow model 
can lead to more significant improvements.
%
Additionally, the render quality of RGB 
images shows a slight improvement, 
by 0.58 in 3DGS and 0.50 in 2DGS, 
benefiting from the incorporation of cross-view consistency in FDS. 
%
On the Mushroom
dataset, adding the FDS loss increases 
the training time by half an hour, which maintains the same
level as baseline.
%
Similarly, our method shows a notable improvement on the ScanNet dataset as well using Sea Raft~\citep{wang2025sea} Model. The "abs rel" metric in 2DGS is improved nearly 50\%. This demonstrates the robustness and effectiveness of the FDS method across different datasets.
%


% \begin{wraptable}{r}{0.6\linewidth} \centering
% \caption{\textbf{Ablation study on geometry priors.}} 
%         \label{tab:analysis_prior}
%         \input{tables/ablation_prior}
% \end{wraptable}



The qualitative comparisons on the Mushroom and ScanNet dataset 
are illustrated in \figref{fig:compare}. 
%
%
As seen in the first row of \figref{fig:compare}, 
both the original 3DGS and 2DGS suffer from overfitting, 
leading to corrupted geometry generation. 
%
Our FDS effectively mitigates this issue by 
supervising the matching relationship between 
the input and sampled views, 
helping to recover the geometry.
%
FDS also improves the refinement of geometric details, 
as shown in other rows. 
By incorporating the matching prior through FDS, 
the quality of the rendered depth is significantly improved.
%

\begin{table}[t] \centering
\begin{minipage}[t]{0.96\linewidth}
        \captionof{table}{\textbf{3D Reconstruction 
        and novel view synthesis results on Mushroom dataset. * 
        Represents that FDS uses the Raft model.
        }}
        \label{tab:mushroom}
        \input{tables/mushroom}
\end{minipage}\hfill
\end{table}

\begin{table}[t] \centering
\begin{minipage}[t]{0.96\linewidth}
        \captionof{table}{\textbf{3D Reconstruction 
        and novel view synthesis results on ScanNet dataset.}}
        \label{tab:scannet}
        \input{tables/scannet_replica}
\end{minipage}\hfill
\end{table}


\begin{table}[t] \centering
\begin{minipage}[t]{0.96\linewidth}
        \captionof{table}{\textbf{Ablation study on geometry priors.}}
        \label{tab:analysis_prior}
        \input{tables/ablation_prior}
\end{minipage}\hfill
\end{table}




\subsubsection{Mesh extraction}
To further demonstrate the improvement in geometry quality, 
we applied methods used in ~\citep{turkulainen2024dnsplatter} 
to extract meshes from the input views of optimized 3DGS. 
The comparison results are presented  
in \tabref{tab:mushroom}. 
With the integration of FDS, the mesh quality is significantly enhanced compared to the baseline, featuring fewer floaters and more well-defined shapes.
 %
% Following the incorporation of FDS, the reconstruction 
% results exhibit fewer floaters and more well-defined 
% shapes in the meshes. 
% Visualized comparisons
% are provided in the supplementary material.

% \begin{figure}[t] \centering
%     \makebox[0.19\textwidth]{\scriptsize GT}
%     \makebox[0.19\textwidth]{\scriptsize 3DGS}
%     \makebox[0.19\textwidth]{\scriptsize 3DGS+FDS}
%     \makebox[0.19\textwidth]{\scriptsize 2DGS}
%     \makebox[0.19\textwidth]{\scriptsize 2DGS+FDS} \\

%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare1/gt02.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare1/baseline06.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare1/baseline_fds05.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare1/2dgs04.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare1/2dgs_fds03.png} \\

%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare2/gt00.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare2/baseline02.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare2/baseline_fds01.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare2/2dgs04.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare2/2dgs_fds03.png} \\
      
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare3/gt05.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare3/3dgs03.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare3/3dgs_fds04.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare3/2dgs02.png}
%     \includegraphics[width=0.19\textwidth]{figure/fig4_img/compare3/2dgs_fds01.png} \\

%     \caption{\textbf{Qualitative comparison of extracted mesh 
%     on Mushroom and ScanNet datasets.}}
%     \label{fig:mesh}
% \end{figure}












\subsection{Ablation study}


\textbf{Ablation study on geometry priors:} 
To highlight the advantage of incorporating matching priors, 
we incorporated various types of priors generated by different 
models into 2DGS. These include a monocular depth estimation
model (Depth Anything v2)~\citep{yang2024depth}, a two-view depth estimation 
model (Unimatch)~\citep{xu2023unifying}, 
and a monocular normal estimation model (DSINE)~\citep{bae2024rethinking}.
We adapt the scale and shift-invariant loss in Midas~\citep{birkl2023midas} for
monocular depth supervision and L1 loss for two-view depth supervison.
%
We use Sea Raft~\citep{wang2025sea} as our default optical flow model.
%
The comparison results on Mushroom dataset 
are shown in ~\tabref{tab:analysis_prior}.
We observe that the normal prior provides accurate shape information, 
enhancing the geometric quality of the radiance field. 
%
% In contrast, the monocular depth prior slightly increases 
% the 'Abs Rel' due to its ambiguous scale and inaccurate depth ordering.
% Moreover, the performance of monocular depth estimation 
% in the sauna scene is particularly poor, 
% primarily due to the presence of numerous reflective 
% surfaces and textureless walls, which limits the accuracy of monocular depth estimation.
%
The multi-view depth prior, hindered by the limited feature overlap 
between input views, fails to offer reliable geometric 
information. We test average "Abs Rel" of multi-view depth prior
, and the result is 0.19, which performs worse than the "Abs Rel" results 
rendered by original 2DGS.
From the results, it can be seen that depth order information provided by monocular depth improves
reconstruction accuracy. Meanwhile, our FDS achieves the best performance among all the priors, 
and by integrating all
three components, we obtained the optimal results.
%
%
\begin{figure}[t] \centering
    \makebox[0.16\textwidth]{\scriptsize RF (16000 iters)}
    \makebox[0.16\textwidth]{\scriptsize RF* (20000 iters)}
    \makebox[0.16\textwidth]{\scriptsize RF (20000 iters)  }
    \makebox[0.16\textwidth]{\scriptsize PF (16000 iters)}
    \makebox[0.16\textwidth]{\scriptsize PF (20000 iters)}


    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare1/16000.png}
    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare1/20000_wo_flow_loss.png}
    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare1/20000.png}
    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare1/16000_prior.png}
    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare1/20000_prior.png}\\

    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare2/16000.png}
    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare2/20000_wo_flow_loss.png}
    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare2/20000.png}
    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare2/16000_prior.png}
    % \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare2/20000_prior.png}\\

    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare3/16000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare3/20000_wo_flow_loss.png}
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare3/20000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare3/16000_prior.png}
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare3/20000_prior.png}\\
    
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare4/16000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare4/20000_wo_flow_loss.png}
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare4/20000.png}
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare4/16000_prior.png}
    \includegraphics[width=0.16\textwidth]{figure/fig5_img/compare4/20000_prior.png}\\

    \includegraphics[width=0.30\textwidth]{figure/fig5_img/bar.png}

    \caption{\textbf{The error map of Radiance Flow and Prior Flow.} RF: Radiance Flow, PF: Prior Flow, * means that there is no FDS loss supervision during optimization.}
    \label{fig:error_map}
\end{figure}




\textbf{Ablation study on FDS: }
In this section, we present the design of our FDS 
method through an ablation study on the 
Mushroom dataset to validate its effectiveness.
%
The optional configurations of FDS are outlined in ~\tabref{tab:ablation_fds}.
Our base model is the 2DGS equipped with FDS,
and its results are shown 
in the first row. The goal of this analysis 
is to evaluate the impact 
of various strategies on FDS sampling and loss design.
%
We observe that when we 
replace $I_i$ in \eqref{equ:mflow} with $C_i$, 
as shown in the second row, the geometric quality 
of 2DGS deteriorates. Using $I_i$ instead of $C_i$ 
help us to remove the floaters in $\bm{C^s}$, which are also 
remained in $\bm{C^i}$.
We also experiment with modifying the FDS loss. For example, 
in the third row, we use the neighbor 
input view as the sampling view, and replace the 
render result of neighbor view with ground truth image of its input view.
%
Due to the significant movement between images, the Prior Flow fails to accurately 
match the pixel between them, leading to a further degradation in geometric quality.
%
Finally, we attempt to fix the sampling view 
and found that this severely damaged the geometric quality, 
indicating that random sampling is essential for the stability 
of the mean error in the Prior flow.



\begin{table}[t] \centering

\begin{minipage}[t]{1.0\linewidth}
        \captionof{table}{\textbf{Ablation study on FDS strategies.}}
        \label{tab:ablation_fds}
        \input{tables/ablation_fds}
\end{minipage}
\end{table}




\begin{figure}[htbp] \centering
    \makebox[0.22\textwidth]{}
    \makebox[0.22\textwidth]{}
    \makebox[0.22\textwidth]{}
    \makebox[0.22\textwidth]{}
    \\

    \includegraphics[width=0.22\textwidth]{figure/fig6_img/l1/rgb/frame00096.png}
    \includegraphics[width=0.22\textwidth]{figure/fig6_img/l1/render_rgb/frame00096.png}
    \includegraphics[width=0.22\textwidth]{figure/fig6_img/l1/render_depth/frame00096.png}
    \includegraphics[width=0.22\textwidth]{figure/fig6_img/l1/depth/frame00096.png}

    % \includegraphics[width=0.22\textwidth]{figure/fig6_img/l2/rgb/frame00112.png}
    % \includegraphics[width=0.22\textwidth]{figure/fig6_img/l2/render_rgb/frame00112.png}
    % \includegraphics[width=0.22\textwidth]{figure/fig6_img/l2/render_depth/frame00112.png}
    % \includegraphics[width=0.22\textwidth]{figure/fig6_img/l2/depth/frame00112.png}

    \caption{\textbf{Limitation of FDS.} }
    \label{fig:limitation}
\end{figure}


% \begin{figure}[t] \centering
%     \makebox[0.48\textwidth]{}
%     \makebox[0.48\textwidth]{}
%     \\
%     \includegraphics[width=0.48\textwidth]{figure/loss_Ignatius.pdf}
%     \includegraphics[width=0.48\textwidth]{figure/loss_family.pdf}
%     \caption{\textbf{Comparison the photometric error of Radiance Flow and Prior Flow:} 
%     We add FDS method after 2k iteration during training.
%     The results show
%     that:  1) The Prior Flow is more precise and 
%     robust than Radiance Flow during the radiance 
%     optimization; 2) After adding the FDS loss 
%     which utilize Prior 
%     flow to supervise the Radiance Flow at 2k iterations, 
%     both flow are more accurate, which lead to
%     a mutually reinforcing effects.(TODO fix it)} 
%     \label{fig:flowcompare}
% \end{figure}






\textbf{Interpretive Experiments: }
To demonstrate the mutual refinement of two flows in our FDS, 
For each view, we sample the unobserved 
views multiple times to compute the mean error 
of both Radiance Flow and Prior Flow. 
We use Raft~\citep{teed2020raft} as our default optical flow model
for visualization.
The ground truth flow is calculated based on 
~\eref{equ:flow_pose} and ~\eref{equ:flow} 
utilizing ground truth depth in dataset.
We introduce our FDS loss after 16000 iterations during 
optimization of 2DGS.
The error maps are shown in ~\figref{fig:error_map}.
Our analysis reveals that Radiance Flow tends to 
exhibit significant geometric errors, 
whereas Prior Flow can more accurately estimate the geometry,
effectively disregarding errors introduced by floating Gaussian points. 

%





\subsection{Limitation and further work}

Firstly, our FDS faces challenges in scenes with 
significant lighting variations between different 
views, as shown in the lamp of first row in ~\figref{fig:limitation}. 
%
Incorporating exposure compensation into FDS could help address this issue. 
%
 Additionally, our method struggles with 
 reflective surfaces and motion blur,
 leading to incorrect matching. 
 %
 In the future, we plan to explore the potential 
 of FDS in monocular video reconstruction tasks, 
 using only a single input image at each time step.
 


\section{Conclusions}
In this paper, we propose Flow Distillation Sampling (FDS), which
leverages the matching prior between input views and 
sampled unobserved views from the pretrained optical flow model, to improve the geometry quality
of Gaussian radiance field. 
Our method can be applied to different approaches (3DGS and 2DGS) to enhance the geometric rendering quality of the corresponding neural radiance fields.
We apply our method to the 3DGS-based framework, 
and the geometry is enhanced on the Mushroom, ScanNet, and Replica datasets.

\section*{Acknowledgements} This work was supported by 
National Key R\&D Program of China (2023YFB3209702), 
the National Natural Science Foundation of 
China (62441204, 62472213), and Gusu 
Innovation \& Entrepreneurship Leading Talents Program (ZXL2024361)