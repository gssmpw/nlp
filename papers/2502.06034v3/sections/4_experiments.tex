\input{figures/fig_states}

\section{Results}

\paragraph{Polygons}
 As an initial proof of concept, in Figure \ref{fig:polygons_vid} we show the hidden state evolution for the NWM model of Equation \ref{eqn:nwm}, with FFT readout, on a single example of the polygons dataset. We see that the model initializes the hidden state such that waves are propagated from the edges of the object in all directions. From naive inspection of the sequence, we can see that waves appear to propagate differently within the object, seemingly changing the spectral representation of each point on the interior of the hexagon. Figure \ref{fig:polygons_fft} (left) shows the magnitudes of a subset of Fourier coefficients for all neurons in response to a test image, while Figure \ref{fig:polygons_fft} (right) shows the frequency representations for each object class averaged over all pixels in the validation set which are labeled as that class. We see that there is a clear distinction between the shapes that the model appears to pick up on, which allows it to identify all polygons with $>99\%$ accuracy on a held out test set. We provide additional analysis of the results of the model on the polygons dataset in Figures \ref{fig:all_fft} \& \ref{fig:shape_combo} of the Appendix.

\vspace{-2mm}
\paragraph{Tetrominoes \& MNIST} As a concrete comparison of local recurrent models with different readouts and feed-forward models with different receptive field sizes, in Table \ref{tab:merged} we include the aggregated results of 300 total models trained on Tetrominoes and MNIST. We observe that CNNs with 2 and 4 layers perform poorly on both datasets, with performance improving as the receptive field (RF) increases, as expected. This improvement is most pronounced in 16-layer CNNs (with an effective RF size of 33) on MNIST and in 8-layer CNNs (with an effective RF size of 17) on Tetrominoes. However, mean performance declines with 32 layers on MNIST and with 16 and 32 layers on Tetrominoes, though the variance remains high. As deeper networks contain more parameters, they pose a more challenging optimization problem, leading to inconsistent convergence. Nevertheless, peak performance continues to improve as the number of layers increases, even in the 16- and 32-layer models, despite a higher number of failed training runs. For the minimum, maximum, and median performance across different seeds, refer to Tables \ref{tab:max_min} and \ref{tab:fg_max_min} in the supplement.

Among recurrent models, those with linear projections perform best, with the NWM outperforming baselines. Recurrent models that rely solely on the last hidden state for predictions achieve the weakest results. The NWM models exhibit the lowest variance, indicating greater training stability. Figure \ref{fig:states} visualizes the recurrent states and linear projections for a sample image. Interestingly, the LSTM learns to generate wave dynamics despite lacking an explicit inductive bias for doing so.

\looseness=-1
\vspace{-3mm}
\paragraph{Multi-MNIST}
Most impressively, in Table \ref{tab:multi-mnist}, we see that the NWM with 54K parameters performs better than U-Net's with 30K and 68K parameters, despite having only local connectivity and no explicit skip connections. In addition, our NWM performs only slightly worse than U-Net's with 122K and 190K parameters. Interestingly, the NWM has the lowest foreground loss of all models, possibly due to an increased confidence in predictions (e.g. predicting background) compared with other models. Once again, we see NWM models have much lower variance, suggesting training stability benefits over comparable U-Net models. These results suggest wave dynamics with linear readouts over time may be a promising avenue to explore as an alternative to U-Net style architectures for integrating spatial information in artificial neural networks.




\input{tables/tab1}
\input{tables/tab2}