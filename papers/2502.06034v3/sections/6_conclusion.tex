\section{Limitations \& Future Work}
While we believe the experiments above are convincing of the fact that traveling waves are an effective and efficient mechanism for integrating spatial information through the time dimensions, they are inherently limited in a number of ways. First, from the machine learning perspective, while the wave-based models may be able to outperform U-Net models with an equivalent number of parameters on the Multi-MNIST task presented here, the amount of computation time is significantly higher to run these models on our current hardware. This is due to the fact that the oscillatory wave dynamics must be accurately numerically integrated (with a small $\Delta t$), while U-Net type models are optimized for parallel GPU hardware. In future work, we intend to explore the potential of using oscillatory state space models \citep{rusch2025oscillatorystatespacemodels} to enable the parallel processing of the recurrent NWM dynamics over sequence length, which would significantly lessen this computational bottleneck. From the neuroscience perspective, our proposed wave-based models are highly abstract idealizations of a cortical sheet, thereby allowing for the tractable computation, but also obscuring how some of the parameters such as the natural frequencies or damping parameters could be mapped onto neurobiological components. Despite this limitation, this remains one of the few models which can be trained to leverage wave dynamics in a task-oriented manner; and therefore, in future work, we intend to leverage this uniquely new framework to compare the learned dynamics with neural recordings in a precise manner. Finally, although our work is inspired by the ‘hearing the shape of a drum’ problem, we have no guarantee that our trained models form image representations in precisely that manner. We do find the analogy valuable for guiding model development, and the success of time-based readouts supports this intuition. However, we caution readers against overinterpreting this analogy as a literal account of how the models operate. 

\section{Conclusion}

In the above, we have presented arguments both theoretical and empirical supporting the idea that traveling waves may serve to integrate spatial information through the time dimension in otherwise locally constrained architectures, achieving performance comparable with globally connected counterparts. Furthermore, we have demonstrated empirically that this wave-encoded information is most directly accessible through linear projections of the hidden state time-dynamics, contrary to how most recurrent alternatives to depth have previously been studied. We showed that even if models are not biased towards wave dynamics initially, such as the Conv-LSTM, they will still learn to propagate waves in order to transfer information effectively through space, thereby implicating waves and wave-based representations as an optimal solution to information transfer under such constraints. Finally, we demonstrated that wave-based integration of information may be a stable and parameter efficient rival to common U-Net architectures. Notably, these wave-based solutions—naturally spanning both spatial and frequency domains—could align more directly with EEG or MEG measurements in neuroscience, while on the machine learning side we speculate they could someday help alleviate the computational bottlenecks of global self-attention mechanisms. We hope that this work draws increased attention to the idea that wave-based representations may carry global task-relevant information in both biological and artificial systems, thereby encouraging their further study.