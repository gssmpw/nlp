\documentclass[10pt,letterpaper]{article}

\usepackage{ccn}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{lineno}
\usepackage{url}
\usepackage{booktabs}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{multirow} 
\usepackage[title]{appendix}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}

\usepackage[T1]{fontenc}

\input{math_commands.tex}


\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\fixme}[1]{\textcolor{red}{#1}}


\title{Traveling Waves Integrate Spatial Information Through Time}
 
\author{
    {\large \bf Mozes Jacobs\textsuperscript{1} \quad 
    Roberto C. Budzinski\textsuperscript{2} \quad 
    Lyle Muller\textsuperscript{2} \quad 
    Demba Ba\textsuperscript{1} \quad 
    T. Anderson Keller\textsuperscript{1}} \\
    \textsuperscript{1}The Kempner Institute for the Study of Natural and Artificial Intelligence, Harvard University \\
    \textsuperscript{2}Western University, Department of Mathematics, London, Ontario, Canada \\
}


\begin{document}

\maketitle

\section{Abstract}
{
\bf
Traveling waves of neural activity are widely observed in the brain, but their precise computational function remains unclear. One prominent hypothesis is that they enable the transfer and integration of spatial information across neural populations. However, few computational models have explored how traveling waves might be harnessed to perform such integrative processing. Drawing inspiration from the famous “\emph{Can one hear the shape of a drum?}” problem -- which highlights how normal modes of wave dynamics encode geometric information -- we investigate whether similar principles can be leveraged in artificial neural networks. Specifically, we introduce convolutional recurrent neural networks that learn to produce traveling waves in their hidden states in response to visual stimuli, enabling spatial integration. By then treating these wave-like activation sequences as visual representations themselves, we obtain a powerful representational space that outperforms local feed-forward networks on tasks requiring global spatial context. In particular, we observe that traveling waves effectively expand the receptive field of locally connected neurons, supporting long-range encoding and communication of information. We demonstrate that models equipped with this mechanism solve visual semantic segmentation tasks demanding global integration, significantly outperforming local feed-forward models and rivaling non-local U-Net models with fewer parameters. As a first step toward traveling-wave-based communication and visual representation in artificial networks, our findings suggest wave-dynamics may provide efficiency and training stability benefits, while simultaneously offering a new framework for connecting models to biological recordings of neural activity.
}
\begin{quote}
\small
\textbf{Keywords:} 
Traveling Waves; Oscillation; Information Integration
\end{quote}

\input{sections/1_introduction}
\input{sections/2_background}
\input{sections/3_method}
\input{sections/4_experiments}
\input{sections/5_related_work}
\input{sections/6_conclusion}


\newpage

\bibliographystyle{ccn_style}


\bibliography{ccn_style}
\appendix
\onecolumn
\begin{appendices}
\section{Supplementary Material}
\input{sections/appendix/7_experimental_details}
\end{appendices}

\end{document}
