\begin{table*}[h!]
    \centering
    \begin{tabular}{llllrrr}
    \toprule
        & Model & Arch. & Parameters & Acc & IoU & Loss \\
    \midrule
        & U-Net & 2     & 30745      & 0.98 ± 0.01 & 0.66 ± 0.27 & 0.06 ± 0.03 \\
        &       & 3     & 68834      & 1.00 ± 0.00 & 0.91 ± 0.08 & 0.03 ± 0.01 \\
        &       & 4     & 122071     & 1.00 ± 0.00 & 0.97 ± 0.01 & 0.01 ± 0.00 \\
        &       & 5     & 190456     & 1.00 ± 0.00 & 0.98 ± 0.00 & 0.01 ± 0.00 \\
    \midrule
        & NWM   & Linear & 54855      & 1.00 ± 0.00 & 0.94 ± 0.01 & 0.01 ± 0.00 \\
    \bottomrule
    \end{tabular}
    % }
    \caption{Supervised segmentation performance of UNet and NWM with Linear Time Projection on Multi-MNIST. Arch for the U-Net refers to the number of feature maps output by the first layer. The number of feature maps doubles between each layer (e.g. 3 means 3 $\rightarrow$ 6 $\rightarrow$ 12 $\rightarrow$ 24 $\rightarrow$ 48 by the final layer). For the NWM, Arch (architecture) refers to the type of recurrent readout used.
    Each model is trained with 12 random seeds, and the results are displayed as $mean \pm standard \text{ }deviation$ over the 12 seeds.}
    \vspace{-3mm}
    \label{tab:multi-mnist_appendix}
\end{table*}