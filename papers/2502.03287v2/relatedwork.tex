\section{Related work} \label{sec:related_work}

Earlier work on SNN mapping assumed fully distributed multicore architectures with no shared memory, where the focus was on partitioning and mapping neurons on a homogeneous multicore architecture, which is a well-known NP-hard problem \cite{huynh2022implementing}. Except for mapping tools that target specific hardware platforms \cite{10.1145/3192366.3192371}, the optimization goal is to maximize resource utilization while minimizing inter-core communication. This problem has been solved with many different heuristics, such as particle swarm optimization \cite{8342201, 10.1145/3386263.3406900}, graph partitioning \cite{titirsha2020thermal, 9996702}, and integer linear programming \cite{das2022realtime}. Some also consider hardware characteristics such as reliability and endurance \cite{titirsha2021endurance}. All these methods do not consider off-chip memories, so they can not handle situations when an SNN does not fit on-chip. They also do not consider shared on-chip memory resources or loop nest optimizations.

NeuProMa \cite{neuproma} is an SNN mapping framework that considers off-chip data movement, where an SNN can not fit onto on-chip and resources have to be time-multiplexed. Their framework maps SNNs in three steps: split, partition, and map. First, the SNN is divided into several subnetworks that fit on-chip resources. SNNs are split according to one of three splitting strategies: channel split, pixel split, or link split. The link split, which creates depth-first subnets similar to layer fusion, performed overall better than the other two on different benchmarks. Then, each subnetwork is mapped using heuristics to reduce inter-core spike communication. This work considers limited splitting strategies and does not consider shared on-chip memories and loop nest optimizations.

SMART is a design flow for mapping SNNs in resource-constrained heterogeneous neuromorphic systems coupled with a CPU \cite{das2022realtime}. This work breaks down the mapping problem into four smaller sub-problems; throughput lower bound, operation mapping, activation/weight mapping, and parallel scheduling. The lower throughput bound is estimated using a self-timed execution schedule. Operation and activation/weight mapping are done using integer linear programming. For operation mapping, latency and memory requirements are combined in a cost function to determine whether operations (i.e. layers) are to be mapped on neuromorphic cores or a CPU. For activation/weight mapping, scratchpad memories are split into a pinned space and an immediate space. Activation/weights mapped to pinned space are never ejected to main memory, allowing better data reuse, while those mapped to immediate space can be ejected to free up space whenever necessary, with the objective of minimizing data movement between main memory and distributed memories. Finally, a parallel schedule is formed, with task- and batch-level parallelism possible. While this work optimizes data movement, it does not consider intra-layer nor inter-layer optimizations.
%, nor loop nest optimization. 


%AHM tools have gained recent popularity, where tools such as Zigzag \cite{zigzag} and Timeloop \cite{9923807} explore tiling, re-ordering, and mapping of linear layers (e.g. convolution) on a hardware architecture model consisting of multi-level memories and parallel compute arrays, using a polyhedral-based analytical cost model. These models rely on performance indicators such as data reuse and data access count, along with an estimated hardware cost model. Such tools were limited to a single layer. However, Stream \cite{stream} extends Zigzag to model multiple layers mapped on multiple (heterogeneous) accelerators, using a graph-based approach that leverages Zigzag. In Stream, the workload graph is broken into a finer computation node graph, resulting in a depth-first schedule. Each unique computation node is mapped to each unique core using Zigzag. Then, a genetic algorithm is used to allocate computation nodes to cores. Such tools provide fast analytical search of a large design space, where Pareto-optimal mappings can provide orders of magnitude better performance compared to other possible solutions.



In \cite{10.1145/3531437.3539704}, the authors take a similar approach to our work, where they use Timeloop \cite{9923807} to explore efficient data flows for SNN workloads on an Eyeriss-like hardware architecture\cite{7738524}. They explore a set of mapping rules and dataflows. However, they do not explore inter-layer optimizations. 

To our knowledge, our work is the first to explore SNN mapping in neuromorphic architectures, with intra-layer and inter-layer mapping optimization across spatial (layer fusion) and temporal (time batching) dimensions to improve hardware utilization and minimize data movement. We highlight in this work how inter-layer (on top of intra-layer) optimizations can significantly reduce off-chip data movement under stringent on-chip memory capacity, by improving reuse of neuron states over time and reducing the size of intermediate features/spikes.