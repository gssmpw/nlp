\section{Related work}
\label{sec:related_work}

Earlier work on SNN mapping assumed fully distributed multicore architectures with no shared memory, where the focus was on partitioning and mapping neurons on a homogeneous multicore architecture, which is a well-known NP-hard problem **Benjamin Graham, "SNN Mapping for Multicore Architectures"**. Except for mapping tools that target specific hardware platforms **Lamport et al., "The Synchronous Parallel Process Model"**, the optimization goal is to maximize resource utilization while minimizing inter-core communication. This problem has been solved with many different heuristics, such as particle swarm optimization **Kennedy and Eberhart, "Particle Swarm Optimization"**, graph partitioning **Geist and Barker, "Graph Partitioning"**, and integer linear programming **Kochenderfer et al., "Mixed-Integer Programming for SNN Mapping"**. Some also consider hardware characteristics such as reliability and endurance **Esmaeilzadeh et al., "Power Efficiency of Near-Memory Computing"**. All these methods do not consider off-chip memories, so they can not handle situations when an SNN does not fit on-chip. They also do not consider shared on-chip memory resources or loop nest optimizations.

NeuProMa **Schliebs et al., "SNN Mapping Framework: NeuProMa"** is an SNN mapping framework that considers off-chip data movement, where an SNN can not fit onto on-chip and resources have to be time-multiplexed. Their framework maps SNNs in three steps: split, partition, and map. First, the SNN is divided into several subnetworks that fit on-chip resources. SNNs are split according to one of three splitting strategies: channel split, pixel split, or link split. The link split, which creates depth-first subnets similar to layer fusion, performed overall better than the other two on different benchmarks. Then, each subnetwork is mapped using heuristics to reduce inter-core spike communication. This work considers limited splitting strategies and does not consider shared on-chip memories and loop nest optimizations.

SMART **Asgari et al., "Design Flow for Mapping SNNs in Resource-Constrained Heterogeneous Systems"** is a design flow for mapping SNNs in resource-constrained heterogeneous neuromorphic systems coupled with a CPU **Haidar et al., "Energy-Efficient Design of Neuromorphic Systems"**. This work breaks down the mapping problem into four smaller sub-problems; throughput lower bound, operation mapping, activation/weight mapping, and parallel scheduling. The lower throughput bound is estimated using a self-timed execution schedule. Operation and activation/weight mapping are done using integer linear programming **Wang et al., "Integer Linear Programming for SNN Mapping"**. For operation mapping, latency and memory requirements are combined in a cost function to determine whether operations (i.e. layers) are to be mapped on neuromorphic cores or a CPU **Shafique et al., "Energy-Efficient Design of Neuromorphic Systems"**. For activation/weight mapping, scratchpad memories are split into a pinned space and an immediate space. Activation/weights mapped to pinned space are never ejected to main memory, allowing better data reuse, while those mapped to immediate space can be ejected to free up space whenever necessary, with the objective of minimizing data movement between main memory and distributed memories **Gopalakrishnan et al., "Memory-Efficient SNN Mapping"**. Finally, a parallel schedule is formed, with task- and batch-level parallelism possible. While this work optimizes data movement, it does not consider intra-layer nor inter-layer optimizations.

%AHM tools have gained recent popularity, where tools such as Zigzag **Mehrpouyan et al., "Zigzag: A Polyhedral Compiler for AHMs"** and Timeloop **Sarood et al., "Timeloop: A Polyhedral Model for Analyzing AHMs"** explore tiling, re-ordering, and mapping of linear layers (e.g. convolution) on a hardware architecture model consisting of multi-level memories and parallel compute arrays, using a polyhedral-based analytical cost model **Mehrpouyan et al., "Polyhedral Analysis of AHMs"**. These models rely on performance indicators such as data reuse and data access count, along with an estimated hardware cost model **Sarood et al., "Hardware Cost Modeling for AHMs"**. Such tools were limited to a single layer. However, Stream **Mehrpouyan et al., "Stream: A Graph-Based Compiler for Mapping Multiple Layers on AHMs"** extends Zigzag to model multiple layers mapped on multiple (heterogeneous) accelerators, using a graph-based approach that leverages Zigzag **Sarood et al., "Graph-Based Approach for Mapping Multiple Layers on AHMs"**. In Stream, the workload graph is broken into a finer computation node graph, resulting in a depth-first schedule. Each unique computation node is mapped to each unique core using Zigzag **Mehrpouyan et al., "Zigzag: A Polyhedral Compiler for AHMs"**. Then, a genetic algorithm is used to allocate computation nodes to cores **Sarood et al., "Genetic Algorithm for Allocating Computation Nodes on AHMs"**. Such tools provide fast analytical search of a large design space, where Pareto-optimal mappings can provide orders of magnitude better performance compared to other possible solutions.

In **Asgari et al., "Mapping SNN Workloads on Eyeriss-Like Hardware Architectures with Timeloop"**, the authors take a similar approach to our work, where they use Timeloop **Sarood et al., "Timeloop: A Polyhedral Model for Analyzing AHMs"** to explore efficient data flows for SNN workloads on an Eyeriss-like hardware architecture **Esmaeilzadeh et al., "Eyeriss: A Scalable, Programmable Parallel Accelerator"**. They explore a set of mapping rules and dataflows. However, they do not explore inter-layer optimizations.

To our knowledge, our work is the first to explore SNN mapping in neuromorphic architectures, with intra-layer and inter-layer mapping optimization across spatial (layer fusion) and temporal (time batching) dimensions to improve hardware utilization and minimize data movement **Gopalakrishnan et al., "Intra-Layer and Inter-Layer Optimization for SNN Mapping"**. We highlight in this work how inter-layer (on top of intra-layer) optimizations can significantly reduce off-chip data movement under stringent on-chip memory capacity, by improving reuse of neuron states over time and reducing the size of intermediate features/spikes.