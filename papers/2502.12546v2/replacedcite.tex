\section{Related Work}
\subsection{Point-set Registration} 

Point-set registration estimates a transformation matrix to align two point clouds. Given correspondences between the points, Procrustes analysis____ finds the similarity transform matrix while orthogonal Procrustes analysis____ finds an orthogonal matrix. Iterative Closest Point (ICP)____ finds a rigid transformation and correspondences simultaneously.


Many variants of ICP____ have been proposed to address limitations, such as initialization, input noise, and outliers.
Probabilistic approaches____ efficiently manage uncertainties in establishing correspondences. Semantic ICP____ integrates semantic cues to enhance the reliability of the registration against noise and outliers. Several investigations____ focus on the rotation search algorithm rather than the full rigid transformation for minimal inlier data. In particular, ARCS____ achieves robust and efficient performance in simultaneous rotation and correspondence search on large-scale datasets.



Compared with these methods, our approach translates camera calibration into 3D \textit{oriented} point sets alignment in a probabilistic framework.
%
This allows calibrating cameras with multiple instances (\eg persons) lookalike each other in their appearances.


\subsection{Spatiotemporal Multi-camera Calibration}

\subsubsection{Multi-camera Calibration} 

A common approach for multi-camera calibration utilizes reference objects such as checkerboard pattern____ and ArUco markers____ to facilitate establishing correspondences across multiple images. These methods, however, can be cumbersome and require careful operations. Leveraging dynamic foreground objects in our daily lives, such as freely moving people in scenes, has been proposed as a potential alternative to such manual calibration____. Using human heights in motion, represented as vertical line segments perpendicular to the ground plane, has demonstrated the possibility for calibration____. This approach facilitated the estimation of vanishing points____ and provided closed-form solutions for the line segments____. Additionally, human keypoints obtained from 2D human pose estimation have served as the calibration pattern~\etal____. Moreover, 3D human poses, derived from elevating 2D human poses, have been employed as reference targets for calibration____. Lee~\etal____ introduced a linear calibration algorithm based on factorization using 3D oriented points extracted from 3D human poses.


The methods discussed so far assume that the correspondences between views are determined beforehand, which lacks the versatility required for dynamic, multi-person scenes. To overcome this challenge, various priors, such as geometry, appearance, and motion, have been explored____. Huang~\etal____ jointly recovers multiple human motions and extrinsic camera parameters using physics-based constraints to denoise 2D poses of pre-established correspondences and ensure temporal coherence with a human motion prior. Yan~\etal____ employed a re-identification (re-ID) network to associate bounding boxes across different camera views, then converted these into point correspondences to calculate relative camera poses across camera pairs. Xu~\etal____ treated the cross-view matching problem as a clustering problem using 2D appearance features within uncalibrated camera networks. Li~\etal____ uses 3D Re-ID appearance features from RGBD images to establish correspondences, which facilitates depth-based camera pose and 3D multi-human pose estimation. 

\subsubsection{Multi-camera Synchronization}

The most straightforward way for aligning timing differences between image sequences is to use wired connections with hardware triggers in a camera network____. Alternatively, audio triggering, which employs microphones to detect sound signals or audio cues, offers another mean of synchronization, particularly useful in setups where a wired connection may not be feasible____. However, this often requires laborious manual intervention conducted by experts in controlled environments. In contrast, video-based synchronization analyzes the trajectories of moving points observed across multi-view videos and estimates the time shift between image sequences without the need for manual intervention. This often minimizes an error function by imposing epipolar constraints on point correspondences established in advance____. Additionally, the movement of humans and their structural characteristics, such as rhythm and articulation, have been demonstrated flexibility as reference targets for temporal alignment in multi-view synchronization____. Recently, deep neural networks have been shown significant potential in aligning unsynchronized video clips captured from different camera views____. 


\subsubsection{Spatiotemporal calibration}

 

Simultaneous estimation of spatial and temporal transformations from multi-view videos has been achieved using multimodal data: audio and visual features____. This method estimates camera poses using Structure-from-Motion (SfM) based on static feature points in the background. It also aligns temporal differences between image sequences by analyzing audio signals. Vision-based spatiotemporal alignment commonly relies on trajectories of dynamic objects to associate multiple views and to minimize geometric projection errors within joint optimization schemes____. Additionally, motion priors on specific targets can be applied as temporal constraints of the optimization.  In particular, the physics-based motion priors of dynamic human movements and static background facilitate spatiotemporal calibration____.

These methods address the challenges of multi-person associations, camera calibration, and temporal alignment separately. In this paper, we show that these three coupled sub-problems can be solved as a single registration problem by utilizing sets of 3D joint trajectories obtained from dynamic human movements and converting them to a unit sphere rather than the appearance-based association.