\section{Related Work}
\textbf{Knowledge Graph Question Answering.}
Conventional KBQA solutions can be categorized into three types: Semantic Parsing-based (SP-based) methods, Information Retrieval-based (IR-based) methods, and Embedding-based methods. SP-based methods parse the question into a structural query (e.g., SPARQL) which can be executed by a query engine to get answers~\cite{lan2022complex}. ArcaneQA~\cite{gu2022arcaneqa} dynamically generates the query based on results from previous steps. RnG-KBQA~\cite{ye2021rng} first enumerate all possible queries and then rank them to get the final output. These methods heavily rely on the quality of generated queries. If the query is not executable, no answers will be generated. DECAF~\cite{donahue2014decaf} combines semantic parsing and LLMs reasoning to jointly generate answers, which also reach salient performance on KGQA tasks. However, these methods need to annotate expensive logic forms as supervision or are limited to narrow domains with a few logical predicates~\cite{lan2022complex}. KG embedding, which aims to encode entities and relations into a continuous vector space~\cite{bordes2013translating,long2022neural, sun2019rotate, long2024fact}, and its effectiveness has been validated in knowledge graph question answering (KGQA) tasks. Embedding-based methods model the entities and relations in embedding space and design special model architectures to reason answers. KV-Mem~\cite{miller2016key} adopts a Key-Value memory network to store triples for reasoning. EmbedKGQA~\cite{saxena2020improving} and NSM~\cite{he2021improving} utilize the sequential model to mimic the multi-hop reasoning process. IR-based methods primarily retrieve relevant factual triples or text from Knowledge Graphs (KGs) based on natural language questions and then design special model architectures to reason answers. Early works adopt the page rank or random walk algorithm to retrieve subgraphs from KGs for reasoning~\cite{sun2018open}. Recently, to integrate LLMs for KGQA, retrieval augmented methods~\cite{jiang2022unikgqa, luo2023reasoning} aim to leverage the LLMs to reason on the retrieved facts from the KGs to improve the reasoning performance. For example, UniKGQA~\cite{jiang2022unikgqa} unifies the graph retrieval and reasoning process into a single model with LLMs. ToG~\cite{sun2023think} uses LLM as an agent to iteratively perform beam search on knowledge graphs to find answers. RoG~\cite{luo2023reasoning} uses LLM to generate relation plans, which are used to retrieve the relative facts from raw KGs for LLMs to conduct faithful reasoning. However, these methods treat the different retrieval information equally to reason the answer, ignoring the differences between retrieved information. EPERM proposes to retrieve and score the evidence paths, which consider the different importance of the structural information for better reasoning the answers. 

\noindent \textbf{Large Language Models.} 
With the launch of ChatGPT and GPT-4~\cite{openai2023gpt}, displaying the prowess of decoder-only large language models (LLMs) with a vast number of parameters that exhibit emergent phenomena, many traditional NLP tasks are becoming simplified~\cite{hadi2023survey}. Subsequently, open-source models like Llama-2-7B~\cite{touvron2023llama}, ChatGLM2-6B~\cite{zeng2022glm} and Qwen-Chat~\cite{bai2023qwen} emerged and can be supervised fine-tuned (SFT) using instruction-tuning technologies~\cite{zhang2023fc} such as LoRA~\cite{hu2021lora}, QLoRA~\cite{dettmers2024qlora}, P-Tuning v2~\cite{liu2021p}, and Freeze~\cite{geva2020transformer}, enhancing the capabilities of LLMs for specific tasks. Additionally, Chain-of-Thought (CoT)~\cite{wei2022chain} has been shown to be effective in enhancing LLM reasoning. It creates a series of prompt instances according to reasoning logic under a few-shot learning paradigm in order to improve LLMâ€™s performance on complex tasks. In this paper, EPERM employs the instruction-tuning technique to fine-tune open-source LLMs, which consists of the subgraph retriever, evidence path finder, and answer predictor. All the modules in EPERM are joint fine-tuning to learn the parameters.