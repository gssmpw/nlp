@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{bordes2013translating,
  title={Translating embeddings for modeling multi-relational data},
  author={Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{dettmers2024qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{donahue2014decaf,
  title={Decaf: A deep convolutional activation feature for generic visual recognition},
  author={Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={647--655},
  year={2014},
  organization={PMLR}
}

@article{geva2020transformer,
  title={Transformer feed-forward layers are key-value memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  journal={arXiv preprint arXiv:2012.14913},
  year={2020}
}

@article{gu2022arcaneqa,
  title={ArcaneQA: Dynamic program induction and contextualized encoding for knowledge base question answering},
  author={Gu, Yu and Su, Yu},
  journal={arXiv preprint arXiv:2204.08109},
  year={2022}
}

@article{hadi2023survey,
  title={A survey on large language models: Applications, challenges, limitations, and practical usage},
  author={Hadi, Muhammad Usman and Qureshi, Rizwan and Shah, Abbas and Irfan, Muhammad and Zafar, Anas and Shaikh, Muhammad Bilal and Akhtar, Naveed and Wu, Jia and Mirjalili, Seyedali and others},
  journal={Authorea Preprints},
  year={2023},
  publisher={Authorea}
}

@inproceedings{he2021improving,
  title={Improving multi-hop knowledge base question answering by learning intermediate supervision signals},
  author={He, Gaole and Lan, Yunshi and Jiang, Jing and Zhao, Wayne Xin and Wen, Ji-Rong},
  booktitle={Proceedings of the 14th ACM international conference on web search and data mining},
  pages={553--561},
  year={2021}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{jiang2022unikgqa,
  title={Unikgqa: Unified retrieval and reasoning for solving multi-hop question answering over knowledge graph},
  author={Jiang, Jinhao and Zhou, Kun and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2212.00959},
  year={2022}
}

@article{lan2022complex,
  title={Complex knowledge base question answering: A survey},
  author={Lan, Yunshi and He, Gaole and Jiang, Jinhao and Jiang, Jing and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={35},
  number={11},
  pages={11196--11215},
  year={2022},
  publisher={IEEE}
}

@article{liu2021p,
  title={P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2110.07602},
  year={2021}
}

@inproceedings{long2022neural,
  title={Neural-based mixture probabilistic query embedding for answering fol queries on knowledge graphs},
  author={Long, Xiao and Zhuang, Liansheng and Aodi, Li and Wang, Shafei and Li, Houqiang},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={3001--3013},
  year={2022}
}

@inproceedings{long2024fact,
  title={Fact Embedding through Diffusion Model for Knowledge Graph Completion},
  author={Long, Xiao and Zhuang, Liansheng and Li, Aodi and Li, Houqiang and Wang, Shafei},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={2020--2029},
  year={2024}
}

@article{luo2023reasoning,
  title={Reasoning on graphs: Faithful and interpretable large language model reasoning},
  author={Luo, Linhao and Li, Yuan-Fang and Haffari, Gholamreza and Pan, Shirui},
  journal={arXiv preprint arXiv:2310.01061},
  year={2023}
}

@article{miller2016key,
  title={Key-value memory networks for directly reading documents},
  author={Miller, Alexander and Fisch, Adam and Dodge, Jesse and Karimi, Amir-Hossein and Bordes, Antoine and Weston, Jason},
  journal={arXiv preprint arXiv:1606.03126},
  year={2016}
}

@article{openai2023gpt,
  title={Gpt-4 technical report. arxiv 2303.08774},
  author={OpenAI, R},
  journal={View in Article},
  volume={2},
  number={5},
  year={2023}
}

@inproceedings{saxena2020improving,
  title={Improving multi-hop question answering over knowledge graphs using knowledge base embeddings},
  author={Saxena, Apoorv and Tripathi, Aditay and Talukdar, Partha},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={4498--4507},
  year={2020}
}

@article{sun2018open,
  title={Open domain question answering using early fusion of knowledge bases and text},
  author={Sun, Haitian and Dhingra, Bhuwan and Zaheer, Manzil and Mazaitis, Kathryn and Salakhutdinov, Ruslan and Cohen, William W},
  journal={arXiv preprint arXiv:1809.00782},
  year={2018}
}

@article{sun2019rotate,
  title={Rotate: Knowledge graph embedding by relational rotation in complex space},
  author={Sun, Zhiqing and Deng, Zhi-Hong and Nie, Jian-Yun and Tang, Jian},
  journal={arXiv preprint arXiv:1902.10197},
  year={2019}
}

@article{sun2023think,
  title={Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph},
  author={Sun, Jiashuo and Xu, Chengjin and Tang, Lumingyuan and Wang, Saizhuo and Lin, Chen and Gong, Yeyun and Shum, Heung-Yeung and Guo, Jian},
  journal={arXiv preprint arXiv:2307.07697},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{ye2021rng,
  title={Rng-kbqa: Generation augmented iterative ranking for knowledge base question answering},
  author={Ye, Xi and Yavuz, Semih and Hashimoto, Kazuma and Zhou, Yingbo and Xiong, Caiming},
  journal={arXiv preprint arXiv:2109.08678},
  year={2021}
}

@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}

@article{zhang2023fc,
  title={FC-KBQA: A fine-to-coarse composition framework for knowledge base question answering},
  author={Zhang, Lingxi and Zhang, Jing and Wang, Yanling and Cao, Shulin and Huang, Xinmei and Li, Cuiping and Chen, Hong and Li, Juanzi},
  journal={arXiv preprint arXiv:2306.14722},
  year={2023}
}

