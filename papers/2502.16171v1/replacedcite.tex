\section{Related Work}
\textbf{Knowledge Graph Question Answering.}
Conventional KBQA solutions can be categorized into three types: Semantic Parsing-based (SP-based) methods, Information Retrieval-based (IR-based) methods, and Embedding-based methods. SP-based methods parse the question into a structural query (e.g., SPARQL) which can be executed by a query engine to get answers____. ArcaneQA____ dynamically generates the query based on results from previous steps. RnG-KBQA____ first enumerate all possible queries and then rank them to get the final output. These methods heavily rely on the quality of generated queries. If the query is not executable, no answers will be generated. DECAF____ combines semantic parsing and LLMs reasoning to jointly generate answers, which also reach salient performance on KGQA tasks. However, these methods need to annotate expensive logic forms as supervision or are limited to narrow domains with a few logical predicates____. KG embedding, which aims to encode entities and relations into a continuous vector space____, and its effectiveness has been validated in knowledge graph question answering (KGQA) tasks. Embedding-based methods model the entities and relations in embedding space and design special model architectures to reason answers. KV-Mem____ adopts a Key-Value memory network to store triples for reasoning. EmbedKGQA____ and NSM____ utilize the sequential model to mimic the multi-hop reasoning process. IR-based methods primarily retrieve relevant factual triples or text from Knowledge Graphs (KGs) based on natural language questions and then design special model architectures to reason answers. Early works adopt the page rank or random walk algorithm to retrieve subgraphs from KGs for reasoning____. Recently, to integrate LLMs for KGQA, retrieval augmented methods____ aim to leverage the LLMs to reason on the retrieved facts from the KGs to improve the reasoning performance. For example, UniKGQA____ unifies the graph retrieval and reasoning process into a single model with LLMs. ToG____ uses LLM as an agent to iteratively perform beam search on knowledge graphs to find answers. RoG____ uses LLM to generate relation plans, which are used to retrieve the relative facts from raw KGs for LLMs to conduct faithful reasoning. However, these methods treat the different retrieval information equally to reason the answer, ignoring the differences between retrieved information. EPERM proposes to retrieve and score the evidence paths, which consider the different importance of the structural information for better reasoning the answers. 

\noindent \textbf{Large Language Models.} 
With the launch of ChatGPT and GPT-4____, displaying the prowess of decoder-only large language models (LLMs) with a vast number of parameters that exhibit emergent phenomena, many traditional NLP tasks are becoming simplified____. Subsequently, open-source models like Llama-2-7B____, ChatGLM2-6B____ and Qwen-Chat____ emerged and can be supervised fine-tuned (SFT) using instruction-tuning technologies____ such as LoRA____, QLoRA____, P-Tuning v2____, and Freeze____, enhancing the capabilities of LLMs for specific tasks. Additionally, Chain-of-Thought (CoT)____ has been shown to be effective in enhancing LLM reasoning. It creates a series of prompt instances according to reasoning logic under a few-shot learning paradigm in order to improve LLMâ€™s performance on complex tasks. In this paper, EPERM employs the instruction-tuning technique to fine-tune open-source LLMs, which consists of the subgraph retriever, evidence path finder, and answer predictor. All the modules in EPERM are joint fine-tuning to learn the parameters.