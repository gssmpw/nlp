




\subsection{Fine-Grained Structured Sparsity}
\label{subsec:Fine_grained_structured_sparsity}
In this work, we leverage the regular patterns of fine-grained structured sparsity to architect SST slices with low area overhead. 
Fig. \ref{fig:random_sparsity} depicts a 50\% unstructured sparse matrix, where the non-zero data are distributed \textit{randomly}, \emph{i.e.,} there is no specific pattern of their locations.
In contrast, in Fig. \ref{fig:structured_sparsity}, the 2:4 structured sparsity pattern is illustrated, which has the same sparsity level (50\%), but in every group of four \textit{consecutive} elements
% row-wise, 
there are two non-zero values. 
Notice that the location of the two non-zero values can vary significantly within the four-element group, offering \textit{fine-grained} sparsity flexibility.  
These types of constraints enable low area hardware enhancements, allowing for efficient  exploitation of sparsity.


\begin{figure}[t]
\vspace{-0.70cm}
\centering
\subfloat[]
{\includegraphics[width=0.31\linewidth]{03_Architecture_Overview/unstructured_50_percent_sparsity.pdf}
\label{fig:random_sparsity}}
\subfloat[]{\includegraphics[width=0.685\linewidth]{03_Architecture_Overview/structured_2_4_sparsity.pdf}
\label{fig:structured_sparsity}} 

\vspace{-0.35cm}

\caption{50\% unstructured sparse matrix (a) and 2:4 (50\%) structured sparse matrix along with compressed format (b).} 
\label{fig:sparsity_struct_unstruct}
\vspace{-0.50cm}
\end{figure}


A 2:4 sparse matrix can be efficiently stored in  compressed format by saving only the non-zero values.
The location of each non-zero data is encoded using 2-bit indices, as shown in Fig. \ref{fig:structured_sparsity}.
Similar to 2:4, for 1:4 (75\%) sparsity one every four consecutive elements is non-zero, while for 1:3 (66.7\%) sparsity there is one non-zero every three consecutive elements.  
For all aforementioned patterns, 2-bit indices are required to encode the location of each non-zero element.
This is a very efficient compressed format, as we show in Sec. \ref{subsec:AIE_ML_comparison}, where comparison among other formats is performed.










\subsection{Systolic Sparse Tensor Slices Architecture}
\label{subsec:Sparse_Tensor_slices_architecture}

In this section, we present an
% high-level 
overview of the proposed SST slices. 
The core compute unit of the SSTs is a 4$\times$4 systolic array (SA) \cite{Kung_SA_1982}, as depicted in Fig. \ref{fig:ST_architecture}.
A 2D SA consists of homogeneous processing elements (PEs), where each PE performs a multiply--accumulate (MAC) operation and forwards the input operands to the neighboring PEs. 
This architecture allows maximization of data reuse
in GEMM, 
while also delivering high performance due to its regular and highly scalable design.
Hence, SAs have become a prime architecture in many DNN accelerators \cite{TPUV2_v3_2021, TPUv42021, S2TA_HPCA_2022, Vegeta_HPCA_2023, SA_CNN_FPGA_2017, SA_attention_FPGA_TECS_2023, Scale_sim_2020}.
In this work, we show that incorporating SST slices in FPGAs leads to high performance and scalable dense/sparse GEMM accelerators. 




\begin{figure}[tbp]
\vspace{-0.50cm}
\centering
\includegraphics[width=0.89\linewidth]{03_Architecture_Overview/SST_architecture.pdf}

\vspace{-0.50cm}

\caption{Systolic Sparse Tensor slice architecture.}
\label{fig:ST_architecture}

\vspace{-0.60cm}

\end{figure}


\subsubsection{SST Operation} 
We enhance the systolic PEs with sparse features by introducing sparse processing elements (SPEs), while maintaining the properties of the SAs discussed above. 
Our SSTs utilize an output stationary SA, consisting of 16 SPEs.
The accumulations remain stationary in the SPEs, while input operands are propagated to their neighbors every clock cycle.
The $a\_data$ of an input matrix $A$ are propagated and reused across SPEs horizontally, while the $b\_data$ of an input matrix $B$ are propagated and reused vertically (Fig. \ref{fig:ST_architecture}).
The matrix $A$ can be either sparse or dense (typically to map \textit{weights}), while $B$ is dense (typically to map input \textit{activations}).
The architecture of the SPEs is delineated in Sec. \ref{subsec:Sparse_Processing_Element}.


Besides the 4$\times$4 SPE grid, we also implement pipeline registers to delay the input operands for systolic data setup \cite{TPUv1_2017} (arranged in triangular manner in Fig. \ref{fig:ST_architecture}).
Systolic setup is needed at the interface for loading input matrices (typically from on-chip memory), when chaining multiple SSTs to construct larger SA grids (Sec. \ref{subsec:Matrix_multiplication_mapping}).
Multiplexers are used to select either the systolic setup
% registers
or directly the input data, and are configured \textit{statically} (during bitstream loading). 




\begin{figure*}[tbp]
\vspace{-0.40cm}
\centering
\includegraphics[width=1.00\textwidth]{03_Architecture_Overview/SPE_all_sparse_modes.pdf}

\vspace{-0.45cm}

\caption{Sparsity modes in Systolic Sparse Elements of the SST slices (multiplexing logic omitted for clarity).}
\label{fig:SPE_sparse_modes}
\vspace{-0.35cm}
\end{figure*}


The SSTs support both int8 and bfloat16 precisions, while accumulations are realized in 32-bit integer (int32) and IEEE 32-bit floating-point (fp32), respectively, similar to Nvidia GPUs \cite{Nvidia_accelerate_sparse_2021} and Google TPUs \cite{TPUV2_v3_2021}.
When the SA operation is completed, the output matrix $C$ is extracted via the $c\_data$ output ports.
We note that SPEs finish their operation in a \textit{diagonal} fashion cycle after cycle.
In the first cycle, $SPE00$ finishes, in the second cycle both $SPE01$ and $SPE10$ finish, etc. (Fig. \ref{fig:ST_architecture}). 
However, to maintain \textit{regularity}, thus simplifying the downstream logic (typically in CLBs), we extract the output values in a column-wise manner (four values per cycle).
To achieve that, we introduce a six-element buffer (consisting of registers), to store the data before getting extracted.
% column-wise.
This is particularly important in sustaining 100\% SPE utilization (16 MACs per cycle) at the steady-state (matrices processed one after the other).

Since SPEs complete their operation diagonally, the six upper-triangular SPE outputs, shown in Fig. \ref{fig:ST_architecture}, need to be stored in the buffer.
Suppose a cycle $T$ where the outputs of the biggest diagonal, \emph{i.e.,} $SPEs$ $\{03, 12, 21, 30\}$ are generated.
In cycle $T$, the values of the first column, \emph{i.e.,} $SPEs$ $\{00, 10, 20, 30\}$ can be extracted, where $SPEs$ $\{00, 10, 20\}$ are loaded from the buffer, while only $SPE30$ is directly extracted.
In cycle $T + 1$, the values of $SPEs$ $\{03, 12, 21\}$ replace the position of $SPEs$ $\{00, 10, 20\}$ in the buffer (since they have been extracted).
Therefore, the locations of the six-element buffer are being effectively reused, and in cycle $T+1$, the second column can be extracted, \emph{i.e.,} $SPEs$ $\{01, 11, 21, 31\}$.
In a similar fashion, the rest two columns are extracted in cycles $T+2$ and $T+3$, respectively, while the buffer locations are efficiently reused due to replacement. 








\subsubsection{Global Routing Interface \& Dedicated Wires}

As illustrated in Fig. \ref{fig:ST_architecture}, the $a\_data$ and $b\_data$ input ports as well as $c\_data$ output ports are connected to the global FPGA routing resources.
When chaining multiple SSTs, $a\_data$ and $b\_data$ are forwarded to their next in the chain SSTs, horizontally and vertically, respectively.
Horizontally, the data are propagated via the $a\_data\_out$ using the FPGA routing resources.
However, vertically, we utilize \textit{dedicated} wires to propagate the data (via the $b\_ded\_out$ ports) and connect them to the next SST in the \textit{same} FPGA column (via the $b\_ded\_in$ ports).
These vertical dedicated wires provide efficient connections without the usage of the global routing resources, matching the columnar nature of the modern FPGA fabric \cite{FPGA_architecture_2021, FPGA_for_DL_2024}.
This approach significantly reduces routing resources, as opposed to  \cite{TS_Aman_FPGA_2021, Aman_TS_TRETS_2022}, where all inputs/outputs (I/Os) of the in-fabric tensor slices are connected to global routing (see comparison in Sec. \ref{subsec:Dedicated_wires_benefits}).




Besides the I/Os shown in Fig. \ref{fig:ST_architecture}, the SSTs include also several dynamic control signals.
In particular, an input $enable$ signal is used to control the operation of the SSTs.
This signal should be deasserted when the operation of the SST needs to be stalled.
% in the case where the SST needs to stall its operation.
Moreover, an $accumulate$ signal is utilized to control the accumulation in the SPEs.
This signal remains asserted when accumulation is desirable in the SPEs, \emph{e.g.,} during tiling to process larger matrices.
However, for every new matrix operation the $accumulate$ signal should be deasserted for one cycle.
Another input signal is the  $d\_type$, which  dynamically selects the precision, \emph{i.e.,} int8 or bfloat16.
Finally, a 2-bit $sparsity\_level$ signal is employed to dynamically select the sparsity level of the matrix $A$, \emph{i.e.,} dense, 2:4, 1:3, 1:4.
This signal is utilized internally in the SSTs to control the operation of the supported sparsity modes, as discussed in the next section.

Regarding the outputs of the SST, an $accumulate\_out$ signal is used for systolic distribution of the $accumulate$ signal when chaining multiple SSTs.
This systolic distribution makes the control logic significantly simpler, since the $accumulate$ is set only for the first SST in the 2D array layout, while being distributed to the remaining SSTs, as explained in Sec. \ref{subsec:Matrix_multiplication_mapping}.
Another output signal is the $valid\_out$, which is asserted when the output $c\_data$ are extracted column-wise (Fig. \ref{fig:ST_architecture}). 
This signal simplifies the downstream logic, since only $valid\_out$ needs to be checked for valid output data.





\subsection{Sparse Processing Element}
\label{subsec:Sparse_Processing_Element}

The SPE architecture in all supported sparsity modes is illustrated in Fig. \ref{fig:SPE_sparse_modes}.
When the SPE is configured in dense mode (Fig. \ref{fig:SPE_sparse_modes}a), it operates as a regular dense PE.
In particular, one MAC operation is performed every cycle, while the elements of matrices $A$ and $B$ are forwarded to their neighboring SPEs (via pipeline registers) horizontally and vertically, respectively.
The output value of matrix $C$ in each SPE is calculated after $K$ cycles, when considering the $M$$\times$$K$$\times$$N$ matrix dimensions depicted in Fig. \ref{fig:SPE_sparse_modes}a.



In 2:4 mode (50\% sparsity), matrix $A$ is stored in a compressed format of $M$$\times$$K/2$ size for both values and the 2-bit indices, as shown in Fig. \ref{fig:SPE_sparse_modes}b.
In order to achieve speedup over the dense case, we increase the number of ports of each SPE in the vertical dimension, to load four elements of the matrix $B$ in parallel.
Furthermore, the 2-bit index is also loaded in the SPE to select the corresponding $B$ values (via a 4:1 multiplexer), which need to get multiplied with each $A$ value.
However, in 2:4 sparsity, for every four values of the matrix $B$, two MAC operations need to be performed.
Hence, the four $B$ values remain in the SPE registers for two clock cycles (the four green registers in Fig. \ref{fig:SPE_sparse_modes}b are loaded every two cycles).
To correctly synchronize the systolic operation, two pipeline stages are required for both the $A$ values and their indices (blue and yellow registers in Fig. \ref{fig:SPE_sparse_modes}b), which are loaded every cycle. 
In this manner, one MAC operation is performed every cycle, ensuring 100\% utilization.
Moreover, the output value of matrix $C$ in each SPE is calculated in $K/2$ cycles, achieving 2$\times$ acceleration over dense operation.




\begin{table}[t]
\centering
\caption{Summary of supported sparsity levels in SST slices.}

\setlength\tabcolsep{9pt}
\renewcommand{\arraystretch}{1.0}
\resizebox{0.80\linewidth}{!}{
% \vspace{-0.10cm}
\begin{tabular}{c|cc|c|c}
\Xhline{2.5\arrayrulewidth}

\textbf{Sparsity}  &  
\multicolumn{2}{c|}{\textbf{Compres. ratio}} & \textbf{Speedup} & \textbf{SPE} \\

\cline{2-3}

\textbf{level}  & \textbf{int8} & \textbf{bfloat16} 
 & \textbf{over dense} & \textbf{util.} \\

\hline
\hline

\textbf{Dense (0\%)} & 1$\times$ & 1$\times$ & 1$\times$ & 100\% \\ 

\textbf{2:4 (50\%)} & 1.6$\times$ & 1.78$\times$ & 2$\times$ & 100\% \\ 

\textbf{1:3 (66.7\%)} & 2.4$\times$ & 2.67$\times$ & 3$\times$ & 100\% \\ 

\textbf{1:4 (75\%)} & 3.2$\times$ & 3.56$\times$ & 4$\times$ & 100\% \\ 


\Xhline{2.5\arrayrulewidth}

\end{tabular}
}

\label{tb:sparsity_summary_benefits}

\vspace{-0.50cm}

\end{table}



\begin{figure*}[ht]

\vspace{-0.55cm}

\centering
\includegraphics[width=0.81\textwidth]{03_Architecture_Overview/GEMM_2D_design.pdf}

\vspace{-0.35cm}

\caption{2D systolic GEMM design: dense implementation (a) and dynamic configuration of all supported sparsity modes (b).}
\label{fig:GEMM_2D_array_SSTs}

\vspace{-0.45cm}

\end{figure*}


Similar to 2:4, for 1:4 (75\%) sparsity, four $B$ values are loaded in the SPE.
However, in this case the $B$ values are loaded every cycle, while only one pipeline stage is required for the $A$ value and its index, as shown in Fig. \ref{fig:SPE_sparse_modes}c.
The output value needs $K/4$ cycles to be calculated, offering 4$\times$ speedup over the dense case.
To fill the sparsity gap between 50\% and 75\% as explained in Sec. \ref{sec:Introduction}, we leverage the same hardware enhancements for 2:4 and 1:4 sparsity to also support the 1:3 (66.7\%) pattern.
In particular, as illustrated in Fig. \ref{fig:SPE_sparse_modes}d, the 1:3 operation is similar to 1:4, with the main difference being that three $B$ values are loaded every cycle instead of four.
The indices ensure that the fourth $B$ value is never selected, thus no additional hardware is required.
In this case, $K/3$ cycles are needed for every SPE output value, providing 3$\times$ acceleration.
Finally, we note that similar to 1:3, 2:3 sparsity can also be supported by directly utilizing the 2:4 mode, leading to 33.3\% sparsity.
However, a matrix is typically considered sparse when it has sparsity of 50\% or higher \cite{AMD_AIE_ML_kernel_guide}.
Hence, in this work, we do not consider the 2:3 pattern. 







In Table \ref{tb:sparsity_summary_benefits}, we present a summary of the supported sparsity levels.
First, we show the \textit{compression ratio}, \emph{i.e.,} the memory reduction over dense storage due to compressed format, for both int8 and bfloat16 precisions.
For all sparsity levels, bfloat16 offers a higher compression ratio over int8, \emph{e.g.,} 1.78$\times$ \emph{vs.} 1.6$\times$ for 2:4 sparsity. 
This is because 2-bit indices are required for both 8-bit and 16-bit data types, resulting in relatively lower overhead for the compressed representation in bfloat16 compared to int8.
This compressed format substantially reduces both on-chip and off-chip memory requirements, achieving up to 3.56$\times$ reduction (Table \ref{tb:sparsity_summary_benefits}).


Second, we notice that every sparsity level is
% effectively
translated to its corresponding speedup, \emph{e.g.,} 4$\times$ for 1:4 (75\%) sparsity, achieving 100\% SPE utilization in all cases (Table \ref{tb:sparsity_summary_benefits}).
For all sparsity levels, data reuse is maximized since both indices and values are propagated and reused horizontally and vertically, similar to dense operation.






\subsection{GEMM Design Utilizing Multiple SST Slices}
\label{subsec:Matrix_multiplication_mapping}


In this section, we describe parametric GEMM implementations for both dense and sparse configurations, utilizing multiple SST slices.
Both implementations are highly regular and scale effectively on the FPGA fabric, attaining high frequencies as shown in Sec. \ref{subsec:Sparse_GEMM_implementation}.




\subsubsection{Dense Implementation}

Fig. \ref{fig:GEMM_2D_array_SSTs}a depicts a parametric GEMM accelerator comprising a 2D array of SST slices, which are configured in \textit{dense} mode (Sec. \ref{subsec:Sparse_Processing_Element}). 
The 2D array consists of $Y \cdot X$ SST slices, implementing a total SA size of $(Y \cdot 4) \times (X \cdot 4)$.
This size is denoted as the \textit{native} size of the GEMM accelerator. 
On-chip memory buffers are implemented to store the input matrices $A$, $B$ and the output matrix $C$.
The input buffers $A$, $B$ are located in the left and top edges of the 2D array, respectively, and are partitioned into banks, providing sufficient bandwidth to feed the SSTs.
In particular, for buffer $A$, $Y$ banks are required, while for buffer $B$, $X$ banks are needed.
Since each SST slice includes a 4$\times$4 SA, each bank needs to provide a bandwidth of 32-bits per cycle when SSTs are configured for int8 precision, while for bfloat16, 64-bits per cycle are required.
Regarding the output buffer $C$, $X \cdot Y$ banks are needed due to the output stationary architecture of the SSTs, each receiving an output of 128-bits per cycle (four 32-bit values as explained in Sec. \ref{subsec:Sparse_Tensor_slices_architecture}).
 



The data from the buffers $A$, $B$ are propagated in a systolic fashion between the SST slices, as illustrated in Fig. \ref{fig:GEMM_2D_array_SSTs}a.
Horizontally, the $A$ data are propagated via the global routing resources of the FPGA fabric.
Vertically, the $B$ data are inserted via global routing wires in the first SST at each vertical chain ($Y$ SSTs in Fig. \ref{fig:GEMM_2D_array_SSTs}a), while being forwarded to the next SSTs via dedicated wires.
It is important to note here that the SSTs comprising each vertical chain are \textit{physically} contiguous in the FPGA.
Nevertheless, in the horizontal dimension, the $Y$ chains might not follow the \textit{logical} arrangement shown in Fig. \ref{fig:GEMM_2D_array_SSTs}a inside the FPGA fabric, due to the routing flexibility of FPGAs.
This depends on decisions made by the FPGA place and route (PnR) algorithm.
Finally, notice the (static) systolic data setup configuration specifically for the SST slices that interface with the buffers $A$, $B$ (left and top edge of the 2D array).


Control logic, mapped to the CLB resources of the FPGA, is utilized to orchestrate the entire operation of the GEMM design.
We also implement tiling logic (in CLBs) to exploit data reuse in GEMM, as well as to support arbitrary GEMM sizes based on the available on-chip memory resources.
When mapping an arbitrary GEMM of $M^\prime$$\times$$K^\prime$$\times$$N^\prime$ dimensions, $M^\prime$ must be a multiple of $(Y \cdot 4)$, while $N^\prime$ must be a multiple of $(X \cdot 4)$, since the \textit{native} size of the accelerator is $(Y \cdot 4) \times (X \cdot 4)$.
Note that there is no constraint on the reduction $K^\prime$ dimension.
Finally, although not shown in Fig. \ref{fig:GEMM_2D_array_SSTs}a, $accumulate$ signals utilized during tiling (Sec. \ref{subsec:Sparse_Tensor_slices_architecture}) are propagated in a systolic fashion among the 2D array of SSTs, similar to the $A$, $B$ data.
The control logic sets the $accumulate$ signal only for the first SST in both vertical and horizontal dimensions (\emph{i.e.,} the SST fed by buffers $A_{1}$ and $B_{1}$), which significantly simplifies the overall logic.






\subsubsection{Dynamic Sparse Configuration}

Fig. \ref{fig:GEMM_2D_array_SSTs}b illustrates a parametric GEMM design that is \textit{dynamically} configured to support all the sparsity modes in the SSTs, \emph{i.e.,} dense, 2:4, 1:3 and 1:4.
This dynamic configuration is particularly important for layer-wise sparsity exploitation in DNNs, since each layer might require different sparsity level for optimal trade-off between DNN accuracy and speedup (Sec. \ref{subsec:Performance_estimation_DNNs}).
We note that the implementation is similar to the dense design (Fig. \ref{fig:GEMM_2D_array_SSTs}a), with main differences lying in the design of buffers $A$ and $B$, as well as in the vertical and horizontal propagation of the data.
Horizontally, the $A$ data are kept in the buffer banks in compressed format for the sparse modes (2:4, 1:3 and 1:4).
In this case, both non-zero data and indices are loaded in the SSTs and are propagated horizontally (see Sec. \ref{subsec:Sparse_Processing_Element}).
More specifically, for int8, each buffer $A$ bank needs to provide a bandwidth of 40-bits per cycle, due to the additional 8-bits indices for the four vertical SPEs at the interface of each SST.
Similarly, for bfloat16, 72-bits per cycle are required.


Vertically, four $B$ banks are needed to feed the SSTs due to the 4$\times$ increase in ports for 2:4 and 1:4 sparsity acceleration (Sec. \ref{subsec:Sparse_Processing_Element}).
Each $B$ bank provides the same bandwidth as the dense design (Fig. \ref{fig:GEMM_2D_array_SSTs}a), \emph{i.e.,} 32-bits and 64-bits per cycle for int8 and bfloat16, respectively.
Similar to the dense design, the $B$ data are inserted in the first SST at each vertical chain and dedicated wires are used to propagate them vertically (Fig. \ref{fig:GEMM_2D_array_SSTs}b).
These dedicated wires are particularly important for the sparse design, since otherwise 4$\times$ more vertical wires would be required to use global routing compared to the dense design (in the case where \textit{only} non-dedicated wires are employed).




Besides sparse operation, the design in Fig. \ref{fig:GEMM_2D_array_SSTs}b also supports dense computation.
This is because dense computation might still be needed, even if all weights in DNNs are sparse.
For instance, in Transformer-based DNNs \cite{Attention_all_you_need_2017, BERT_2019, ViT_2020}, the QKV (Query, Key, Value) 
% self-attention 
GEMMs do not involve weights, and are typically computed as dense.
For dense computation, only one $B$ bank is sufficient at each vertical chain, \emph{e.g.,} $B_{x,0}$ (Fig. \ref{fig:GEMM_2D_array_SSTs}b).
However, multiplexing logic can be employed to 
% effectively 
utilize the remaining $B_{x,1}$, $B_{x,2}$, $B_{x,3}$ banks.
This is particularly important to ensure efficient utilization of on-chip memory resources, which leads to maximized data reuse and thus optimized energy efficiency \cite{Versal_vs_Stratix_FCCM_2024, MaxEVA_2023}.
Finally, for 1:3 sparsity, only banks $B_{x,0}$, $B_{x,1}$, $B_{x,2}$ are required, leaving bank $B_{x,3}$ unused. 
However, similar to the dense operation, 
% additional 
multiplexing logic can be employed to reuse this bank when it comprises multiple BRAMs, which we do not explore in this work (see Sec. \ref{subsec:Sparse_GEMM_implementation} for implementation details). 



The dynamic configuration among all sparsity levels 
% in Fig. \ref{fig:GEMM_2D_array_SSTs}b
is implemented in the control logic (using CLBs).
However, FPGA accelerators can be designed in a custom fashion depending on the sparsity of each DNN.
% required in DNN.
For instance, a specific DNN might require only 1:3 sparsity and dense computation across all of its layers.
The control and tiling logic for sparsity is similar to the dense design (Fig. \ref{fig:GEMM_2D_array_SSTs}a), showcasing a marginal increase in CLB resources (see Sec. \ref{subsec:Sparse_GEMM_implementation}).




