% I think the start of the paper needs to be squarely on Nesys.
% * I'd introduce them in the first para.
Neuro-Symbolic Artificial Intelligence (NeSy AI) \cite{hitzler2022neuro,marra2024statistical} aims to combine the strengths of neural-based learning with those of symbolic reasoning. Such techniques have gained popularity, as they have been shown to improve the generalization capacity and interpretability of neural networks (NNs) by seamlessly combining deep learning with domain knowledge. We focus on NeSy approaches that perform probabilistic reasoning. Such systems are typically compositional; first, a NN extracts symbols from sub-symbolic input, which are then used for formal reasoning by a symbolic component. They rely on formal probabilistic semantics to handle uncertainty in a principled fashion \cite{marra2024statistical}, and are for this reason adopted by several state-of-the-art NeSy systems \cite{manhaeve2018deepproblog,winters2022deepstochlog}. 

% * Explain where the problem is (lack of reliability/verifiability trust)
% * Then come in by saying that similar problems have been solved for NNs
% (eg something like first para now)
% * We can take inspiration and lift some of this work to the context of
% NeSys and provide a solution to the validation problem.
% In order to deploy such NeSy systems in mission-critical applications, it is mandatory to obtain formal guarantees on their reliable performance. While the NeSy approach often claims to produce more verifiable systems, this area remains largely underexplored. An important verification property is robustness, i.e. that a system's behaviour remains unchanged under perturbations to its input. In this work, we address the problem of formally verifying the robustness of NeSy probabilistic reasoning systems. The property of adversarial robustness has been extensively researched in the pure-neural context, yielding a multitude of methods which derive mathematical proofs of a NN's robustness. In this work we lift such methods from the purely-neural to the NeSy setting, delivering the first method for the robustness verification problem of probabilistic NeSy systems.

In order to deploy such NeSy systems in mission-critical applications, it is often necessary to have formal guarantees of their reliable performance. Techniques for NN verification are valuable to that end, since they are able to derive such guarantees for purely neural systems. Still, verifying properties on top of hybrid systems combining neural and symbolic components remains largely under-explored. In this work we address this challenge, focusing on verifying the robustness of probabilistic NeSy systems, i.e., verifying the property that input perturbations do not affect the reasoning output. We do so by lifting existing NN verification techniques to the NeSy setting.

% Despite these desirable characteristics, these systems remain partly comprised of neural networks, which have been shown to be fragile and susceptible to adversarial attacks \cite{goodfellow2014explaining}. It is worth investigating the robustness of these systems specifically as the neural and the symbolic components form a complex interaction. Therefore, verifying NeSy systemsâ€™ adversarial robustness, i.e. proving the resilience of their predictions to input perturbations, is mandatory for their deployment in safety-critical applications.


% related work
A few related verification approaches, often termed Neuro-Symbolic, have been proposed in the literature \cite{akintunde2020verifying,xie2022neuro,daggitt2024vehiclebridgingembeddinggap}. Such methods go beyond neural classification robustness, by verifying more complex properties on top of a NN \cite{xie2022neuro}, or by verifying the correct behaviour of hybrid systems consisting of neural and symbolic components. In the latter case, the symbolic component includes some form of control logic over the neural outputs \cite{akintunde2020verifying}, or programs that make use of such outputs in the context of neuro-symbolic programming \cite{daggitt2024vehiclebridgingembeddinggap}. These methods differ substantially from our proposed approach, which targets systems that perform probabilistic reasoning, a task that is beyond the reach of the aforementioned techniques. Moreover, existing methods rely on solver-based verification techniques, which translate the verification query into a satisfiability modulo theories (SMT) problem \cite{xie2022neuro,daggitt2024vehiclebridgingembeddinggap} or into a mixed-integer linear programming (MILP) instance \cite{akintunde2020verifying}. While such techniques result in approaches that are sound and complete, they suffer from serious scalability issues, which often renders them impractical. 

These scalability issues motivate the use of relaxation-based verification approaches, which sacrifice completeness for efficiency. Such techniques reason over a relaxed version of the verification problem by over-approximating the exact bounds~\cite{Ehlers17,autolirpaXu2020}. Our proposed approach extends relaxation-based NN verification methods to the NeSy setting, by relying on knowledge compilation (KC) \cite{darwiche2002knowledge}. KC is widely used (e.g. in \cite{xu2018semantic,manhaeve2018deepproblog}) to represent the probabilistic symbolic component of the system as an algebraic computational graph comprised solely of addition, subtraction, and multiplication nodes. This can in turn be appended to the output layer of the neural component. The resulting structure, which encapsulates both the neural and the symbolic components, is amenable to verification by off-the-shelf, state-of-the-art formal NN verifiers. 

The contributions of this work are summarized as follows:
% \begin{itemize}
%     \item We introduce a lightweight solution to the robustness verification problem for NeSy probabilistic reasoning systems. Our solution is based on extending relaxation-based verification techniques from the purely-neural to the neurosymbolic setting.

%     \item We provide a theoretical evaluation of the complexity of solving the probabilistic neurosymbolic verification task exactly, showing that exact bound propagation through the symbolic component is $\mathrm{NP}^{\# \mathrm{P}}$-hard. Beyond this theoretical analysis, we experimentally demonstrate that the proposed approach scales exponentially better than solver-based solutions.

%     \item We show that our method is applicable to real-world problems involving high-dimensional input and larger network sizes. We demonstrate this by applying our technique to an autonomous driving dataset where we verify a safety property on top of an object detection network and an action selector network.
% \end{itemize}

\begin{itemize}
    \item We introduce a scalable approach to the robustness verification of NeSy probabilistic reasoning systems. Our solution is based on extending relaxation-based verification techniques from the pure-neural to the NeSy setting.

    \item We study the complexity of solving the probabilistic NeSy verification task exactly, showing that exact bound propagation through the symbolic component is $\mathrm{NP}^{\# \mathrm{P}}$-hard. Beyond this theoretical analysis, we experimentally demonstrate that the proposed approach scales exponentially better than solver-based solutions.
    
    \item We show that our method is applicable to real-world problems involving high-dimensional input and realistic network sizes. We demonstrate this by applying our technique to an autonomous driving dataset, where we verify a safety property on top of an object detection network and an action selector network.
\end{itemize}

    % \item Via an autonomous driving application we show that our method is applicable to real-world problems involving high-dimensional input and networks. 
% The rest of the paper is organized as follows. In Section \ref{background} we review the necessary background. In Section \ref{methodology} we present our proposed method for approximate probabilistic NeSy verification. We demonstrate the efficacy and applicability of this approach in Section \ref{experiments}, and provide an overview and comparison with the related work in Section \ref{related-work}. We end the paper by summarizing our main contributions and giving pointers to potential future work in Section \ref{conclusion}.