We presented a scalable technique for verifying the robustness of probabilistic neuro-symbolic reasoning systems. Our method combines relaxation-based techniques from the NN verification domain with knowledge compilation, in order to assess the effects of input perturbations on the probabilistic logical output of the system. We motivated our approach via a theoretical analysis, and demonstrated its efficacy via experimental evaluation on synthetic and real-world data. Future work includes extending our method to more sophisticated neural verification techniques, such as (Reverse) Symbolic Interval Propagation \cite{gehr2018ai2,wang2021beta}, towards obtaining tighter bounds. Further, integrating certified training techniques \cite{smallBoxesMuller2023,expressiveLossesDePalma2024} would substantially increase the magnitude of perturbations that our approach can verify, as such training explicitly optimizes for easier verification.

% , as well as integrating certified training techniques, which directly optimize for easier verification \cite{smallBoxesMuller2023,expressiveLossesDePalma2024}.

% We are currently only using IBP. In future work, we will extend to more sophisticated methods (e.g. SIP/RSIP) [CROWN ref], as well as combine with BaB for a relaxation-method that is both sound and complete [$\alpha\beta$-CROWN ref].

% While our experiments use networks trained via standard methods, integrating certified training techniques would substantially increase the magnitude of perturbations, $\epsilon$, that our approach can verify, as such training explicitly optimizes for easier verification \cite{smallBoxesMuller2023,expressiveLossesDePalma2024}.