[
  {
    "index": 0,
    "papers": [
      {
        "key": "transfomer",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "s4",
        "author": "Gu, Albert and Goel, Karan and R{\\'e}, Christopher",
        "title": "Efficiently modeling long sequences with structured state spaces"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "mamba",
        "author": "Gu, Albert and Dao, Tri",
        "title": "Mamba: Linear-time sequence modeling with selective state spaces"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "vim",
        "author": "Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang",
        "title": "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "vmamba",
        "author": "Liu, Yue and Tian, Yunjie and Zhao, Yuzhong and Yu, Hongtian and Xie, Lingxi and Wang, Yaowei and Ye, Qixiang and Liu, Yunfan",
        "title": "Vmamba: Visual state space model"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "plainmamba",
        "author": "Yang, Chenhongyi and Chen, Zehui and Espinosa, Miguel and Ericsson, Linus and Wang, Zhenyu and Liu, Jiaming and Crowley, Elliot J",
        "title": "Plainmamba: Improving non-hierarchical mamba in visual recognition"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "localmamba",
        "author": "Huang, Tao and Pei, Xiaohuan and You, Shan and Wang, Fei and Qian, Chen and Xu, Chang",
        "title": "Localmamba: Visual state space model with windowed selective scan"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "transfomer",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "vit",
        "author": "Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "deit",
        "author": "Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\\'e}gou, Herv{\\'e}",
        "title": "Training data-efficient image transformers \\& distillation through attention"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "knowledgedistilling",
        "author": "Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff",
        "title": "Distilling the knowledge in a neural network"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "imagenet",
        "author": "Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others",
        "title": "Imagenet large scale visual recognition challenge"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "swin",
        "author": "Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining",
        "title": "Swin transformer: Hierarchical vision transformer using shifted windows"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "pvt",
        "author": "Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling",
        "title": "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions"
      },
      {
        "key": "pvtv2",
        "author": "Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling",
        "title": "Pvt v2: Improved baselines with pyramid vision transformer"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "pvt",
        "author": "Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling",
        "title": "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions"
      },
      {
        "key": "pvtv2",
        "author": "Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling",
        "title": "Pvt v2: Improved baselines with pyramid vision transformer"
      },
      {
        "key": "dat",
        "author": "Xia, Zhuofan and Pan, Xuran and Song, Shiji and Li, Li Erran and Huang, Gao",
        "title": "Vision transformer with deformable attention"
      },
      {
        "key": "cswin",
        "author": "Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining",
        "title": "Cswin transformer: A general vision transformer backbone with cross-shaped windows"
      },
      {
        "key": "biformer",
        "author": "Zhu, Lei and Wang, Xinjiang and Ke, Zhanghan and Zhang, Wayne and Lau, Rynson WH",
        "title": "BiFormer: Vision Transformer with Bi-Level Routing Attention"
      },
      {
        "key": "dilateformer",
        "author": "Jiao, Jiayu and Tang, Yu-Ming and Lin, Kun-Yu and Gao, Yipeng and Ma, Jinhua and Wang, Yaowei and Zheng, Wei-Shi",
        "title": "Dilateformer: Multi-scale dilated transformer for visual recognition"
      },
      {
        "key": "qformer",
        "author": "Zhang, Qiming and Zhang, Jing and Xu, Yufei and Tao, Dacheng",
        "title": "Vision transformer with quadrangle attention"
      },
      {
        "key": "transnext",
        "author": "Shi, Dai",
        "title": "TransNeXt: Robust Foveal Visual Perception for Vision Transformers"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "depsconv",
        "author": "Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig",
        "title": "Mobilenets: Efficient convolutional neural networks for mobile vision applications"
      },
      {
        "key": "depsconv2",
        "author": "Chollet, Fran{\\c{c}}ois",
        "title": "Xception: Deep learning with depthwise separable convolutions"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "layernorm",
        "author": "Ba, Jimmy and Kiros, JamieRyan and Hinton, GeoffreyE.",
        "title": "Layer Normalization"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "gelu",
        "author": "Hendrycks, Dan and Gimpel, Kevin",
        "title": "Gaussian error linear units (gelus)"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "cnn",
        "author": "LeCun, Yann and Bottou, L{\\'e}on and Bengio, Yoshua and Haffner, Patrick",
        "title": "Gradient-based learning applied to document recognition"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "alexnet",
        "author": "Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E",
        "title": "Imagenet classification with deep convolutional neural networks"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "vgg",
        "author": "Simonyan, Karen and Zisserman, Andrew",
        "title": "Very deep convolutional networks for large-scale image recognition"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "googlenet",
        "author": "Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew",
        "title": "Going deeper with convolutions"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "resnet",
        "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
        "title": "Deep residual learning for image recognition"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "densenet",
        "author": "Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q",
        "title": "Densely connected convolutional networks"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "dgcnet",
        "author": "Zhang, Li and Li, Xiangtai and Arnab, Anurag and Yang, Kuiyuan and Tong, Yunhai and Torr, Philip HS",
        "title": "Dual graph convolutional network for semantic segmentation"
      },
      {
        "key": "internimage",
        "author": "Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others",
        "title": "Internimage: Exploring large-scale vision foundation models with deformable convolutions"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "efficientnet",
        "author": "Tan, Mingxing and Le, Quoc",
        "title": "Efficientnet: Rethinking model scaling for convolutional neural networks"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "convnet",
        "author": "Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining",
        "title": "A convnet for the 2020s"
      },
      {
        "key": "convnextv2",
        "author": "Woo, Sanghyun and Debnath, Shoubhik and Hu, Ronghang and Chen, Xinlei and Liu, Zhuang and Kweon, In So and Xie, Saining",
        "title": "Convnext v2: Co-designing and scaling convnets with masked autoencoders"
      },
      {
        "key": "RepLKNet",
        "author": "Ding, Xiaohan and Zhang, Xiangyu and Han, Jungong and Ding, Guiguang",
        "title": "Scaling up your kernels to 31x31: Revisiting large kernel design in cnns"
      },
      {
        "key": "SLaK",
        "author": "Liu, Shiwei and Chen, Tianlong and Chen, Xiaohan and Chen, Xuxi and Xiao, Qiao and Wu, Boqian and K{\\\"a}rkkainen, Tommi and Pechenizkiy, Mykola and Mocanu, Decebal C and Wang, Zhangyang",
        "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity"
      }
    ]
  }
]