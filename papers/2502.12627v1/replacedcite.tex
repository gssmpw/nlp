\section{Related Work}
\subsection{Vision State Space Models}
Although the Transformer____ has achieved remarkable success in natural language processing, its quadratic complexity poses challenges when handling long sequence structures. To address this issue, state-space models____ (SSMs), represented by Mamba____, have gradually emerged as an alternative to Transformers. In visual tasks, the quadratic complexity of the standard self-attention mechanism similarly presents challenges for processing high-resolution images. Thus, the Vim____ and VMamba____ attempt to incorporate Mamba into computer vision tasks. However, inputting images into SSM models remains a critical challenge. Vim and VMamba address this by employing bidirectional and four-directional scanning strategies to transform image patches into one-dimensional sequences. Building on this, subsequent research introduced continuous scanning____ and local four-directional scan____ to better align with the two-dimensional structure of images. Despite the significant achievements of Mamba models in computer vision, existing scanning methods heavily rely on manual design, making it difficult to dynamically and flexibly adapt to input variations. This limitation hinders the model's ability to capture complex two-dimensional structures. Therefore, our goal is to propose a vision Mamba model capable of adaptively and flexibly adjusting scanning paths based on input image, further enhancing its performance in vision tasks.


\subsection{Vision Transformers}
The Transformer____ model was first introduced in 2017 for natural language processing (NLP) tasks. With its powerful global modeling capabilities and excellent parallelism, the Transformer quickly gained popularity in the NLP. By the end of 2020, Vision Transformer____ (ViT) successfully extended the Transformer model to large-scale image classification tasks, achieving state-of-the-art performance. Subsequently, DeiT____ improved ViT by introducing knowledge distillation____ and more efficient training strategies, enabling effective training even on relatively small datasets such as ImageNet-1K____. Following this development trajectory, researchers proposed numerous hierarchical Transformer models that reduce computational complexity for high-resolution images through various sparse attention mechanisms. Notable examples include the Swin Transformer____ and PVT____. Subsequent research____ introduced various sparse attention mechanisms to strike a balance between global modeling capability and computational complexity. However, the global modeling capabilities of these improved sparse attention mechanisms still fall short of the standard self-attention mechanism.


\begin{figure*}[h]
    \centering
    \includegraphics[width=1.\linewidth]{image/architecture.pdf}
    \vspace{-3mm}
    \caption{Illustration of the proposed Dynamic Adaptive Scan (DAS). For clarity, only four reference points are shown. \textbf{Left}: each initial reference point represents the original position of a patch, with its offsets learned by an Offset Prediction Network (OPN). Features of important regions are sampled based on the predicted 2D coordinates using bilinear interpolation. \textbf{Right} the detailed structure of the OPN is revealed. The query feature map is first transformed through depthwise convolution____ to integrate local information. Then, another linear layer, after layer normalization____ and GELU____ activation, converts the feature map into offset values.}
    \label{fig:das}
    \vspace{-1em}
\end{figure*}
 
\subsection{Convolutional Neural Networks}
Convolutional Neural Network (CNN)____ was initially proposed for handwritten digit recognition, but it wasn't until the introduction of AlexNet____ in 2012, which triggered the "ImageNet moment," that the full potential of CNNs was realized. This breakthrough led to a rapid development in computer vision, driven by the resurgence of neural networks, with CNNs becoming the standard architecture for computer vision tasks. During this period, many representative CNN models emerged, such as VGG____, GoogLeNet____, ResNet____, DenseNet____, DCN____, and EfficientNet____. These models focused on different aspects, including accuracy, efficiency, and scalability, while promoting valuable design principles. In recent years, inspired by ViTs, some CNNs____ have incorporated large kernel convolutions to capture long-range dependencies, achieving performance competitive with ViT. At the same time, CNNs have been widely integrated into various ViTs and vision Mambas to enhance local modeling capabilities, creating a complementary synergy between the two approaches. These advancements have driven the diversification and convergence of model design in vision tasks.