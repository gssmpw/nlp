
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@article{mit_paper,
              title={Customizing Motion in Text-to-Video Diffusion Models},
              author={Materzy\'nska, Joanna and Sivic, Josef and Shechtman, Eli and Torralba, Antonio and Zhang, Richard and Russell, Bryan},
              journal={arXiv preprint arXiv:2312.04966},
              year={2023}}


@INPROCEEDINGS{Weizman_paper,
  author={Yatim, Danah and Fridman, Rafail and Bar-Tal, Omer and Kasten, Yoni and Dekel, Tali},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer}, 
  year={2024},
  volume={},
  number={},
  pages={8466-8476},
  keywords={Computer vision;Shape;Layout;Dogs;Diffusion models;Pattern recognition;Text to video;video editing;motion transfer;diffusion models},
  doi={10.1109/CVPR52733.2024.00809}}

@article{chen2023fit,
  title={FIT: Far-reaching Interleaved Transformers},
  author={Chen, Ting and Li, Lala},
  journal={arXiv preprint arXiv:2305.12689},
  year={2023}
}

@article{Dannys_3D_paper,
author = {Cohen-Or, Daniel and Solomovic, Amira and Levin, David},
title = {Three-dimensional distance field metamorphosis},
year = {1998},
issue_date = {April 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {0730-0301},
url = {https://doi.org/10.1145/274363.274366},
doi = {10.1145/274363.274366},
journal = {ACM Trans. Graph.},
month = apr,
pages = {116–141},
numpages = {26},
keywords = {computer animation, interpolation, morphing, radial basis function, shape-blending, warping}
}


@inproceedings{textual_inversion,
	title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
	author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
	booktitle={ICLR},
	year={2023}
}

@inproceedings{custom-diffusion,
  title={Multi-concept customization of text-to-image diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  booktitle={CVPR},
  pages={1931--1941},
  year={2023}
}

@article{subject-diffusion,
  title={Subject-Diffusion: Open domain personalized text-to-image generation without test-time fine-tuning},
  author={Ma, Jian and Liang, Junhao and Chen, Chen and Lu, Haonan},
  journal={arXiv preprint arXiv:2307.11410},
  year={2023}
}

@article{fastcomposer,
  title={FastComposer: Tuning-Free multi-subject image generation with localized attention},
  author={Xiao, Guangxuan and Yin, Tianwei and Freeman, William T and Durand, Fr{\'e}do and Han, Song},
  journal={arXiv preprint arXiv:2305.10431},
  year={2023}
}


@inproceedings{ldm,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={CVPR},
  pages={10684--10695},
  year={2022}
}

@article{wu2023human,
  title={Human preference score v2: A solid benchmark for evaluating human preferences of text-to-image synthesis},
  author={Wu, Xiaoshi and Hao, Yiming and Sun, Keqiang and Chen, Yixiong and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
  journal={arXiv preprint arXiv:2306.09341},
  year={2023}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal=NIPS,
  volume={30},
  year={2017}
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={586--595},
  year={2018}
}

@article{ryoo2010overview,
  title={An overview of contest on semantic description of human activities (sdha) 2010},
  author={Ryoo, Michael S and Chen, Chia-Chih and Aggarwal, JK and Roy-Chowdhury, Amit},
  journal={Recognizing Patterns in Signals, Speech, Images and Videos: ICPR 2010 Contests, Istanbul, Turkey, August 23-26, 2010, Contest Reports},
  pages={270--285},
  year={2010},
  publisher={Springer}
}

@inproceedings{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  booktitle={NIPS},
  pages={25278--25294},
  year={2022}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{zhao2023magicfusion,
  title={MagicFusion: Boosting text-to-image generation performance by fusing diffusion models},
  author={Zhao, Jing and Zheng, Heliang and Wang, Chaoyue and Lan, Long and Yang, Wenjing},
  journal={arXiv preprint arXiv:2303.13126},
  year={2023}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@article{tuning-encoder,
  title={Pivotal tuning for latent-based editing of real images},
  author={Roich, Daniel and Mokady, Ron and Bermano, Amit H and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={1},
  pages={1--13},
  year={2022}
}

@inproceedings{gal2023designing,
  title={Designing an encoder for fast personalization of text-to-image models},
  author={Gal, Rinon and Arar, Moab and Atzmon, Yuval and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  booktitle={Siggraph},
  year={2023}
}

@article{kirstain2023x,
  title={X\&Fuse: Fusing visual information in text-to-image generation},
  author={Kirstain, Yuval and Levy, Omer and Polyak, Adam},
  journal={arXiv preprint arXiv:2303.01000},
  year={2023}
}

@article{wei2023elite,
  title={Elite: Encoding visual concepts into textual embeddings for customized text-to-image generation},
  author={Wei, Yuxiang and Zhang, Yabo and Ji, Zhilong and Bai, Jinfeng and Zhang, Lei and Zuo, Wangmeng},
  journal={arXiv preprint arXiv:2302.13848},
  year={2023}
}

@article{shi2023instantbooth,
  title={Instantbooth: Personalized text-to-image generation without test-time finetuning},
  author={Shi, Jing and Xiong, Wei and Lin, Zhe and Jung, Hyun Joon},
  journal={arXiv preprint arXiv:2304.03411},
  year={2023}
}

@article{wang2023high,
  title={High-fidelity Person-centric Subject-to-Image Synthesis},
  author={Wang, Yibin and Zhang, Weizhong and Zheng, Jianwei and Jin, Cheng},
  journal={arXiv preprint arXiv:2311.10329},
  year={2023}
}

@inproceedings{avrahami2023spatext,
  title={Spatext: Spatio-textual representation for controllable image generation},
  author={Avrahami, Omri and Hayes, Thomas and Gafni, Oran and Gupta, Sonal and Taigman, Yaniv and Parikh, Devi and Lischinski, Dani and Fried, Ohad and Yin, Xi},
  booktitle={CVPR},
  pages={18370--18380},
  year={2023}
}

@article{sarukkai2023collage,
  title={Collage diffusion},
  author={Sarukkai, Vishnu and Li, Linden and Ma, Arden and R{\'e}, Christopher and Fatahalian, Kayvon},
  journal={arXiv preprint arXiv:2303.00262},
  year={2023}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={CVPR},
  pages={4401--4410},
  year={2019}
}

@article{zhang2016joint,
  title={Joint face detection and alignment using multitask cascaded convolutional networks},
  author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
  journal={IEEE signal processing letters},
  volume={23},
  number={10},
  pages={1499--1503},
  year={2016},
  publisher={IEEE}
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={CVPR},
  pages={815--823},
  year={2015}
}

@misc{von-platen-etal-2022-diffusers,
  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Thomas Wolf},
  title = {Diffusers: State-of-the-art diffusion models},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/diffusers}}
}

@article{chang2023muse,
  title={Muse: Text-to-image generation via masked generative transformers},
  author={Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, AJ and Lezama, Jose and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin and Freeman, William T and Rubinstein, Michael and others},
  journal={arXiv preprint arXiv:2301.00704},
  year={2023}
}

@inproceedings{ding2021cogview,
  title={Cogview: Mastering text-to-image generation via transformers},
  author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others},
  booktitle={NeruIPS},
  pages={19822--19835},
  year={2021}
}

@inproceedings{kang2023scaling,
  title={Scaling up gans for text-to-image synthesis},
  author={Kang, Minguk and Zhu, Jun-Yan and Zhang, Richard and Park, Jaesik and Shechtman, Eli and Paris, Sylvain and Park, Taesung},
  booktitle={CVPR},
  pages={10124--10134},
  year={2023}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={ICML},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@inproceedings{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  booktitle={NIPS},
  pages={36479--36494},
  year={2022}
}
@inproceedings{zheng2023layoutdiffusion,
  title={LayoutDiffusion: Controllable diffusion model for layout-to-image generation},
  author={Zheng, Guangcong and Zhou, Xianpan and Li, Xuewei and Qi, Zhongang and Shan, Ying and Li, Xi},
  booktitle={CVPR},
  pages={22490--22499},
  year={2023}
}

@inproceedings{ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={CVPR},
  pages={22500--22510},
  year={2023}
}

@article{hao2023vico,
  title={ViCo: Detail-preserving visual condition for personalized text-to-image generation},
  author={Hao, Shaozhe and Han, Kai and Zhao, Shihao and Wong, Kwan-Yee K},
  journal={arXiv preprint arXiv:2306.00971},
  year={2023}
}

@inproceedings{bolya2023token,
  title={Token merging for fast stable diffusion},
  author={Bolya, Daniel and Hoffman, Judy},
  booktitle={CVPR},
  pages={4598--4602},
  year={2023}
}

@inproceedings{huang2023collaborative,
  title={Collaborative diffusion for multi-modal face generation and editing},
  author={Huang, Ziqi and Chan, Kelvin CK and Jiang, Yuming and Liu, Ziwei},
  booktitle={CVPR},
  pages={6080--6090},
  year={2023}
}

@article{si2023freeu,
  title={FreeU: Free Lunch in Diffusion U-Net},
  author={Si, Chenyang and Huang, Ziqi and Jiang, Yuming and Liu, Ziwei},
  journal={arXiv preprint arXiv:2309.11497},
  year={2023}
}

@inproceedings{transformer,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention is All you Need},
  booktitle    = NeurIPS,
  pages        = {5998--6008},
  year         = {2017}
}


@article{avrahami2023break,
  title={Break-A-Scene: Extracting Multiple Concepts from a Single Image},
  author={Avrahami, Omri and Aberman, Kfir and Fried, Ohad and Cohen-Or, Daniel and Lischinski, Dani},
  journal={arXiv preprint arXiv:2305.16311},
  year={2023}
}

@article{hertz2022prompt,
  title = {Prompt-to-Prompt Image Editing with Cross Attention Control},
  author = {Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal = {ICLR},
  year = {2023},
}


@article{li2023q,
  title={Q-Diffusion: Quantizing Diffusion Models},
  author={Li, Xiuyu and Lian, Long and Liu, Yijiang and Yang, Huanrui and Dong, Zhen and Kang, Daniel and Zhang, Shanghang and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2302.04304},
  year={2023}
}

@inproceedings{bolya2022token,
  title={Token Merging: Your {ViT} but Faster},
  author={Bolya, Daniel and Fu, Cheng-Yang and Dai, Xiaoliang and Zhang, Peizhao and Feichtenhofer, Christoph and Hoffman, Judy},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={ICLR},
  year={2016}
}

@article{xiao2022smoothquant,
  title={Smoothquant: Accurate and efficient post-training quantization for large language models},
  author={Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Demouth, Julien and Han, Song},
  journal={arXiv preprint arXiv:2211.10438},
  year={2022}
}

@article{gal2023designing,
  title={Designing an encoder for fast personalization of text-to-image models},
  author={Gal, Rinon and Arar, Moab and Atzmon, Yuval and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={Siggraph},
  year={2023}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal=NIPS,
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle=CVPR,
  pages={10684--10695},
  year={2022}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={ICLR},
  year={2021}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{casanova2021instance,
  title={Instance-conditioned gan},
  author={Casanova, Arantxa and Careil, Marlene and Verbeek, Jakob and Drozdzal, Michal and Romero Soriano, Adriana},
  journal=NIPS,
  volume={34},
  pages={27517--27529},
  year={2021}
}

@article{nitzan2022mystyle,
  title={Mystyle: A personalized generative prior},
  author={Nitzan, Yotam and Aberman, Kfir and He, Qiurui and Liba, Orly and Yarom, Michal and Gandelsman, Yossi and Mosseri, Inbar and Pritch, Yael and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={6},
  pages={1--10},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{po2023orthogonal,
  title={Orthogonal adaptation for modular customization of diffusion models},
  author={Po, Ryan and Yang, Guandao and Aberman, Kfir and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2312.02432},
  year={2023}
}

@article{kumari2022multi,
  title={Multi-Concept Customization of Text-to-Image Diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  journal={CVPR},
  year={2023}
}


@article{gal2024lcm,
  title={LCM-Lookahead for Encoder-based Text-to-Image Personalization},
  author={Gal, Rinon and Lichter, Or and Richardson, Elad and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2404.03620},
  year={2024}
}

@article{kirstain2023x,
  title={X\&Fuse: Fusing Visual Information in Text-to-Image Generation},
  author={Kirstain, Yuval and Levy, Omer and Polyak, Adam},
  journal={arXiv preprint arXiv:2303.01000},
  year={2023}
}

@article{li2023photomaker,
  title={Photomaker: Customizing realistic human photos via stacked id embedding},
  author={Li, Zhen and Cao, Mingdeng and Wang, Xintao and Qi, Zhongang and Cheng, Ming-Ming and Shan, Ying},
  journal={arXiv preprint arXiv:2312.04461},
  year={2023}
}

@article{ma2023unified,
  title={Unified Multi-Modal Latent Diffusion for Joint Subject and Text Conditional Image Generation},
  author={Ma, Yiyang and Yang, Huan and Wang, Wenjing and Fu, Jianlong and Liu, Jiaying},
  journal={arXiv preprint arXiv:2303.09319},
  year={2023}
}


@inproceedings{liu2022compositional,
  title={Compositional visual generation with composable diffusion models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XVII},
  pages={423--439},
  year={2022},
  organization={Springer}
}

@article{xiao2023fastcomposer,
  title={FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention},
  author={Xiao, Guangxuan and Yin, Tianwei and Freeman, William T and Durand, Fr{\'e}do and Han, Song},
  journal={arXiv preprint arXiv:2305.10431},
  year={2023}
}

@article{yan2024perflow,
    title   = {PeRFlow: Accelerating Diffusion models via Piecewise Rectified Flow},
    author  = {Yan, Hanshu and Liu, Xingchao and Pan, Jiachun and Liew, Jun Hao and Liu, Qiang and Feng, Jiashi},
    year    = {2024}
}

@Misc{accelerate,
  title =        {Accelerate: Training and inference at scale made simple, efficient and adaptable.},
  author =       {Sylvain Gugger and Lysandre Debut and Thomas Wolf and Philipp Schmid and Zachary Mueller and Sourab Mangrulkar and Marc Sun and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/accelerate}},
  year =         {2022}
}
@article{zhao2024unipc,
  title={Unipc: A unified predictor-corrector framework for fast sampling of diffusion models},
  author={Zhao, Wenliang and Bai, Lujia and Rao, Yongming and Zhou, Jie and Lu, Jiwen},
  journal=NIPS,
  volume={36},
  year={2023}
}


@article{betker2023improving,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others},
  journal={Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf},
  volume={2},
  number={3},
  pages={8},
  year={2023}
}

@article{tewel2024training,
  title={Training-Free Consistent Text-to-Image Generation},
  author={Tewel, Yoad and Kaduri, Omri and Gal, Rinon and Kasten, Yoni and Wolf, Lior and Chechik, Gal and Atzmon, Yuval},
  journal={arXiv preprint arXiv:2402.03286},
  year={2024}
}

@article{feng2022training,
  title={Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis},
  author={Feng, Weixi and He, Xuehai and Fu, Tsu-Jui and Jampani, Varun and Akula, Arjun and Narayana, Pradyumna and Basu, Sugato and Wang, Xin Eric and Wang, William Yang},
  journal={arXiv preprint arXiv:2212.05032},
  year={2022}
}

@article{chefer2023attend,
  title={Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models},
  author={Chefer, Hila and Alaluf, Yuval and Vinker, Yael and Wolf, Lior and Cohen-Or, Daniel},
  journal={Siggraph},
  year={2023}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{chang2023muse,
  title={Muse: Text-To-Image Generation via Masked Generative Transformers},
  author={Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, AJ and Lezama, Jose and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin and Freeman, William T and Rubinstein, Michael and others},
  journal={arXiv preprint arXiv:2301.00704},
  year={2023}
}

@article{kang2023scaling,
  title={Scaling up gans for text-to-image synthesis},
  author={Kang, Minguk and Zhu, Jun-Yan and Zhang, Richard and Park, Jaesik and Shechtman, Eli and Paris, Sylvain and Park, Taesung},
  journal={CVPR},
  year={2023}
}

@article{ding2021cogview,
  title={Cogview: Mastering text-to-image generation via transformers},
  author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others},
  journal=NIPS,
  volume={34},
  pages={19822--19835},
  year={2021}
}



@misc{chen2016training,
      title={Training Deep Nets with Sublinear Memory Cost}, 
      author={Tianqi Chen and Bing Xu and Chiyuan Zhang and Carlos Guestrin},
      year={2016},
      eprint={1604.06174},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{tov2021designing,
  title={Designing an encoder for stylegan image manipulation},
  author={Tov, Omer and Alaluf, Yuval and Nitzan, Yotam and Patashnik, Or and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--14},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{roich2022pivotal,
  title={Pivotal tuning for latent-based editing of real images},
  author={Roich, Daniel and Mokady, Ron and Bermano, Amit H and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={1},
  pages={1--13},
  year={2022},
  publisher={ACM New York, NY}
}

@inproceedings{CLIP,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={EMNLP},
  year={2019}
}

@article{BLIP,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@inproceedings{arar2023domain,
  title={Domain-agnostic tuning-encoder for fast personalization of text-to-image models},
  author={Arar, Moab and Gal, Rinon and Atzmon, Yuval and Chechik, Gal and Cohen-Or, Daniel and Shamir, Ariel and H. Bermano, Amit},
  booktitle={SIGGRAPH Asia 2023 Conference Papers},
  pages={1--10},
  year={2023}
}

@article{avrahami2023chosen,
  title={The Chosen One: Consistent Characters in Text-to-Image Diffusion Models},
  author={Avrahami, Omri and Hertz, Amir and Vinker, Yael and Arar, Moab and Fruchter, Shlomi and Fried, Ohad and Cohen-Or, Daniel and Lischinski, Dani},
  journal={arXiv preprint arXiv:2311.10093},
  year={2023}
}

@inproceedings{richardson2021encoding,
  title={Encoding in style: a stylegan encoder for image-to-image translation},
  author={Richardson, Elad and Alaluf, Yuval and Patashnik, Or and Nitzan, Yotam and Azar, Yaniv and Shapiro, Stav and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2287--2296},
  year={2021}
}

@inproceedings{cheng2022masked,
  title={Masked-attention mask transformer for universal image segmentation},
  author={Cheng, Bowen and Misra, Ishan and Schwing, Alexander G and Kirillov, Alexander and Girdhar, Rohit},
  booktitle=CVPR,
  pages={1290--1299},
  year={2022}
}

@article{li2024blipdiffusion,
  title={Blip-diffusion: Pre-trained subject representation for controllable text-to-image generation and editing},
  author={Li, Dongxu and Li, Junnan and Hoi, Steven},
  journal=NIPS,
  volume={36},
  year={2024}
}

@software{OpenCLIP,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}

@unpublished{spacy2,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {To appear}
}

@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "http://arxiv.org/abs/1908.10084",
}


@inproceedings{liu2015deep,
  title={Deep learning face attributes in the wild},
  author={Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3730--3738},
  year={2015}
}



@article{zhang2016joint,
  title={Joint face detection and alignment using multitask cascaded convolutional networks},
  author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
  journal={IEEE signal processing letters},
  volume={23},
  number={10},
  pages={1499--1503},
  year={2016},
  publisher={IEEE}
}

@misc{diffusers,
  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Thomas Wolf},
  title = {Diffusers: State-of-the-art diffusion models},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/diffusers}}
}

@article{avrahami2022spatext,
  title={SpaText: Spatio-Textual Representation for Controllable Image Generation},
  author={Avrahami, Omri and Hayes, Thomas and Gafni, Oran and Gupta, Sonal and Taigman, Yaniv and Parikh, Devi and Lischinski, Dani and Fried, Ohad and Yin, Xi},
  journal={CVPR},
  year = {2023}
}

@article{sarukkai2023collage,
  title={Collage Diffusion},
  author={Sarukkai, Vishnu and Li, Linden and Ma, Arden and R{\'e}, Christopher and Fatahalian, Kayvon},
  journal={arXiv preprint arXiv:2303.00262},
  year={2023}
}

@article{goel2023pair,
  title={PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models},
  author={Goel, Vidit and Peruzzo, Elia and Jiang, Yifan and Xu, Dejia and Sebe, Nicu and Darrell, Trevor and Wang, Zhangyang and Shi, Humphrey},
  journal={arXiv preprint arXiv:2303.17546},
  year={2023}
}

@article{dolhansky2020deepfake,
  title={The deepfake detection challenge (dfdc) dataset},
  author={Dolhansky, Brian and Bitton, Joanna and Pflaum, Ben and Lu, Jikuo and Howes, Russ and Wang, Menglin and Ferrer, Cristian Canton},
  journal={arXiv preprint arXiv:2006.07397},
  year={2020}
}

@misc{lin2014coco,
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  biburl = {https://www.bibsonomy.org/bibtex/2f4ab9f41677ee189a8cbc5a92cc0dc74/jan.hofmann1},
  description = {Microsoft COCO: Common Objects in Context},
  interhash = {a3a26c6fe173264a6b812e3b7b4119bd},
  intrahash = {f4ab9f41677ee189a8cbc5a92cc0dc74},
  keywords = {thema:pyramid_scene_parsing},
  timestamp = {2020-06-07T20:25:18.000+0200},
  title = {Microsoft COCO: Common Objects in Context},
  url = {http://arxiv.org/abs/1405.0312},
  year = 2014
}




@article{chen2023subject,
  title={Subject-driven text-to-image generation via apprenticeship learning},
  author={Chen, Wenhu and Hu, Hexiang and Li, Yandong and Rui, Nataniel and Jia, Xuhui and Chang, Ming-Wei and Cohen, William W},
  journal={arXiv preprint arXiv:2304.00186},
  year={2023}
}

@article{chen2022re,
  title={Re-imagen: Retrieval-augmented text-to-image generator},
  author={Chen, Wenhu and Hu, Hexiang and Saharia, Chitwan and Cohen, William W},
  journal={arXiv preprint arXiv:2209.14491},
  year={2022}
}

% CUSTOMIZATION


@article{wang2024instantid,
  title={Instantid: Zero-shot identity-preserving generation in seconds},
  author={Wang, Qixun and Bai, Xu and Wang, Haofan and Qin, Zekui and Chen, Anthony},
  journal={arXiv preprint arXiv:2401.07519},
  year={2024}
}

@inproceedings{avrahami2022blended,
  title={Blended diffusion for text-driven editing of natural images},
  author={Avrahami, Omri and Lischinski, Dani and Fried, Ohad},
  booktitle=CVPR,
  pages={18208--18218},
  year={2022}
}


@article{gu2024mix,
  title={Mix-of-show: Decentralized low-rank adaptation for multi-concept customization of diffusion models},
  author={Gu, Yuchao and Wang, Xintao and Wu, Jay Zhangjie and Shi, Yujun and Chen, Yunpeng and Fan, Zihan and Xiao, Wuyou and Zhao, Rui and Chang, Shuning and Wu, Weijia and others},
  journal=NIPS,
  volume={36},
  year={2024}
}

@article{Dhariwal2021DiffusionMB,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal=NIPS,
  volume={34},
  pages={8780--8794},
  year={2021}
}


@misc{kakaobrain2022coyo,
  title         = {COYO-700M: Image-Text Pair Dataset},
  author        = {Byeon, Minwoo and Park, Beomhee and Kim, Haecheon and Lee, Sungjun and Baek, Woonhyuk and Kim, Saehoon},
  year          = {2022},
  howpublished  = {\url{https://github.com/kakaobrain/coyo-dataset}},
}

@misc{toonyou,
  title  = {CivitAI checkpoint},
  author = {CivitAI},
  year = {2023},
  howpublished  = {\url{https://civitai.com/models/30240/toonyou}},
}


@article{gal2023encoder,
  title={Encoder-based domain tuning for fast personalization of text-to-image models},
  author={Gal, Rinon and Arar, Moab and Atzmon, Yuval and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--13},
  year={2023},
  publisher={ACM New York, NY, USA}
}


@misc{pixar,
  title  = {CivitAI checkpoint},
  author = {CivitAI},
  year = {2023},
  howpublished  = {\url{https://civitai.com/models/65203/disney-pixar-cartoon-type-a}},
}
@inproceedings{kulal2023putting,
  title={Putting people in their place: Affordance-aware human insertion into scenes},
  author={Kulal, Sumith and Brooks, Tim and Aiken, Alex and Wu, Jiajun and Yang, Jimei and Lu, Jingwan and Efros, Alexei A and Singh, Krishna Kumar},
  booktitle=CVPR,
  pages={17089--17099},
  year={2023}
}

@article{liu2023cones1,
  title={Cones 2: Customizable image synthesis with multiple subjects},
  author={Liu, Zhiheng and Zhang, Yifei and Shen, Yujun and Zheng, Kecheng and Zhu, Kai and Feng, Ruili and Liu, Yu and Zhao, Deli and Zhou, Jingren and Cao, Yang},
  journal={arXiv preprint arXiv:2305.19327},
  year={2023}
}

@article{liu2023cones2,
  title={Cones 2: Customizable image synthesis with multiple subjects},
  author={Liu, Zhiheng and Zhang, Yifei and Shen, Yujun and Zheng, Kecheng and Zhu, Kai and Feng, Ruili and Liu, Yu and Zhao, Deli and Zhou, Jingren and Cao, Yang},
  journal={arXiv preprint arXiv:2305.19327},
  year={2023}
}


@inproceedings{tewel2023key,
  title={Key-locked rank one editing for text-to-image personalization},
  author={Tewel, Yoad and Gal, Rinon and Chechik, Gal and Atzmon, Yuval},
  booktitle={ACM SIGGRAPH 2023 Conference Proceedings},
  pages={1--11},
  year={2023}
}

@inproceedings{mokady2023null,
  title={Null-text inversion for editing real images using guided diffusion models},
  author={Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle=CVPR,
  pages={6038--6047},
  year={2023}
}

@article{zhang2023prospect,
  title={Prospect: Prompt spectrum for attribute-aware personalization of diffusion models},
  author={Zhang, Yuxin and Dong, Weiming and Tang, Fan and Huang, Nisha and Huang, Haibin and Ma, Chongyang and Lee, Tong-Yee and Deussen, Oliver and Xu, Changsheng},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={6},
  pages={1--14},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

@misc{dblora,
  title = {Low-rank Adaptation for Fast Text-to-Image Diffusion Fine-tuning},
  howpublished = {\url{https://github.com/cloneofsimo/lora}},
  year = {2022},
}

@article{voynov2023p+,
  title={$ P+ $: Extended Textual Conditioning in Text-to-Image Generation},
  author={Voynov, Andrey and Chu, Qinghao and Cohen-Or, Daniel and Aberman, Kfir},
  journal={arXiv preprint arXiv:2303.09522},
  year={2023}
}

@inproceedings{kumari2023multi,
  title={Multi-concept customization of text-to-image diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  booktitle=CVPR,
  pages={1931--1941},
  year={2023}
}

# Test
@inproceedings{parmar2023zero,
  title={Zero-shot image-to-image translation},
  author={Parmar, Gaurav and Kumar Singh, Krishna and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan},
  booktitle={ACM SIGGRAPH 2023 Conference Proceedings},
  pages={1--11},
  year={2023}
}

@inproceedings{gu2023mix,
  title={Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept Customization of Diffusion Models},
  author={Gu, Yuchao and Wang, Xintao and Wu, Jay Zhangjie and Shi, Yujun and Chen, Yunpeng and Fan, Zihan and Xiao, Wuyou and Zhao, Rui and Chang, Shuning and Wu, Weijia and others},
  journal=NIPS,
  booktitle=NIPS,
  year={2023}
}

@article{han2023svdiff,
  title={Svdiff: Compact parameter space for diffusion fine-tuning},
  author={Han, Ligong and Li, Yinxiao and Zhang, Han and Milanfar, Peyman and Metaxas, Dimitris and Yang, Feng},
  journal={arXiv preprint arXiv:2303.11305},
  year={2023}
}

%%%%% Continuel Learning %%%%%%
@article{li2017learning,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}

@article{wang2023comprehensive,
  title={A comprehensive survey of continual learning: Theory, method and application},
  author={Wang, Liyuan and Zhang, Xingxing and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2302.00487},
  year={2023}
}

@inproceedings{farajtabar2020orthogonal,
  title={Orthogonal gradient descent for continual learning},
  author={Farajtabar, Mehrdad and Azizan, Navid and Mott, Alex and Li, Ang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3762--3773},
  year={2020},
  organization={PMLR}
}

@inproceedings{Po:2023:star_diffusion_models,
author = {Ryan Po and Wang Yifan and Vladislav Golyanik et al.},
title = {State of the Art on Diffusion Models for Visual Computing},
booktitle = {arxiv},
year = {2023}
}

@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={ICLR},
year={2022},
}

@inproceedings{kumari2022customdiffusion,
  author = {Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  title = {Multi-Concept Customization of Text-to-Image Diffusion},
  booktitle = {CVPR},
  year = {2023},
}


@misc{hessel2022clipscore,
      title={CLIPScore: A Reference-free Evaluation Metric for Image Captioning}, 
      author={Jack Hessel and Ari Holtzman and Maxwell Forbes and Ronan Le Bras and Yejin Choi},
      year={2022},
      eprint={2104.08718},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Serengil2020LightFaceAH,
  title={LightFace: A Hybrid Deep Face Recognition Framework},
  author={Sefik Ilkin Serengil and A. Ozpinar},
  journal={2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},
  year={2020},
  pages={1-5},
  url={https://api.semanticscholar.org/CorpusID:227220279}
}
@article{bar2023multidiffusion,
  title={MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation},
  author={Bar-Tal, Omer and Yariv, Lior and Lipman, Yaron and Dekel, Tali},
  journal={arXiv preprint arXiv:2302.08113},
  year={2023}
}
@article{ArcFace,
	doi = {10.1109/tpami.2021.3087709},
  
	url = {https://doi.org/10.1109%2Ftpami.2021.3087709},
  
	year = 2022,
	month = {oct},
  
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {44},
  
	number = {10},
  
	pages = {5962--5979},
  
	author = {Jiankang Deng and Jia Guo and Jing Yang and Niannan Xue and Irene Kotsia and Stefanos Zafeiriou},
  
	title = {{ArcFace}: Additive Angular Margin Loss for Deep Face Recognition},
  
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

@article{Song2020DenoisingDI,
  title={Denoising Diffusion Implicit Models},
  author={Jiaming Song and Chenlin Meng and Stefano Ermon},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.02502},
  url={https://api.semanticscholar.org/CorpusID:222140788}
}

@article{Ho2022ClassifierFreeDG,
  title={Classifier-Free Diffusion Guidance},
  author={Jonathan Ho},
  journal={ArXiv},
  year={2022},
  volume={abs/2207.12598},
  url={https://api.semanticscholar.org/CorpusID:249145348}
}

@article{Pandey2022DiffuseVAEEC,
  title={DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents},
  author={Kushagra Pandey and Avideep Mukherjee and Piyush Rai and Abhishek Kumar},
  journal={Trans. Mach. Learn. Res.},
  year={2022},
  volume={2022},
  url={https://api.semanticscholar.org/CorpusID:245650542}
}

@article{Rombach2021HighResolutionIS,
  title={High-Resolution Image Synthesis with Latent Diffusion Models},
  author={Robin Rombach and A. Blattmann and Dominik Lorenz and Patrick Esser and Bj{\"o}rn Ommer},
  journal={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021},
  pages={10674-10685},
  url={https://api.semanticscholar.org/CorpusID:245335280}
}

@article{Avrahami2023BreakASceneEM,
  title={Break-A-Scene: Extracting Multiple Concepts from a Single Image},
  author={Omri Avrahami and Kfir Aberman and Ohad Fried and Daniel Cohen-Or and Dani Lischinski},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.16311},
  url={https://api.semanticscholar.org/CorpusID:258888228}
}

@misc{mcmahan2023communicationefficient,
      title={Communication-Efficient Learning of Deep Networks from Decentralized Data}, 
      author={H. Brendan McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Agüera y Arcas},
      year={2023},
      eprint={1602.05629},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}

@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{brock2018large,
  title={Large scale GAN training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}

@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@article{karras2021alias,
  title={Alias-free generative adversarial networks},
  author={Karras, Tero and Aittala, Miika and Laine, Samuli and H{\"a}rk{\"o}nen, Erik and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  journal=NIPS,
  volume={34},
  pages={852--863},
  year={2021}
}


@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle=CVPR,
  pages={8110--8119},
  year={2020}
}

@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={International Conference on Machine Learning},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}

@article{yu2022scaling,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  volume={2},
  number={3},
  pages={5},
  year={2022},
  publisher={Jun}
}


@inproceedings{huang2022multimodal,
  title={Multimodal conditional image synthesis with product-of-experts gans},
  author={Huang, Xun and Mallya, Arun and Wang, Ting-Chun and Liu, Ming-Yu},
  booktitle=ECCV,
  pages={91--109},
  year={2022},
  organization={Springer}
}

@inproceedings{abdal2022clip2stylegan,
  title={Clip2stylegan: Unsupervised extraction of stylegan edit directions},
  author={Abdal, Rameen and Zhu, Peihao and Femiani, John and Mitra, Niloy and Wonka, Peter},
  booktitle={ACM SIGGRAPH 2022 conference proceedings},
  pages={1--9},
  year={2022}
}

@article{bau2021paint,
  title={Paint by word},
  author={Bau, David and Andonian, Alex and Cui, Audrey and Park, YeonHwan and Jahanian, Ali and Oliva, Aude and Torralba, Antonio},
  journal={arXiv preprint arXiv:2103.10951},
  year={2021}
}

@article{gal2021stylegan,
  title={Stylegan-nada: Clip-guided domain adaptation of image generators},
  author={Gal, Rinon and Patashnik, Or and Maron, Haggai and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2108.00946},
  year={2021}
}

@inproceedings{mokady2022self,
  title={Self-distilled stylegan: Towards generation from internet photos},
  author={Mokady, Ron and Tov, Omer and Yarom, Michal and Lang, Oran and Mosseri, Inbar and Dekel, Tali and Cohen-Or, Daniel and Irani, Michal},
  booktitle={ACM SIGGRAPH 2022 Conference Proceedings},
  pages={1--9},
  year={2022}
}

@inproceedings{xia2021tedigan,
  title={Tedigan: Text-guided diverse face image generation and manipulation},
  author={Xia, Weihao and Yang, Yujiu and Xue, Jing-Hao and Wu, Baoyuan},
  booktitle=CVPR,
  pages={2256--2265},
  year={2021}
}


@inproceedings{parmar2022spatially,
  title={Spatially-adaptive multilayer selection for gan inversion and editing},
  author={Parmar, Gaurav and Li, Yijun and Lu, Jingwan and Zhang, Richard and Zhu, Jun-Yan and Singh, Krishna Kumar},
  booktitle=CVPR,
  pages={11399--11409},
  year={2022}
}


%%%%%%%% Adaptors
%style Adaptor

%T2I adaptor
@article{mou2023t2i,
  title={T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Zhang, Jian and Qi, Zhongang and Shan, Ying and Qie, Xiaohu},
  journal={arXiv preprint arXiv:2302.08453},
  year={2023}
}

%% From HyperDreambooth
@article{ruiz2023hyperdreambooth,
  title={Hyperdreambooth: Hypernetworks for fast personalization of text-to-image models},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Wei, Wei and Hou, Tingbo and Pritch, Yael and Wadhwa, Neal and Rubinstein, Michael and Aberman, Kfir},
  journal={arXiv preprint arXiv:2307.06949},
  year={2023}
}   
%style drop
@article{sohn2023styledrop,
  title={StyleDrop: Text-to-Image Generation in Any Style},
  author={Sohn, Kihyuk and Ruiz, Nataniel and Lee, Kimin and Chin, Daniel Castro and Blok, Irina and Chang, Huiwen and Barber, Jarred and Jiang, Lu and Entis, Glenn and Li, Yuanzhen and others},
  journal={arXiv preprint arXiv:2306.00983},
  year={2023}
}

%Adaptor tuning
@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

%Dream Artiest


% Taming adaptor
@article{jia2023taming,
  title={Taming encoder for zero fine-tuning image customization with text-to-image diffusion models},
  author={Jia, Xuhui and Zhao, Yang and Chan, Kelvin CK and Li, Yandong and Zhang, Han and Gong, Boqing and Hou, Tingbo and Wang, Huisheng and Su, Yu-Chuan},
  journal={arXiv preprint arXiv:2304.02642},
  year={2023}
}

@article{Su2023IdentityEF,
  title={Identity Encoder for Personalized Diffusion},
  author={Yu-Chuan Su and Kelvin C. K. Chan and Yandong Li and Yang Zhao and Han-Ying Zhang and Boqing Gong and H. Wang and Xuhui Jia},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.07429},
  url={https://api.semanticscholar.org/CorpusID:258179645}
}

@article{ye2023ip-adapter,
  title={IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models},
  author={Ye, Hu and Zhang, Jun and Liu, Sibo and Han, Xiao and Yang, Wei},
  journal={arXiv preprint arxiv:2308.06721},
  year={2023}
}

@article{alaluf2023neural,
  title={A Neural Space-Time Representation for Text-to-Image Personalization},
  author={Alaluf, Yuval and Richardson, Elad and Metzer, Gal and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={6},
  pages={1--10},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{Wang2023StyleAdapterAS,
  title={StyleAdapter: A Single-Pass LoRA-Free Model for Stylized Image Generation},
  author={Zhouxia Wang and Xintao Wang and Liangbin Xie and Zhongang Qi and Ying Shan and Wenping Wang and Ping Luo},
  journal={ArXiv},
  year={2023},
  volume={abs/2309.01770},
  url={https://api.semanticscholar.org/CorpusID:261531689}
}

@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press}
}

@article{jordan1994hierarchical,
  title={Hierarchical mixtures of experts and the EM algorithm},
  author={Jordan, Michael I and Jacobs, Robert A},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={181--214},
  year={1994},
  publisher={MIT Press}
}

@article{eigen2013learning,
  title={Learning factored representations in a deep mixture of experts},
  author={Eigen, David and Ranzato, Marc'Aurelio and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1312.4314},
  year={2013}
}

@article{wang2024moa,
  title={Moa: Mixture-of-attention for subject-context disentanglement in personalized image generation},
  author={Wang, Kuan-Chieh and Ostashev, Daniil and Fang, Yuwei and Tulyakov, Sergey and Aberman, Kfir},
  journal={arXiv preprint arXiv:2404.11565},
  year={2024}
}

@inproceedings{
shazeer2017,
title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
author={Noam Shazeer and *Azalia Mirhoseini and *Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=B1ckMDqlg}
}

@article{lepikhin2020gshard,
  title={Gshard: Scaling giant models with conditional computation and automatic sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  journal={arXiv preprint arXiv:2006.16668},
  year={2020}
}

@article{puigcerver2020scalable,
  title={Scalable transfer learning with expert models},
  author={Puigcerver, Joan and Riquelme, Carlos and Mustafa, Basil and Renggli, Cedric and Pinto, Andr{\'e} Susano and Gelly, Sylvain and Keysers, Daniel and Houlsby, Neil},
  journal={arXiv preprint arXiv:2009.13239},
  year={2020}
}

@article{riquelme2021scaling,
  title={Scaling vision with sparse mixture of experts},
  author={Riquelme, Carlos and Puigcerver, Joan and Mustafa, Basil and Neumann, Maxim and Jenatton, Rodolphe and Susano Pinto, Andr{\'e} and Keysers, Daniel and Houlsby, Neil},
  journal=NIPS,
  volume={34},
  pages={8583--8595},
  year={2021}
}

@article{artetxe2021efficient,
  title={Efficient large scale language modeling with mixtures of experts},
  author={Artetxe, Mikel and Bhosale, Shruti and Goyal, Naman and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Lin, Xi Victoria and Du, Jingfei and Iyer, Srinivasan and Pasunuru, Ramakanth and others},
  journal={arXiv preprint arXiv:2112.10684},
  year={2021}
}

@article{you2021speechmoe,
  title={Speechmoe: Scaling to large acoustic models with dynamic routing mixture of experts},
  author={You, Zhao and Feng, Shulin and Su, Dan and Yu, Dong},
  journal={arXiv preprint arXiv:2105.03036},
  year={2021}
}

@article{roller2021hash,
  title={Hash layers for large sparse models},
  author={Roller, Stephen and Sukhbaatar, Sainbayar and Weston, Jason and others},
  journal=NIPS,
  volume={34},
  pages={17555--17566},
  year={2021}
}

@inproceedings{lewis2021base,
  title={Base layers: Simplifying training of large, sparse models},
  author={Lewis, Mike and Bhosale, Shruti and Dettmers, Tim and Goyal, Naman and Zettlemoyer, Luke},
  booktitle={International Conference on Machine Learning},
  pages={6265--6274},
  year={2021},
  organization={PMLR}
}

@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={5232--5270},
  year={2022},
  publisher={JMLRORG}
}

@inproceedings{50136,title	= {Mixture of Informed Experts for Multilingual Speech Recognition},author	= {Neeraj Gaur and Brian Farris and Parisa Haghani and Isabel Leal and Pedro Jose Moreno Mengibar and Manasa Prasad and Bhuvana Ramabhadran and Yun Zhu},year	= {2021},booktitle	= {ICASSP 2021, IEEE International Conference on Acoustics, Speech and Signal Processing}}

@article{shen2023scaling,
  title={Scaling Vision-Language Models with Sparse Mixture of Experts},
  author={Shen, Sheng and Yao, Zhewei and Li, Chunyuan and Darrell, Trevor and Keutzer, Kurt and He, Yuxiong},
  journal={arXiv preprint arXiv:2303.07226},
  year={2023}
}

@article{zhu2023exploring,
  title={Exploring Sparse MoE in GANs for Text-conditioned Image Synthesis},
  author={Zhu, Jiapeng and Yang, Ceyuan and Zheng, Kecheng and Xu, Yinghao and Shi, Zifan and Shen, Yujun},
  journal={arXiv preprint arXiv:2309.03904},
  year={2023}
}

@article{xue2024raphael,
  title={Raphael: Text-to-image generation via large mixture of diffusion paths},
  author={Xue, Zeyue and Song, Guanglu and Guo, Qiushan and Liu, Boxiao and Zong, Zhuofan and Liu, Yu and Luo, Ping},
  journal=NIPS,
  volume={36},
  year={2024}
}

@article{mustafa2022multimodal,
  title={Multimodal contrastive learning with limoe: the language-image mixture of experts},
  author={Mustafa, Basil and Riquelme, Carlos and Puigcerver, Joan and Jenatton, Rodolphe and Houlsby, Neil},
  journal=NIPS,
  volume={35},
  pages={9564--9576},
  year={2022}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@inproceedings{FaRL,
  author       = {Yinglin Zheng and
                  Hao Yang and
                  Ting Zhang and
                  Jianmin Bao and
                  Dongdong Chen and
                  Yangyu Huang and
                  Lu Yuan and
                  Dong Chen and
                  Ming Zeng and
                  Fang Wen},
  title        = {General Facial Representation Learning in a Visual-Linguistic Manner},
  booktitle    = CVPR,
  pages        = {18676--18688},
  publisher    = {{IEEE}},
  year         = {2022}
}

@inproceedings{EsserKSD3,
  author       = {Patrick Esser and
                  Sumith Kulal and
                  Andreas Blattmann and
                  Rahim Entezari and
                  Jonas M{\"{u}}ller and
                  Harry Saini and
                  Yam Levi and
                  Dominik Lorenz and
                  Axel Sauer and
                  Frederic Boesel and
                  Dustin Podell and
                  Tim Dockhorn and
                  Zion English and
                  Robin Rombach},
  title        = {Scaling Rectified Flow Transformers for High-Resolution Image Synthesis},
  booktitle    = ICML,
  publisher    = {OpenReview.net},
  year         = {2024}
}

@misc{FLUX,
  author = {{Black Forest Labs}},
  title = {Flux},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/black-forest-labs/flux}}
}

@inproceedings{He2022MAE,
  author       = {Kaiming He and
                  Xinlei Chen and
                  Saining Xie and
                  Yanghao Li and
                  Piotr Doll{\'{a}}r and
                  Ross B. Girshick},
  title        = {Masked Autoencoders Are Scalable Vision Learners},
  booktitle    = CVPR,
  pages        = {15979--15988},
  publisher    = {{IEEE}},
  year         = {2022}
}

@inproceedings{Blanz3DMM,
  author       = {Volker Blanz and
                  Thomas Vetter},
  title        = {A Morphable Model for the Synthesis of 3D Faces},
  booktitle    = SIGGRAPH,
  pages        = {187--194},
  publisher    = {{ACM}},
  year         = {1999}
}

@article{rumelhart1986autoencoders,
  title={Learning internal representations by error propagation, parallel distributed processing, explorations in the microstructure of cognition, ed. de rumelhart and j. mcclelland. vol. 1. 1986},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Biometrika},
  volume={71},
  number={599-607},
  pages={6},
  year={1986}
}

@inproceedings{Dosovitskiy2021ViT,
  author       = {Alexey Dosovitskiy and
                  Lucas Beyer and
                  Alexander Kolesnikov and
                  Dirk Weissenborn and
                  Xiaohua Zhai and
                  Thomas Unterthiner and
                  Mostafa Dehghani and
                  Matthias Minderer and
                  Georg Heigold and
                  Sylvain Gelly and
                  Jakob Uszkoreit and
                  Neil Houlsby},
  title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition
                  at Scale},
  booktitle    = ICLR,
  publisher    = {OpenReview.net},
  year         = {2021}
}

@inproceedings{Peebles2023DiT,
  author       = {William Peebles and
                  Saining Xie},
  title        = {Scalable Diffusion Models with Transformers},
  booktitle    = ICCV,
  pages        = {4172--4182},
  publisher    = {{IEEE}},
  year         = {2023}
}


@article{yuan2023reliableswap,
    title={ReliableSwap: Boosting General Face Swapping Via Reliable Supervision},
    author={Yuan, Ge and Li, Maomao and Zhang, Yong and Zheng, Huicheng},
    journal={arXiv preprint arXiv:2306.05356},
    year={2023}
}

@InProceedings{Hopenet_Ruiz_2018_CVPR_Workshops,
author = {Ruiz, Nataniel and Chong, Eunji and Rehg, James M.},
title = {Fine-Grained Head Pose Estimation Without Keypoints},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2018}
}

@misc{ControlNet,
  title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
  author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
  booktitle=ICCV, 
  year={2023},
}
@inproceedings{CosFace,
  author       = {Hao Wang and
                  Yitong Wang and
                  Zheng Zhou and
                  Xing Ji and
                  Dihong Gong and
                  Jingchao Zhou and
                  Zhifeng Li and
                  Wei Liu},
  title        = {CosFace: Large Margin Cosine Loss for Deep Face Recognition},
  booktitle    = {{CVPR}},
  pages        = {5265--5274},
  publisher    = {Computer Vision Foundation / {IEEE} Computer Society},
  year         = {2018}
}


@inproceedings{zhu2021webface260m,
  title={Webface260m: A benchmark unveiling the power of million-scale deep face recognition},
  author={Zhu, Zheng and Huang, Guan and Deng, Jiankang and Ye, Yun and Huang, Junjie and Chen, Xinze and Zhu, Jiagang and Yang, Tian and Lu, Jiwen and Du, Dalong and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10492--10502},
  year={2021}
}

@article{FLAME:SiggraphAsia2017, 
  title = {Learning a model of facial shape and expression from {4D} scans}, 
  author = {Li, Tianye and Bolkart, Timo and Black, Michael. J. and Li, Hao and Romero, Javier}, 
  journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH Asia)}, 
  volume = {36}, 
  number = {6}, 
  year = {2017}, 
  pages = {194:1--194:17},
  url = {https://doi.org/10.1145/3130800.3130813} 
}

@ARTICLE{FaceWarehouse,
  author={Cao, Chen and Weng, Yanlin and Zhou, Shun and Tong, Yiying and Zhou, Kun},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={FaceWarehouse: A 3D Facial Expression Database for Visual Computing}, 
  year={2014},
  volume={20},
  number={3},
  pages={413-425},
  keywords={Face;Three-dimensional displays;Databases;Solid modeling;Computational modeling;Mouth;Color;Face modeling;facial animation;face database;mesh deformation;RGBD camera},
  doi={10.1109/TVCG.2013.249}}

@inproceedings{10.1145/311535.311556,
author = {Blanz, Volker and Vetter, Thomas},
title = {A morphable model for the synthesis of 3D faces},
year = {1999},
isbn = {0201485605},
publisher = {ACM Press/Addison-Wesley Publishing Co.},
address = {USA},
url = {https://doi.org/10.1145/311535.311556},
doi = {10.1145/311535.311556},
abstract = {In this paper, a new technique for modeling textured 3D faces is introduced. 3D faces can either be generated automatically from one or more photographs, or modeled directly through an intuitive user interface. Users are assisted in two key problems of computer aided face modeling. First, new face images or new 3D face models can be registered automatically by computing dense one-to-one correspondence to an internal face model. Second, the approach regulates the naturalness of modeled faces avoiding faces with an "unlikely" appearance.Starting from an example set of 3D face models, we derive a morphable face model by transforming the shape and texture of the examples into a vector space representation. New faces and expressions can be modeled by forming linear combinations of the prototypes. Shape and texture constraints derived from the statistics of our example faces are used to guide manual modeling or automated matching algorithms.We show 3D face reconstructions from single images and their applications for photo-realistic image manipulations. We also demonstrate face manipulations according to complex parameters such as gender, fullness of a face or its distinctiveness.},
booktitle = {Proceedings of the 26th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {187–194},
numpages = {8},
keywords = {computer vision, facial animation, facial modeling, morphing, photogrammetry, registration},
series = {SIGGRAPH '99}
}



@inproceedings{abdal2019image2stylegan,
  title={Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?},
  author={Abdal, Rameen and Qin, Yipeng and Wonka, Peter},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4432--4441},
  year={2019}
}

@inproceedings{harkonen2020ganspace,
  title={GANSpace: Discovering Interpretable GAN Controls},
  author={H{\"a}rk{\"o}nen, Erik and Hertzmann, Aaron and Lehtinen, Jaakko and Paris, Sylvain},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9841--9850},
  year={2020}
}

@inproceedings{abdal2020styleflow,
  title={StyleFlow: Attribute-conditioned exploration of StyleGAN-generated images using conditional continuous normalizing flows},
  author={Abdal, Rameen and Zhu, Peihao and Mitra, Niloy J and Wonka, Peter},
  booktitle={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={4},
  pages={1--21},
  year={2020},
  publisher={ACM}
}

@inproceedings{chen2020simswap,
  title={SimSwap: An efficient framework for high fidelity face swapping},
  author={Chen, Renwang and Zhang, Zhangyang and Lu, Juyong and Li, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6575--6584},
  year={2020}
}


@inproceedings{E4S,
  author       = {Maomao Li and
                  Ge Yuan and
                  Cairong Wang and
                  Zhian Liu and
                  Yong Zhang and
                  Yongwei Nie and
                  Jue Wang and
                  Dong Xu},
  title        = {{E4S:} Fine-grained Face Swapping via Editing With Regional {GAN}
                  Inversion},
  journal      = CVPR,
  year         = {2023}
}

@article{Arc2Face,
  author       = {Foivos Paraperas Papantoniou and
                  Alexandros Lattas and
                  Stylianos Moschoglou and
                  Jiankang Deng and
                  Bernhard Kainz and
                  Stefanos Zafeiriou},
  title        = {Arc2Face: {A} Foundation Model of Human Faces},
  journal      = {CoRR},
  volume       = {abs/2403.11641},
  year         = {2024}
}


@inproceedings{CelebVHQ,
  author       = {Hao Zhu and
                  Wayne Wu and
                  Wentao Zhu and
                  Liming Jiang and
                  Siwei Tang and
                  Li Zhang and
                  Ziwei Liu and
                  Chen Change Loy},
  title        = {CelebV-HQ: {A} Large-Scale Video Facial Attributes Dataset},
  booktitle    = ECCV,
  series       = {Lecture Notes in Computer Science},
  volume       = {13667},
  pages        = {650--667},
  publisher    = {Springer},
  year         = {2022}
}


@inproceedings{VFHQ,
  author       = {Liangbin Xie and
                  Xintao Wang and
                  Honglun Zhang and
                  Chao Dong and
                  Ying Shan},
  title        = {{VFHQ:} {A} High-Quality Dataset and Benchmark for Video Face Super-Resolution},
  booktitle    = {{CVPR} Workshops},
  pages        = {656--665},
  publisher    = {{IEEE}},
  year         = {2022}
}


@inproceedings{wang2021facevid2vid,
    title={One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing},
    author={Ting-Chun Wang and Arun Mallya and Ming-Yu Liu},
    booktitle=CVPR,
    year={2021}
}


@inproceedings{CelebV-Text,
  author       = {Jianhui Yu and
                  Hao Zhu and
                  Liming Jiang and
                  Chen Change Loy and
                  Weidong Cai and
                  Wayne Wu},
  title        = {CelebV-Text: {A} Large-Scale Facial Text-Video Dataset},
  booktitle    = CVPR,
  pages        = {14805--14814},
  publisher    = {{IEEE}},
  year         = {2023}
}


@InProceedings{HopeNet,
author = {Ruiz, Nataniel and Chong, Eunji and Rehg, James M.},
title = {Fine-Grained Head Pose Estimation Without Keypoints},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2018}
}


@misc{flux_controlnet,
  author       = {XLabs-AI},
  title        = {Flux-ControlNet Collections},
  howpublished = {\url{https://huggingface.co/XLabs-AI/flux-controlnet-collections}},
  year         = {2024},
  note         = {Accessed: 2024-11-13}
}

@article{PuLID,
  author       = {Zinan Guo and
                  Yanze Wu and
                  Zhuowei Chen and
                  Lang Chen and
                  Qian He},
  title        = {PuLID: Pure and Lightning {ID} Customization via Contrastive Alignment},
  journal      = {CoRR},
  volume       = {abs/2404.16022},
  year         = {2024}
}

@article{chen2024topiq,
  author={Chen, Chaofeng and Mo, Jiadi and Hou, Jingwen and Wu, Haoning and Liao, Liang and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
  title={TOPIQ: A Top-Down Approach From Semantics to Distortions for Image Quality Assessment}, 
  journal={IEEE Transactions on Image Processing}, 
  year={2024},
  volume={33},
  pages={2404-2418},
  doi={10.1109/TIP.2024.3378466}
}

@inproceedings{aberman2019deep,
  title={Deep video-based performance cloning},
  author={Aberman, Kfir and Shi, Mingyi and Liao, Jing and Lischinski, Dani and Chen, Baoquan and Cohen-Or, Daniel},
  booktitle={Computer Graphics Forum},
  volume={38},
  number={2},
  pages={219--233},
  year={2019},
  organization={Wiley Online Library}
}

@inproceedings{menapace2024snap,
  title={Snap video: Scaled spatiotemporal transformers for text-to-video synthesis},
  author={Menapace, Willi and Siarohin, Aliaksandr and Skorokhodov, Ivan and Deyneka, Ekaterina and Chen, Tsai-Shien and Kag, Anil and Fang, Yuwei and Stoliar, Aleksei and Ricci, Elisa and Ren, Jian and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7038--7048},
  year={2024}
}

@misc{insightface,
  author       = {InsightFace Contributors},
  title        = {InsightFace: 2D and 3D Face Analysis Project},
  year         = {2024},
  howpublished = {\url{https://github.com/deepinsight/insightface}},
  note         = {Accessed: 2024-11-15}
}


@inproceedings{SDXL,
  author       = {Dustin Podell and
                  Zion English and
                  Kyle Lacey and
                  Andreas Blattmann and
                  Tim Dockhorn and
                  Jonas M{\"{u}}ller and
                  Joe Penna and
                  Robin Rombach},
  title        = {{SDXL:} Improving Latent Diffusion Models for High-Resolution Image
                  Synthesis},
  booktitle    = ICLR,
  publisher    = {OpenReview.net},
  year         = {2024}
}

@article{polyak2024movie,
  title={Movie gen: A cast of media foundation models},
  author={Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others},
  journal={arXiv preprint arXiv:2410.13720},
  year={2024}
}

@article{sora,
  title={SORA},
  author={OPENAI},
  journal={https://openai.com/sora/},
  year={2024}
}

@article{veo2,
  title={VEO2},
  author={Google DeepMind},
  journal={https://deepmind.google/technologies/veo/veo-2/},
  year={2024}
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

@inproceedings{bar2024lumiere,
  title={Lumiere: A space-time diffusion model for video generation},
  author={Bar-Tal, Omer and Chefer, Hila and Tov, Omer and Herrmann, Charles and Paiss, Roni and Zada, Shiran and Ephrat, Ariel and Hur, Junhwa and Liu, Guanghui and Raj, Amit and others},
  booktitle={SIGGRAPH Asia 2024 Conference Papers},
  pages={1--11},
  year={2024}
}


@article{hong2022cogvideo,
  title={Cogvideo: Large-scale pretraining for text-to-video generation via transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

@article{yang2024cogvideox,
  title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}

@Misc{modelscope,
  title = {ModelScope: bring the notion of Model-as-a-Service to life.},
  author = {The ModelScope Team},
  howpublished = {\url{https://github.com/modelscope/modelscope}},
  year = {2023}
}

@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@article{wang2024motionctrl,
  title={MotionCtrl: A Unified and Flexible Motion Controller for Video Generation},
  author={Wang, Zhouxia and Yuan, Ziyang and Wang, Xintao and Li, Yaowei and Chen, Tianshui and Xia, Menghan and Luo, Ping and Shan, Ying},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  year={2023}
}


@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}


@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  year={2023}
}


@misc{he2024idanimatorzeroshotidentitypreservinghuman,
      title={ID-Animator: Zero-Shot Identity-Preserving Human Video Generation}, 
      author={Xuanhua He and Quande Liu and Shengju Qian and Xin Wang and Tao Hu and Ke Cao and Keyu Yan and Jie Zhang},
      year={2024},
      eprint={2404.15275},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.15275}, 
}

@misc{ma2024magicmeidentityspecificvideocustomized,
      title={Magic-Me: Identity-Specific Video Customized Diffusion}, 
      author={Ze Ma and Daquan Zhou and Chun-Hsiao Yeh and Xue-She Wang and Xiuyu Li and Huanrui Yang and Zhen Dong and Kurt Keutzer and Jiashi Feng},
      year={2024},
      eprint={2402.09368},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.09368}, 
}


@misc{zhang2024moonshotcontrollablevideogeneration,
      title={Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions}, 
      author={David Junhao Zhang and Dongxu Li and Hung Le and Mike Zheng Shou and Caiming Xiong and Doyen Sahoo},
      year={2024},
      eprint={2401.01827},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2401.01827}, 
}

@misc{zhou2024storydiffusionconsistentselfattentionlongrange,
      title={StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation}, 
      author={Yupeng Zhou and Daquan Zhou and Ming-Ming Cheng and Jiashi Feng and Qibin Hou},
      year={2024},
      eprint={2405.01434},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.01434}, 
}

@article{wu2024customttt,
        title={CustomTTT: Motion and Appearance Customized Video Generation via Test-Time Training},
        author={Bi, Xiuli and Lu, Jian and Liu, Bo and Cun, Xiaodong and Zhang, Yong and Li, WeiSheng and Xiao, Bin},
        journal={arXiv preprint arXiv:2412.15646},
        year={2024}
      }


@inproceedings{wei2023dreamvideo,
  title={DreamVideo: Composing Your Dream Videos with Customized Subject and Motion},
  author={Wei, Yujie and Zhang, Shiwei and Qing, Zhiwu and Yuan, Hangjie and Liu, Zhiheng and Liu, Yu and Zhang, Yingya and Zhou, Jingren and Shan, Hongming},
  booktitle={CVPR},
  year={2024}
}


@inproceedings{liew2023magicedit,
    author = {Liew, Jun Hao and Yan, Hanshu and Zhang, Jianfeng and Xu, Zhongcong and Feng, Jiashi},
    title = {MagicEdit: High-Fidelity and Temporally Coherent Video Editing},
    booktitle={arXiv},
    year = {2023}
}

@inproceedings{materzynska2024newmove,
  title={NewMove: Customizing text-to-video models with novel motions},
  author={Materzy{\'n}ska, Joanna and Sivic, Josef and Shechtman, Eli and Torralba, Antonio and Zhang, Richard and Russell, Bryan},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={1634--1651},
  year={2024}
}

@article{bai2024uniedit,
            title={UniEdit: A Unified Tuning-Free Framework for Video Motion and Appearance Editing},
            author={Bai, Jianhong and He, Tianyu and Wang, Yuchi and Guo, Junliang and Hu, Haoji and Liu, Zuozhu and Bian, Jiang},
            journal={arXiv preprint arXiv:2402.13185},
            year={2024}
          }

@misc{wu2023tuneavideooneshottuningimage,
      title={Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation}, 
      author={Jay Zhangjie Wu and Yixiao Ge and Xintao Wang and Weixian Lei and Yuchao Gu and Yufei Shi and Wynne Hsu and Ying Shan and Xiaohu Qie and Mike Zheng Shou},
      year={2023},
      eprint={2212.11565},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.11565}, 
}

@article{qi2023fatezero,
        title={FateZero: Fusing Attentions for Zero-shot Text-based Video Editing}, 
        author={Chenyang Qi and Xiaodong Cun and Yong Zhang and Chenyang Lei and Xintao Wang and Ying Shan and Qifeng Chen},
        year={2023},
        journal={arXiv:2303.09535},
}

@article{tokenflow2023,
        title = {TokenFlow: Consistent Diffusion Features for Consistent Video Editing},
        author = {Geyer, Michal and Bar-Tal, Omer and Bagon, Shai and Dekel, Tali},
        journal={arXiv preprint arxiv:2307.10373},
        year={2023}
        }


@inproceedings{cai2023genren,
                            author={Cai, Shengqu and Ceylan, Duygu and Gadelha, Matheus
                                    and Huang, Chun-Hao and Wang, Tuanfeng and Wetzstein, Gordon.},
                            title={Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models},
                            booktitle={CVPR},
                            year={2024}
                        }       

@inproceedings{kara2024rave,
  title={RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models},
  author={Ozgur Kara and Bariscan Kurtkaya and Hidir Yesiltepe and James M. Rehg and Pinar Yanardag},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{liang2023flowvid,
  title={FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis},
  author={Liang, Feng and Wu, Bichen and Wang, Jialiang and Yu, Licheng and Li, Kunpeng and Zhao, Yinan and Misra, Ishan and Huang, Jia-Bin and Zhang, Peizhao and Vajda, Peter and others},
  journal={arXiv preprint arXiv:2312.17681},
  year={2023}
}

@article{ren2024customize,
  title={Customize-a-video: One-shot motion customization of text-to-video diffusion models},
  author={Ren, Yixuan and Zhou, Yang and Yang, Jimei and Shi, Jing and Liu, Difan and Liu, Feng and Kwon, Mingi and Shrivastava, Abhinav},
  journal={arXiv preprint arXiv:2402.14780},
  year={2024}
}

@misc{molad2023dreamixvideodiffusionmodels,
      title={Dreamix: Video Diffusion Models are General Video Editors}, 
      author={Eyal Molad and Eliahu Horwitz and Dani Valevski and Alex Rav Acha and Yossi Matias and Yael Pritch and Yaniv Leviathan and Yedid Hoshen},
      year={2023},
      eprint={2302.01329},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2302.01329}, 
}


@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@misc{
chen2024videoalchemy,
title={VideoAlchemy: Open-set Personalization in Video Generation},
author={Tsai-Shien Chen and Aliaksandr Siarohin and Willi Menapace and Yuwei Fang and Ivan Skorokhodov and Jun-Yan Zhu and Kfir Aberman and Ming-Hsuan Yang and Sergey Tulyakov},
year={2024},
url={https://openreview.net/forum?id=popKM1zAYa}
}

@article{ren2024consisti2v,
  title={ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation},
  author={Ren, Weiming and Yang, Harry and Zhang, Ge and Wei, Cong and Du, Xinrun and Huang, Stephen and Chen, Wenhu},
  journal={arXiv preprint arXiv:2402.04324},
  year={2024}
}

@misc{atomovideo,
      title={AtomoVideo: High Fidelity Image-to-Video Generation},
      author={Gong, Litong and Zhu, Yiran and Li, Weijie and Kang, Xiaoyang and Wang, Biao and Ge, Tiezheng and Zheng, Bo},
      year={2024},
      eprint={arXiv:2403.01800},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{dai2023animateanything,
      title={AnimateAnything: Fine-Grained Open Domain Image Animation with Motion Guidance}, 
      author={Zuozhuo Dai and Zhenghao Zhang and Yao Yao and Bingxue Qiu and Siyu Zhu and Long Qin and Weizhi Wang},
      year={2023},
      eprint={2311.12886},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{HaCohen2024LTXVideo,
  title={LTX-Video: Realtime Video Latent Diffusion},
  author={HaCohen, Yoav and Chiprut, Nisan and Brazowski, Benny and Shalem, Daniel and Moshe, Dudu and Richardson, Eitan and Levin, Eran and Shiran, Guy and Zabari, Nir and Gordon, Ori and Panet, Poriya and Weissbuch, Sapir and Kulikov, Victor and Bitterman, Yaki and Melumian, Zeev and Bibi, Ofir},
  journal={arXiv preprint arXiv:2501.00103},
  year={2024}
}

@misc{qian2024omniidholisticidentityrepresentation,
      title={Omni-ID: Holistic Identity Representation Designed for Generative Tasks}, 
      author={Guocheng Qian and Kuan-Chieh Wang and Or Patashnik and Negin Heravi and Daniil Ostashev and Sergey Tulyakov and Daniel Cohen-Or and Kfir Aberman},
      year={2024},
      eprint={2412.09694},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.09694}, 
}

@misc{wang2024moamixtureofattentionsubjectcontextdisentanglement,
      title={MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation}, 
      author={Kuan-Chieh Wang and Daniil Ostashev and Yuwei Fang and Sergey Tulyakov and Kfir Aberman},
      year={2024},
      eprint={2404.11565},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.11565}, 
}

@INPROCEEDINGS{9709990,
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jegou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Emerging Properties in Self-Supervised Vision Transformers}, 
  year={2021},
  volume={},
  number={},
  pages={9630-9640},
  keywords={Training;Image segmentation;Computer vision;Semantics;Layout;Image retrieval;Computer architecture;Representation learning;Recognition and classification;Transfer/Low-shot/Semi/Unsupervised Learning},
  doi={10.1109/ICCV48922.2021.00951}}

@misc{liu2024unziploraseparatingcontentstyle,
      title={UnZipLoRA: Separating Content and Style from a Single Image}, 
      author={Chang Liu and Viraj Shah and Aiyu Cui and Svetlana Lazebnik},
      year={2024},
      eprint={2412.04465},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.04465}, 
}

@misc{jones2024customizingtexttoimagemodelssingle,
      title={Customizing Text-to-Image Models with a Single Image Pair}, 
      author={Maxwell Jones and Sheng-Yu Wang and Nupur Kumari and David Bau and Jun-Yan Zhu},
      year={2024},
      eprint={2405.01536},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.01536}, 
}

@article{zhao2023motiondirector,
  title={MotionDirector: Motion Customization of Text-to-Video Diffusion Models},
  author={Zhao, Rui and Gu, Yuchao and Wu, Jay Zhangjie and Zhang, David Junhao and Liu, Jiawei and Wu, Weijia and Keppo, Jussi and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2310.08465},
  year={2023}
}

@article{zhang2023motioncrafter,
  title={MotionCrafter: One-Shot Motion Customization of Diffusion Models},
  author={Zhang, Yuxin and Tang, Fan and Huang, Nisha and Huang, Haibin and Ma, Chongyang and Dong, Weiming and Xu, Changsheng},
  journal={arXiv preprint arXiv:2312.05288},
  year={2023}
}

@inproceedings{
    yu2024language,
    title={Language Model Beats Diffusion - Tokenizer is key to visual generation},
    author={Lijun Yu and Jose Lezama and Nitesh Bharadwaj Gundavarapu and Luca Versari and Kihyuk Sohn and David Minnen and Yong Cheng and Agrim Gupta and Xiuye Gu and Alexander G Hauptmann and Boqing Gong and Ming-Hsuan Yang and Irfan Essa and David A Ross and Lu Jiang},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=gzqrANCF4g}
}

@article{su2024roformer,
title = {RoFormer: Enhanced transformer with Rotary Position Embedding},
journal = {Neurocomputing},
volume = {568},
pages = {127063},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.127063},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223011864},
author = {Jianlin Su and Murtadha Ahmed and Yu Lu and Shengfeng Pan and Wen Bo and Yunfeng Liu},
keywords = {Pre-trained language models, Position information encoding, Pre-training, Natural language processing},
abstract = {Position encoding has recently been shown to be effective in transformer architecture. It enables valuable supervision for dependency modeling between elements at different positions of the sequence. In this paper, we first investigate various methods to integrate positional information into the learning process of transformer-based language models. Then, we propose a novel method named Rotary Position Embedding (RoPE) to effectively leverage the positional information. Specifically, the proposed RoPE encodes the absolute position with a rotation matrix and meanwhile incorporates the explicit relative position dependency in the self-attention formulation. Notably, RoPE enables valuable properties, including the flexibility of sequence length, decaying inter-token dependency with increasing relative distances, and the capability of equipping linear self-attention with relative position encoding. Finally, we evaluate the enhanced transformer with rotary position embedding, also called RoFormer, on various long text classification benchmark datasets. Our experiments show that it consistently overcomes its alternatives. Furthermore, we provide a theoretical analysis to explain some experimental results. RoFormer is already integrated into Huggingface: https://huggingface.co/docs/transformers/model_doc/roformer.}
}

@article{raffel2020t5,
author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pretraining objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {140},
numpages = {67},
keywords = {deep learning, attention based models, multi-task learning, natural language processing, transfer learning}
}

@inproceedings{dao2023flashattention2,
  title={Flash{A}ttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author={Dao, Tri},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@misc{zhao2023pytorchfsdpexperiencesscaling,
      title={PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel}, 
      author={Yanli Zhao and Andrew Gu and Rohan Varma and Liang Luo and Chien-Chin Huang and Min Xu and Less Wright and Hamid Shojanazeri and Myle Ott and Sam Shleifer and Alban Desmaison and Can Balioglu and Pritam Damania and Bernard Nguyen and Geeta Chauhan and Yuchen Hao and Ajit Mathews and Shen Li},
      year={2023},
      eprint={2304.11277},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2304.11277}, 
}

@inproceedings{
loshchilov2018decoupled,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

@misc{simo,
      title={DreamboothLoRA},
 year={2023},
      author={Simo Ryu},
      url={https://github.com/cloneofsimo/lora}, 
}

@article{FlowStraightAndFast,
  title={Flow straight and fast: Learning to generate and transfer data with rectified flow},
  author={Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  journal={arXiv preprint arXiv:2209.03003},
  year={2022}
}

@article{NormFlowStochInterp,
  title={Building normalizing flows with stochastic interpolants},
  author={Albergo, Michael S and Vanden-Eijnden, Eric},
  journal={arXiv preprint arXiv:2209.15571},
  year={2022}
}

@inproceedings{U-net,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{HunyuanVideo,
  title={HunyuanVideo: A Systematic Framework For Large Video Generative Models},
  author={Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others},
  journal={arXiv preprint arXiv:2412.03603},
  year={2024}
}

@inproceedings{RIN,
    author = {Jabri, Allan and Fleet, David J. and Chen, Ting},
    title = {Scalable adaptive computation for iterative generation},
    year = {2023},
    publisher = {JMLR.org},
    abstract = {Natural data is redundant yet predominant architectures tile computation uniformly across their input and output space. We propose the Recurrent Interface Network (RIN), an attention-based architecture that decouples its core computation from the dimensionality of the data, enabling adaptive computation for more scalable generation of high-dimensional data. RINs focus the bulk of computation (i.e. global self-attention) on a set of latent tokens, using cross-attention to read and write (i.e. route) information between latent and data tokens. Stacking RIN blocks allows bottomup (data to latent) and top-down (latent to data) feedback, leading to deeper and more expressive routing. While this routing introduces challenges, this is less problematic in recurrent computation settings where the task (and routing problem) changes gradually, such as iterative generation with diffusion models. We show how to leverage recurrence by conditioning the latent tokens at each forward pass of the reverse diffusion process with those from prior computation, i.e. latent self-conditioning. RINs yield state-of-the-art pixel diffusion models for image and video generation, scaling to 1024\texttimes{}1024 images without cascades or guidance, while being domain-agnostic and up to 10\texttimes{} more efficient than 2D and 3D U-Nets.},
    booktitle = {Proceedings of the 40th International Conference on Machine Learning},
    articleno = {594},
    numpages = {21},
    location = {Honolulu, Hawaii, USA},
    series = {ICML'23}
}


