
% \vspace{-0.3cm}
\section{Limitations}

While our framework achieves state-of-the-art performance in video personalization and dynamic concept modeling, it does have limitations. The training process, which involves LoRA optimization with additional regularization, can be computationally intensive. An encoder based approach would be an ideal solution for future work. Additionally, while the method captures most motions with high fidelity, it may struggle with high-frequency or highly complex motion patterns, such as erratic or rapid movements, where temporal consistency could be further improved. These challenges present opportunities for future work to enhance efficiency, speed, and robustness in handling more dynamic scenarios.


\section{Conclusion}

We introduced a novel framework for personalized video generation that captures dynamic concepts using a two-stage \textit{Set-and-Sequence} paradigm i.e. the first stage of identity encoding and then learning coupled motion residuals on the top. By embedding these concepts into this unified spatio-temporal weight space, our method achieves high fidelity in appearance preservation, motion coherence, and text adherence, surpassing state-of-the-art baselines. The evaluations demonstrated versatility of our framework in editing and composition, while maintaining identity and motion fidelity. The ability to compose and adapt dynamic concepts in novel ways highlights the transformative potential of our approach. This work addresses long-standing challenges in video personalization and sets a new benchmark for personalized and compositional video generation.