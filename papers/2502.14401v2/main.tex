% This is a modified version of Springer's LNCS template suitable for anonymized MICCAI 2025 main conference submissions. 
% Original file: samplepaper.tex, a sample chapter demonstrating the LLNCS macro package for Springer Computer Science proceedings; Version 2.21 of 2022/01/12

\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encodings may result in incorrect characters.
%
\usepackage{graphicx,verbatim}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{siunitx}
\usepackage{tikz}
\usepackage{orcidlink}

\DeclareMathOperator*{\argmin}{arg\,min}

% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}

%
\begin{document}
%
\title{MedFuncta: Modality-Agnostic Representations Based on Efficient Neural Fields}
\titlerunning{Modality-Agnostic Representations Based on Efficient Neural Fields}
%
\author{Paul Friedrich\orcidlink{0000-0003-3653-5624} \and
Florentin Bieder\orcidlink{0000-0001-9558-0623} \and
Philippe C. Cattin\orcidlink{0000-0001-8785-2713}}
%
\authorrunning{P. Friedrich et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Department of Biomedical Engineering, University of Basel, Allschwil, Switzerland\\
\email{paul.friedrich@unibas.ch}}
 
\maketitle              % typeset the header of the contribution
%
%
%
% ---- Abstract ----
\begin{abstract}
Recent research in medical image analysis with deep learning almost exclusively focuses on grid- or voxel-based data representations. We challenge this common choice by introducing MedFuncta, a modality-agnostic continuous data representation based on neural fields. We demonstrate how to scale neural fields from single instances to large datasets by exploiting redundancy in medical signals and by applying an efficient meta-learning approach with a context reduction scheme. We further address the spectral bias in commonly used SIREN activations, by introducing an $\omega_0$-schedule, improving reconstruction quality and convergence speed. We validate our proposed approach on a large variety of medical signals of different dimensions and modalities (1D: ECG; 2D: Chest X-ray, Retinal OCT, Fundus Camera, Dermatoscope, Colon Histopathology, Cell Microscopy; 3D: Brain MRI, Lung CT) and successfully demonstrate that we can solve relevant downstream tasks on these representations. We additionally release a large-scale dataset of $> \SI{550}{k}$ annotated neural fields to promote research in this direction. The project page is available at \url{https://pfriedri.github.io/medfuncta-io/}.
\keywords{Neural Fields \and Modality-Agnostic \and Representation Learning \and Meta-Learning.}
% Authors must provide keywords and are not allowed to remove this Keyword section.
\end{abstract}
%
%
%
% ---- Introduction ----
\section{Introduction}
It is a common choice to represent data on discretized grids, e.g., to represent an image as a grid of pixels. While this data representation is widely explored, it poorly scales with grid resolution and ignores the often continuous nature of the underlying signal \cite{dupont2022data}. Recent research has shown that neural fields (NFs) provide an interesting, continuous alternative to represent different kinds of data modalities like sound \cite{sitzmann2020implicit}, images \cite{stanley2007compositional}, shapes \cite{mescheder2019occupancy}, or 3D scenes \cite{mildenhall2021nerf}, by treating data as a neural function that takes a spatial position (e.g., a pixel coordinate) as input and outputs the appropriate measurement (e.g., an image intensity value).
This work investigates how to find meaningful functional representations of medical data, allowing relevant downstream tasks to be solved on this modality-agnostic representation rather than the original signal, mitigating the need to design modality-specific networks. To do this, we need to scale NFs from single instances to large datasets. While previous work on similar ideas exists \cite{du2021learning,dupont2022data}, a high computational burden, limited reconstruction quality and the inability to scale to high-resolution signals remain main limitations. This work is the first to explore a Functa-like approach \cite{dupont2022data} in the medical domain, addressing these limitations by introducing a SIREN activation with an $\omega_0$-schedule that significantly improves the reconstruction quality and speeds up the training procedure. We additionally propose an efficient meta-learning approach with a context reduction scheme, effectively reducing the computational overhead and scaling our method to high-resolution signals. Unlike other work that addresses these limitations \cite{bauer2023spatial,dupont2022coin++}, we do not rely on patch-based representations. Our approach represents each signal with a single 1D latent vector per subject, a critical requirement that ultimately allows the application of similar downstream networks to input data of different dimensions and modalities.
%
%
%
% ---- Parameter-Efficient Neural Fields ----
\section{Parameter-Efficient Neural Fields}
In this work, we aim to find parameter-efficient NFs for $N$ signals 
$\{s_{1}, ..., s_{N}\}$, e.g., a set of images, by learning a functional representation of the signal $s_i$ given some context set $\mathcal{C}^{(i)}:=\{(\mathbf{x}_j,\mathbf{y}_j)\}_{j=1}^{M}$ with $M$ coordinate-value pairs $(\mathbf{x}_j,\mathbf{y}_j)$, where $\mathbf{x}_j\in \mathbb{R}^C$ and $\mathbf{y}_j\in \mathbb{R}^D$. While parameterizing such a function as a neural network $f_{\theta}:\mathbb{R}^C\to\mathbb{R}^D$, with all parameters $\theta$ being optimized to fit a single signal is widely explored~\cite{mildenhall2021nerf,saragadam2023wire,sitzmann2020implicit}, this approach is suboptimal for our problem setting for two key reasons: (1) We aim to find efficient representations that minimize the number of parameters optimized per signal by exploiting redundancy. (2) Neural network weights are permutation-invariant, meaning reordering neurons within a layer changes the weight matrix but not the represented function. This makes direct operations on the network weights $\theta$ difficult~\cite{navon2023equivariant}. As we want to learn on these NFs, we require a permutation-equivariant parameterization.
%
%
%
% ---- Signals as Network Modulations ----
\subsubsection{Signals as Network Modulations}
\label{subsec:modulation}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/Network.pdf}
    \caption{\textit{(Left)} The proposed network architecture with shared network parameters $\theta$, that is conditioned by a single signal-specific parameter vector $\phi^{(i)}$. \textit{(Right)} The proposed meta-learning strategy that, starting from a random initialization of $\theta$, learns shared network parameters $\theta^{*}$ in such a way, that we can fit signal-specific parameters $\phi^{(i)}$ in a few update steps.}
    \label{fig:network}
\end{figure}
We argue that most signals, especially in medicine, contain large amounts of redundant information or structure that we can learn over an entire set of signals. We therefore define a neural network $f_{\theta,\phi^{(i)}}:\mathbb{R}^C\rightarrow\mathbb{R}^D$ with shared network parameters $\theta$ that represents this redundant information and additional permutation-equivariant signal-specific parameters $\phi^{(i)}\in\mathbb{R}^{P}$ that condition the base network to represent a specific signal $s_i$. We apply a $K$-layer MLP architecture with a hidden dimension of $L$ and modulated SIREN activations \cite{mehta2021modulated,sitzmann2020implicit}, where each layer is defined as:
\begin{equation}
    x \mapsto \sin(\omega_{0,k}(\mathbf{W}_kx+\mathbf{b}_k+\mathbf{m}_k(\phi^{(i)}))) + x,
\end{equation}
with $\mathbf{W}_k$ and $\mathbf{b}_k$ being the weights and biases of the $k$-th layer, and $\mathbf{m}_k(\cdot)$ being a linear layer that maps the signal-specific parameters $\phi^{(i)}$ to a shift-modulation vector that is added in the base networks nonlinearity \cite{perez2018film}. While recent research treats $\omega_{0}$ as a single hyperparameter that remains constant over all network layers \cite{dupont2022coin++,dupont2022data,sitzmann2020implicit}, we identify this as a main restriction, limiting the networks expressiveness by inducing a strong spectral bias. Following the intuition, that the first network layers learn the low-frequency content of the signal and subsequent layers add more and more high-frequency information, we introduce a $\omega_0$-schedule that linearly increases $\omega_{0,k}$ from $\omega_{0,1}$ to $\omega_{0,K}$. The weights and biases of the network are initialized according to Sitzmann et al. \cite{sitzmann2020implicit}:
\begin{equation}
    \textbf{W}_k, \textbf{b}_k \sim \mathcal{U}(-\frac{\sqrt{6/n}}{\omega_{0,k}},\frac{\sqrt{6/n}}{\omega_{0,k}}),
\end{equation}
with $n$ being the layers input dimension and the first layers weights and biases being initialized as $\textbf{W}_1, \textbf{b}_1 \sim \mathcal{U}(-1/n, 1/n)$. The network architecture is shown in Fig. \ref{fig:network}. 
%
%
%
% ---- Meta-Learning Shared Network Parameters ----
\subsubsection{Meta-Learning Shared Network Parameters}
To efficiently create a set of NFs, we aim to meta-learn the shared parameters $\theta$ so that we can fit a signal $s_i$ by only optimizing $\phi^{(i)}$ for very few update steps \cite{dupont2022coin++,dupont2022data} 
(see Fig. \ref{fig:network}). We follow a CAVIA approach \cite{zintgraf2019fast}, shown in Fig. \ref{fig:meta_learn}, by defining an optimization process over the shared model parameters
\begin{equation}
    \theta^{*} = \argmin_{\theta}\frac{1}{N}\sum_{i=1}^{N}\mathcal{L}_{\mathtt{MSE}}(\phi_G^{(i)},\theta;\mathcal{C}^{(i)}),
\end{equation}
where in each \emph{meta/outer-loop} update step (i.e., the optimization of $\theta$), the \emph{inner-loop} optimizes $\phi^{(i)}$ from scratch ($\phi_0^{(i)} := \vec 0$), performing $G$ update steps 
\begin{equation}
    \phi_{g+1}^{(i)} := \phi_g^{(i)}- \alpha \nabla_\phi \mathcal L_{\texttt{MSE}}(\phi_g^{(i)}, \theta, \mathcal{C}^{(i)})
\end{equation}
using SGD with a fixed learning-rate $\alpha$. The meta-update is performed using AdamW \cite{loshchilov2019decoupled} with a learning-rate $\beta$.
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/LearningFitting.pdf}
    \caption{\textit{(Left)} The proposed approach for meta-learning the shared parameters $\theta$. We perform $G$ inner-loop updates, before performing a single meta-update. To compensate for the expensive second-order optimization, we reduce the context set $\mathcal{C}_{\mathtt{red}}$ in the inner-loop. \textit{(Right)} The proposed test time adaptation scheme. There is no need to update $\theta$ at test-time, which allows us to use the full context set $\mathcal{C}$.}
    \label{fig:meta_learn}
\end{figure}
All optimization steps aim to minimize the reconstruction error when evaluating the learned function $f_{\theta, \phi^{(i)}_{g}}$ on a given context set $\mathcal{C}^{(i)}$, by minimizing the mean squared-error (MSE) loss defined as:
\begin{equation}
    \mathcal{L}_{\mathtt{MSE}}(\phi^{(i)}_{g}, \theta; \mathcal{C}^{(i)}):=\frac{1}{\vert \mathcal{C}^{(i)} \vert }\sum_{j \in \mathcal{C}^{(i)}} \| f_{\theta, \phi^{(i)}_{g}}(\mathbf{x}_j) - \mathbf{y}_j\|_{2}^{2}.
\end{equation}
Since performing a single meta-update step requires backpropagating through the entire inner-loop optimization, the computational graph must be retained in GPU memory to compute the required second-order gradients \cite{finn2017model}. This is a resource-intensive task that does not scale well to high-dimensional signals. While first-order approximations \cite{finn2017model,nichol2018first} or auto-decoder training approaches \cite{park2019deepsdf} that do not rely on second-order optimization exist, recent research has shown that this results in severe performance drops or unstable training \cite{dupont2022data,dupont2022coin++}.
%
%
%
% ---- Reducing the Context Set During Inner Loop Optimization ----
\subsubsection{Reducing the Context Set During Inner-Loop Optimization}
\label{subsec:contextred}
Similar to ideas presented in \cite{tack2024learning}, we propose to make use of a reduced context set $\mathcal{C}_{\mathtt{red}}^{(i)}$ during the inner-loop optimization. This reduced context set contains a subset of the full context set $\mathcal{C}_{\mathtt{red}}^{(i)}\leq\mathcal{C}^{(i)}$, thus saving GPU memory that is required for second-order optimization. We obtain the reduced context set by randomly sampling $\gamma|\mathcal{C}^{(i)}|$ coordinate-value pairs from $\mathcal{C}^{(i)}$. We empirically find that reducing the selection ratio $\gamma$ results in marginal performance drops, while significantly reducing the required GPU memory (see Table \ref{tab:ablation_selectionratio}). This allows to scale our proposed approach to high-dimensional signals or adapt it to the available hardware.
%
%
%
% ---- Fitting Neural Fields to Signals ----
\subsubsection{Fitting Neural Fields to Signals}
\label{subsec:fitNF}
Given the meta-learned model parameters $\theta^{*}$, we fit a NF to each signal $s_1, ..., s_N$. We start with initializing the signal-specific parameters $\phi^{(i)}:=\mathbf{0}$ and optimize $\phi^{(i)}$ for $H$ steps by minimizing $\mathcal{L}_{\mathtt{MSE}}(\phi^{(i)}, \theta^{*}; \mathcal{C}^{(i)})$. As no second-order optimization is required at test-time (see Fig. \ref{fig:meta_learn}), we can make use of the full context set $\mathcal{C}^{(i)}$. A set of NFs representing the signals $s_1, ..., s_N$ is therefore defined by the network architecture, the shared model parameters $\theta^{*}$, and the signal-specific parameters $\phi^{(1)}, ..., \phi^{(N)}$.
%
%
%
% ---- Experiments ----
\section{Experiments}
%
%
%
% ---- Datasets ----
\subsubsection{Datasets}
We perform experiments on a wide range of publicly available datasets containing different medical signals: a single-lead ECG dataset \cite{kachuee2018ecg}, two different chest X-ray datasets \cite{kermany2018identifying,wang2017chestx}, a retinal OCT dataset \cite{kermany2018identifying}, a color fundus image dataset \cite{liu2022deepdrid}, a dermatoscopy image dataset \cite{codella2019skin,tschandl2018ham10000}, a colon histopathology dataset \cite{kather2019predicting}, a cell microscopy dataset \cite{ljosa2012annotated}, a brain MRI dataset \cite{baid2021rsna,bakas2017advancing,menze2014multimodal}, as well as a lung CT dataset \cite{armato2011lung}. No preprocessing was needed for the ECG dataset. For all 2D datasets, we use preprocessed versions from MedMNIST \cite{medmnistv1,medmnistv2}. The brain MRI and lung CT datasets were preprocessed as described in \cite{friedrich2024wdm}.
\subsubsection{Implementation Details}
Network configurations, training details and other relevant hyperparameters are reported in Table \ref{tab:hyperparameters}. All experiments were carried out on a single NVIDIA A100 (\SI{40}{\giga\byte}) GPU. Our code is publicly available at \url{https://github.com/pfriedri/medfuncta}. We additionally release 7 MedFuncta sets with $>\SI{550}{k}$ annotated NFs. A link to access these datasets will be provided in our code repository.
\begin{table}
    \centering
    \caption{A list of hyperparameters. We report the number of layers $K$, the hidden dimension $L$, the number of inner-loop steps $G$, the number of test-time optimization steps $H$, the batch size $BS$, the representation size $P$, the inner-loop learning rate $\alpha$, the global learning rate $\beta$, the context selection ratio $\gamma$, as well as $\omega_{0,1}$ and $\omega_{0,K}$.}
    \begin{tabular}{c|ccccccccccc}
        Dim. & $K$ & $L$ & $G$ & $H$ & $BS$ & $P$ & $\alpha$ & $\beta$ &$\gamma$ & $\omega_{0,1}$ & $\omega_{0,K}$\\\hline
        1D & $8$ & $64$ & $10$ & $20$ & $64$ & $64$ & $1\times10^{-2}$ & $3\times 10^{-6}$ & $1.00$ & $10$ & $80$\\
        2D & $15$ & $256$ & $10$ & $20$ & $24$ & $2048$ & $1\times10^{-2}$ & $3\times 10^{-6}$ & $0.25$ & $10$ & $80$\\
        3D & $15$ & $256$ & $10$ & $20$ & $4$ & $8192$ & $1\times10^{-2}$ & $3\times 10^{-6}$ & $0.25$ & $10$ & $80$
    \end{tabular}
    \label{tab:hyperparameters}
\end{table}
%
%
%
% ---- Reconstruction Quality ----
\subsubsection{Reconstruction Quality}
We first validate that our proposed approach is capable of fitting a wide range of medical signals by performing reconstruction experiments. We meta-learn the shared network parameters $\theta$ on a training set and evaluate the reconstruction quality on a hold-out test set.
\begin{table}
    \centering
    \caption{Mean reconstruction quality of our proposed method, evaluated on a hold-out test set after meta-learning for $\SI{500}{k}$ iterations. MSE scores are multiplied by $10^{3}$. The spatial dimensions are 1D: $187$, 2D: $64\times 64$, 3D: $32 \times 32\times 32$.}
    \begin{tabular}{ll|cccc}
         \textbf{Dim.} & \textbf{Signal Type} & \textbf{MSE $(\downarrow)$} & \textbf{PSNR $(\uparrow)$} & \textbf{SSIM $(\uparrow)$} & \textbf{LPIPS $(\downarrow)$}\\\hline
         1D & ECG \cite{kachuee2018ecg} & $0.090$ & $42.809$ & -- & -- \\\hline
         \multirow{7}{*}{2D} & Chest X-ray \cite{wang2017chestx} & $0.191$ & $37.528$ & $0.966$ & $0.013$\\
                             & Chest X-ray \cite{kermany2018identifying} & $0.227$ & $37.364$ & $0.954$ & $0.013$ \\
                             & Retinal OCT \cite{kermany2018identifying} & $0.271$ & $36.037$ & $0.915$ & $0.039$\\
                             & Fundus Camera \cite{liu2022deepdrid} & $0.129$ & $39.154$ & $0.945$ & $0.009$\\
                             & Dermatoscope \cite{codella2019skin,tschandl2018ham10000} & $0.271$ & $36.606$ & $0.915$ & $0.021$\\
                             & Colon Histopathology \cite{kather2019predicting} & $1.277$ & $30.076$ & $0.879$ & $0.029$\\
                             & Cell Microscopy \cite{ljosa2012annotated} & $0.044$ & $44.293$ & $0.979$ & $0.005$ \\\hline
         \multirow{2}{*}{3D} & Brain MRI \cite{baid2021rsna,bakas2017advancing,menze2014multimodal} & $0.296$ & $35.666$ & $0.945$ & -- \\
                             & Lung CT \cite{armato2011lung} & $3.902$ & $24.316$ & $0.813$ & --
    \end{tabular}
    \label{tab:reconstruction}
\end{table}
We measure mean squared error (MSE), peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), and learned perceptual image patch similarity (LPIPS) \cite{zhang2018unreasonable} and report the results in Table \ref{tab:reconstruction}. Qualitative examples of the performed reconstruction experiments are shown in Fig. \ref{fig:reconstruction}. 
\begin{figure}
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tikzpicture}
            % First row: Input images
            \node[rotate=90] at (-0.125, 1.65)       {\tiny Input};
            \node[] at (0, 1)   [anchor=south west]  {\includegraphics[height=1cm]{images/chest/input.png}};
            \node[] at (1, 1)   [anchor=south west]  {\includegraphics[height=1cm]{images/pneum/input.png}};
            \node[] at (2, 1)   [anchor=south west]  {\includegraphics[height=1cm]{images/oct/input.png}};
            \node[] at (3, 1)   [anchor=south west]  {\includegraphics[height=1cm]{images/fundus/input.png}};
            \node[] at (4, 1)   [anchor=south west]  {\includegraphics[height=1cm]{images/derma/input.png}};
            \node[] at (5, 1)   [anchor=south west]  {\includegraphics[height=1cm]{images/histo/input.png}};
            \node[] at (6, 1)   [anchor=south west]  {\includegraphics[height=1cm]{images/micro/input.png}};

            % Second row: Reconstruction images
            \node[rotate=90] at (-0.125, 0.65)       {\tiny Recon.};
            \node[] at (0, 0)   [anchor=south west]  {\includegraphics[height=1cm]{images/chest/recon.png}};
            \node[] at (1, 0)   [anchor=south west]  {\includegraphics[height=1cm]{images/pneum/recon.png}};
            \node[] at (2, 0)   [anchor=south west]  {\includegraphics[height=1cm]{images/oct/recon.png}};
            \node[] at (3, 0)   [anchor=south west]  {\includegraphics[height=1cm]{images/fundus/recon.png}};
            \node[] at (4, 0)   [anchor=south west]  {\includegraphics[height=1cm]{images/derma/recon.png}};
            \node[] at (5, 0)   [anchor=south west]  {\includegraphics[height=1cm]{images/histo/recon.png}};
            \node[] at (6, 0)   [anchor=south west]  {\includegraphics[height=1cm]{images/micro/recon.png}};
        \end{tikzpicture}
    }
    \caption{Input and reconstruction examples from the hold-out test set for \textit{(from left to right)} chest X-ray \cite{wang2017chestx}, chest X-ray \cite{kermany2018identifying}, retinal OCT \cite{kermany2018identifying}, fundus camera \cite{liu2022deepdrid}, dermatoscope \cite{codella2019skin,tschandl2018ham10000}, colon histopathology \cite{kather2019predicting}, and cell microscopy \cite{ljosa2012annotated} images.}
    \label{fig:reconstruction}
\end{figure}
While performance is generally better on homogeneous datasets, where redundancies can more effectively be exploited, the proposed method also learns to represent complex inhomogeneous datasets, such as the colon histopathology dataset.
%
%
%
\subsubsection{Scaling MedFuncta to High-Resolution Signals}
To highlight the computational efficiency and scalability of our proposed approach, we additionally evaluate its performance on higher-resolution signals. We, therefore, perform reconstruction experiments on the dermatoscopy dataset \cite{codella2019skin,tschandl2018ham10000}, using images with a resolution of $128 \times 128$ and $224 \times 224$ as supervision signals. Reconstruction scores after \SI{500}{k} meta-learning steps are reported in Table \ref{tab:reconstruction_highres}.
\begin{table}
    \centering
    \caption{Mean reconstruction quality of MedFuncta on the dermatoscopy dataset \cite{codella2019skin,tschandl2018ham10000} at higher resolutions. We use the setup in Table \ref{tab:hyperparameters}, only changing batch size $BS$, representation size $P$ and selection ratio $\gamma$. We also report the required training GPU memory in GB. MSE scores are multiplied by $10^{3}$.}
    \begin{tabular}{lccc|cccc}
         \textbf{Resolution} & \textbf{BS} & \textbf{P} & $\gamma$ & \textbf{MSE $(\downarrow)$} & \textbf{PSNR $(\uparrow)$} & \textbf{SSIM $(\uparrow)$} & \textbf{Mem.} $(\downarrow)$\\\hline
         $128 \times 128 $ & $8$ & $8192$ & $0.25$ & $0.352$ & $35.853$ & $0.883$ & $37.01$ \\
         $224 \times 224 $ & $4$ & $16384$ & $0.10$ & $0.565$ & $33.914$ & $0.903$ & $36.91$ \\
    \end{tabular}
    \label{tab:reconstruction_highres}
\end{table}
The results demonstrate that our proposed method can accurately reconstruct high-resolution signals, even when being trained on a single \SI{40}{\giga\byte} GPU only.
%
%
%
% ---- Classification Experiments ----
\subsubsection{Classification Experiments}
To assess whether the learned representation captures relevant information about the underlying signal, we perform classification experiments on the signal-specific parameters $\phi^{(i)}$ \cite{dupont2022data,navon2023equivariant}, using a 3-layer MLP with ReLU activations and dropout. We compare this simple classifier on our MedFuncta representation to ResNet50 \cite{he2016deep} and EfficientNet-B0 \cite{tan2019efficientnet} on the original data. We report the number of network parameters, training time, accuracy, and F1 scores. All models were trained for 50 epochs using Adam with a learning rate of $1\times10^{-3}$. The scores in Table \ref{tab:class} show the classification performance on a holdout test set based on the model parameters yielding the highest validation accuracy.
\begin{table}
    \centering
    \caption{Classification Performance. We report the number of network parameters, the training time in seconds, accuracy, as well as F1 scores.}
    \begin{tabular}{ll|cccc}
        \textbf{Dataset (Classes)} & \textbf{Classifier} & \textbf{Param.} & \textbf{Time $(\downarrow)$} & \textbf{Acc. $(\uparrow)$} & \textbf{F1 $(\uparrow)$}\\\hline
        \multirow{3}{*}{Chest X-ray \cite{kermany2018identifying} (2)} & MLP on MedFuncta & $\mathbf{2.6\times10^{6}}$ & $\mathbf{75}$ & $\mathbf{85.10}$ & $\mathbf{0.83}$ \\
          & ResNet50 & $23.5\times10^{6}$ & $200$ & $81.73$ &  $0.78$ \\
          & EfficientNet-B0 & $4.0\times10^{6}$ & $300$ & $83.17$ & $0.80$ \\\hline
        \multirow{3}{*}{Dermatoscope \cite{codella2019skin,tschandl2018ham10000} (7)} & MLP on MedFuncta & $\mathbf{2.6\times10^{6}}$ & $\mathbf{120}$ &$\mathbf{73.17}$ & $0.45$ \\
         & ResNet50 & $23.5\times10^{6}$ & $340$ & $71.92$ & $\mathbf{0.49}$ \\
         & EfficientNet-B0 & $4.0\times10^{6}$ & $420$ & $72.97$ & $0.48$ \\\hline
        \multirow{3}{*}{Colon Hist. \cite{kather2019predicting} (9)} & MLP on MedFuncta & $\mathbf{2.6\times10^{6}}$ & $\mathbf{1510}$ &$73.84$ & $0.67$ \\
         & ResNet50 & $23.5\times10^{6}$ & $4100$ & $80.01$ & $0.78$ \\
         & EfficientNet-B0 & $4.0\times10^{6}$ & $6400$ & $\mathbf{87.79}$ & $\mathbf{0.84}$ \\
    \end{tabular}
    \label{tab:class}
\end{table}
While the simple MLP classifier generally performs well, we observe that a reduced reconstruction quality, as for the colon histopathology dataset, results in poor classification scores. This suggests that reconstruction quality provides important insights into the performance of downstream tasks on MedFuncta.
%
%
%
% ---- Ablation Studies ----
\subsubsection{Ablation Studies}
\label{subsec:ablations}
To validate our proposed context reduction strategy, we study the effect of the context selection ratio $\gamma$ on the reconstruction quality. The results, presented in Table \ref{tab:ablation_selectionratio}, demonstrate that reducing the context set in the inner-loop significantly reduces the required GPU memory while resulting in marginal performance drops. 
\begin{table}
    \centering
    \caption{Effect of the context selection ratio $\gamma$ on the reconstruction quality, as well as the GPU memory required for training. Measured on chest X-ray dataset \cite{wang2017chestx} $(64 \times 64)$ test-set after 100 k iterations and a batch size of 12, using the baseline configuration.}
    \begin{tabular}{l|p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}
        \textbf{Selection Ratio $(\gamma)$} & $\mathbf{0.1}$ & $\mathbf{0.25}$ & $\mathbf{0.5}$ & $\mathbf{0.75}$ & $\mathbf{1.0}$ \\\hline
        PSNR (dB) & $32.57$ & $33.24$ & $33.50$ & $33.75$ & $33.64$\\
        Memory (GB) & $9.76$ & $14.58$ & $22.30$ & $32.37$ & $38.50$ \\
    \end{tabular}
    \label{tab:ablation_selectionratio}
\end{table}
We identify a context size of $\gamma=0.25$ as a good trade-off between required memory and reconstruction performance. We additionally compare our approach to Functa \cite{dupont2022data} and evaluate the effect of our proposed $\omega_0$-schedule and the proposed context reduction scheme $\mathcal{C}_{\mathtt{red}}$ on the reconstruction performance, by comparing them to a baseline with constant $\omega_0=30$ and no context reduction.
\begin{table}
    \centering
     \caption{Effect of $\omega_{0,k}$-schedule and a reduced context set $\mathcal{C}_{\mathtt{red}}$ with $\gamma=0.25$ on the reconstruction quality. Measured on chest X-ray dataset \cite{wang2017chestx} $(64 \times 64)$ after 72 hours of training. MSE scores are multiplied by $10^{3}$.}
    \begin{tabular}{llc|cccc}
        \textbf{Method} & \textbf{BS} & \textbf{Memory (GB)}&  \textbf{MSE $(\downarrow)$} & \textbf{PSNR $(\uparrow)$} & \textbf{SSIM $(\uparrow)$} & \textbf{LPIPS $(\downarrow)$} \\\hline
        Functa \cite{dupont2022data} & $12$ & $31.54$ & $0.326$ & $35.174$ & $0.944$ & $0.027$\\
        Ours - \textit{Baseline} & $12$ & $38.50$ & $0.314$ & $35.364$ & $0.938$ & $0.032$\\
        Ours - \textit{with $\omega_{0,k}$} & $12$ & $38.50$ & $0.195$ & $37.393$ & $0.961$ & $0.016$\\
        Ours - \textit{with $\mathcal{C}_{\mathtt{red}}$} & $24$ & $27.67$ & $0.285$ & $35.839$ & $0.949$ & $0.024$\\
        Ours - \textit{All} & $24$ & $27.67$ & $\mathbf{0.191}$ & $\mathbf{37.537}$ & $\mathbf{0.966}$ & $\mathbf{0.013}$
    \end{tabular}
    \label{tab:ablationothers}
\end{table}
The results in Table \ref{tab:ablationothers} show that our approach outperforms Functa by a PSNR of $\SI{2.4}{\decibel}$, and that the presented $\omega_0$-schedule, as well as the context reduction scheme consistently increase performance over our baseline. We can additionally show that trading context for batch size is beneficial and increases reconstruction quality.
%
%
%
% ---- Discussion ----
\section{Discussion}
\label{sec:discussion}
This paper introduces \textbf{MedFuncta}, a modality-agnostic functional representation for medical signals. We present an efficient meta-learning approach to obtain these representations and validate its performance across a diverse range of medical signals. Additionally, we demonstrate how to scale our method to high-resolution signals and introduce an $\omega_0$-schedule to mitigate spectral bias in commonly used SIREN activations. We demonstrate how to solve downstream tasks within this new representation and release a large-scale dataset of $> \SI{550}{k}$ annotated NFs. Since NFs are inherently capable of dealing with arbitrary-resolution data and exhibit interesting scaling properties (i.e., they scale with signal complexity, not grid resolution), we believe that NF-based representations are particularly interesting in medicine and are a promising research direction.

For future work, we plan to model the distribution over the signal-specific parameter vectors, using e.g. diffusion models to solve generation tasks. We also intend to explore various downstream applications, including image-to-image translation and image inpainting using paired MedFuncta datasets. Another promising direction is the application of the MedFuncta framework for replacing the auto-decoder training in methods such as \cite{bieder2024modeling} or \cite{stolt2023nisf}. Furthermore, we plan to assess our method's effectiveness in dealing with multimodal data and plan to train our model at scale, exploring its potential as a self-supervised representation learner.
%
%
%
% ---- Credits ----
\begin{credits}
\subsubsection{\ackname} We thank Julian McGinnis and Julia Wolleb for stimulating discussions and useful input. This work was financially supported by the Werner Siemens Foundation through the MIRACLE II project.

\subsubsection{\discintname}
The authors have no competing interests to declare that are
relevant to the content of this article.
\end{credits}
%
%
%
% ---- Bibliography ----
\bibliographystyle{splncs04}
\bibliography{bibliography}
%

\end{document}
