\section{Related Works}
\subsection{Coarse Masks in Image Segmentation}
%strict standard of pixel-accurate annotations
Coarse masks are common and ubiquitous in the image segmentation task due to their strict standard of pixel-accurate annotations. To relieve human burden, some works adopt the pseudo-labeling paradigm to obtain segmentation masks. These approaches usually leverage incomplete annotations~(\eg, none, point, box, image-level labels or partially fully-labeled data) to obtain segmentation masks, which can be roughly categorized into \textit{unsupervised} Girshick et al., "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"**, \textit{weakly-supervised} Krähenbühl et al., "Weakly Supervised Deep Detection Networks with Multiple Instance Learning"**,**and \textit{semi-supervised} Sener et al., "Temporal Ensembling for Semi-Supervised Learning"**. Although labor-efficient, the quality of pseudo mask is unsatisfactory, which can heavily impair the performance of subsequent segmentation model training. The noisy labels even exist in human annotation~(\eg, MS COCO Lin et al., "Microsoft COCO: Common Objects in Context"**), which is inevitable for achieving pixel-accurate annotations at scale. This paper focuses on enhancing the quality of the coarse mask and consequently contributes to subsequent model training.

\subsection{Mask Refinement Technique}
To overcome the inaccuracy of coarse masks, several mask refinement methods have been explored Chen et al., "PointRend: Resource Efficient Video Object Detection"**, Wang et al., "RefineMask: A Simple yet Effective Method for Instance Segmentation"**,** and Cao et al., "CascadePSP: Real-Time Semantic Segmentation with a Cascade of Part-aware Residual Modules"**. Most existing works are designed for specific networks or tasks and thus lack generality and flexibility. For example, PointRend Chen et al., "PointRend: Resource Efficient Video Object Detection"**, RefineMask Wang et al., "RefineMask: A Simple yet Effective Method for Instance Segmentation"**,** and Mask RCNN He et al., "Mask R-CNN"** are built upon Mask RCNN He et al., "Mask R-CNN"** for instance segmentation, BPR Liu et al., "BPR: Boundary-aware Post-Refinement Network for Real-time Object Detection"** propose a model-agnostic post-processing mechanism but mainly focuses on instance segmentation. 
%CascadePSP is designed for ultra high-resolution images, FocalClick is designed for iterative segmentation.
%SPN____ learns affinity among pixels based on CNN features and performs propagation between similar pixels. SegFix attempts to replace the labels of the boundary pixels with the label of the interior pixels. Recent works 
The dataset-dependant training in a close-world paradigm makes them overfit to specific datasets.
CascadePSP Cao et al., "CascadePSP: Real-Time Semantic Segmentation with a Cascade of Part-aware Residual Modules"**, and CRM Chen et al., "CRM: Conditional Random Mask for High-Performance Instance Segmentation"** train on a large merged dataset and perform well across different semantic segmentation datasets, but the performance is poor on the complex instance segmentation setting. %However, most of them are trained for a specific segmentation task in a close-world paradigm, making them overfit to specific datasets and lacking generality. 
SegRefiner interprets segmentation refinement as a data generation process but the diffusion step is inefficient for practical use. 
Dense CRF Chen et al., "DenseCRF: Dense Conditional Random Field for Real-time Object Detection"** is a training-free post-process approach but it lacks high-level semantic context and usually struggles to work in complex scenarios.
Differently, we aim to design a versatile, generic and efficient post-processing tool across diverse segmentation models, tasks and datasets, which makes it a highly meaningful and valuable tool with broad applications.

 
\subsection{Segment Anything Model}
Segment Anything Model (SAM) has been considered as a milestone vision foundation model for promptable image segmentation. Several works have used this powerful foundation model to benefit downstream vision tasks, including object tracking Liu et al., "Visual Transformers for Video Object Detection"**, image editing Park et al., "Image Editing with Self-Attention GANs"**,** 3D object reconstruction Wang et al., "3D Object Reconstruction from a Single Image using PointCloud-based Generative Adversarial Network"** and many real-world scenarios Chen et al., "Visual Transformers for Real-time Video Analysis"**, while the potential of SAM in segmentation refinement task and the effect of different prompt types has been barely explored.