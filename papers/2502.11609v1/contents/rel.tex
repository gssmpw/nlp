\subsection{Rehearsal-free Continual Learning}

The strictness of CL settings varies with the extent of allowed previous data accessibility. Multi-task learning \citep{caruana1997multitask}, with full data availability of all tasks, can actually be viewed as a special case of CL, while rehearsal-free CL \citep{smith2023closer}, with no previous data involved in the training of new tasks, is the strictest CL setting under this criteria. Despite the success of rehearsal-based methods in various benchmarks \citep{bang2021rainbow,shin2017continual,belouadah2019il2m}, rehearsal-free CL is catching the attention of researchers recently \citep{smith2023closer} because of its low dependency on revisiting previous tasks and therefore broader application in the era of growing data privacy concern. 
Existing works on rehearsal-free CL are mostly based on regularization strategies.
EWC \citep{kirkpatrick2017overcoming} and SI \citep{zenke2017continual} introduce penalties to restrict the alteration of parameters vital for addressing prior tasks, thereby reducing the risk of CF. 
% EWC \citep{kirkpatrick2017overcoming} regularizes the model parameters with  Fisher Information matrix weighted distance between network weights. 
LwF \citep{li2017learning,rebuffi2017icarl} proposes a cross-entropy loss between the predicted class distribution of the \textit{(n-1)}-th task, as generated by the model before and after learning the \textit{n}-th task. \cite{smith2023closer} reviews these methods and proposes regularization combinations for better CL performance. In this work, we follow these works and focus on the more challenging rehearsal-free CL setting. 
% , we believe rehearsal-free CL can not only be a strong boost to the data \& training efficiency but also offer as an alternative solution when previous data are inaccessible because of private concerns. can be generally described as regularization-based approaches, including parameter space regularization and feature space regularization, with the latter alternatively referred to as distillation approaches. These approaches introduce different model regularization losses during training. For instance, EWC regularizes the model parameters with L2 distance between network weights, and LwF proposes a cross entropy loss between the predicted class distribution on the n-1th task produced by the model before and after learning the nth task. Recent works also proposed prompt based approaches specially on Vision Transformer (ViT) backbones.  

\subsection{Hypernets}

% Hypernets \citep{ha2017hypernetworks}, or hypernetworks, are neural networks that generate weights for another neural network, known as the target network. They have nowadays emerged as a powerful deep learning technique that
% allows for greater flexibility, adaptability, dynamism, faster training, information sharing, and model
% compression. Hypernets have shown promising results in a variety of deep learning problems, including continual learning, causal inference, transfer learning, weight pruning, uncertainty quantification,
% zero-shot learning, natural language processing, and reinforcement learning.
Hypernets \citep{ha2017hypernetworks}, or hypernetworks, are specialized neural networks that produce weights for another neural network, \textit{i.e.}, the target network. Recently, they have gained recognition as a potent tool in deep learning, providing advantages such as increased flexibility, adaptability, dynamic nature, training efficiency, and model compression \citep{chauhan2023brief}. Hypernets have yielded encouraging results in various deep learning applications, including continual learning \citep{von2020continual}, causal inference \citep{chauhan2024dynamic}, domain adaptation \citep{volk2022example}, uncertainty quantification \citep{krueger2017bayesian}, few-shot learning \citep{sendera2023hypershot}, and reinforcement learning \citep{sarafian2021recomposing}.

\subsection{Transferability Metrics}


Task transferability \citep{zamir2018taskonomy} investigates the relationships between tasks and provides an effective method to evaluate and select source tasks in transfer learning. It also plays a crucial role in developing strategies for multi-task learning and meta-learning. For ease of use, previous studies have proposed metrics based on task models and data distributions for a quick estimation of transferability \citep{ding2024model}.
% Task transferability \citep{zamir2018taskonomy} aims to explore the relationship among tasks and offers an effective approach for the source task evaluation and selection in transfer learning, also playing an important role in making strategies for multi-task learning and meta learning problems. Previous research has distilled the estimation of transferability into metrics for the ease of usage.
H-score \citep{bao2019information, ibrahim2022newer, wu2024h} uses an information-theoretic framework to evaluate transferability by solving a maximum correlation problem. NCE \citep{tran2019transferability} employs conditional entropy to assess transferability and task difficulty. LEEP score \citep{nguyen2020leep, agostinelli2022transferability} offers a more generalized metric, defined by measuring the performance of a classifier developed from source model predictions when applied to the target task. LogME \citep{you2021logme} assesses target task accuracy using a formulation integrating all possible linear classifiers derived from source model features. 
OTCE \citep{tan2021otce, tan2024transferability} combines optimal transport with conditional entropy to both estimate the domain and task difference between source and target.
These metrics are mostly designed with differed assumptions and source accessibility, with their use applicable to different problem settings.