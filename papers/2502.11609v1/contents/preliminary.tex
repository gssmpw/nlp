\subsection{Mathematical Formulation}

Consider a problem setting consisting of $M$ tasks $\{T_j\}_{j=1}^M$, the data of task $j$ is denoted by $D_j = (X^{(j)}, Y^{(j)})$, with input samples $X^{(j)} = \{x^{(j,i)}\}_{i=1}^{N_j}$ and output samples $Y^{(j)} = \{y^{(j,i)}\}_{i=1}^{N_j}$. Here, $N_j = |X^{(j)}| = |Y^{(j)}|$ denotes the sample size of the $j$-th task, and the attributes of sample data $x^{(j,i)}$, $y^{(j,i)}$ depends on the particular CL setting as well as the form of tasks. In CL, the $M$ tasks are learned sequentially during the training stage. To be specific, denoting a neural network model as $f(x, \Theta)$ (where $f$ represents the model function, $x$ represents the input data, and $\Theta$ represents the model weights) and the model weights acquired in task $j-1$ as $\Theta^{(j-1)}$, the goal of learning task $j$ is to derive a new set of weights $\Theta^{(j)}$ that not only achieves the optimal performance on task $j$, but also performs better or not significantly worse than $\Theta^{(j-1)}$ on tasks $T_1, \dots, T_{j-1}$. For a rehearsal-free CL setting, the previous data $D_1, \dots, D_{j-1}$ are not accessible during the training of the $j$-th task.


% \subsection{Continual Learning Setting}

% For task incremental, the output spaces are separated by task IDs and are disjoint between $D_{j-1}$ and $D_{j}$. We denote this setting as $\{Y_{j-1}\}\neq\{Y_{j}\}$, which in turn leads to $P(Y_{j-1})\neq P(Y_{j})$. In this setting, task-IDs are available during both train and test times. 

%For class incremental, mutually exclusive sets of classes comprise each data distribution Di
% , meaning that there
% is no duplicated class among different task distributions. Thus
% P(Yiâˆ’1) , P(Yi), but the output space is the same for all distributions since this setting adopts the single-head configuration
% where the model needs to classify all labels without a task-ID.
% Domain incremental represents the setting where input distributions are different, while the output spaces and distribution
% are the same. Note that task IDs are not available for both class
% and domain incremental
\subsection{H-score}

H-score is firstly introduced by \citeauthor{huang2019information} in \citeyear{huang2019information} as a metric assessing the informativeness of features for a task. Theoretically derived from the maximal correlation interpretation of deep neural networks, its mathematical foundation roots to the information theory work known as maximal correlation analysis, which originates from the works of Hirschfeld, Gebelein and Renyi \citep{hirschfeld1935connection, gebelein1941statistische, renyi1959measures} and has been followed and further explored by a broad spectrum of successive work. The H-score of $f$ with regard to the task casting $X$ to $Y$ is defined as:
\begin{equation}
    H(f) = tr(cov(f(X))^{-1}cov(\mathbb{E}_{P_{X|Y}}[f(X)|Y])),
\label{singlehscore}
\end{equation}
% The H-score, introduced by \citeauthor{huang2019information} in \citeyear{huang2019information}, is a metric for evaluating feature informativeness in tasks. It is grounded in the maximal correlation theory of deep neural networks, which traces its roots to maximal correlation analysis pioneered by Hirschfeld, Gebelein, and Renyi \citep{hirschfeld1935connection, gebelein1941statistische, renyi1959measures}. Subsequent research has expanded the H-score to also serve as a metric for transferability, with extensive experiments confirming its utility in transfer learning and related applications \citep{bao2019information, ibrahim2022newer}.
with input data $X$, label $Y$ and feature extractor function $f(X)$.
Subsequent work has extended H-score to also serve as a metric for transferability and validated its efficiency with extensive experiments \citep{bao2019information, ibrahim2022newer}, implying the potential of H-score for transfer learning and its application in related problems.  The choice of H-score employment in our framework is because of its strong theoretical reliability, conformity of assumption to our problem setting, as well as its non-dependence on source data which makes possible an online embedding estimation. 

\begin{figure*}[htb]
    \centering
    % \centerline{\includesvg[width=2\columnwidth]{figs/framework.svg}}
    \centerline{\includegraphics[width=2.1\columnwidth]{figs/new_CL.pdf}}
    \caption{\textbf{Illustration of the CL status on the step of learning task $j$ under our framework.} The hypernet is being trained to provide the optimal task model weight $\Theta^{(j)}$ concurrently with the learning of current task embedding $e^{(j)}$, where regularization and guidance are applied using previous embeddings and H-embeddings.} 
    % $\{e^{(n)}\}_{n=1}^{j-1}$.}
    \label{fig:CL}
\end{figure*}


