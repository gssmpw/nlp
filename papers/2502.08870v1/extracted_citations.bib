@article{abbasi2011improved,
  title   = {Improved algorithms for linear stochastic bandits},
  author  = {Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal = {Advances in Neural Information Processing Systems},
  year    = {2011},
}

@article{abeille2017linear,
  title   = {Linear Thompson sampling revisited},
  author  = {Abeille, Marc and Lazaric, Alessandro},
  journal = {Electronic Journal of Statistics},
  volume  = 11,
  number  = 2,
  pages   = {5165--5197},
  year    = 2017,
}

@inproceedings{agrawal2012analysis,
  title     = {Analysis of Thompson sampling for the multi-armed bandit problem},
  author    = {Agrawal, Shipra and Goyal, Navin},
  booktitle = {Conference on Learning Theory},
  year      = {2012},
}

@inproceedings{agrawal2013thompson,
  title     = {Thompson sampling for contextual bandits with linear payoffs},
  author    = {Agrawal, Shipra and Goyal, Navin},
  booktitle = {International Conference on Machine Learning},
  year      = {2013},
}

@article{auer2002using,
  title={Using confidence bounds for exploitation-exploration trade-offs},
  author={Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={397--422},
  year={2002}
}

@inproceedings{chapelle2011empirical,
  title={An empirical evaluation of {T}hompson sampling},
  author={Chapelle, Olivier and Li, Lihong},
 booktitle={Advances in Neural Information Processing Systems},
  year={2011}
}

@inproceedings{dani2008stochastic,
  title={Stochastic linear optimization under bandit feedback},
  author={Dani, Varsha and Hayes, Thomas P and Kakade, Sham M},
  booktitle={Conference on Learning Theory},
  year={2008}
}

@article{hamidi2020worst,
  title={On the frequentist regret of linear {T}hompson sampling},
  author={Hamidi, Nima and Bayati, Mohsen},
  journal={arXiv preprint arXiv:2006.06790},
  year={2023}
}

@inproceedings{honda2014optimality,
  title={Optimality of {T}hompson sampling for Gaussian bandits depends on priors},
  author={Honda, Junya and Takemura, Akimichi},
  booktitle={Artificial Intelligence and Statistics},
  year={2014},
}

@inproceedings{huix2023tight,
  title={Tight regret and complexity bounds for Thompson sampling via Langevin Monte Carlo},
  author={Huix, Tom and Zhang, Matthew and Durmus, Alain},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2023},
}

@inproceedings{janz2023exploration,
  title   = {Exploration via linearly perturbed loss minimisation},
  author  = {Janz, David and Liu, Shuai and Ayoub, Alex and Szepesv{\'a}ri, Csaba},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  year    = {2024},
}

@inproceedings{kaufmann2012thompson,
  title={Thompson sampling: An asymptotically optimal finite-time analysis},
  author={Kaufmann, Emilie and Korda, Nathaniel and Munos, R{\'e}mi},
  booktitle={International Conference on Algorithmic Learning Theory},
  year={2012},
}

@inproceedings{korda2013thompson,
  title={Thompson sampling for 1-dimensional exponential family bandits},
  author={Korda, Nathaniel and Kaufmann, Emilie and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2013}
}

@inproceedings{kveton2020randomized,
  title={Randomized exploration in generalized linear bandits},
  author={Kveton, Branislav and Zaheer, Manzil and Szepesvari, Csaba and Li, Lihong and Ghavamzadeh, Mohammad and Boutilier, Craig},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2020},
}

@inproceedings{lattimore2017end,
  title={The end of optimism? An asymptotic analysis of finite-armed linear bandits},
  author={Lattimore, Tor and Szepesvari, Csaba},
  booktitle={Artificial Intelligence and Statistics},
  pages={728--737},
  year={2017},
  organization={PMLR}
}

@article{may2012optimistic,
  title={Optimistic Bayesian sampling in contextual-bandit problems},
  author={May, Benedict C and Korda, Nathan and Lee, Anthony and Leslie, David S},
  journal={Journal of Machine Learning Research},
  volume={13},
  pages={2069--2106},
  year={2012}
}

@article{rusmevichientong2010linearly,
  title={Linearly parameterized bandits},
  author={Rusmevichientong, Paat and Tsitsiklis, John N},
  journal={Mathematics of Operations Research},
  volume={35},
  number={2},
  pages={395--411},
  year={2010},
  publisher={INFORMS}
}

@article{russo2014learning,
  title={Learning to optimize via posterior sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Mathematics of Operations Research},
  volume={39},
  number={4},
  pages={1221--1243},
  year={2014},
  publisher={INFORMS}
}

@article{russo2016information,
  title={An information-theoretic analysis of {T}hompson sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2442--2471},
  year={2016},
  publisher={JMLR}
}

@inproceedings{vaswani2020old,
  title={Old Dog Learns New Tricks: Randomized {UCB} for Bandit Problems},
  author={Vaswani, Sharan and Mehrabian, Abbas and Durand, Audrey and Kveton, Branislav},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2020},
}

@article{xu2023noise,
  title={Noise-adaptive thompson sampling for linear contextual bandits},
  author={Xu, Ruitu and Min, Yifei and Wang, Tianhao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{zhang2021feel,
  title={Feel-good thompson sampling for contextual bandits and reinforcement learning},
  author={Zhang, Tong},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={4},
  number={2},
  pages={834--857},
  year={2022},
  publisher={SIAM}
}

