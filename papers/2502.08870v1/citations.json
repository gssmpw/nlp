[
  {
    "index": 0,
    "papers": [
      {
        "key": "dani2008stochastic",
        "author": "Dani, Varsha and Hayes, Thomas P and Kakade, Sham M",
        "title": "Stochastic linear optimization under bandit feedback"
      },
      {
        "key": "rusmevichientong2010linearly",
        "author": "Rusmevichientong, Paat and Tsitsiklis, John N",
        "title": "Linearly parameterized bandits"
      },
      {
        "key": "lattimore2017end",
        "author": "Lattimore, Tor and Szepesvari, Csaba",
        "title": "The end of optimism? An asymptotic analysis of finite-armed linear bandits"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "rusmevichientong2010linearly",
        "author": "Rusmevichientong, Paat and Tsitsiklis, John N",
        "title": "Linearly parameterized bandits"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "auer2002using",
        "author": "Auer, Peter",
        "title": "Using confidence bounds for exploitation-exploration trade-offs"
      },
      {
        "key": "dani2008stochastic",
        "author": "Dani, Varsha and Hayes, Thomas P and Kakade, Sham M",
        "title": "Stochastic linear optimization under bandit feedback"
      },
      {
        "key": "abbasi2011improved",
        "author": "Abbasi-Yadkori, Yasin and P{\\'a}l, D{\\'a}vid and Szepesv{\\'a}ri, Csaba",
        "title": "Improved algorithms for linear stochastic bandits"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "abbasi2011improved",
        "author": "Abbasi-Yadkori, Yasin and P{\\'a}l, D{\\'a}vid and Szepesv{\\'a}ri, Csaba",
        "title": "Improved algorithms for linear stochastic bandits"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chapelle2011empirical",
        "author": "Chapelle, Olivier and Li, Lihong",
        "title": "An empirical evaluation of {T}hompson sampling"
      },
      {
        "key": "may2012optimistic",
        "author": "May, Benedict C and Korda, Nathan and Lee, Anthony and Leslie, David S",
        "title": "Optimistic Bayesian sampling in contextual-bandit problems"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "agrawal2012analysis",
        "author": "Agrawal, Shipra and Goyal, Navin",
        "title": "Analysis of Thompson sampling for the multi-armed bandit problem"
      },
      {
        "key": "kaufmann2012thompson",
        "author": "Kaufmann, Emilie and Korda, Nathaniel and Munos, R{\\'e}mi",
        "title": "Thompson sampling: An asymptotically optimal finite-time analysis"
      },
      {
        "key": "korda2013thompson",
        "author": "Korda, Nathaniel and Kaufmann, Emilie and Munos, Remi",
        "title": "Thompson sampling for 1-dimensional exponential family bandits"
      },
      {
        "key": "honda2014optimality",
        "author": "Honda, Junya and Takemura, Akimichi",
        "title": "Optimality of {T}hompson sampling for Gaussian bandits depends on priors"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "russo2014learning",
        "author": "Russo, Daniel and Van Roy, Benjamin",
        "title": "Learning to optimize via posterior sampling"
      },
      {
        "key": "russo2016information",
        "author": "Russo, Daniel and Van Roy, Benjamin",
        "title": "An information-theoretic analysis of {T}hompson sampling"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "russo2014learning",
        "author": "Russo, Daniel and Van Roy, Benjamin",
        "title": "Learning to optimize via posterior sampling"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "agrawal2013thompson",
        "author": "Agrawal, Shipra and Goyal, Navin",
        "title": "Thompson sampling for contextual bandits with linear payoffs"
      },
      {
        "key": "abeille2017linear",
        "author": "Abeille, Marc and Lazaric, Alessandro",
        "title": "Linear Thompson sampling revisited"
      },
      {
        "key": "xu2023noise",
        "author": "Xu, Ruitu and Min, Yifei and Wang, Tianhao",
        "title": "Noise-adaptive thompson sampling for linear contextual bandits"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "may2012optimistic",
        "author": "May, Benedict C and Korda, Nathan and Lee, Anthony and Leslie, David S",
        "title": "Optimistic Bayesian sampling in contextual-bandit problems"
      },
      {
        "key": "vaswani2020old",
        "author": "Vaswani, Sharan and Mehrabian, Abbas and Durand, Audrey and Kveton, Branislav",
        "title": "Old Dog Learns New Tricks: Randomized {UCB} for Bandit Problems"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zhang2021feel",
        "author": "Zhang, Tong",
        "title": "Feel-good thompson sampling for contextual bandits and reinforcement learning"
      },
      {
        "key": "huix2023tight",
        "author": "Huix, Tom and Zhang, Matthew and Durmus, Alain",
        "title": "Tight regret and complexity bounds for Thompson sampling via Langevin Monte Carlo"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "kveton2020randomized",
        "author": "Kveton, Branislav and Zaheer, Manzil and Szepesvari, Csaba and Li, Lihong and Ghavamzadeh, Mohammad and Boutilier, Craig",
        "title": "Randomized exploration in generalized linear bandits"
      },
      {
        "key": "janz2023exploration",
        "author": "Janz, David and Liu, Shuai and Ayoub, Alex and Szepesv{\\'a}ri, Csaba",
        "title": "Exploration via linearly perturbed loss minimisation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "hamidi2020worst",
        "author": "Hamidi, Nima and Bayati, Mohsen",
        "title": "On the frequentist regret of linear {T}hompson sampling"
      },
      {
        "key": "zhang2021feel",
        "author": "Zhang, Tong",
        "title": "Feel-good thompson sampling for contextual bandits and reinforcement learning"
      }
    ]
  }
]