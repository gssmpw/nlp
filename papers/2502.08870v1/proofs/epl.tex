\section{Proof of the change of geometry lemma (\cref{lem:geometry})}\label{sec:change-of-geometry}

\newcommand{\uorth}{u^{\perp}}

Let $\uorth \colon \Rd \to \Rd$ be a basis completion orthogonal to $u$ (a projection onto the orthogonal complement of the span of $u$). Let $\epsilon = \langle \eta_t, u \rangle / \norm{u}$, and let $\tilde{\epsilon}$ be an independent copy of $\epsilon$ independent of $\FF_{t-1}$ and define
$$
    \tilde{\theta}_t = \thetapred + \Vt^{-1/2} \uorth \eta_t + \Vt^{-1/2} u \tilde{\epsilon} \spaced{observing that} \thetat - \tilde{\theta}_t = (\epsilon - \tilde{\epsilon})u\,.
$$
Also define the indicators $\iota = \1{J(\thetat) \leq J(\thetaopt)}$ and $\tilde{\iota} = \1{J(\tilde{\theta}_t) \leq J(\thetaopt)}$. 

\begin{proof}[Proof of \cref{lem:geometry}]
    The proof is based on lower and upper-bounding $\Et \iota \tilde{\iota} \Djj(\tilde{\theta}_t, \thetat) $.

For the lower bound, note that by strong convexity, 
$$
    \Et \iota \tilde{\iota}  \Djj(\tilde{\theta}_t, \thetat) \geq \frac{m}{2} \snorm{\Vt^{-1/2}u}^2 \,\Et  \iota \tilde{\iota} (\tilde{\epsilon} - \epsilon)^2\,,
$$
where
\begin{align*}
    \Et  \iota \tilde{\iota} (\tilde{\epsilon} - \epsilon)^2 
        &= \Et (\tilde{\epsilon} - \epsilon)^2 - \Et ((\iota + \tilde{\iota}) \wedge 1) (\tilde{\epsilon} - \epsilon)^2  \\
        &\geq 2 -  \Et ((\iota + \tilde{\iota}) \wedge 1) (\tilde{\epsilon} - \epsilon)^2  \tag{marginal variance assumption} \\
        &\geq 2 - 2\Et \iota (\tilde{\epsilon} - \epsilon)^2  \tag{drop $\wedge$} \\
        &\geq 2 - 2\Et \iota (K^2 + \epsilon^2)  \tag{marginal variance assumption} \\
        &\geq 2 - 2 \sqrt{p_{t-1}}\sqrt{\Et(K^2 + \epsilon^2)^2} \tag{Cauchy-Schwarz and $\Et \iota = p_{t-1}$} \\
        &\geq 2 - 4K^2 \sqrt{p_{t-1}} \tag{marginal variance and fourth moment assumptions} \\
        &\geq 1 \tag{$p_{t-1} \leq p = 1/(16K^4)$ by assumption}
\end{align*}

For the upper bound, we have that
\begin{align*}
  \Et \iota \tilde{\iota}  \Djj(\tilde{\theta}_t, \thetat) 
    &= \Et\iota \tilde{\iota} (J^2(\tilde{\theta}_t) - J^2(\thetat) - \langle \nabla J^2(\thetat), \tilde{\theta}_t - \thetat \rangle ) \\
    &= \Et\iota \tilde{\iota} (J^2(\tilde{\theta}_t) - J^2(\thetat) - \langle 2J(\thetat)  \nabla J(\thetat), \tilde{\theta}_t - \thetat \rangle ) \\
    &\leq \Et \iota \tilde{\iota} |J^2(\tilde{\theta}_t) - J^2(\thetat)|  + 2J(\thetaopt) \Et |\langle \nabla J(\thetat), \tilde{\theta}_t - \thetat \rangle |   \tag{$0 < \iota J(\theta_t) \leq J(\thetaopt)$}\\
    &= \Et  \iota \tilde{\iota} |J(\tilde{\theta}_t) - J(\thetat)|(J(\thetat) + J(\tilde{\theta}_t))  + 2J(\thetaopt) \Et |\langle \nabla J(\thetat), \tilde{\theta}_t - \thetat \rangle| \\
    &\leq 2J(\thetaopt) \left\{ \Et |J(\tilde{\theta}_t) - J(\thetat)| + \Et |\langle \nabla J(\thetat), \tilde{\theta}_t - \thetat \rangle| \right\} \\
    &\leq 6J(\thetaopt) \Et |\langle \nabla J(\thetat), \tilde{\theta}_t - \thetat \rangle| \tag{convexity} \\
    &= 6J(\thetaopt) \Et (\tilde{\epsilon} - \epsilon) |\langle \nabla J(\thetat), \Vt^{-1/2}u \rangle | \\
    &\leq 6J(\thetaopt) \Et[(\tilde{\epsilon} - \epsilon)^2]^{1/2} \norm{\E_{t-1} [\nabla J(\thetat) \nabla J(\thetat)\tran]^{1/2} \Vt^{-1/2} u} \tag{Cauchy-Schwarz} \\
    &\leq 6\sqrt{2} J(\thetaopt) K \norm{\E_{t-1} [\nabla J(\thetat) \nabla J(\thetat)\tran]^{1/2} \Vt^{1/2} u}\,. \tag{marginal variance assumption}
\end{align*}

Chaining the lower and upper bounds yields the claimed result.
\end{proof}


\section{Proof of directional concentration (\cref{claim:pointwise-concentration})}\label{sec:proof-covering}
\begin{lemma}\label{lem:covering-size}
    For any $r,\epsilon > 0$, the covering number of $r \Bd$ is upper bounded by $r^d(1+\frac{2}{\epsilon})^d$.
\end{lemma}


\begin{proof}[Proof of \cref{claim:pointwise-concentration}]
    For each $n \geq 1$, let $\cN_n$ be a minimal $\epsilon_n$-cover of $r\Bd$ in $\norm{\cdot}$, where the value of $\epsilon_n > 0$ will be chosen shortly. Let 
    $$
        \Delta_n = \sum_{t=1}^n \Xt\Xt\tran - (1-1/e)\sum_{t=1}^n \Et [\Xt\Xt\tran]\,.
    $$
    For every $n \geq 1$ and $u \in \cN_n$, we apply \cref{lem:nonneg-concentration} to the sequence $\alpha_t = \langle X_t, u \rangle^2$, $t \geq 1$, using the upper bound $\alpha_t \leq J(u)^2$ for all $t \geq 1$, and confidence level $\delta_n = 6 \delta / (\pi^2 n^2 |\cN_n|)$. Taking a union bound over the resulting events, we obtain that with probability $1-\delta$, for all $n \geq 1$ and $u \in \cN_n$, 
    $$
        f_n(u) := u\tran \Delta_n u + J(u)^2 \log(1/\delta_n) \geq 0\,.
    $$
    Now for each $n \geq 1$, let $\pi_n \colon r\Bd \to \cN_n$ be a map satisfying $\norm{u - \pi_n(u)} \leq \epsilon_n$ for all $u \in r\Bd$. The proof will be complete once we show that for a suitable choice of $\epsilon_n$, $|f_n(u) - f_n(\pi_n(u))| \leq 5$ for all $u \in r\Bd$, and that for the chosen $\epsilon_n$, we have the bound $\log(1/\delta_n) \leq \omega_n$. We begin with the bound
    \begin{equation*}
        |f_n(u) - f_n(\pi_n(u))| 
            \leq \underbrace{|u\tran \Delta_n u - \pi_n(u)\tran \Delta_t \pi_n(u)|}_{=:A_n} + \underbrace{|J^2(u) - J^2(\pi_n(u))|}_{=:B_n} \log (1/\delta_n)\,, 
    \end{equation*}
    Letting $\norm{\cdot}_{\mathrm{op}}$ denote the $\ell_2 \to \ell_2$ operator norm,
    \begin{align*}
        A_n &= |(u - \pi_n(u))\tran \Delta_n(u-\pi_n(u)) - 2\pi_n(u)\tran \Delta_n(\pi_n(u) - u)|\\
            &\leq (\norm{u-\pi_n(u)}^2 + 2 \norm{\pi_n(u)} \norm{\pi_n(u) - u}) \norm{\Delta_n}_{\mathrm{op}} \\
            &\leq \epsilon_n(\epsilon_n + 2r)2n < 6\epsilon_n n\,. \tag{$\norm{\Delta_n}_{\mathrm{op}}\leq 2n$, $r \leq 1$, $\epsilon_n < 1$}
    \end{align*}
    Also,
    \begin{align*}
            B_n &= |(J(u) - J(\pi_n(u))(J(u) + J(\pi_n(u)))| \\
            &\leq 2r|(J(u) - J(\pi_n(u))| \tag{$\forall u \in r\Bd$, $J(u) \leq \norm{u} \leq r$} \\
            & \leq 2 r|J(u - \pi_n(u))|  \tag{$\forall u,u'$, $|J(u) - J(u')| \leq |J(u-u')|$}\\ 
            &\leq 2r \epsilon_n < 2\epsilon_n \,. \tag{$r \leq 1$}
    \end{align*}
    Now choose  $\epsilon_n = 1/(4nd^2 \log(1/\delta))$. By \cref{lem:covering-size}, for this choice, $\log(1/\delta_n) \leq \omega_n$. Combining the bounds on $A_n$ and $B_n$, we now indeed have that for all $u \in r\Bd$,
    \begin{equation*}
        |f_n(u) - f_n(\pi_n(u))| \leq A_n + B_n \log(1/\delta_n) \leq \epsilon_n (2+6n + \log(1/\delta_n))  \leq 5\,. \qedhere
    \end{equation*} 
\end{proof}