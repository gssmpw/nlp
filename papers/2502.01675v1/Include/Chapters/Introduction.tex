\chapter{\textcolor{black}{Introduction}}
\thispagestyle{plain}
The rapid advancement of digital technology has fundamentally transformed the way information is generated, transmitted, and consumed. From high-resolution multimedia content to the proliferation of the \gls{iot}, autonomous vehicles, and smart cities, the modern world is producing data at an unprecedented rate \cite{Aliyu2017Towards, Balaji2023Machine}. Traditional communication systems, initially designed for human-to-human interaction and optimized for transmitting raw data, are struggling to keep pace with the vast amount of information generated on a daily basis \cite{Jaafreh2018Multimodal, Mordacchini2020HumanCentric}. Bandwidth limitations, latency constraints and numerous other issues represent significant challenges in modern network designs \cite{Tassi2017Modeling}.

At the core of these issues lies a fundamental mismatch between the growth of data generation and the expansion of communication infrastructure capabilities. Conventional communication paradigms, based on Shannon's information theory \cite{Shannon1948Communication}, focus on the accurate compression and delivery of bits and symbols, regardless of their contextual significance. While this bit-centric approach is effective in scenarios where preserving every detail of the original data is crucial (such as transmitting ultra-high-definition images e.g. to be posted on social networks), it becomes increasingly inefficient in contexts where only a fraction of the transmitted data is relevant to the end-user or application \cite{Strinati20216G, Gunduz20246G}. Considering all symbols as equally important can lead to suboptimal use of bandwidth and computational resources, increasing the pressure on communication networks.

One possible scenario where the bit-centric communication framework could increase the pressure on the communication network is in the so-called machine-to-machine communication. The absence of humans in this type of communication relies on the fact that machines can autonomously collect, process, and send data from a transmitter to a receiver that will further process them to take some actions. In this context, transmitting the raw data in its entirety can be both redundant and counterproductive. Machines are, in fact, designed to process the data via some algorithms. These can either be a simple rule-based algorithm or a more complex and advanced \gls{nn}. In both cases the model will focus mainly on particular features that most influence the decision. All the other features will be discarded as they are non-relevant \cite{Tishby2015DNNIB}. This implies that the same action or decision can often be executed without the need for the original raw data but instead just by using a transformation that preserves information about the relevant parts. This process will guarantee the same level of performance, eliminating the necessity for bit-by-bit transmission \cite{Luo2022Semantic}. An example where it is beneficial to consider only relevant features is the so-called human-robot interaction. In this framework a human is interacting with machines that communicate with each other. This can happen, for example, in an industrial scenario where the human works in close proximity to robotic arms. These arms will have to move loads and perform some actions, but more importantly, avoid any potentially dangerous contact with the human. This task requires constant and real-time monitoring and prediction of the human movements'. This task could be performed by recording \gls{hr} images of the human and transmitting them to another machine that will process and aggregate multiple images to decide whether to stop the movement of the arm or not. Another better option would be to pre-process the data locally. To this scope, it is possible to locally extract the graph representation of the human's pose, transmit it to the receiver which will further process the information considering possible transmission errors \cite{Sampieri2022Pose, Testa2024Stability}. By transmitting only this distilled information, the communication load can be drastically reduced without compromising the final goal.

\begin{wrapfigure}[12]{r}{0.45\textwidth}
    \vspace{-10pt} % Adjust as needed
    \centering
    \includegraphics[width=0.4\textwidth]{Figures/Semantic_communication/Coom_levels_interconnection.pdf}
    \caption[Scheme of three levels of communication]{Diagram illustrating the three levels of communication and their interconnection as proposed in \cite{WARREN1953semantic}}
    \label{fig: INTRO semantic_communication}
\end{wrapfigure}

This idea of going beyond the classical bit-by-bit reconstruction was proposed by Weaver in 1953 when he introduced the three different levels of communication \cite{WARREN1953semantic}: (i) the syntactic level, focusing on the accurate transmission of symbols; (ii) the semantic level, focusing on the conveyance of meaning; and (iii) the effectiveness level, focusing on the impact of the communication on the desired outcome or action. The syntactic level represents the fundamental level of communication. For this level, Shannon provided a rigorous and formal solution in what is known as \gls{it} \cite{Shannon1948Communication}. This level involves the technical aspects of transmitting and reconstructing symbols through physical channels. The semantic level builds upon this by addressing the interpretation and extraction of the \textit{semantic meaning} embedded within the data. Instead of considering the data as a series of symbols, the semantic level tries to focus on the information conveyed by the data. At the top is the effectiveness level, which ensures that the communication achieves its intended purpose. This level is designed to orchestrate and interact with both previous communication levels and the environment resources to fulfill specific goals, embodying the essence of what is referred to as \gls{goc}. 
As shown in \fref{fig: INTRO semantic_communication}, these levels are intrinsically interconnected, forming a hierarchical structure where each higher level builds upon and controls the lower ones.

The correct implementation of these higher-level communication paradigms has interested researchers for their potential in improving communications \cite{Strinati20216G, Han2022SemanticPreserved, Gunduz2023Beyond, Qin2021Semantic, Lu2021Rethinking}. \gls{sc} addresses the inefficiencies of traditional paradigms by focusing on the extraction and transmission of the actual information that the transmitter intends to convey, rather than the raw data itself. For example, in the context of autonomous vehicles, it is important to avoid any collision between the vehicle and any other object. The classical way to perform this task is by continuously sending \gls{hr} images to a base station that will process the images and select the best action to avoid a car accident. However, the vehicle could pre-process these images locally to identify and extract critical information about the position and shape of other objects, such as pedestrians, other vehicles, traffic signals, and more \cite{Grigorescu2020survey}. All of this information can be represented via the so-called \gls{ssm}, a representation that can be compressed far more than the original image while preserving all the essential semantic information necessary for navigation and obstacle avoidance. Sometimes, to safely navigate a vehicle it might be necessary to have more information than the position and shape of the surrounding objects. For example, only knowing the shape of a traffic sign might not be enough. In this case, the effectiveness level may identify that the information conveyed by the \gls{ssm} is not enough and instruct the transmitter to send additional information, such as a low-resolution version of the original image. This adaptive approach significantly reduces the amount of data that needs to be transmitted and adapts it to the specific semantic content and to the goals of the application.

In contexts where the semantic and the goal of communication are crucial, the integration of \gls{ai}, particularly generative models, provides valuable benefits. Combined with classical optimization techniques, these approaches offer promising ways to improve communication efficiency and effectiveness \cite{Xie2021DeepLearningEnabled}.


Generative models, such as \glspl{gan} \cite{goodfellow2014generative}, \glspl{vae} \cite{Kingma2014VAE}, and \glspl{ddpm} \cite{Ho2020ddpm}, have demonstrated incredible capabilities in learning complex data distributions and generating high-quality synthetic data \cite{Dhariwal2021DDPM_beat_GAN}. By leveraging these models, it becomes possible to reconstruct or generate data at the receiver side based on few compressed semantic representations of the original data \cite{He2022Robust}. For example, when a transmitter processes an image of a street scene and sends only the \gls{ssm}, the receiver can use that information as input of a generative model to reconstruct an image that, while visually different in terms of colors and textures, maintains all objects in their correct positions. This ensures that the essential semantic information required for tasks like navigation or scene understanding are preserved while drastically reducing the amount of bits to be transmitted thus decreasing latency which is critical for applications requiring real-time responses.

However, the practical implementation of \gls{sc} and \gls{goc} using generative models in real-world applications present significant challenges. One of the most critical issues is related to resource constraints, including limited computational power and energy availability, especially on devices \cite{Zhou2019Edge, Chis2016PerformanceEnergy, Wang2019An}. Generative models, while capable of producing high-quality images, are computationally intensive and typically require substantial processing power and memory. Running these models on servers or cloud infrastructures is relatively feasible. Instead, deploying them on devices like smartphones, autonomous vehicles, or \gls{iot} sensors introduces constraints due to limited hardware capabilities and the necessity for energy efficiency. Moreover, the communication channels themselves may have limited bandwidth and are susceptible to latency and reliability issues. Therefore, trade-offs between computational and communication resources, compression efficiency, reconstruction quality, and semantic preservation must be meticulously balanced to meet application-specific requirements. Pre-processing the data too much could decrease the autonomy of the device battery, while insufficient pre-processing could excessively load the communication infrastructure.

A special and quite useful case where it is possible to monitor and control every single aspect of the communication is the edge computing in the \gls{en}. Edge computing has emerged as a pivotal component in modern communication networks, offering a paradigm where computation and data storage are brought closer to the data sources \cite{Shi2016edge}. This proximity significantly reduces latency and bandwidth usage, enabling real-time applications like augmented reality, autonomous driving, and \gls{iot}. 
Research has focused on developing techniques for optimizing resources within the context of \glspl{en} to achieve a favorable trade-off between computational demands and communication efficiency \cite{Binucci2023goaloriented, Hu2024Semantic}.

By integrating generative models at the edge, it becomes possible to perform complex data processing tasks locally, reducing the need for extensive data transmission to centralized servers. For instance, an \gls{ed} can observe an image, and preprocess it via some classic compression algorithms or \gls{nn} model before transmitting only the essential semantic information. It will be at the \gls{es} that the power of the generative models is used to reconstruct an image similar to the original one in terms of semantic information preservation. Additionally, the use of \gls{goc} protocols ensures that the transmitted data aligns with the specific objectives of the application, further optimizing resource utilization.\\

This thesis will focus  on the interconnection between \gls{sc}, \gls{goc} and edge computing optimization in the context of image compression. Multiple \gls{sc} image compression algorithms will be proposed in parallel with resource allocation strategies to enhance communication efficiency and effectiveness. The structure of the semantic image compression and reconstruction algorithm will be based on the use of generative models. The reconstruction of the image will be mainly, but not only, based on the information contained in the \gls{ssm}. The performance of the proposed models will be compared with classical image compression algorithms like \gls{bpg} or \gls{jpeg2000} in terms of classical and semantic metrics. Moreover, these models will be designed to be integrated into an \gls{en} framework. A resource allocation strategy based on the \gls{ib} problem \cite{Tishby1999IB,Tishby2015DNNIB} will be proposed to enhance communication efficiency and the resources will be optimized via stochastic optimization techniques to provide an overall insight into the performance of the \gls{en}. 
\section{\textcolor{black}{Contribution and Thesis Outline}}

In this section, the structure of the thesis is introduced and a brief description of the main contributions is provided.

\begin{itemize}[label={}]
    \item {\textbf{Chapter \ref{ch: SEMCOM}) Foundations of Semantic and Goal-Oriented Communication:}} This chapter provides an overview of the three levels of communication proposed by Weaver in 1953, focusing on the \gls{sc} and \gls{goc} levels. The differences and the relations between these levels are discussed, highlighting the importance of semantic information in communication systems. Additionally, in this chapter the advantages of employing generative models to achieve \gls{sc} and how the \gls{ib} problem can be useful for \gls{goc} are suggested.
    \item {\textbf{Chapter \ref{ch: generative_models}) Foundations of Generative Models and Evaluation Metrics:}} This chapter goes over the fundamental concepts of generative models, including \glspl{vqgan}, \glspl{vqvae}, and \glspl{ddpm}, providing all the necessary background on the most important architectures that will be used in the following chapters. Furthermore, various classical and semantic evaluation metrics used to assess the performance of the proposed image compression models will be discussed. After a general overview of these metrics, the last part of this chapter will be devoted to the introduction of a new specifically designed metric. This is expressed in terms of traffic sign classification accuracy and involves a specific process for identification and classification of traffic signs.
    \item {\textbf{Chapter \ref{ch: SPIC}) Semantic-Preserving Image Coding based on Conditional Diffusion Models:}} This chapter introduces a novel semantic image coding scheme designed to preserve the semantic content of an image  while ensuring a good trade-off between coding rate and image quality preservation. The proposed Semantic-Preserving Image Coding framework (\acrshort{spic}) is based on a modular approach where the transmitter encodes the \gls{ssm} and a low-resolution version of the original image. The receiver then employs the proposed Semantic-Conditioned Super-Resolution Diffusion Model (\acrshort{semcore}) to reconstruct the \gls{hr} image based on the information contained in the \gls{ssm} and the low-resolution image. 
    The modular approach allows the framework to be easily updated, and to be more flexible in case of architectural changes without requiring any further fine-tuning or re-training. Thanks to this design choice, other variations are proposed to address multiple scenarios where different elements are considered semantically relevant and computational and/or communication resources are limited.
    \item {\textbf{Chapter \ref{ch: SQGAN}) Semantic Image Coding Using
Masked Vector Quantization:}} This chapter introduces the Semantic Masked VQ-GAN (\acrshort{sqgan}), a novel approach that integrates \gls{vqgan} and \gls{sc} principles to optimize image compression and transmission. This new model is designed to selectively encode and transmit only semantically relevant parts of the image, effectively reducing redundancy and enhancing communication efficiency. The task is performed by a designed module, the Semantic Conditioned Adaptive Mask Module (\acrshort{samm}), that learns how to identify and rank semantically relevant features. This chapter also introduces a data augmentation technique designed to target specific semantically relevant classes to allow better reconstruction. Moreover, a variation of the discriminator network designed to focus only on some specific semantically relevant classes is introduced in this chapter.
    The proposed model outperforms traditional compression algorithms such as \gls{bpg} and \gls{jpeg2000} across multiple metrics and works at extremely low values of \gls{bpp}. Moreover, it is designed to be easily implemented in an \gls{en} framework due to the presence of two parameters that can be dynamically adjusted in a \gls{goc} fashion and directly influence the level of compression.
    \item {\textbf{Chapter \ref{ch: Goal_oriented}) Goal-Oriented Resource Allocation in Edge Networks:}} This chapter introduces the resource allocation of the \gls{en}. The goal is to minimize the average power consumption while meeting constraints on average service delay and evaluation metrics of the learning task. Stochastic optimization methods are used to dynamically adjust all the computational, communication, and compression resources in a Goal-Oriented fashion. This chapter begins with combining the \gls{ib} problem and stochastic optimization to achieve \gls{goc}. The \gls{ib} principle is used to design the encoder in order to find an optimal balance between representation complexity and relevance of the transmitted data with respect to the goal. Additionally, the same stochastic optimization framework is used to integrate in the \gls{en} the proposed \acrshort{sqgan} introduced in \cref{ch: SQGAN}. This will provide an overview of what is defined as \gls{sgoc}.
\end{itemize}

\section{Related Publications}
The main contributions of this thesis will be introduced in \cref{ch: SPIC}, \ref{ch: SQGAN} and \ref{ch: Goal_oriented} and are based on the following publications:
\begin{quotation}
\noindent \textit{\textbf{\large Goal-Oriented Communication for Edge Learning based on the Information Bottleneck}}\\
\textit{Francesco Pezone, Sergio Barbarossa, Paolo Di Lorenzo}\\
Proceedings of 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022, pp. 8832-8836


\vspace{0.2cm}

\noindent \textit{\textbf{\large Semantic-Preserving Image Coding based on Conditional Diffusion Models}}\\
\textit{Francesco Pezone, Osman Musa, Giuseppe Caire, Sergio Barbarossa}\\
Proceedings of 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2024, pp. 13501-13505

\vspace{0.2cm}

\noindent \textit{\textbf{\large C-SPIC: Class-Specific Semantic-Preserving Image Coding with Residual Enhancement for Accurate Object Recovery}}\\
\textit{Francesco Pezone, Osman Musa, Giuseppe Caire, Sergio Barbarossa}\\
Manuscript in Preparation 

\vspace{0.2cm}

\noindent \textit{\textbf{\large SQ-GAN: Semantic Image Coding Using
Masked Vector Quantization}}\\
\textit{Francesco Pezone, Sergio Barbarossa, Giuseppe Caire}\\
Manuscript in Preparation
\end{quotation}
\noindent Other contributions more related to the overall idea and advantages of generative models for \gls{sc} and the \gls{ib} problem for \gls{goc} are presented in \cref{ch: SEMCOM} and are based on the following publications:
\begin{quotation}
\noindent \textit{\textbf{\large Semantic and Goal-Oriented Communications}}\\
\textit{Sergio Barbarossa, Francesco Pezone}\\
\textit{6G Wireless Systems: Enabling Technologies}, edited by M. Chiani, S. Buzzi, L. Sanguinetti, and U. Spagnolini, CNIT Tech Report, 2022

\vspace{0.2cm}

\noindent \textit{\textbf{\large Semantic Communications based on Adaptive Generative Models and Information Bottleneck}}\\
\textit{Sergio Barbarossa, Danilo Comminiello, Eleonora Grassucci, Francesco Pezone, Stefania Sardellitti, Paolo Di Lorenzo}\\
IEEE Communications Magazine, vol. 61, no. 11, 2023, pp. 36-41
\end{quotation}
\noindent Additionally, a publication leveraging the syntactic level of communication to perform radio frequency denoising could have been included. However, it has been left out for sake of exposition and is reported here for reference:
\begin{quotation}
\noindent \textit{\textbf{\large Demucs for Data-Driven RF Signal Denoising}}\\
\textit{Çağkan Yapar, Fabian Jaensch, Jan C. Hauffen, Francesco Pezone, Peter Jung, Saeid K. Dehkordi, Giuseppe Caire}\\
Proceedings of 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW), 2024, pp. 95-96
\end{quotation}


\section{Remark on Notation}
This thesis extensively utilizes concepts from \gls{ml}, for this reason it is important to introduce some notation that will be used throughout the following chapters. \\
The original image will be referred to as $\x$ and the original \gls{ssm} as $\s$. They are both represented by tensors in three dimensions. In the context of tensors, the term "shape" will be used to refer to the dimensions of the tensor, that is, how many elements exist in each dimension. The term "size" will be used to refer to the total number of elements present in the entire tensor.

The original image $\x$ is a tensor of shape $3 \times H \times W $, where $3$ refers to the RGB channels, $H$ is the height and $W$ is the width of the frame. The \gls{ssm} $\s$ is a tensor of shape $n_c \times H \times W $, where $n_c$ refers to the number of semantic classes, $H$ is the height and $W$ is the width of the frame. In some contexts, the \gls{ssm} will be represented by a tensor of shape $3 \times H \times W $ for the RGB representation of $1 \times H \times W $ for the grayscale representation, they can all be considered interchangeable. However, the first representation will be the one used as input to any \gls{nn} model.

The proposed models in this thesis are designed to compress $\x$ and $\s$ at the transmitter side and reconstruct an image $\hat{\x}$ and a \gls{ssm} $\hat{\s}$ at the receiver. The term "reconstructed" will be used when referring to the output of the proposed models, i.e. $\hat{\x}$ and  $\hat{\s}$, while the term "generated" refers to the \gls{ssm} obtained from an image, either $\x$ or $\hat{\x}$, via some out-of-the-shelf pre-trained \gls{sota} \gls{ssmodel}. In this context, the term \textit{\gls{ssm} preservation} or \textit{\gls{ssm} retention} will refer to the property of the reconstructed image $\hat{\x}$ to generate a \gls{ssm} that is similar to the original $\s$ associated to $\x$. 

Any intermediate output of the model is referred to as the "latent representation," the "latent tensor," or the "features tensor".  

Moreover, a generic part $P$ of the model is understood to depend on some trainable parameters $\theta$. If 
$P(\cdot)$ is used instead, it denotes the function implemented by this part, mapping a given input to its corresponding output based on the current parameters.

Other specific notations are defined along the thesis when necessary.


