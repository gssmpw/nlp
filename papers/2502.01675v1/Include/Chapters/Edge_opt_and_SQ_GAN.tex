\chapter{\textcolor{black}{Goal-Oriented Resource Allocation in Edge Networks}}
\label{ch: Goal_oriented}
The content of this chapter is entirely based on the following publications:
\begin{quotation}
    \noindent \textit{\textbf{\large Goal-Oriented Communication for Edge Learning based on the Information Bottleneck}}\\
    \textit{Francesco Pezone, Sergio Barbarossa, Paolo Di Lorenzo}

    \vspace{0.1cm}
    \noindent \textit{\textbf{\large SQ-GAN: Semantic Image Coding Using
Masked Vector Quantization}}\\
    \textit{Francesco Pezone, Sergio Barbarossa, Giuseppe Caire}
\end{quotation}

\section{Introduction}
At this point, it should be clear that \gls{sc} is achievable thanks to generative models. The models presented in previous chapters have been specifically designed to enable the compression and reconstruction of images at very low values of \gls{bpp} while maintaining high levels of semantic preservation. By tweaking a limited number of parameters\footnote{For the \gls{spic} and \gls{cspic} it is possible to tweak the compression level of the coarse $\co$ and the compacted residual $\br'$. For the \gls{sqgan} it is possible to tweak the masking fractions $m_\x$ and $m_\x$. In both cases the effects have been discussed in the respective chapters in the Result sections.}, it is possible to easily explore the trade-off between compression and semantic preservation. However, identifying this optimal trade-off goes beyond the scope of \gls{sc} and is deeply rooted in the concept of \gls{goc}, as introduced in \sref{sec: SEMCOM go}.

This framework enables the communication system to be tailored to specific application objectives, accounting for external factors such as resource constraints and network conditions \cite{Strinati20216G}. In particular, the dynamic adaptation of compression parameters based on feedback mechanisms becomes essential for optimizing performance in varying environments.

This chapter introduces a methodology for achieving optimal Goal-Oriented resource allocation within \glspl{en} by leveraging stochastic optimization techniques. The primary objective is to ensure that the \gls{en} minimizes the average power consumption over time. Concurrently, the system aims to constrain the processing and transmission delays, as well as the level of performance over time.\footnote{Performance is quantified using task-specific metrics, which are defined subsequently.}

In contrast to existing research that predominantly focuses on \gls{en} optimization in isolation \cite{Mohammad2019Adaptive, Wang2018whenedge, Skatchkovsky2019optimizing, Merluzzi2020dynamic}, this chapter integrates \gls{goc} principles into the optimization process. Two distinct approaches are proposed: pure \gls{goc} via the \gls{gib} problem and \gls{sgoc} through the \gls{sqgan} model.

The \gls{gib} framework is particularly well-suited for \gls{goc}, as detailed in \sref{sec: SEMCOM ib}. By identifying the trade-off between complexity and relevance through the parameter $\beta$, the \gls{gib} method allows the system to reduce resource consumption while maintaining task performance \cite{Chechik2004GIB}. In \sref{sec: EN_ib} a mechanism based on a dynamic feedback will be proposed to adjust $\beta$ based on real-time network conditions and resource availability. This will enable the \gls{en} to autonomously optimize its operations, thereby ensuring efficient resource utilization in a \gls{goc} fashion.

Alternatively, when preserving semantic information is of paramount importance, the \gls{sqgan} model offers a robust solution for \gls{sgoc}. As introduced in \cref{ch: SQGAN}, the \gls{sqgan} model provides semantic image compression capabilities. By applying stochastic optimization techniques to dynamically adjust the masking fractions $m_\x$ and $m_\s$, it becomes possible to exert precise control over the performance metrics of the \gls{en}.

The integration of stochastic optimization and feedback mechanisms, informed by real-time monitoring of resource usage, network conditions, and performance indicators, allows the system to dynamically balance resource consumption and performance. This comprehensive framework is designed to orchestrate resource allocation within the \gls{en}, ensuring that computational and communication resources are utilized efficiently while satisfying the specific objectives of the application.

\begin{figure}[!t] 
    \centering 
    \includegraphics[width=0.9\textwidth]{Figures/Edge_network/schema_edge_network.png} 
    \caption[Edge Network Scheme]{\acrshort{en} scheme with connected \acrshort{ed}s transmitting signals and receiving feedback from the \acrshort{es}.}
    %[Schema of the Edge Network]{Edge Network scheme.} 
    \label{fig: EN en_scheme} 
\end{figure} 

By adopting these methodologies, the system is capable of transmitting only the most relevant information necessary for the task at hand, thereby optimizing overall performance within the constraints of available resources. The adaptive mechanisms ensure that the communication process is closely aligned with application-specific goals, resulting in enhanced efficiency and effectiveness.


The structure of this chapter is as follows. \sref{sec: EN_en desciption} provides a comprehensive overview of the \gls{en}architecture. \sref{sec: EN_ib} discusses the implementation of \gls{goc} within the \gls{en} using the \gls{gib} framework, presenting the mathematical formulations and optimization strategies for resource allocation. This section also explores how stochastic optimization facilitates the adjustment of the compression parameter $\beta$. \sref{sec: EN_nn} focuses on the application of the \gls{sqgan}-based \gls{sgoc} paradigm, highlighting how this model can be integrated into the \gls{en} and how to dynamically adjust the masking fractions $m_\x$ and $m_\s$.

\section{Edge Network}\label{sec: EN_en desciption}
Edge computing represents a decentralized computing architecture that brings data processing, storage, and networking capabilities closer to the physical location where data is generated \cite{Shi2016edge,Satyanarayanan2017edge,Liu2019edge}. This approach contrasts with traditional cloud computing, where data is transmitted to centralized data centers via the internet for processing. By moving computational tasks closer to the data source—the \textit{edge} of the network—latency is minimized, and real-time applications become more feasible. This is particularly beneficial for applications requiring immediate processing and response, such as autonomous vehicles, industrial automation, and real-time analytics.

An Edge Network (\gls{en}) typically consists of multiple Edge Devices (\glspl{ed}) connected via wireless communication to an Edge Server (\gls{es}). The \glspl{ed} are capable of data collection and preliminary processing, while the \gls{es} handles more intensive computational tasks and orchestrates the network resources. In this work, the \gls{en} is composed of $K$ \glspl{ed}, each connected to the \gls{es} through an Access Point operating at a predefined carrier frequency $f_0$. The total available bandwidth $B$ is equally divided among the \glspl{ed} and the wireless communication is characterized by flat-fading channels and additive white Gaussian noise.

For the purpose of focusing on the most significant factors affecting performance, several simplifications are made in the network model:

\begin{itemize} \item \textbf{Edge Devices (\glspl{ed}):} Each \gls{ed} is equipped with: \begin{itemize} \item \textbf{Central Processing Unit (CPU):} Responsible for pre-processing data, the CPU is characterized by a maximum power consumption $p_k^{cpu}$, a working clock frequency $f_k$, a maximum clock frequency $f_k^{max}$, and an effective switch capacitance $\eta_k$ \cite{Burd1996EffSwithc}. \item \textbf{Wireless Network Interface:} Facilitates wireless communication, allowing the \gls{ed} to transmit data at a rate $R_k$, with a maximum value $R_k^{max}$. This rate depends on the allocated bandwidth $B_k$, the flat-fading channel coefficient $h_k$, the noise power spectral density $N_0$, and the maximum transmission power $p_k^{tr}$. \end{itemize} \item \textbf{Edge Server (\gls{es}):} Acts as the central processing unit for the network and is responsible for final data processing and resource orchestration. The \gls{es} includes: \begin{itemize} \item \textbf{Central Processing Unit (CPU):} More powerful than those in the \glspl{ed}, the \gls{es} CPU is characterized by maximum power consumption $p^{cpu}$, working clock frequency $f_c$, maximum clock frequency $f_c^{max}$, and effective switch capacitance $\eta$. The \gls{es} allocates a portion of its computing time, denoted by $\frac{\tau_k}{\tau}$ or equivalently $f_k^{es}$, to each \gls{ed}, ensuring that $\sum_{k=1}^K f_k^{es} \leq f_c$. \end{itemize} \end{itemize}

Other components present in a real-world \gls{en} are omitted for simplicity, as their impact on the resource optimization problem is either limited or constant.

Resource optimization in an \gls{en} refers to the efficient management and allocation of computational and networking resources to achieve specific performance objectives \cite{Mach2017mobile, Huang2019multi, Mach2017mobile, Binucci2023goaloriented}. In this context, a dynamic resource allocation strategy is proposed, aiming to minimize the average power expenditure while satisfying constraints on the average service delay and the desired performance metrics. The service delay encompasses the time required for data pre-processing at the \gls{ed}, data transmission to the \gls{es}, and post-processing at the \gls{es}. The performance metrics are task-specific and could include measures such as reconstruction quality, classification accuracy, or other relevant indicators.

The optimization problem involves several controllable variables:

\begin{itemize} \item \textbf{CPU Clock Frequencies ($f_k$ and $f_k^{es}$):} Adjusting the clock frequencies of the CPUs at the \glspl{ed} and the \gls{es} affects both power consumption and processing delay. \item \textbf{Data Transmission Rate ($R_k$):} Modulating the transmission rate influences the transmission power consumption and the communication delay. \item \textbf{Model Hyperparameters:} Parameters of the encoding and decoding models, such as the trade-off parameter $\beta$ in the Information Bottleneck method or the masking fractions $m_\x$ and $m_\s$ in the \gls{sqgan}, impact the quality of the reconstructed data and the amount of information transmitted. \end{itemize}

Time is considered to be slotted, indexed by $t$, and tasks starting in one time-slot are completed within the same slot to prevent queue formation. The subsequent sections delve into the specifics of the optimization problems formulated for both the Information Bottleneck approach and the \gls{sqgan}-based \gls{sgoc} paradigm.

\section{Goal-Oriented communication based on the Information Bottleneck}\label{sec: EN_ib}
In this section the scenario composed of $K$ \glspl{ed} sending data to an \gls{ed} using a \gls{gib}-based encoder is discussed.

The solution of the \gls{gib} problem described in \sref{sec: SEMCOM ib} was obtained starting from two joint random variables $\x\sim \mathcal{N}(\mathbf{0}, \Sigma_{X})$ and $\y\sim \mathcal{N}(\mathbf{0}, \Sigma_{Y})$ of dimension $d_\x$ and $d_\y$, respectively, with the cross-covariance matrix denoted by $\Sigma_{XY}$. In this specific case, Chechik et al. were able to express in a closed-form solution the best transformation $z= \Phi(\x)$ able to optimize the \gls{ib} problem in \eref{eq: SEMCOM ib_problem} as a function of the trade-off parameter $\beta$  \cite{Chechik2004GIB}. This solution was represented by the linear projection $\z = \mathbf{A} \x + \boldsymbol{\xi}$, where $\boldsymbol{\xi}$ represent the added white Gaussian noise, while $\mathbf{A}$ is the projection matrix described in \eref{eq: EN_ib Matrice_A} and reported below:

\begin{equation}
    \mathbf{A} = \left\{\begin{matrix}
                [\mathbf{0}^T;...;\mathbf{0}^T] & 0 \leq \beta \leq \beta_1^c\\
                [\alpha_1\mathbf{v}_1^T; \mathbf{0}^T;...;\mathbf{0}^T] & \beta_1^c < \beta \leq \beta_2^c\\
                [\alpha_1 \mathbf{v}_1^T;\alpha_2\mathbf{v}_2^T;\mathbf{0}^T;\ldots;\mathbf{0}^T] & \beta_2^c < \beta \leq \beta_3^c\\
                \vdots\\
                [\alpha_1 \mathbf{v}_1^T;\alpha_2\mathbf{v}_2^T;\ldots;\alpha_{n_{\beta}}\mathbf{v}_{n_{\beta}}^T] & \beta_{n_{\beta}}^c < \beta 
                \end{matrix}\right.
    \tag{\ref{eq: SEMCOM Matrice_A}}
    \label{eq: EN_ib Matrice_A}
\end{equation}

The structure of the matrix $\mathbf{A}$ is strongly influenced by the parameter $\beta$. By changing $\beta$, the number of rows in $\mathbf{A}$ will change accordingly, up to a certain value $n_{\beta}$. The value $n_{\beta}$ can be computed starting from the covariance matrices $\Sigma_{X}$, $\Sigma_{Y}$, and $\Sigma_{XY}$.

Due to the complicated structure of the matrix $\mathbf{A}$, in this section, only some specific values of  $\beta$ will be considered. Instead of letting $\beta$ vary from $0$ to infinity, a finite subset composed as follows will be taken into account: 
\begin{equation} 
    \mathcal{B}_k = \{ \beta_{2_k}^c, \beta_{3_k}^c, \ldots, \beta_{n_{\beta_k}}^c, 10*\beta_{n_{\beta_k}}^c\}. \label{eq: EN_ib beta_set} 
\end{equation} 


These values correspond to the last values of $\beta$ before the number of rows in $\mathbf{A}_k$ is increased. They are selected in a way that at least one row is considered, thus avoiding cases where no data is transmitted, and the maximum value of $\beta_k= 10*\beta_{n_{\beta_k}}^c$ is sufficiently high to be considered as infinite.\

At the \gls{es}, the goal is to reconstruct an estimate $\hat{\y}_k=\mathbf{M}_k\z_k$ of the original data $\y_k$. The specifications of the matrix $\mathbf{M}_k$ will be described in the following when discussing the evaluation metric.\\

After this introductory review and clarification about the \gls{gib} problem, it is possible to discuss how the \gls{en} is structured and what the role of the optimization variables is. This will be done by discussing how the power consumption, the delays and the evaluation metric are represented in this framework.\

\begin{itemize}[label={}] 
    \item {\textbf{Power consumption:}} The power consumption represents the objective function of the optimization problem. This term is composed of the contributions of the \glspl{ed} and the \gls{es}. After the observation of the data, the first task to be performed is the encoding based on the \gls{gib}. This task will require the CPU of the \gls{ed} to be active and work at a certain clock frequency $f_k(t)$. The power consumption will then be a function of the frequency and expressed as: \begin{equation} P_k^{ib}(f_k(t)) = \eta_k \cdot (f_k(t))^3 \equiv P_k^{ib}(t), \end{equation} where $\eta_k$ is the effective switch capacitance of processor $k$ \cite{Burd1996EffSwithc}.

    For simplicity of notation, the power consumption will be written only as a function of time as $P_k^{ib}(f_k(t)) \equiv P_k^{ib}(t)$. This notation will be used for all the other terms in the following sections.

    After the encoding step, the data is ready to be transmitted. The transmission power can be expressed as a function of the transmission rate $R_k(t)$ using Shannon's formula:
    \begin{equation}
        P_k^{tr}(R_k(t)) =  \frac{B_k N_0}{h_k(t)} \left[  {\rm exp} \left(\frac{R_k(t) \ln(2)}{B_k} \right)   -1 \right] \equiv P_k^{tr}(t).
    \end{equation}

    After the data has been transmitted to the \gls{es}, the final processing has to be performed. The power consumption of the CPU at the \gls{es} is evaluated in the same way as the one at the \gls{ed}:
    \begin{equation}
        P^{es}(f_c(t)) = \eta \cdot (f_c(t))^3 \equiv P^{es}(t).
    \end{equation}
    These terms can be combined to obtain the total power consumption of the \gls{en}:

    \begin{equation}
        P^{tot}(t) = P^{es}(t) + \sum_{k=1}^K \Gamma_k P_k^{ib}(t) + P_k^{tr}(t),
        \label{eq: EN_ib total power}
    \end{equation}
    where $\Gamma_k$ is the tunable term that weights the power consumption of the CPU of the \gls{ed}.

    \item {\textbf{Delay:}}
    Every stage of the processing pipeline will be associated with a specific delay. After the data is collected, the encoding is performed. The first important term influencing the computational delay at the \gls{ed} is given by the number of operations to perform the matrix multiplication $\z_k = \mathbf{A}_k \x + \boldsymbol{\xi}$. This value is expressed as:
    \begin{equation}
        W_k(\beta_k(t)) = d_x\cdot n_{\beta_k}(t) \equiv W_k(t).
    \end{equation}
    The other term influencing the encoding delay is the number of \gls{flops} that the CPU can perform at a given clock frequency $f_k(t)$. This value depends on the product $\rho_k$ between the number of cores and the number of \gls{flopc} of the CPU. After the CPU has been selected, this value is fixed and cannot change. By considering all these terms, the delay of the encoding process can be expressed as:
    \begin{equation}
        D_k^{ib}(f_k(t)) = \frac{W_k(t)}{FLOPS(f_k(t))} = \frac{W_k(t)}{f_k(t) \cdot \rho_k} \equiv D_k^{ib}(t).
    \end{equation}
    After the encoding, the transformation $\z$ has to be transmitted. The delay involved with the transmission is dependent on the transmission rate $R_k(t)$ and on the number of bits to be transmitted $N_k(t)$. This number of bits corresponds to the entropy of the random Gaussian variable $\z_k(\beta_k(t))$ and can be expressed as:
    \begin{equation}
        N_k(\beta_k(t)) = h(\z_k(\beta_k(t)))  \equiv N_k(t),
    \end{equation}
    The delay associated with the transmission step can be expressed as:
    \begin{equation}
        D_k^{tr}(\beta_k(t), R_k(t)) = \frac{N_k(t)}{R_k(t)} \equiv D_k^{tr}(t).
    \end{equation}
    At the receiver, every sub-process associated with a device $k$ is performed. The estimate $\hat{\y}_k=\mathbf{M}_k\z_k$ has to be evaluated, and this matrix multiplication requires a number of operations equal to:
    \begin{equation}
        W_k^{es}(\beta_k(t)) = d_y\cdot n_{\beta_k}(t) \leq  d_y \cdot d_{min} \equiv W_k^{es},
    \end{equation}
    with $n_{\beta_k}(t)\leq d_{min}= \min\{ d_x, d_y\}$.
    
    Overall, this processing at the \gls{es} is associated with a delay per \gls{ed} equal to:
    \begin{equation}
        D_k^{es}(f(t)) = \frac{W_k^{es}}{FLOPS(f_k^{es}(t))} = \frac{W_k^{es}}{f_k^{es}(t) \cdot \rho_k^{es}} \equiv D_k^{es}(t),
    \end{equation}
    where $\rho_k^{es}$ is the product between the number of cores and the number of Floating Point Operations Per Cycle of the CPU at the \gls{es}.

    By considering all the three components, it is possible to express the total delay associated with the process of every \gls{ed} as:
    \begin{equation}
        D_k^{tot}(t) = D_k^{es}(t) + D_k^{ib}(t) + D_k^{tr}(t).
    \end{equation}

    \item {\textbf{Evaluation metric:}}
    The last term to consider is the evaluation metric.

    After the transformation reaches the \gls{es}, it has to be processed to estimate $\hat{\y}_k=\mathbf{M}_k\z_k$. This task is performed via a matrix $\mathbf{M}_k$ designed to minimize the \gls{mse} between $\y_k$ and $\hat{\y}_k$.

    This process is associated the \gls{nmse} evaluation metric that can be evaluated in closed-form solution as:
    \begin{equation}
        G_k(\beta_k(t)) = NMSE_{\beta_k(t)}(\y_k, \hat{\y}_k) =  1 - \frac{\mathrm{tr} \left( \bSigma_{Y_kZ_{\beta_k(t)}} \bSigma_{Z_{\beta_k(t)}}^{-1} \bSigma_{Y_kZ_{\beta_k(t)}}^{T}\right)}{\mathrm{tr}(\bSigma_{Y_k})} \equiv G_k(t).
    \end{equation}

\end{itemize}

Now that all the terms have been introduced, it is possible to discuss and present the optimization problem. As already mentioned at the beginning of this chapter, the goal is to minimize the average power consumption over time while respecting the average constraints on the delay and the evaluation metric.

The optimization problem can then be cast as follows:
\begin{mini}|s|[0]
    {\mathbf{\Psi}(t)}{\lim_{T \to +\infty}\; \frac{1}{T} \sum_{t=1}^T  \mathbb{E}[P^{tot}(t)] }
    {}{}
    \addConstraint{\lim_{T \to +\infty}\; \frac{1}{T} \sum_{t=1}^T  \mathbb{E}[D_k^{tot}(t)] \leq D_k^{avg}\qquad \forall k }{}
    \addConstraint{ \lim_{T \to +\infty}\; \frac{1}{T} \sum_{t=1}^T  \mathbb{E}[G_k(t)] \leq G_k^{avg}\qquad \forall k }{}
    \addConstraint{0 \leq f_k(t) \leq f_k^{max} \qquad \forall k,t }{}
    \addConstraint{0 \leq R_k(t) \leq R_k^{max}(t) \qquad \forall k,t }{}
    \addConstraint{\beta_k(t) \in \mathcal{B}_k  \qquad \forall k,t}{}
    \addConstraint{0 \leq f_c(t) \leq f_c^{max} \qquad \forall t}{}
    \addConstraint{f_k^{es}(t) \geq 0 \quad \forall k,t}, \qquad {\sum_{k=1}^K f_k^{es}(t) \leq f_c(t)  \quad \forall t,}{}
    \label{eq: EN_ib initial opt problem}
\end{mini}
where $\mathbf{\Psi}(t) = [\{f_k(t)\}_k,\{ R_k(t)\}_k, \{\beta_k(t)\}_k, \{f_k^{es}(t)\}_k, f_c(t)]$ is the vector of the optimization variables at time $t$.
The first two constraints refer to the average delay $D_k^{avg}$ and the average evaluation metric $G_k^{avg}$ constraints. All the others are instead used to define the feasible space of the optimization variables in $\mathbf{\Psi}(t)$ and the value of the maximum transmission rate $R_k^{max}(t)$ at time $t$ is evaluated as follows:
\begin{equation}
    R_k^{max}(t) = B_k\; log \left[ 1 + \frac{p_k^{tr}\; h_k(t)}{N_0 B_k} \right]
\label{eq: EN_ib maximum rate}
\end{equation}


This optimization problem is complex to solve. However, in the next subsection will be shown how to handle it resorting to stochastic optimization \cite{Neely2010Lyapunov}.
\subsection{The Edge Network Optimization}
The first step to handle problem \eref{eq: EN_ib initial opt problem} is to introduce two \textit{virtual queues} for each \gls{ed}. These virtual queues will be associated to the long-term delay and evaluation metric constraints, $T_k(t)$ and $U_k(t)$ respectively. Proceeding similarly as in \cite{Merluzzi2021EN}, these two virtual queues evolve as follows:
\begin{align}
    T_k(t+1) &= \max [0,T_k(t) + \varepsilon_k(D_k^{tot}(t) - D_k^{avg})] \label{eq: EN_ib virtulQueue T_true}\\
    U_k(t+1) &= \max [0,U_k(t) + \nu_k(G_k(t) - G_k^{avg})],  \label{eq: EN_ib virtulQueue U_true}
\end{align}
where $\epsilon_k$ and $ \nu_k $ are the learning rate for the update of the virtual queues. 

Based on these virtual queues is possible to define the \textit{Lyapunov function} $L(\mathbf{\Theta}(t))$ as:
\begin{equation}
    L(\mathbf{\Theta}(t)) = \frac{1}{2} \sum_{k=1}^K T_k^2(t) + U_k^2(t),
\label{eq: EN_ib Lyapunov function}
\end{equation}
where $\mathbf{\Theta}(t) = [\{T_k(t)\}_k, \{U_k(t)\}_k]$ is the vector composed by all the virtual queues at time $t$. The idea is to use this Lyapunov function to satisfy the constraints on $D_k^{avg}$ and $G_k^{avg}$ by enforcing the stability of $L(\mathbf{\Theta}(t))$. To this scope it is introduced the so called \textit{drift-plus-penalty} function
\begin{equation}
    \Delta_p(\Theta(t)) = \mathbb{E}\left[L({\Theta}(t+1))-L({\Theta}(t))+V\cdot P^{tot}(t)  \;\Big|\; \Theta(t)\right],
    \label{eq: EN_ib drift_plus_penalty}
\end{equation}
whose minimization aims to stabilize the virtual queues in \eref{eq: EN_ib virtulQueue T_true} and \eqref{eq: EN_ib virtulQueue U_true}, while promoting low-power solutions for large values of the parameter $V$.

Using stochastic approximation arguments \cite{Neely2010Lyapunov} in \aref{app: EN_ib}, it is possible to maximize the drift-plus-penalty function with the suitable upper-bound and obtain the following optimization problem:
\begin{mini}|s|[0]
    {\mathbf{\Psi}(t)}{\sum_{k=1}^K \bigg[ \epsilon_k T_k(t)D_k^{tot}(t) + \nu_k U_k(t) G_k(t)\bigg]  + V P^{tot}(t) }{}{}
    \addConstraint{\mathbf{\Psi}(t) \in \mathcal{T}(t),}{}
    \label{eq: EN_ib per-slot opt problem structure}
\end{mini}
where $\mathcal{T}(t)$ indicates the space of possible solutions given by the constraints on the optimization variables. 

This per-slot deterministic optimization problem can now be solved at every time slot $t$ and the constant update of the virtual queues will ensure that, over time, the two constrains on the average delay and the average evaluation metric are satisfied.

The optimization of \eref{eq: EN_ib per-slot opt problem structure}, even if much simpler than \eref{eq: EN_ib initial opt problem}, is still non-trivial. This is a direct cause of its mixed-integer nature.

However, the time-slot optimization problem can be decoupled into two sub-problems, one associated with the \gls{ed} parameters, i.e., $[\{f_k(t)\}_k,\{ R_k(t)\}_k,\{\beta_k(t)\}_k]$, and the other associated with the \gls{es} parameters, i.e., $[\{f_k^{es}(t)\}_k, f_c(t)]$.

\begin{itemize}[label={}]
    \item {\textbf{ED sub-problem:}}
    The optimization problem associated with the $k$-th \gls{ed} can be expressed as follows:

    \begin{mini}|s|[0]
        {\mathbf{\Psi}^{ed}(t)}{g_k : g_k=\frac{\epsilon_kT_k(t)N_k(t)}{R_k(t)} + \frac{\epsilon_kT_k(t)W_k(t)}{f_k(t)\rho_k } + \nu_k U_k(t)G_k(t) +}{}{} \breakObjective{\qquad  \qquad+ V \frac{B_k N_0}{h_k(t)} {\rm exp} \left(\frac{R_k(t) ln(2)}{B_k} \right) + V \Gamma_k \eta_k (f_k(t))^3 }{}{}
        \addConstraint{\mathbf{\Psi}^{ed}(t) \in \mathcal{T}^{ed}(t),}{}
        \label{eq: EN_ib per-slot opt ed}
    \end{mini}
    where $\mathbf{\Psi}^{ed}(t) = [f_k(t), R_k(t), \beta_k(t)]$ is the vector of the optimization variables at time $t$ for the \gls{ed} sub-problem and $\mathcal{T}^{ed}(t)$ is the space of possible solutions given by the constraints on the optimization variables at the \gls{ed}.

    For a fixed value of the parameters $\beta_k(t)$ it is possible to evaluate a close form solution of both the optimal values of the clock frequency $f_k(t)$ and the transmission rate $R_k(t)$, \aref{app: EN_ib ed opt} for more details. These solutions are given by:
    \begin{equation}
        R_k^*(t) = \frac{2 B_k}{ln(2)}\; W\! \!\left(\sqrt{\frac{\epsilon_k T_k(t)\; ln(2)\; h_k(t)N_k(t)\; }{4 B_k^2\;V \;N_0}}\right)\; \Biggr|_0^{R_k^{max}(t)}
    \label{eq: EN_ib optimal rate}
    \end{equation}
    \begin{equation}
        f_k^* (t) = \sqrt[4]{\frac{\epsilon_k T_k(t) W_k(t)}{3 V \Gamma_k \eta_k \rho_k} }\; \Biggr|_0^{f_k^{max}},
    \label{eq: EN_ib optimal freq device}    
    \end{equation}
    where $W(\cdot)$ in \eref{eq: EN_ib optimal rate} denotes the principal branch of the Lambert function.
    
    At this point the optimal value $\beta_k^*(t)$ can be found by simply searching the value in $\mathcal{B}_k$ that, together with \eref{eq: EN_ib optimal rate} and \eqref{eq: EN_ib optimal freq device}, minimize the objective of the sub-problem associated with device k in \eref{eq: EN_ib per-slot opt ed}. 
    \item {\textbf{ES sub-problem:}}
    The optimization problem associated with the \gls{es} can be expressed as follows:
    \begin{mini}|s|[0]
        {\mathbf{\Psi}^{es}(t)}{g : g= \sum_{k=1}^K \frac{\epsilon_kT_k(t)W_{max}^{es}}{f_k^{es}(t)\rho_k^{es}} + V \eta (f_c(t))^3 }{}{}
        \addConstraint{\mathbf{\Psi}^{es}(t) \in \mathcal{T}^{es}(t),}{}
        \label{eq: EN_ib per-slot opt ed}
    \end{mini}
    where $\mathbf{\Psi}^{es}(t) = [\{f_k^{es}(t)\}_k, f_c(t)]$ is the vector of the optimization variables at time $t$ for the \gls{es} sub-problem, $\mathcal{T}^{es}(t)$ is the space of possible solutions given by the constraints on the optimization variables at the \gls{es} and $W_{max}^{es} = \displaystyle\max_{k} W_k^{es}$.
    
    The choice of substituting $W_k^{es}$ with $W_{max}^{es}$ is to avoid a combinatorial optimization problem. By maximizing the number of operations in such a way it is in fact possible to identify the optimal value the clock frequencies $f_k^{es}(t)$ and $f_c(t)$ as:
    \begin{equation}
        f_c^{*} (t) = \frac{\sqrt{\sum_{k=1}^K \sqrt{\frac{\epsilon_k T_k(t)W_{max}^{es}}{\rho_k^{es}}}}}{\sqrt[4]{3V\eta}} \; \Biggr|_0^{f_{c}^{max}},
    \label{eq: EN_ib optimal freq device ES}    
    \end{equation} 
    \begin{equation}
        f_k^{es*}(t) = \frac{\sqrt{\frac{\epsilon_k T_k(t)W_{max}^{es}}{\rho_k^{es}}}}{\sqrt{\sum_{k=1}^K \sqrt{\frac{\epsilon_k T_k(t)W_{max}^{es}}{\rho_k^{es}}}}\sqrt[4]{3V\eta} },  \qquad \forall k.
    \label{eq: EN_ib optimal freq ES}    
    \end{equation}
    More details in \aref{app: EN_ib ed opt}.

\end{itemize}

The final algorithm to solve the resource allocation optimization problem in \eref{eq: EN_ib initial opt problem} can be summarized as the algorithm in \tref{tab: EN_ib algorithm}.


\begin{table}[ht]
    \centering
    \rule{\textwidth}{0.4pt} % Line at the top
    \vspace{-22pt} % Adjust the space between the top line and the caption
    \caption{Edge Network Resource Allocation Algorithm}
    \vspace{-10pt} % Adjust the space between the caption and the line below it
    \rule{\textwidth}{0.4pt} % Line below the caption
    \vspace{-15pt} % Adjust the space between the line and the algorithmic content
        \begin{algorithmic}[1]
            \item Set the Lyapunov parameters $V$, $T_k(0)$, $U_k(0)$, $\epsilon_k$ and $\nu_k \;\;\forall k$
            \item Set the desired values for delay $D_k^{avg}$ and evaluation metric $G_k^{avg}$
            \For{$t$ at least until $T_k$ and $U_k$ converges}
                \State Compute the optimal $R_k^*(t)$ and $f_k^*(t)$ with \eref{eq: EN_ib optimal rate} and \eqref{eq: EN_ib optimal freq device} as a function of $\beta_k(t)$ $\forall k$.
                \State Select the optimal $\{R_k^*(t)\}_k$,  $\{f_k^*(t)\}_k$ and $\{\beta_k^*(t)\}_k$ that minimizes \eref{eq: EN_ib per-slot opt ed} $\forall k$.
                \State Evaluate the optimal $f_c^*(t)$ with \eref{eq: EN_ib optimal freq device ES} and then $f_k^{es*}(t)$ with \eref{eq: EN_ib optimal freq ES} $\forall k$.
                \State Run the online inference task
                \State Update  the virtual queues $T_k$ and $U_k$ $\forall k$ via \eref{eq: EN_ib virtulQueue T_true} and \eqref{eq: EN_ib virtulQueue U_true}
                
            \EndFor
        \end{algorithmic}
    \vspace{-10pt} % Adjust the space between the content and the bottom line
    \rule{\textwidth}{0.4pt} % Line at the bottom
    \label{tab: EN_ib algorithm}
\end{table}


\subsection{Results}
In this section the results obtained by solving the optimization problem in \eref{eq: EN_ib initial opt problem} will be presented using the algorithm in \tref{tab: EN_ib algorithm}. 

To this scope the \gls{en} is designed to be composed of $K=100$ \glspl{ed} that sends independent tasks to a common \gls{es}. These \glspl{ed} are placed at a random distance, from 5 to 150 meters, from the \gls{es}. The maximum transmit power is $p_k^{tr} = 100mW$ . The access point operates with a carrier frequency $f_0 = 1GHz$ and the wireless channels are generated using the Alpha-Beta-Gamma model from \cite{MacCartney2016AlphaBetaGamma}. The total available bandwidth per \gls{ed} is set to $ B_k = 1kHz $ and the noise spectral density at the receiver is set to $ N_0 = -174  dBm/Hz $.

Both \gls{es} and all the \glspl{ed} are equipped with a $1.8 \; GHz $ CPU (Intel$^{\circledR}$ Celeron$^{\circledR}$  6305E Processor 4M Cache) and the product between the numbers of cores and the number of \gls{flopc} is $\rho_k=4$. With this designing choice the parameters for CPUs are set to $ f_c^{max} = f_k^{max} = 1.8GHz $, and $  \eta = \eta_k = 2.57*10 ^ {-27} $, for all $k$. 

The input data $\x_k$ has a dimension of $d_x=750$, whereas the output $\y_k$ has $d_y=8$ and this is the same for all the \glspl{ed}. \\
\begin{figure}[!t]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Edge_network/IB/final_output_log_log_ib.pdf}
        \caption*{(a)} % Caption under image without adding to list
    \end{subfigure}%
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Edge_network/IB/final_output_log_scale_ib.pdf}
        \caption*{(b)}
    \end{subfigure}
    \caption[Goal-Oriented communication Edge Network trade-off plots ]{(a) The effects of $\Gamma_k\in \{0.5, 1, 8, 30, 50\}$ on the power consumption of the \gls{ed} and the \gls{es}. In this plot the value of $G_k^{avg}$ changes as seen in the legend while the delay is fixed to $D_k^{avg}= 0.003s$. (b) The trade-off between device power consumption as a function of the \gls{nmse}. The value of the delay changes as in the legend and $\Gamma_k=8$.}
    \label{fig: EN_ib trade-off}
\end{figure}

After setting these architectural parameters, it is possible to execute the algorithm in \tref{tab: EN_ib algorithm} multiple times for different values of $D_k^{avg}$ and $G_k^{avg}$ to evaluate the performance of the \gls{en} in different scenarios. Every time, the algorithm is evaluated for the time necessary to let the virtual queues converge. After convergence, the average power consumption, the average delay and the average evaluation metric are obtained by averaging their values over the following $1000$ time-slots. The results are shown in \fref{fig: EN_ib trade-off}.

In \fref{fig: EN_ib trade-off}~(a), the effects of $\Gamma_k$ on the power consumption are shown. This parameter was introduced in \eref{eq: EN_ib total power} to adjust the importance of the CPU and transmission power consumption in the \gls{ed}. In the plot its effect are showed, where the total power consumption at the \gls{ed} versus the power consumption of the \gls{es} is reported. The different lines represent different values of $G_k^{avg}$ at a predefined $D_k^{avg}=0.003,\text{s}$.

By letting $\Gamma_k$ vary, it is possible to deliberately decide if the CPU or the transmission should consume more or less power. It was chosen to set $\Gamma_k \in {0.5, 1, 8, 30, 50}$.

As this value increase the points move toward the right showing that the power consumption at the \gls{es} increases. This is due to the fact that by increasing the weight of the CPU power consumption of the \gls{ed}, the optimization algorithm will prefer to process the data at lower frequencies. This will increase the associated delay that will require the \gls{es} to process the data faster, resulting in a higher power consumption at the \gls{es}.

Moreover, it is possible to identify a value at which the total power consumption of the \gls{ed} is minimized. This represents a very important point since, in general, \glspl{ed} are not connected to the main power supply like the \gls{es}. Minimizing their power consumption might be very helpful.

For almost all the different lines the minimum in the power consumption of the \gls{ed} is reached at $\Gamma_k=8$.  For this reason this value is used for the next plot.

In \fref{fig: EN_ib trade-off}~(b), the trade-off between the power consumption of the \gls{ed} and the evaluation metric is shown as the delay requirements change. This is a very fundamental trade-off that is used to fully characterize the network. In fact, it allows for a desired value of power consumption, an idea of the value of the associated delay and \gls{nmse}. 




\section{Semantic-Goal-Oriented communication based on the SQ-GAN}\label{sec: EN_nn}
A more interesting approach is obtained by considering a less theoretical scenario.

In a real-world scenario, the \gls{en} is composed of a set of \glspl{ed} that are required to deal with non-simple data domains. Considering the data to follow a Gaussian distribution to apply the \gls{gib} might not always be possible.

Additionally, there are cases in which the goal of the communication lies in the transmission of the semantic information.

In this section, instead of encoding the data via \gls{gib}, the \gls{sqgan} is employed. In such a scenario, the orchestration of the resources is oriented to the transmission of the semantic information that the image $\x$ and the \gls{ssm} $\s$ contain.

The general setup of the \gls{en} discussed in the previous section will hold also in this specific application. However, some changes will be applied due to the design and nature of the \gls{sqgan}.

While in the \gls{gib} case the quality of the encoding was conditioned on the parameter $\beta$, in the \gls{sqgan} case the quality of the encoding is conditioned on the two masking fractions $m^{\x}$ and $m^{\s}$. Moreover, the number of operations performed by the model is mostly independent of the value of the masking fractions.

For this reason, the following modifications are applied to the \gls{en}. 
\begin{itemize}[label={}] 
    \item \textbf{ED:} For the \gls{ed}, some minor modifications are introduced: 
    \begin{itemize}[label={}] 
        \item \textbf{CPU:} The CPU is composed as before. Each \gls{ed} is equipped with a CPU with maximum power consumption $p_k^{cpu}$, working clock frequency $f_k$, maximum clock frequency $f_k^{max}$, and the effective switch capacitance of the processor $\eta_k$~\cite{Burd1996EffSwithc}.
        
        The difference is that, in this case, the CPU will be used only to perform the part of operations that are dependent on the masking fractions. This means that it will be employed only to perform the vector quantization.

        All the other constant computations will be implemented by a dedicated analog chip.

        \item \textbf{Analog chip:} The analog chip is a specifically designed chip that can perform the encoding and the \gls{samm}. Being independent of the masking fraction, its contribution will not be taken into account in the optimization. The only assumption is that it is powerful enough not to represent a bottleneck in the computations.

        \item \textbf{Wireless Network Interfaces:} The network interface remains unchanged. Each \gls{ed} will be able to transmit data at a rate $R_k$ with maximum value of $R_k^{max}$. This value will depend on the available bandwidth $B_k$, the flat-fading coefficient $h_k$, the noise power spectral density at the receiver $N_0$, and the maximum transmission power $p_k^{tr}$.
    \end{itemize}
    \item \textbf{ES:} For the same reasons of the independence from the masking fractions, the \gls{es} will not be considered in the optimization. All the operations at the receiver will not be taken into account.
\end{itemize}

After these necessary considerations, it is possible to start discussing all the optimization problem terms. As before, the power consumption, the delay, and the evaluation metric will be considered separately.

\begin{itemize}[label={}] 
    \item \textbf{Power Consumption:} The task of the device, after the analog chip has correctly encoded the data and evaluated the relevance score via the \gls{samm}, is to perform the vector quantization. The power consumption of the CPU associated with this task can be expressed as: 
    \begin{equation} 
        P_k^{vq}(f_k(t)) = \eta_k \cdot (f_k(t))^3 \equiv P_k^{vq}(t), 
    \end{equation} where $ \eta_k $ is the effective switch capacitance of processor $k$.

    After the vector quantization, the data is ready to be transmitted, and the power consumption of the transmission is evaluated as a function of the transmission rate $R_k(t)$ as:
    \begin{equation}
        P_k^{tr}(R_k(t)) =  \frac{B_k N_0}{h_k(t)} \left[  {\rm exp} \left(\frac{R_k(t) \ln(2)}{B_k} \right)   -1 \right] \equiv P_k^{tr}(t).
    \end{equation}

    These two terms are then summed to obtain the total power consumption of the \gls{ed} as:
    \begin{equation}
        P_k^{tot}(t) = P_k^{vq}(t) + P_k^{tr}(t).
    \end{equation}

    \item \textbf{Delay:} The first part of the delay is associated with the time required to perform the vector quantization. This term is proportional to the number of operations required to perform the vector quantization. By considering the same hyperparameters described in \cref{ch: SQGAN}, this value assumes the following form:
    \begin{equation}
        W_k(m_\x^k(t), m_\s^k(t)) = 769 \cdot (|\C| - 1) \cdot 512  \cdot [m_\x^k(t) + m_\s^k(t)] = 402{,}783{,}744 \cdot [m_\x^k(t) + m_\s^k(t)] \equiv W_k(t),
    \end{equation}
    where $769 = 256 \cdot 3 + 1$ is the number of operations to evaluate the distance between two vectors in $256$ dimensions, $|\C|=1024$ is the number of codewords in the codebooks,  and $512 \cdot [m_\x^k(t) + m_\s^k(t)]$ is the number of selected vectors after the \gls{samm}.

    The associated delay is expressed as:
    \begin{equation}
        D_k^{vq}(m_\x^k(t), m_\s^k(t), f_k(t)) = \frac{W_k(t)}{\mathrm{FLOPS}(f_k(t))} = \frac{W_k(t)}{f_k(t) \cdot \rho_k} \equiv D_k^{vq}(t),
    \end{equation}
    where $\rho_k$ is the product between the number of cores and the number of Floating Points Operations Per Cycle of the CPU.

    After the vector quantization, the data is ready to be sent. The number of bits to be sent can be expressed as a function of the two masking fractions by following the steps in \eref{eq: SQGAN BPP} as:
    \begin{equation}
        N_k(m_\x^k(t), m_\s^k(t)) = 512 \cdot [10(m_\x^k(t) + m_\s^k(t)) + 2] \equiv N_k(t),
    \end{equation}
    where $512$ is the maximum number of elements to be transmitted. The delay associated with the transmission is then expressed as:
    \begin{equation}
        D_k^{tr}(m_\x^k(t), m_\s^k(t), R_k(t)) = \frac{N_k(t)}{R_k(t)} \equiv D_k^{tr}(t).
    \end{equation}

    The total delay is then expressed as:
    \begin{equation}
        D_k^{tot}(t) = D_k^{vq}(t) + D_k^{tr}(t).
    \end{equation}
    \item \textbf{Evaluation Metric:} In \sref{sec: SQGAN numerical results}, it was shown that the evaluation metrics are in general functions of both $m_\x^k(t)$ and $m_\s^k(t)$. The \gls{lpips} metric shown in \fref{fig: SQGAN lpips 3d plot} is a clear example of this relationship. Both the masking fractions influence the result. For this reason, in this \gls{en} application, the evaluation metric considered is the \gls{lpips}.

    Working directly on the \gls{lpips} is not the best option. The case discussed in the previous section with the \gls{gib} approach is an example. The best value for the optimization variable $\beta_k^*$ was selected via a grid search approach. This is not an elegant approach and can be improved.

    The idea is to approximate the true metric $G_k(m_\x^k(t), m_\s^k(t))$ with a function $G_k^{approx}(m_\x^k(t), m_\s^k(t))$. This function will be used to replace the original one in the optimization problem of the \gls{en}, removing the grid search approach in two variables.

    The smooth structure of the \gls{lpips}, shown in \fref{fig: SQGAN lpips 3d plot}, makes this approximation even easier. The \gls{lpips} can, in fact, be approximated with the following separable function:
    \begin{equation}
        G_k^{approx}(m_\x^k(t), m_\s^k(t)) = \frac{a}{(m_\x^k(t))^b} + \frac{c}{m_\s^k(t)} \equiv G_k^{approx}(t).
    \end{equation}
    By fitting this function to the true \gls{lpips}, the $l_2$ error is on the order of $1\mathrm{e}{-5}$. The optimal values for the parameters are selected to be $a=2.58\mathrm{e}{-1}$, $b=1.20\mathrm{e}{-1}$, and $c=2.95\mathrm{e}{-3}$.
\end{itemize}

By knowing all the components of the \gls{en}, the optimization problem can be formulated as follows:
\begin{mini}|s|[0]
    {\mathbf{\Psi}(t)}{\lim_{T \to +\infty}\; \frac{1}{T} \sum_{t=1}^T  \mathbb{E}[P^{tot}(t)] }
    {}{}
    \addConstraint{\lim_{T \to +\infty}\; \frac{1}{T} \sum_{t=1}^T  \mathbb{E}[D_k^{tot}(t)] \leq D_k^{avg}\qquad \forall k }{}
    \addConstraint{ \lim_{T \to +\infty}\; \frac{1}{T} \sum_{t=1}^T  \mathbb{E}[G_k(t)] \leq G_k^{avg}\qquad \forall k }{}
    \addConstraint{0 \leq f_k(t) \leq f_k^{max} \qquad \forall k,t }{}
    \addConstraint{0 \leq R_k(t) \leq R_k^{max}(t) \qquad \forall k,t }{}
    \addConstraint{0 \leq m_\x^k(t) \leq 1  \qquad \forall k,t}{}
    \addConstraint{0 \leq m_\s^k(t) \leq 1  \qquad \forall k,t}{}
    \label{eq: EN_nn initial opt problem}
\end{mini}
with  $\mathbf{\Psi}(t) = [\{f_k(t)\}_k,\{ R_k(t)\}_k, \{m_\x^k(t)\}_k, \{m_\s^k(t)\}_k]$ the vector of the optimization variables at time $t$. The only constraint on the optimization variable that is time dependent is $R_k^{max}(t)$, evaluated at every time-step as in \eref{eq: EN_ib maximum rate}.

\subsection{The Edge Network Optimization}
After the formulation of the minimization problem, it is possible to proceed with the optimization. The first step is to introduce two \textit{virtual queues} for each \gls{ed}, one for the long-term constraint on delays, $T_k(t)$, and the other one for the long-term constraint on the metric, $U_k(t)$.

The update of the virtual queues is expressed as: 
\begin{align}
    T_k(t+1) &= \max [0,T_k(t) + \varepsilon_k(D_k^{tot}(t) - D_k^{avg})] \label{eq: EN_nn virtulQueue T_true}\\
    U_k(t+1) &= \max [0,U_k(t) + \nu_k(G_k(t) - G_k^{avg})],  \label{eq: EN_nn virtulQueue U_true}
\end{align}
where $\epsilon_k$ and $ \nu_k $ are the learning rate for the update of the virtual queues. 

While the virtual queue $T_k(t)$ can be used directly, for $U_k(t)$ a clarification is needed. The virtual queue $U_k(t)$ will always be updated as shown in \eref{eq: EN_nn virtulQueue U_true}. However, for defining the Lyapunov function $L(\Theta(t))$, the virtual queue will be written as: 
\begin{equation} 
    U_k(t+1) = \max [0,U_k(t) + \nu_k(G_k^{approx}(t) - G_k^{avg})]. \label{eq: EN_nn virtulQueue U_approx} 
\end{equation} 
By using the approximation of the \gls{lpips} instead of the true value, it is possible to work with a smooth continuous function. This will help in the optimization process and avoid the need for a grid search approach.

In the remainder of this section, the virtual queue $U_k(t)$ will be considered as in \eref{eq: EN_nn virtulQueue U_approx}, unless differently specified.

The Lyapunov function $L(\Theta(t))$ and the drift-plus-penalty function $\Delta(\Theta(t))$ are defined and obtained as in \eref{eq: EN_ib Lyapunov function} and \eref{eq: EN_ib drift_plus_penalty}, respectively. The final per-slot optimization problem has the same form as the one in \eref{eq: EN_ib per-slot opt problem structure}. By substituting the correct expressions of delay, power, and evaluation metric specific to this application, the per-slot problem can be written as: 
\begin{mini}|s|[0]
    {\mathbf{\Psi}(t)}{\sum_{k=1}^K \bigg[ \frac{\epsilon_kT_k(t)N_k(t)}{R_k(t)} + \frac{\epsilon_kT_k(t)W_k(t)}{f_k(t)\rho_k } + \nu_k U_k(t) \left(\frac{a}{(m_\x^k(t))^b} + \frac{c}{m_\s^k(t)}\right)+}{}{} \breakObjective{\qquad+ V \frac{B_k N_0}{h_k(t)} {\rm exp} \left(\frac{R_k(t) ln(2)}{B_k} \right) + V \eta_k (f_k(t))^3} \bigg] 
    \addConstraint{\mathbf{\Psi}(t) \in \mathcal{T}(t).}{}
    \label{eq: EN_nn per-slot opt problem}
\end{mini}  
The solution of this problem is not simple. It is, however, possible to see the similarities with the problem discussed in the previous section. The solutions for the transmission rate $R_k(t)$ and the CPU clock frequency $f_k(t)$ are, in fact, the same as in \eref{eq: EN_ib optimal rate} and \eref{eq: EN_ib optimal freq device}. The only difference is that these values can now be expressed as functions of the two masking fractions $m_\x^k(t)$ and $m_\s^k(t)$ as follows:

\begin{equation}
    R_k^*(m_\x^k(t), m_\s^k(t)) = \frac{2 B_k}{ln(2)}\; W\! \!\left(\sqrt{\frac{512\epsilon_k T_k(t)\; ln(2)\; h_k(t)}{4B_k^2\;V \;N_0} [2+ 10(m_\x^k(t) + m_\s^k(t))] }\right)\; \Biggr|_0^{R_k^{max}(t)}
\label{eq: EN_nn optimal rate masks_func}
\end{equation}
\begin{equation}
    f_k^* (m_\x^k(t), m_\s^k(t)) = 107.64\sqrt[4]{\frac{\epsilon_k T_k(t)}{V \eta_k \rho_k} [m_\x^k(t) + m_\s^k(t)]}\; \Biggr|_0^{f_k^{max}}.
\label{eq: EN_nn optimal freq device masks_func}    
\end{equation}
Due to the very intricate nature of these equations, an exact analytical solution is not possible. However, the solution can be found by using numerical approaches. The first step involves the representation of all the optimization variables as functions of $m_\s^k(t)$.

To achieve this result, the first step is to derive the Lagrangian associated with the optimization problem in \eref{eq: EN_nn per-slot opt problem} with respect to $m_\x^k(t)$ and $m_\s^k(t)$. Then, by setting the derivative to zero, it is possible to drop all the constant terms and write $m_\x^k(t)$ as follows
\begin{equation}
    m_\x^{k*}(m_\s^k(t)) = \left(\frac{a}{c}\right)^{\frac{1}{b}} (m_\s^k(t))^{\frac{2}{b}}\; \Biggr|_0^{1}.
    \label{eq: EN_nn optimal m_x masks_func}
\end{equation}
The last step involves the substitution of \eref{eq: EN_nn optimal m_x masks_func} in the solutions of the transmission rate, \eref{eq: EN_nn optimal rate masks_func}, and the CPU clock frequency, \eref{eq: EN_nn optimal freq device masks_func}. The final system of equations is:
\begin{align}
    R_k^*(m_\s^k(t)) &= \frac{2 B_k}{ln(2)}\; W\! \!\left(\sqrt{\frac{512\epsilon_k T_k(t)\; ln(2)\; h_k(t)}{4B_k^2\;V \;N_0} \left[2+ 10\left( \left(\frac{a}{c}\right)^{\frac{1}{b}} (m_\s^k(t))^{\frac{2}{b}} + m_\s^k(t)\right)\right] }\right)\; \Biggr|_0^{R_k^{max}(t)}, \label{eq: EN_nn optimal rate}\\
    f_k^* (m_\s^k(t)) &= 45.26\sqrt[4]{\frac{\epsilon_k T_k(t)}{V \eta_k} \left[\left(\frac{a}{c}\right)^{\frac{1}{b}} (m_\s^k(t))^{\frac{2}{b}} + m_\s^k(t)\right]}\; \Biggr|_0^{f_k^{max}}, \label{eq: EN_nn optimal freq device}\\
    m_\x^{k*}(m_\s^k(t)) &= \left(\frac{a}{c}\right)^{\frac{1}{b}} (m_\s^k(t))^{\frac{2}{b}}\; \Biggr|_0^{1}. \label{eq: EN_nn optimal m_x}
\end{align}

By substituting the solutions at \eref{eq: EN_nn optimal rate}, \eqref{eq: EN_nn optimal freq device}, and \eqref{eq: EN_nn optimal m_x} inside the per-slot objective function in \eqref{eq: EN_nn per-slot opt problem}, the resulting problem can be optimized as a single-variable optimization problem. The final solution can be found by using a numerical approach.

Once the optimal solutions for all the optimization variables are found, the virtual queues can be updated as in \eref{eq: EN_nn virtulQueue T_true} and \eqref{eq: EN_nn virtulQueue U_approx}.

The overall procedure is summarized in the algorithm in \tref{tab: EN_nn algorithm}.


\begin{table}[ht]
    \centering
    \rule{\textwidth}{0.4pt} % Line at the top
    \vspace{-22pt} % Adjust the space between the top line and the caption
    \caption{Edge Device Resource Allocation Algorithm}
    \vspace{-10pt} % Adjust the space between the caption and the line below it
    \rule{\textwidth}{0.4pt} % Line below the caption
    \vspace{-15pt} % Adjust the space between the line and the algorithmic content
        \begin{algorithmic}[1]
            \item Set the Lyapunov parameters $V$, $T_k(0)$, $U_k(0)$, $\epsilon_k$ and $\nu_k \;\;\forall k$
            \item Set the desired values for delay $D_k^{avg}$ and metric $G_k^{avg}$
            \For{$t$ at least until $T_k$ and $U_k$ converges $\forall k$}
                \State Find the minimum of \eref{eq: EN_nn per-slot opt problem} as a function of $m_\s^k(t)$ via numerical optimization.
                \State Select the optimal $m_\s^k(t)$.
                \State Evaluate the optimal $R_k^*(t)$, $f_k^*(t)$ and $m_\x^{k*}(t)$ with \eref{eq: EN_nn optimal rate}, \eqref{eq: EN_nn optimal freq device} and \eqref{eq: EN_nn optimal m_x} respectively.
                \State Run the online inference task with the \gls{sqgan} model.
                \State Update  the virtual queues $T_k$ and $U_k$ $\forall k$ via \eref{eq: EN_nn virtulQueue T_true} and \eqref{eq: EN_nn virtulQueue U_approx}
            \EndFor
        \end{algorithmic}
    \vspace{-10pt} % Adjust the space between the content and the bottom line
    \rule{\textwidth}{0.4pt} % Line at the bottom
    \label{tab: EN_nn algorithm}
\end{table}
\subsection{Results}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{Figures/Edge_network/SQGAN/General_tradeoff.pdf}
    \caption[Semantic-Goal-Oriented communication Edge Network trade-off plot]{The trade-off between average power consumption, delay, and \gls{lpips} metric.}
    \label{fig: EN_nn power-delay-metric trade-off}
\end{figure}
In the previous subsection, the algorithm in \tref{tab: EN_nn algorithm} was introduced. By using this algorithm, it is possible to dynamically allocate the resources of the \gls{en} to guarantee target levels of delay and \gls{lpips}.

In this section, we will discuss the trade-off between power consumption, delay and metric. The \gls{en} will be composed of $K=10$ \glspl{ed} placed at a random distance from the \gls{es} between $5$ and $150$ meters. The specifics of the CPU are: (i) $f_k^{max}=1GHz$, (ii) the effective switched capacitance $\eta_k = 10^{-26}$, (iii) the product between the number of cores and the number of \gls{flopc} $\rho_k=16$. The antenna can work at a maximum power of $p_k^{tr}=500mW$.

The access point operates with a carrier frequency $f_0 = 1GHz$ and the wireless channels are generated using the Alpha-Beta-Gamma model from~\cite{MacCartney2016AlphaBetaGamma}. The total available bandwidth is set to $ B = 1MHz $ equally distributed among \glspl{ed}. The noise spectral density at the receiver is set to $ N_0 = -174dBm/Hz $.

Now that the \gls{en} is defined, it is possible to see how it will perform for different values of required delay $D_k^{avg}$ and metric $G_k^{avg}$. The performances of the \gls{en} can be evaluated by using the algorithm in \tref{tab: EN_nn algorithm} until convergence of the virtual queues. After convergence, the value of $P^{tot}$ is obtained by averaging the results over the following $1000$ time-steps. The results are shown in \fref{fig: EN_nn power-delay-metric trade-off}.

In summary, the results demonstrate a clear trade-off between power consumption, delay, and the \gls{lpips} metric within the \gls{sgoc} framework based on the \gls{sqgan}. Specifically, as the desired \gls{lpips} increases, the overall power consumption of the \gls{en} decreases, indicating more efficient resource utilization when lower semantic fidelity is acceptable. Conversely, achieving lower \gls{lpips} values necessitates higher power consumption, especially under stringent delay constraints. This is primarily due to the increased computational load on the \gls{ed} CPUs to meet the tight delay requirements, thereby highlighting the inherent balance between maintaining high semantic accuracy and conserving energy in edge networks.\\

This chapter has thoroughly explored the integration of \gls{goc} principles into \gls{en} for optimal resource allocation. Initially, it introduced the foundational concepts of \gls{goc} and its significance in tailoring communication systems to specific application objectives. Building on this, two distinct methodologies were presented: one leveraging the \gls{ib} framework and the other utilizing the \gls{sqgan} model for \gls{sc}-based image compression. Both approaches were formulated as stochastic optimization problems aimed to minimize average power consumption while adhering to constraints on processing delays and performance metrics. The implementation details, including the decomposition of the optimization problem and the application of Lyapunov-based techniques, were meticulously discussed allowing real-time adaptive resource management.

The empirical evaluations substantiated the efficacy of the proposed frameworks, illustrating how \gls{goc} and \gls{sgoc} paradigms can significantly enhance the performance and efficiency of edge networks. By dynamically adjusting key parameters such as compression levels, data transmission rates and CPU frequencies the systems were able to achieve a balanced trade-off between energy consumption, latency, and semantic fidelity based on real-time network conditions and resource availability. These findings underscore the potential of Goal-Oriented resource allocation strategies in meeting the demanding requirements of modern edge computing applications.
