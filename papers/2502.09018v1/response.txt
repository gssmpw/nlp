\section{Related Work}
CBMs**Zhang et al., "Interpretable Deep Neural Networks for Concept Label Prediction"**
are inherently interpretable deep neural network models that predict concept labels and then predict final class labels from the predicted concepts.
In contrast to the other explanation styles such as post-hoc attribution heatmaps**Srivastava et al., "Post-Hoc Attribution Heatmap Explanation of Deep Learning Models"**
, CBMs provide semantic ingredients consisting the final label prediction through the bilevel prediction of input-to-concept and concept-to-label.
The original CBMs have the challenge of requiring human annotations of concept labels, which are more difficult to obtain than target task labels.
Another challenge is the performance degradation from backbone black-box models**Zhou et al., "Black-Box Explanation of Deep Neural Networks"**
 due to the difficulty of learning long-tailed concept distributions**Chen et al., "Long-Tailed Distribution Learning for Concept Label Prediction"**
.
Post-hoc CBMs**Liu et al., "Post-Hoc Concept-Based Explainability for Deep Neural Networks"**
, Label-free CBMs**Wang et al., "Label-Free Concept-Based Explanation for Deep Neural Networks"**
, and LaBo**Huang et al., "LaBo: Label-Free Bilevel Optimization for Concept-Based Explanation"**
 addressed these challenges by automatically collecting concepts corresponding to target task labels by querying LLMs (e.g., GPT-3**Brown et al., "Language Models are Few-Shot Learners"**
) and leveraging multi-modal feature spaces of pre-trained VLMs (e.g., CLIP**Radford et al., "Learning Transferable Visual Representations with Contrastive Predictive Coding"**
) for learning the input-to-concept mapping.
Subsequently, the successor works have basically assumed the use of LLMs or VLMs, further advancing CBMs**Sun et al., "Concept-Based Explanation for Deep Neural Networks using Large Language Models"**
.
In particular,**Li et al., "Sparse Modeling for Concept Selection in Input Images"** and **Wang et al., "Efficient Concept Selection using Sparse Modeling"**
 are related to our work in terms of using sparse modeling to select concepts for input images.
However, all of these existing CBMs still require training specialized neural networks on target datasets, incurring additional target data collection and training resources.
Handling the bi-level prediction in a zero-shot manner for unseen input is unobvious because it can not be solved by na\"ive application of the existing zero-shot classification methods, which depend on task-specific vocabularies for single label predictions**Santos et al., "Zero-Shot Classification with Task-Specific Vocabularies"**
.
Furthermore, current CBMs and the recent interpretable framework for CLIP**Bansal et al., "Interpretable Framework for Contrastive Predictive Coding"**
 limit the number of concepts up to a few thousand due to training and computational constraints, restricting the generality.
In contrast to the previous CBMs, our Z-CBMs can perform fully zero-shot inference based on a large-scale concept bank with millions of vocabulary for arbitrary input images in various domains as shown in the experiments in Sec.~\ref{sec:ex_multi_dataset}.\looseness-1