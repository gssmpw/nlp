@article{ATOC,
  author    = {Jiechuan Jiang and
               Zongqing Lu},
  title     = {Learning Attentional Communication for Multi-Agent Cooperation},
  journal   = {CoRR},
  volume    = {abs/1805.07733},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.07733},
  eprinttype = {arXiv},
  eprint    = {1805.07733},
  timestamp = {Mon, 13 Aug 2018 16:46:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-07733.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{CommNet,
      title={Learning Multiagent Communication with Backpropagation}, 
      author={Sainbayar Sukhbaatar and Arthur Szlam and Rob Fergus},
      year={2016},
      eprint={1605.07736},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1605.07736}, 
}

@inproceedings{DGN,
    	title={Graph Convolutional Reinforcement Learning},
    	author={Jiang, Jiechuan and Dun, Chen and Huang, Tiejun and Lu, Zongqing},
    	booktitle={ICLR},
    	year={2020}
}

@misc{EMP,
      title={Learning Transferable Cooperative Behavior in Multi-Agent Teams}, 
      author={Akshat Agarwal and Sumit Kumar and Katia Sycara},
      year={2019},
      eprint={1906.01202},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ETC,
      title={Event-Triggered Multi-agent Reinforcement Learning with Communication under Limited-bandwidth Constraint}, 
      author={Guangzheng Hu and Yuanheng Zhu and Dongbin Zhao and Mengchen Zhao and Jianye Hao},
      year={2020},
      eprint={2010.04978},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2010.04978}, 
}

@article{ETC_descript,
title = {Event-triggered communication and control of networked systems for multi-agent consensus},
journal = {Automatica},
volume = {105},
pages = {1-27},
year = {2019},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2019.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S000510981930130X},
author = {Cameron Nowzari and Eloy Garcia and Jorge Cortés},
keywords = {Networked systems, Event-triggered control, Distributed coordination, Multi-agent consensus},
abstract = {This article provides an introduction to event-triggered coordination for multi-agent average consensus. We provide a comprehensive account of the motivations behind the use of event-triggered strategies for consensus, the methods for algorithm synthesis, the technical challenges involved in establishing desirable properties of the resulting implementations, and their applications in distributed control. We pay special attention to the assumptions on the capabilities of the network agents and the resulting features of the algorithm execution, including the interconnection topology, the evaluation of triggers, and the role of imperfect information. The issues raised in our discussion transcend the specific consensus problem and are indeed characteristic of cooperative algorithms for networked systems that solve other coordination tasks. As our discussion progresses, we make these connections clear, highlighting general challenges and tools to address them widespread in the event-triggered control of networked systems.}
}

@misc{IC3Net,
      title={Learning when to Communicate at Scale in Multiagent Cooperative and Competitive Tasks}, 
      author={Amanpreet Singh and Tushar Jain and Sainbayar Sukhbaatar},
      year={2018},
      eprint={1812.09755},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1812.09755}, 
}

@article{MBC, title={Model-based Sparse Communication in Multi-agent Reinforcement Learning}, journal={AAMAS ’23: Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems}, author={Han, Shuai and Dastani, Mehdi and Wang, Shihan}, year={2023}, month={May}, pages={439–447}}

@article{Menda_2019,
   title={Deep Reinforcement Learning for Event-Driven Multi-Agent Decision Processes},
   volume={20},
   ISSN={1558-0016},
   url={http://dx.doi.org/10.1109/TITS.2018.2848264},
   DOI={10.1109/tits.2018.2848264},
   number={4},
   journal={IEEE Transactions on Intelligent Transportation Systems},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Menda, Kunal and Chen, Yi-Chun and Grana, Justin and Bono, James W. and Tracey, Brendan D. and Kochenderfer, Mykel J. and Wolpert, David},
   year={2019},
   month=apr, pages={1259–1268} }

@article{TarMAC,
  author    = {Abhishek Das and
               Th{\'{e}}ophile Gervet and
               Joshua Romoff and
               Dhruv Batra and
               Devi Parikh and
               Michael G. Rabbat and
               Joelle Pineau},
  title     = {TarMAC: Targeted Multi-Agent Communication},
  journal   = {CoRR},
  volume    = {abs/1810.11187},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.11187},
  eprinttype = {arXiv},
  eprint    = {1810.11187},
  timestamp = {Mon, 09 Nov 2020 08:50:24 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-11187.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{VBC,
      title={Efficient Communication in Multi-Agent Reinforcement Learning via Variance Based Control}, 
      author={Sai Qian Zhang and Qi Zhang and Jieyu Lin},
      year={2019},
      eprint={1909.02682},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1909.02682}, 
}

@misc{comm_survey,
      title={A Survey of Multi-Agent Reinforcement Learning with Communication}, 
      author={Changxi Zhu and Mehdi Dastani and Shihan Wang},
      year={2022},
      eprint={2203.08975},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2203.08975}, 
}

@InProceedings{informarl_icml,
  title = 	 {Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation},
  author =       {Nayak, Siddharth and Choi, Kenneth and Ding, Wenqi and Dolan, Sydney and Gopalakrishnan, Karthik and Balakrishnan, Hamsa},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {25817--25833},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/nayak23a/nayak23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/nayak23a.html},
  abstract = 	 {We consider the problem of multi-agent navigation and collision avoidance when observations are limited to the local neighborhood of each agent. We propose InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. Specifically, InforMARL aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm. We show that (1) in training, InforMARL has better sample efficiency and performance than baseline approaches, despite using less information, and (2) in testing, it scales well to environments with arbitrary numbers of agents and obstacles. We illustrate these results using four task environments, including one with predetermined goals for each agent, and one in which the agents collectively try to cover all goals.}
}

@article{macpomdp, title={Planning with macro-actions in decentralized POMDPs},   journal={Proceedings of the International Conference on Autonomous Agents and Multiagent Systems}, author={Amato, Christopher and Konidaris, George D. and Kaelbling, Leslie}, year={2012}, }}

@inproceedings{magic,
  title={Multi-Agent Graph-Attention Communication and Teaming.},
  author={Niu, Yaru and Paleja, Rohan R and Gombolay, Matthew C},
  booktitle={AAMAS},
  volume={21},
  pages={20th},
  year={2021}
}

