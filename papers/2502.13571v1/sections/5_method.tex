\section{Methodology}
\label{sec:method}
\begin{figure}[!ht]
% \vspace{-1em}
\centering
    \includegraphics[width=0.90\columnwidth]{figures/HIM-framework.pdf}
    % \vspace{-1em}
    \caption{The overall framework of HIM.}
    \label{fig:HIM}
\end{figure}
% \vspace{-2em}
\subsection{Overview}
This work aims to address the IM problem from a new perspective.
We encode potential influence spread trends into hyperbolic representations for the effective selection of highly influential seed users.
Our motivation has two key points.
(1) We aim for a diffusion model agnostic method that solves the IM problem without relying on any assumptions on diffusion parameters.
(2) The influenc trend of users can be efficiently approximated by directly utilizing the properties of learned representations.
To this end, we leverage the benefits of hyperbolic geometry to propose a novel method for IM.

We use the social network and the graph set of influence propagation instances as learning data and apply hyperbolic network embedding to construct user representations.
Instead of explicitly computing users' influence spread, we implicitly estimate their influence spread with the learned representations.
The distance information of the representations can effectively measure the influence spread of seed user nodes.

Specifically, a novel hyperbolic spread learning method HIM is proposed, as is shown in Figure~\ref{fig:HIM}. HIM mainly consists of two modules: (1) \textit{Hyperbolic Influence Representation} aims to learn user representations in the hyperbolic space. (2) \textit{Adaptive Seed Selection} selects target seed users based on learned hyperbolic representations via an adaptive algorithm. 

\subsection{Hyperbolic Influence Representation}
We first encode influence spread features from social influence data to construct user representations in hyperbolic space. The social influence data includes social networks and influence propagation instances, as mentioned in Section~\ref{sec:assume}.
The structural information of the network and the historical spread patterns of propagation instances are crucial for estimating the influence spread of seed users. Both should be effectively integrated into user representations.

% Social connections can be easily obtained from a given social network.
% However, the propagation relations are relatively complicated. Instead of relying on specific diffusion models, we attempt to learn the influence propagation information from the observed data. Given the historical diffusion cascades, we can obtain their propagation instances~\cite{ICDE_feng2018inf2vec}. 
% As mentioned, each instance can be viewed as a directed subgraph $G_D$ of the social network $G$.
% Each instance can be viewed as a directed propagation subgraph of the social network, where an edge $(u \to v)$ denotes that user $u$ influences user $v$. 

The learning process follows a shallow embedding approach.
Both types of data naturally form a graph, enabling effective representation learning on edge sets.
We do not adopt more complex embedding methods as~\cite{KDD2016_grover_node2vec, KDD2017_ribeiro_struc2vec} as we aim to intuitively demonstrate that influence spread can be estimated based on hyperbolic representations learned from social influence data, which is previously unexplored.
Meanwhile, this approach maintains computational efficiency, making it scalable for large-scale social networks.

Given social influence data, we propose a rotation-based Lorentz model to learn hyperbolic user representations. 
Note that this preprocess is model-agnostic, making it adaptable to various diffusion models and practical applications. 

At first, given a social network $G = (V, E)$, we assign each user $u \in V$ an initial representation $\mathbf{x}_u \in \mathbb{L}^{n}_{\gamma}$, initialized via hyperbolic Gaussian sampling as in work~\cite{sun2021hgcf}.

\subsubsection{Rotation Operation.}
We apply hyperbolic rotation operation~\cite{ICLR19rotate, ACL20_chami2020low} to assist in integrating structure and influence spread information for effective representation learning. 
By adjusting angles, various rotation operations capture different types of information, ensuring seamless integration into unified user representations.

In detail, we use two sets of rotation matrices $(\mathbf{Rot}^{S}_{s}, \mathbf{Rot}^{T}_{s})$ and $(\mathbf{Rot}^{S}_{d}, \mathbf{Rot}^{T}_{d})$ to assist in representation learning. Here, $s$ denotes the social relation, while $d$ denotes the propagation relation. $S$ and $T$ denote the rotation operations applied to head nodes and tail nodes, respectively.
The rotation operation further brings extra benefits for IM.
% Employing rotation transformation offers several benefits to learning influence representations for the IM problem.
% First, rotations can capture various symmetric and asymmetric relations among users~\cite{ICLR19rotate,ACL20_chami2020low}.
The rotation operation in representation learning adjusts vectors' angles to bring related user representations closer while preserving their distances, therefore maintaining hierarchical information.
Besides, It is also efficient and easy to implement.

% -------------------------------------------------------------------------------------
% Learn Static Influence
% -------------------------------------------------------------------------------------

\subsubsection{Network Structure Learning.}

In this part, we deduce structure influence from the social connections present in the social network by modeling the edges within the given graph $G=(V, E)$. 
The core idea is to maximize the joint probability of observing all edges in the graph to learn node embeddings.

Specifically, given an observed edge $(u \rightarrow v) \in E$, the probability $\Pr(v|u)$ can be estimated by a score function based on the squared Lorentzian distance:
% $\small \Pr(v|u) = \frac{ \exp(\mathcal{V}^{S}_{uv}) } { Z(u) }$,
$\small \Pr(v|u) = \exp(\mathcal{V}^{S}_{uv})  /  Z(u) $,
% \begin{equation} \small \Pr(v|u) = \frac{ \exp(\mathcal{V}^{S}_{uv}) } { Z(u) }, \label{eq:prob-u-v} \end{equation}
where $Z(u) = \sum_{ o \in V } \exp(\mathcal{V}^{S}_{uo})$, and
edge score $\mathcal{V}^{S}_{uv} $ is defined as:
\begin{equation} 
\small \mathcal{V}^{S}_{uv} = - w_{uv} \cdot d^2_{\mathcal{L}}\left(\mathbf{x}^S_u, \mathbf{x}^T_v\right) + b_u + b_v,
\label{eq:relation-score}
\end{equation}
where $ w_{uv} > 0 $ is the coefficient associated with the edge $(u \rightarrow v)$.
Generally, we set $w_{uv} = 1/d_{u}$.
$b_u$ and $b_v$ represent biases of node $u$ and node $v$, respectively.
$\mathbf{x}^S_u = \mathbf{Rot}_{s}^S(\mathbf{x}_u)$ and $\mathbf{x}^T_v = \mathbf{Rot}_{s}^T(\mathbf{x}_v)$ are the rotated representations. 
Since the normalization term $Z(u)$ is expensive to compute, we approximate it via a negative sampling strategy~\cite{mikolov2013neg-sampling}.
% Note that the normalization term $Z(u)$ is expensive to compute, we approximate it via a new negative sampling strategy: We first divide all nodes into $L$ ranges according to their degrees. 
% When sampling negative nodes for given users, we carry out sample selection in the corresponding range according to their degrees, making refined distinctions among users with similar degrees. 
Therefore, we estimate $\Pr(v|u)$ in the log form as:
\begin{equation}
\small \log P(v|u) \approx \log \varphi \left(\mathcal{V}_{uv} \right) + \sum_{o \in \mathcal{N}_u} \log \varphi \left( - \mathcal{V}_{uo}\right),
\label{eq:log_p_u_v}
\end{equation}
where $\varphi(x) = 1/(1+e^{-x})$ is the Sigmoid function and $\mathcal{N}_u$ is the set of sampled negative nodes.
Assuming they are independent of each other, the joint probability of all social connections can be calculated as:
\begin{equation} \small \mathcal{P} = \sum_{(u,v)\in E} \log P(v|u). \end{equation}
By maximizing this joint probability, we encode the structure information of the social network into user representations.
% Accordingly, our goal is to capture the static influence of all users by maximizing this joint probability.

% -------------------------------------------------------------------------------------
% Learn Dynamic Influence
% -------------------------------------------------------------------------------------

\subsubsection{Influence Propagation Learning.}
Here, we extract historical influence spread patterns from the propagation instance graph sets $\mathcal{G}_D$.
Similarly, given any propagation graph $G^i_D \in \mathcal{G}_D$, we maximize the joint probability of observing influence activations in the $G^i_D$ to encode spread patterns into user embeddings.

In detail, given $G^i_D = (V^i_D, E^i_D)$, the edge probability of $(u \rightarrow v) \in E^i_D$ can be calculated similar to Eq. (\ref{eq:log_p_u_v}) as:
\begin{equation}
\small \log P(v|u) \approx \log \varphi \left(\mathcal{V}^{D}_{uv}\right) + \sum_{o \in \mathcal{N}_u} \log \varphi \left( - \mathcal{V}^{D}_{uo}\right),
\end{equation}
% \;\:
\begin{equation}
\small \mathcal{V}^{D}_{uv} = - w_{uv} \cdot d^2_{\mathcal{L}}\left(\mathbf{x}^S_u, \mathbf{x}^T_v\right) + b_u + b_v,
\label{eq:propagation_score}
\end{equation}
where $ w_{uv} = 1/d_u $ is the coefficient, $\mathbf{x}^S_u = \mathbf{Rot}_{d}^S(\mathbf{x}_u)$ and $\mathbf{x}^T_v = \mathbf{Rot}_{d}^T(\mathbf{x}_v)$ are the rotated user representations. 
The joint probability of all edges in $G^{i}_D$ can be calculated as:
\begin{equation} \small \mathcal{P}_{G^i_D} = \sum_{(u,v)\in E^{i}_D} \log P(v|u). \end{equation}

During the propagation process, once a user $u$ triggers influence activation, we want to assign a bonus to highlight this userâ€™s tendency to positively influence others. 
Inspired by the approach in~\cite{ICML2023_Yang}, we address this intuitively by reducing the hyperbolic distance of the related user representations from the origin in the embedding space.
Thus, for all influence activations in $G^i_D$, we propose a proactive influence regularization term:
\begin{equation}
 \mathcal{I}_{G^i_D} = \sum_{(u,v)\in G^i_D} \alpha_u \cdot \log \varphi \left(d^2_{\mathcal{L}}(\mathbf{x_u}, \mathbf{o}_{\mathcal{L}})\right).
\end{equation}
where $\mathbf{o}_{\mathcal{L}}$ is the origin of the Lorentz model and $\alpha_u$ is calculated as $\sqrt{d_u/d_{\text{max}}}$.
This term further pulls high-influence users closer to the origin in the representation space.
The illustration of learning an observed influence instance $(u \rightarrow v)$ is shown in Figure~\ref{fig:emb}.
\begin{figure}[h]
  \centering
  \includegraphics[width=0.90\columnwidth]{figures/method/do_emb.pdf}
  \caption{ Illustration of the influence propagation learning. The propagation relation between user $u$ and $v$ is depicted by the distance $d^2_{\mathcal{L}}$ between their rotated embeddings. }
  \label{fig:emb}
\end{figure}

For simplicity, we define $LDO$ as the squared Lorentzian distance from a given representation to the origin. Specifically, for user $u$, the $LDO_u$ is defined as $LDO_u = d^2_{\mathcal{L}}(\mathbf{x}_u, \mathbf{o}_{\mathcal{L}})$.
Previous studies~\cite{nickel2017poincare, ICML2023_Yang, feng2022role} have shown that hierarchical information can be effectively inferred from $LDO$s. In our method, user nodes with smaller $LDO$ values are more likely to be influential in social networks. 
We will later design seed selection strategies based on $LDO$.

% -------------------------------------------------------------------------------------
% Objective Function
% -------------------------------------------------------------------------------------

\subsubsection{Objective Function.}

Combining above two parts, the overall loss function is calculated as:
\begin{equation}
\small
\mathcal{L} = - \left( \mathcal{P} + \sum_{G^i_D \in \mathcal{G}_D}\left(\mathcal{P}_{G^{i}_D} + \mathcal{I}_{G^i_D}\right)\right). 
\label{eq:over_loss}
\end{equation}
Optimizing Eq. (\ref{eq:over_loss}) brings relevant nodes closer together while keeping irrelevant nodes as far apart as possible. Meanwhile, users involved in more influence activations tend to have their representations move closer to the origin, indicating potential higher influence spread.
The time complexity can be found in Appendix.

Once the learning process is complete, users with strong spread relations will be clustered together in the embedding space, and highly influential users tend to be located near the origin, which helps to identify seed users for the IM problem.

\subsection{Adaptive Seed Selection} 
\begin{algorithm}[H]
% \small
\caption{Adaptive Sliding Window (ASW)}\label{alg:ASW}
\begin{algorithmic}[1]
\Statex \textbf{Input:} social graph $G$, user representations $\mathbf{X}$, seed number $k$ and window size coefficient $\beta$ 
\Statex \textbf{Output:} $S^*$ with $k$ seed users
\State $S^* \gets$ an empty set, window size $w \gets \beta \cdot k$
\State $D \gets$ compute $ LDO_u = d^2_{\mathcal{L}}(\mathbf{x}_u, \mathbf{o}_{\mathcal{L}}) \text{ for each } u \text{ in } V$ 
\State $\mathcal{Z} \gets \text{sort } D  \text{ in ascending order} $
\State $c \gets$ select the $u$ with minimum $\mathcal{Z}_u$
\State $Q \gets$ a priority queue initialized with key-value pairs $(u, \mathcal{Z}_u)$ for the next $w$ users in $\mathcal{Z}$.
\While{$|S^*| < k$}
\State add $c$ to $S^*$ and find $N_c$ the neighbors of $c$ from $G$
\State $\mathcal{C} = N_c \cap Q_{keys}$
\If{$ \mathcal{C} = \emptyset $}
\State $c = Q.$pop and add the next $(u, \mathcal{Z}_u)$ in $\mathcal{Z}$ to $Q$ 
\Else
\State compute $\mathcal{Z}'_v$ according to Eq. (\ref{eq:update_score}) 
\State update $Q$ with $(v, \mathcal{Z}'_v)$ for each $v$ in $\mathcal{C}$
\State $c = Q.$pop and add the next $(u, \mathcal{Z}_u)$ in $\mathcal{Z}$ to $Q$ 
\EndIf
\EndWhile \textbf{ and return $S^*$} 
\end{algorithmic}
\end{algorithm}

After integrating social influence information into the hyperbolic representations, the next step involves designing strategies to select target seed users based on these learned representations. Specifically, we propose adaptive seed selection, which aims to leverage the geometric properties of the hyperbolic representations to effectively find seed users who possess large influence spread.

In practice, users with high influence might have overlapping areas of influence. Independently selecting highly influential users may not result in optimal overall performance due to the submodularity of social influence~\cite{kempe2003im}. Additionally, the submodularity property of the IM problem implies diminishing marginal gains from seed users~\cite{TKDE18_li2018influence_survey}, particularly for users who are close to the already selected seed users. Therefore, it is crucial to consider these spread relations among users when selecting seed nodes. Previous methods required traversing all nodes, leading to high computational costs. Given that influence strength can be estimated by the distance of representations from the origin and that the spread relations among users can be measured by the distance between their representation vectors, we have designed a new algorithm for seed set selection, which is shown in Algorithm~\ref{alg:ASW}.

The key idea of our strategy is to assign each user an initial score and dynamically adjust these scores during the selection process. Therefore, we could determine the final seed set by considering the spread relation among users. Specifically, we first assign each user with a score $\mathcal{Z}_u = LDO_u = d^2_{\mathcal{L}}(\mathbf{x}_u, \mathbf{o}_{\mathcal{L}})$. We sort all scores $\mathcal{Z}$ and select the node $c$ with the smallest $\mathcal{Z}_c$ as the first seed user. Instead of directly choosing the node with the second lowest $LDO$, the next $w$ nodes in the sorted list are viewed as candidate nodes, where $w$ is the size of a sliding window $W$. The $W$ is used to explore a wider range of candidate nodes while maintaining computational efficiency. We determine the window size $w$ based on $k$ as $w = \beta \cdot k$, allowing it to adaptively adjust its size for different data scales.
In Algorithm~\ref{alg:ASW}, the sliding window $W$ is implemented by a priority queue $Q$.
Next, we find the intersection $\mathcal{C}$ of the current seed node's neighbors with the candidate nodes.
Accordingly, we update the scores of the nodes in $\mathcal{C}$. 
For a user $u \in \mathcal{C}$, the updated score $\mathcal{Z}'_u$ is calculated as:
\begin{equation}
\small
\mathcal{Z}'_u = \mathcal{Z}_u + \frac{w_{c,u}}{d_c} \cdot  \mathcal{Z}_{c},
\label{eq:update_score}
\end{equation}
\begin{equation}
% \;\;
\small
w_{c,u} = \frac{
\exp(1/d^2_{\mathcal{L}}(\mathbf{x}_c, \mathbf{x}_u))
}{ \sum_{v \in \mathcal{C}} \exp(1/d^2_{\mathcal{L}}(\mathbf{x}_c, \mathbf{x}_v))}.
\label{eq:update_score_2}
\end{equation}
Here, $c$ denotes the recently selected node, $d_c$ is the degree of node $c$, and $w_{c,u}$ means the weight between them. Intuitively, a node closer to node $c$ may have a larger spread overlap with $c$, leading to a larger penalty from node $c$ and thus increasing its score.
In this way, the candidates' scores in the sliding window will be updated. After that, we select the node with the lowest score. At each iteration, the chosen node is removed from the window, and the next node from the sorted $LDO$ list is added to the window. This process is repeated until $k$ seed users are selected. 
Due to space limitations, the time complexity analysis can be found in Appendix.

% \subsubsection{Discussion.} 

% The influence strength of user nodes can be effectively measured by the distance of their representations from the space's origin. Meanwhile, the relationship between two users can be efficiently measured by the distance between their representations. Compared to other methods that utilize graph properties, such as the shortest path, to measure the relationship between two nodes, calculating the distance between representation vectors can greatly enhance computational efficiency. Representations in hyperbolic space can effectively measure both the influence of individual users and the social relations among them, enabling the design of efficient algorithms for classic IM problems. 
% Indeed, how to effectively select seed nodes based on the learned hyperbolic representations remains an open question worth further exploration.

% The influence strength of user nodes can be effectively measured by the distance of their representations from the origin in hyperbolic space. Similarly, the relationship between two users can be efficiently assessed by the distance between their respective representations. Compared to traditional methods that rely on graph properties, such as the shortest path, calculating the distance between representation vectors significantly enhances computational efficiency. Thus, we argue that hyperbolic space representations are particularly well-suited for measuring both individual user influence and social relationships, thereby facilitating the design of efficient algorithms for the IM problem.

% Applying two proposed strategies to HIM, we obtain two specific IM methods: HIM-MD and HIM-ASW.
% Later, in the experimental section, we will evaluate the performance of two methods.

% Section Transition