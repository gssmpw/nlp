\begin{table*}[t] 
\caption{Accuracy (\%) for \sname (Ours) and other baselines, including Few-shot CoT, SFT, RFT, $\text{STAR}^+$ trained models. We consider two math reasoning benchmarks, GSM8K~\citep{cobbe2021gsm8k} and MATH-500~\citep{lightman2023let}. MATH-500 is a subset of the original MATH benchmark~\citep{hendrycks2021math}. Maj@K indicates that majority voting for K samples, exceptionally \sname used its own verification confidence-aware majority voting. The \textbf{bold} indicated the best result within the group.} 
\label{tab:main}
\vspace{0.05in}
\small
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lccc ccc ccc}
\toprule
& \multicolumn{6}{c}{Llama-3.2-1B} & \multicolumn{3}{c}{Llama-3.1-8B} \\
\cmidrule(lr){2-7}\cmidrule(lr){8-10}
& \multicolumn{3}{c}{GSM8K} & \multicolumn{3}{c}{MATH-500} & \multicolumn{3}{c}{MATH-500}\\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
Methods & Maj@1 & Maj@3 & Maj@5 & Maj@1& Maj@3 & Maj@5 & Maj@1 & Maj@3 & Maj@5\\
\midrule

Few-shot CoT & \phantom{0}5.7 & \phantom{0}6.8 & \phantom{0}7.2 & \phantom{0}3.0&\phantom{0}2.6&\phantom{0}3.2& 23.4 &22.2&23.2  \\ 
SFT \citep{brown2020language} & 22.1 & 23.5 & 26.4 & 10.4 & 10.6 & 11.4 & 27.8 & 31.0 & 33.2 \\
RFT \citep{yuan2023scaling} & 26.2 & 26.8 & 28.6 & 12.6 & 12.4 & 12.8 & 30.8 & 33.2 & 35.6 \\
STaR$^+$ \citep{zelikman2022star} & 26.2 & 27.1 & 29.9 & 11.4 & 13.1 & 13.4 & 30.4 &  31.8 & 32.8 \\
\rowcolor{RowHighlight}\textbf{\sname (Ours)}& \textbf{28.1} & \textbf{31.3} & \textbf{32.8} & \textbf{13.4} & \textbf{14.0} & \textbf{14.8} & \textbf{33.6} & \textbf{36.0} & \textbf{37.6}\\
\bottomrule
\end{tabular}
}
\vspace{-.07in}
\end{table*}
