@inproceedings{naous-etal-2024-beer,
    title = "Having Beer after Prayer? Measuring Cultural Bias in Large Language Models",
    author = "Naous, Tarek  and
      Ryan, Michael  and
      Ritter, Alan  and
      Xu, Wei",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.862",
    pages = "16366--16393",
    abstract = "As the reach of large language models (LMs) expands globally, their ability to cater to diverse cultural contexts becomes crucial. Despite advancements in multilingual capabilities, models are not designed with appropriate cultural nuances. In this paper, we show that multilingual and Arabic monolingual LMs exhibit bias towards entities associated with Western culture. We introduce CAMeL, a novel resource of 628 naturally-occurring prompts and 20,368 entities spanning eight types that contrast Arab and Western cultures. CAMeL provides a foundation for measuring cultural biases in LMs through both extrinsic and intrinsic evaluations. Using CAMeL, we examine the cross-cultural performance in Arabic of 16 different LMs on tasks such as story generation, NER, and sentiment analysis, where we find concerning cases of stereotyping and cultural unfairness. We further test their text-infilling performance, revealing the incapability of appropriate adaptation to Arab cultural contexts. Finally, we analyze 6 Arabic pre-training corpora and find that commonly used sources such as Wikipedia may not be best suited to build culturally aware LMs, if used as they are without adjustment. We will make CAMeL publicly available at: https://github.com/tareknaous/camel",
}

@inproceedings{xue-etal-2021-mt5,
    title = "m{T}5: A Massively Multilingual Pre-trained Text-to-Text Transformer",
    author = "Xue, Linting  and
      Constant, Noah  and
      Roberts, Adam  and
      Kale, Mihir  and
      Al-Rfou, Rami  and
      Siddhant, Aditya  and
      Barua, Aditya  and
      Raffel, Colin",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.41",
    doi = "10.18653/v1/2021.naacl-main.41",
    pages = "483--498",
    abstract = "The recent {``}Text-to-Text Transfer Transformer{''} (T5) leveraged a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of English-language NLP tasks. In this paper, we introduce mT5, a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. We detail the design and modified training of mT5 and demonstrate its state-of-the-art performance on many multilingual benchmarks. We also describe a simple technique to prevent {``}accidental translation{''} in the zero-shot setting, where a generative model chooses to (partially) translate its prediction into the wrong language. All of the code and model checkpoints used in this work are publicly available.",
}
@article{kramsch2014language,
  title={Language and culture},
  author={Kramsch, Claire},
  journal={AILA review},
  volume={27},
  number={1},
  pages={30--55},
  year={2014},
  publisher={John Benjamins}
}
@article{wiener1960some,
  title={Some Moral and Technical Consequences of Automation: As machines learn they may develop unforeseen strategies at rates that baffle their programmers.},
  author={Wiener, Norbert},
  journal={Science},
  volume={131},
  number={3410},
  pages={1355--1358},
  year={1960},
  publisher={American Association for the Advancement of Science}
}
@misc{zhou2024does,
      title={Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural Knowledge}, 
      author={Li Zhou and Taelin Karidi and Nicolas Garneau and Yong Cao and Wanlong Liu and Wenyu Chen and Daniel Hershcovich},
      year={2024},
      eprint={2404.06833},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{ahmed2023representation,
  title={Representation of non-western cultural knowledge on Wikipedia: The case of the visual arts},
  author={Ahmed, Waq{\=a}s and Poulter, Martin Lewis},
  journal={Digital Studies/Le Champ Num{\'e}rique},
  volume={13},
  number={1},
  year={2023},
  publisher={Open Library of Humanities}
}
@book{montanari2006food,
  title={Food is culture},
  author={Montanari, Massimo},
  year={2006},
  publisher={Columbia University Press}
}
@book{anderson2014everyone,
  title={Everyone eats: Understanding food and culture},
  author={Anderson, Eugene Newton},
  year={2014},
  publisher={NYU Press}
}
@misc{kandpal2023large,
      title={Large Language Models Struggle to Learn Long-Tail Knowledge}, 
      author={Nikhil Kandpal and Haikang Deng and Adam Roberts and Eric Wallace and Colin Raffel},
      year={2023},
      eprint={2211.08411},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{elazar2024whats,
      title={What's In My Big Data?}, 
      author={Yanai Elazar and Akshita Bhagia and Ian Magnusson and Abhilasha Ravichander and Dustin Schwenk and Alane Suhr and Pete Walsh and Dirk Groeneveld and Luca Soldaini and Sameer Singh and Hanna Hajishirzi and Noah A. Smith and Jesse Dodge},
      year={2024},
      eprint={2310.20707},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{feng-etal-2023-pretraining,
    title = "From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair {NLP} Models",
    author = "Feng, Shangbin  and
      Park, Chan Young  and
      Liu, Yuhan  and
      Tsvetkov, Yulia",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.656",
    doi = "10.18653/v1/2023.acl-long.656",
    pages = "11737--11762",
    abstract = "Language models (LMs) are pretrained on diverse data sources{---}news, discussion forums, books, online encyclopedias. A significant portion of this data includes facts and opinions which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure media biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings which reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and media biases into misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness.",
}
@inproceedings{thelen2002bootstrapping,
  title={A bootstrapping method for learning semantic lexicons using extraction pattern contexts},
  author={Thelen, Michael and Riloff, Ellen},
  booktitle={Proceedings of the 2002 conference on empirical methods in natural language processing (EMNLP 2002)},
  pages={214--221},
  year={2002}
}
@article{shen2023large,
  title={Large language model alignment: A survey},
  author={Shen, Tianhao and Jin, Renren and Huang, Yufei and Liu, Chuang and Dong, Weilong and Guo, Zishan and Wu, Xinwei and Liu, Yan and Xiong, Deyi},
  journal={arXiv preprint arXiv:2309.15025},
  year={2023}
}
@misc{bekbayev2023poison,
      title={The Poison of Alignment}, 
      author={Aibek Bekbayev and Sungbae Chun and Yerzat Dulat and James Yamazaki},
      year={2023},
      eprint={2308.13449},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{yin2023survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023}
}
@misc{chen2023pretrained,
      title={Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?}, 
      author={Yang Chen and Hexiang Hu and Yi Luan and Haitian Sun and Soravit Changpinyo and Alan Ritter and Ming-Wei Chang},
      year={2023},
      eprint={2302.11713},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{hu2024large,
      title={Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages}, 
      author={Jinyi Hu and Yuan Yao and Chongyi Wang and Shan Wang and Yinxu Pan and Qianyu Chen and Tianyu Yu and Hanghao Wu and Yue Zhao and Haoye Zhang and Xu Han and Yankai Lin and Jiao Xue and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2308.12038},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{geigle2023mblip,
      title={mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs}, 
      author={Gregor Geigle and Abhay Jain and Radu Timofte and Goran Glavaš},
      year={2023},
      eprint={2307.06930},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{maaz2024palo,
      title={PALO: A Polyglot Large Multimodal Model for 5B People}, 
      author={Muhammad Maaz and Hanoona Rasheed and Abdelrahman Shaker and Salman Khan and Hisham Cholakal and Rao M. Anwer and Tim Baldwin and Michael Felsberg and Fahad S. Khan},
      year={2024},
      eprint={2402.14818},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{xue2021mt5,
      title={mT5: A massively multilingual pre-trained text-to-text transformer}, 
      author={Linting Xue and Noah Constant and Adam Roberts and Mihir Kale and Rami Al-Rfou and Aditya Siddhant and Aditya Barua and Colin Raffel},
      year={2021},
      eprint={2010.11934},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{aho1975efficient,
  title={Efficient string matching: an aid to bibliographic search},
  author={Aho, Alfred V and Corasick, Margaret J},
  journal={Communications of the ACM},
  volume={18},
  number={6},
  pages={333--340},
  year={1975},
  publisher={ACM New York, NY, USA}
}
@misc{tang2023codi2,
      title={CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation}, 
      author={Zineng Tang and Ziyi Yang and Mahmoud Khademi and Yang Liu and Chenguang Zhu and Mohit Bansal},
      year={2023},
      eprint={2311.18775},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{Marquardt_2022, title={Language, Ethnicity, and Separatism: Survey Results from Two Post-Soviet Regions}, volume={52}, DOI={10.1017/S0007123421000533}, number={4}, journal={British Journal of Political Science}, author={Marquardt, Kyle L.}, year={2022}, pages={1831–1851}}
@misc{liu2023visual,
      title={Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
      year={2023},
      eprint={2304.08485},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ormazabal2024reka,
      title={Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models}, 
      author={Aitor Ormazabal and Che Zheng and Cyprien de Masson d'Autume and Dani Yogatama and Deyu Fu and Donovan Ong and Eric Chen and Eugenie Lamprecht and Hai Pham and Isaac Ong and Kaloyan Aleksiev and Lei Li and Matthew Henderson and Max Bain and Mikel Artetxe and Nishant Relan and Piotr Padlewski and Qi Liu and Ren Chen and Samuel Phua and Yazheng Yang and Yi Tay and Yuqi Wang and Zhongkai Zhu and Zhihui Xie},
      year={2024},
      eprint={2404.12387},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
}@misc{li2024culturegen,
      title={CULTURE-GEN: Revealing Global Cultural Perception in Language Models through Natural Language Prompting}, 
      author={Huihan Li and Liwei Jiang and Jena D. Huang and Hyunwoo Kim and Sebastin Santy and Taylor Sorensen and Bill Yuchen Lin and Nouha Dziri and Xiang Ren and Yejin Choi},
      year={2024},
      eprint={2404.10199},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{shi2024culturebank,
      title={CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies}, 
      author={Weiyan Shi and Ryan Li and Yutong Zhang and Caleb Ziems and Chunhua yu and Raya Horesh and Rogério Abreu de Paula and Diyi Yang},
      year={2024},
      eprint={2404.15238},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}
@inproceedings{gupta-manning-2014-improved,
    title = "Improved Pattern Learning for Bootstrapped Entity Extraction",
    author = "Gupta, Sonal  and
      Manning, Christopher",
    editor = "Morante, Roser  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the Eighteenth Conference on Computational Natural Language Learning",
    month = jun,
    year = "2014",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-1611",
    doi = "10.3115/v1/W14-1611",
    pages = "98--108",
}
@misc{li2024culturellmincorporatingculturaldifferences,
      title={CultureLLM: Incorporating Cultural Differences into Large Language Models}, 
      author={Cheng Li and Mengzhou Chen and Jindong Wang and Sunayana Sitaram and Xing Xie},
      year={2024},
      eprint={2402.10946},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.10946}, 
}
@inproceedings{zhang-etal-2023-dont,
    title = "Don{'}t Trust {C}hat{GPT} when your Question is not in {E}nglish: A Study of Multilingual Abilities and Types of {LLM}s",
    author = "Zhang, Xiang  and
      Li, Senyu  and
      Hauer, Bradley  and
      Shi, Ning  and
      Kondrak, Grzegorz",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.491",
    doi = "10.18653/v1/2023.emnlp-main.491",
    pages = "7915--7927",
    abstract = "Large language models (LLMs) have demonstrated exceptional natural language understanding abilities, and have excelled in a variety of natural language processing (NLP) tasks. Despite the fact that most LLMs are trained predominantly on English, multiple studies have demonstrated their capabilities in a variety of languages. However, fundamental questions persist regarding how LLMs acquire their multilingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds, potentially influencing how they use LLMs and interpret their output. In this work, we propose a systematic way of qualitatively and quantitatively evaluating the multilingual capabilities of LLMs. We investigate the phenomenon of cross-language generalization in LLMs, wherein limited multilingual training data leads to advanced multilingual capabilities. To accomplish this, we employ a novel prompt back-translation method. The results demonstrate that LLMs, such as GPT, can effectively transfer learned knowledge across different languages, yielding relatively consistent results in translation-equivariant tasks, in which the correct output does not depend on the language of the input. However, LLMs struggle to provide accurate results in translation-variant tasks, which lack this property, requiring careful user judgment to evaluate the answers.",
}
@book{pesetsky2013russian,
  title={Russian case morphology and the syntactic categories},
  author={Pesetsky, David},
  volume={66},
  year={2013},
  publisher={MIT Press}
}
@book{press2015ukrainian,
  title={Ukrainian: A comprehensive grammar},
  author={Press, Ian and Pugh, Stefan},
  year={2015},
  publisher={Routledge}
}
@article{spektor2021detection,
  title={Detection and morphological analysis of novel Russian loanwords},
  author={Spektor, Yulia},
  year={2021}
}
@inproceedings{wu2023multimodal,
  title={Multimodal large language models: A survey},
  author={Wu, Jiayang and Gan, Wensheng and Chen, Zefeng and Wan, Shicheng and Philip, S Yu},
  booktitle={2023 IEEE International Conference on Big Data (BigData)},
  pages={2247--2256},
  year={2023},
  organization={IEEE}
}
@misc{wu2024nextgptanytoanymultimodalllm,
      title={NExT-GPT: Any-to-Any Multimodal LLM}, 
      author={Shengqiong Wu and Hao Fei and Leigang Qu and Wei Ji and Tat-Seng Chua},
      year={2024},
      eprint={2309.05519},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.05519}, 
}
@article{xu2024survey,
  title={A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias},
  author={Xu, Yuemei and Hu, Ling and Zhao, Jiayi and Qiu, Zihan and Ye, Yuqi and Gu, Hanwen},
  journal={arXiv preprint arXiv:2404.00929},
  year={2024}
}
@inproceedings{ustun-etal-2024-aya,
    title = "Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model",
    author = {{\"U}st{\"u}n, Ahmet  and
      Aryabumi, Viraat  and
      Yong, Zheng  and
      Ko, Wei-Yin  and
      D{'}souza, Daniel  and
      Onilude, Gbemileke  and
      Bhandari, Neel  and
      Singh, Shivalika  and
      Ooi, Hui-Lee  and
      Kayid, Amr  and
      Vargus, Freddie  and
      Blunsom, Phil  and
      Longpre, Shayne  and
      Muennighoff, Niklas  and
      Fadaee, Marzieh  and
      Kreutzer, Julia  and
      Hooker, Sara},
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.845",
    pages = "15894--15939",
    abstract = "Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50{\%} are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages {---}{---} including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models.",
}
@misc{ananthram2024perspectivediagnosingwesterncultural,
      title={See It from My Perspective: Diagnosing the Western Cultural Bias of Large Vision-Language Models in Image Understanding}, 
      author={Amith Ananthram and Elias Stengel-Eskin and Carl Vondrick and Mohit Bansal and Kathleen McKeown},
      year={2024},
      eprint={2406.11665},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.11665}, 
}
@inproceedings{wang-etal-2024-countries,
    title = "Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models",
    author = "Wang, Wenxuan  and
      Jiao, Wenxiang  and
      Huang, Jingyuan  and
      Dai, Ruyi  and
      Huang, Jen-tse  and
      Tu, Zhaopeng  and
      Lyu, Michael",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.345",
    pages = "6349--6384",
    abstract = "This paper identifies a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g., ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in non-English languages. To systematically evaluate the cultural dominance issue, we build a benchmark of concrete (e.g., holidays and songs) and abstract (e.g., values and opinions) cultural objects. Empirical results show that the representative GPT models suffer from the culture dominance problem, where GPT-4 is the most affected while text-davinci-003 suffers the least from this problem. Our study emphasizes the need to critically examine cultural dominance and ethical considerations in their development and deployment. We show that two straightforward methods in model development (i.e., pretraining on more diverse data) and deployment (e.g., culture-aware prompting) can significantly mitigate the cultural dominance issue in LLMs.",
}
  @misc{Tao_Kizilcec_2024,
  title={Cultural Bias and Cultural Alignment of Large Language Models},
  url={osf.io/7sj3w},
  publisher={OSF},
  author={Tao, Yan and Kizilcec, René F},
  year={2024},
  month={Aug}
}
@inproceedings{shen-etal-2024-understanding,
    title = "Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense",
    author = "Shen, Siqi  and
      Logeswaran, Lajanugen  and
      Lee, Moontae  and
      Lee, Honglak  and
      Poria, Soujanya  and
      Mihalcea, Rada",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.316",
    doi = "10.18653/v1/2024.naacl-long.316",
    pages = "5668--5680",
    abstract = "Large language models (LLMs) have demonstrated substantial commonsense understanding through numerous benchmark evaluations. However, their understanding of cultural commonsense remains largely unexamined. In this paper, we conduct a comprehensive examination of the capabilities and limitations of several state-of-the-art LLMs in the context of cultural commonsense tasks. Using several general and cultural commonsense benchmarks, we find that (1) LLMs have a significant discrepancy in performance when tested on culture-specific commonsense knowledge for different cultures; (2) LLMs{'} general commonsense capability is affected by cultural context; and (3) The language used to query the LLMs can impact their performance on cultural-related tasks.Our study points to the inherent bias in the cultural understanding of LLMs and provides insights that can help develop culturally-aware language models.",
}
@inproceedings{Nguyen_2023, series={WWW ’23},
   title={Extracting Cultural Commonsense Knowledge at Scale},
   url={http://dx.doi.org/10.1145/3543507.3583535},
   DOI={10.1145/3543507.3583535},
   booktitle={Proceedings of the ACM Web Conference 2023},
   publisher={ACM},
   author={Nguyen, Tuan-Phong and Razniewski, Simon and Varde, Aparna and Weikum, Gerhard},
   year={2023},
   month=apr, collection={WWW ’23} }
@inproceedings{yin2022geomlama,
  title={GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models},
  author={Yin, Da and Bansal, Hritik and Monajatipoor, Masoud and Li, Liunian Harold and Chang, Kai-Wei},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={2039--2055},
  year={2022}
}
@article{myung2024blend,
  title={BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages},
  author={Myung, Junho and Lee, Nayeon and Zhou, Yi and Jin, Jiho and Putri, Rifki Afina and Antypas, Dimosthenis and Borkakoty, Hsuvas and Kim, Eunsu and Perez-Almendros, Carla and Ayele, Abinew Ali and others},
  journal={arXiv preprint arXiv:2406.09948},
  year={2024}
}
@article{baek2024evaluating,
  title={Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration},
  author={Baek, Yujin and Park, ChaeHun and Kim, Jaeseok and Heo, Yu-Jung and Chang, Du-Seong and Choo, Jaegul},
  journal={arXiv e-prints},
  pages={arXiv--2406},
  year={2024}
}
@article{nayak2024benchmarking,
  title={Benchmarking Vision Language Models for Cultural Understanding},
  author={Nayak, Shravan and Jain, Kanishk and Awal, Rabiul and Reddy, Siva and van Steenkiste, Sjoerd and Hendricks, Lisa Anne and Sta{\'n}czak, Karolina and Agrawal, Aishwarya},
  journal={arXiv e-prints},
  pages={arXiv--2407},
  year={2024}
}
@article{zhang2024cultiverse,
  title={CultiVerse: Towards Cross-Cultural Understanding for Paintings with Large Language Model},
  author={Zhang, Wei and Kam-Kwai, Wong and Xu, Biying and Ren, Yiwen and Li, Yuhuai and Zhu, Minfeng and Feng, Yingchaojie and Chen, Wei},
  journal={arXiv e-prints},
  pages={arXiv--2405},
  year={2024}
}
@inproceedings{saxon2023multilingual,
  title={Multilingual Conceptual Coverage in Text-to-Image Models},
  author={Saxon, Michael and Wang, William Yang},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={4831--4848},
  year={2023}
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}


@inproceedings{rottger-etal-2024-political,
    title = "Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models",
    author = {R{\"o}ttger, Paul  and
      Hofmann, Valentin  and
      Pyatkin, Valentina  and
      Hinck, Musashi  and
      Kirk, Hannah  and
      Schuetze, Hinrich  and
      Hovy, Dirk},
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.816",
    doi = "10.18653/v1/2024.acl-long.816",
    pages = "15295--15311",
    abstract = "Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are used by millions of people. Such real-world concerns, however, stand in stark contrast to the artificiality of current evaluations: real users do not typically ask LLMs survey questions. Motivated by this discrepancy, we challenge the prevailing *constrained* evaluation paradigm for values and opinions in LLMs and explore more realistic *unconstrained* evaluations. As a case study, we focus on the popular Political Compass Test (PCT). In a systematic review, we find that most prior work using the PCT *forces models to comply with the PCT{'}s multiple-choice format. We show that models give substantively different answers when not forced; that answers change depending on how models are forced; and that answers lack paraphrase robustness. Then, we demonstrate that models give different answers yet again in a more realistic open-ended answer setting. We distill these findings into recommendations and open challenges in evaluating values and opinions in LLMs.",
}
@inproceedings{salinas-morstatter-2024-butterfly,
    title = "The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance",
    author = "Salinas, Abel  and
      Morstatter, Fred",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.275",
    doi = "10.18653/v1/2024.findings-acl.275",
    pages = "4629--4651",
    abstract = "Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or {``}prompting,{''} practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of decisions by the practitioner, from simple wording of the prompt, to requesting the output in a certain data format, to jailbreaking in the case of prompts that address more sensitive topics. In this work, we ask: do variations in the way a prompt is constructed change the ultimate decision of the LLM? We answer this using a series of prompt variations across a variety of text classification tasks. We find that even the smallest of perturbations, such as adding a space at the end of a prompt, can cause the LLM to change its answer. Further, we find that requesting responses in XML and commonly used jailbreaks can have cataclysmic effects on the data labeled by LLMs.",
}
@article{Honnibal_spaCy_Industrial-strength_Natural_2020,
author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
doi = {10.5281/zenodo.1212303},
title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
year = {2020}
}
@article{10.1162/ling.2008.39.3.379,
    author = {Hayes, Bruce and Wilson, Colin},
    title = "{A Maximum Entropy Model of Phonotactics and Phonotactic Learning}",
    journal = {Linguistic Inquiry},
    volume = {39},
    number = {3},
    pages = {379-440},
    year = {2008},
    month = {07},
    abstract = "{The study of phonotactics is a central topic in phonology. We propose a theory of phonotactic grammars and a learning algorithm that constructs such grammars from positive evidence. Our grammars consist of constraints that are assigned numerical weights according to the principle of maximum entropy. The grammars assess possible words on the basis of the weighted sum of their constraint violations. The learning algorithm yields grammars that can capture both categorical and gradient phonotactic patterns. The algorithm is not provided with constraints in advance, but uses its own resources to form constraints and weight them. A baseline model, in which Universal Grammar is reduced to a feature set and an SPE-style constraint format, suffices to learn many phonotactic phenomena. In order for the model to learn nonlocal phenomena such as stress and vowel harmony, it must be augmented with autosegmental tiers and metrical grids. Our results thus offer novel, learning-theoretic support for such representations. We apply the model in a variety of learning simulations, showing that the learned grammars capture the distributional generalizations of these languages and accurately predict the findings of a phonotactic experiment.}",
    issn = {0024-3892},
    doi = {10.1162/ling.2008.39.3.379},
    url = {https://doi.org/10.1162/ling.2008.39.3.379},
    eprint = {https://direct.mit.edu/ling/article-pdf/39/3/379/724418/ling.2008.39.3.379.pdf},
}
@article{JMLR:v23:21-0635,
  author  = {Jonathan Ho and Chitwan Saharia and William Chan and David J. Fleet and Mohammad Norouzi and Tim Salimans},
  title   = {Cascaded Diffusion Models for High Fidelity Image Generation},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {47},
  pages   = {1--33},
  url     = {http://jmlr.org/papers/v23/21-0635.html}
}
@ARTICLE{10419041,

  author={Cao, Hanqun and Tan, Cheng and Gao, Zhangyang and Xu, Yilun and Chen, Guangyong and Heng, Pheng-Ann and Li, Stan Z.},

  journal={IEEE Transactions on Knowledge and Data Engineering}, 

  title={A Survey on Generative Diffusion Models}, 

  year={2024},

  volume={36},

  number={7},

  pages={2814-2830},

  keywords={Mathematical models;Kernel;Computational modeling;Training;Surveys;Noise reduction;Markov processes;Diffusion model;deep generative model;diffusion algorithm;diffusion applications},

  doi={10.1109/TKDE.2024.3361474}}
@misc{jiang2024genaiarenaopenevaluation,
      title={GenAI Arena: An Open Evaluation Platform for Generative Models}, 
      author={Dongfu Jiang and Max Ku and Tianle Li and Yuansheng Ni and Shizhuo Sun and Rongqi Fan and Wenhu Chen},
      year={2024},
      eprint={2406.04485},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.04485}, 
}
@misc{oquab2023dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timothée and Moutakanni, Theo and Vo, Huy V. and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Howes, Russell and Huang, Po-Yao and Xu, Hu and Sharma, Vasu and Li, Shang-Wen and Galuba, Wojciech and Rabbat, Mike and Assran, Mido and Ballas, Nicolas and Synnaeve, Gabriel and Misra, Ishan and Jegou, Herve and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
  journal={arXiv:2304.07193},
  year={2023}
}
@misc{darcet2023vitneedreg,
  title={Vision Transformers Need Registers},
  author={Darcet, Timothée and Oquab, Maxime and Mairal, Julien and Bojanowski, Piotr},
  journal={arXiv:2309.16588},
  year={2023}
}
@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}
@article{gemma_2024,
    title={Gemma},
    url={https://www.kaggle.com/m/3301},
    DOI={10.34740/KAGGLE/M/3301},
    publisher={Kaggle},
    author={Gemma Team},
    year={2024}
}
@article{odumakinde2024multilingual,
  title={Multilingual Arbitrage: Optimizing Data Pools to Accelerate Multilingual Progress},
  author={Odumakinde, Ayomide and D'souza, Daniel and Verga, Pat and Ermis, Beyza and Hooker, Sara},
  journal={arXiv preprint arXiv:2408.14960},
  year={2024}
}
@article{dang2024rlhf,
  title={Rlhf can speak many languages: Unlocking multilingual preference optimization for llms},
  author={Dang, John and Ahmadian, Arash and Marchisio, Kelly and Kreutzer, Julia and {\"U}st{\"u}n, Ahmet and Hooker, Sara},
  journal={arXiv preprint arXiv:2407.02552},
  year={2024}
}
@article{ahmadian2024multilingual,
  title={The multilingual alignment prism: Aligning global and local preferences to reduce harm},
  author={Ahmadian, Arash and Ermis, Beyza and Goldfarb-Tarrant, Seraphina and Kreutzer, Julia and Fadaee, Marzieh and Hooker, Sara and others},
  journal={arXiv preprint arXiv:2406.18682},
  year={2024}
}
@article{ahmadian2024mix,
  title={Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning},
  author={Ahmadian, Arash and Goldfarb-Tarrant, Seraphina and Ermis, Beyza and Fadaee, Marzieh and Hooker, Sara and others},
  journal={arXiv preprint arXiv:2410.10801},
  year={2024}
}
@misc{qwen2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {Qwen Team},
    month = {September},
    year = {2024}
}

@article{qwen2,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      journal={arXiv preprint arXiv:2407.10671},
      year={2024}
}
@article{george1935zipf,
  title={Zipf. The Psychobiology of Language},
  author={George, K},
  journal={An Introduction to Dynamic Philology},
  year={1935}
}
@article{jaccard1901etude,
  title={{\'E}tude comparative de la distribution florale dans une portion des Alpes et des Jura},
  author={Jaccard, Paul},
  journal={Bull Soc Vaudoise Sci Nat},
  volume={37},
  pages={547--579},
  year={1901}
}
@inproceedings{schmitt2019replicable,
  title={A replicable comparison study of NER software: StanfordNLP, NLTK, OpenNLP, SpaCy, Gate},
  author={Schmitt, Xavier and Kubler, Sylvain and Robert, J{\'e}r{\'e}my and Papadakis, Mike and LeTraon, Yves},
  booktitle={2019 sixth international conference on social networks analysis, management and security (SNAMS)},
  pages={338--343},
  year={2019},
  organization={IEEE}
}
@article{racek2024russian,
  title={The Russian war in Ukraine increased Ukrainian language use on social media},
  author={Racek, Daniel and Davidson, Brittany I and Thurner, Paul W and Zhu, Xiao Xiang and Kauermann, G{\"o}ran},
  journal={Communications Psychology},
  volume={2},
  number={1},
  pages={1},
  year={2024},
  publisher={Nature Publishing Group UK London}
}
@Inbook{Danylenko2016,
author="Danylenko, Andrii",
editor="Kamusella, Tomasz
and Nomachi, Motoki
and Gibson, Catherine",
title="Iazychie and Surzhyk: Mixing Languages and Identities in the Ukrainian Borderlands",
bookTitle="The Palgrave Handbook of Slavic Languages, Identities and Borders",
year="2016",
publisher="Palgrave Macmillan UK",
address="London",
pages="81--100",
abstract="There are several concepts in Ukrainian sociolinguistics that seem to be better off classified as spooky, scary terms. Among them are iazychie and surzhyk1 referring to linguistic hybrids routinely castigated in both public and scholarly discourse in today's Ukraine. To take iazychie as defined in the Encyclopedia of the Ukrainian Language, published by the O. Potebnia Institute of Linguistics jointly with the Institute of the Ukrainian Language of the National Academy of Sciences of Ukraine, it is conceived of as `an artificial bookish language', based on Old Church Slavonic and western Ukrainian dialects. At the time of the formation of literary Ukrainian on vernacular foundations in the nineteenth century, the use of this mix was allegedly anachronistic, thus hindering the development of language norms (Muromtseva 2000: 745). The term surzhyk refers to modern vernacular Ukrainian, permeated with `unmotivated' Russian elements (borrowed as a result of heavy Ukrainian-Russian interference); to fight against this mix might be one of the major goals in the fostering of the norms of the Ukrainian language (Lenets' 2000: 616).",
isbn="978-1-137-34839-5",
doi="10.1007/978-1-137-34839-5_5",
url="https://doi.org/10.1007/978-1-137-34839-5_5"
}
@article{murphy2023historical,
  title={On “historical unity” of Russian and Ukrainian: A linguistic perspective on language conflict and change},
  author={Murphy, Anyssa and Whalen, Lex and Dubinsky, Stanley and Gavin, Michael and Bailyn, John F and Ginn, Jackson},
  journal={Proceedings of the Linguistic Society of America},
  volume={8},
  number={1},
  pages={5467--5467},
  year={2023}
}
@misc{zhang2024cooccurrencefactualassociationlanguage,
      title={Co-occurrence is not Factual Association in Language Models}, 
      author={Xiao Zhang and Miao Li and Ji Wu},
      year={2024},
      eprint={2409.14057},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.14057}, 
}
@misc{liu2024culturallyawareadaptednlp,
      title={Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the State of the Art}, 
      author={Chen Cecilia Liu and Iryna Gurevych and Anna Korhonen},
      year={2024},
      eprint={2406.03930},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.03930}, 
}
@misc{zhou2024foodskyfoodorientedlargelanguage,
      title={FoodSky: A Food-oriented Large Language Model that Passes the Chef and Dietetic Examination}, 
      author={Pengfei Zhou and Weiqing Min and Chaoran Fu and Ying Jin and Mingyu Huang and Xiangyang Li and Shuhuan Mei and Shuqiang Jiang},
      year={2024},
      eprint={2406.10261},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.10261}, 
}
@misc{qi2023foodgptlargelanguagemodel,
      title={FoodGPT: A Large Language Model in Food Testing Domain with Incremental Pre-training and Knowledge Graph Prompt}, 
      author={Zhixiao Qi and Yijiong Yu and Meiqi Tu and Junyi Tan and Yongfeng Huang},
      year={2023},
      eprint={2308.10173},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.10173}, 
}
@misc{li2024foodieqamultimodaldatasetfinegrained,
      title={FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture}, 
      author={Wenyan Li and Xinyu Zhang and Jiaang Li and Qiwei Peng and Raphael Tang and Li Zhou and Weijia Zhang and Guimin Hu and Yifei Yuan and Anders Søgaard and Daniel Hershcovich and Desmond Elliott},
      year={2024},
      eprint={2406.11030},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.11030}, 
}
@article{10.1162/tacl_a_00634,
    author = {Cao, Yong and Kementchedjhieva, Yova and Cui, Ruixiang and Karamolegkou, Antonia and Zhou, Li and Dare, Megan and Donatelli, Lucia and Hershcovich, Daniel},
    title = "{Cultural Adaptation of Recipes}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {12},
    pages = {80-99},
    year = {2024},
    month = {01},
    abstract = "{Building upon the considerable advances in Large Language Models (LLMs), we are now equipped to address more sophisticated tasks demanding a nuanced understanding of cross-cultural contexts. A key example is recipe adaptation, which goes beyond simple translation to include a grasp of ingredients, culinary techniques, and dietary preferences specific to a given culture. We introduce a new task involving the translation and cultural adaptation of recipes between Chinese- and English-speaking cuisines. To support this investigation, we present CulturalRecipes, a unique dataset composed of automatically paired recipes written in Mandarin Chinese and English. This dataset is further enriched with a human-written and curated test set. In this intricate task of cross-cultural recipe adaptation, we evaluate the performance of various methods, including GPT-4 and other LLMs, traditional machine translation, and information retrieval techniques. Our comprehensive analysis includes both automatic and human evaluation metrics. While GPT-4 exhibits impressive abilities in adapting Chinese recipes into English, it still lags behind human expertise when translating English recipes into Chinese. This underscores the multifaceted nature of cultural adaptations. We anticipate that these insights will significantly contribute to future research on culturally aware language models and their practical application in culturally diverse contexts.}",
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00634},
    url = {https://doi.org/10.1162/tacl\_a\_00634},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00634/2325708/tacl\_a\_00634.pdf},
}
@misc{fung2024massivelymulticulturalknowledgeacquisition,
      title={Massively Multi-Cultural Knowledge Acquisition and LM Benchmarking}, 
      author={Yi Fung and Ruining Zhao and Jae Doo and Chenkai Sun and Heng Ji},
      year={2024},
      eprint={2402.09369},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.09369}, 
}
@inproceedings{Nguyen_2024, series={CIKM ’24},
   title={Cultural Commonsense Knowledge for Intercultural Dialogues},
   url={http://dx.doi.org/10.1145/3627673.3679768},
   DOI={10.1145/3627673.3679768},
   booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
   publisher={ACM},
   author={Nguyen, Tuan-Phong and Razniewski, Simon and Weikum, Gerhard},
   year={2024},
   month=oct, pages={1774–1784},
   collection={CIKM ’24} }
@misc{arora2024calmqaexploringculturallyspecific,
      title={CaLMQA: Exploring culturally specific long-form question answering across 23 languages}, 
      author={Shane Arora and Marzena Karpinska and Hung-Ting Chen and Ipsita Bhattacharjee and Mohit Iyyer and Eunsol Choi},
      year={2024},
      eprint={2406.17761},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.17761}, 
}


@article{winata2024worldcuisines,
  title={WORLDCUISINES: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines},
  author={Winata, Genta Indra and Hudi, Frederikus and Irawan, Patrick Amadeus and Anugraha, David and Putri, Rifki Afina and Wang, Yutong and Nohejl, Adam and Prathama, Ubaidillah Ariq and Ousidhoum, Nedjma and Amriani, Afifa and others},
  journal={arXiv preprint arXiv:2410.12705},
  year={2024}
}

@misc{myung2024blendbenchmarkllmseveryday,
      title={BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages}, 
      author={Junho Myung and Nayeon Lee and Yi Zhou and Jiho Jin and Rifki Afina Putri and Dimosthenis Antypas and Hsuvas Borkakoty and Eunsu Kim and Carla Perez-Almendros and Abinew Ali Ayele and Víctor Gutiérrez-Basulto and Yazmín Ibáñez-García and Hwaran Lee and Shamsuddeen Hassan Muhammad and Kiwoong Park and Anar Sabuhi Rzayev and Nina White and Seid Muhie Yimam and Mohammad Taher Pilehvar and Nedjma Ousidhoum and Jose Camacho-Collados and Alice Oh},
      year={2024},
      eprint={2406.09948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.09948}, 
}
@article{grigoreva2024rubia,
  title={RuBia: A Russian Language Bias Detection Dataset},
  author={Grigoreva, Veronika and Ivanova, Anastasiia and Alimova, Ilseyar and Artemova, Ekaterina},
  journal={arXiv preprint arXiv:2403.17553},
  year={2024}
}
@misc{li2024uncoveringdifferencespersuasivelanguage,
      title={Uncovering Differences in Persuasive Language in Russian versus English Wikipedia}, 
      author={Bryan Li and Aleksey Panasyuk and Chris Callison-Burch},
      year={2024},
      eprint={2409.19148},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.19148}, 
}
@misc{kharchenko2024llmsrepresentvaluescultures,
      title={How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of LLM Responses Based on Hofstede Cultural Dimensions}, 
      author={Julia Kharchenko and Tanya Roosta and Aman Chadha and Chirag Shah},
      year={2024},
      eprint={2406.14805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.14805}, 
}
@article{km,
  title={Machine Learning and Culture: An Analysis of Sociocultural Biases in Large Language Models Using Gigachat and YandexGPT (Russian)},
  author={Aleksey Kuznetsov},
  year={2024},
  url={https://is.muni.cz/publication/2396639/__________2024.pdf#page=16}
}
@inproceedings{palta2023fork,
  title={FORK: A bite-sized test set for probing culinary cultural biases in commonsense reasoning models},
  author={Palta, Shramay and Rudinger, Rachel},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={9952--9962},
  year={2023}
}
@article{schneider2024m,
  title={M5--A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks},
  author={Schneider, Florian and Sitaram, Sunayana},
  journal={arXiv preprint arXiv:2407.03791},
  year={2024}
}
@article{khanuja2024image,
  title={An image speaks a thousand words, but can everyone listen? On translating images for cultural relevance},
  author={Khanuja, Simran and Ramamoorthy, Sathyanarayanan and Song, Yueqi and Neubig, Graham},
  journal={arXiv preprint arXiv:2404.01247},
  year={2024}
}
@misc{ramaswamy2023geodegeographicallydiverseevaluation,
      title={GeoDE: a Geographically Diverse Evaluation Dataset for Object Recognition}, 
      author={Vikram V. Ramaswamy and Sing Yu Lin and Dora Zhao and Aaron B. Adcock and Laurens van der Maaten and Deepti Ghadiyaram and Olga Russakovsky},
      year={2023},
      eprint={2301.02560},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2301.02560}, 
}
@article{liu2023cultural,
  title={On the cultural gap in text-to-image generation},
  author={Liu, Bingshuai and Wang, Longyue and Lyu, Chenyang and Zhang, Yong and Su, Jinsong and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2307.02971},
  year={2023}
}
@article{bhatia2024local,
  title={From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models},
  author={Bhatia, Mehar and Ravi, Sahithya and Chinchure, Aditya and Hwang, Eunjeong and Shwartz, Vered},
  journal={arXiv preprint arXiv:2407.00263},
  year={2024}
}
@article{karamolegkou2024vision,
  title={Vision-Language Models under Cultural and Inclusive Considerations},
  author={Karamolegkou, Antonia and Rust, Phillip and Cao, Yong and Cui, Ruixiang and S{\o}gaard, Anders and Hershcovich, Daniel},
  journal={arXiv preprint arXiv:2407.06177},
  year={2024}
}
@article{kannen2024beyond,
  title={Beyond Aesthetics: Cultural Competence in Text-to-Image Models},
  author={Kannen, Nithish and Ahmad, Arif and Andreetto, Marco and Prabhakaran, Vinodkumar and Prabhu, Utsav and Dieng, Adji Bousso and Bhattacharyya, Pushpak and Dave, Shachi},
  journal={arXiv preprint arXiv:2407.06863},
  year={2024}
}
@article{adilazuarda2024towards,
  title={Towards measuring and modeling" culture" in llms: A survey},
  author={Adilazuarda, Muhammad Farid and Mukherjee, Sagnik and Lavania, Pradhyumna and Singh, Siddhant and Dwivedi, Ashutosh and Aji, Alham Fikri and O'Neill, Jacki and Modi, Ashutosh and Choudhury, Monojit},
  journal={arXiv preprint arXiv:2403.15412},
  year={2024}
}
@misc{hershcovich2022challengesstrategiescrossculturalnlp,
      title={Challenges and Strategies in Cross-Cultural NLP}, 
      author={Daniel Hershcovich and Stella Frank and Heather Lent and Miryam de Lhoneux and Mostafa Abdou and Stephanie Brandl and Emanuele Bugliarello and Laura Cabello Piqueras and Ilias Chalkidis and Ruixiang Cui and Constanza Fierro and Katerina Margatina and Phillip Rust and Anders Søgaard},
      year={2022},
      eprint={2203.10020},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.10020}, 
}
@article{she2024mapo,
  title={Mapo: Advancing multilingual reasoning through multilingual alignment-as-preference optimization},
  author={She, Shuaijie and Zou, Wei and Huang, Shujian and Zhu, Wenhao and Liu, Xiang and Geng, Xiang and Chen, Jiajun},
  journal={arXiv preprint arXiv:2401.06838},
  year={2024}
}
@inproceedings{romanyshyn2023proceedings,
  title={Proceedings of the Second Ukrainian Natural Language Processing Workshop (UNLP)},
  author={Romanyshyn, Mariana},
  booktitle={Proceedings of the Second Ukrainian Natural Language Processing Workshop (UNLP)},
  year={2023}
}
@article{fomenko2023brand,
  title={Brand new Ukraine? Cultural icons and national identity in times of war},
  author={Fomenko, Olena},
  journal={Place Branding and Public Diplomacy},
  volume={19},
  number={2},
  pages={223--227},
  year={2023},
  publisher={Springer}
}
@misc{ukraine_language_law_2019,
  title        = {Law of Ukraine "On Protecting the Functioning of the Ukrainian Language as the State Language"},
  howpublished = {\url{https://zakon.rada.gov.ua/laws/show/2704-19}},
  note         = {Accessed: 2024-11-03},
  year         = {2019},
  author = {Verkhovna Rada, Ukraine}
}
@article{Pompino-Marschall_Steriopolo_Żygis_2017, title={Ukrainian}, volume={47}, DOI={10.1017/S0025100316000372}, number={3}, journal={Journal of the International Phonetic Association}, author={Pompino-Marschall, Bernd and Steriopolo, Elena and Żygis, Marzena}, year={2017}, pages={349–357}}
@InProceedings{Tong_2024_CVPR,
    author    = {Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
    title     = {Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {9568-9578}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@article{taras2016does,
  title={Does country equate with culture? Beyond geography in the search for cultural boundaries},
  author={Taras, Vas and Steel, Piers and Kirkman, Bradley L},
  journal={Management International Review},
  volume={56},
  pages={455--487},
  year={2016},
  publisher={Springer}
}
@Inbook{Currie2021,
author="Currie, Morgan
and Miranda Correa, Melisa",
title="Theories and Methods of Cultural Mapping",
bookTitle="The Culture and Communities Mapping Project",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="15--40",
abstract="In this chapter, we review literature on cultural mapping that has served as the intellectual underpinnings of the Culture {\&} Communities Mapping Project, beginning with indigenous counter-mapping in Canada, largely considered the foundation of cultural mapping. We discuss how the methods and applications of cultural mapping have since expanded to encompass an array of spatial practices for studying cultural identities and the cultural assets of an area, with methods ranging from participatory community asset mapping to the use of online GIS maps to drive cultural policy. This chapter also takes us through some of the major theoretical writings about cartography, drawing on scholars of critical cartography and cultural geography who ask us to read maps as constructed texts or arguments communicating the political context of their creation. We then draw on scholarship that looks at how maps act in the world---at their role as everyday objects or as aesthetic and political expressions. These writings lead us to a series of questions that people can ask to think about their own cultural mapping work---about the choices to make concerning what kinds of information to collect, how participatory the project should be, what materials to use, what the aims ultimately are and how to understand the project's limitations.",
isbn="978-3-030-88651-6",
doi="10.1007/978-3-030-88651-6_2",
url="https://doi.org/10.1007/978-3-030-88651-6_2"
}
@inproceedings{srivastava2017significance,
  title={Significance of neural phonotactic models for large-scale spoken language identification},
  author={Srivastava, Brij Mohan Lal and Vydana, Hari and Vuppala, Anil Kumar and Shrivastava, Manish},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={2144--2151},
  year={2017},
  organization={IEEE}
}
@inproceedings{NEURIPS2023_b01153e7,
 author = {Luccioni, Sasha and Akiki, Christopher and Mitchell, Margaret and Jernite, Yacine},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {56338--56351},
 publisher = {Curran Associates, Inc.},
 title = {Stable Bias: Evaluating Societal Representations in Diffusion Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/b01153e7112b347d8ed54f317840d8af-Paper-Datasets_and_Benchmarks.pdf},
 volume = {36},
 year = {2023}
}
@article{mayer2014gagauz,
  title={Gagauz people--their language and ethnic identity},
  author={Mayer, Milan},
  year={2014},
  publisher={https://kulturnistudia. cz/}
}
@inproceedings{das2023diversity,
  title={Diversity matters: Robustness of bias measurements in Wikidata},
  author={Das, Paramita and Karnam, Sai Keerthana and Panda, Anirban and Guda, Bhanu Prakash Reddy and Sarkar, Soumya and Mukherjee, Animesh},
  booktitle={Proceedings of the 15th ACM Web Science Conference 2023},
  pages={208--218},
  year={2023}
}
@article{paret2023words,
  title={Words at War: The Impact of Language on Perceptions and Representations of the Enemy in Russia-Ukraine War},
  author={Paret, Julien},
  journal={Close Encounters in War Journal},
  volume={6},
  pages={92--118},
  year={2023}
}
@article{yavorska2010impact,
  title={The impact of ideologies on the standardization of modern Ukrainian},
  author={Yavorska, Galina},
  year={2010},
  publisher={Walter de Gruyter GmbH \& Co. KG}
}
@inproceedings{10.1145/3366424.3383536,
author = {H. Lee, Helena and Shu, Ke and Achananuparp, Palakorn and Prasetyo, Philips Kokoh and Liu, Yue and Lim, Ee-Peng and Varshney, Lav R.},
title = {RecipeGPT: Generative Pre-training Based Cooking Recipe Generation and Evaluation System},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3383536},
doi = {10.1145/3366424.3383536},
abstract = {Interests in the automatic generation of cooking recipes have been growing steadily over the past few years thanks to a large amount of online cooking recipes. We present RecipeGPT, a novel online recipe generation and evaluation system. The system provides two modes of text generations: (1) instruction generation from given recipe title and ingredients; and (2) ingredient generation from recipe title and cooking instructions. Its back-end text generation module comprises a generative pre-trained language model GPT-2 fine-tuned on a large cooking recipe dataset. Moreover, the recipe evaluation module allows the users to conveniently inspect the quality of the generated recipe contents and store the results for future reference. RecipeGPT can be accessed online at  https://recipegpt.org/},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {181–184},
numpages = {4},
keywords = {natural language generation, recipe generation, web application},
location = {Taipei, Taiwan},
series = {WWW '20}
}
@inproceedings{zhang-etal-2024-knowledge-alignment,
    title = "The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large Language Models",
    author = "Zhang, Shuo  and
      Pan, Liangming  and
      Zhao, Junzhou  and
      Wang, William Yang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.121",
    doi = "10.18653/v1/2024.findings-acl.121",
    pages = "2025--2038",
    abstract = "Large language models often necessitate grounding on external knowledge to generate faithful and reliable answers. Yet even with the correct groundings in the reference, they can ignore them and rely on wrong groundings or their inherent biases to hallucinate when users, being largely unaware of the specifics of the stored information, pose questions that might not directly correlate with the retrieved groundings. In this work, we formulate this knowledge alignment problem and introduce MixAlign, a framework that interacts with both the human user and the knowledge base to obtain and integrate clarifications on how the user question relates to the stored information. MixAlign employs a language model to achieve automatic knowledge alignment and, if necessary, further enhances this alignment through human user clarifications. Experimental results highlight the crucial role of knowledge alignment in boosting model performance and mitigating hallucination, with improvements noted up to 22.2{\%} and 27.1{\%} respectively. We also demonstrate the effectiveness of MixAlign in improving knowledge alignment by producing high-quality, user-centered clarifications.",
}

@article{yu2016place,
  title={The place of the Kievan Rus in history},
  author={Yu, Dvornichenko Andrey},
  journal={Bulletin of St. Petersburg University. History},
  number={4},
  pages={5--17},
  year={2016},
  publisher={Federal State Budgetary Educational Institution of Higher}
}
@inproceedings{chhikara2024fire,
  title={Fire: Food image to recipe generation},
  author={Chhikara, Prateek and Chaurasia, Dhiraj and Jiang, Yifan and Masur, Omkar and Ilievski, Filip},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={8184--8194},
  year={2024}
}
@inproceedings{mohbat2024llava,
  title={LLaVA-Chef: A Multi-modal Generative Model for Food Recipes},
  author={Mohbat, Fnu and Zaki, Mohammed J},
  booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
  pages={1711--1721},
  year={2024}
}
@inproceedings{hu-etal-2024-bridging,
    title = "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval",
    author = "Hu, Tianyi  and
      Maistro, Maria  and
      Hershcovich, Daniel",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.61",
    pages = "1068--1080",
    abstract = "The cross-cultural adaptation of recipes is an important application of identifying and bridging cultural differences in language. The challenge lies in retaining the essence of the original recipe while also aligning with the writing and dietary habits of the target culture. Information Retrieval (IR) offers a way to address the challenge because it retrieves results from the culinary practices of the target culture while maintaining relevance to the original recipe. We introduce a novel task about cross-cultural recipe retrieval and present a unique Chinese-English cross-cultural recipe retrieval benchmark. Our benchmark is manually annotated under limited resource, utilizing various retrieval models to generate a pool of candidate results for manual annotation. The dataset provides retrieval samples that are culturally adapted but textually diverse, presenting greater challenges. We propose CARROT, a plug-and-play cultural-aware recipe information retrieval framework that incorporates cultural-aware query rewriting and re-ranking methods and evaluate it both on our benchmark and intuitive human judgments. The results show that our framework significantly enhances the preservation of the original recipe and its cultural appropriateness for the target culture. We believe these insights will significantly contribute to future research on cultural adaptation.",
}

@article{yao2023benchmarking,
  title={Benchmarking llm-based machine translation on cultural awareness},
  author={Yao, Binwei and Jiang, Ming and Yang, Diyi and Hu, Junjie},
  journal={arXiv preprint arXiv:2305.14328},
  year={2023}
}

@article{putri2024can,
  title={Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese},
  author={Putri, Rifki Afina and Haznitrama, Faiz Ghifari and Adhista, Dea and Oh, Alice},
  journal={arXiv preprint arXiv:2402.17302},
  year={2024}
}
@article{doi:10.1177/13670069040080040101,
author = {Laada Bilaniuk},
title ={A typology of surzhyk: Mixed Ukrainian-Russian language},

journal = {International Journal of Bilingualism},
volume = {8},
number = {4},
pages = {409-425},
year = {2004},
doi = {10.1177/13670069040080040101},

URL = { 
    
        https://doi.org/10.1177/13670069040080040101
    
    

},
eprint = { 
    
        https://doi.org/10.1177/13670069040080040101
    
    

}
,
    abstract = { A typology is developed that systematizes the various linguistic phenomena in Ukraine that are commonly referred to as surzhyk—a Ukrainian term meaning `impure, mixed language'. The term surzhyk has become frequently used in public discourse and the media since Ukrainian was elevated to the status of official state language and Ukraine declared its independence. A heightened purist ideology has led to broad use of the term, which tends to have pejorative connotations. The typology is based on the historical, social, and ideological factors that have shaped language use. Five major categories of surzhyk are defined: (1) urbanized peasant surzhyk, (2) village dialect-surzhyk, (3) Sovietized-Ukrainian surzhyk, (4) urban bilinguals' surzhyk, and (5) post-independence surzhyk. These five prototypes are further characterized according to the typology of bilingualism proposed by Auer (1999), by considering the degree of pragmatic salience and the grammaticalization of language alternation. This case study presents a paradigm for the analysis of mixed languages. }
}

@article{podolyan2005ukrainians,
  title={How Do Ukrainians Communicate?(Observations Based upon Youth Population of Kyiv)},
  author={Podolyan, Ilona E and others},
  journal={Journal of Intercultural Communication},
  volume={5},
  number={2},
  pages={1--14},
  year={2005},
  publisher={International Collaboration for Research \& Publications}
}
@inproceedings{kenton2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of naacL-HLT},
  volume={1},
  pages={2},
  year={2019},
  organization={Minneapolis, Minnesota}
}
@book{romaine2017pidgin,
  title={Pidgin and creole languages},
  author={Romaine, Suzanne},
  year={2017},
  publisher={Routledge}
}
@inproceedings{adilazuarda-etal-2024-towards,
    title = "Towards Measuring and Modeling {``}Culture{''} in {LLM}s: A Survey",
    author = "Adilazuarda, Muhammad Farid  and
      Mukherjee, Sagnik  and
      Lavania, Pradhyumna  and
      Singh, Siddhant Shivdutt  and
      Aji, Alham Fikri  and
      O{'}Neill, Jacki  and
      Modi, Ashutosh  and
      Choudhury, Monojit",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.882",
    pages = "15763--15784",
    abstract = "We present a survey of more than 90 recent papers that aim to study cultural representation and inclusion in large language models (LLMs). We observe that none of the studies explicitly define {``}culture, which is a complex, multifaceted concept; instead, they probe the models on some specially designed datasets which represent certain aspects of {``}culture{''}. We call these aspects the proxies of culture, and organize them across two dimensions of demographic and semantic proxies. We also categorize the probing methods employed. Our analysis indicates that only certain aspects of {``}culture,{''} such as values and objectives, have been studied, leaving several other interesting and important facets, especially the multitude of semantic domains (Thompson et al., 2020) and aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps are the lack of robustness of probing techniques and situated studies on the impact of cultural mis- and under-representation in LLM-based applications.",
}
@inproceedings{laufer2015mining,
  title={Mining cross-cultural relations from Wikipedia: a study of 31 European food cultures},
  author={Laufer, Paul and Wagner, Claudia and Fl{\"o}ck, Fabian and Strohmaier, Markus},
  booktitle={Proceedings of the ACM web science conference},
  pages={1--10},
  year={2015}
}
@article{miquel2018wikipedia,
  title={Wikipedia culture gap: quantifying content imbalances across 40 language editions},
  author={Miquel-Rib{\'e}, Marc and Laniado, David},
  journal={Frontiers in physics},
  volume={6},
  pages={54},
  year={2018},
  publisher={Frontiers Media SA}
}
@article{doi:10.1177/00220221241256322,
author = {Anton Kurapov and Oleksandra Balashevych and Christoph Bamberg and Pawel Boski},
title ={Cutting Cultural Ties? Reasons Why Ukrainians Terminate or Continue to Interact With Russian Culture Despite the Ongoing Russian-Ukrainian War},

journal = {Journal of Cross-Cultural Psychology},
volume = {55},
number = {5},
pages = {553-571},
year = {2024},
doi = {10.1177/00220221241256322},

URL = { 
    
        https://doi.org/10.1177/00220221241256322
    
    

},
eprint = { 
    
        https://doi.org/10.1177/00220221241256322
    
    

}
,
    abstract = { The study investigates the factors related to Ukrainian nationals’ engagement or disengagement with Russian culture amid Russian-Ukrainian war. It explores the predictors of both continued engagement and reasons for terminating interaction, considering demographic, emotional, and circumstantial factors. A cross-sectional correlational design was used, involving 935 participants (305 continuing and 630 ceasing interaction with Russian culture). Participants completed questionnaires and detailed their engagement with Russian culture across various cultural items. Multiple linear and logistic regressions were conducted for analysis. The study found that factors like spoken language and coping strategies play a significant role in the decision to cut cultural ties. For those continuing interaction, language and emotional attachment were influential, alongside practical necessities like work/study requirements and the absence of Ukrainian alternatives. The study highlights a complex interplay of emotion, language, and age in shaping Ukrainians’ interaction with Russian culture during the war. It suggests future research should include additional sociopolitical and sociocultural factors, and a broader demographic representation to gain more nuanced perspectives. }
}
@article{Rutland_2023, title={Thirty Years of Nation-Building in the Post-Soviet States}, volume={51}, DOI={10.1017/nps.2021.94}, number={1}, journal={Nationalities Papers}, author={Rutland, Peter}, year={2023}, pages={14–32}} <div></div>
@incollection{webber2014former,
  title={The Former Soviet Union: Russia and Ukraine},
  author={Webber, Mark},
  booktitle={Foreign policy in a transformed world},
  pages={137--178},
  year={2014},
  publisher={Routledge}
}

@article{silver1974social,
  title={Social mobilization and the Russification of Soviet nationalities},
  author={Silver, Brian},
  journal={American Political Science Review},
  volume={68},
  number={1},
  pages={45--66},
  year={1974},
  publisher={Cambridge University Press}
}
@article{boman2023coexistence,
  title={The coexistence of nationalism, Westernization, Russification, and Russophobia: facets of parallelization in the Russian invasion of Ukraine},
  author={Boman, Bj{\"o}rn},
  journal={International Politics},
  volume={60},
  number={6},
  pages={1315--1331},
  year={2023},
  publisher={Springer}
}
@article{kreutzer2022quality,
  title={Quality at a glance: An audit of web-crawled multilingual datasets},
  author={Kreutzer, Julia and Caswell, Isaac and Wang, Lisa and Wahab, Ahsan and van Esch, Daan and Ulzii-Orshikh, Nasanbayar and Tapo, Allahsera and Subramani, Nishant and Sokolov, Artem and Sikasote, Claytone and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={50--72},
  year={2022},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{boychuk2023effect,
  title={The effect of Russian colonialism on Ukrainian cultural identity},
  author={Boychuk, Yuliana and Dumelier, Rory and Fau, Yevheniya and Mysiv, Khrystyna and Sereda, Anastasiya and Toews, Alison and White, Courage},
  year={2023}
}
@article{soldaini2024dolma,
  title={Dolma: An open corpus of three trillion tokens for language model pretraining research},
  author={Soldaini, Luca and Kinney, Rodney and Bhagia, Akshita and Schwenk, Dustin and Atkinson, David and Authur, Russell and Bogin, Ben and Chandu, Khyathi and Dumas, Jennifer and Elazar, Yanai and others},
  journal={arXiv preprint arXiv:2402.00159},
  year={2024}
}
@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}
@misc{li2024attributingcultureconditionedgenerationspretraining,
      title={Attributing Culture-Conditioned Generations to Pretraining Corpora}, 
      author={Huihan Li and Arnav Goel and Keyu He and Xiang Ren},
      year={2024},
      eprint={2412.20760},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.20760}, 
}


@article{naous2025origin,
  title={On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena},
  author={Naous, Tarek and Xu, Wei},
  journal={arXiv preprint arXiv:2501.04662},
  year={2025}
}
@article{kulyk2024language,
  title={Language shift in time of war: the abandonment of Russian in Ukraine},
  author={Kulyk, Volodymyr},
  journal={Post-Soviet Affairs},
  volume={40},
  number={3},
  pages={159--174},
  year={2024},
  publisher={Taylor \& Francis}
}
@incollection{comrie2018russian,
  title={Russian},
  author={Comrie, Bernard},
  booktitle={The world's major languages},
  pages={282--297},
  year={2018},
  publisher={Routledge}
}
@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, P},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}
@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}