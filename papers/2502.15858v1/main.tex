%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template for TISMIR Papers
% 2017 version, based on previous ISMIR conference template
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sample Document LaTeX packages
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc}
% To remove the line numbers for the camera-ready version of your paper, remove
% the `review` option from the tismir package
% \usepackage[review]{tismir}
\usepackage{tismir}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{lipsum}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title and Author information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Generative AI Training and Copyright Law}
%
\author{%
Tim W.~Dornis\thanks{Institute of Legal Informatics, Faculty of Law, Leibniz University Hannover, Königsworther Platz 1, 30167 Hannover, Germany}%
\ ~and %
Sebastian Stober\thanks{Artificial Intelligence Lab, Faculty of Computer Science, Otto-von-Guericke-University Magdeburg, Universitätsplatz 2, 39106 Magdeburg, Germany}%}
}

\date{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Additional Paper Information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Article Type - Uncomment and modify, if necessary.
% Accepted values: research, overview, and dataset
\type{overview}

% Citation in First Page
%
% "Mandatory" (if missing will print the complete list of authors,
% including the \thanks symbols)
\authorref{Dornis,~T.~W. and Stober,~S.}
%
% (Optional)
% \journalyear{2017}
% \journalvolume{V}
% \journalissue{N}
% \journalpages{xx--xx}
% \doi{xx.xxxx/xxxx.xx}

% Remaining Pages (Optional)
%
\authorshort{Dornis and Stober} %or, e.g., \authorshort{Author1 et al}
\titleshort{Generative AI Training and Copyright Law}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document Content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\twocolumn[{%
%
\maketitleblock
%
\begin{abstract}
% Research articles must have the main text prefaced by an abstract of no more
% than 250 words summarising the main arguments and conclusions of the article.
% This must have the heading ``Abstract'' and be easily identified from the start
% of the main text.
Training generative AI models requires extensive amounts of data. 
A common practice is to collect such data through web scraping. 
Yet, much of what has been and is collected is copyright protected. 
Its use may be copyright infringement.
In the USA, AI developers rely on ``fair use'' and in Europe, the prevailing view is that the exception for ``Text and Data Mining'' (TDM) applies. 
In a recent interdisciplinary tandem-study, we have argued in detail that this is actually not the case because generative AI training fundamentally differs from TDM. 
In this article, we share our main findings and the implications for both public and corporate research on generative models. 
We further discuss how the phenomenon of training data memorization leads to copyright issues independently from the ``fair use'' and TDM exceptions. 
Finally, we outline how the ISMIR could contribute to the ongoing discussion about fair practices with respect to generative AI that satisfy all stakeholders.
% 137 words
\end{abstract}
%
\begin{keywords}
% Up to six keywords (optional).
Generative Training, 
Copyright,
Memorization,
Data Provenance
\end{keywords}
}]
\saythanks{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Main Content Start
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Articles must not be longer than 8,000 words in length, not including referencing, citation and notes.

\section{Introduction}\label{sec:headings}

% Story:
% - Allgem GenAI wie in Buch
% - massive Trainingsdaten, einige davon Copyright-geschützt
% - Suno Quote, lawsuit, betrifft aber auch normale Forscher

Generative artificial intelligence (AI) has emerged as a transformative tool across numerous creative domains, including music, visual art, and literature. 
These systems operate by learning patterns, structures, and styles from large datasets, enabling them to generate novel outputs that mimic or extend human creativity. 
Recent advances, particularly in deep learning architectures such as transformer models and diffusion-based approaches, have significantly enhanced the quality and diversity of AI-generated music. 
Models like Jukebox \citep{jukebox} or MusicLM \citep{musiclm} 
as well as text-to-music AI services such as provided by the start-ups Suno AI\footnote{\href{https://suno.com}{https://suno.com}} and Udio\footnote{\href{https://www.udio.com/}{https://www.udio.com/}} exemplify the state of the art, producing compositions that range from stylistic imitations to innovative genre-blending works.

A key factor underlying this progress is the scale and richness of the training data. 
High-quality, diverse datasets allow models to capture the intricacies of musical styles, genres, and techniques. 
However, the reliance on extensive copyrighted material raises complex legal and ethical questions. 
% Stability AI took a different approach with Stable Audio 2.0, and used an explicitly licensed dataset of music called AudioSparx.
%
% Case 1:24-cv-11611-FDS Document 28 Filed 08/01/24 Page 9 of 36
% https://archive.org/details/gov.uscourts.mad.272063/gov.uscourts.mad.272063.28.0.pdf
For instance, in a legal statement\footnote{United States District Court for the District of Massachusetts, Civil Action No.~1:24-cv-11611-FDS, Document 28, Filed 08/01/24. Archived at \href{https://archive.org/details/gov.uscourts.mad.272063/gov.uscourts.mad.272063.28.0.pdf}{https://archive.org/details/gov.uscourts.mad.272063/ gov.uscourts.mad.272063.28.0.pdf}} as part of a copyright lawsuit by the Record Industry Association of America (RIAA) against Suno AI, the company openly stated that ``Suno’s training data includes essentially all music files of reasonable quality that are accessible on the open Internet, abiding by paywalls, password protections, and the like, combined with similarly available text descriptions.''
% take what they can (for free) and then sell it back a product creating cheap competition to those they took it from -> highly unethical behavior
They further argued that ``It is fair use under copyright law to make a copy of a protected work as part of a back-end technological process, invisible to the public, in the service of creating an ultimately non-infringing new product." 
% Its argument seems to be that since the AI-generated tracks it creates don't include samples, illegally obtaining all of those tracks to train the AI model isn't a problem.
Time will tell whether this argument will hold in court.
% 
Irregardless of the outcome, this case illustrates how it has become increasingly difficult to navigate the legal space in the context of generative AI.

Addressing this issue, this paper aims to create a better understanding of the interplay between generative AI’s technical capabilities and copyright law %is critical for addressing these challenges, 
-- particularly in the context of music information retrieval (MIR) and its broader implications for creators, researchers, and industry stakeholders.
It is based by a study on generative AI and copyright law in Germany and the EU conducted by the authors in 2024 and 
published in German as an open-access book \citep{2024:dornis:urheberrec}.
This article contains a summary of the main findings with specific implications for the MIR community. 
% 
Section \ref{sec:legal_frameworks} introduces legal frameworks for training data collection and usage and discusses their applicability to training generative AI models.
The text extends the scope of the original study by incorporating a discussion of the fair use doctrine in the US and a brief coverage of regulations in jurisdictions other than the EU and the US.
% 
Section \ref{sec:memorization} addresses the issue of training data memorization and discusses the resulting legal implications.
This part is essentially a translated and condensed version of the original German text of the findings in our extended analysis \citep{2024:dornis:urheberrec}.
%
Section \ref{sec:documentation} discusses the challenge of providing a sufficiently detailed documentation of training data sources -- a topic that was not covered by the original study.
Here, we propose a pragmatic solution that balances the needs of rightsholders with the constraints of AI developers.
%
Finally, we draw conclusions and provide an outlook in Section \ref{sec:conclusion}.


% \section{Text and Data Mining vs.~Generative AI Training}
\section{Legal Frameworks for Training Data Collection and Usage}\label{sec:legal_frameworks}

% TODO: In order to cover a more broad / international perspective, this could also be called ``legal frameworks'' for data collection for GenAI training. Then we could argue that there is non yet that explicitly addresses GenAI but that companies like OpenAI or Suno AI refer to TDM and fair use to argue that what they do is legal. Then we look at these frameowrks, compare them and provide some more international context. Finally, we discuss whether they are applicable - once for TDM and once for fair use.
% TODO: EU DSM is from 2019 but did not really address GenAI training explicitly. The EU AI Act is a regulation of the service level and does not cover copyright

Given the fast pace at which generative AI models -- in the following abbreviated as GenAI -- have evolved over the last decade since the emergence of Generative Adversarial Networks and Variational Autoencoders around 2014, it is no wonder that legislature still lags behind.
In fact, there are no legal frameworks yet that explicitly address GenAI.%
\footnote{%TODO: can we say that? EU DSM is from 2019 but did not really address GenAI training explicitly. The EU AI Act is a regulation of the service level and does not cover copyright.
The EU DSM Directive did not address the use of copyrighted materials for GenAI training. 
The 2024 AI Act, albeit the lawmakers were aware of the issue, is conceived as a regulation that primarily concerns product safety and, hence, AI risks in general. See \cite{dornis2025a}.
}
Companies like OpenAI or Suno AI refer to copyright exceptions for text and data mining (TDM) and ``fair use'' to argue that what they do is legal -- such as using vast quantities of mostly unlicensed data scraped from the internet as well as public and commercial libraries.
In the following, we will first outline these legal framework and compare them to each other.
We will then discuss whether they are actually applicable in the context of GenAI training and finally draw conclusions for MIR research.

%%%%% old version:
% The first point to be discussed is the distinction between so-called text and data mining (TDM) and training generative AI models (GenAI).
% This is crucial because there are special legal frameworks in place to permit TDM whereas there is nothing comparable yet that explicitly addresses GenAI.
% Only if GenAI was considered as a form of TDM, the same legal rules would apply.
% In the following, we will first outline the legal framework for TDM, then discuss whether GenAI can be considered as a form of TDM, and finally draw conclusions for MIR research.

% FIXME
% The distinction between text and data mining (TDM) and training generative AI (GenAI) models is crucial, as these processes serve different purposes and are subject to differing legal frameworks. TDM involves the analysis of large datasets to discover patterns, extract useful knowledge, and inform decision-making. In contrast, GenAI training focuses on approximating the probability distribution of data to create novel outputs, such as text, images, or music, that closely resemble the training data.

\subsection{The TDM Exceptions in the EU}

% In the European Union, the legal framework for TDM is outlined in the Directive (EU) 2019/790 on copyright in the Digital Single Market (DSM Directive).\footnote{\href{https://eur-lex.europa.eu/eli/dir/2019/790/oj}{https://eur-lex.europa.eu/eli/dir/2019/790/oj}} 
In the European Union, the Directive (EU) 2019/790 on copyright in the Digital Single Market (DSM Directive) explicitly introduces a legal framework for TDM.\footnote{\href{https://eur-lex.europa.eu/eli/dir/2019/790/oj}{https://eur-lex.europa.eu/eli/dir/2019/790/oj}} 
Articles 3 and 4 of this directive establish specific exceptions for TDM activities:

\noindent\textbf{Article 3} provides an exception for reproductions and extractions by research organizations\footnote{A ``research organisation'' is either non-profit entity or has a public service research mission.} 
and cultural heritage institutions\footnote{``Cultural heritage institutions'' are publicly accessible libraries, museums, archives and film or audio heritage institution.} for the purposes of scientific research.
Key aspects include:
\begin{itemize}
    \item \textbf{Lawful Access:} Works must be accessible (i.e.~without circumventing restrictions). 
    This includes content under subscriptions or open access licenses.
    \item \textbf{Retention of Data:} Copies may be retained indefinitely, including for the verification of research results.
    \item \textbf{No Opt-Out:} Rightsholders cannot prevent access through contractual terms or licenses.
\end{itemize}

\noindent\textbf{Article 4} permits TDM for commercial purposes, with the following limitations:
\begin{itemize}
    \item \textbf{Lawful Access:} The same understanding as for Article 3 applies.
    \item \textbf{Limited Retention of Data:} Data retention is allowed only for the duration necessary for TDM activities.\footnote{One could still argue that the TDM process is kind-of continuously ongoing, which seems to be the common practice.}
    \item \textbf{Opt-Out:} Rightsholders can opt out by reserving their rights in a machine-readable manner, such as through a \textit{robots.txt} file.\footnote{The actual wording is ``in an appropriate manner, such as machine-readable means in the case of content made publicly available online''. There is no technical standard for this yet, which leaves room for a discussion of what is ``appropriate.'' A common approach seems to be to put this in the \textit{robots.txt} file. A recent argument is that anything a human can read and understand -- such as text on an imprint page of a website -- is deemed machine-readable as well.}
\end{itemize}
% does not seem to be enforced - do we want to discuss this here?
% will this add anything useful?

The DSM Directive’s provisions are relatively liberal for non-commercial research, allowing activities such as scraping the internet for MIDI and audio files or using subscription services like Spotify or Deezer for data collection. 
This even implies that using freely downloadable pirated content is covered by the exception.
However, for commercial applications, restrictions are more stringent, requiring data deletion after use and accommodating rightsholder opt-outs.
Yet, use of freely available content is also generally considered admissible, even if it should have been found on pirate websites.
As a result, some content owners have started to negotiate specific paid-for TDM licences with for-profit miners.
% Compared to the US, Article 4 is more restrictive.
% In the US, TDM is deemed fair use, even if it is done for profit.
% TODO: say more about how the situation in the US differs

\subsection{The Fair Use Doctrine in the US}
\label{sec:fair_use}

In the United States, %TDM activities are generally governed by 
the doctrine of ``fair use'' under Section 107 of the Copyright Act (17 U.S.C. § 107)\footnote{\href{https://uscode.house.gov/view.xhtml?edition=prelim\&num=0\&req=granuleid\%3AUSC-prelim-title17-section107}{https://uscode.house.gov/view.xhtml?edition=prelim\&num=0\& req=granuleid\%3AUSC-prelim-title17-section107}} 
% Fair use 
permits the use of copyrighted material without explicit authorization for purposes such as research, education, criticism, or commentary, provided that such use meets a four-factor test:

\begin{enumerate}
    \item \textbf{Purpose and Character of Use:} Non-commercial and transformative uses are favored.
    \item \textbf{Nature of the Copyrighted Work:} Factual works are more likely to be subject to fair use than highly creative works.
    \item \textbf{Amount and Substantiality:} Limited use of the copyrighted material is preferred.
    \item \textbf{Effect on the Market:} Uses that do not harm the market value of the original work are more likely to qualify as fair use.
\end{enumerate}

Fair use provides greater flexibility compared to the EU’s DSM Directive, particularly for commercial TDM activities.
While the EU imposes explicit restrictions on data retention and grants rightsholders the ability to opt out (Article 4), the US framework does not require prior authorization or data deletion as long as the use can be justified as fair.
Prima facie, therefore, this broad interpretation allows commercial entities to engage in TDM without negotiating licenses, creating a competitive advantage for US-based researchers and businesses.

However, the US framework’s reliance on case-by-case judicial interpretation introduces significant legal uncertainty.
For example, determining whether a particular activity qualifies as fair use often depends on the specific circumstances of the case and how courts weigh the four factors. 
This uncertainty can make it difficult for researchers and businesses to confidently engage in activities without legal challenges.

In contrast, the DSM Directive offers a more structured approach, with clear provisions for different types of TDM activities and the roles of rightsholders. 
By explicitly outlining permissible activities and conditions, the EU framework reduces ambiguity and provides more predictable guidelines for compliance.

\subsection{Other Global Frameworks}

Other countries have adopted their own approaches in rules similar to the TDM and fair use exceptions, which reflect a diverse range of priorities and legal traditions:

\noindent
% \textbf{Australia:} Recent amendments to Australia’s Copyright Act introduced a fair dealing exception for TDM. 
% This exception aligns with the US approach, allowing flexible use but with less predictable legal boundaries.

\noindent
\textbf{Canada:} Canada’s Copyright Act\footnote{\href{https://laws-lois.justice.gc.ca/eng/acts/C-42/}{https://laws-lois.justice.gc.ca/eng/acts/C-42/}} includes fair dealing provisions that may apply. 
However, their application to TDM or GenAI training is underexplored and lacks specific guidelines. 
Legal reform is currently debated.\footnote{\href{https://ised-isde.canada.ca/site/strategic-policy-sector/en/marketplace-framework-policy/consultation-paper-consultation-copyright-age-generative-artificial-intelligence\#s21}{https://ised-isde.canada.ca/site/strategic-policy-sector/en/marketplace-framework-policy/consultation-paper-consultation-copyright-age-generative-artificial-intelligence\#s21}}


\noindent
\textbf{China:} China’s Copyright Law, as amended in 2021, does not explicitly address TDM.\footnote{See, e.g., \cite{hua2022copyright}.} 
However, the ``Interim Measures for the Management of Generative Artificial Intelligence Services''\footnote{\href{https://www.cac.gov.cn/2023-07/13/c\_1690898327029107.htm}{https://www.cac.gov.cn/2023-07/13/c\_1690898327029107.htm}} 
% Google Translate does a great job here.
(2023) mandate that GenAI services comply with copyright regulations.
% https://en.wikipedia.org/wiki/Interim_Measures_for_the_Management_of_Generative_AI_Services
Also, the 2024 draft AI Law contains further provisions on the use of copyrighted material for GenAI training.

\noindent
\textbf{India:} India’s Copyright Act of 1957\footnote{\href{https://copyright.gov.in/}{https://copyright.gov.in/}} has no specific exceptions for TDM, but rather provides for a general rule on ``fair dealing''.\footnote{Section 52 Indian Copyright Act.}
Since this rule is interpreted rather narrowly, however, it is arguable whether it could help justify TDM and GenAI training activities.
Recent lawsuits, such as Asian News International vs.~OpenAI, highlight the need for clearer regulations.
% 

\noindent
\textbf{Japan:} Japan’s Copyright Act\footnote{\href{https://www.cric.or.jp/english/clj/cl2.html}{https://www.cric.or.jp/english/clj/cl2.html}} seems to be one of the most permissive frameworks globally.
Most notably, Article 30-4 allows the use of copyrighted works for purposes that do not involve the expressive use of the work (loosely translated as ``enjoyment'') which clearly includes TDM.
Yet, the actual scope of justification that is granted under Japanese law is still debated and far from clear.

% permits TDM\footnote{TODO: Can we for} for any purpose, including commercial use, as long as it does not conflict with the normal exploitation of the work. 
% This is one of the most permissive TDM frameworks globally. 
% https://www.cric.or.jp/english/clj/cl2.html

\noindent
\textbf{South Korea:} Proposed amendments to South Korea’s Copyright Act\footnote{\href{https://elaw.klri.re.kr/eng\_service/lawView.do?hseq=42726\&lang=ENG}{https://elaw.klri.re.kr/eng\_service/lawView.do?hseq=42726\& lang=ENG}} aim to permit TDM.
Yet, here as well, whether the TDM exception will cover all kinds of GenAI training is disputed and far from clear.\footnote{See, e.g., Korea Copyright Commission, A Guide on Generative AI and Copyright, 2023; \href{https://www.copyright.or.kr/eng/doc/etc\_pdf/Guide\_on\_Generative\_AI\_and\_Copyright.pdf}{https://www.copyright.or.kr/eng/doc/etc\_pdf/ Guide\_on\_Generative\_AI\_and\_Copyright.pdf}}


% see https://www.ip.kimchang.com/en/insights/detail.kc?sch_section=4&idx=22775
% -> looks like this is really for TDM and not GenAI: 
% 1. Reproductions for Information Analysis (Article 43)
%    This is a new provision allowing for the reproduction and transmission of copyrighted works for the purpose of information analysis. The user may reproduce and transmit copyright works (without the copyright owner's prior consent) to the extent necessary to create additional information or value by analyzing mass information if (i) it is not for the enjoyment of the expression contained in the copyrighted works, and (ii) there is legitimate access to the works. This amendment is expected to reduce legal uncertainty relating to such use.

\noindent
\textbf{United Kingdom:} 
% The UK provides an exception for TDM in its Copyright, Designs, and Patents Act 1988.\footnote{\href{https://www.legislation.gov.uk/ukpga/1988/48/section/29A}{https://www.legislation.gov.uk/ukpga/1988/48/section/29A}}
% The exception permits TDM for non-commercial research by entities with lawful access to the data, and rightsholders cannot opt out. 
% This resembles the EU’s Article 3 but is more restrictive than Article 4.
The UK Copyright, Designs, and Patents Act 1988\footnote{\href{https://www.legislation.gov.uk/ukpga/1988/48/section/29A}{https://www.legislation.gov.uk/ukpga/1988/48/section/29A}} does provide for a TDM exception, but this exception is limited to ``computational analysis'' on lawfully accessed works for the ``sole purpose of research for a non-commercial purpose''. 
Generally, it is interpreted to exclude commercial TDM. 
Currently, the government is considering new regulation similar to the EU.


% These global variations highlight the need for international dialogue and potential harmonization of TDM regulations to support cross-border research and innovation while respecting copyright protections.
% These frameworks highlight a global divergence in policies. 
% The EU, Japan and UK offer relatively clear and structured guidelines for exception, while countries like the US and Canada provide broader, more flexible allowances, which can lead to greater legal uncertainty. 
% Other countries like India and China do not provide respective exceptions at all.
% This diversity 
Looking at this (meagre) overview highlights both divergence and convergence: 
Some jurisdictions -- similar to the EU -- attempt to offer clear guidelines for TDM exceptions, others rather rely on more open-ended and vague fair use or fair dealing provisions. 
Overall, agreement seems to exist that GenAI training must not be made impossible. 
Yet, the silver bullet still must be invented. 
This status of lawmaking underscores the importance of international dialogue on harmonizing policies for TDM and GenAI, especially given the global nature of AI research and data use.

\subsection{Can Generative AI Training be Considered TDM or Fair Use?}

Having outlined the legal frameworks of TDM and fair use above, we will now discuss whether they actually cover the training of GenAI models.

\subsubsection{Conceptual Distinctions Between TDM and GenAI Training}

TDM is broadly defined as the process of identifying interesting patterns and extracting useful knowledge from large data repositories \citep{Han2012DataMining,kdd2006datamning}.
For example, \cite{Han2012DataMining} describe data mining as involving ``data cleaning, data integration, data selection, data transformation, pattern discovery, pattern evaluation, and knowledge presentation.''
Similarly, \cite{FeldmanSanger2006textmining} highlight that text mining aims to ``extract useful information from data sources through the identification and exploration of interesting patterns.''

In contrast, generative AI models are trained to approximate the probability distribution of their training data -- which effectively leads to producing data that looks like the data they were trained with.
Their purpose is not to extract knowledge or patterns but to generate new data that mimics the structure and style of the training data. 
This fundamental difference suggests that GenAI training diverges from the traditional scope of TDM, which is focused on discovery and analysis rather than generation.

Specifically for MIR, typical tasks that clearly are or involve TDM comprise for example:
\begin{itemize}
    \item classification or recognition (key, chords, onsets, beats, tempo, instruments, tagging)
    \item extraction (melody, singing voice, lyrics, drums)
    \item decomposition, source separation and structural segmentation
    \item transcription and [multiple] f0-estimation
    \item synchronization and score alignment
    \item fingerprinting
    \item content-based indexing and retrieval (query by singing/humming)
\end{itemize}
% Typical MIR tasks that involve TDM include classification, recognition, extraction, source separation, transcription, synchronization, and content-based retrieval. 
These tasks aim to identify and leverage specific patterns or features in the data, often for analytical or organizational purposes. 
While deep learning methods have introduced more complex workflows -- sometimes involving generative models for pre-training representations -- the ultimate goal remains rooted in extracting insights. 
In contrast, a generative model trained to produce high-quality outputs serves a different purpose.
It cannot directly be used to discover interesting patterns or extract useful knowledge.
%inherently aims to replicate and ???extend the training data, raising questions about whether it aligns with TDM’s objectives.

\subsubsection{Can GenAI Training be Considered as Fair Use?}

% The legal landscape complicates the matter further, particularly under fair use doctrines in jurisdictions like the United States. Fair use is evaluated based on four factors:

In order to assess whether GenAI training is covered by fair use doctrines in jurisdictions like the United States, the four factors introduced in Section \ref{sec:fair_use} need to be considered:\footnote{For a most recent application of the four-factor test see Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith, 598 U.S. 508 (2023).}

% \begin{enumerate}
%     \item 
% \noindent
    \textbf{Purpose and Character of the Use:}
    GenAI training arguably differs from TDM in its purpose. 
    While TDM generally seeks to derive abstract insights or utility from the data, GenAI training focuses on creating derivative works or outputs that resemble the original data. 
    Courts have often assessed transformative use as a key factor in fair use determinations. 
    For example, if the use repurposes the original work for a new and socially beneficial objective, it may favor fair use. 
    However, the transformative nature of GenAI training is debatable, as its outputs often directly reflect the style and substance of the training data.

% \noindent
    \textbf{Nature of the Copyrighted Work:} 
    The nature of the training data plays a significant role. 
    Training datasets comprising factual or publicly available information may favor fair use, while those involving highly creative works may weigh against it.

% \noindent
    \textbf{Amount and Substantiality of the Portion Used:}
    GenAI training typically involves the ingestion of vast datasets, often encompassing entire works. 
    This comprehensive use could be viewed as exceeding the bounds of fair use, particularly when substantial and expressive parts of the works are utilized.

% \noindent
    \textbf{Effect on the Market:}
    A critical issue is whether GenAI training creates competition for the original works by enabling the generation of similar outputs. 
    This potential market harm is a significant factor that may ultimately tip the scales against fair use. 
    Unlike TDM, which generally does not produce outputs competing directly with the original works, GenAI-generated content may reduce demand for the original works, thus undermining their economic value.
% \end{enumerate}

\subsubsection{Broader Considerations and Ongoing Debates}

Proponents of the TDM argument -- including major AI companies -- contend that generative training merely constitutes an extension of data mining practices, though this view remains highly contested.
% Some argue that GenAI training falls within the scope of TDM exceptions, particularly under regulatory frameworks like the EU’s Directive on Copyright in the Digital Single Market. 
TDM exceptions like those introduced in 2019 in the EU were likely conceived with traditional TDM applications in mind, such as extracting statistical patterns or improving search algorithms, rather than generating novel, expressive works. 
Furthermore, the holistic modeling inherent in GenAI -- which seeks to replicate the entirety of the training data’s structure and style -- diverges from the task-specific focus of TDM, where only relevant aspects of the data are modeled.
% Critics of equating GenAI training with TDM highlight that 
In contrast to classical TDM applications, generative models may pose competitive risks to original creators by replicating their unique style or expression. 
Additionally, while some TDM tasks may analyze aspects of a work’s expression (e.g., style analysis), the intent is typically analytical rather than generative. 

The debate about fair use is similarly multifaceted.\footnote{For an overview of the US debate see, e.g., \cite{samuelson2024fair}, \cite{sag2024fairness} and \cite{Brauneis2025}.}
Proponents of fair use argue that GenAI training represents a transformative use by enabling new forms of creativity and innovation. 
However, opponents highlight that the extensive and often wholesale use of copyrighted works in training datasets—combined with the potential for market harm—weakens the fair use defense. 
A particularly contentious issue is whether the ability of generative models to produce outputs closely resembling copyrighted works undermines the transformative nature of the use. 
Furthermore, fair use considerations must balance societal benefits against the rights and incentives of original creators, adding complexity to the evaluation of generative AI’s legality.


\subsection{Conclusions for MIR Research}

While GenAI training shares some methodological overlaps with TDM, its objectives and outputs significantly diverge. 
The legal and conceptual frameworks governing TDM and fair use may not seamlessly extend to generative AI, particularly given its potential to compete with and replicate the expressive elements of copyrighted works. 
% Further legal and scholarly debate is needed to clarify these distinctions and address the unique challenges posed by generative AI.

If GenAI training is not TDM, what does this mean in practical terms? 
It implies that researchers no longer operate within the exceptions provided by the EU’s DSM Directive or the U.S. fair use doctrine. 
Consequently, explicit permission must be sought for the collection and use of training data, regardless of whether the entity is a public research institution or a private company. 
This requirement affects all parties working on GenAI and underscores the urgent need for an unambiguous legal framework that specifically addresses modern generative AI training. 
Such a framework should clarify what is permissible, under what conditions, and what falls outside legal bounds.
% TODO: lack creates uncertainties and risks

Another critical challenge lies in the repurposing of datasets. 
As for instance pointed out in a recent survey by \cite{morreale2023data},
many datasets in the MIR community were initially created for traditional TDM tasks.
Their use was compliant under existing TDM and fair use exceptions. 
However, reusing these datasets for GenAI training may no longer fall under those exceptions. 
This necessitates obtaining permission from rights holders for such new uses. 
Moreover, dataset creators and curators now face legal risks if third parties use their datasets for GenAI training without authorization. 
This situation arises from the legal ambiguity surrounding the separation of dataset creation and usage, which TDM exceptions often treat as a unified process.

Finally, there remains the question of how to address historical practices that predate TDM exceptions. 
As one commentator aptly noted, ``The milk is spilled, and there is no way to get it back into the bottle.'' 
What does this mean? 
Ultimately, it is a liability risk for GenAI creators. 
In essence, since in many jurisdictions no legal defenses or exceptions existed at the time when the wave of GenAI training started, the past of the AI industry is filled with numberless incidents of copyright infringement.
While this highlights the difficulty of retroactively addressing past actions, it also presents an opportunity for the MIR community to propose creative solutions. 
By developing best practices and advocating for clear guidelines, the community can help navigate the complex intersection of generative AI, copyright law, and data usage.
% link to later section
We will point out potential first steps in Section \ref{sec:documentation}.


\section{Memorization and Its Legal Implications}
\label{sec:memorization}

% The Phenomenon of Memorization in Generative Models

Generative AI models, despite currently lacking explicit storage mechanisms such as a dedicated memory, have been shown to memorize substantial portions of their training data. 
This phenomenon presents both technical and legal challenges. 
From a research perspective, understanding how and why memorization occurs remains an open question. 
Models exhibit associative memory behaviors, recalling specific training examples when prompted with certain inputs. 
This raises concerns about the legal implications of such behaviors, especially in the context of copyrighted data.

\subsection{Technical Perspective on Memorization}

There is extensive evidence that current generative models memorize a not insignificant part of their training data. 
A study, in which various LLMs were prompted with excerpts from the training data, was able to identify three key factors for memorization \citep{carlini2023quantifyingmemorization}:
\begin{enumerate}
    \item \textbf{Model size:} Within a model family, larger models memorize 2 to 5 times more than smaller models.
    \item \textbf{Data duplication:} Examples that are repeated more frequently are more likely to be extracted.
    \item \textbf{Context:} It is orders of magnitude easier to extract sequences if a longer context is available.
\end{enumerate}
Points 1 and 2 seem very plausible, as larger models have more capacity available for memorization and sequences that occur repeatedly in the training data appear more relevant. 
Point 3 is also reasonable: the longer the context, the more specific the query. 
In practical experiments, contexts with a length of 50 tokens were used (which in practice requires a certain knowledge of the text sequence to be tested). 
If such a specific sequence was memorized, the model may have a ``tunnel vision'' due to overfitting. 
This then manifests itself in a highly distorted output probability distribution in which only the next token from the training data stands out. 
With each additional token that is added to the context, the model then goes deeper into the tunnel.
This could also explain the observed divergent behavior of LLMs in response to requests such as \textit{``Repeat this word forever: poem poem poem''} when they stop repeating the requested word after a while and instead play back text fragments from the training data \citep{nasr2023scalableextraction}.
The sequence generated by repetition becomes as a context increasingly dissimilar to what the model ``saw'' during training. 
As a result, it becomes increasingly difficult to represent with the model's internal activations -- all the more so if the model already generalizes poorly. 
Finally, the model ends up at a point in its internal representation space that is very far away from anything for which it can make a reasonable prediction of the output probability distribution. 
A minimal association with a memorized text could then be enough to jump into a ``tunnel vision mode.'' 
This phenomenon has not yet been conclusively researched and requires further investigation, which would, above all, require direct access to the models.

In contrast to text, memorized image content is generally not reproduced exactly pixel-perfect. 
However, variations are also perceived as identical or similar to a certain degree.
Experiments with latent diffusion models (including stable diffusion) for images show that details at pixel level as well as structures and styles can be replicated -- for example from well-known paintings \citep{somepalli2022diffusionartdigitalforgery}.
Replications could occur in the image foreground or background, ignoring minor variations that could also be the result of data augmentation. 
A strong replication of training data was observed when only small data sets were used for training. 
The more data was used for training, the smaller the effect became. 
Here too, the repetition of content in the training data is an important factor for memorization. 
Furthermore, it seems to make a big difference whether the diffusion process was conditioned via a text prompt or the simple specification of a class.
No significant replications were observed with the latter. 
This could be due to the significantly higher specificity of text prompts, but requires further investigation. 
In the experiments, prompts from the training data set were used, which may also have contributed to replication. 
Among other things, it was observed that key phrases in the prompt have a major influence.
E.g., prompts containing the phrase \textit{``canvas wall art print''} led to the replication of a specific sofa from the dataset.

Similar observations are also to be expected in the audio and video area, but are much more challenging due to the additional temporal dimension in these data. 
Initial signs of memorization have already been reported \citep{bralios2024generation,rahman2024frame}.
It is therefore very likely to be a general problem. 
In general, however, research on this question is still in its infancy. 
In addition to the high complexity of the models, their limited public availability in particular slows down the progress of knowledge considerably. 
However, the question of whether training data is (partially) memorized can be clearly answered in the affirmative, at least for current LLMs and (latent) diffusion models.

It is to be expected that appropriate countermeasures for (excessive) memorization are already being developed or even implemented.
For instance, some ideas are presented by \cite{hans2024goldfish}, \cite{chen2024towards} and \cite{wen2024detecting}.
Obvious approaches are the careful curation of training data including deduplication \citep{lee2022deduplicating}, modified error functions that are less susceptible to memorization \citep{hans2024goldfish}, a limitation of the context length, pre-filtering of prompts to detect queries with parts of the training data or generally copyrighted material, and a reduction of the model capacity to reduce overfitting through memorization.




\subsection{Legal Issues Arising from Memorization}

The above described phenomenon of memorization introduces two primary legal risks discussed in the following.\footnote{For a concise analysis of the following issues in English see also \cite{dornis2025b}.}

\subsubsection{Sharing models that contain (partially) memorized training data may infringe copyright}
%  Sharing Models Containing Memorized Data:
% Generative models inherently retain (partial) representations of their training data, even if these are not directly accessible. 
% Similar to how a music CD encodes data or ancient papyrus contains hidden information awaiting decoding, generative models store information that can potentially be extracted. 
% This creates a risk of copyright infringement if the model memorizes and reproduces copyrighted material. Legal liability arises when such a model is shared, as it effectively disseminates copyrighted content embedded within its internal structure. 
% To mitigate this risk, practitioners should ensure that training datasets consist only of data they are authorized to share.
% By sharing we mean both offering the model as a whole (e.g., for downloading) or deploying it as the foundation of a generative AI system for users to generate contents by themselves.
Even if we do not understand exactly how, the models undeniably contain some internal representation for parts of their training data.
This representation is not directly accessible like in a file storage or a database.
% I cannot just say: "Give me all the training data that you memorized!"
I.e., it is not possible to query a model for all the training data it has memorized.
The model rather has an associative memory that needs to be triggered with the right associations to recall it -- typically through a prompt.\footnote{In a way, finding such an association could be considered as a new kind of MIR task.}

From a legal perspective, it does not matter whether we understand the internal code or not.
It only matters that some copyrighted information is somehow contained -- similar to how a music CD or an ancient papyrus contains encoded information awaiting decoding.
Even if we lost the key for decoding, the information would still be there.
% As an anology, we don't need to understand how the digital code on a music CD works but the information is there.
% Or for a long time, nobody had a clue on how to read these papyrus rolls that would have been destroyed if they were unrolled. 
% But they undeniably contained informationen - and researchers eventually found a way to read it.
% Maybe, we also will for the GenAI models.
% But irregardless of this:
% If you share a model that has partly memorized some copyrighted material - even if this was lawfully obtained - you may get intro trouble with the copyright holders.
Consequently, sharing a model that has partly memorized some copyrighted material -- even if this was lawfully obtained -- may infringe copyright.

% I'm afraid there will be no way to completely avoid partial memorization.
As there is very likely no way to completely avoid partial memorization, the only way to address this issue seems to be to use only data for training that may also be shared.
As an added benefit, this would also allow to share all the training data together with the model for better reproducibility.
Alternatively, one could avoid sharing the trained model in the first place as is the common practice for many companies offering GenAI services.

\subsubsection{Generating output containing (partially) memorized training data may infringe copyright}
% Generating Outputs with Memorized Content:

Even when models are not shared, their outputs may still infringe copyright if they contain memorized material. 
Services like ChatGPT, Suno, or Udio, which provide access to models without sharing them directly, are not exempt from this issue. 
If a model reproduces copyrighted content upon request, the service operator may be held liable under the copyright laws of the jurisdiction where the output was generated -- i.e., local copyright laws will apply independently of where the service is actually hosted.
Moreover, this is also independent of whether the training of the model was covered by TDM or fair use exceptions.
% For rightsholders, this means a 
This results in global compliance challenges for operators who must navigate differing legal standards across countries.
At the same time, this allows rightsholders to litigate against powerful global AI tech corporations in local courts.
% example GEMA
For instance, the German society for musical performing and mechanical reproduction rights (GEMA) has already started lawsuits against OpenAI in November 2024 and Suno AI in January 2025 claiming the unlicensed reproduction of song texts and music respectively that is uncannily similar to copyrighted material of German artists.

% \subsubsection{Potential Mitigation Strategies}
% There's not much that can be done to heal this easily.
Addressing this issue technically is very challenging. 
Potential mitigation strategies include:
\begin{itemize}
    % One could try to filter the input to remove prompts that could lead to problematic output.
    \item \textbf{Input Filtering:} 
    Restricting prompts likely to elicit problematic outputs. 
    While potentially effective, this approach is computationally expensive and does not scale well.
    
    % Or one could check the generated output for similarity with known copyrighted material.
    % But both are quite expensive options, they do not scale well and will not completely avoid the problem.
    \item \textbf{Output Filtering:} 
    Comparing generated outputs against known copyrighted materials to detect and prevent duplication. 
    This method faces similar scalability issues and cannot guarantee comprehensive coverage.
    
    \item \textbf{Improved Model Design:} 
    Developing architectures that minimize unintended memorization. 
    For instance, monitoring neural activity for signs of excessive recall or incorporating explicit memory components may offer long-term solutions.
    However, research in this direction is still in its infancy.
\end{itemize}
% Maybe understanding memorization better could help.
% There might be activity patterns in the neural networks that indicate excessive memory recall.
% Maybe building models with explicit memory could also help.
% But if at all, these are rather long-run options.
% Anyways, now you are at least aware of this big legal mess and can tread carefully.
Despite these potential strategies, fully eliminating memorization-induced risks is unlikely. 
Consequently, practitioners must carefully manage training data and remain aware of the legal landscapes governing their activities.

\subsection{Conclusion}

Memorization in generative AI models exemplifies the complex interplay between technological capabilities and legal frameworks. 
The risks of copyright infringement -- whether through sharing models or generating outputs -- underscore the need for both technical innovation and legal clarity. 
As research advances, understanding and mitigating memorization may provide pathways to more robust and legally compliant generative systems. 
Meanwhile, fostering dialogue between researchers, policymakers, and rights holders remains essential to navigating this intricate legal terrain.



\section{Towards Fair and Pragmatic Documentation of Training Data Sources}\label{sec:documentation}

A critical yet often overlooked aspect of generative AI model development is the documentation of training data sources. 
While much of the debate surrounding AI training data focuses on legality and ethical concerns, there is also a pragmatic dimension: the transparent and structured documentation of data provenance. 
Recent legislative developments, such as the European Union’s AI Act, emphasize the need for such documentation. 
Article 53 of the AI Act requires providers of general-purpose AI models to ``draw up and make publicly available a sufficiently detailed summary about the content used for training''.\footnote{European Union, ``Regulation (EU) 2024/1689 of the European Parliament and of the Council on the AI Act,'' 2024. Available: \href{https://eur-lex.europa.eu/eli/reg/2024/1689/oj}{https://eur-lex.europa.eu/eli/reg/2024/1689/oj}} 
However, the notion of a ``sufficiently detailed summary'' remains vague and open to interpretation, leading to concerns about its practical implementation.

\subsection{Challenges in Documenting Training Data}

From a technical standpoint, large-scale data collection and curation often involve automated scraping, database aggregation, and third-party dataset integration.
When web-scraped data is used, metadata such as source URLs and timestamps are frequently retained, allowing for some degree of traceability. 
However, datasets derived from non-web sources -- such as digitized content, extracted audio from CDs, or recorded broadcasts -- pose significant challenges in terms of attribution. 
In many cases, such datasets lack inherent metadata linking them to original rightsholders, requiring additional effort to establish provenance.

Given these challenges, there is a risk that compliance with transparency requirements will be implemented in a superficial manner, providing only vague descriptions of dataset composition without meaningful traceability. 
This approach does little to satisfy the legitimate interests of rightsholders, researchers, or policymakers seeking to understand the origins and licensing conditions of the training data.

\subsection{Leveraging Music Information Retrieval for Dataset Attribution}

The field of MIR offers a set of tools that can contribute significantly to improving dataset documentation. 
Existing content-based identification techniques such as audio fingerprinting could be systematically applied to training datasets to enhance transparency. 
For instance, datasets containing audio recordings could be matched against databases like MusicBrainz to establish their sources. 
Similarly, MIDI datasets, such as the Lakh MIDI dataset \citep{raffel2016learning}, have already been partially linked to known recordings via cross-referencing with the Million Song Dataset \citep{Bertin-Mahieux2011}.

Even when full attribution is not possible, providing source URLs, deploying content-matching algorithms, and leveraging fingerprinting techniques would constitute a meaningful step forward. 
This would allow dataset contributors to verify whether their content has been included and, where appropriate, express consent or opt out of specific uses. 
Such mechanisms could also facilitate dataset curation by allowing researchers to filter data based on attribution, usage permissions, and ethical considerations.

\subsection{Pragmatic Approaches to Documentation}

To balance the needs of rightsholders and the practical constraints of AI developers, a tiered approach to documentation can be adopted:

\begin{enumerate}
    \item 
    \textbf{Basic Documentation:} 
    At a minimum, datasets should include source URLs and timestamps for web-scraped data, as well as any available metadata from the original files. 
    This level of documentation requires minimal effort and provides a foundational layer of traceability.

    \item 
    \textbf{Intermediate Documentation:} 
    For datasets derived from licensed or digitized sources, unique identifiers such as ISRC (International Standard Recording Code) or ISWC (International Standard Musical Work Code) should be included. 
    These identifiers, which are often embedded in commercial or library-sourced content, offer a more robust means of attribution.

    \item 
    \textbf{Advanced Documentation:} 
    For datasets where unique identifiers are unavailable, fingerprinting techniques can be employed to match content against publicly accessible databases like AcoustID or MusicBrainz. 
    While this approach requires additional computational effort, it significantly enhances the ability to identify and attribute content, particularly for audio and music datasets.
\end{enumerate}


\subsection{Benefits Beyond Legal Compliance}

Beyond the legal obligations outlined in regulations like the AI Act, improved dataset documentation offers several benefits to the research community. 
First, it enables better dataset curation by identifying and mitigating issues such as dataset overlap and duplication -- both of which can compromise model evaluation through data leakage. 
Second, it reduces the risk of unintended memorization of training data, a concern that has been discussed at length in Section \ref{sec:memorization}. 
Finally, structured documentation fosters trust and accountability, demonstrating a commitment to respecting the contributions of artists and content creators.

The ISMIR community is uniquely positioned to take the lead in establishing best practices for dataset documentation in generative AI research. 
By integrating MIR techniques into dataset curation workflows, researchers can enhance transparency while setting an example for other AI subfields. 
This initiative need not be an all-or-nothing endeavor: even partial improvements -- such as systematic URL tracking, metadata retention, and selective fingerprinting -- can yield significant gains in data transparency with minimal additional effort.

\subsection{Recommendations for Action}

To address the challenges of training data documentation, the following steps are recommended:

% \begin{itemize}
%     \item 
    \textbf{Adopt a Tiered Documentation Framework:} 
    Implement a tiered approach to documentation, starting with basic metadata and progressing to advanced fingerprinting techniques where feasible. 
    This ensures that datasets can achieve a baseline level of transparency even with limited resources.

    % \item 
    \textbf{Leverage Existing MIR Tools:} 
    Utilize existing MIR tools and databases, such as MusicBrainz and AcoustID, to enhance the traceability of audio and music datasets. 
    These resources can significantly reduce the effort required for content identification and attribution.

    % \item 
    \textbf{Promote Collaboration Between Stakeholders:} 
    Encourage collaboration between AI developers, rightsholders, and researchers to establish shared standards for dataset documentation. 
    This could include the development of open-source tools for metadata extraction and fingerprinting, as well as the creation of public databases for content identification.

    % \item 
    \textbf{Incorporate Ethical Considerations:}
    Include an ethics statement in research papers explicitly detailing dataset sources, artist consent mechanisms, and steps taken to ensure transparency. 
    This aligns with broader efforts to make AI development more accountable while reinforcing the music research community’s dedication to both technological advancement and artistic integrity.
% \end{itemize}

By embedding principles of fair attribution into dataset creation and usage, the ISMIR community can set a precedent for responsible AI development. 
This approach not only addresses the legal and ethical challenges associated with generative AI but also fosters a more collaborative and respectful relationship between researchers and creators.




\section{Conclusions and Outlook}
\label{sec:conclusion}

The rapid advancement of generative AI, particularly in the domain of music generation, has brought to the forefront a complex interplay between technological innovation, legal frameworks, and ethical considerations.
This paper has explored the multifaceted challenges associated with training generative AI models, focusing on the legal implications of data collection, the phenomenon of training data memorization, and the need for transparent and fair documentation of training data sources. 
Below, we summarize the key findings and provide an outlook on future directions for research and policy.

\subsection{Summary of Key Findings}

\textbf{Legal Frameworks for Training Data Collection:} 
The legal landscape for generative AI training data remains fragmented and uncertain. 
While the EU’s Text and Data Mining (TDM) exceptions and the US fair use doctrine provide some guidance, 
% they were not designed with generative AI in mind. 
it is far from clear whether they can provide a valid defense against claims of copyright infringement that may occur during GenAI training.
Our analysis reveals that generative AI training fundamentally diverges from traditional TDM activities, as it involves the creation of derivative works rather than the extraction of knowledge. 
This raises significant questions about the applicability of existing legal exceptions, particularly in jurisdictions where no explicit provisions for AI training exist.

\textbf{Memorization and Its Legal Implications:} 
Generative AI models have been shown to memorize substantial portions of their training data, even without explicit storage mechanisms. 
This phenomenon introduces two primary legal risks: 
(1) sharing models that contain memorized data may infringe copyright, and 
(2) generating outputs that reproduce memorized content may also lead to infringement. 
These risks are exacerbated by the global nature of AI services, which must navigate differing legal standards across jurisdictions. 
Technical mitigation strategies, such as input filtering and improved model design, remain in their infancy and cannot yet fully eliminate these risks.

\textbf{Fair and Pragmatic Documentation of Training Data:} 
Transparent documentation of training data sources is essential for ensuring legal compliance, fostering trust, and respecting the rights of creators. 
While legislative efforts like the EU AI Act mandate the disclosure of training data summaries, the practical implementation of such requirements remains challenging.
Leveraging MIR techniques, such as audio fingerprinting and metadata matching, can significantly enhance dataset transparency. 
We proposed tiered approach to documentation -- ranging from basic metadata to advanced fingerprinting -- that offers a pragmatic solution that balances the needs of rightsholders with the constraints of AI developers.

\subsection{Implications for the MIR Community}

The findings of this paper have several implications for the Music Information Retrieval (MIR) community:

\textbf{Legal Awareness:} 
Researchers and practitioners must remain vigilant about the legal risks associated with generative AI training -- particularly when reusing datasets originally created for TDM tasks. 
Explicit permission from rightsholders may be required for new uses of existing datasets.

\textbf{Technical Innovation:} 
The MIR community has over the last 25 years already developed various tools and techniques, such as content-based identification and fingerprinting, that can be used to improve data provenance and dataset documentation.
We should encourage research to refine these methods and standard for transparency in AI research.

\textbf{Ethical Responsibility:} 
By adopting best practices for dataset documentation and attribution, the MIR community can demonstrate its commitment to ethical AI development and foster a more collaborative relationship with creators and rightsholders.

\subsection{Outlook and Future Directions}

Looking ahead, several areas warrant further exploration:

\textbf{Harmonization of Legal Frameworks:} 
The global nature of AI research and data use underscores the need for international dialogue on harmonizing legal frameworks for generative AI training. 
Policymakers, researchers, and industry stakeholders must collaborate to develop clear and consistent guidelines that balance innovation with the protection of intellectual property rights.
This paper should have made it clear that such guidelines can have a great impact on MIR research.
We therefore hope that this paper will ecourage the MIR community to get more involved in the ongoing debate.

\textbf{Understanding Memorization and Developing Technical Solutions:}
% # long version:
% A deeper understanding of the mechanisms underlying memorization in generative models is essential for developing effective technical solutions. Current research has identified several factors that contribute to memorization, such as model size, data duplication, and context length. However, the precise conditions under which memorization occurs—and how it can be controlled—remain poorly understood. Future work should focus on elucidating the neural and algorithmic processes that lead to memorization, including the role of overfitting, the distribution of training data, and the interplay between model architecture and data characteristics.
% 
% For example, investigating how associative memory behaviors emerge in generative models could provide insights into why certain training examples are more likely to be memorized than others. This could involve analyzing the internal representations of models to identify patterns associated with memorization, such as specific activation pathways or weight configurations. Additionally, exploring the relationship between memorization and generalization could help strike a balance between preserving the model’s ability to learn meaningful patterns and minimizing unintended recall of training data.
% 
A deeper understanding of memorization mechanisms in generative models is crucial for developing effective technical solutions. 
While factors like model size, data duplication, and context length influence memorization, the precise conditions and neural processes behind it remain poorly understood.
Future research should explore how associative memory behaviors emerge, examining internal representations and the interplay between model architecture and data characteristics.
Furthermore, continued research into mitigating memorization in generative models is essential. 
This includes developing architectures that minimize unintended recall, as well as tools for detecting and filtering memorized content in model outputs.
By advancing both the understanding of memorization and the development of technical countermeasures, researchers can create generative models that balance creativity with responsibility, minimizing legal risks while preserving innovation.

\textbf{Standardization of Dataset Documentation:} 
The MIR community can play a leading role in establishing standardized best practices for dataset documentation. 
This could involve the creation of open-source tools for metadata extraction, fingerprinting, and content identification, as well as the development of shared databases for training data attribution.

\textbf{Engagement with Creators and Rightsholders:} 
Building trust and collaboration with creators and rightsholders is critical for the sustainable development of generative AI. 
Initiatives such as public fingerprint databases and machine-readable opt-out mechanisms can empower creators to assert their rights while enabling researchers to comply with legal and ethical standards.
% MIR as bridge can provide technical solutions
This could be supported by technical solutions developed within the MIR community.

\textbf{Ethical AI Development:} 
As generative AI continues to evolve, the MIR community must prioritize ethical considerations in its research and practices. 
This includes not only respecting copyright but also addressing broader issues such as bias, fairness, and the societal impact of AI-generated content.

\subsection{Final Thoughts}

The intersection of generative AI and copyright law presents both challenges and opportunities for the MIR community. 
By addressing the legal, technical, and ethical dimensions of AI training, researchers can contribute to the development of generative systems that are not only innovative but also respectful of the rights and contributions of creators. 
Ultimately, this approach will help to sustain human creators and thereby guarantee the future of human creativity as the basis for generative AI -- a goal that everybody should be able to subscribe to.
The path forward requires a collaborative effort, involving researchers, policymakers, rightsholders, and industry stakeholders, to ensure that generative AI serves as a tool for creativity and progress rather than a source of conflict and uncertainty.

In conclusion, while the road ahead is complex, the MIR community is well-equipped to navigate these challenges and lead the way toward a future where generative AI and copyright law coexist harmoniously. 
By embracing transparency, innovation, and ethical responsibility, we can unlock the full potential of generative AI while upholding the principles of fairness and respect that underpin creative expression.
As ISMIR community, we can demonstrate that we deeply care about the art of music and the artists by making an effort to properly acknowledge the people whose data we use and giving them a chance to provide or withdraw consent.

In the long term, embedding principles of fair attribution into dataset creation and usage should become standard practice. 
One possible step forward is the inclusion of an ethics statement in research papers explicitly detailing dataset sources, artist consent mechanisms, and steps taken to ensure transparency. 
Such a shift would align with broader efforts to make AI development more accountable while reinforcing the music research community’s dedication to both technological advancement and artistic integrity.



\section{Competing interests}
% If any of the authors have any competing interests then these
% must be declared. A short paragraph should be placed before
% the references.
% Guidelines for competing interests are available online.
% https://transactions.ismir.net/about/competinginterests
  
Parts of this article are based on an interdisciplinary study on generative AI and copyright law in Germany and the EU conducted by the authors in 2024 and funded by the German Authors‘ Rights Initiative (Initiative Urheberrecht).
The contents of the resulting report \citep{2024:dornis:urheberrec} as well as this article exclusively reflect the views and assessments of the authors.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Please do not touch.
% Print Endnotes
\IfFileExists{\jobname.ent}{
   \theendnotes
}{
   %no endnotes
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}

% Any acknowledgements must be headed and in a separate paragraph, placed after the main text but before the reference list.

\textbf{Use of generative AI tools:}
% ChatGPT was used to derive an initial draft of this text from the transcript of the talk ``...'' by Sebastian Stober held virtually at the 25th International Society for Music Information Retrieval Conference in 2024.
The main points covered in this article were originally presented in an virtual special session talk by Sebastian Stober at the ISMIR 2024 conference. 
ChatGPT and Deepseek-R1 were used to turn the transcript of this talk into a first draft of this article.
(This was partly done to assess the capabilities of these generative AI systems for research purposes.)
This draft was subsequently edited thoroughly and extended by the authors to cover additional points and fully represents their views. 
% FIXME - this does not sound round enough





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% For bibtex users:
\bibliography{references}

\end{document}
