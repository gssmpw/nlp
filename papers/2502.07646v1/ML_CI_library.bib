@article{athey_imbens_2006,
 ISSN = {00129682, 14680262},
 abstract = {This paper develops a generalization of the widely used difference-in-differences method for evaluating the effects of policy changes. We propose a model that allows the control and treatment groups to have different average benefits from the treatment. The assumptions of the proposed model are invariant to the scaling of the outcome. We provide conditions under which the model is nonparametrically identified and propose an estimator that can be applied using either repeated cross section or panel data. Our approach provides an estimate of the entire counterfactual distribution of outcomes that would have been experienced by the treatment group in the absence of the treatment and likewise for the untreated group in the presence of the treatment. Thus, it enables the evaluation of policy interventions according to criteria such as a mean-variance trade-off. We also propose methods for inference, showing that our estimator for the average treatment effect is root-N consistent and asymptotically normal. We consider extensions to allow for covariates, discrete dependent variables, and multiple groups and time periods.},
 author = {Susan Athey and Guido W. Imbens},
 journal = {Econometrica},
 number = {2},
 pages = {431--497},
 publisher = {[Wiley, Econometric Society]},
 title = {Identification and Inference in Nonlinear Difference-in-Differences Models},
 urldate = {2023-01-18},
 volume = {74},
 year = {2006}
}

@article{yokoyama_2025,
      title={Causal-discovery-based root-cause analysis and its application in time-series prediction error diagnosis}, 
      author={Hiroshi Yokoyama and Ryusei Shingaki and Kaneharu Nishino and Shohei Shimizu and Thong Pham},
      year={2025},
journal = {arXiv preprint}}
%url{https://arxiv.org/abs/2411.06990}, 
}

@inproceedings{pham_2024,
  author={Thong Pham and Shohei Shimizu and Hideitsu Hino and Tam Le},
  title={Scalable Counterfactual Distribution Estimation in Multivariate Causal Models},
  year={2024},
  cdate={1704067200000},
  pages={1118-1140},
  url={https://proceedings.mlr.press/v236/pham24a.html},
  booktitle={CLeaR},
  crossref={conf/clear2/2024}
}

@article{takayama_2024a,
      title={Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach}, 
      author={Masayuki Takayama and Tadahisa Okuda and Thong Pham and Tatsuyoshi Ikenoue and Shingo Fukuma and Shohei Shimizu and Akiyoshi Sannai},
      year={2024},
      journal = {arXiv preprint},
doi = {10.48550/arXiv.2402.01454}
}

@article{CAM,
author = {Peter B{\"u}hlmann and Jonas Peters and Jan Ernest},
title = {{CAM: Causal additive models, high-dimensional order search and penalized regression}},
volume = {42},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {2526 -- 2556},
keywords = {graphical modeling, intervention calculus, Nonparametric regression, regularized estimation, Sparsity, structural equation model},
year = {2014},
doi = {10.1214/14-AOS1260},
URL = {https://doi.org/10.1214/14-AOS1260}
}

@article{Schultheiss_2024,
  author  = {Christoph Schultheiss and Peter B{{\"u}}hlmann},
  title   = {Assessing the Overall and Partial Causal Well-Specification of Nonlinear Additive Noise Models},
  journal = {Journal of Machine Learning Research},
  year    = {2024},
  volume  = {25},
  number  = {159},
  pages   = {1--41}
}

@article{james_2025,
      title={Causal models and prediction in cell line perturbation experiments}, 
      author={James P. Long and Yumeng Yang and Shohei Shimizu and Thong Pham and Kim-Anh Do},
      year={2025},
      journal = {BMC Bioinformatics},
      volume = {26},
doi = {10.1186/s12859-024-06027-7}
}

@InProceedings{pmlr-v162-budhathoki22a,
  title = 	 {Causal structure-based root cause analysis of outliers},
  author =       {Budhathoki, Kailash and Minorics, Lenon and Bl\"{o}baum, Patrick and Janzing, Dominik},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {2357--2369},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/budhathoki22a/budhathoki22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/budhathoki22a.html},
  abstract = 	 {Current techniques for explaining outliers cannot tell what caused the outliers. We present a formal method to identify "root causes" of outliers, amongst variables. The method requires a causal graph of the variables along with the functional causal model. It quantifies the contribution of each variable to the target outlier score, which explains to what extent each variable is a "root cause" of the target outlier. We study the empirical performance of the method through simulations and present a real-world case study identifying "root causes" of extreme river flows.}
}


@book{Spirtes2000,
  author = {Spirtes, P. and Glymour, C. and Scheines, R.},
  edition = {2nd},
  publisher = {MIT press},
  timestamp = {2009-09-12T19:19:43.000+0200},
  title = {Causation, Prediction, and Search},
  year = 2000
}

@article{hastie_GAM,
author = {Trevor Hastie and Robert Tibshirani},
title = {{Generalized Additive Models}},
volume = {1},
journal = {Statistical Science},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {297 -- 310},
keywords = {generalized linear models, nonlinearity, Nonparametric regression, partial residuals, smoothing},
year = {1986},
doi = {10.1214/ss/1177013604},
URL = {https://doi.org/10.1214/ss/1177013604}
}


@article{GPDC,
author = {G{\'a}bor J. Sz{\'e}kely and Maria L. Rizzo and Nail K. Bakirov},
title = {{Measuring and testing dependence by correlation of distances}},
volume = {35},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {2769 -- 2794},
keywords = {Distance correlation, distance covariance, multivariate independence},
year = {2007},
doi = {10.1214/009053607000000505},
URL = {https://doi.org/10.1214/009053607000000505}
}

@inproceedings{gretton_hsic,
 author = {Gretton, Arthur and Fukumizu, Kenji and Teo, Choon and Song, Le and Sch\"{o}lkopf, Bernhard and Smola, Alex},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Platt and D. Koller and Y. Singer and S. Roweis},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {A Kernel Statistical Test of Independence},
 url = {https://proceedings.neurips.cc/paper_files/paper/2007/file/d5cfead94f5350c12c322b5b664544c1-Paper.pdf},
 volume = {20},
 year = {2007}
}


@InProceedings{Runge_CMIknn,
  title = 	 {Conditional independence testing based on a nearest-neighbor estimator of conditional mutual information},
  author = 	 {Runge, Jakob},
  booktitle = 	 {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics},
  pages = 	 {938--947},
  year = 	 {2018},
  editor = 	 {Storkey, Amos and Perez-Cruz, Fernando},
  volume = 	 {84},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--11 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v84/runge18a/runge18a.pdf},
  url = 	 {https://proceedings.mlr.press/v84/runge18a.html},
  abstract = 	 {Conditional independence testing is a fundamental problem underlying causal discovery and a particularly challenging task in the presence of nonlinear dependencies. Here a fully non-parametric test for continuous data based on conditional mutual information combined with a local permutation scheme is presented. Numerical experiments covering sample sizes from $50$ to $2,000$ and dimensions up to $10$ demonstrate that the test reliably generates the null distribution. For smooth nonlinear dependencies, the test has higher power than kernel-based tests in lower dimensions and similar or slightly lower power in higher dimensions. For highly non-smooth densities the data-adaptive nearest neighbor approach is particularly well-suited while kernel methods yield much lower power. The experiments also show that kernel methods utilizing an analytical approximation of the null distribution are not well-calibrated for sample sizes below $1,000$. Combining the local permutation scheme with these kernel tests leads to better calibration but lower power.  For smaller sample sizes and lower dimensions, the proposed test is faster than random fourier feature-based kernel tests if (embarrassingly) parallelized, but the runtime increases more sharply with sample size and dimensionality. Thus, more theoretical research to analytically approximate the null distribution and speed up the estimation is desirable.  As illustrated on real data here, the test is ideally suited in combination with causal discovery algorithms.}
}


@InProceedings{maeda21a,
  title = 	 {Causal additive models with unobserved variables},
  author =       {Maeda, Takashi Nicholas and Shimizu, Shohei},
  booktitle = 	 {Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence},
  pages = 	 {97--106},
  year = 	 {2021},
  editor = 	 {de Campos, Cassio and Maathuis, Marloes H.},
  volume = 	 {161},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {27--30 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v161/maeda21a/maeda21a.pdf},
  url = 	 {https://proceedings.mlr.press/v161/maeda21a.html},
  abstract = 	 {Causal discovery from data affected by unobserved variables is an important but difficult problem to solve. The effects that unobserved variables have on the relationships between observed variables are more complex in nonlinear cases than in linear cases. In this study, we focus on causal additive models in the presence of unobserved variables. Causal additive models exhibit structural equations that are additive in the variables and error terms. We take into account the presence of not only unobserved common causes but also unobserved intermediate variables. Our theoretical results show that, when the causal relationships are nonlinear and there are unobserved variables, it is not possible to identify all the causal relationships between observed variables through regression and independence tests. However, our theoretical results also show that it is possible to avoid incorrect inferences. We propose a method to identify all the causal relationships that are theoretically possible to identify without being biased by unobserved variables. The empirical results using artificial data and simulated functional magnetic resonance imaging (fMRI) data show that our method effectively infers causal structures in the presence of unobserved variables.}
}


@article{rubin_74,
 URL = {https://doi.org/10.1037/h0037350},
 abstract = {},
 author = {Donald B. Rubin},
 journal = {Journal of Educational Psychology},
 number = {5},
 pages = {688–701},
 title = {Estimating causal effects of treatments in randomized and nonrandomized studies},
 volume = {66},
 year = {1974}
}
@article{rubin_78,
author = {Donald B. Rubin},
title = {{Bayesian Inference for Causal Effects: The Role of Randomization}},
volume = {6},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {34 -- 58},
keywords = {Bayesian, causality, experimentation, inference, missing data, Randomization},
year = {1978},
doi = {10.1214/aos/1176344064},
URL = {https://doi.org/10.1214/aos/1176344064}
}
@article{Gruber_1994,
 ISSN = {00028282},
 abstract = {I consider the labor-market effects of mandates which raise the costs of employing a demographically identifiable group. The efficiency of these policies will be largely dependent on the extent to which their costs are shifted to group-specific wages. I study several state and federal mandates which stipulated that childbirth be covered comprehensively in health insurance plans, raising the relative cost of insuring women of childbearing age. I find substantial shifting of the costs of these mandates to the wages of the targeted group. Correspondingly, I find little effect on total labor input for that group.},
 author = {Jonathan Gruber},
 journal = {The American Economic Review},
 number = {3},
 pages = {622--641},
 publisher = {American Economic Association},
 title = {The Incidence of Mandated Maternity Benefits},
 urldate = {2023-06-28},
 volume = {84},
 year = {1994}
}

@article{Olden_2022,
    author = {Olden, Andreas and Møen, Jarle},
    title = "{The triple difference estimator}",
    journal = {The Econometrics Journal},
    volume = {25},
    number = {3},
    pages = {531-553},
    year = {2022},
    month = {03},
    abstract = "{Triple difference has become a widely used estimator in empirical work. A close reading of articles in top economics journals reveals that the use of the estimator to a large extent rests on intuition. The identifying assumptions are neither formally derived nor generally agreed on. We give a complete presentation of the triple difference estimator, and show that even though the estimator can be computed as the difference between two difference-in-differences estimators, it does not require two parallel trend assumptions to have a causal interpretation. The reason is that the difference between two biased difference-in-differences estimators will be unbiased as long as the bias is the same in both estimators. This requires only one parallel trend assumption to hold.}",
    issn = {1368-4221},
    eprint = {https://academic.oup.com/ectj/article-pdf/25/3/531/45842047/utac010.pdf},
}

@article{Callaway_2019,
author = {Callaway, Brantly and Li, Tong},
title = {Quantile treatment effects in difference in differences models with panel data},
journal = {Quantitative Economics},
volume = {10},
number = {4},
pages = {1579-1618},
keywords = {Quantile Treatment Effect on the Treated, Difference in Differences, copula, panel data, propensity score reweighting, C14, C20, C23},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.3982/QE935},
abstract = {This paper considers identification and estimation of the Quantile Treatment Effect on the Treated (QTT) under a straightforward distributional extension of the most commonly invoked Mean Difference in Differences Assumption used for identifying the Average Treatment Effect on the Treated (ATT). Identification of the QTT is more complicated than the ATT though because it depends on the unknown dependence (or copula) between the change in untreated potential outcomes and the initial level of untreated potential outcomes for the treated group. To address this issue, we introduce a new Copula Stability Assumption that says that the missing dependence is constant over time. Under this assumption and when panel data is available, the missing dependence can be recovered, and the QTT is identified. We use our method to estimate the effect of increasing the minimum wage on quantiles of local labor markets' unemployment rates and find significant heterogeneity.},
year = {2019}
}
@inproceedings{
martineztaboada2023counterfactual,
title={Counterfactual Density Estimation using Kernel {S}tein Discrepancies},
author={Diego Martinez-Taboada and Edward Kennedy},
booktitle={International Conference on Learning Representations},
year={2024}
}

@InProceedings{pmlr-v202-melnychuk23a,
  title = {Normalizing Flows for Interventional Density Estimation},
  author =  {Melnychuk, Valentyn and Frauen, Dennis and Feuerriegel, Stefan},
  booktitle = {International Conference on Machine Learning},
  pages = {24361--24397},
  year = {2023},
  pdf = 	 {https://proceedings.mlr.press/v202/melnychuk23a/melnychuk23a.pdf}
}


@article{10.1214/19-AOS1835,
	author = {Ted Westling and Marco Carone},
	journal = {The Annals of Statistics},
	keywords = {cube-root asymptotics, dependent censoring, g-formula, isotonic regression},
	number = {2},
	pages = {1001 -- 1024},
	publisher = {Institute of Mathematical Statistics},
	title = {A unified study of nonparametric inference for monotone functions},
	volume = {48},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1214/19-AOS1835}}


@article{kennedy2021semiparametric,
      title={Semiparametric counterfactual density estimation}, 
      author={Edward H. Kennedy and Sivaraman Balakrishnan and Larry Wasserman},
      year={2021},
      eprint={2102.12034},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
journal = {arXiv preprint},
doi = {10.48550/arXiv.2102.12034}
}

@article{kim2021causal,
      title={Causal effects based on distributional distances}, 
      author={Kwangho Kim and Jisu Kim and Edward H. Kennedy},
      year={2021},
      eprint={1806.02935},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
journal = {arXiv preprint},
doi = {10.48550/arXiv.1806.02935}
}

@article{Robins_Rotnitzky_2001,
 author = {James M Robins and Andrea Rotnitzky},
 journal = {Statistica Sinica},
 number = {4},
 pages = {920--936},
 publisher = {The MIT Press},
 title = {Inference for semiparametric models: Some questions and an answer - Comments},
 volume = {11},
 year = {2001}
}

@article{Bonhomme_2011,
 ISSN = {00346535, 15309142},
 abstract = {We compare the effects of selective and nonselective secondary education on children's test scores, using British data from the National Child Development Study. Test scores are modeled as the output of an additive production function. An important input is the child's unobserved initial endowment, which may be correlated with the education system attended. In this model, we generalize the difference-in-differences approach and identify the entire counterfactual distribution of potential outcomes. Our results suggest that the better performance of selective schools relative to nonselective ones is essentially due to differences in pupils' composition.},
 author = {Stéphane Bonhomme and Ulrich Sauder},
 journal = {The Review of Economics and Statistics},
 number = {2},
 pages = {479--494},
 publisher = {The MIT Press},
 title = {RECOVERING DISTRIBUTIONS IN DIFFERENCE-IN-DIFFERENCES MODELS: A COMPARISON OF SELECTIVE AND COMPREHENSIVE SCHOOLING},
 urldate = {2023-06-28},
 volume = {93},
 year = {2011}
}

@article{Roth_2023,
author = {Roth, Jonathan and Sant'Anna, Pedro H. C.},
title = {When Is Parallel Trends Sensitive to Functional Form?},
journal = {Econometrica},
volume = {91},
number = {2},
pages = {737-747},
keywords = {Difference-in-differences, functional form, robustness, testable implications},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.3982/ECTA19402},
abstract = {This paper assesses when the validity of difference-in-differences depends on functional form. We provide a novel characterization: the parallel trends assumption holds under all strictly monotonic transformations of the outcome if and only if a stronger “parallel trends”-type condition holds for the cumulative distribution function of untreated potential outcomes. This condition for parallel trends to be insensitive to functional form is satisfied if and essentially only if the population can be partitioned into a subgroup for which treatment is effectively randomly assigned and a remaining subgroup for which the distribution of untreated potential outcomes is stable over time. These conditions have testable implications, and we introduce falsification tests for the null that parallel trends is insensitive to functional form.},
year = {2023}
}

@article{Abadie_2006,
 ISSN = {00346527, 1467937X},
 abstract = {The difference-in-differences (DID) estimator is one of the most popular tools for applied research in economics to evaluate the effects of public interventions and other treatments of interest on some relevant outcome variables. However, it is well known that the DID estimator is based on strong identifying assumptions. In particular, the conventional DID estimator requires that, in the absence of the treatment, the average outcomes for the treated and control groups would have followed parallel paths over time. This assumption may be implausible if pre-treatment characteristics that are thought to be associated with the dynamics of the outcome variable are unbalanced between the treated and the untreated. That would be the case, for example, if selection for treatment is influenced by individual-transitory shocks on past outcomes (Ashenfelter's dip). This article considers the case in which differences in observed characteristics create non-parallel outcome dynamics between treated and controls. It is shown that, in such a case, a simple two-step strategy can be used to estimate the average effect of the treatment for the treated. In addition, the estimation framework proposed in this article allows the use of covariates to describe how the average effect of the treatment varies with changes in observed characteristics.},
 author = {Alberto Abadie},
 journal = {The Review of Economic Studies},
 number = {1},
 pages = {1--19},
 publisher = {[Oxford University Press, The Review of Economic Studies, Ltd.]},
 title = {Semiparametric Difference-in-Differences Estimators},
 urldate = {2023-06-28},
 volume = {72},
 year = {2005}
}
@InProceedings{KingBa15,
  author    = {Kingma, Diederik and Ba, Jimmy},
  booktitle = {International Conference on Learning Representations},
  title     = {Adam: A Method for Stochastic Optimization},
  year      = {2015}
}

@article{did_review_1,
    author = {Donald, Stephen G and Lang, Kevin},
    title = {Inference with Difference-in-Differences and Other Panel Data},
    journal = {The Review of Economics and Statistics},
    volume = {89},
    number = {2},
    pages = {221-233},
    year = {2007},
    month = {05},
    abstract = "{We examine inference in panel data when the number of groups is small, as is typically the case for difference-in-differences estimation and when some variables are fixed within groups. In this case, standard asymptotics based on the number of groups going to infinity provide a poor approximation to the finite sample distribution. We show that in some cases the t-statistic is distributed as t and propose simple two-step estimators for these cases. We apply our analysis to two well-known papers. We confirm our theoretical analysis with Monte Carlo simulations.}",
    issn = {0034-6535},
    eprint = {https://direct.mit.edu/rest/article-pdf/89/2/221/1614427/rest.89.2.221.pdf},
}


@article{did_review_3,
	abstract = {This paper synthesizes recent advances in the econometrics of difference-in-differences (DiD) and provides concrete recommendations for practitioners. We begin by articulating a simple set of ``canonical'' assumptions under which the econometrics of DiD are well-understood. We then argue that recent advances in DiD methods can be broadly classified as relaxing some components of the canonical DiD setup, with a focus on (i) multiple periods and variation in treatment timing, (ii) potential violations of parallel trends, or (iii) alternative frameworks for inference. Our discussion highlights the different ways that the DiD literature has advanced beyond the canonical model, and helps to clarify when each of the papers will be relevant for empirical work. We conclude by discussing some promising areas for future research.},
	author = {Jonathan Roth and Pedro H.C. Sant'Anna and Alyssa Bilinski and John Poe},
	
	issn = {0304-4076},
	journal = {Journal of Econometrics},
	keywords = {Difference-in-differences, Causal Inference, Staggered Treatment timing, Sensitivity Analysis, Clustering, Parallel trends, Treatment Effect Heterogeneity},
	number = {2},
	pages = {2218-2244},
	title = {What's trending in difference-in-differences? {A} synthesis of the recent econometrics literature},
	volume = {235},
	year = {2023},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0304407623001318},
	bdsk-url-2 = {https://doi.org/10.1016/j.jeconom.2023.03.008}}


@article{snow_1855,
    author = {Snow, John},
    title =  {On the Mode of Communication of Cholera},
   publisher ={London:John Churchill},
    pages = {162.1},
    year = {1855}
}

@article{snow_1854,
    author = {Snow, John},
    title =  {The cholera near {G}olden-square, and at {D}eptford},
journal = {Medical Times and Gazette},
volume = {9},
    pages = {321-322},
    year = {1854}
}

@article{Sofer_2016,
author = {Tamar Sofer and David B. Richardson and Elena Colicino and Joel Schwartz and Eric J. Tchetgen Tchetgen},
title = {On Negative Outcome Control of Unobserved Confounding as a Generalization of Difference-in-Differences},
volume = {31},
journal = {Statistical Science},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {348 -- 361},
keywords = {Air pollution, inflammation, location-scale models, quantile–quantile transformation},
year = {2016}
}


@ARTICLE{blundell_costa_2009,
title = {Alternative Approaches to Evaluation in Empirical Microeconomics},
author = {Blundell, Richard and Costa Dias, Monica},
year = {2009},
journal = {Journal of Human Resources},
volume = {44},
number = {3},
abstract = {This paper reviews some of the most popular policy evaluation methods in empirical microeconomics: social experiments, natural experiments, matching, instrumental variables, discontinuity design, and control functions. It discusses identification of traditionally used average parameters and more complex distributional parameters. The adequacy, assumptions, and data requirements of each approach are discussed, drawing on empirical evidence from the education and employment policy evaluation literature. A workhorse simulation model of education and earnings is used throughout the paper to discuss and illustrate each approach. The full set of STATA data sets and do-files are available free online and can be used to reproduce all estimation results.}
}

@inproceedings{
sauter2023a,
title={A Meta-Reinforcement Learning Algorithm for Causal Discovery},
author={Andreas W.M. Sauter and Erman Acar and Vincent Francois-Lavet},
booktitle={2nd Conference on Causal Learning and Reasoning},
year={2023}
}

@inproceedings{
hwang2023on,
title={On Discovery of Local Independence over Continuous Variables via Neural Contextual Decomposition},
author={Inwoo Hwang and Yunhyeok Kwak and Yeon-Ji Song and Byoung-Tak Zhang and Sanghack Lee},
booktitle={2nd Conference on Causal Learning and Reasoning},
year={2023}
}

@InProceedings{pmlr-v213-wildberger23a,
  title = 	 {On the Interventional {K}ullback-{L}eibler Divergence},
  author =       {Wildberger, Jonas Bernhard and Guo, Siyuan and Bhattacharyya, Arnab and Sch\"olkopf, Bernhard},
  booktitle = 	 {2nd Conference on Causal Learning and Reasoning},
  year = 	 {2023},
  pdf = 	 {https://proceedings.mlr.press/v213/wildberger23a/wildberger23a.pdf},
  abstract = 	 {Modern machine learning approaches excel in static settings where a large amount of i.i.d. training data are available for a given task. In a dynamic environment though, an intelligent agent needs to be able to transfer knowledge and re-use learned components across domains. It has been argued that this may be possible through causal models, aiming to mirror the modularity of the real world in terms of independent causal mechanisms. However, the true causal structure underlying a given set of data is generally not identifiable, so it is desirable to have means to quantify differences between models (e.g., between the ground truth and an estimate), on both the observational and interventional level. In the present work, we introduce the Interventional Kullback-Leibler (IKL) divergence to quantify both structural and distributional differences between models based on a finite set of multi-environment distributions generated by interventions from the ground truth.  Since we generally cannot quantify all differences between causal models for every finite set of interventional distributions, we propose a sufficient condition on the intervention targets to identify subsets of observed variables on which the models provably agree or disagree.}
}


@article{kladny2023deep,
      title={Deep Backtracking Counterfactuals for Causally Compliant Explanations}, 
      author={Klaus-Rudolf Kladny and Julius von Kügelgen and Bernhard Schölkopf and Michael Muehlebach},
      year={2023},
      eprint={2310.07665},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
journal = {arXiv preprint},
doi = {10.48550/arXiv.2310.07665}
}

@inproceedings{Immer_2023,
author = {Immer, Alexander and Schultheiss, Christoph and Vogt, Julia E and Sch\"{o}lkopf, Bernhard and B\"{u}hlmann, Peter and Marx, Alexander},
title = {On the Identifiability and Estimation of Causal Location-Scale Noise Models},
year = {2023},
abstract = {We study the class of location-scale or heteroscedastic noise models (LSNMs), in which the effect Y can be written as a function of the cause X and a noise source N independent of X, which may be scaled by a positive function g over the cause, i.e., Y = f(X) + g(X)N. Despite the generality of the model class, we show the causal direction is identifiable up to some pathological cases. To empirically validate these theoretical findings, we propose two estimators for LSNMs: an estimator based on (non-linear) feature maps, and one based on neural networks. Both model the conditional distribution of Y given X as a Gaussian parameterized by its natural parameters. When the feature maps are correctly specified, we prove that our estimator is jointly concave, and a consistent estimator for the cause-effect identification task. Although the the neural network does not inherit those guarantees, it can fit functions of arbitrary complexity, and reaches state-of-the-art performance across benchmarks.},
booktitle = {International Conference on Machine Learning},
articleno = {583},
numpages = {17},
pages = {14316-14332},
location = {Honolulu, Hawaii, USA}
}

@article{takayama_2024a,
      title={Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach}, 
      author={Masayuki Takayama and Tadahisa Okuda and Thong Pham and Tatsuyoshi Ikenoue and Shingo Fukuma and Shohei Shimizu and Akiyoshi Sannai},
      year={2024},
      journal = {arXiv preprint},
doi = {10.48550/arXiv.2402.01454}
}

@article{scholkopf_causality_review_2022,
author = {Sch\"{o}lkopf, Bernhard},
title = {Causality for Machine Learning},
year = {2022},
isbn = {9781450395861},
address = {New York, NY, USA},
edition = {1},
journal = {Probabilistic and Causal Inference: The Works of Judea Pearl},
pages = {765–804},
numpages = {40}
}

@inproceedings{
ashman2023causal,
title={Causal Reasoning in the Presence of Latent Confounders via Neural {ADMG} Learning},
author={Matthew Ashman and Chao Ma and Agrin Hilmkil and Joel Jennings and Cheng Zhang},
booktitle={International Conference on Learning Representations },
year={2023}
}

@inproceedings{tu2022optimal,
author = {Tu, Ruibo and Kjellstrom, Hedvig and Zhang, Kun and Zhang, Cheng},
title = {Optimal Transport for Causal Discovery},
booktitle = {International Conference on Learning Representations},
year = {2022},
abstract = {Approaches based on Functional Causal Models (FCMs) have been proposed to determine causal direction between two variables, by properly restricting model classes; however, their performance is sensitive to the model assumptions, which makes it difficult for practitioners to use. In this paper, we provide a novel dynamical-system view of FCMs and propose a new framework for identifying causal direction in the bivariate case. We first show the connection between FCMs and optimal transport, and then study optimal transport under the constraints of FCMs. Furthermore, by exploiting the dynamical interpretation of optimal transport under the FCM constraints, we determine the corresponding underlying dynamical process of the static cause-effect pair data under the least action principle. It provides a new dimension for describing static causal discovery tasks, while enjoying more freedom for modeling the quantitative causal influences. In particular, we show that Additive Noise Models (ANMs) correspond to volume-preserving pressureless flows. Consequently, based on their velocity field divergence, we introduce a criterion to determine causal direction. With this criterion, we propose a novel optimal transport-based algorithm for ANMs which is robust to the choice of models and extend it to post-noninear models. Our method demonstrated state-of-the-art results on both synthetic and causal discovery benchmark datasets.}
}

@article{akbari2023learning,
      title={Learning Causal Graphs via Monotone Triangular Transport Maps}, 
      author={Sina Akbari and Luca Ganassali and Negar Kiyavash},
      year={2023},
      eprint={2305.18210},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
journal = {arXiv preprint},
doi = {10.48550/arXiv.2305.18210}
}

@article{did_review_2011,
year = {2011},
volume = {4},
journal = {Foundations and Trends® in Econometrics},
title = {The Estimation of Causal Effects by Difference-in-Difference Methods},
issn = {1551-3076},
number = {3},
pages = {165-224},
author = {Michael Lechner}
}
@article{causal_survey_2021,
author = {Yao, Liuyi and Chu, Zhixuan and Li, Sheng and Li, Yaliang and Gao, Jing and Zhang, Aidong},
title = {A Survey on Causal Inference},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {1556-4681},
url = {https://doi.org/10.1145/3444944},
doi = {10.1145/3444944},
abstract = {Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy, and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well-known causal inference frameworks. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent machine learning enhanced methods are discussed and compared. The plausible applications of these methods are also presented, including the applications in advertising, recommendation, medicine, and so on. Moreover, the commonly used benchmark datasets as well as the open-source codes are also summarized, which facilitate researchers and practitioners to explore, evaluate and apply the causal inference methods.},
journal = {ACM Trans. Knowl. Discov. Data},
month = {may},
articleno = {74},
numpages = {46},
keywords = {Treatment effect estimation; Representation learning}
}
@article{causal_medical_IT,
title = {A review of causal inference for biomedical informatics},
journal = {Journal of Biomedical Informatics},
volume = {44},
number = {6},
pages = {1102-1112},
year = {2011},
issn = {1532-0464},
author = {Samantha Kleinberg and George Hripcsak},
keywords = {Causal inference, Causal explanation, Electronic health records},
abstract = {Causality is an important concept throughout the health sciences and is particularly vital for informatics work such as finding adverse drug events or risk factors for disease using electronic health records. While philosophers and scientists working for centuries on formalizing what makes something a cause have not reached a consensus, new methods for inference show that we can make progress in this area in many practical cases. This article reviews core concepts in understanding and identifying causality and then reviews current computational methods for inference and explanation, focusing on inference from large-scale observational data. While the problem is not fully solved, we show that graphical models and Granger causality provide useful frameworks for inference and that a more recent approach based on temporal logic addresses some of the limitations of these methods.}
}

@article{causal_sociology,
author = {Gangl, Markus},
title = {Causal Inference in Sociological Research},
journal = {Annual Review of Sociology},
volume = {36},
number = {1},
pages = {21-47},
year = {2010},
eprint = { 
    
        https://doi.org/10.1146/annurev.soc.012809.102702
    
    

}
,
    abstract = { Originating in econometrics and statistics, the counterfactual model provides a natural framework for clarifying the requirements for valid causal inference in the social sciences. This article presents the basic potential outcomes model and discusses the main approaches to identification in social science research. It then addresses approaches to the statistical estimation of treatment effects either under unconfoundedness or in the presence of unmeasured heterogeneity. As an update to Winship \& Morgan's (1999) earlier review, the article summarizes the more recent literature that is characterized by a broader range of estimands of interest, a renewed interest in exploiting experimental and quasi-experimental designs, and important progress in the areas of semi- and nonparametric estimation of treatment effects, difference-in-differences estimation, and instrumental variable estimation. The review concludes by highlighting implications of the recent econometric and statistical literature for sociological research practice. }
}

@article{causal_public_health,
author = {Glass, Thomas A. and Goodman, Steven N. and Hern\'{a}n, Miguel A. and Samet, Jonathan M.},
title = {Causal Inference in Public Health},
journal = {Annual Review of Public Health},
volume = {34},
number = {1},
pages = {61-75},
year = {2013},
eprint = { 
    
        https://doi.org/10.1146/annurev-publhealth-031811-124606
    
    

}
,
    abstract = { Causal inference has a central role in public health; the determination that an association is causal indicates the possibility for intervention. We review and comment on the long-used guidelines for interpreting evidence as supporting a causal association and contrast them with the potential outcomes framework that encourages thinking in terms of causes that are interventions. We argue that in public health this framework is more suitable, providing an estimate of an action's consequences rather than the less precise notion of a risk factor's causal effect. A variety of modern statistical methods adopt this approach. When an intervention cannot be specified, causal relations can still exist, but how to intervene to change the outcome will be unclear. In application, the often-complex structure of causal processes needs to be acknowledged and appropriate data collected to study them. These newer approaches need to be brought to bear on the increasingly complex public health challenges of our globalized world. }
}

@article{causal_review_pearl_2009,
author = {Judea Pearl},
title = {Causal inference in statistics: An overview},
volume = {3},
journal = {Statistics Surveys},
publisher = {Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist., and the Statist. Soc. Canada},
pages = {96 -- 146},
keywords = {causal effects, causes of effects, confounding, counterfactuals, graphical methods, mediation, policy evaluation, potential-outcome, structural equation models},
year = {2009}
}

@article{did_review_2,
author = {Wing, Coady and Simon, Kosali and Bello-Gomez, Ricardo A.},
title = {Designing Difference in Difference Studies: Best Practices for Public Health Policy Research},
journal = {Annual Review of Public Health},
volume = {39},
number = {1},
pages = {453-469},
year = {2018},
doi = {10.1146/annurev-publhealth-040617-013507},
    note ={PMID: 29328877},

URL = { 
    
        https://doi.org/10.1146/annurev-publhealth-040617-013507
    
    

},
eprint = { 
    
        https://doi.org/10.1146/annurev-publhealth-040617-013507
    
    

}
,
    abstract = { The difference in difference (DID) design is a quasi-experimental research design that researchers often use to study causal relationships in public health settings where randomized controlled trials (RCTs) are infeasible or unethical. However, causal inference poses many challenges in DID designs. In this article, we review key features of DID designs with an emphasis on public health policy research. Contemporary researchers should take an active approach to the design of DID studies, seeking to construct comparison groups, sensitivity analyses, and robustness checks that help validate the method's assumptions. We explain the key assumptions of the design and discuss analytic tactics, supplementary analysis, and approaches to statistical inference that are often important in applied research. The DID design is not a perfect substitute for randomized experiments, but it often represents a feasible way to learn about casual relationships. We conclude by noting that combining elements from multiple quasi-experimental techniques may be important in the next wave of innovations to the DID approach. }
}

@incollection{BLUNDELL19991559,
title = {Chapter 27 - Labor Supply: A Review of Alternative Approaches},
editor = {Orley C. Ashenfelter and David Card},
series = {Handbook of Labor Economics},
publisher = {Elsevier},
volume = {3},
pages = {1559-1695},
year = {1999},
issn = {1573-4463},
doi = {https://doi.org/10.1016/S1573-4463(99)03008-4},
url = {https://www.sciencedirect.com/science/article/pii/S1573446399030084},
author = {Richard Blundell and Thomas Macurdy},
abstract = {This chapter surveys existing approaches to modeling labor supply and identifies important gaps in the literature that could be addressed in future research. The discussion begins with a look at recent policy reforms and labor market facts that motivate the study of labor supply. The analysis then presents a unifying framework that allows alternative empirical formulations of the labor supply model to be compared and their resulting elasticities to be interpreted. This is followed by critical reviews of alternative approaches to labor-supply modeling. The first review assesses the difference-in-differences approach and its relationship to natural experiments. The second analyzes estimation with non-linear budget constraints and welfare-program participation. The third appraises developments of family labor-supply models including both the standard unitary and collective labor-supply formulations. The fourth briefly explores dynamic extensions of the labor supply model, characterizing how participation decisions, learning-by-doing, human capital accumulation and habit formation affect the analysis of the lifecycle model. At the end of each of the four broad reviews, we summarize a selection of the recent empirical findings. The concluding section asks whether the developments reviewed in this chapter place us in a better position to answer the policy-reform questions and to interpret the trends in participation and hours with which we began this review. © 1999 Elsevier Science B.V. All rights reserved.}}
@INPROCEEDINGS{lee_2019,
  author={Lee, Chen-Yu and Batra, Tanmay and Baig, Mohammad Haris and Ulbricht, Daniel},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Sliced {W}asserstein Discrepancy for Unsupervised Domain Adaptation}, 
  year={2019},
  volume={},
  number={},
  pages={10277-10287},
  keywords={Representation Learning;Deep Learning ; Recognition: Detection;Categorization;Retrieval; Scene Analysis and Understanding}}

@inproceedings{
kolouri2018sliced,
title={Sliced {W}asserstein Auto-Encoders},
author={Soheil Kolouri and Phillip E. Pope and Charles E. Martin and Gustavo K. Rohde},
booktitle={International Conference on Learning Representations},
year={2019}
}


@inproceedings{Navid_2021,
	author = {Naderializadeh, Navid and Comer, Joseph F and Andrews, Reed and Hoffmann, Heiko and Kolouri, Soheil},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {3389--3400},
	title = {Pooling by Sliced-{W}asserstein Embedding},
	volume = {34},
	year = {2021},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2021/file/1bc2029a8851ad344a8d503930dfd7f7-Paper.pdf}}


@phdthesis{bonnotte:tel-00946781,
  TITLE = {{Unidimensional and Evolution Methods for Optimal Transportation}},
  AUTHOR = {Bonnotte, Nicolas},
  URL = {https://theses.hal.science/tel-00946781},
  NUMBER = {2013PA112297},
  SCHOOL = {{Universit{\'e} Paris Sud - Paris XI ; Scuola normale superiore (Pise, Italie)}},
  YEAR = {2013},
  MONTH = Dec,
  KEYWORDS = {Distance de Wasserstein projet{\'e}e ; Flots de gradients ; Transport optimal ; R{\'e}arrangement de Knothe--Rosenblatt ; M{\'e}thodes de continuit{\'e} ; Th{\'e}or{\`e}me de Nash--Moser ; Algorithme IDT},
  TYPE = {Theses},
  PDF = {https://theses.hal.science/tel-00946781/file/VA2_BONNOTTE_NICOLAS_16122013.pdf},
  HAL_ID = {tel-00946781},
  HAL_VERSION = {v1},
}

@INPROCEEDINGS{wu_2019,
  author={Wu, Jiqing and Huang, Zhiwu and Acharya, Dinesh and Li, Wen and Thoma, Janine and Paudel, Danda Pani and Van Gool, Luc},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Sliced {W}asserstein Generative Models}, 
  year={2019},
  volume={},
  number={},
  pages={3708-3717},
  keywords={Measurement;Deep learning;Computer vision;Image resolution;Image synthesis;Computational modeling;Generative adversarial networks;Image and Video Synthesis;Deep Learning;Optimization Methods}}



@INPROCEEDINGS{Kolouri,
  author={Kolouri, Soheil and Zou, Yang and Rohde, Gustavo K.},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Sliced {W}asserstein Kernels for Probability Distributions}, 
  year={2016},
  volume={},
  number={},
  pages={5258-5267},
  keywords={Kernel;Computer vision;Extraterrestrial measurements;Biomedical measurement;Density measurement;Pattern recognition}}

@incollection{ANGRIST19991277,
title = {Chapter 23 - Empirical Strategies in Labor Economics},
editor = {Orley C. Ashenfelter and David Card},
series = {Handbook of Labor Economics},
publisher = {Elsevier},
volume = {3},
pages = {1277-1366},
year = {1999},
issn = {1573-4463},
doi = {https://doi.org/10.1016/S1573-4463(99)03004-7},
url = {https://www.sciencedirect.com/science/article/pii/S1573446399030047},
author = {Joshua D. Angrist and Alan B. Krueger},
abstract = {This chapter provides an overview of the methodological and practical issues that arise when estimating causal relationships that are of interest to labor economists. The subject matter includes identification, data collection, and measurement problems. Four identification strategies are discussed, and five empirical examples – the effects of schooling, unions, immigration, military service, and class size – illustrate the methodological points. In discussing each example, we adopt an experimentalist perspective that emphasizes the distinction between variables that have causal effects, control variables, and outcome variables. The chapter also discusses secondary datasets, primary data collection strategies, and administrative data. The section on measurement issues focuses on recent empirical examples, presents a summary of empirical findings on the reliability of key labor market data, and briefly reviews the role of survey sampling weights and the allocation of missing values in empirical research. © 1999 Elsevier Science B.V. All rights reserved.}
}

@article{Card_Krueger_2020,
 ISSN = {00028282},
 author = {David Card and Alan B. Krueger},
 journal = {The American Economic Review},
 number = {5},
 pages = {1397--1420},
 publisher = {American Economic Association},
 title = {Minimum Wages and Employment: A Case Study of the Fast-Food Industry in {N}ew {J}ersey and {P}ennsylvania: Reply},
 urldate = {2023-06-28},
 volume = {90},
 year = {2000}
}

@article{neyman,
author = {Jerzy Neyman},
title = {{Sur les applications de la theorie des probabilites aux experiences agricoles: Essai des principes.} {Master's Thesis (1923). Excerpts reprinted in English.}},
volume = {5},
journal = {Statistical Science},
pages = {463–472 (D. M. Dabrowska, and T. P. Speed, Translators)},
year = {1923}
}
@inproceedings{saks_yu,
author = {Saks, Michael and Yu, Lan},
title = {Weak Monotonicity Suffices for Truthfulness on Convex Domains},
year = {2005},
isbn = {1595930493},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1064009.1064040},
doi = {10.1145/1064009.1064040},
abstract = {Weak monotonicity is a simple necessary condition for a social choice function to be implementable by a truthful mechanism. Roberts [10] showed that it is sufficient for all social choice functions whose domain is unrestricted. Lavi, Mu'alem and Nisan [6] proved the sufficiency of weak monotonicity for functions over order-based domains and Gui, Muller and Vohra [5] proved sufficiency for order-based domains with range constraints and for domains defined by other special types of linear inequality constraints. Here we show the more general result, conjectured by Lavi, Mu'alem and Nisan [6], that weak monotonicity is sufficient for functions defined on any convex domain.},
booktitle = {Proceedings of the 6th ACM Conference on Electronic Commerce},
pages = {286–293},
numpages = {8},
keywords = {weak monotonicity, strategyproof, mechanism design, truthful, dominant strategy},
location = {Vancouver, BC, Canada},
series = {EC '05}
}
@article{brenier,
author = {Brenier, Yann},
title = {Polar factorization and monotone rearrangement of vector-valued functions},
journal = {Communications on Pure and Applied Mathematics},
volume = {44},
number = {4},
pages = {375-417},
doi = {https://doi.org/10.1002/cpa.3160440402},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.3160440402},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpa.3160440402},
abstract = {Abstract Given a probability space (X, μ) and a bounded domain Ω in ℝd equipped with the Lebesgue measure |·| (normalized so that |Ω| = 1), it is shown (under additional technical assumptions on X and Ω) that for every vector-valued function u ∈ Lp (X, μ; ℝd) there is a unique “polar factorization” u = ∇Ψs, where Ψ is a convex function defined on Ω and s is a measure-preserving mapping from (X, μ) into (Ω, |·|), provided that u is nondegenerate, in the sense that μ(u−1(E)) = 0 for each Lebesgue negligible subset E of ℝd. Through this result, the concepts of polar factorization of real matrices, Helmholtz decomposition of vector fields, and nondecreasing rearrangements of real-valued functions are unified. The Monge-Ampère equation is involved in the polar factorization and the proof relies on the study of an appropriate “Monge-Kantorovich” problem.},
year = {1991}
}

@article{Lu_Rosenbaum,
author = {Bo Lu and Paul R Rosenbaum},
title = {Optimal Pair Matching With Two Control Groups},
journal = {Journal of Computational and Graphical Statistics},
volume = {13},
number = {2},
pages = {422-434},
year  = {2004},
publisher = {Taylor & Francis},
eprint = { 
https://doi.org/10.1198/1061860043470
}
}


@book{rocka,
author = {Ralph Tyrell Rockafella},
title = {Convex analysis
},
year = {1997},
publisher = {Princeton university press
}
}

@techreport{NBERw4509,
 title = "Minimum Wages and Employment: A Case Study of the Fast Food Industry in {N}ew {J}ersey and {P}ennsylvania",
 author = "Card, David and Krueger, Alan B",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "4509",
 year = "1993",
 month = "October",
 doi = {10.3386/w4509},
 URL = "http://www.nber.org/papers/w4509",
 abstract = {On April 1, 1992 New Jersey's minimum wage increased from $4.25 to $5.05 per hour.  To evaluate the impact of the law we surveyed 410 fast food restaurants in New Jersey and Pennsylvania before and after the rise in the minimum.  Comparisons of the changes in wages, employment, and prices at stores in New Jersey relative to stores in Pennsylvania (where the minimum wage remained fixed at \$4.25 per hour) yield simple estimates of the effect of the higher minimum wage. Our empirical findings challenge the prediction that a rise in the minimum reduces employment.  Relative to stores in Pennsylvania, fast food restaurants in New Jersey increased employment by 13 percent.  We also compare employment growth at stores in New Jersey that were initially paying high wages (and were unaffected by the new law) to employment changes at lower-wage stores.  Stores that were unaffected by the minimum wage had the same employment growth as stores in Pennsylvania, while stores that had to increase their wages increased their employment.},
}


@article{torous_2021,
  doi = {10.48550/ArXiv.2108.05858},
  
  
  author = {Torous, William and Gunsilius, Florian and Rigollet, Philippe},
  
  keywords = {Methodology (stat.ME), Econometrics (econ.EM), Statistics Theory (math.ST), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Economics and business, FOS: Economics and business, FOS: Mathematics, FOS: Mathematics},
  
  title = {An Optimal Transport Approach to Causal Inference},
  journal = {arXiv preprint},
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{subspace_detour_2019,
 author = {Muzellec, Boris and Cuturi, Marco},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Subspace Detours: Building Transport Plans that are Optimal on Subspace Projections},
 url = {https://proceedings.neurips.cc/paper/2019/file/f9beb1e831faf6aaec2a5cecaf1af293-Paper.pdf},
 volume = {32},
 year = {2019}
}


@InProceedings{pmlr-v70-carriere17a,
  title = 	 {Sliced {W}asserstein Kernel for Persistence Diagrams},
  author =       {Mathieu Carri{\`e}re and Marco Cuturi and Steve Oudot},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {664--673},
  year = 	 {2017},
  volume = 	 {70},
  pdf = 	 {http://proceedings.mlr.press/v70/carriere17a/carriere17a.pdf},
  abstract = 	 {Persistence diagrams (PDs) play a key role in topological data analysis (TDA), in which they are routinely used to describe succinctly complex topological properties of complicated shapes. PDs enjoy strong stability properties and have proven their utility in various learning contexts. They do not, however, live in a space naturally endowed with a Hilbert structure and are usually compared with specific distances, such as the bottleneck distance. To incorporate PDs in a learning pipeline, several kernels have been proposed for PDs with a strong emphasis on the stability of the RKHS distance w.r.t. perturbations of the PDs. In this article, we use the Sliced Wasserstein approximation of the Wasserstein distance to define a new kernel for PDs, which is not only provably stable but also provably discriminative w.r.t. the Wasserstein distance $W^1_\infty$ between PDs. We also demonstrate its practicality, by developing an approximation technique to reduce kernel computation time, and show that our proposal compares favorably to existing kernels for PDs on several benchmarks.}
}


@InProceedings{pmlr-v97-liutkus19a,
  title = 	 {Sliced-{W}asserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions},
  author =       {Liutkus, Antoine and Simsekli, Umut and Majewski, Szymon and Durmus, Alain and St{\"o}ter, Fabian-Robert},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {4104--4113},
  year = 	 {2019},
  pdf = 	 {http://proceedings.mlr.press/v97/liutkus19a/liutkus19a.pdf},
  abstract = 	 {By building upon the recent theory that established the connection between implicit generative modeling (IGM) and optimal transport, in this study, we propose a novel parameter-free algorithm for learning the underlying distributions of complicated datasets and sampling from them. The proposed algorithm is based on a functional optimization problem, which aims at finding a measure that is close to the data distribution as much as possible and also expressive enough for generative modeling purposes. We formulate the problem as a gradient flow in the space of probability measures. The connections between gradient flows and stochastic differential equations let us develop a computationally efficient algorithm for solving the optimization problem. We provide formal theoretical analysis where we prove finite-time error guarantees for the proposed algorithm. To the best of our knowledge, the proposed algorithm is the first nonparametric IGM algorithm with explicit theoretical guarantees. Our experimental results support our theory and show that our algorithm is able to successfully capture the structure of different types of data distributions.}
}


@InProceedings{pmlr-v139-rakotomamonjy21a,
  title = 	 {Differentially Private Sliced {W}asserstein Distance},
  author =       {Rakotomamonjy, Alain and Liva, Ralaivola},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {8810--8820},
  year = 	 {2021},
  pdf = 	 {http://proceedings.mlr.press/v139/rakotomamonjy21a/rakotomamonjy21a.pdf},
  abstract = 	 {Developing machine learning methods that are privacy preserving is today a central topic of research, with huge practical impacts. Among the numerous ways to address privacy-preserving learning, we here take the perspective of computing the divergences between distributions under the Differential Privacy (DP) framework — being able to compute divergences between distributions is pivotal for many machine learning problems, such as learning generative models or domain adaptation problems. Instead of resorting to the popular gradient-based sanitization method for DP, we tackle the problem at its roots by focusing on the Sliced Wasserstein Distance and seamlessly making it differentially private. Our main contribution is as follows: we analyze the property of adding a Gaussian perturbation to the intrinsic randomized mechanism of the Sliced Wasserstein Distance, and we establish the sensitivity of the resulting differentially private mechanism. One of our important findings is that this DP mechanism transforms the Sliced Wasserstein distance into another distance, that we call the Smoothed Sliced Wasserstein Distance. This new differentially private distribution distance can be plugged into generative models and domain adaptation algorithms in a transparent way, and we empirically show that it yields highly competitive performance compared with gradient-based DP approaches from the literature, with almost no loss in accuracy for the domain adaptation problems that we consider.}
}


@inproceedings{Kolouri_NEURIPS2019,
 author = {Kolouri, Soheil and Nadjahi, Kimia and Simsekli, Umut and Badeau, Roland and Rohde, Gustavo},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Generalized Sliced {W}asserstein Distances},
 volume = {32},
 year = {2019}
}

@InProceedings{Deshpande_2019_CVPR,
author = {Deshpande, Ishan and Hu, Yuan-Ting and Sun, Ruoyu and Pyrros, Ayis and Siddiqui, Nasir and Koyejo, Sanmi and Zhao, Zhizhen and Forsyth, David and Schwing, Alexander G.},
title = {Max-Sliced {W}asserstein Distance and Its Use for {GAN}s},
booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
pages = {10640-10648},
year = {2019}
}


###############################
@incollection{Tillman2009ION,
  title={Integrating locally learned causal structures with overlapping variables},
  author={Tillman, Robert E. and Danks, David and Glymour, Clark},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1665--1672},
  year={2009},
  publisher = {Curran Associates Inc.}
}

@article{shimizu2006,
	author = {Shimizu, Shohei and Hoyer, Patrik O. and Hyv{\"a}rinen, Aapo and Kerminen, Antti},
	date-added = {2019-08-25 19:03:22 +0900},
	date-modified = {2019-09-09 03:38:51 +0900},
	journal = {Journal of Machine Learning Research},
	number = {Oct},
	pages = {2003--2030},
	title = {A linear {non-Gaussian} acyclic model for causal discovery},
	volume = {7},
	year = {2006}}

@article{chickering2002,
	Author = {Chickering, David Maxwell},
	Date-Added = {2019-08-25 19:28:56 +0900},
	Date-Modified = {2019-08-25 19:32:47 +0900},
	Journal = {Journal of Machine Learning Research},
	Number = {Nov},
	Pages = {507--554},
	Title = {Optimal structure identification with greedy search},
	Volume = {3},
	Year = {2002}}

@inproceedings{Triantafillou2010COmbINE,
  title={Learning causal structure from overlapping variable sets},
  author={Sofia Triantafillou and Ioannis Tsamardinos and Ioannis Tollis},
  booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages={860--867},
  year={2010}
}

@inproceedings{Tillman2011IOD,
  title={Learning equivalence classes of acyclic models with latent and selection variables from multiple datasets with overlapping variables},
  author={Tillman, Robert and Spirtes, Peter},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={3--15},
  year={2011}
}
@book{barabasi2016network,
  abstract = {La 4ème de couverture indique : "Networks are everywhere, from the Internet, to social networks, and the genetic networks that determine our biological existence. Illustrated throughout in full colour, this pioneering textbook, spanning a wide range of topics from physics to computer science, engineering, economics and the social sciences, introduces network science to an interdisciplinary audience. From the origins of the six degrees of separation to explaining why networks are robust to random failures, the author explores how viruses like Ebola and H1N1 spread, and why it is that our friends have more friends than we do. Using numerous real-world examples, this innovatively designed text includes clear delineation between undergraduate and graduate level material"},
  added-at = {2016-10-10T20:23:59.000+0200},
  address = {Cambridge},
  author = {Barab{\'{a}}si, Albert-L{\'{a}}szl{\'{o}} and P{\'{o}}sfai, M{\'{a}}rton},
  biburl = {https://www.bibsonomy.org/bibtex/22a71231091413325c03aaed76c32a66b/schmitz},
  description = {Network Science: Albert-László Barabási: 9781107076266: Amazon.com: Books},
  interhash = {2dcba3ae6b58627716c5d2a63f7c0855},
  intrahash = {2a71231091413325c03aaed76c32a66b},
  isbn = {9781107076266 1107076269},
  keywords = {required sna snaseminar},
  publisher = {Cambridge University Press},
  refid = {958874494},
  timestamp = {2016-12-18T12:26:46.000+0100},
  title = {Network science},
  year = 2016
}

@article{ba_model,
author = {Albert-L{\'{a}}szl{\'{o}} Barab{\'{a}}si  and R{\'{e}}ka Albert },
title = {Emergence of Scaling in Random Networks},
journal = {Science},
volume = {286},
number = {5439},
pages = {509-512},
year = {1999},
doi = {10.1126/science.286.5439.509},
URL = {https://www.science.org/doi/abs/10.1126/science.286.5439.509},
eprint = {https://www.science.org/doi/pdf/10.1126/science.286.5439.509},
abstract = {Systems as diverse as genetic networks or the World Wide Web are best described as networks with complex topology. A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. This feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. A model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.}}

@inproceedings{Huang2020CD-MiNi,
  title={Causal discovery from multiple data sets with non-identical variable sets},
  author={Huang, Biwei and Zhang, Kun and Gong, Mingming and Glymour, Clark},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={06},
  pages={10153--10161},
  year={2020}
}

@inproceedings{Maeda21UAI,
  title={Causal additive models with unobserved variables},
  author={Maeda, Takashi Nicholas and Shimizu, Shohei},
  booktitle={Proc. 37th Conference on Uncertainty in Artificial Intelligence (UAI2021)},
  pages={97--106},
  year={2021},
  organization={PMLR}
}

@article{Tillman14BHMK,
  title={Learning causal structure from multiple datasets with similar variable sets},
  author={E. Tillman, Robert and Eberhardt, Frederick},
  journal={Behaviormetrika},
  volume={41},
  number={1},
  pages={41--64},
  year={2014}
}

@article{Mooij20JCI,
  author  = {Joris M. Mooij and Sara Magliacane and Tom Claassen},
  title   = {Joint Causal Inference from Multiple Contexts},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {99},
  pages   = {1--108}
}

@article{Ding2019OICA,
  title={Likelihood-free overcomplete ICA and applications in causal discovery},
  author={Ding, Chenwei and Gong, Mingming and Zhang, Kun and Tao, Dacheng},
  journal={Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  volume={32},
  year={2019}
}

@article{Spirtes91PC,
	Author = {Peter Spirtes and Clark Glymour},
	Journal = {Social Science Computer Review},
	Pages = {67-72},
	Title = {An algorithm for fast recovery of sparse causal graphs},
	Volume = {9},
	Year = {1991}}

@inproceedings{Spirtes95FCI,
	Author = {Peter Spirtes and Christopher Meek and Thomas Richardson},
	Booktitle = {{Proc. 11th Annual Conference on Uncertainty in Artificial Intelligence (UAI1995)}},
	Title = {Causal Inference in the presence of latent variables and selection bias},
	Year = 1995,
	pages = {491-506}
	}

@article{Smith11NeuroImage,
	Author = {Stephen M. Smith and Karla L Miller and Gholamreza Salimi-Khorshidi and Matthew Webster and Christian F. Beckmann and Thomas E. Nichols and Joseph D. Ramsey and Mark W. Woolrich
},
	Journal = {NeuroImage},
	Pages = {875--891},
	Title = {Network modelling methods for {FMRI}},
	Volume = {54},
	number = {2},
	Year = {2011}}

@article{Shimizu11JMLR,
  title={{DirectLiNGAM}: A direct method for learning a linear non-{G}aussian structural equation model},
  author={Shimizu, Shohei and Inazumi, Takanori and Sogawa, Yasuhiro and Hyv{\"a}rinen, Aapo and Kawahara, Yoshinobu and Washio, Takashi and Hoyer, Patrik O and Bollen, Kenneth},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={1225--1248},
  year={2011},
  publisher={JMLR. org}
}
@article{erdos59a,
  added-at = {2010-05-05T00:38:27.000+0200},
  author = {Erd\"{o}s, P. and R\'{e}nyi, A.},
  biburl = {https://www.bibsonomy.org/bibtex/25aab47a7be9ec47644735f8e0a4607b6/alex},
  interhash = {99061fc859ba540d4485abfbce44f298},
  intrahash = {5aab47a7be9ec47644735f8e0a4607b6},
  journal = {Publicationes Mathematicae Debrecen},
  keywords = {graph sna},
  pages = 290,
  timestamp = {2010-05-05T00:38:27.000+0200},
  title = {On Random Graphs I},
  volume = 6,
  year = 1959
}


@article{SMITH2011875,
title = {Network modelling methods for FMRI},
journal = {NeuroImage},
volume = {54},
number = {2},
pages = {875-891},
year = {2011},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2010.08.063},
url = {https://www.sciencedirect.com/science/article/pii/S1053811910011602},
author = {Stephen M. Smith and Karla L. Miller and Gholamreza Salimi-Khorshidi and Matthew Webster and Christian F. Beckmann and Thomas E. Nichols and Joseph D. Ramsey and Mark W. Woolrich},
keywords = {Network modelling, FMRI, Causality},
abstract = {There is great interest in estimating brain “networks” from FMRI data. This is often attempted by identifying a set of functional “nodes” (e.g., spatial ROIs or ICA maps) and then conducting a connectivity analysis between the nodes, based on the FMRI timeseries associated with the nodes. Analysis methods range from very simple measures that consider just two nodes at a time (e.g., correlation between two nodes' timeseries) to sophisticated approaches that consider all nodes simultaneously and estimate one global network model (e.g., Bayes net models). Many different methods are being used in the literature, but almost none has been carefully validated or compared for use on FMRI timeseries data. In this work we generate rich, realistic simulated FMRI data for a wide range of underlying networks, experimental protocols and problematic confounds in the data, in order to compare different connectivity estimation approaches. Our results show that in general correlation-based approaches can be quite successful, methods based on higher-order statistics are less sensitive, and lag-based approaches perform very poorly. More specifically: there are several methods that can give high sensitivity to network connection detection on good quality FMRI data, in particular, partial correlation, regularised inverse covariance estimation and several Bayes net methods; however, accurate estimation of connection directionality is more difficult to achieve, though Patel's τ can be reasonably successful. With respect to the various confounds added to the data, the most striking result was that the use of functionally inaccurate ROIs (when defining the network nodes and extracting their associated timeseries) is extremely damaging to network estimation; hence, results derived from inappropriate ROI definition (such as via structural atlases) should be regarded with great caution.}
}

@article{FRISTON20031273,
title = {Dynamic causal modelling},
journal = {NeuroImage},
volume = {19},
number = {4},
pages = {1273-1302},
year = {2003},
issn = {1053-8119},
doi = {https://doi.org/10.1016/S1053-8119(03)00202-7},
url = {https://www.sciencedirect.com/science/article/pii/S1053811903002027},
author = {K.J. Friston and L. Harrison and W. Penny},
keywords = {Nonlinear system identification, Functional neuroimaging, fMRI, Hemodynamic response function, Effective connectivity, Bilinear model},
abstract = {In this paper we present an approach to the identification of nonlinear input–state–output systems. By using a bilinear approximation to the dynamics of interactions among states, the parameters of the implicit causal model reduce to three sets. These comprise (1) parameters that mediate the influence of extrinsic inputs on the states, (2) parameters that mediate intrinsic coupling among the states, and (3) [bilinear] parameters that allow the inputs to modulate that coupling. Identification proceeds in a Bayesian framework given known, deterministic inputs and the observed responses of the system. We developed this approach for the analysis of effective connectivity using experimentally designed inputs and fMRI responses. In this context, the coupling parameters correspond to effective connectivity and the bilinear parameters reflect the changes in connectivity induced by inputs. The ensuing framework allows one to characterise fMRI experiments, conceptually, as an experimental manipulation of integration among brain regions (by contextual or trial-free inputs, like time or attentional set) that is revealed using evoked responses (to perturbations or trial-bound inputs, like stimuli). As with previous analyses of effective connectivity, the focus is on experimentally induced changes in coupling (cf., psychophysiologic interactions). However, unlike previous approaches in neuroimaging, the causal model ascribes responses to designed deterministic inputs, as opposed to treating inputs as unknown and stochastic.}
}

@article{Peters14JMLR,
  title={Causal Discovery with Continuous Additive Noise Models},
  author={Peters, Jonas and Mooij, Joris M and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  journal={Journal of Machine Learning Research},
  volume={15},
  pages={2009--2053},
  year={2014}
}

@inproceedings{Zhang09UAI,
	author = {K. Zhang and A. Hyv\"arinen},
	title = {On the identifiability of the post-nonlinear causal model},
	booktitle = {{Proc. 25th Conference on Uncertainty in Artificial Intelligence (UAI2009)}},
	year = {2009},
	pages = {647-655},
 	location = {Montreal, Canada},
 }

@article{Sachs05Science,
journal ={Science},
author="Karen Sachs and Omar Perez and Dana Pe'er and Douglas A. Lauffenburger and Garry P. Nolan",
title="Causal Protein-Signaling Networks Derived from Multiparameter Single-Cell Data",
year="2005",
volume  = "308",
number = "5721",
pages = "523-529",
}

@InProceedings{Maeda2020RCD,
  title = 	 {{RCD}: Repetitive causal discovery of linear non-{G}aussian acyclic models with latent confounders},
  author =       {Maeda, Takashi Nicholas and Shimizu, Shohei},
  booktitle = 	 {Proc. 23rd International Conference on Artificial Intelligence and Statistics (AISTATS2020)},
  pages = 	 {735--745},
  year = 	 {2020},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR}
}