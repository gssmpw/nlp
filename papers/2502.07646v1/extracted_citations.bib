@InProceedings{Bhattacharya21ABC,
  title = 	 { Differentiable Causal Discovery Under Unmeasured Confounding },
  author =       {Bhattacharya, Rohit and Nagarajan, Tushar and Malinsky, Daniel and Shpitser, Ilya},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2314--2322},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/bhattacharya21a/bhattacharya21a.pdf},
  url = 	 {https://proceedings.mlr.press/v130/bhattacharya21a.html},
  abstract = 	 { The data drawn from biological, economic, and social systems are often confounded due to the presence of unmeasured variables. Prior work in causal discovery has focused on discrete search procedures for selecting acyclic directed mixed graphs (ADMGs), specifically ancestral ADMGs, that encode ordinary conditional independence constraints among the observed variables of the system. However, confounded systems also exhibit more general equality restrictions that cannot be represented via these graphs, placing a limit on the kinds of structures that can be learned using ancestral ADMGs. In this work, we derive differentiable algebraic constraints that fully characterize the space of ancestral ADMGs, as well as more general classes of ADMGs, arid ADMGs and bow-free ADMGs, that capture all equality restrictions on the observed variables. We use these constraints to cast causal discovery as a continuous optimization problem and design differentiable procedures to find the best fitting ADMG when the data comes from a confounded linear system of equations with correlated errors. We demonstrate the efficacy of our method through simulations and application to a protein expression dataset. Code implementing our methods is open-source and publicly available at https://gitlab.com/rbhatta8/dcd and will be incorporated into the Ananke package. }
}

@article{Hoyer08IJAR,
	Author = {Patrik O. Hoyer and Shohei Shimizu and Antti Kerminen and Markus. Palviainen},
	Journal = {International Journal of Approximate Reasoning},
	Pages = {362-378},
	Title = {Estimation of causal effects using linear non-{Gaussian} causal models with hidden variables},
	Volume = {49},
	Number = {2},
	Year = {2008},
}

@incollection{Hoyer09NIPS,
 title = {Nonlinear causal discovery with additive noise models},
 author = {Patrik O. Hoyer and Dominik Janzing and Joris Mooij and Jonas Peters and Bernhard Sch\"{o}lkopf},
 booktitle = {{Advances in Neural Information Processing Systems 21}},
 pages = {689--696},
 year = {2009},
 publisher = {Curran Associates Inc.}
}

@InProceedings{Maeda20AISTATS,
  title =  {{RCD}: Repetitive causal discovery of linear non-{G}aussian acyclic models with latent confounders},
  author =       {Maeda, Takashi Nicholas and Shimizu, Shohei},
  booktitle =  {Proc. 23rd International Conference on Artificial Intelligence and Statistics (AISTATS2010)},
  pages =  {735--745},
  year =  {2020},
  volume =  {108},
  series =  {Proceedings of Machine Learning Research},
  month =  {26--28 Aug},
  publisher =    {PMLR}
}

@InProceedings{Ogarrio16Hybrid,
  title = 	 {A Hybrid Causal Search Algorithm for Latent Variable Models},
  author = 	 {Ogarrio, Juan Miguel and Spirtes, Peter and Ramsey, Joe},
  booktitle = 	 {Proceedings of the Eighth International Conference on Probabilistic Graphical Models},
  pages = 	 {368--379},
  year = 	 {2016},
  editor = 	 {Antonucci, Alessandro and Corani, Giorgio and Campos, Cassio Polpo},
  volume = 	 {52},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lugano, Switzerland},
  month = 	 {06--09 Sep},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v52/ogarrio16.pdf},
  url = 	 {https://proceedings.mlr.press/v52/ogarrio16.html},
  abstract = 	 {Existing score-based causal model search algorithms such as \textitGES (and a speeded up version, \textitFGS) are asymptotically correct, fast, and reliable, but make the unrealistic assumption that the true causal graph does not contain any unmeasured confounders. There are several constraint-based causal search algorithms (e.g \textitRFCI, \emphFCI, or \emphFCI+) that are asymptotically correct without assuming that there are no unmeasured confounders, but often perform poorly on small samples. We describe a combined score and constraint-based algorithm, \emphGFCI, that we prove is asymptotically correct. On synthetic data, \textitGFCI is only slightly slower than \emphRFCI but more accurate than \textitFCI, \textitRFCI and \textitFCI+.}
}

@article{Salehkaleybar2020learning,
  title={Learning Linear Non-{G}aussian Causal Models in the Presence of Latent Variables.},
  author={Salehkaleybar, Saber and Ghassami, AmirEmad and Kiyavash, Negar and Zhang, Kun},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={39--1},
  year={2020}
}

@article{Shimizu06JMLR,
	Author = {Shohei Shimizu and Patrik O. Hoyer and Aapo Hyv{\"a}rinen and Antti Kerminen},
	Journal = {Journal of Machine Learning Research},
	Pages = {2003-2030},
	Title = {A linear non-{Gaussian} acyclic model for causal discovery},
	Volume = {7},
	Year = {2006}}

@article{Tashiro14NECO,
  title={{ParceLiNGAM}: A Causal Ordering Method Robust Against Latent Confounders},
  author={Tashiro, Tatsuya and Shimizu, Shohei and Hyv{\"a}rinen, Aapo and Washio, Takashi},
  journal={Neural Computation},
  volume={26},
  number={1},
  pages={57--83},
  year={2014},
  publisher={MIT Press}
}

@inproceedings{Zhang10UAI-GP,
	author = {Zhang, K. and Sch{\"o}lkopf, B. and Janzing, D.},
	title = {Invariant {Gaussian} process latent variable models and application in causal discovery},
	booktitle = {{Proc. 26th Conference on Uncertainty in Artificial Intelligence (UAI2010)}},
	year = {2010},
	pages = {717-724},
 }

@inproceedings{Zheng18Neurips,
 author = {Zheng, Xun and Aragam, Bryon and Ravikumar, Pradeep K and Xing, Eric P},
 booktitle = {Advances in Neural Information Processing Systems},
pages = {},
 publisher = {Curran Associates, Inc.},
 title = {{DAG}s with {NO TEARS}: Continuous Optimization for Structure Learning},
 volume = {31},
 year = {2018}
}

