{\renewcommand{\arraystretch}{1.3}
\setlength{\tabcolsep}{4pt}
\hyphenpenalty=10000\exhyphenpenalty=10000
\begin{tabularx}{0.98\textwidth}{@{}p{1.6cm}>{\raggedright}p{2.5cm}>{\raggedright}p{1.5cm}p{1.5cm}X@{}}
\toprule
\textbf{Submission} & \textbf{Authors} & \textbf{Institutions} & \textbf{Framework} & \textbf{Description} \\ \midrule
\makecell{\textsc{Schedule}\\ \textsc{Free}\\ \textsc{AdamW}} & Alice Yang, Aaron Defazio, Konstantin Mishchenko & Meta AI, Samsung AI & \pytorch & A self-tuning version of \sfadam \citep{defazio2024road} using a single \hp configuration.\\
\rowcolor{TUgray_light}\baseline & &  & \jax & Baseline using \nadamw, a linear learning rate warmup followed by a cosine decay, and a single hyperparameter point \citep{Dahl2023AlgoPerf}. \\
\makecell{\textsc{NadamW}\\ \textsc{Sequential}} & George Dahl, Sourabh Medapati, Zack Nado, Rohan Anil, Shankar Krishnan, Naman Agarwal, Priya Kasimbeg, Vlad Feinberg & Google & \jax & Uses \nadamw update rule and runs 3 fixed \hp points sequentially. The intention was for these to be the top 3 \hp points found at one third the self-tuning ruleset step budgets. \\
\textsc{Sinv6 75} & Abhinav Moudgil & Mila, Concordia University & \jax & A submission for a task-invariant learned optimizer meta-trained on small tasks. Uses $75\%$ of the number of steps as target in learned optimizer initialization.\\
\textsc{Sinv6} & Abhinav Moudgil & Mila, Concordia University & \jax & A submission for a task-invariant learned optimizer meta-trained on small tasks. \\
\textsc{AdamG} & Yijiang Pang & Michigan State University & \pytorch & A submission based on the \textsc{AdamG} optimizer \citep{Pang2024}. \\
\bottomrule
\end{tabularx}
}
