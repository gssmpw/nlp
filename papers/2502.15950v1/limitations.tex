\section{Limitations}

While this study provides insights into using mixtures of data experts (MDE) to better predict validation loss and optimize mixtures, several limitations should be acknowledged.

First, we conducted experiments solely on the SlimPajama dataset, which consists of seven training domains with predominantly English text. We have not evaluated our method on datasets with a larger number of domains or multiple languages. Additionally, our experiments were limited to text datasets, and we did not explore multi-modal data. Furthermore, we assume that training domains are predefined and meaningful, without addressing how to construct such domains from raw data.

Second, we only experimented with models up to the size of 1B parameters and have not evaluated our method on larger models or models trained for more than 100B tokens. Assessing its effectiveness on larger models/datasets remains an important area for future research. When the token horizon allows for sources to be repeated many times, diminishing returns from data repetition need to be taken into account as well.

Third, although we evaluated mixture performance using 10 downstream generation and ranking tasks, expanding the evaluation to a broader and more diverse set of tasks would provide a more comprehensive picture. Additionally, we did not investigate safety and inclusion-related criteria, which are important considerations for deploying such methods in real-world scenarios.

Despite these limitations, our findings contribute to the existing literature by demonstrating that MDE features can significantly improve performance and design sample-efficient regression models that outperform previous approaches, offering a strong foundation for further research in this field.

