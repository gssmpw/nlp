[
  {
    "index": 0,
    "papers": [
      {
        "key": "albalak2024surveydataselectionlanguage",
        "author": "Alon Albalak and Yanai Elazar and Sang Michael Xie and Shayne Longpre and Nathan Lambert and Xinyi Wang and Niklas Muennighoff and Bairu Hou and Liangming Pan and Haewon Jeong and Colin Raffel and Shiyu Chang and Tatsunori Hashimoto and William Yang Wang",
        "title": "A Survey on Data Selection for Language Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "albalak2023efficientonlinedatamixing",
        "author": "Alon Albalak and Liangming Pan and Colin Raffel and William Yang Wang",
        "title": "Efficient Online Data Mixing For Language Model Pre-Training"
      },
      {
        "key": "anelia_mix",
        "author": "AJ Piergiovanni and Weicheng Kuo and Wei Li and Anelia Angelova",
        "title": "Dynamic Pre-training of Vision-Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "DOGE",
        "author": "Fan, Simin and Pagliardini, Matteo and Jaggi, Martin",
        "title": "{DOGE}: Domain Reweighting with Generalization Estimation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "doremi",
        "author": "Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy S and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei",
        "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "regmix",
        "author": "Qian Liu and Xiaosen Zheng and Niklas Muennighoff and Guangtao Zeng and Longxu Dou and Tianyu Pang and Jing Jiang and Min Lin",
        "title": "RegMix: Data Mixture as Regression for Language Model Pre-training"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bimix",
        "author": "Ce Ge and Zhijian Ma and Daoyuan Chen and Yaliang Li and Bolin Ding",
        "title": "BiMix: Bivariate Data Mixing Law for Language Model Pretraining"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "dml",
        "author": "Jiasheng Ye and Peiju Liu and Tianxiang Sun and Yunhua Zhou and Jun Zhan and Xipeng Qiu",
        "title": "Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "regmix",
        "author": "Qian Liu and Xiaosen Zheng and Niklas Muennighoff and Guangtao Zeng and Longxu Dou and Tianyu Pang and Jing Jiang and Min Lin",
        "title": "RegMix: Data Mixture as Regression for Language Model Pre-training"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "doremi",
        "author": "Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy S and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei",
        "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "DOGE",
        "author": "Fan, Simin and Pagliardini, Matteo and Jaggi, Martin",
        "title": "{DOGE}: Domain Reweighting with Generalization Estimation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "regmix",
        "author": "Qian Liu and Xiaosen Zheng and Niklas Muennighoff and Guangtao Zeng and Longxu Dou and Tianyu Pang and Jing Jiang and Min Lin",
        "title": "RegMix: Data Mixture as Regression for Language Model Pre-training"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "bimix",
        "author": "Ce Ge and Zhijian Ma and Daoyuan Chen and Yaliang Li and Bolin Ding",
        "title": "BiMix: Bivariate Data Mixing Law for Language Model Pretraining"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "emnlp-merge",
        "author": "Na, Clara  and\nMagnusson, Ian  and\nJha, Ananya Harsh  and\nSherborne, Tom  and\nStrubell, Emma  and\nDodge, Jesse  and\nDasigi, Pradeep",
        "title": "Scalable Data Ablation Approximations for Language Models through Modular Training and Merging"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "pmlr-v162-wortsman22a",
        "author": "Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and Schmidt, Ludwig",
        "title": "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "NEURIPS2020_0607f4c7",
        "author": "Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan",
        "title": "What is being transferred in transfer learning? "
      }
    ]
  }
]