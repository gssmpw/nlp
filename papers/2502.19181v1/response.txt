\section{Related Works}
Recently, due to the significant advantages of deep networks in the field of image restoration, convolutional neural network (CNN)-based methods have garnered increasing attention and research. Dong et al. proposed a deep neural network for artifact reduction**Dong, "Artifacts Reduction Convolutional Neural Networks, ARCNN"**. ARCNN extracts effective image representations using a deep convolutional neural network and learns a network-based mapping structure for image restoration. Zhang et al. introduced a fast and flexible denoising convolutional neural network**Zhang, "Fast and Flexible Denoising Convolutional Neural Network, FFDNet"**. FFDNet employs a multi-layer convolutional network with batch normalization to extract and fuse features from downsampled input images and noise level maps, accelerating training and enhancing the network's expressive power. Zhang et al. proposed a CNN-based image restoration method**Zhang, "Image Restoration CNN, IRCNN"**. IRCNN analyzes the strengths and weaknesses of model-based and learning-based approaches, combining their advantages to improve network performance in image restoration tasks. Liu et al. developed a novel multi-level wavelet CNN**Liu, "Multi-level Wavelet CNN, MWCNN"**. MWCNN integrates wavelet decomposition with CNNs, designing a multi-level wavelet convolutional network and incorporating it into a U-shaped CNN architecture. Tian et al. proposed an attention-guided CNN**Tian, "Attention-guided CNN, ADNet"**. ADNet uses an attention mechanism to more accurately extract noise information and employs dilated convolution to balance network performance and efficiency. Anwar et al. introduced a feature attention-based method**Anwar, "Real Image Denoising Network, RIDNet"**. RIDNet constructs long and short skip connections to learn global and local feature map residuals, respectively. The residual design in RIDNet effectively prevents gradient explosion or vanishing, ensuring stable training, while the skip connections enable complementary information exchange between low-level representations and high-level semantics. Additionally, Chupraphawan et al. proposed a method leveraging edge images**Chupraphawan, "Deep Convolutional Neural Network with Edge Feature, DCEF"**. DCEF addresses the long convergence time in deep network training by introducing an adaptive learning rate based on triangular techniques, enabling faster convergence. It also incorporates edge image information into the denoising task, improving edge quality in restored images. Fang et al. proposed a multilevel edge features-guided network**Fang, "Multilevel Edge Features Guided Network, MLEFGN"**. MLEFGN integrates edge detection, edge guidance, and image denoising into a single end-to-end network, predicting edge information from noisy images and using it as a prior for low-quality images. This approach enhances the network's accuracy and robustness. Liu et al. introduced a gradient-based method**Liu, "Gradient Network, GradNet"**. GradNet fuses gradient information computed from a prior network with shallow image features, preserving high-frequency textures and edges to improve restoration quality. It also proposes a gradient consistency regularization to enforce gradient similarity between denoised and high-quality images, ensuring that the restored images are closer to the ground truth.

Recently, the rise of graph convolutional networks (GCNs) has expanded the range of methods applicable to image restoration tasks. Valsesia et al. proposed a graph convolutional denoiser network**Valsesia, "Graph Convolutional Denoiser Network, GCDN"**. GCDN dynamically computes graph adjacency relationships based on feature similarity and employs a lightweight edge convolutional network to avoid gradient explosion or vanishing and over-parameterization, ensuring stable and efficient learning. Mou et al. introduced a dynamic attentive graph learning framework**Mou, "Dynamic Attentive Graph Learning, DAGL"**. DAGL transmits and aggregates local structural information through a graph network embedded in a residual network for end-to-end learning. The graph structure in DAGL supplements missing information in low-quality images by leveraging local structural information from the entire feature map, improving network accuracy. However, traditional CNNs often focus on information within the receptive field, neglecting the analysis and integration of global feature map information. While non-local neural network methods fuse global information, they typically involve large computational costs or parameters and lack a unified design framework, requiring manual intervention.