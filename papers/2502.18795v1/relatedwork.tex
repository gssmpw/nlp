\section{Related Work}
\label{literature_review}
\subsection{Language Models \& Cognitive Plausibility}
The advancement of neural networks makes connectionism a widely adopted framework in cognitive language studies \citep[e.g.,][]{wilcox-etal-2023-testing,borenstein-etal-2024-languages,kirov-cotterell-2018-recurrent}. However, linguists remain divided on whether language models can meaningfully inform linguistic theories. On the one hand, language models have advanced psycholinguistics by serving as highly accurate probability estimators, and, in this capacity, have already been used for testing and refining Surprisal Theory \citep{goodkind-bicknell-2018-predictive,oh-schuler-2023-surprisal,oh-schuler-2023-transformer,kuribayashi-etal-2024-psychometric}, Uniform Information Density \citep{meister-etal-2021-revisiting,tsipidi-etal-2024-surprise}, and other cognitive-linguistic theories and psychometrics \citep{pearl2011far,gibson2019efficiency,kuribayashi2025large}. On the other hand, their limitations, including a lack of generalization \citep{yao-koller-2022-structural,kim-linzen-2020-cogs}, the shortcomings of prompt-based approaches \citep{hu-levy-2023-prompting}, and inconsistency with humans \citep{de-dios-flores-etal-2023-dependency,davis-van-schijndel-2020-recurrent} suggest that, beyond their role as sophisticated estimators, they are limited as cognitive models.

The most relevant work to our study in this context is \citet{kallini-etal-2024-mission}, which tests the hypothesis that LLMs cannot distinguish between possible and impossible languages \citep{chomsky2023false, moro2023large}. Their study relies on a 100M-word dataset from the BabyLM Challenge \citep{warstadt-etal-2023-findings}, focusing on systematically modified versions of English to investigate learnability and model performance. Using the language modeling task with English on GPT-2 small architecture and its impossible variants, \citet{kallini-etal-2024-mission} demonstrate that natural English is consistently easier to learn than its impossible counterparts, as reflected in lower perplexity scores on heldout data. They conclude that the above critique of language models as cognitive models is largely invalid. \looseness=-1

\subsection{Multilingual Language Modeling}

Whether languages vary in complexity remains a controversial topic, and linguists have taken different approaches to address this question \citep[e.g.,][]{mcwhorter2001worlds,mcwhorter2011linguistic,newmeyer2021complexity,joseph2012all}. While most generative linguists argue that Universal Grammar requires that all languages be equally complex, others have challenged this notion \citep{gil2008complex}.\footnote{See \citet{newmeyer2021complexity} for a more thorough discussion.}

Initial computational attempts to examine language complexity using language models were limited to RNN-based architectures \citep{cotterell-etal-2018-languages,mielke-etal-2019-kind,Johnson2021InvestigatingTE} and $n$-grams \citep{koplenig2023languages}. These studies suggest that language complexity correlates with morphological richness and the size of speaker populations. More recently, \citet{arnett-bergen-2025-language} investigated why morphologically rich languages are harder to model. By testing monolingual language models trained on carefully curated comparative datasets \citep{chang2024goldfishmonolinguallanguagemodels}, they found that morphological features alone could not predict language learnability when training data size was controlled.

While valuable, previous studies often rely on comparative corpora, introducing inconsistencies across languages. Even with parallel corpora \citep{mielke-etal-2019-kind}, studies are limited by small datasets and outdated models. Our study addresses these gaps using a larger parallel corpus and modern transformer architectures.