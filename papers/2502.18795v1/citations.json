[
  {
    "index": 0,
    "papers": [
      {
        "key": "wilcox-etal-2023-testing",
        "author": "Wilcox, Ethan G.  and\nPimentel, Tiago  and\nMeister, Clara  and\nCotterell, Ryan  and\nLevy, Roger P.",
        "title": "Testing the Predictions of Surprisal Theory in 11 Languages"
      },
      {
        "key": "borenstein-etal-2024-languages",
        "author": "Borenstein, Nadav  and\nSvete, Anej  and\nChan, Robin  and\nValvoda, Josef  and\nNowak, Franz  and\nAugenstein, Isabelle  and\nChodroff, Eleanor  and\nCotterell, Ryan",
        "title": "What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages"
      },
      {
        "key": "kirov-cotterell-2018-recurrent",
        "author": "Kirov, Christo  and\nCotterell, Ryan",
        "title": "Recurrent Neural Networks in Linguistic Theory: Revisiting {Pinker and Prince} (1988) and the Past Tense Debate"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "goodkind-bicknell-2018-predictive",
        "author": "Goodkind, Adam  and\nBicknell, Klinton",
        "title": "Predictive power of word surprisal for reading times is a linear function of language model quality"
      },
      {
        "key": "oh-schuler-2023-surprisal",
        "author": "Oh, Byung-Doh  and\nSchuler, William",
        "title": "Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?"
      },
      {
        "key": "oh-schuler-2023-transformer",
        "author": "Oh, Byung-Doh  and\nSchuler, William",
        "title": "Transformer-Based Language Model Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens"
      },
      {
        "key": "kuribayashi-etal-2024-psychometric",
        "author": "Kuribayashi, Tatsuki  and\nOseki, Yohei  and\nBaldwin, Timothy",
        "title": "Psychometric Predictive Power of Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "meister-etal-2021-revisiting",
        "author": "Meister, Clara  and\nPimentel, Tiago  and\nHaller, Patrick  and\nJ{\\\"a}ger, Lena  and\nCotterell, Ryan  and\nLevy, Roger",
        "title": "Revisiting the {U}niform {I}nformation {D}ensity Hypothesis"
      },
      {
        "key": "tsipidi-etal-2024-surprise",
        "author": "Tsipidi, Eleftheria  and\nNowak, Franz  and\nCotterell, Ryan  and\nWilcox, Ethan  and\nGiulianelli, Mario  and\nWarstadt, Alex",
        "title": "Surprise! {U}niform {I}nformation {D}ensity Isn{'}t the Whole Story: Predicting Surprisal Contours in Long-form Discourse"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "pearl2011far",
        "author": "Pearl, Lisa and Mis, Benjamin",
        "title": "How far can indirect evidence take us? {A}naphoric one revisited"
      },
      {
        "key": "gibson2019efficiency",
        "author": "Gibson, Edward and Futrell, Richard and Piantadosi, Steven P and Dautriche, Isabelle and Mahowald, Kyle and Bergen, Leon and Levy, Roger",
        "title": "How efficiency shapes human language"
      },
      {
        "key": "kuribayashi2025large",
        "author": "Kuribayashi, Tatsuki and Oseki, Yohei and Taieb, Souhaib Ben and Inui, Kentaro and Baldwin, Timothy",
        "title": "Large Language Models Are Human-Like Internally"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yao-koller-2022-structural",
        "author": "Yao, Yuekun  and\nKoller, Alexander",
        "title": "Structural generalization is hard for sequence-to-sequence models"
      },
      {
        "key": "kim-linzen-2020-cogs",
        "author": "Kim, Najoung  and\nLinzen, Tal",
        "title": "{COGS}: A Compositional Generalization Challenge Based on Semantic Interpretation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hu-levy-2023-prompting",
        "author": "Hu, Jennifer  and\nLevy, Roger",
        "title": "Prompting is not a substitute for probability measurements in large language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "de-dios-flores-etal-2023-dependency",
        "author": "de-Dios-Flores, Iria  and\nGarcia Amboage, Juan  and\nGarcia, Marcos",
        "title": "Dependency resolution at the syntax-semantics interface: psycholinguistic and computational insights on control dependencies"
      },
      {
        "key": "davis-van-schijndel-2020-recurrent",
        "author": "Davis, Forrest  and\nvan Schijndel, Marten",
        "title": "Recurrent Neural Network Language Models Always Learn {E}nglish-Like Relative Clause Attachment"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "kallini-etal-2024-mission",
        "author": "Kallini, Julie  and\nPapadimitriou, Isabel  and\nFutrell, Richard  and\nMahowald, Kyle  and\nPotts, Christopher",
        "title": "Mission: Impossible Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "chomsky2023false",
        "author": "Chomsky, Noam and Roberts, Lan and Watumull, Jeffrey",
        "title": "Noam {C}homsky: The False Promise of {ChatGPT}"
      },
      {
        "key": "moro2023large",
        "author": "Moro, Andrea and Greco, Matteo and Cappa, Stefano F",
        "title": "Large languages, impossible languages and human brains"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "warstadt-etal-2023-findings",
        "author": "Warstadt, Alex  and\nMueller, Aaron  and\nChoshen, Leshem  and\nWilcox, Ethan  and\nZhuang, Chengxu  and\nCiro, Juan  and\nMosquera, Rafael  and\nParanjabe, Bhargavi  and\nWilliams, Adina  and\nLinzen, Tal  and\nCotterell, Ryan",
        "title": "Findings of the {B}aby{LM} Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "kallini-etal-2024-mission",
        "author": "Kallini, Julie  and\nPapadimitriou, Isabel  and\nFutrell, Richard  and\nMahowald, Kyle  and\nPotts, Christopher",
        "title": "Mission: Impossible Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "mcwhorter2001worlds",
        "author": "McWhorter, John H",
        "title": "The worlds simplest grammars are creole grammars"
      },
      {
        "key": "mcwhorter2011linguistic",
        "author": "McWhorter, John H",
        "title": "Linguistic simplicity and complexity: Why do languages undress?"
      },
      {
        "key": "newmeyer2021complexity",
        "author": "Newmeyer, Frederick J",
        "title": "Complexity and relative complexity in generative grammar"
      },
      {
        "key": "joseph2012all",
        "author": "Joseph, John E and Newmeyer, Frederick J",
        "title": "`{A}ll Languages Are Equally Complex'."
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "gil2008complex",
        "author": "Gil, David",
        "title": "How complex are isolating languages"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "newmeyer2021complexity",
        "author": "Newmeyer, Frederick J",
        "title": "Complexity and relative complexity in generative grammar"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "cotterell-etal-2018-languages",
        "author": "Cotterell, Ryan  and\nMielke, Sabrina J.  and\nEisner, Jason  and\nRoark, Brian",
        "title": "Are All Languages Equally Hard to Language-Model?"
      },
      {
        "key": "mielke-etal-2019-kind",
        "author": "Mielke, Sabrina J.  and\nCotterell, Ryan  and\nGorman, Kyle  and\nRoark, Brian  and\nEisner, Jason",
        "title": "What Kind of Language Is Hard to Language-Model?"
      },
      {
        "key": "Johnson2021InvestigatingTE",
        "author": "Tamar Johnson and Kexin Gao and Kenny Smith and Hugh Rabagliati and Jennifer Culbertson",
        "title": "Investigating the effects of i-complexity and e-complexity on the learnability of morphological systems"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "koplenig2023languages",
        "author": "Koplenig, Alexander and Wolfer, Sascha",
        "title": "Languages with more speakers tend to be harder to (machine-) learn"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "arnett-bergen-2025-language",
        "author": "Arnett, Catherine  and\nBergen, Benjamin",
        "title": "Why do language models perform worse for morphologically complex languages?"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "chang2024goldfishmonolinguallanguagemodels",
        "author": "Tyler A. Chang and Catherine Arnett and Zhuowen Tu and Benjamin K. Bergen",
        "title": "Goldfish: Monolingual Language Models for 350 Languages"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "mielke-etal-2019-kind",
        "author": "Mielke, Sabrina J.  and\nCotterell, Ryan  and\nGorman, Kyle  and\nRoark, Brian  and\nEisner, Jason",
        "title": "What Kind of Language Is Hard to Language-Model?"
      }
    ]
  }
]