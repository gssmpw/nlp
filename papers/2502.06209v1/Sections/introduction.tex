\section{Introduction}
\label{sec:intro}

Deep neural networks owe much of their success to large-scale annotated datasets~\citep{Imagenet, kirillov2023segment, openai2023gpt4, radford2021learning}.
Scaling datasets is crucial for improving both of their performance~\citep{hestness2017deep, zhai2022scaling} and robustness~\citep{fang2022data}.
However, the resources demanded for manual annotation pose a significant bottleneck, particularly in fields requiring expert input like medical data.
In response to these challenges, cost-efficient methods for dataset collection, such as semi-automatic labeling~\citep{kim2024active,qu2024abdomenatlas,wang2024samrs}, synthetic data generation~\citep{liu2019generative,tran2019bayesian}, and active learning (AL)~\citep{ash2019deep,kirsch2019batchbald,sener2017active,settles2009active,sinha2019variational,wang2015querying} have been studied.

This paper investigates AL for classification, where a training algorithm selects informative samples from the data pool and queries annotators for their class labels within a limited budget.
We focus on improving the design of annotation queries, emphasizing their critical role.
To be specific, we consider image classification of $L$ classes.
In the conventional design of query, an annotator is asked to choose a class
in the list of $L$ classes. Here, the effort needed to review 
the entire class list and identify the correct class increases as the list size $L$ increases; according to an information-theoretic analysis~\citep{hu2020one}, the cost of choosing among $L$ options is $\log_2{L}$.
To address this issue of growing annotation cost, recent studies~\citep{hu2020one,kim2024active} employ a 1-bit query design asking annotators to check if the top-1 model prediction is correct.
While this simplifies and speeds up annotation, it produces weak supervision incompatible with standard classification loss functions, necessitating specialized losses and algorithms like contrastive loss and semi-supervised learning techniques.

We propose \emph{candidate set query} (CSQ), a novel AL query design that remains cost-efficient with increasing classes and integrates seamlessly with existing loss functions.
CSQ presents the annotator with an image and a narrowed set of candidate classes, which is likely to include the ground-truth class.
If the ground-truth class is within these candidates, the annotator selects from this smaller group; otherwise, they select from the remaining classes.
This query approach can reduce labeling costs by reducing the search space required for annotation, which is particularly effective in scenarios with a wide range of classes where the search space for the annotator could be extensive.
\Fig{teaser}(\emph{left}) compares CSQ with the conventional query in AL for classification to show its efficiency. 

In the CSQ framework, the design of the candidate set is crucial for its effectiveness.
Too many candidates unnecessarily increase the labeling costs.
On the other hand, too few candidates are likely to omit the ground-truth class, requiring an additional query to identify the ground-truth class among the remaining classes, which is more expensive than the conventional query.
To enhance the effectiveness of the CSQ framework, we propose to construct candidate sets guided by prediction uncertainty from a trained model using conformal prediction~\citep{shafer2008tutorial, angelopoulos-gentle}.
Conformal prediction aims at constructing a set of predictions including the true class, where each set is properly sized based on the certainty of the model about the input.
This strategy enables flexible adjustment of the candidate set for each sample, expanding it for an uncertain sample to include the true label and shrinking it for more certain one to reduce the labeling cost.
Furthermore, we optimize the level of certainty in conformal prediction to minimize the labeling cost for each round.
Therefore, this candidate set construction adapts to the increasing accuracy of the model over successive AL rounds, refining the candidate set as the model improves.

\begin{figure*}
    \centering
    \includegraphics[width=0.99\textwidth]{figure/main_figure_v6.pdf}
    \caption{
    Conventional query versus CSQ.
    (\emph{left}) While the conventional query presents all possible options to annotators, CSQ leverages the knowledge of the model to offer narrowed options that are likely to include the ground-truth label, thereby reducing the annotation time.
    (\emph{right}) By conducting a user study on 40 participants, we demonstrate that the labeling cost increases logarithmically to the candidate set size, which closely aligns with the information-theoretic cost suggested by~\citet{hu2020one} with a correlation coefficient of 0.97.
    Note that as the labeling cost increases per sample, the overall labeling cost increases significantly when multiplied by the total number of labeled samples.
    Further details of the user study are provided in Sec.~\ref{sec:user-study} and Appendix~\ref{app:user-study}.}
    \label{fig:teaser}
\end{figure*}

Last but not least, we propose a new acquisition function designed to maximize the cost efficiency of CSQ.
Conventional acquisition functions in AL are designed to favor samples with high estimated information gain, assuming uniform annotation costs across all samples.
On the other hand, in CSQ, the labeling cost for each sample varies according to the size of its candidate set.
Thus, we propose an acquisition function that evaluates samples based on the ratio of estimated information gain to labeling cost.
Specifically, we combine the conventional acquisition function score, which indicates the estimated information gain, with the estimated cost derived from the candidate set, favoring samples that maximize information gain per unit cost.
This cost-efficient acquisition function can incorporate with any sample-wise acquisition score, ensuring the selection of both informative and cost-efficient samples.

The proposed method achieved state-of-the-art performance on CIFAR-10~\citep{krizhevsky2009learning}, CIFAR-100~\citep{krizhevsky2009learning}, and ImageNet64x64~\citep{chrabaszcz2017downsampled}.
We verify the effectiveness and robustness of CSQ through extensive experiments with varying datasets, acquisition functions, and budgets.
Notably, CSQ achieves the same performance as the conventional query on ImageNet64x64 at only 42\% of the cost, showing its scalability.
Our ablation studies demonstrate that both our candidate set construction and sampling strategy contribute to the performance.
Furthermore, the necessity of CSQ is demonstrated by a user study involving 40 participants.
In short, the main contribution of this paper is four-fold:

\begin{itemize}[leftmargin=6mm] 
    \item We propose a novel query design for active learning, where the annotator is presented with an image and a narrowed set of candidate classes that are likely to include the ground-truth class.
    This approach, termed CSQ, significantly reduces labeling cost by minimizing the search space the annotator needs to explore.

    \item To maximize the advantage of CSQ, we propose to utilize conformal prediction to dynamically generate small yet reliable candidate sets optimized to reduce labeling costs, adapting to the evolving model throughout successive AL rounds.
    
    \item We propose a new acquisition function that prioritizes a data point expected to have high information gain relative to its labeling cost, enhancing cost efficiency.

    \item The proposed framework achieved state-of-the-art performance on diverse image classification datasets, CIFAR-10, CIFAR-100, and ImageNet64x64, showing its effectiveness and generalizability.
\end{itemize}
