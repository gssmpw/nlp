\section{Related works}
LLM-based agents are being experimented in different applications. Some of them include web navigation \cite{abuelsaad2024agenteautonomouswebnavigation}, travel planning \cite{xie2024travelplannerbenchmarkrealworldplanning}, video understanding \cite{zhang2024omagentmultimodalagentframework}, biomedical discovery  \cite{gao2024empoweringbiomedicaldiscoveryai}, code documentation  \cite{luo2024repoagentllmpoweredopensourceframework}, knowledge graph reasoning \cite{jiang2024kgagentefficientautonomousagent}, knowledge base question answering \cite{zong2024triadframeworkleveragingmultirole}.
Memory is a crucial component of agents. Zhang et al. \cite{zhang2024surveymemorymechanismlarge} provided an extensive survey of memory methods for agents.

% Abuelsaad et. al. \cite{abuelsaad2024agenteautonomouswebnavigation}
% presented a web navigation agent, 
% Xie et. al. \cite{xie2024travelplannerbenchmarkrealworldplanning} proposed  a travel planning agent, Zhang et. al. \cite{zhang2024omagentmultimodalagentframework} proposed video understanding agent, Zhu et. al. \cite{zhu2024knowagentknowledgeaugmentedplanningllmbased} proposed KnowAgent to enhance the planning capabilities of LLMs, Gao et. al. \cite{gao2024empoweringbiomedicaldiscoveryai} proposed a biomedical discovery agent. Memory is a crucial component of agents. Zhang et al. \cite{zhang2024surveymemorymechanismlarge} provided an extensive survey of memory methods for LLM agents.

Wu et al. \cite{wu2024stateflowenhancingllmtasksolving} proposed an LLM-based state machine paradigm for complex task-solving processes. The state transitions are controlled by the LLM or by heuristic rules. Each state can perform a series of actions augmented with external tools. 
In the state machine approach, an LLM prompt needs to be developed for each state to guide the state transitions. Our approach has an advantage in that the single-state LLM prompt can predict the actions across all SOPs. Therefore, our approach offers more flexibility in terms of SOPs and error handling.  

% Since the LLM prompt decides the state transton, it poses a limitation on the number of states With the state machine, the nuAn advantage with 
% The transitions between states are controlled by heuristic rules or decisions made by the LLM, allowing for a dynamic and adaptive progression. Upon entering a state, a series of actions is executed, involving not only calling LLMs guided by different prompts, but also the utilization of external tools as needed.

% it has many advantages. In the state flow paper, the LLM decides the next state and state decision is part of the LLM itself. This disadvatge that the number of states that can be connected to state or that can be traisiontoed from the state is limimted becuase state is part of the prompt. n contract, in out ppaper we have a sepeprte mechinasim to decide the state, then finding coreedponding action and executing it. that way a transion can b done from any state to any state without changing the prompt. the state in way depnds on the current step in sop workflow.

% they highlighted the importance of distillation and de-noising of environmental observations, the advantages of a hierarchical architecture, and the role of agentic self-improvement to enhance agent efficiency and efficacy as the agent gathers experience.



% They employ an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents.
% Abuelsaad et. al. \cite{abuelsaad2024agenteautonomouswebnavigation}
% presented a web agent  where they introduced different  architectural improvements such as hierarchical architecture, flexible DOM distillation and denoising method, and the concept of \textit{change observation} to guide the agent towards more accurate performance.
% They highlighted the importance of distillation and de-noising of environmental observations, the advantages of a hierarchical architecture, and the role of agentic self-improvement to enhance agent efficiency and efficacy as the agent gathers experience.

% Xie et. al. \cite{xie2024travelplannerbenchmarkrealworldplanning} proposed we propose TravelPlanner, a new planning benchmark that focuses on travel planning, a common real-world planning scenario.
% They created a sandbox environment, various tools for accessing large travel data records. Their comprehensive evaluations showed that the current language agents are not yet capable of handling such complex planning tasks-even GPT-4 only achieves a success rate of 0.6\%.