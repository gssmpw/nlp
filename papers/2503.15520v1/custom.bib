% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz



@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@misc{zhang2020bertscore,
      title={BERTScore: Evaluating Text Generation with BERT}, 
      author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
      year={2020},
      eprint={1904.09675},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{ramesh2021samanantar,
      title={Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages}, 
      author={Gowtham Ramesh and Sumanth Doddapaneni and Aravinth Bheemaraj and Mayank Jobanputra and Raghavan AK and Ajitesh Sharma and Sujit Sahoo and Harshita Diddee and Mahalakshmi J and Divyanshu Kakwani and Navneet Kumar and Aswin Pradeep and Kumar Deepak and Vivek Raghavan and Anoop Kunchukuttan and Pratyush Kumar and Mitesh Shantadevi Khapra},
      year={2021},
      eprint={2104.05596},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{sanscript,
  title={https://github.com/sanskrit/sanskrit/blob/master/sanskrit/transliterate/sanscript.py},
  
}

@misc{jawahar2021exploring,
      title={Exploring Text-to-Text Transformers for English to Hinglish Machine Translation with Synthetic Code-Mixing}, 
      author={Ganesh Jawahar and El Moatez Billah Nagoudi and Muhammad Abdul-Mageed and Laks V. S. Lakshmanan},
      year={2021},
      eprint={2105.08807},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{raffel2020exploring,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2020},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{lewis2019bart,
      title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
      author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
      year={2019},
      eprint={1910.13461},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{post2018clarity,
      title={A Call for Clarity in Reporting BLEU Scores}, 
      author={Matt Post},
      year={2018},
      eprint={1804.08771},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gulcehre2015using,
      title={On Using Monolingual Corpora in Neural Machine Translation}, 
      author={Caglar Gulcehre and Orhan Firat and Kelvin Xu and Kyunghyun Cho and Loic Barrault and Huei-Chi Lin and Fethi Bougares and Holger Schwenk and Yoshua Bengio},
      year={2015},
      eprint={1503.03535},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sennrich2016improving,
      title={Improving Neural Machine Translation Models with Monolingual Data}, 
      author={Rico Sennrich and Barry Haddow and Alexandra Birch},
      year={2016},
      eprint={1511.06709},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{dhar-etal-2018-enabling,
    title = "Enabling Code-Mixed Translation: Parallel Corpus Creation and {MT} Augmentation Approach",
    author = "Dhar, Mrinal  and
      Kumar, Vaibhav  and
      Shrivastava, Manish",
    booktitle = "Proceedings of the First Workshop on Linguistic Resources for Natural Language Processing",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-3817",
    pages = "131--140",
    
}


@inproceedings{srivastava-singh-2020-phinc,
    title = "{PHINC}: A Parallel {H}inglish Social Media Code-Mixed Corpus for Machine Translation",
    author = "Srivastava, Vivek  and
      Singh, Mayank",
    booktitle = "Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.wnut-1.7",
    doi = "10.18653/v1/2020.wnut-1.7",
    pages = "41--49",
    
}


@misc{kim2016sequencelevel,
      title={Sequence-Level Knowledge Distillation}, 
      author={Yoon Kim and Alexander M. Rush},
      year={2016},
      eprint={1606.07947},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{englesson2021generalized,
      title={Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels}, 
      author={Erik Englesson and Hossein Azizpour},
      year={2021},
      eprint={2105.04522},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{cheng2016semisupervised,
      title={Semi-Supervised Learning for Neural Machine Translation}, 
      author={Yong Cheng and Wei Xu and Zhongjun He and Wei He and Hua Wu and Maosong Sun and Yang Liu},
      year={2016},
      eprint={1606.04596},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{kim2016sequencelevel,
      title={Sequence-Level Knowledge Distillation}, 
      author={Yoon Kim and Alexander M. Rush},
      year={2016},
      eprint={1606.07947},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{englesson2021generalized,
      title={Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels}, 
      author={Erik Englesson and Hossein Azizpour},
      year={2021},
      eprint={2105.04522},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{cheng2016semisupervised,
      title={Semi-Supervised Learning for Neural Machine Translation}, 
      author={Yong Cheng and Wei Xu and Zhongjun He and Wei He and Hua Wu and Maosong Sun and Yang Liu},
      year={2016},
      eprint={1606.04596},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lample2018unsupervised,
      title={Unsupervised Machine Translation Using Monolingual Corpora Only}, 
      author={Guillaume Lample and Alexis Conneau and Ludovic Denoyer and Marc'Aurelio Ranzato},
      year={2018},
      eprint={1711.00043},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tang2020multilingual,
      title={Multilingual Translation with Extensible Multilingual Pretraining and Finetuning}, 
      author={Yuqing Tang and Chau Tran and Xian Li and Peng-Jen Chen and Naman Goyal and Vishrav Chaudhary and Jiatao Gu and Angela Fan},
      year={2020},
      eprint={2008.00401},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2020multilingual,
      title={Multilingual Denoising Pre-training for Neural Machine Translation}, 
      author={Yinhan Liu and Jiatao Gu and Naman Goyal and Xian Li and Sergey Edunov and Marjan Ghazvininejad and Mike Lewis and Luke Zettlemoyer},
      year={2020},
      eprint={2001.08210},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{stickland2021multilingual,
      title={Multilingual Domain Adaptation for NMT: Decoupling Language and Domain Information with Adapters}, 
      author={Asa Cooper Stickland and Alexandre Bérard and Vassilina Nikoulina},
      year={2021},
      eprint={2110.09574},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chu2018survey,
      title={A Survey of Domain Adaptation for Neural Machine Translation}, 
      author={Chenhui Chu and Rui Wang},
      year={2018},
      eprint={1806.00258},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{saunders2021domain,
      title={Domain Adaptation and Multi-Domain Adaptation for Neural Machine Translation: A Survey}, 
      author={Danielle Saunders},
      year={2021},
      eprint={2104.06951},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{artetxe2018unsupervised,
      title={Unsupervised Neural Machine Translation}, 
      author={Mikel Artetxe and Gorka Labaka and Eneko Agirre and Kyunghyun Cho},
      year={2018},
      eprint={1710.11041},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{Yao2020DomainTB,
  title={Domain Transfer based Data Augmentation for Neural Query Translation},
  author={Liang Yao and Baosong Yang and Haibo Zhang and Boxing Chen and Weihua Luo},
  booktitle={COLING},
  year={2020}
}

@article{DBLP:journals/corr/abs-1710-04087,
  author    = {Alexis Conneau and
               Guillaume Lample and
               Marc'Aurelio Ranzato and
               Ludovic Denoyer and
               Herv{\'{e}} J{\'{e}}gou},
  title     = {Word Translation Without Parallel Data},
  journal   = {CoRR},
  volume    = {abs/1710.04087},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.04087},
  eprinttype = {arXiv},
  eprint    = {1710.04087},
  timestamp = {Mon, 13 Aug 2018 16:48:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-04087.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{10.1016/j.neunet.2021.10.008,
author = {Verma, Vikas and Kawaguchi, Kenji and Lamb, Alex and Kannala, Juho and Solin, Arno and Bengio, Yoshua and Lopez-Paz, David},
title = {Interpolation Consistency Training for Semi-Supervised Learning},
year = {2022},
issue_date = {Jan 2022},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {145},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2021.10.008},
doi = {10.1016/j.neunet.2021.10.008},
journal = {Neural Netw.},
month = {jan},
pages = {90–106},
numpages = {17},
keywords = {Mixup, Semi-supervised learning, Deep Neural Networks, Consistency regularization}
}

@misc{https://doi.org/10.48550/arxiv.2106.11528,
  doi = {10.48550/ARXIV.2106.11528},
  
  url = {https://arxiv.org/abs/2106.11528},
  
  author = {Kim, Gyeongho},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Recent Deep Semi-supervised Learning Approaches and Related Works},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2104.08821,
  doi = {10.48550/ARXIV.2104.08821},
  
  url = {https://arxiv.org/abs/2104.08821},
  
  author = {Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {SimCSE: Simple Contrastive Learning of Sentence Embeddings},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ma2019nlpaug,
  title={NLP Augmentation},
  author={Edward Ma},
  howpublished={https://github.com/makcedward/nlpaug},
  year={2019}
}

@inproceedings{Jindal2020LeveragingBW,
  title={Leveraging BERT with Mixup for Sentence Classification (Student Abstract)},
  author={Amit Jindal and Dwaraknath Gnaneshwar and Ramit Sawhney and Rajiv Ratn Shah},
  booktitle={AAAI},
  year={2020}
}

@misc{https://doi.org/10.48550/arxiv.2010.02394,
  doi = {10.48550/ARXIV.2010.02394},
  
  url = {https://arxiv.org/abs/2010.02394},
  
  author = {Sun, Lichao and Xia, Congying and Yin, Wenpeng and Liang, Tingting and Yu, Philip S. and He, Lifang},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Mixup-Transformer: Dynamic Data Augmentation for NLP Tasks},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.2102.11402,
  doi = {10.48550/ARXIV.2102.11402},
  
  url = {https://arxiv.org/abs/2102.11402},
  
  author = {Zhang, Wancong and Vaidya, Ieshan},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {MixUp Training Leads to Reduced Overfitting and Improved Calibration for the Transformer Architecture},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2209.11055,
  doi = {10.48550/ARXIV.2209.11055},
  
  url = {https://arxiv.org/abs/2209.11055},
  
  author = {Tunstall, Lewis and Reimers, Nils and Jo, Unso Eun Seo and Bates, Luke and Korat, Daniel and Wasserblat, Moshe and Pereg, Oren},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Efficient Few-Shot Learning Without Prompts},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2103.00550,
  doi = {10.48550/ARXIV.2103.00550},
  
  url = {https://arxiv.org/abs/2103.00550},
  
  author = {Yang, Xiangli and Song, Zixing and King, Irwin and Xu, Zenglin},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Survey on Deep Semi-supervised Learning},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2208.03713,
  doi = {10.48550/ARXIV.2208.03713},
  
  url = {https://arxiv.org/abs/2208.03713},
  
  author = {Kulkarni, Mandar and Chennabasavaraj, Soumya and Garera, Nikesh},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Study of Encoder-Decoder Architectures for Code-Mix Search Query Translation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@Misc{peft,
  title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author =       {Sourab Mangrulkar and Sylvain Gugger and Lysandre Debut and Younes Belkada and Sayak Paul and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year =         {2022}
}

@misc{oord2019representation,
      title={Representation Learning with Contrastive Predictive Coding}, 
      author={Aaron van den Oord and Yazhe Li and Oriol Vinyals},
      year={2019},
      eprint={1807.03748},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{goyal2021selfsupervised,
      title={Self-supervised Pretraining of Visual Features in the Wild}, 
      author={Priya Goyal and Mathilde Caron and Benjamin Lefaudeux and Min Xu and Pengchao Wang and Vivek Pai and Mannat Singh and Vitaliy Liptchinsky and Ishan Misra and Armand Joulin and Piotr Bojanowski},
      year={2021},
      eprint={2103.01988},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wang2022text,
      title={Text Embeddings by Weakly-Supervised Contrastive Pre-training}, 
      author={Liang Wang and Nan Yang and Xiaolong Huang and Binxing Jiao and Linjun Yang and Daxin Jiang and Rangan Majumder and Furu Wei},
      year={2022},
      eprint={2212.03533},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2023textbooks,
      title={Textbooks Are All You Need II: phi-1.5 technical report}, 
      author={Yuanzhi Li and Sébastien Bubeck and Ronen Eldan and Allie Del Giorno and Suriya Gunasekar and Yin Tat Lee},
      year={2023},
      eprint={2309.05463},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{kulkarni2024reinforcement,
      title={Reinforcement Learning for Optimizing RAG for Domain Chatbots}, 
      author={Mandar Kulkarni and Praveen Tangarajan and Kyung Kim and Anusua Trivedi},
      year={2024},
      eprint={2401.06800},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@inproceedings{hossain2020simple,
  title={Simple and effective retrieve-edit-rerank text generation},
  author={Hossain, Nabil and Ghazvininejad, Marjan and Zettlemoyer, Luke},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={2532--2538},
  year={2020}
}

@inproceedings{cao-etal-2018-retrieve,
    title = "Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization",
    author = "Cao, Ziqiang  and
      Li, Wenjie  and
      Li, Sujian  and
      Wei, Furu",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1015",
    doi = "10.18653/v1/P18-1015",
    pages = "152--161",
    abstract = "Most previous seq2seq summarization systems purely depend on the source text to generate summaries, which tends to work unstably. Inspired by the traditional template-based summarization approaches, this paper proposes to use existing summaries as soft templates to guide the seq2seq model. To this end, we use a popular IR platform to Retrieve proper summaries as candidate templates. Then, we extend the seq2seq framework to jointly conduct template Reranking and template-aware summary generation (Rewriting). Experiments show that, in terms of informativeness, our model significantly outperforms the state-of-the-art methods, and even soft templates themselves demonstrate high competitiveness. In addition, the import of high-quality external summaries improves the stability and readability of generated summaries.",
}

@misc{ghazvininejad2018knowledgegrounded,
      title={A Knowledge-Grounded Neural Conversation Model}, 
      author={Marjan Ghazvininejad and Chris Brockett and Ming-Wei Chang and Bill Dolan and Jianfeng Gao and Wen-tau Yih and Michel Galley},
      year={2018},
      eprint={1702.01932},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{Lowe2015IncorporatingUT,
  title={Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems},
  author={Ryan Lowe and Nissan Pow and Laurent Charlin and Joelle Pineau},
  year={2015},
  url={https://api.semanticscholar.org/CorpusID:13812031}
}

@misc{zhu2017flexible,
      title={Flexible End-to-End Dialogue System for Knowledge Grounded Conversation}, 
      author={Wenya Zhu and Kaixiang Mo and Yu Zhang and Zhangbin Zhu and Xuezheng Peng and Qiang Yang},
      year={2017},
      eprint={1709.04264},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{xue2022recent,
      title={Recent Progress in Conversational AI}, 
      author={Zijun Xue and Ruirui Li and Mingda Li},
      year={2022},
      eprint={2204.09719},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{yuan-etal-2019-multi,
    title = "Multi-hop Selector Network for Multi-turn Response Selection in Retrieval-based Chatbots",
    author = "Yuan, Chunyuan  and
      Zhou, Wei  and
      Li, Mingming  and
      Lv, Shangwen  and
      Zhu, Fuqing  and
      Han, Jizhong  and
      Hu, Songlin",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1011",
    doi = "10.18653/v1/D19-1011",
    pages = "111--120",
    abstract = "Multi-turn retrieval-based conversation is an important task for building intelligent dialogue systems. Existing works mainly focus on matching candidate responses with every context utterance on multiple levels of granularity, which ignore the side effect of using excessive context information. Context utterances provide abundant information for extracting more matching features, but it also brings noise signals and unnecessary information. In this paper, we will analyze the side effect of using too many context utterances and propose a multi-hop selector network (MSN) to alleviate the problem. Specifically, MSN firstly utilizes a multi-hop selector to select the relevant utterances as context. Then, the model matches the filtered context with the candidate response and obtains a matching score. Experimental results show that MSN outperforms some state-of-the-art methods on three public multi-turn dialogue datasets.",
}

@misc{adiwardana2020humanlike,
      title={Towards a Human-like Open-Domain Chatbot}, 
      author={Daniel Adiwardana and Minh-Thang Luong and David R. So and Jamie Hall and Noah Fiedel and Romal Thoppilan and Zi Yang and Apoorv Kulshreshtha and Gaurav Nemade and Yifeng Lu and Quoc V. Le},
      year={2020},
      eprint={2001.09977},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{zhao-etal-2020-knowledge-grounded,
    title = "Knowledge-Grounded Dialogue Generation with Pre-trained Language Models",
    author = "Zhao, Xueliang  and
      Wu, Wei  and
      Xu, Can  and
      Tao, Chongyang  and
      Zhao, Dongyan  and
      Yan, Rui",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.272",
    doi = "10.18653/v1/2020.emnlp-main.272",
    pages = "3377--3390",
    abstract = "We study knowledge-grounded dialogue generation with pre-trained language models. To leverage the redundant external knowledge under capacity constraint, we propose equipping response generation defined by a pre-trained language model with a knowledge selection module, and an unsupervised approach to jointly optimizing knowledge selection and response generation with unlabeled dialogues. Empirical results on two benchmarks indicate that our model can significantly outperform state-of-the-art methods in both automatic evaluation and human judgment.",
}

@article{FU202214,
title = {Learning towards conversational AI: A survey},
journal = {AI Open},
volume = {3},
pages = {14-28},
year = {2022},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2022.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666651022000079},
author = {Tingchen Fu and Shen Gao and Xueliang Zhao and Ji-rong Wen and Rui Yan},
keywords = {Human-machine conversation, Response generation, Informativeness dialogue, Controllable dialogue},
abstract = {Recent years have witnessed a surge of interest in the field of open-domain dialogue. Thanks to the rapid development of social media, large dialogue corpus from the Internet builds up a fundamental premise for data-driven dialogue model. The breakthrough in neural network also brings new ideas to researchers in AI and NLP. A great number of new techniques and methods therefore came into being. In this paper, we review some of the most representative works in recent years and divide existing prevailing frameworks for a dialogue model into three categories. We further analyze the trend of development for open-domain dialogue and summarize the goal of an open-domain dialogue system in two aspects, informative and controllable. The methods we review in this paper are selected according to our unique perspectives and by no means complete. Rather, we hope this servery could benefit NLP community for future research in open-domain dialogue.}
}

@misc{yan2024correctiveretrievalaugmentedgeneration,
      title={Corrective Retrieval Augmented Generation}, 
      author={Shi-Qi Yan and Jia-Chen Gu and Yun Zhu and Zhen-Hua Ling},
      year={2024},
      eprint={2401.15884},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.15884}, 
}

@misc{vakulenko2020questionrewritingconversationalquestion,
      title={Question Rewriting for Conversational Question Answering}, 
      author={Svitlana Vakulenko and Shayne Longpre and Zhucheng Tu and Raviteja Anantha},
      year={2020},
      eprint={2004.14652},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2004.14652}, 
}

@misc{zhang2024surveymemorymechanismlarge,
      title={A Survey on the Memory Mechanism of Large Language Model based Agents}, 
      author={Zeyu Zhang and Xiaohe Bo and Chen Ma and Rui Li and Xu Chen and Quanyu Dai and Jieming Zhu and Zhenhua Dong and Ji-Rong Wen},
      year={2024},
      eprint={2404.13501},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2404.13501}, 
}

@misc{zhu2024knowagentknowledgeaugmentedplanningllmbased,
      title={KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents}, 
      author={Yuqi Zhu and Shuofei Qiao and Yixin Ou and Shumin Deng and Ningyu Zhang and Shiwei Lyu and Yue Shen and Lei Liang and Jinjie Gu and Huajun Chen},
      year={2024},
      eprint={2403.03101},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.03101}, 
}

@misc{abuelsaad2024agenteautonomouswebnavigation,
      title={Agent-E: From Autonomous Web Navigation to Foundational Design Principles in Agentic Systems}, 
      author={Tamer Abuelsaad and Deepak Akkil and Prasenjit Dey and Ashish Jagmohan and Aditya Vempaty and Ravi Kokku},
      year={2024},
      eprint={2407.13032},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.13032}, 
}

@misc{xie2024travelplannerbenchmarkrealworldplanning,
      title={TravelPlanner: A Benchmark for Real-World Planning with Language Agents}, 
      author={Jian Xie and Kai Zhang and Jiangjie Chen and Tinghui Zhu and Renze Lou and Yuandong Tian and Yanghua Xiao and Yu Su},
      year={2024},
      eprint={2402.01622},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.01622}, 
}

@misc{wu2024stateflowenhancingllmtasksolving,
      title={StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows}, 
      author={Yiran Wu and Tianwei Yue and Shaokun Zhang and Chi Wang and Qingyun Wu},
      year={2024},
      eprint={2403.11322},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.11322}, 
}

@misc{gao2024empoweringbiomedicaldiscoveryai,
      title={Empowering Biomedical Discovery with AI Agents}, 
      author={Shanghua Gao and Ada Fang and Yepeng Huang and Valentina Giunchiglia and Ayush Noori and Jonathan Richard Schwarz and Yasha Ektefaie and Jovana Kondic and Marinka Zitnik},
      year={2024},
      eprint={2404.02831},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2404.02831}, 
}

@misc{zhang2024omagentmultimodalagentframework,
      title={OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer}, 
      author={Lu Zhang and Tiancheng Zhao and Heting Ying and Yibo Ma and Kyusong Lee},
      year={2024},
      eprint={2406.16620},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.16620}, 
}

@misc{luo2024repoagentllmpoweredopensourceframework,
      title={RepoAgent: An LLM-Powered Open-Source Framework for Repository-level Code Documentation Generation}, 
      author={Qinyu Luo and Yining Ye and Shihao Liang and Zhong Zhang and Yujia Qin and Yaxi Lu and Yesai Wu and Xin Cong and Yankai Lin and Yingli Zhang and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2402.16667},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.16667}, 
}

@misc{jiang2024kgagentefficientautonomousagent,
      title={KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph}, 
      author={Jinhao Jiang and Kun Zhou and Wayne Xin Zhao and Yang Song and Chen Zhu and Hengshu Zhu and Ji-Rong Wen},
      year={2024},
      eprint={2402.11163},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.11163}, 
}

@misc{zong2024triadframeworkleveragingmultirole,
      title={Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering}, 
      author={Chang Zong and Yuchen Yan and Weiming Lu and Jian Shao and Eliot Huang and Heng Chang and Yueting Zhuang},
      year={2024},
      eprint={2402.14320},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.14320}, 
}

@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}