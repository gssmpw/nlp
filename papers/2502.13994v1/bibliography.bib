@article{gauthier2024matup,
      journal   = {Computer Graphics Forum},
      title     = {MatUp: Repurposing Image Upsamplers for SVBRDFs},
      author    = {Gauthier, Alban and Kerbl, Bernhard and Levallois, Jérémy and Faury, Robin and Thiery, Jean-Marc and Boubekeur, Tamy},
      year      = {2024},
      volume    = {43},
      number    = {4},
}

@article{Saharia2023,
  author={Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J. and Norouzi, Mohammad},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Image Super-Resolution via Iterative Refinement}, 
  year={2023},
  volume={45},
  number={4},
  pages={4713--4726},
}

@inproceedings{wang2018esrgan,
author = {Wang, Xintao and Yu, Ke and Wu, Shixiang and Gu, Jinjin and Liu, Yihao and Dong, Chao and Qiao, Yu and Change Loy, Chen},
title = {ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV) Workshops},
month = {September},
year = {2018}
}

@article{wu2024cat4d,
    title={{CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models}},
    author={Wu, Rundi and Gao, Ruiqi and Poole, Ben and Trevithick, Alex and Zheng, Changxi and Barron, Jonathan T. and Holynski, Aleksander},
    journal={arXiv:2411.18613},
    year={2024}
}

@article{shi2023MVDream,
  author = {Shi, Yichun and Wang, Peng and Ye, Jianglong and Mai, Long and Li, Kejie and Yang, Xiao},
  title = {MVDream: Multi-view Diffusion for 3D Generation},
  journal = {arXiv:2308.16512},
  year = {2023},
}

@article{taoran2023gaussiandreamer,
    title={GaussianDreamer: Fast Generation from Text to 3D Gaussian Splatting with Point Cloud Priors},
    author={Taoran Yi and Jiemin Fang and Guanjun Wu and Lingxi Xie and Xiaopeng Zhang and Wenyu Liu and Qi Tian and Xinggang Wang},
    journal={arxiv:2310.08529},
    year={2023}
}

@article{zhu2023hifa,
      title={HiFA: High-fidelity Text-to-3D Generation with Advanced Diffusion Guidance}, 
      author={Junzhe Zhu and Peiye Zhuang},
      journal={arXiv:2305.18766},
      year={2023}
}

@inproceedings{lin2023magic3d,
  title={Magic3D: High-Resolution Text-to-3D Content Creation},
  author={Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition ({CVPR})},
  year={2023}
} 

@article{wang2023prolificdreamer,
      title={ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation},
      author={Zhengyi Wang and Cheng Lu and Yikai Wang and Fan Bao and Chongxuan Li and Hang Su and Jun Zhu},
      journal={arXiv:2305.16213},
      year={2023}
}

@inproceedings{chen2023fantasia3d,
  author={Chen, Rui and Chen, Yongwei and Jiao, Ningxin and Jia, Kui},
  title={Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month={October},
  year={2023},
  pages={22246--22256}
}

@Article{kerbl3Dgaussians,
	author       = {Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
	title        = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
	journal      = {ACM Transactions on Graphics},
	number       = {4},
	volume       = {42},
	year         = {2023},
}

@inproceedings{richardson2023texture,
      author = {Richardson, Elad and Metzer, Gal and Alaluf, Yuval and Giryes, Raja and Cohen-Or, Daniel},
      title = {TEXTure: Text-Guided Texturing of 3D Shapes},
      year = {2023},
      booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
      articleno = {54},
      numpages = {11},
      series = {SIGGRAPH '23}
}

@inproceedings{tumanyan2023pnp,
      author    = {Tumanyan, Narek and Geyer, Michal and Bagon, Shai and Dekel, Tali},
      title     = {Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month     = {June},
      year      = {2023},
      pages     = {1921-1930}
}

@inproceedings{mokady2023nulltext,
  author={Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Null-text Inversion for Editing Real Images using Guided Diffusion Models}, 
  year={2023},
  volume={},
  number={},
  pages={6038-6047},
}

@inproceedings{parmar2023pix2pixzero,
      author = {Parmar, Gaurav and Kumar Singh, Krishna and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan},
      title = {Zero-shot Image-to-Image Translation},
      year = {2023},
      booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
      articleno = {11},
      numpages = {11},
      series = {SIGGRAPH '23}
}

@inproceedings{chen2023text2tex,
      author = { Chen, Dave Zhenyu and Siddiqui, Yawar and Lee, Hsin-Ying and Tulyakov, Sergey and Niesner, Matthias },
      booktitle = { 2023 IEEE/CVF International Conference on Computer Vision (ICCV) },
      title = {{ Text2Tex: Text-driven Texture Synthesis via Diffusion Models }},
      year = {2023},
      pages = {18512-18522},
}

@inproceedings{cao2023textfusion,
      author = { Cao, Tianshi and Kreis, Karsten and Fidler, Sanja and Sharp, Nicholas and Yin, Kangxue },
      booktitle = { 2023 IEEE/CVF International Conference on Computer Vision (ICCV) },
      title = {{ TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion Models }},
      year = {2023},
      pages = {4146-4158},
}

@inproceedings{youwang2024paintit,
    title = {Paint-it: Text-to-Texture Synthesis via Deep Convolutional Texture Map Optimization and Physically-Based Rendering},
    author = {Youwang, Kim and Oh, Tae-Hyun and Pons-Moll, Gerard},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year = {2024}
}

@inproceedings{martin2021nerf,
	title="{NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections}",
	author={Martin-Brualla, Ricardo and Radwan, Noha and Sajjadi, Mehdi SM and Barron, Jonathan T and Dosovitskiy, Alexey and Duckworth, Daniel},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={7210--7219},
	year={2021}
}

@inproceedings{mildenhall2020nerf,
 title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
 author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
 year={2020},
 booktitle={ECCV},
}

@inproceedings{poole2023dreamfusion,
	title={DreamFusion: Text-to-3D using 2D Diffusion},
	author={Ben Poole and Ajay Jain and Jonathan T. Barron and Ben Mildenhall},
	booktitle={The Eleventh International Conference on Learning Representations },
	year={2023}
}

@inproceedings{song2021denoising,
	title={Denoising Diffusion Implicit Models},
	author={Jiaming Song and Chenlin Meng and Stefano Ermon},
	booktitle={International Conference on Learning Representations},
	year={2021}
}

@misc{rombach2022stablediffusion,
	title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
	author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
	year={2022},
	journal={arXiv:2112.10752}
}

@article{blattmann2023svd,
	title={Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets}, 
	author={Andreas Blattmann and Tim Dockhorn and Sumith Kulal and Daniel Mendelevitch and Maciej Kilian and Dominik Lorenz and Yam Levi and Zion English and Vikram Voleti and Adam Letts and Varun Jampani and Robin Rombach},
	year={2023},
	journal={arXiv:2311.15127}
}

@misc{yang2024cogvideox,
      title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer}, 
      author={Zhuoyi Yang and Jiayan Teng and Wendi Zheng and Ming Ding and Shiyu Huang and Jiazheng Xu and Yuanming Yang and Wenyi Hong and Xiaohan Zhang and Guanyu Feng and Da Yin and Xiaotao Gu and Yuxuan Zhang and Weihan Wang and Yean Cheng and Ting Liu and Bin Xu and Yuxiao Dong and Jie Tang},
      year={2024},
      journal={arXiv:2408.06072}
}

@inproceedings{hong2023cogvideo,
	title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
	author={Wenyi Hong and Ming Ding and Wendi Zheng and Xinghan Liu and Jie Tang},
	booktitle={The Eleventh International Conference on Learning Representations },
	year={2023}
}

@article{voleti2024sv3d,
      title={SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion}, 
      author={Vikram Voleti and Chun-Han Yao and Mark Boss and Adam Letts and David Pankratz and Dmitry Tochilkin and Christian Laforte and Robin Rombach and Varun Jampani},
      year={2024},
      journal={arXiv:2403.12008},
}

@article{nvidia2025cosmos,
	title={Cosmos World Foundation Model Platform for Physical AI}, 
	author={NVIDIA},
	year={2025},
	journal={arXiv:2501.03575},
	year={2025},
}

@inproceedings{vecchio2024matsynth,
	author    = {Vecchio, Giuseppe and Deschaintre, Valentin},
	title     = {MatSynth: A Modern PBR Materials Dataset},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month     = {June},
	year      = {2024},
	pages     = {22109-22118}
}

@misc{flashtex,
      title={FlashTex: Fast Relightable Mesh Texturing with LightControlNet}, 
      author={Kangle Deng and Timothy Omernick and Alexander Weiss and Deva Ramanan and Jun-Yan Zhu and Tinghui Zhou and Maneesh Agrawala},
      year={2024},
      eprint={2402.13251},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2402.13251}, 
}

@misc{dreammat,
      title={DreamMat: High-quality PBR Material Generation with Geometry- and Light-aware Diffusion Models}, 
      author={Yuqing Zhang and Yuan Liu and Zhiyu Xie and Lei Yang and Zhongyuan Liu and Mengzhou Yang and Runze Zhang and Qilong Kou and Cheng Lin and Wenping Wang and Xiaogang Jin},
      year={2024},
      eprint={2405.17176},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2405.17176}, 
}

@misc{controlnet,
      title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
      author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
      year={2023},
      eprint={2302.05543},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2302.05543}, 
}

@misc{controlnet_normal,
  author       = {Liylasviel},
  title        = {ControlNet NormalBae Model (v1.1p, SD15)},
  year         = {2025},
  howpublished = {\url{https://huggingface.co/lllyasviel/control_v11p_sd15_normalbae}},
  note         = {Accessed: 2025-01-15}
}

@misc{controlnet_tile,
  author       = {Liylasviel},
  title        = {ControlNet Tile Model (v1.1f1e, SD15)},
  year         = {2025},
  howpublished = {\url{https://huggingface.co/lllyasviel/control_v11f1e_sd15_tile}},
  note         = {Accessed: 2025-01-15}
}



@inproceedings{RGBX,
   title={RGB-X: Image decomposition and synthesis using material- and lighting-aware diffusion models},
   url={http://dx.doi.org/10.1145/3641519.3657445},
   DOI={10.1145/3641519.3657445},
   booktitle={Special Interest Group on Computer Graphics and Interactive Techniques Conference Conference Papers ’24},
   publisher={ACM},
   author={Zeng, Zheng and Deschaintre, Valentin and Georgiev, Iliyan and Hold-Geoffroy, Yannick and Hu, Yiwei and Luan, Fujun and Yan, Ling-Qi and Hašan, Miloš},
   year={2024},
   month=jul, pages={1–11},
   collection={SIGGRAPH ’24}
}

@misc{cerkezi2023multiview,
      title={Multi-View Unsupervised Image Generation with Cross Attention Guidance}, 
      author={Llukman Cerkezi and Aram Davtyan and Sepehr Sameni and Paolo Favaro},
      year={2023},
      eprint={2312.04337},
      archivePrefix={arXiv},
      url={https://arxiv.org/abs/2312.04337}, 
}

@misc{diffusion_handles,
      title={Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D}, 
      author={Karran Pandey and Paul Guerrero and Matheus Gadelha and Yannick Hold-Geoffroy and Karan Singh and Niloy Mitra},
      year={2023},
      eprint={2312.02190},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.02190}, 
}


@article{bao2024tex4d,
      title={Tex4D: Zero-shot 4D Scene Texturing with Video Diffusion Models}, 
      author={Jingzhi Bao and Xueting Li and Ming-Hsuan Yang},
      journal={arXiv preprint arxiv:2410.10821},
      year={2024}
}

@inproceedings{spiderman,
author = {Patashnik, Or and Gal, Rinon and Cohen-Or, Daniel and Zhu, Jun-Yan and De La Torre, Fernando},
title = {Consolidating Attention Features for Multi-view Image Editing},
year = {2024},
isbn = {9798400711312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680528.3687611},
doi = {10.1145/3680528.3687611},
abstract = {Large-scale text-to-image models enable a wide range of image editing techniques, using text prompts or even spatial controls. However, applying these editing methods to multi-view images depicting a single scene leads to 3D-inconsistent results. In this work, we focus on spatial control-based geometric manipulations and introduce a method to consolidate the editing process across various views. We build on two insights: (1) maintaining consistent features throughout the generative process helps attain consistency in multi-view editing, and (2) the queries in self-attention layers significantly influence the image structure. Hence, we propose to improve the geometric consistency of the edited images by enforcing the consistency of the queries. To do so, we introduce QNeRF, a neural radiance field trained on the internal query features of the edited images. Once trained, QNeRF can render 3D-consistent queries, which are then softly injected back into the self-attention layers during generation, greatly improving multi-view consistency. We refine the process through a progressive, iterative method that better consolidates queries across the diffusion timesteps. We compare our method to a range of existing techniques and demonstrate that it can achieve better multi-view consistency and higher fidelity to the input scene. These advantages allow us to train NeRFs with fewer visual artifacts, that are better aligned with the target geometry.},
booktitle = {SIGGRAPH Asia 2024 Conference Papers},
articleno = {40},
numpages = {12},
keywords = {Multi-view, Diffusion Models, Image Editing},
location = {
},
series = {SA '24}
}


@misc{texpainter,
      title={TexPainter: Generative Mesh Texturing with Multi-view Consistency}, 
      author={Hongkun Zhang and Zherong Pan and Congyi Zhang and Lifeng Zhu and Xifeng Gao},
      year={2024},
      eprint={2406.18539},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.18539}, 
}


@misc{ddim,
      title={Denoising Diffusion Implicit Models}, 
      author={Jiaming Song and Chenlin Meng and Stefano Ermon},
      year={2022},
      eprint={2010.02502},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2010.02502}, 
}


@misc{mvdiffusion,
      title={MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion}, 
      author={Shitao Tang and Fuyang Zhang and Jiacheng Chen and Peng Wang and Yasutaka Furukawa},
      year={2023},
      eprint={2307.01097},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.01097}, 
}

@misc{spad,
      title={SPAD : Spatially Aware Multiview Diffusers}, 
      author={Yash Kant and Ziyi Wu and Michael Vasilkovsky and Guocheng Qian and Jian Ren and Riza Alp Guler and Bernard Ghanem and Sergey Tulyakov and Igor Gilitschenski and Aliaksandr Siarohin},
      year={2024},
      eprint={2402.05235},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.05235}, 
}


@misc{objaverse,
      title={Objaverse: A Universe of Annotated 3D Objects}, 
      author={Matt Deitke and Dustin Schwenk and Jordi Salvador and Luca Weihs and Oscar Michel and Eli VanderBilt and Ludwig Schmidt and Kiana Ehsani and Aniruddha Kembhavi and Ali Farhadi},
      year={2022},
      eprint={2212.08051},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.08051}, 
}


@misc{pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.01703}, 
}


@misc{huggingface,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.03771}, 
}


@software{mitsuba,
    title = {Mitsuba 3 renderer},
    author = {Wenzel Jakob and Sébastien Speierer and Nicolas Roussel and Merlin Nimier-David and Delio Vicini and Tizian Zeltner and Baptiste Nicolet and Miguel Crespo and Vincent Leroy and Ziyi Zhang},
    note = {https://mitsuba-renderer.org},
    version = {3.0.1},
    year = 2022,
}

@article{drjit,
  author = {Wenzel Jakob and S{\'e}bastien Speierer and Nicolas Roussel and Delio Vicini},
  title = {Dr.Jit: A Just-In-Time Compiler for Differentiable Rendering},
  journal = {Transactions on Graphics (Proceedings of SIGGRAPH)},
  volume = {41},
  number = {4},
  year = {2022},
  month = jul,
  doi = {10.1145/3528223.3530099}
}


@Misc{xFormers,
  author =       {Benjamin Lefaudeux and Francisco Massa and Diana Liskovich and Wenhan Xiong and Vittorio Caggiano and Sean Naren and Min Xu and Jieru Hu and Marta Tintore and Susan Zhang and Patrick Labatut and Daniel Haziza and Luca Wehrstedt and Jeremy Reizenstein and Grigory Sizov},
  title =        {xFormers: A modular and hackable Transformer modelling library},
  howpublished = {\url{https://github.com/facebookresearch/xformers}},
  year =         {2022}
}

@inproceedings{flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}
@inproceedings{flashattention2,
  title={Flash{A}ttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author={Dao, Tri},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}


@misc{memeffattention,
    title   = {Self-attention Does Not Need $O(n^2)$ Memory}, 
    author  = {Markus N. Rabe and Charles Staats},
    year    = {2021},
    eprint  = {2112.05682},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}
@misc{memeffattention2,
    title   = {Swin Transformer V2: Scaling Up Capacity and Resolution},
    author  = {Ze Liu and Han Hu and Yutong Lin and Zhuliang Yao and Zhenda Xie and Yixuan Wei and Jia Ning and Yue Cao and Zheng Zhang and Li Dong and Furu Wei and Baining Guo},
    year    = {2021},
    eprint  = {2111.09883},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}


@misc{flexattention,
      title={Flex Attention: A Programming Model for Generating Optimized Attention Kernels}, 
      author={Juechu Dong and Boyuan Feng and Driss Guessous and Yanbo Liang and Horace He},
      year={2024},
      eprint={2412.05496},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.05496}, 
}


@inproceedings{texsliders, series={SIGGRAPH ’24},
   title={TexSliders: Diffusion-Based Texture Editing in CLIP Space},
   url={http://dx.doi.org/10.1145/3641519.3657444},
   DOI={10.1145/3641519.3657444},
   booktitle={Special Interest Group on Computer Graphics and Interactive Techniques Conference Conference Papers ’24},
   publisher={ACM},
   author={Guerrero-Viu, Julia and Hasan, Milos and Roullier, Arthur and Harikumar, Midhun and Hu, Yiwei and Guerrero, Paul and Gutiérrez, Diego and Masia, Belen and Deschaintre, Valentin},
   year={2024},
   month=jul, pages={1–11},
   collection={SIGGRAPH ’24} }

@misc{SD3,
      title={Scaling Rectified Flow Transformers for High-Resolution Image Synthesis}, 
      author={Patrick Esser and Sumith Kulal and Andreas Blattmann and Rahim Entezari and Jonas Müller and Harry Saini and Yam Levi and Dominik Lorenz and Axel Sauer and Frederic Boesel and Dustin Podell and Tim Dockhorn and Zion English and Kyle Lacey and Alex Goodwin and Yannik Marek and Robin Rombach},
      year={2024},
      eprint={2403.03206},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.03206}, 
}

@misc{SD3_5_large,
  author       = {{Stability AI}},
  title        = {Stable Diffusion 3.5 Large},
  year         = {2025},
  howpublished = {\url{https://huggingface.co/stabilityai/stable-diffusion-3.5-large}},
  note         = {Accessed: 2025-01-15}
}



@misc{SD3_5_controlnet_blur,
  author       = {{Stability AI}},
  title        = {Stable Diffusion 3.5 Large ControlNet Blur},
  year         = {2025},
  howpublished = {\url{https://huggingface.co/stabilityai/stable-diffusion-3.5-large-controlnet-blur}},
  note         = {Accessed: 2025-01-15}
}



@misc{DiT,
      title={Scalable Diffusion Models with Transformers}, 
      author={William Peebles and Saining Xie},
      year={2023},
      eprint={2212.09748},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.09748}, 
}


@misc{stable_unclip_pipeline,
  author       = {Hugging Face},
  title        = {Stable UnCLIP Pipeline Documentation},
  year         = {2025},
  howpublished = {\url{https://huggingface.co/docs/diffusers/en/api/pipelines/stable_unclip}},
  note         = {Accessed: 2025-01-15}
}



@misc{dall_e2,
      title={Hierarchical Text-Conditional Image Generation with CLIP Latents}, 
      author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
      year={2022},
      eprint={2204.06125},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.06125}, 
}

@misc{Burley2012,
    title = "{Physically-Based Shading at Disney}",
    author = {Brent Burley},
    year = {2012},
    howpublished = {SIGGRAPH 2012 Course: Physically-Based Shading},
}

@inproceedings{ho2020diffusion,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {6840--6851},
 publisher = {Curran Associates, Inc.},
 title = {Denoising Diffusion Probabilistic Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{
      chang2024how,
      title={How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models},
      author={Pascal Chang and Jingwei Tang and Markus Gross and Vinicius C. Azevedo},
      booktitle={The Twelfth International Conference on Learning Representations},
      year={2024},
      url={https://openreview.net/forum?id=pzElnMrgSD}
}

@article{daras2024warped,
  title={Warped diffusion: Solving video inverse problems with image diffusion models},
  author={Daras, Giannis and Nie, Weili and Kreis, Karsten and Dimakis, Alex and Mardani, Morteza and Kovachki, Nikola Borislavov and Vahdat, Arash},
  journal={arXiv preprint arXiv:2410.16152},
  year={2024}
}

@inproceedings{Vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{KingmaBa2014Adam,
    author = {Kingma, Diederik and Ba, Jimmy},
    year = {2014},
    month = {12},
    pages = {},
    title = {Adam: A Method for Stochastic Optimization},
    journal = {International Conference on Learning Representations}
}

@article{Reinhard2002,
author = {Reinhard, Erik and Stark, Michael and Shirley, Peter and Ferwerda, James},
title = {Photographic tone reproduction for digital images},
year = {2002},
issue_date = {July 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/566654.566575},
doi = {10.1145/566654.566575},
journal = {ACM Trans. Graph.},
month = jul,
pages = {267–276},
numpages = {10},
keywords = {zone system, tone reproduction, dynamic range}
}

@article{Vecchio2024controlmat,
      author = {Vecchio, Giuseppe and Martin, Rosalie and Roullier, Arthur and Kaiser, Adrien and Rouffet, Romain and Deschaintre, Valentin and Boubekeur, Tamy},
      title = {ControlMat: A Controlled Generative Approach to Material Capture},
      year = {2024},
      issue_date = {October 2024},
      publisher = {Association for Computing Machinery},
      address = {New York, NY, USA},
      volume = {43},
      number = {5},
      issn = {0730-0301},
      url = {https://doi.org/10.1145/3688830},
      doi = {10.1145/3688830},
      journal = {ACM Trans. Graph.},
      month = sep,
      articleno = {164},
      numpages = {17},
}

@inproceedings{mapa,
author = {Zhang, Shangzhan and Peng, Sida and Xu, Tao and Yang, Yuanbo and Chen, Tianrun and Xue, Nan and Shen, Yujun and Bao, Hujun and Hu, Ruizhen and Zhou, Xiaowei},
title = {MaPa: Text-driven Photorealistic Material Painting for 3D Shapes},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657504},
doi = {10.1145/3641519.3657504},
abstract = {This paper aims to generate materials for 3D meshes from text descriptions. Unlike existing methods that synthesize texture maps, we propose to generate segment-wise procedural material graphs as the appearance representation, which supports high-quality rendering and provides substantial flexibility in editing. Instead of relying on extensive paired data, i.e., 3D meshes with material graphs and corresponding text descriptions, to train a material graph generative model, we propose to leverage the pre-trained 2D diffusion model as a bridge to connect the text and material graphs. Specifically, our approach decomposes a shape into a set of segments and designs a segment-controlled diffusion model to synthesize 2D images that are aligned with mesh parts. Based on generated images, we initialize parameters of material graphs and fine-tune them through the differentiable rendering module to produce materials in accordance with the textual description. Extensive experiments demonstrate the superior performance of our framework in photorealism, resolution, and editability over existing methods.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {4},
numpages = {12},
keywords = {3D asset creation, generative modeling, material painting},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@article{Jakob2012Manifold,
    author = {Wenzel Jakob and Steve Marschner},
    title = {Manifold Exploration: A Markov Chain Monte Carlo Technique for Rendering Scenes with Difficult Specular Transport},
    journal = {ACM Transactions on Graphics (Proceedings of SIGGRAPH)},
    volume = {31},
    number = {4},
    pages = {58:1--58:13},
    year = {2012},
    month = jul,
    doi = {10.1145/2185520.2185554}
}

@inproceedings{meng2022sdedit,
title={{SDE}dit: Guided Image Synthesis and Editing with Stochastic Differential Equations},
author={Chenlin Meng and Yutong He and Yang Song and Jiaming Song and Jiajun Wu and Jun-Yan Zhu and Stefano Ermon},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=aBsCjcPu_tE}
}

@misc{ho2022cfg,
      title={Classifier-Free Diffusion Guidance}, 
      author={Jonathan Ho and Tim Salimans},
      year={2022},
      eprint={2207.12598},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.12598}, 
}