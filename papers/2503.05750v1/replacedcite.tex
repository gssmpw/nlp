\section{Related Work}
\label{sec_rl}

In recent years, deep learning has significantly improved neural abstractive summarization tasks in NLP ____. Traditional models are primarily trained on general datasets like CNN/Daily Mail ____ and Gigaword Corpus ____. The attention-based seq2seq model by ____ and its extension by ____ laid the groundwork for these advancements. Recently, large-scale pre-trained language models have shown impressive summarization results ____. ____ employed BERT and GPT for summarizing COVID-19 research. However, unique word distributions in radiology corpora limit the applicability of these techniques ____.

 ____ first explored automatic radiology Impression generation, followed by ____, who introduced an ontology-aware pointer-generator model to enhance summarization quality. A background-augmented pointer-generator network with copy and background-guided decoding was proposed ____, and a word graph captured critical words and relations ____. Anatomies were extracted, radiographs encoded, and fused with anatomy-enhanced co-attention ____. ____ enhanced clinical summarization by augmenting ontological terms, and ____ integrated findings by a unified framework with knowledge via text and graph encoders. ____ proposed a two-step extractive-abstractive method using a Differentiable Multi-Agent Actor-Critic framework.

A hybrid retrieval-generation agent ____ integrated human knowledge with neural networks for medical report generation. Models like OpenAI GPT ____, BERT ____, ELMo ____, and XLNet ____ have improved various NLP tasks through extensive external knowledge. BioBERT ____ captures semantic features in the biomedical field, pre-trained on large corpora like PubMed abstracts and PMC articles. Recently, ____ proposed a pre-trained language model, ChestXrayBert, specifically designed for summarizing chest radiology reports. However, these studies may struggle with effective Impression generation methodologies.


\begin{table}[t!]
\resizebox{\columnwidth}{!}{%
\begin{threeparttable}
\begin{tabular}{@{}llllllll@{}}
\toprule
\multirow{2}{*}{Dataset} & \multirow{2}{*}{\# Reports} & \multicolumn{3}{l}{Findings (Avg.)} & \multicolumn{3}{l}{Impressions (Avg.)} \\ \cmidrule(l){3-8} 
 &  & \# S & \# W/S & \# Source W & \# S & \# W/S & \# Source W \\ \midrule
MIMIC-CXR & 121,975 & 5.47 & 10.08 & 55.09 & 1.94 & 8.50 & 16.46 \\
Open-I & 3,312 & 4.62 & 8.03 & 37.06 & 1.81 & 5.52 & 9.98 \\ \bottomrule
\end{tabular}%
\begin{tablenotes}
    \item S: Sentence, W: Words
\end{tablenotes}
\end{threeparttable}}
\caption{Summary of dataset statistics of Findings and Impression}
\label{tab:dataset_summary}
\end{table}