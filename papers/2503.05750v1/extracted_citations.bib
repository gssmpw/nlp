@inproceedings{10nallapati2016abstractive,
	address = {Berlin, Germany},
	title = {Abstractive {Text} {Summarization} using {Sequence}-to-sequence {RNNs} and {Beyond}},
	url = {https://aclanthology.org/K16-1028},
	doi = {10.18653/v1/K16-1028},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 20th {SIGNLL} {Conference} on {Computational} {Natural} {Language} {Learning}},
	publisher = {Association for Computational Linguistics},
	author={Nallapati, Ramesh and Zhou, Bowen and Gulcehre, Caglar and Xiang, Bing and others},
	editor = {Riezler, Stefan and Goldberg, Yoav},
	month = aug,
	year = {2016},
	pages = {280--290},
}

@inproceedings{11sutskever2014sequence,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'14},
	title = {Sequence to sequence learning with neural networks},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Neural} {Information} {Processing} {Systems} - {Volume} 2},
	publisher = {MIT Press},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	month = dec,
	year = {2014},
	pages = {3104--3112},
}

@inproceedings{12liu2019reading,
	address = {Florence, Italy},
	title = {Reading {Turn} by {Turn}: {Hierarchical} {Attention} {Architecture} for {Spoken} {Dialogue} {Comprehension}},
	shorttitle = {Reading {Turn} by {Turn}},
	url = {https://aclanthology.org/P19-1543},
	doi = {10.18653/v1/P19-1543},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Zhengyuan and Chen, Nancy},
	editor = {Korhonen, Anna and Traum, David and Màrquez, Lluís},
	month = jul,
	year = {2019},
	pages = {5460--5466},
}

@inproceedings{13karn2021few,
	address = {Kyiv, Ukraine},
	title = {Few-{Shot} {Learning} of an {Interleaved} {Text} {Summarization} {Model} by {Pretraining} with {Synthetic} {Data}},
	url = {https://aclanthology.org/2021.adaptnlp-1.24},
	booktitle = {Proceedings of the {Second} {Workshop} on {Domain} {Adaptation} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Karn, Sanjeev Kumar and Chen, Francine and Chen, Yan-Ying and Waltinger, Ulli and Schütze, Hinrich},
	editor = {Ben-David, Eyal and Cohen, Shay and McDonald, Ryan and Plank, Barbara and Reichart, Roi and Rotman, Guy and Ziser, Yftah},
	month = apr,
	year = {2021},
	pages = {245--254},
}

@article{14raffel2020exploring,
	title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
	volume = {21},
	issn = {1532-4435},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
	month = jan,
	year = {2020},
	pages = {140:5485--140:5551},
}

@misc{15kieuvongngam2020automatic,
	title = {Automatic {Text} {Summarization} of {COVID}-19 {Medical} {Research} {Articles} using {BERT} and {GPT}-2},
	url = {https://arxiv.org/abs/2006.01997v1},
	language = {en},
	journal = {arXiv.org},
	author = {Kieuvongngam, Virapat and Tan, Bowen and Niu, Yiming},
	month = jun,
	year = {2020},
}

@inproceedings{16chang2021jointly,
	address = {Online},
	title = {Jointly {Improving} {Language} {Understanding} and {Generation} with {Quality}-{Weighted} {Weak} {Supervision} of {Automatic} {Labeling}},
	url = {https://aclanthology.org/2021.eacl-main.69},
	doi = {10.18653/v1/2021.eacl-main.69},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Chang, Ernie and Demberg, Vera and Marin, Alex},
	editor = {Merlo, Paola and Tiedemann, Jorg and Tsarfaty, Reut},
	month = apr,
	year = {2021},
	pages = {818--829},
}

@article{1Cai2023,
	title = {{ChestXRayBERT}: {A} {Pretrained} {Language} {Model} for {Chest} {Radiology} {Report} {Summarization}},
	volume = {25},
	issn = {1941-0077},
	shorttitle = {{ChestXRayBERT}},
	url = {https://ieeexplore.ieee.org/document/9638337},
	doi = {10.1109/TMM.2021.3132724},
	journal = {IEEE Transactions on Multimedia},
	author = {Cai, Xiaoyan and Liu, Sen and Han, Junwei and Yang, Libin and Liu, Zhenguo and Liu, Tianming},
	year = {2023},
	keywords = {Radiology, Task analysis, Biomedical imaging, Decoding, Bit error rate, Biological system modeling, Transformers, Pre-trained language model, chest radiology report, abstractive summarization},
	pages = {845--855},
}

@inproceedings{20zhang2018learning,
	address = {Brussels, Belgium},
	title = {Learning to {Summarize} {Radiology} {Findings}},
	url = {https://aclanthology.org/W18-5623},
	doi = {10.18653/v1/W18-5623},
	booktitle = {Proceedings of the {Ninth} {International} {Workshop} on {Health} {Text} {Mining} and {Information} {Analysis}},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Yuhao and Ding, Daisy Yi and Qian, Tianpei and Manning, Christopher D. and Langlotz, Curtis P.},
	editor = {Lavelli, Alberto and Minard, Anne-Lyse and Rinaldi, Fabio},
	month = oct,
	year = {2018},
	pages = {204--213},
}

@inproceedings{21macavaney2019ontology,
	address = {New York, NY, USA},
	series = {{SIGIR}'19},
	title = {Ontology-{Aware} {Clinical} {Abstractive} {Summarization}},
	isbn = {9781450361729},
	url = {https://dl.acm.org/doi/10.1145/3331184.3331319},
	doi = {10.1145/3331184.3331319},
	booktitle = {Proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {MacAvaney, Sean and Sotudeh, Sajad and Cohan, Arman and Goharian, Nazli and Talati, Ish and Filice, Ross W.},
	month = jul,
	year = {2019},
	pages = {1013--1016},
}

@inproceedings{22li2018hybrid,
	address = {Red Hook, NY, USA},
	series = {{NIPS}'18},
	title = {Hybrid retrieval-generation reinforced agent for medical image report generation},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Li, Christy Y. and Liang, Xiaodan and Hu, Zhiting and Xing, Eric P.},
	month = dec,
	year = {2018},
	pages = {1537--1547},
}

@inproceedings{25devlin2019bert,
	address = {Minneapolis, Minnesota},
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {https://aclanthology.org/N19-1423},
	doi = {10.18653/v1/N19-1423},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
	month = jun,
	year = {2019},
	pages = {4171--4186},
}

@inproceedings{26peters2018deep,
	address = {New Orleans, Louisiana},
	title = {Deep {Contextualized} {Word} {Representations}},
	url = {https://aclanthology.org/N18-1202},
	doi = {10.18653/v1/N18-1202},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
	editor = {Walker, Marilyn and Ji, Heng and Stent, Amanda},
	month = jun,
	year = {2018},
	pages = {2227--2237},
}

@incollection{27yang2019xlnet,
	address = {Red Hook, NY, USA},
	title = {{XLNet}: generalized autoregressive pretraining for language understanding},
	shorttitle = {{XLNet}},
	number = {517},
	booktitle = {Proceedings of the 33rd {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
	month = dec,
	year = {2019},
	pages = {5753--5763},
}

@article{28lee2020biobert,
	title = {{BioBERT}: a pre-trained biomedical language representation model for biomedical text mining},
	volume = {36},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1367-4803, 1367-4811},
	shorttitle = {{BioBERT}},
	url = {https://academic.oup.com/bioinformatics/article/36/4/1234/5566506},
	doi = {10.1093/bioinformatics/btz682},
	language = {en},
	number = {4},
	journal = {Bioinformatics},
	author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
	editor = {Wren, Jonathan},
	month = feb,
	year = {2020},
	pages = {1234--1240},
}

@inproceedings{5rush2015neural,
	address = {Lisbon, Portugal},
	title = {A {Neural} {Attention} {Model} for {Abstractive} {Sentence} {Summarization}},
	url = {https://aclanthology.org/D15-1044},
	doi = {10.18653/v1/D15-1044},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Rush, Alexander M. and Chopra, Sumit and Weston, Jason},
	editor = {Màrquez, Lluís and Callison-Burch, Chris and Su, Jian},
	month = sep,
	year = {2015},
	pages = {379--389},
}

@inproceedings{6chopra2016abstractive,
	address = {San Diego, California},
	title = {Abstractive {Sentence} {Summarization} with {Attentive} {Recurrent} {Neural} {Networks}},
	url = {https://aclanthology.org/N16-1012},
	doi = {10.18653/v1/N16-1012},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Chopra, Sumit and Auli, Michael and Rush, Alexander M.},
	editor = {Knight, Kevin and Nenkova, Ani and Rambow, Owen},
	month = jun,
	year = {2016},
	pages = {93--98},
}

@inproceedings{7tan2017abstractive,
	address = {Vancouver, Canada},
	title = {Abstractive {Document} {Summarization} with a {Graph}-{Based} {Attentional} {Neural} {Model}},
	url = {https://aclanthology.org/P17-1108},
	doi = {10.18653/v1/P17-1108},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Tan, Jiwei and Wan, Xiaojun and Xiao, Jianguo},
	editor = {Barzilay, Regina and Kan, Min-Yen},
	month = jul,
	year = {2017},
	pages = {1171--1181},
}

@inproceedings{8zhou2017selective,
	address = {Vancouver, Canada},
	title = {Selective {Encoding} for {Abstractive} {Sentence} {Summarization}},
	url = {https://aclanthology.org/P17-1101},
	doi = {10.18653/v1/P17-1101},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Zhou, Qingyu and Yang, Nan and Wei, Furu and Zhou, Ming},
	editor = {Barzilay, Regina and Kan, Min-Yen},
	month = jul,
	year = {2017},
	pages = {1095--1104},
}

@inproceedings{9li2017deep,
	address = {Copenhagen, Denmark},
	title = {Deep {Recurrent} {Generative} {Decoder} for {Abstractive} {Text} {Summarization}},
	url = {https://aclanthology.org/D17-1222},
	doi = {10.18653/v1/D17-1222},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Piji and Lam, Wai and Bing, Lidong and Wang, Zihao},
	editor = {Palmer, Martha and Hwa, Rebecca and Riedel, Sebastian},
	month = sep,
	year = {2017},
	pages = {2091--2100},
}

@inproceedings{added1zhang-etal-2020-optimizing,
    title = "Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports",
    author = "Zhang, Yuhao  and
      Merck, Derek  and
      Tsai, Emily  and
      Manning, Christopher D.  and
      Langlotz, Curtis",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.458",
    doi = "10.18653/v1/2020.acl-main.458",
    pages = "5108--5120",
    abstract = "Neural abstractive summarization models are able to generate summaries which have high overlap with human references. However, existing models are not optimized for factual correctness, a critical metric in real-world applications. In this work, we develop a general framework where we evaluate the factual correctness of a generated summary by fact-checking it automatically against its reference using an information extraction module. We further propose a training strategy which optimizes a neural summarization model with a factual correctness reward via reinforcement learning. We apply the proposed method to the summarization of radiology reports, where factual correctness is a key requirement. On two separate datasets collected from hospitals, we show via both automatic and human evaluation that the proposed approach substantially improves the factual correctness and overall quality of outputs over a competitive neural summarization system, producing radiology summaries that approach the quality of human-authored ones.",
}

@inproceedings{added2hu-etal-2021-word,
    title = "Word Graph Guided Summarization for Radiology Findings",
    author = "Hu, Jinpeng  and
      Li, Jianling  and
      Chen, Zhihong  and
      Shen, Yaling  and
      Song, Yan  and
      Wan, Xiang  and
      Chang, Tsung-Hui",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.441",
    doi = "10.18653/v1/2021.findings-acl.441",
    pages = "4980--4990",
}

@inproceedings{added3hu-etal-2023-improving-radiology,
    title = "Improving Radiology Summarization with Radiograph and Anatomy Prompts",
    author = "Hu, Jinpeng  and
      Chen, Zhihong  and
      Liu, Yang  and
      Wan, Xiang  and
      Chang, Tsung-Hui",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.764",
    doi = "10.18653/v1/2023.findings-acl.764",
    pages = "12066--12080",
    abstract = "The impression is crucial for the referring physicians to grasp key information since it is concluded from the findings and reasoning of radiologists. To alleviate the workload of radiologists and reduce repetitive human labor in impression writing, many researchers have focused on automatic impression generation. However, recent works on this task mainly summarize the corresponding findings and pay less attention to the radiology images. In clinical, radiographs can provide more detailed valuable observations to enhance radiologists{'} impression writing, especially for complicated cases. Besides, each sentence in findings usually focuses on single anatomy, such that they only need to be matched to corresponding anatomical regions instead of the whole image, which is beneficial for textual and visual features alignment. Therefore, we propose a novel anatomy-enhanced multimodal model to promote impression generation. In detail, we first construct a set of rules to extract anatomies and put these prompts into each sentence to highlight anatomy characteristics. Then, two separate encoders are applied to extract features from the radiograph and findings. Afterward, we utilize a contrastive learning module to align these two representations at the overall level and use a co-attention to fuse them at the sentence level with the help of anatomy-enhanced sentence representation. The experimental results on two benchmark datasets confirm the effectiveness of the proposed method, which achieves state-of-the-art results.",
}

@inproceedings{added4sotudeh-gharebagh-etal-2020-attend,
    title = "Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization",
    author = "Sotudeh Gharebagh, Sajad  and
      Goharian, Nazli  and
      Filice, Ross",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.172",
    doi = "10.18653/v1/2020.acl-main.172",
    pages = "1899--1905",
    abstract = "Sequence-to-sequence (seq2seq) network is a well-established model for text summarization task. It can learn to produce readable content; however, it falls short in effectively identifying key regions of the source. In this paper, we approach the content selection problem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer. Our experiments on two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and 3,366 reports of OpenI) show that our model statistically significantly boosts state-of-the-art results in terms of ROUGE metrics (with improvements: 2.9{\%} RG-1, 2.5{\%} RG-2, 1.9{\%} RG-L), in the healthcare domain where any range of improvement impacts patients{'} welfare.",
}

@inproceedings{added5hu-etal-2022-graph,
    title = "Graph Enhanced Contrastive Learning for Radiology Findings Summarization",
    author = "Hu, Jinpeng  and
      Li, Zhuo  and
      Chen, Zhihong  and
      Li, Zhen  and
      Wan, Xiang  and
      Chang, Tsung-Hui",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.320",
    doi = "10.18653/v1/2022.acl-long.320",
    pages = "4677--4688",
    abstract = "The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians. Summarizing findings is time-consuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention. With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information). Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings. To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation. In detail, for each input findings, it is encoded by a text encoder and a graph is constructed through its entities and dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph. Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words). The experimental results on two datasets, OpenI and MIMIC-CXR, confirm the effectiveness of our proposed method, where the state-of-the-art results are achieved.",
}

@inproceedings{added6karn-etal-2022-differentiable,
    title = "Differentiable Multi-Agent Actor-Critic for Multi-Step Radiology Report Summarization",
    author = "Karn, Sanjeev Kumar  and
      Liu, Ning  and
      Schuetze, Hinrich  and
      Farri, Oladimeji",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.109",
    doi = "10.18653/v1/2022.acl-long.109",
    pages = "1542--1553",
    abstract = "The IMPRESSIONS section of a radiology report about an imaging study is a summary of the radiologist{'}s reasoning and conclusions, and it also aids the referring physician in confirming or excluding certain diagnoses. A cascade of tasks are required to automatically generate an abstractive summary of the typical information-rich radiology report. These tasks include acquisition of salient content from the report and generation of a concise, easily consumable IMPRESSIONS section. Prior research on radiology report summarization has focused on single-step end-to-end models {--} which subsume the task of salient content acquisition. To fully explore the cascade structure and explainability of radiology report summarization, we introduce two innovations. First, we design a two-step approach: extractive summarization followed by abstractive summarization. Second, we additionally break down the extractive part into two independent tasks: extraction of salient (1) sentences and (2) keywords. Experiments on English radiology reports from two clinical sites show our novel approach leads to a more precise summary compared to single-step and to two-step-with-single-extractive-process baselines with an overall improvement in F1 score of 3-4{\%}.",
}

