@article{1Cai2023,
	title = {{ChestXRayBERT}: {A} {Pretrained} {Language} {Model} for {Chest} {Radiology} {Report} {Summarization}},
	volume = {25},
	issn = {1941-0077},
	shorttitle = {{ChestXRayBERT}},
	url = {https://ieeexplore.ieee.org/document/9638337},
	doi = {10.1109/TMM.2021.3132724},
	journal = {IEEE Transactions on Multimedia},
	author = {Cai, Xiaoyan and Liu, Sen and Han, Junwei and Yang, Libin and Liu, Zhenguo and Liu, Tianming},
	year = {2023},
	keywords = {Radiology, Task analysis, Biomedical imaging, Decoding, Bit error rate, Biological system modeling, Transformers, Pre-trained language model, chest radiology report, abstractive summarization},
	pages = {845--855},
}

@article{2Hartung2020,
	title = {How to {Create} a {Great} {Radiology} {Report}},
	volume = {40},
	issn = {0271-5333, 1527-1323},
	url = {http://pubs.rsna.org/doi/10.1148/rg.2020200020},
	doi = {10.1148/rg.2020200020},
	language = {en},
	number = {6},
	urldate = {2024-10-15},
	journal = {RadioGraphics},
	author = {Hartung, Michael P. and Bickle, Ian C. and Gaillard, Frank and Kanne, Jeffrey P.},
	month = oct,
	year = {2020},
	pages = {1658--1670},
}

@article{3Herts2021,
	title = {Make {Even} {Greater} {Radiology} {Reports}},
	volume = {41},
	issn = {0271-5333, 1527-1323},
	url = {http://pubs.rsna.org/doi/10.1148/rg.2021210010},
	doi = {10.1148/rg.2021210010},
	language = {en},
	number = {3},
	urldate = {2024-10-15},
	journal = {RadioGraphics},
	author = {Herts, Brian R. and Berland, Lincoln L.},
	month = may,
	year = {2021},
	pages = {E92--E93},
}

@misc{4Rajagopal2022,
	title = {Creating a {Good} {Radiology} {Report} for {Physicians} and {Patients}},
	url = {https://www.medicaltranscriptionservicecompany.com/blog/how-to-document-a-good-radiology-report/},
	language = {en-US},
	author = {{Rajeev Rajagopal}},
	month = oct,
	year = {2022},
}

@inproceedings{5rush2015neural,
	address = {Lisbon, Portugal},
	title = {A {Neural} {Attention} {Model} for {Abstractive} {Sentence} {Summarization}},
	url = {https://aclanthology.org/D15-1044},
	doi = {10.18653/v1/D15-1044},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Rush, Alexander M. and Chopra, Sumit and Weston, Jason},
	editor = {Màrquez, Lluís and Callison-Burch, Chris and Su, Jian},
	month = sep,
	year = {2015},
	pages = {379--389},
}

@inproceedings{6chopra2016abstractive,
	address = {San Diego, California},
	title = {Abstractive {Sentence} {Summarization} with {Attentive} {Recurrent} {Neural} {Networks}},
	url = {https://aclanthology.org/N16-1012},
	doi = {10.18653/v1/N16-1012},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Chopra, Sumit and Auli, Michael and Rush, Alexander M.},
	editor = {Knight, Kevin and Nenkova, Ani and Rambow, Owen},
	month = jun,
	year = {2016},
	pages = {93--98},
}

@inproceedings{7tan2017abstractive,
	address = {Vancouver, Canada},
	title = {Abstractive {Document} {Summarization} with a {Graph}-{Based} {Attentional} {Neural} {Model}},
	url = {https://aclanthology.org/P17-1108},
	doi = {10.18653/v1/P17-1108},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Tan, Jiwei and Wan, Xiaojun and Xiao, Jianguo},
	editor = {Barzilay, Regina and Kan, Min-Yen},
	month = jul,
	year = {2017},
	pages = {1171--1181},
}

@inproceedings{8zhou2017selective,
	address = {Vancouver, Canada},
	title = {Selective {Encoding} for {Abstractive} {Sentence} {Summarization}},
	url = {https://aclanthology.org/P17-1101},
	doi = {10.18653/v1/P17-1101},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Zhou, Qingyu and Yang, Nan and Wei, Furu and Zhou, Ming},
	editor = {Barzilay, Regina and Kan, Min-Yen},
	month = jul,
	year = {2017},
	pages = {1095--1104},
}

@inproceedings{9li2017deep,
	address = {Copenhagen, Denmark},
	title = {Deep {Recurrent} {Generative} {Decoder} for {Abstractive} {Text} {Summarization}},
	url = {https://aclanthology.org/D17-1222},
	doi = {10.18653/v1/D17-1222},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Piji and Lam, Wai and Bing, Lidong and Wang, Zihao},
	editor = {Palmer, Martha and Hwa, Rebecca and Riedel, Sebastian},
	month = sep,
	year = {2017},
	pages = {2091--2100},
}

@inproceedings{10nallapati2016abstractive,
	address = {Berlin, Germany},
	title = {Abstractive {Text} {Summarization} using {Sequence}-to-sequence {RNNs} and {Beyond}},
	url = {https://aclanthology.org/K16-1028},
	doi = {10.18653/v1/K16-1028},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 20th {SIGNLL} {Conference} on {Computational} {Natural} {Language} {Learning}},
	publisher = {Association for Computational Linguistics},
	author={Nallapati, Ramesh and Zhou, Bowen and Gulcehre, Caglar and Xiang, Bing and others},
	editor = {Riezler, Stefan and Goldberg, Yoav},
	month = aug,
	year = {2016},
	pages = {280--290},
}

@inproceedings{11sutskever2014sequence,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'14},
	title = {Sequence to sequence learning with neural networks},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Neural} {Information} {Processing} {Systems} - {Volume} 2},
	publisher = {MIT Press},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	month = dec,
	year = {2014},
	pages = {3104--3112},
}

@inproceedings{12liu2019reading,
	address = {Florence, Italy},
	title = {Reading {Turn} by {Turn}: {Hierarchical} {Attention} {Architecture} for {Spoken} {Dialogue} {Comprehension}},
	shorttitle = {Reading {Turn} by {Turn}},
	url = {https://aclanthology.org/P19-1543},
	doi = {10.18653/v1/P19-1543},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Zhengyuan and Chen, Nancy},
	editor = {Korhonen, Anna and Traum, David and Màrquez, Lluís},
	month = jul,
	year = {2019},
	pages = {5460--5466},
}

@inproceedings{13karn2021few,
	address = {Kyiv, Ukraine},
	title = {Few-{Shot} {Learning} of an {Interleaved} {Text} {Summarization} {Model} by {Pretraining} with {Synthetic} {Data}},
	url = {https://aclanthology.org/2021.adaptnlp-1.24},
	booktitle = {Proceedings of the {Second} {Workshop} on {Domain} {Adaptation} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Karn, Sanjeev Kumar and Chen, Francine and Chen, Yan-Ying and Waltinger, Ulli and Schütze, Hinrich},
	editor = {Ben-David, Eyal and Cohen, Shay and McDonald, Ryan and Plank, Barbara and Reichart, Roi and Rotman, Guy and Ziser, Yftah},
	month = apr,
	year = {2021},
	pages = {245--254},
}

@article{14raffel2020exploring,
	title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
	volume = {21},
	issn = {1532-4435},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
	month = jan,
	year = {2020},
	pages = {140:5485--140:5551},
}

@misc{15kieuvongngam2020automatic,
	title = {Automatic {Text} {Summarization} of {COVID}-19 {Medical} {Research} {Articles} using {BERT} and {GPT}-2},
	url = {https://arxiv.org/abs/2006.01997v1},
	language = {en},
	journal = {arXiv.org},
	author = {Kieuvongngam, Virapat and Tan, Bowen and Niu, Yiming},
	month = jun,
	year = {2020},
}

@inproceedings{16chang2021jointly,
	address = {Online},
	title = {Jointly {Improving} {Language} {Understanding} and {Generation} with {Quality}-{Weighted} {Weak} {Supervision} of {Automatic} {Labeling}},
	url = {https://aclanthology.org/2021.eacl-main.69},
	doi = {10.18653/v1/2021.eacl-main.69},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Chang, Ernie and Demberg, Vera and Marin, Alex},
	editor = {Merlo, Paola and Tiedemann, Jorg and Tsarfaty, Reut},
	month = apr,
	year = {2021},
	pages = {818--829},
}

@inproceedings{17liu-etal-2021-noisy,
	address = {Online},
	title = {Noisy {Self}-{Knowledge} {Distillation} for {Text} {Summarization}},
	url = {https://aclanthology.org/2021.naacl-main.56},
	doi = {10.18653/v1/2021.naacl-main.56},
	booktitle = {Proceedings of the 2021 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Yang and Shen, Sheng and Lapata, Mirella},
	editor = {Toutanova, Kristina and Rumshisky, Anna and Zettlemoyer, Luke and Hakkani-Tur, Dilek and Beltagy, Iz and Bethard, Steven and Cotterell, Ryan and Chakraborty, Tanmoy and Zhou, Yichao},
	month = jun,
	year = {2021},
	pages = {692--703},
}

@inproceedings{18dong2021pointer,
	address = {Cham},
	title = {A {Pointer}-{Generator} {Based} {Abstractive} {Summarization} {Model} with {Knowledge} {Distillation}},
	isbn = {9783030923075},
	doi = {10.1007/978-3-030-92307-5_20},
	language = {en},
	booktitle = {Neural {Information} {Processing}},
	publisher = {Springer International Publishing},
	author = {Dong, Tao and Shan, Shimin and Liu, Yu and Qian, Yue and Ma, Anqi},
	editor = {Mantoro, Teddy and Lee, Minho and Ayu, Media Anugerah and Wong, Kok Wai and Hidayanto, Achmad Nizar},
	year = {2021},
	pages = {168--177},
}

@article{li_two-step_2021,
	title = {A two-step abstractive summarization model with asynchronous and enriched-information decoding},
	volume = {33},
	issn = {0941-0643, 1433-3058},
	url = {https://link.springer.com/10.1007/s00521-020-05005-3},
	doi = {10.1007/s00521-020-05005-3},
	language = {en},
	number = {4},
	urldate = {2024-10-15},
	journal = {Neural Computing and Applications},
	author = {Li, Shuaimin and Xu, Jungang},
	month = feb,
	year = {2021},
	pages = {1159--1170},
}

@misc{noauthor_enhancing_nodate,
	title = {Enhancing {Text} {Summarization} with a {T5} {Model} and {Bayesian} {Optimization} {\textbar} {IIETA}},
	url = {https://www.iieta.org/journals/ria/paper/10.18280/ria.370513},
	language = {en},
	urldate = {2024-10-15},
	doi = {10.18280/ria.370513},
}

@inproceedings{20zhang2018learning,
	address = {Brussels, Belgium},
	title = {Learning to {Summarize} {Radiology} {Findings}},
	url = {https://aclanthology.org/W18-5623},
	doi = {10.18653/v1/W18-5623},
	booktitle = {Proceedings of the {Ninth} {International} {Workshop} on {Health} {Text} {Mining} and {Information} {Analysis}},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Yuhao and Ding, Daisy Yi and Qian, Tianpei and Manning, Christopher D. and Langlotz, Curtis P.},
	editor = {Lavelli, Alberto and Minard, Anne-Lyse and Rinaldi, Fabio},
	month = oct,
	year = {2018},
	pages = {204--213},
}

@inproceedings{21macavaney2019ontology,
	address = {New York, NY, USA},
	series = {{SIGIR}'19},
	title = {Ontology-{Aware} {Clinical} {Abstractive} {Summarization}},
	isbn = {9781450361729},
	url = {https://dl.acm.org/doi/10.1145/3331184.3331319},
	doi = {10.1145/3331184.3331319},
	booktitle = {Proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {MacAvaney, Sean and Sotudeh, Sajad and Cohan, Arman and Goharian, Nazli and Talati, Ish and Filice, Ross W.},
	month = jul,
	year = {2019},
	pages = {1013--1016},
}

@inproceedings{22li2018hybrid,
	address = {Red Hook, NY, USA},
	series = {{NIPS}'18},
	title = {Hybrid retrieval-generation reinforced agent for medical image report generation},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Li, Christy Y. and Liang, Xiaodan and Hu, Zhiting and Xing, Eric P.},
	month = dec,
	year = {2018},
	pages = {1537--1547},
}

@misc{23liu2019clinically,
	title = {Clinically {Accurate} {Chest} {X}-{Ray} {Report} {Generation}},
	url = {https://arxiv.org/abs/1904.02633v2},
	language = {en},
	journal = {arXiv.org},
	author = {Liu, Guanxiong and Hsu, Tzu-Ming Harry and McDermott, Matthew and Boag, Willie and Weng, Wei-Hung and Szolovits, Peter and Ghassemi, Marzyeh},
	month = apr,
	year = {2019},
}

@inproceedings{25devlin2019bert,
	address = {Minneapolis, Minnesota},
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {https://aclanthology.org/N19-1423},
	doi = {10.18653/v1/N19-1423},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
	month = jun,
	year = {2019},
	pages = {4171--4186},
}

@inproceedings{26peters2018deep,
	address = {New Orleans, Louisiana},
	title = {Deep {Contextualized} {Word} {Representations}},
	url = {https://aclanthology.org/N18-1202},
	doi = {10.18653/v1/N18-1202},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
	editor = {Walker, Marilyn and Ji, Heng and Stent, Amanda},
	month = jun,
	year = {2018},
	pages = {2227--2237},
}

@incollection{27yang2019xlnet,
	address = {Red Hook, NY, USA},
	title = {{XLNet}: generalized autoregressive pretraining for language understanding},
	shorttitle = {{XLNet}},
	number = {517},
	booktitle = {Proceedings of the 33rd {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
	month = dec,
	year = {2019},
	pages = {5753--5763},
}

@article{28lee2020biobert,
	title = {{BioBERT}: a pre-trained biomedical language representation model for biomedical text mining},
	volume = {36},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1367-4803, 1367-4811},
	shorttitle = {{BioBERT}},
	url = {https://academic.oup.com/bioinformatics/article/36/4/1234/5566506},
	doi = {10.1093/bioinformatics/btz682},
	language = {en},
	number = {4},
	journal = {Bioinformatics},
	author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
	editor = {Wren, Jonathan},
	month = feb,
	year = {2020},
	pages = {1234--1240},
}

@article{31ma2020iterative,
	title = {An {Iterative} {Optimizing} {Framework} for {Radiology} {Report} {Summarization} {With} {ChatGPT}},
	volume = {5},
	issn = {2691-4581},
	url = {https://ieeexplore.ieee.org/document/10433180},
	doi = {10.1109/TAI.2024.3364586},
	number = {8},
	journal = {IEEE Transactions on Artificial Intelligence},
	author = {Ma, Chong and Wu, Zihao and Wang, Jiaqi and Xu, Shaochen and Wei, Yaonai and Liu, Zhengliang and Zeng, Fang and Jiang, Xi and Guo, Lei and Cai, Xiaoyan and Zhang, Shu and Zhang, Tuo and Zhu, Dajiang and Shen, Dinggang and Liu, Tianming and Li, Xiang},
	month = aug,
	year = {2024},
	keywords = {Radiology, Chatbots, Task analysis, Optimization, Semantics, Heuristic algorithms, Data models, ChatGPT, dynamic prompt, iterative optimization, radiology report summarization},
	pages = {4163--4175},
}

@inproceedings{32zhang2020pegasus,
	series = {{ICML}'20},
	title = {{PEGASUS}: pre-training with extracted gap-sentences for abstractive summarization},
	volume = {119},
	shorttitle = {{PEGASUS}},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {JMLR.org},
	author = {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J.},
	month = jul,
	year = {2020},
	pages = {11328--11339},
}

@incollection{33yang2019algorithms,
	title = {3 - {Optimization} algorithms},
	isbn = {9780128172162},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128172162000107},
	booktitle = {Introduction to {Algorithms} for {Data} {Mining} and {Machine} {Learning}},
	publisher = {Academic Press},
	author = {Yang, Xin-She},
	editor = {Yang, Xin-She},
	month = jan,
	year = {2019},
	doi = {10.1016/B978-0-12-817216-2.00010-7},
	keywords = {Algorithm, bat algorithm, cuckoo search, evolutionary algorithm, firefly algorithm, gradient-based method, Newton's method, stochastic gradient descent, swarm intelligence, particle swarm optimization, optimization},
	pages = {45--65},
}

@misc{mimic_cxr,
	title = {{MIMIC}-{CXR} {Database}},
	url = {https://physionet.org/content/mimic-cxr/2.1.0/},
	doi = {10.13026/4JQJ-JW95},
	publisher = {PhysioNet},
	author = {Johnson, Alistair and Pollard, Tom and Mark, Roger and Berkowitz, Seth and Horng, Steven},
    year={2024}
}

@inproceedings{35vaswani2017attention,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Ł ukasz and Polosukhin, Illia},
	year = {2017},
}

@misc{36jianmo2021survey,
	title = {A {Survey} on {Transformers} in {NLP} with {Focus} on {Efficiency}},
	url = {http://arxiv.org/abs/2406.16893},
	doi = {10.48550/arXiv.2406.16893},
	publisher = {arXiv},
	author = {Ansar, Wazib and Goswami, Saptarsi and Chakrabarti, Amlan},
	month = may,
	year = {2024},
	note = {arXiv:2406.16893 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
}

@inproceedings{37aigo2021question,
	title = {Question {Generation} using {Knowledge} {Graphs} with the {T5} {Language} {Model} and {Masked} {Self}-{Attention}},
	url = {https://ieeexplore.ieee.org/document/9621874},
	doi = {10.1109/GCCE53005.2021.9621874},
	booktitle = {2021 {IEEE} 10th {Global} {Conference} on {Consumer} {Electronics} ({GCCE})},
	author = {Aigo, Kosuke and Tsunakawa, Takashi and Nishida, Masafumi and Nishimura, Masafumi},
	month = oct,
	year = {2021},
	note = {ISSN: 2378-8143},
	keywords = {Codes, Conferences, Benchmark testing, Task analysis, Consumer electronics, Context modeling, KG2QG, Question generation, T5 language model},
	pages = {85--87},
}

@article{38kirkpatrick2017overcoming,
	title = {Overcoming catastrophic forgetting in neural networks},
	volume = {114},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1611835114},
	doi = {10.1073/pnas.1611835114},
	language = {en},
	number = {13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
	month = mar,
	year = {2017},
	pages = {3521--3526},
}

@inproceedings{46Lin2004,
	address = {Barcelona, Spain},
	title = {{ROUGE}: {A} {Package} for {Automatic} {Evaluation} of {Summaries}},
	shorttitle = {{ROUGE}},
	url = {https://aclanthology.org/W04-1013},
	urldate = {2024-10-15},
	booktitle = {Text {Summarization} {Branches} {Out}},
	publisher = {Association for Computational Linguistics},
	author = {Lin, Chin-Yew},
	month = jul,
	year = {2004},
	pages = {74--81},
}

@inproceedings{40papineni2002bleu,
	address = {Philadelphia, Pennsylvania, USA},
	title = {Bleu: a {Method} for {Automatic} {Evaluation} of {Machine} {Translation}},
	shorttitle = {Bleu},
	url = {https://aclanthology.org/P02-1040},
	doi = {10.3115/1073083.1073135},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 40th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	editor = {Isabelle, Pierre and Charniak, Eugene and Lin, Dekang},
	month = jul,
	year = {2002},
	pages = {311--318},
}

@article{41codish_model_ambiguity_2024,
	title = {A model of ambiguity and vagueness in clinical practice guideline recommendations},
	volume = {2005},
	issn = {1942-597X},
	language = {eng},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Codish, Shlomi and Shiffman, Richard N.},
	year = {2005},
	pmid = {16779019},
	pmcid = {PMC1560665},
	keywords = {Decision Making, Computer-Assisted, Fuzzy Logic, Humans, Linguistics, Practice Guidelines as Topic, Semantics, Terminology as Topic},
	pages = {146--150},
}

@misc{43Fazeela2024,
	title = {Understanding {Medical} {Reports} and {Results} from {Indian} {Hospitals}},
	url = {https://karetrip.com/blogs/understanding-medical-reports-and-results-from-indian-hospitals},
        author={Ashitha Kareem},
	language = {en},
        year={2024},
}

@article{44Christian2023,
	title = {Single {Document} {Automatic} {Text} {Summarization} using {Term} {Frequency}-{Inverse} {Document} {Frequency} ({TF}-{IDF})},
	volume = {7},
	copyright = {Copyright (c)},
	issn = {2476-907X},
	url = {https://journal.binus.ac.id/index.php/comtech/article/view/3746},
	doi = {10.21512/comtech.v7i4.3746},
	language = {en},
	number = {4},
	journal = {ComTech: Computer, Mathematics and Engineering Applications},
	author = {Christian, Hans and Agus, Mikhael Pramodana and Suhartono, Derwin},
	month = dec,
	year = {2016},
	keywords = {TF-IDF},
	pages = {285--294},
}

@article{45Laban2022,
	title = {{SummaC}: {Re}-{Visiting} {NLI}-based {Models} for {Inconsistency} {Detection} in {Summarization}},
	volume = {10},
	shorttitle = {{SummaC}},
	url = {https://aclanthology.org/2022.tacl-1.10},
	doi = {10.1162/tacl_a_00453},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Laban, Philippe and Schnabel, Tobias and Bennett, Paul N. and Hearst, Marti A.},
	editor = {Roark, Brian and Nenkova, Ani},
	year = {2022},
	pages = {163--177},
}

@article{19lubis2024enhancing,
	title = {Enhancing {Text} {Summarization} with a {T5} {Model} and {Bayesian} {Optimization}},
	volume = {37},
	issn = {0992499X, 19585748},
	url = {https://iieta.org/journals/ria/paper/10.18280/ria.370513},
	doi = {10.18280/ria.370513},
	number = {5},
	urldate = {2024-10-15},
	journal = {Revue d'Intelligence Artificielle},
	author = {Lubis, Arif Ridho and Safitri, Habibi Ramdani and {Irvan} and Lubis, Muharman and Hamzah, Muhammad Luthfi and Al-Khowarizmi, Al-Khowarizmi and Nugroho, Okvi},
	month = oct,
	year = {2023},
	pages = {1213--1219},
}

@misc{openi,
    author = {{National Library of Medicine}},
    title = { Open-i: An open access biomedical search engine},
    year = {2024},
    url = {https://openi.nlm.nih.gov},
}

@inproceedings{added1zhang-etal-2020-optimizing,
    title = "Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports",
    author = "Zhang, Yuhao  and
      Merck, Derek  and
      Tsai, Emily  and
      Manning, Christopher D.  and
      Langlotz, Curtis",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.458",
    doi = "10.18653/v1/2020.acl-main.458",
    pages = "5108--5120",
    abstract = "Neural abstractive summarization models are able to generate summaries which have high overlap with human references. However, existing models are not optimized for factual correctness, a critical metric in real-world applications. In this work, we develop a general framework where we evaluate the factual correctness of a generated summary by fact-checking it automatically against its reference using an information extraction module. We further propose a training strategy which optimizes a neural summarization model with a factual correctness reward via reinforcement learning. We apply the proposed method to the summarization of radiology reports, where factual correctness is a key requirement. On two separate datasets collected from hospitals, we show via both automatic and human evaluation that the proposed approach substantially improves the factual correctness and overall quality of outputs over a competitive neural summarization system, producing radiology summaries that approach the quality of human-authored ones.",
}
@inproceedings{added2hu-etal-2021-word,
    title = "Word Graph Guided Summarization for Radiology Findings",
    author = "Hu, Jinpeng  and
      Li, Jianling  and
      Chen, Zhihong  and
      Shen, Yaling  and
      Song, Yan  and
      Wan, Xiang  and
      Chang, Tsung-Hui",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.441",
    doi = "10.18653/v1/2021.findings-acl.441",
    pages = "4980--4990",
}
@inproceedings{added3hu-etal-2023-improving-radiology,
    title = "Improving Radiology Summarization with Radiograph and Anatomy Prompts",
    author = "Hu, Jinpeng  and
      Chen, Zhihong  and
      Liu, Yang  and
      Wan, Xiang  and
      Chang, Tsung-Hui",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.764",
    doi = "10.18653/v1/2023.findings-acl.764",
    pages = "12066--12080",
    abstract = "The impression is crucial for the referring physicians to grasp key information since it is concluded from the findings and reasoning of radiologists. To alleviate the workload of radiologists and reduce repetitive human labor in impression writing, many researchers have focused on automatic impression generation. However, recent works on this task mainly summarize the corresponding findings and pay less attention to the radiology images. In clinical, radiographs can provide more detailed valuable observations to enhance radiologists{'} impression writing, especially for complicated cases. Besides, each sentence in findings usually focuses on single anatomy, such that they only need to be matched to corresponding anatomical regions instead of the whole image, which is beneficial for textual and visual features alignment. Therefore, we propose a novel anatomy-enhanced multimodal model to promote impression generation. In detail, we first construct a set of rules to extract anatomies and put these prompts into each sentence to highlight anatomy characteristics. Then, two separate encoders are applied to extract features from the radiograph and findings. Afterward, we utilize a contrastive learning module to align these two representations at the overall level and use a co-attention to fuse them at the sentence level with the help of anatomy-enhanced sentence representation. The experimental results on two benchmark datasets confirm the effectiveness of the proposed method, which achieves state-of-the-art results.",
}
@inproceedings{added4sotudeh-gharebagh-etal-2020-attend,
    title = "Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization",
    author = "Sotudeh Gharebagh, Sajad  and
      Goharian, Nazli  and
      Filice, Ross",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.172",
    doi = "10.18653/v1/2020.acl-main.172",
    pages = "1899--1905",
    abstract = "Sequence-to-sequence (seq2seq) network is a well-established model for text summarization task. It can learn to produce readable content; however, it falls short in effectively identifying key regions of the source. In this paper, we approach the content selection problem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer. Our experiments on two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and 3,366 reports of OpenI) show that our model statistically significantly boosts state-of-the-art results in terms of ROUGE metrics (with improvements: 2.9{\%} RG-1, 2.5{\%} RG-2, 1.9{\%} RG-L), in the healthcare domain where any range of improvement impacts patients{'} welfare.",
}
@inproceedings{added5hu-etal-2022-graph,
    title = "Graph Enhanced Contrastive Learning for Radiology Findings Summarization",
    author = "Hu, Jinpeng  and
      Li, Zhuo  and
      Chen, Zhihong  and
      Li, Zhen  and
      Wan, Xiang  and
      Chang, Tsung-Hui",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.320",
    doi = "10.18653/v1/2022.acl-long.320",
    pages = "4677--4688",
    abstract = "The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians. Summarizing findings is time-consuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention. With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information). Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings. To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation. In detail, for each input findings, it is encoded by a text encoder and a graph is constructed through its entities and dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph. Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words). The experimental results on two datasets, OpenI and MIMIC-CXR, confirm the effectiveness of our proposed method, where the state-of-the-art results are achieved.",
}
@inproceedings{added6karn-etal-2022-differentiable,
    title = "Differentiable Multi-Agent Actor-Critic for Multi-Step Radiology Report Summarization",
    author = "Karn, Sanjeev Kumar  and
      Liu, Ning  and
      Schuetze, Hinrich  and
      Farri, Oladimeji",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.109",
    doi = "10.18653/v1/2022.acl-long.109",
    pages = "1542--1553",
    abstract = "The IMPRESSIONS section of a radiology report about an imaging study is a summary of the radiologist{'}s reasoning and conclusions, and it also aids the referring physician in confirming or excluding certain diagnoses. A cascade of tasks are required to automatically generate an abstractive summary of the typical information-rich radiology report. These tasks include acquisition of salient content from the report and generation of a concise, easily consumable IMPRESSIONS section. Prior research on radiology report summarization has focused on single-step end-to-end models {--} which subsume the task of salient content acquisition. To fully explore the cascade structure and explainability of radiology report summarization, we introduce two innovations. First, we design a two-step approach: extractive summarization followed by abstractive summarization. Second, we additionally break down the extractive part into two independent tasks: extraction of salient (1) sentences and (2) keywords. Experiments on English radiology reports from two clinical sites show our novel approach leads to a more precise summary compared to single-step and to two-step-with-single-extractive-process baselines with an overall improvement in F1 score of 3-4{\%}.",
}
@misc{extrazhao2024improvingexpertradiologyreport,
      title={Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary}, 
      author={Xingmeng Zhao and Tongnian Wang and Anthony Rios},
      year={2024},
      eprint={2406.14500},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.14500}, 
}


@article{addedextraLiu2023RadiologyLlama2BL,
  title={Radiology-Llama2: Best-in-Class Large Language Model for Radiology},
  author={Zheng Liu and Yiwei Li and Peng Shu and Aoxiao Zhong and Longtao Yang and Chao Ju and Zihao Wu and Chong-Yi Ma and Jie Luo and Cheng Chen and Sekeun Kim and Jiang Hu and Haixing Dai and Lin Zhao and Dajiang Zhu and Jun Liu and W. Liu and Dinggang Shen and Tianming Liu and Quanzheng Li and Xiang Li},
  journal={ArXiv},
  year={2023},
  volume={abs/2309.06419},
  url={https://api.semanticscholar.org/CorpusID:261696494}
}
@misc{addedextrashi2024mghradiologyllamallama,
      title={MGH Radiology Llama: A Llama 3 70B Model for Radiology}, 
      author={Yucheng Shi and Peng Shu and Zhengliang Liu and Zihao Wu and Quanzheng Li and Xiang Li},
      year={2024},
      eprint={2408.11848},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.11848}, 
}
@misc{addedextrazhao2024improvingexpertradiologyreport,
      title={Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary}, 
      author={Xingmeng Zhao and Tongnian Wang and Anthony Rios},
      year={2024},
      eprint={2406.14500},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.14500}, 
}


@ARTICLE{50-9933427,
  author={Wang, Meng and Wang, Qiang and Liu, Haipeng},
  journal={IEEE Access}, 
  title={CLFM: Few-Shot Object Detection via Low-Resource Contrastive Learning and Fisher Matrix Updating for Overcoming Catastrophic Forgetting}, 
  year={2022},
  volume={10},
  number={},
  pages={115307-115321},
  keywords={Learning systems;Encoding;Training data;Object detection;Visualization;Power capacitors;Detectors;Information analysis;Information integrity;Few-shot object detection;contrastive learning;overcoming catastrophic forgetting},
  doi={10.1109/ACCESS.2022.3218464}}

@article{51-michel2019regularizing,
  title={Regularizing trajectories to mitigate catastrophic forgetting},
  author={Michel, Paul and Salesky, Elisabeth and Neubig, Graham},
  year={2019}
}

@article{52-gupta2021addressing,
  title={Addressing catastrophic forgetting for medical domain expansion},
  author={Gupta, Sharut and Singh, Praveer and Chang, Ken and Qu, Liangqiong and Aggarwal, Mehak and Arun, Nishanth and Vaswani, Ashwin and Raghavan, Shruti and Agarwal, Vibha and Gidwani, Mishka and others},
  journal={arXiv preprint arXiv:2103.13511},
  year={2021}
}

@article{53-kutalev2020natural,
  title={Natural way to overcome the catastrophic forgetting in neural networks},
  author={Kutalev, Alexey},
  journal={arXiv preprint arXiv:2005.07107},
  year={2020}
}
@inproceedings{54-liu2018rotate,
  title={Rotate your networks: Better weight consolidation and less catastrophic forgetting},
  author={Liu, Xialei and Masana, Marc and Herranz, Luis and Van de Weijer, Joost and Lopez, Antonio M and Bagdanov, Andrew D},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)},
  pages={2262--2268},
  year={2018},
  organization={IEEE}
}

@article{55-ritter2018online,
  title={Online structured laplace approximations for overcoming catastrophic forgetting},
  author={Ritter, Hippolyt and Botev, Aleksandar and Barber, David},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{56-kemker2018measuring,
  title={Measuring catastrophic forgetting in neural networks},
  author={Kemker, Ronald and McClure, Marc and Abitino, Angelina and Hayes, Tyler and Kanan, Christopher},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}
@inproceedings{57-10.1145/3503181.3503211,
author = {Meng, Hefeng and Lin, Zhiqiang and Yang, Fan and Xu, Yonghui and Cui, Lizhen},
title = {Knowledge Distillation In Medical Data Mining: A Survey},
year = {2022},
isbn = {9781450395540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503181.3503211},
doi = {10.1145/3503181.3503211},
abstract = {In recent years, there have always been many problems in the medical field, such as a shortage of professionals and a shortage of medical resources. With the application of machine learning in the medical field, these problems have been alleviated to a certain extent, but these machine learning methods also have shortcomings, such as models are often too large to be deployed on lightweight equipment, and medical data sets are difficult to share, Many researchers have put forward many methods, and knowledge distillation is one of them. As a model compression and acceleration technology, knowledge distillation has been widely used in the medical field. The research of many researchers also shows that the use of knowledge distillation can effectively compress huge and complex models and improve the performance of models. Many studies show that the use of knowledge distillation can effectively solve many problems existing in models in the medical field, Aiming at the various applications of knowledge distillation in the medical field, this paper makes a comprehensive review from the perspectives of knowledge distillation, the problems that knowledge distillation can solve in the medical field and the practical application of knowledge distillation.},
booktitle = {5th International Conference on Crowd Science and Engineering},
pages = {175–182},
numpages = {8},
keywords = {Knowledge distillation, Medical diagnosis, Medical image classification, Model compression},
location = {Jinan, China},
series = {ICCSE '21}
}

@article{58che2015distilling,
  title={Distilling knowledge from deep networks with applications to healthcare domain},
  author={Che, Zhengping and Purushotham, Sanjay and Khemani, Robinder and Liu, Yan},
  journal={arXiv preprint arXiv:1512.03542},
  year={2015}
}
@article{59liu2020noisy,
  title={Noisy self-knowledge distillation for text summarization},
  author={Liu, Yang and Shen, Sheng and Lapata, Mirella},
  journal={arXiv preprint arXiv:2009.07032},
  year={2020}
}
@article{60santhosh2023understanding,
  title={Understanding BLEU and ROUGE score for NLP evaluation},
  author={Santhosh, S},
  journal={Medium. URL: https://medium. com/@ sthanikamsanthosh1994/understanding-bleu-and-rouge-sc ore-for-nlp-evaluation-1ab334ecadcb (date of access: 15.05. 2024)},
  year={2023}
}
@article{61ibrahim2023systematic,
  title={A SYSTEMATIC REVIEW ON TEXT SUMMARIZATION OF MEDICAL RESEARCH ARTICLES},
  author={Ibrahim, Alshimaa M and Alfonse, Marco and Aref, M},
  journal={International Journal of Intelligent Computing and Information Sciences},
  volume={23},
  number={2},
  pages={50--61},
  year={2023},
  publisher={Ain Shams University, Faculty of Computer and Information Science}
}
@article{62centers2016everyday,
  title={Everyday words for public health communication},
  author={Centers for Disease Control and Prevention and others},
  journal={Atlanta: CDC},
  year={2016}
}
@article{63khorasani2003terminology,
  title={Is terminology used effectively to convey diagnostic certainty in radiology reports?},
  author={Ramin Khorasani and David W Bates and Susan Teeger and Jeffrey M Rothschild and Douglas F Adams and Steven E Seltzer},
  journal={Journal of the American College of Radiology},
  volume={1},
  number={7},
  pages={457-460},
  year={2003},
  doi={10.1016/s1076-6332(03)80089-2},
  pmid={12809424}
}
@article{64panicek2016sure,
  title={How Sure Are You, Doctor? A Standardized Lexicon to Describe the Radiologist's Level of Certainty},
  author={David M Panicek and Hedvig Hricak},
  journal={AJR American Journal of Roentgenology},
  volume={207},
  number={1},
  pages={2-3},
  year={2016},
  doi={10.2214/AJR.15.15895},
  pmid={27065212},
  eprint={2016 Apr 11}
}
