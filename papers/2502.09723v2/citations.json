[
  {
    "index": 0,
    "papers": [
      {
        "key": "DBLP:conf/emnlp/LiGFXHMS23",
        "author": "Haoran Li and\nDadi Guo and\nWei Fan and\nMingshi Xu and\nJie Huang and\nFanpu Meng and\nYangqiu Song",
        "title": "Multi-step Jailbreaking Privacy Attacks on ChatGPT"
      },
      {
        "key": "DBLP:conf/ccs/ShenC0SZ24",
        "author": "Xinyue Shen and\nZeyuan Chen and\nMichael Backes and\nYun Shen and\nYang Zhang",
        "title": "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak\nPrompts on Large Language Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "ARCA",
        "author": "Erik Jones and\nAnca D. Dragan and\nAditi Raghunathan and\nJacob Steinhardt",
        "title": "Automatically Auditing Large Language Models via Discrete Optimization"
      },
      {
        "key": "DBLP:conf/icml/JonesDRS23",
        "author": "Erik Jones and\nAnca D. Dragan and\nAditi Raghunathan and\nJacob Steinhardt",
        "title": "Automatically Auditing Large Language Models via Discrete Optimization"
      },
      {
        "key": "gao2024denial",
        "author": "Gao, Kuofeng and Pang, Tianyu and Du, Chao and Yang, Yong and Xia, Shu-Tao and Lin, Min",
        "title": "Denial-of-Service Poisoning Attacks against Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "PsySafe",
        "author": "Zaibin Zhang and\nYongting Zhang and\nLijun Li and\nJing Shao and\nHongzhi Gao and\nYu Qiao and\nLijun Wang and\nHuchuan Lu and\nFeng Zhao",
        "title": "PsySafe: {A} Comprehensive Framework for Psychological-based Attack,\nDefense, and Evaluation of Multi-agent System Safety"
      },
      {
        "key": "DBLP:journals/corr/abs-2311-03348",
        "author": "Rusheb Shah and\nQuentin Feuillade{-}Montixi and\nSoroush Pour and\nArush Tagade and\nStephen Casper and\nJavier Rando",
        "title": "Scalable and Transferable Black-Box Jailbreaks for Language Models\nvia Persona Modulation"
      },
      {
        "key": "DBLP:conf/iclr/LiuXCX24",
        "author": "Xiaogeng Liu and\nNan Xu and\nMuhao Chen and\nChaowei Xiao",
        "title": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language\nModels"
      },
      {
        "key": "DBLP:journals/corr/abs-2410-10700",
        "author": "Qibing Ren and\nHao Li and\nDongrui Liu and\nZhanxu Xie and\nXiaoya Lu and\nYu Qiao and\nLei Sha and\nJunchi Yan and\nLizhuang Ma and\nJing Shao",
        "title": "Derail Yourself: Multi-turn {LLM} Jailbreak Attack through Self-discovered\nClues"
      },
      {
        "key": "cipherchat",
        "author": "Youliang Yuan and\nWenxiang Jiao and\nWenxuan Wang and\nJen{-}tse Huang and\nPinjia He and\nShuming Shi and\nZhaopeng Tu",
        "title": "{GPT-4} Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher"
      },
      {
        "key": "Multilingual",
        "author": "Yue Deng and\nWenxuan Zhang and\nSinno Jialin Pan and\nLidong Bing",
        "title": "Multilingual Jailbreak Challenges in Large Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "codeattack",
        "author": "Qibing Ren and\nChang Gao and\nJing Shao and\nJunchi Yan and\nXin Tan and\nWai Lam and\nLizhuang Ma",
        "title": "CodeAttack: Revealing Safety Generalization Challenges of Large Language\nModels via Code Completion"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "codechameleon",
        "author": "Huijie Lv and\nXiao Wang and\nYuansen Zhang and\nCaishuang Huang and\nShihan Dou and\nJunjie Ye and\nTao Gui and\nQi Zhang and\nXuanjing Huang",
        "title": "CodeChameleon: Personalized Encryption Framework for Jailbreaking\nLarge Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "RLHF",
        "author": "Paul F. Christiano and\nJan Leike and\nTom B. Brown and\nMiljan Martic and\nShane Legg and\nDario Amodei",
        "title": "Deep Reinforcement Learning from Human Preferences"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "DBLP:conf/emnlp/MehrabiGDHGZCG024",
        "author": "Ninareh Mehrabi and\nPalash Goyal and\nChristophe Dupuy and\nQian Hu and\nShalini Ghosh and\nRichard S. Zemel and\nKai{-}Wei Chang and\nAram Galstyan and\nRahul Gupta",
        "title": "{FLIRT:} Feedback Loop In-context Red Teaming"
      },
      {
        "key": "Self-Alignment",
        "author": "Zhiqing Sun and\nYikang Shen and\nQinhong Zhou and\nHongxin Zhang and\nZhenfang Chen and\nDavid D. Cox and\nYiming Yang and\nChuang Gan",
        "title": "Principle-Driven Self-Alignment of Language Models from Scratch with\nMinimal Human Supervision"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "o1",
        "author": "OpenAI",
        "title": "Learning to Reason with LLMs"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2310-06387",
        "author": "Zeming Wei and\nYifei Wang and\nYisen Wang",
        "title": "Jailbreak and Guard Aligned Language Models with Only Few In-Context\nDemonstrations"
      },
      {
        "key": "DBLP:conf/acl/RenG0LZQL24",
        "author": "Jie Ren and\nQipeng Guo and\nHang Yan and\nDongrui Liu and\nQuanshi Zhang and\nXipeng Qiu and\nDahua Lin",
        "title": "Identifying Semantic Induction Heads to Understand In-Context Learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "paraphrase",
        "author": "Neel Jain and\nAvi Schwarzschild and\nYuxin Wen and\nGowthami Somepalli and\nJohn Kirchenbauer and\nPing{-}yeh Chiang and\nMicah Goldblum and\nAniruddha Saha and\nJonas Geiping and\nTom Goldstein",
        "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language\nModels"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "SafeDecoding",
        "author": "Zhangchen Xu and\nFengqing Jiang and\nLuyao Niu and\nJinyuan Jia and\nBill Yuchen Lin and\nRadha Poovendran",
        "title": "SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware\nDecoding"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "SmoothLLM",
        "author": "Alexander Robey and\nEric Wong and\nHamed Hassani and\nGeorge J. Pappas",
        "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks"
      },
      {
        "key": "SelfDefense",
        "author": "Mansi Phute and\nAlec Helbling and\nMatthew Hull and\nShengyun Peng and\nSebastian Szyller and\nCory Cornelius and\nDuen Horng Chau",
        "title": "{LLM} Self Defense: By Self Examination, LLMs Know They Are Being\nTricked"
      },
      {
        "key": "DBLP:journals/corr/abs-2309-00614",
        "author": "Neel Jain and\nAvi Schwarzschild and\nYuxin Wen and\nGowthami Somepalli and\nJohn Kirchenbauer and\nPing{-}yeh Chiang and\nMicah Goldblum and\nAniruddha Saha and\nJonas Geiping and\nTom Goldstein",
        "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language\nModels"
      },
      {
        "key": "gao2024embedding",
        "author": "Gao, Kuofeng and Cai, Huanqia and Shuai, Qingyao and Gong, Dihong and Li, Zhifeng",
        "title": "Embedding self-correction as an inherent ability in large language models for enhanced mathematical reasoning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "o1",
        "author": "OpenAI",
        "title": "Learning to Reason with LLMs"
      }
    ]
  }
]