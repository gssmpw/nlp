\section{Related Work}
\label{sec: related_work}
\xhdr{Deep Learning on Relational Data} 
Several works have explored the use of GNNs for learning on relational data ~\citep{schlichtkrull2018relational, cvitkovic2020supervisedrd, vsir2021deep, zahradnik2023deep}. These works investigated different GNN architectures that utilize the relational structure. More recently, \citet{fey2023relational} introduced Relational Deep Learning (RDL) (see Sec. \ref{sec:rdl}), establishing a new subfield of machine learning. RDL has enabled various research opportunities, such as advancements in relational graph construction algorithms, GNN architectures, and task-specific prediction heads. \citet{yuan2024contextgnn} focused on improving task-specific prediction heads for recommendation tasks, addressing limitations in the currently employed two-tower and pair-wise prediction heads. In contrast, our work focuses on improving GNN architectures applied to all task types to generate node embeddings, offering an orthogonal contribution. In addition to GNNs, \citet{wydmuch2024tackling} proposed leveraging large language models (LLMs) to address predictive tasks in RDL. 
\xhdr{Distinction Between RDL and Knowledge Graphs} 
The literature of knowledge graphs ~\citep{{bordes2013translating,wang2014knowledge,wang2017knowledge}} differs from RDL in terms of the tasks being tackled. Knowledge graph models mainly focus on \emph{completion} tasks like predicting missing entities (e.g., Q: Who is the author of "Harry Potter"? A: J.K. Rowling) or missing relationships (Q: Did Yoshua Bengio win a Turing Award? A: Yes). 
In contrast, RDL focuses on making \emph{predictions} about entities or groups of entities (e.g., Will a customer churn in the next month? How much will a customer spend in the upcoming week?)