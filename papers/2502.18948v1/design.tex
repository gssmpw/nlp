
% Having presented the problem setting considered in this paper, including the attack strategy that the defense chosen as a worst-case for design purposes, in this section the design problem is formulated, an algorithm for its solution outlined, and its properties analysed.

\subsection{Design problem}
As summarized in Problem~\ref{problem_main}, the objective of the parameter design is to \textit{minimize the maximum performance loss caused by the adversary.} 
This can be translated, exploiting \eqref{eq:o2o}, to the following optimization problem
\begin{align}\label{eq:o2o:problem}
    \inf_{\theta^+} \mathcal{L}(\theta^+,\theta^a)
\end{align}
\begin{equation}\label{p1}
\mathcal{L}(\theta^+,\theta^a) =
 \left\{    \begin{aligned}
    \sup_{\varphi_u \in\ell_{2e}} & \; \|y_J\|_{\ell_2}^2 \\
		\text{s.t.} &\; \|y_r\|_{\ell_2}^2  \leq \epsilon_r,\; \|\varphi_u\|_{\ell_2}^2 \leq \epsilon_a,\\
                    &\; x[0] = 0, \eqref{eq:WM:stab}, \eqref{eq:WM:def},\eqref{eq:atk:cov},\eqref{eq:S_cl} 
\end{aligned}\right.
\end{equation}

In \eqref{eq:o2o:problem}, $\mathcal{L}(\theta^+,\theta^a)$ represents the value of the maximum performance loss caused by the adversary for any given pair of filters $(\theta^+,\theta^a)$.
The optimization problem \eqref{eq:o2o:problem} is an infinite optimization problem in signal space. Using \cite[Lem 3.1, Lem 3.2]{anand2023risk}, \eqref{eq:o2o:problem} is converted to an equivalent, finite-dimensional, non-convex optimization problem in Lemma \ref{lem:sig_2_mat}.
\begin{lemma}\label{lem:sig_2_mat}
The infinite-dimensional optimization problem \eqref{eq:o2o:problem} is equivalent to the following finite-dimensional, non-convex optimization problem
% The optimization problems \eqref{eq:o2o:problem} and \eqref{o1} are equivalent.
\begin{equation}\label{o1}
\begin{aligned}
\inf_{P,\gamma,\gamma_a,\theta^+,Z_\sigma} & \;\epsilon_r\gamma +\epsilon_a\gamma_a \\
\mathrm{s.t.} \;~ & R+\begin{bmatrix}
    \bar{C}_J^\top \bar{C}_J-\gamma \bar{C}_r^\top \bar{C}_r & \bar{C}_J^\top \bar{D}_J\\
    \bar{D}_J^\top \bar{C}_J & \bar{D}_J^\top \bar{D}_J^\top -\gamma_aI_{m}
\end{bmatrix} \preceq 0\\
% & A_g=A_h-B_hD_h^{-1}C_h, \; A_w=A_q-B_qD_q^{-1}C_q\\
% & B_g=-B_hD_h^{-1},\; C_g=D_h^{-1}C_h,\; D_g=D_h^{-1}\\
% & B_w=-B_qD_q^{-1},\; C_w=D_q^{-1}C_q,\; D_w=D_q^{-1}\\
& \eqref{eq:WM:stab}, \eqref{eq:WM:def}, \gamma \geq 0, \gamma_a \geq 0, P \succeq 0, Z_\sigma \succ 0,
\end{aligned}
\end{equation} 
where %$\mathcal{P} \triangleq \{P,\gamma, A_h,B_h,C_h,D_h,A_q,B_q,C_q,D_q\}$, 
$R \triangleq \begin{bmatrix}
    A^\top PA-P & A^\top PB\\B^\top PA & B^\top PB
\end{bmatrix}$.
$\hfill \square$  
\end{lemma}
Finding a solution to \eqref{o1} solves Problem~\ref{problem_main}, as solving for $\theta^+$ achieves the minimal worst-case impact of a covert attack satisfying Assumption~\ref{ass:param}. Although \eqref{o1} is convex in $P,\gamma$ and $\gamma_a$, it contains non-convex terms in $A$.
As such, it cannot be easily solved via standard convex solvers \citep{lofberg2004yalmip}. %Next we discuss the well-posedness of \eqref{o1} (or, equivalently, of \eqref{eq:o2o:problem}).

\subsection{Well-posedness of the impact metric \eqref{eq:o2o:problem}}
Differently to our previous results~\citep{gallo2021design}, using the AEC-OOG ensures that the optimization problem used for the design of the mWM parameters is always feasible, as summarized in the following.

% The modified OOG used to formulate \eqref{eq:o2o:problem}
% was initially proposed in \cite{anand2023risk}. 
% \ajg{This metric, as shown in the following result, ensures that the optimization problem used for design of the mWM parameters is always feasible.}

\begin{theorem}\label{thm:well:posed}
Let the parameters $\theta^{+}$ be chosen such that \eqref{eq:WM:stab}, \eqref{eq:WM:def}, and Assumption \ref{ass:stable} hold. 
Then, the value of the metric $\mathcal{L}$ in \eqref{p1} is bounded if the closed-loop matrix $A$ in \eqref{eq:S_cl} is Schur stable. 
$\hfill \square$
\end{theorem}

\begin{pf} 
Let $\Sigma_J \triangleq (A,B,\bar{C}_J,\bar{D}_J)$ be the closed loop system from the attack input $\varphi_u$ to the performance output $y_J$. The objective is to show that the value of \eqref{p1} is bounded given Assumption \ref{ass:stable}, and for any given value of $\theta^+$ that satisfies \eqref{eq:WM:stab} and \eqref{eq:WM:def}. To this end, start by considering the optimization problem \eqref{p1} without the constraint $||y_r||_{\ell_2}^2 \leq \epsilon_r$. %as follows
%     \begin{equation}\label{eq:OOG}
% \bar{\mathcal{L}} \triangleq \left\{
% \begin{aligned}
%     \sup_{\varphi_u \in\ell_{2e}} & \; \|y_J\|_{\ell_2}^2 \\
% 		\text{s.t.} &\; \|\varphi_u\|_{\ell_2}^2  \leq \epsilon_a,\;x[0] = 0 
% \end{aligned}\right\}.
% \end{equation}
The value of the resulting optimization problem is the $H_{\infty}$ gain of the system $\Sigma_J$, which is bounded, so long as $\Sigma_J$ is stable. Thus, \eqref{p1} is bounded, as the optimal value of any maximization problem cannot increase under additional constraints.
% Thus \eqref{p1} without the detection constraint is guaranteed to be bounded. The remainder of the proof follows from the observation that, for any optimization problem whose aim is to maximize the objective, the optimal value cannot increase in the presence of additional constraints. 
% This concludes the proof.
$\hfill\blacksquare$
\end{pf}
The condition of $A$ being stable is required only at any given time $k \in \mathbb N$, and not under switching. The problem of ensuring $A$ is stable under switching is addressed in \cite[Thm. 3]{ferrari2020switching}.

% \begin{remark}
%     In \eqref{p1}, $\epsilon_r$ and $\epsilon_a$ play in a critical role.
%     Firstly, the metric is always bounded, as is demonstrated in Theorem~\ref{thm:well:posed} and thus is well-posed for a design algorithm. 
%     %
%     Furthermore, it has explicit relations to both the $H_\infty$ metric (for increasing values of $\epsilon_r$) and to the original OOG (for increasing values of $\epsilon_a$ \citep[Prop.1]{anand2023risk}.
%     %
%     Finally, let us comment on the constraint on the attack energy, and argue that the choice of $\epsilon_a$ as a design parameter, to be chosen by the defender, rather than an assumpiton on the attack strategy is warranted. To do this, we consider \eqref{p1} (which is equivalent to \eqref{o1}, under Lemma~\ref{lem:sig_2_mat}) under increasing values of $\epsilon_a$, as well as the OOG as defined in \cite{teixeira2015strategic}.
%     If there are no zero dynamics in the system, the OOG is finite, and thus there is some value $\bar\epsilon_a$ such that, for all $\epsilon_a > \bar\epsilon_a$, the value of $\|y_r\|_{\ell_2}^2 = \epsilon_r$, and $\|y_J\|_{\ell_2}^2$ remains constant. Thus, defining $\epsilon_a \geq \bar \epsilon_a$, the optimal value $\theta^{+*}$ is not influenced by the constraint on the attack energy.
%     On the other hand, if there are zero dynamics that the attacker can exploit, the OOG is infinite, and $\|y_J\|_{\ell_2}^2$ grows unbounded as $\epsilon_a \rightarrow \infty$.
%     Thus, while $\theta^{+*}$, the solution to \eqref{o1}, is only optimal for $\|\varphi_u\| \leq \epsilon_a$, defining $\theta^*$ ensures the effect of $\varphi_u$ on $y_J$ is in some sense minimal if this is not the case.
%     % if the constraint is violated, defining $\theta^*$ ensures that the effect of an attack with unbounded energy on the performance output is in some sense minimal.
%     $\hfill\triangleleft$
% \end{remark}


%Furthermore, Theorem~\ref{thm:well:posed} demonstrates the merits of adopting the AEC-OOG~\eqref{eq:o2o:problem}: the metric is always bounded, and thus well posed for a design algorithm; it has explicit relations to both the $H_\infty$ metric (for increasing values of $\epsilon_r$), and to the original OOG (for increasing values of $\epsilon_a$) \citep[Prop.1]{anand2023risk}.


\subsection{Filter parameter update algorithm}\label{ch:design:algo}
As mentioned previously, the optimization problem \eqref{o1} is non-convex and cannot be solved exactly. %Although designing an approximate solution to problem~\eqref{o1} is out of the scope of this paper, we provide a preliminary algorithm to solve it. 
One approach to solve \eqref{o1} is to reformulate the problem with Bi-linear Matrix inequalities (BMI) and use some existing approaches in the literature to solve them (e.g., \cite{gallo2021design,dehnert2021less,dinh2011combining}, etc.), which however come with drawbacks. In light of this, here an exhaustive search algorithm, defined in Algorithm~\ref{algo2}, is adopted, to show the main advantage of the proposed design problem \eqref{o1}.
% The main reason for this choice is to depict the advantage of the the proposed design problem \eqref{o1}, as there are no known algorithms to find its exact solutions, and standard convexification techniques do not apply, due to bilinearity of parameters in \eqref{matrix_strip}.
%
% Because of this, it cannot help depict the merits of the proposed design problem.
%
% \ajg{Furthermore, standard techniques to convexify \eqref{o1} are not of use, as the bilinearity in the decision variables appear in the system matrices~\eqref{matrix_strip}.}
% Developing an algorithm for \eqref{o1} and discussing its merits is left for future work. 

The exhaustive search algorithm we proposed can be sketched out as follows. Let the values of all matrices be chose \textit{a priori}, apart from $A_\sigma$, such that they satisfy \eqref{eq:WM:def}.
Thus, the objective is to find optimal values of $A_\sigma$ minimizing \eqref{o1}. Furthermore, to ensure tractability, let us restrict the matrices $A_\sigma$ to be diagonal. To guarantee stability of the watermark generating matrices, it is sufficient to constrain the diagonal elements to lie in $(-1,1)$.
Discretizing this set into a grid of $n_s$ elements, $\mathcal A_h$ and $\mathcal A_q$ can be obtained, with cardinality $n_s^{n_h}$ and $n_s^{n_q}$, respectively.
Thus, the exhaustive search algorithm searches for optimal matrices $A_h, A_q$, under the constraint \eqref{eq:WM:def}.
The complete algorithm is summarized in Algorithm~\ref{algo2}, where the final step provides an ordering, in case multiple parameters obtain the same optimum.

% The main idea behind the exhaustive search algorithm is as follows. Let us \textit{a priori} choose the values of all matrices (such that they obey \eqref{eq:WM:def}) except  $A_g$, $A_w$, $A_h$, and $A_q$. 
% The objective is to find the optimal matrices $A_g, A_h \in \mathbb{R}^{h \times h}$ and $A_w, A_q \in \mathbb{R}^{q \times q}$ such the value of \eqref{o1} is minimized. 
% To this end, let us construct the set of all stable matrices $A_h$ (say $\mathcal{A}_h$) and $A_q$ ($\mathcal{A}_q$). In general, constructing this set $\mathcal{A}_h$ and $\mathcal{A}_q$ is not possible since it is a dense set. Thus the matrices are restricted to being diagonal.
% To ensure that the matrices are stable, it is sufficient to ensure that the diagonal elements lie in the set $(-1,1)$. 
% Discretizing the set $(-1,1)$ into grids with $n_s$ elements, the set $\mathcal{A}_h\, (\mathcal{A}_q)$ can be obtained with cardinality $n_s^g \, (n_s^w)$. Then, the exhaustive search algorithm searches for the matrix from the sets $\mathcal{A}_h \, (\mathcal{A}_q)$ under the constraint \eqref{eq:WM:def} minimizing the objective function \eqref{o1}. \ajg{The final step of Algorithm~\ref{algo2} ensures that the algorithm is capable of discriminating between different parameters giving the same value of the objective function \eqref{o1}.}

% Although defined a priori, the values of the matrices $D_{\sigma}$ can be altered to promote randomness in the selection of $\theta^+$, a characteristic which is critical to prevent attackers from predicting its value. In the next section an approach to achieve this randomization is described, after which the complete algorithm is presented.

\subsection{\ajg{Randomizing the solution}
% Randomness of solution
}
\label{ch:design:nonRep}

Until now, the design of the algorithm has been purely deterministic: given the parameters $\theta$, \eqref{o1} uniquely determines the parameters $\theta^+$.
This provides optimal results, but it makes the architecture vulnerable to attacks\footnote{The attacker in question is different to that defined in Section~\ref{ch:probFor:atk}, where the attack strategy was considered as a \textit{design choice} for the formulation of the optimization problem.} capable of identifying the mWM filter parameters, as the attacker can compute future values of $\theta$ by solving Algorithm~\ref{algo2}.
We therefore propose a method to counteract this vulnerability. %, randomizing the definition of certain elements of $\theta^+$, giving provably different mWM filters compared to the deterministic algorithm.
% it exposes the entire architecture to any attack capable to identify the mWM filter parameters.
% Indeed, once knowledge of $\theta$ is obtained, the adversary can accurately construct $\theta_\sigma^+$ by computing its own solution to Algorithm 1.
% \begin{remark}
%     Note that the attacker in question, here, is different to the definition of $\mathcal A$ in Section~\ref{ch:probFor:atk}. Indeed, there an attacker strategy is defined as a \textit{design choice} for the formulation of the optimization problem, and therefore is internal to the defender's strategy.
%     Here, on the other hand, we are concerned with the vulnerability of our scheme to external attackers. $\hfill \triangleleft$
% \end{remark}
% In this section we propose, as a method to counteract the outlined vulnerability, a mechanism that randomizes the definition of certain elements of the parameters $\theta_\sigma^+$, showing that this results in different mWM filters compared to the algorithm without randomization.
%
Specifically, by initializing matrices $D_q$ and $D_h$ randomly in the first step of the algorithm, it can be shown that the resulting parameters $\theta^+$ are also random.
% . Let $D_q, D_h$ be defined via a pseudo-random number generator.
% ; this can be made to depend on time-varying signals, such as those transmitted over the communication network, as is done in \cite{zhang2022sensor}. Other methods could be used to generate values that, although deterministic, are hard to predict, such as the method based on synchronized unobservable systems in \cite{zhang2023hybrid}. In the following, it is shown that changing $D_\sigma$ is sufficient to ensure that two resulting parameters are not equivalent.

\begin{algorithm}
\caption{Filter parameters selection algorithm}\vspace{-5pt}
\noindent\rule{8cm}{0.1pt}
\textbf{Initialization}: $K,L,\theta, \theta^a, \gamma^* = \infty$ \\
\textbf{Result:} $\theta^{+,*}$\vspace{-5pt}\\
\noindent\rule{8cm}{0.1pt}
\begin{enumerate}[label=\textbf{\arabic*:},leftmargin=*]
\item Pick random matrices $D_h$ and $D_q$.
\item[] \textbf{While} $((\mathcal{A}_h \neq \emptyset) || (\mathcal{A}_q \neq \emptyset))$, \textbf{do:}
    \item Draw a matrix $A_h$ from $\mathcal{A}_h$ and delete it from $\mathcal{A}_h$. 
    \item If the inverse of $A_h: A_g$ obtained from $\eqref{eq:WM:def}$ is unstable go to step $\textbf{2}$.
    \item Draw a matrix $A_q$ from $\mathcal{A}_q$ and delete it from $\mathcal{A}_q$. 
    \item If the inverse of $A_q: A_w$ obtained from $\eqref{eq:WM:def}$ is unstable go to step $\textbf{4}$.
    \item Derive the inverse filters using \eqref{eq:WM:def}.
    \item Using the values of the watermarking filters, and $\theta^a$, solve the convex optimization problem \eqref{o1}. Let us denote the value of \eqref{o1} as $\gamma_t$.
    \item If $\gamma_t < \gamma^*$, store the values of watermarking parameters, else go back to step (1).
    \item[] \textbf{end While}\vspace{-15pt}\\
\end{enumerate}
\noindent\rule{8cm}{0.1pt}
\label{algo2}
\end{algorithm}

\begin{theorem}\label{thm:nonRepeat}
    Let us $D_q[k_i],D_h[k_i]$ be the matrices defined in Step~1 of Algorithm~\ref{algo2} at switching times $k_i, i = 0,1,\dots \in \mathbb{N}_+$. It is sufficient to select $D_q[k_i] \neq D_q[k_j]$ and $D_h[k_i] \neq D_h[k_j]$ to ensure that $\theta_\sigma^+(k_i) \neq \theta_\sigma^+(k_j)$, $\forall i,j = 0,1,\dots \in \mathcal N_+, i \neq j$. 
    % Furthermore, if $\theta[k_i] = \theta[k_j]$, $D_q[k_i] \neq D_q[k_j]$ and $D_h[k_i] \neq D_h[k_j]$ is a necessary condition.
    $\hfill\square$
\end{theorem}
\begin{pf}
    The proof follows directly from the fact that, for any two state space realizations $(A_1,B_1,C_1,D_1)$ and $(A_2,B_2,C_2,D_2)$ with compatible dimensions, it is sufficient for $D_1 \neq D_2$ for the resulting transfer functions $G_1(z) \neq G_2(z)$ \cite[Th. 4.1]{chen1984linear}.
    As a consequence, so long as $D_h[k_i] \neq D_h[k_j]$ and $D_q[k_i] \neq D_q[k_j]$, there are no mWM parameters such that the resulting closed loop transfer functions are the same.
    $\hfill\blacksquare$
\end{pf}

% \begin{remark}
%     Theorem~\ref{thm:nonRepeat} only provides sufficiency, as necessity does not follow, given the algorithm's dependence on $\theta$.
%     % is proven. Indeed, necessity cannot be proven directly from the condition on the values of $D_h$ and $D_q$, as the result of the algorithm also depend on the values of $\theta$ prior to the switching event.
%     $\hfill\triangleleft$
% \end{remark}

\begin{corollary}
    Let $D_h[k_i], D_q[k_i]$ be realizations of random variables. Then, the filter parameters $\theta^+[k_i]$ are also randomized.
    $\hfill\square$
\end{corollary}

To ensure that the parameters $\theta^+$ remain synchronous, it is necessary for the randomized values of $D_h, D_q$ be the same on both plant and control side.
The problem of selecting variables that are synchronized and (pseudo)random is a common issue in the secure control literature, and different solutions have been found, such as (\cite{zhang2022sensor}, \cite{zhang2023hybrid}).