% In this section, the effectiveness of the proposed algorithm is described through a numerical example. 
\subsection{Plant description}
Consider a power generating system \citep[Sec.4]{park2019stealthy} %which can be modeled as as shown in Fig. \ref{turbine} and 
modeled by the dynamics:
\begin{align}
\label{power_AB} \begin{bmatrix}
\dot{\eta}_1\\ \dot{\eta}_2 \\ \dot{\eta}_3
\end{bmatrix} &= 
\begin{bmatrix}
\frac{-1}{T_{lm}} & \frac{K_{lm}}{T_{lm}} & \frac{-2K_{lm}}{T_{lm}}\\
0 & \frac{-2}{T_h} & \frac{6}{T_h}\\
\frac{-1}{T_g R} & 0 & \frac{-1}{T_g}
\end{bmatrix}
\underbrace{\begin{bmatrix}
{\eta}_1\\ {\eta}_2 \\ {\eta}_3
\end{bmatrix}}_{\eta}
+ \begin{bmatrix}
0\\ 0 \\ \frac{1}{T_g}
\end{bmatrix}
{u}\\
\label{power_C} y_p &= \underbrace{ \begin{bmatrix}
1 & 0 & 0 
\end{bmatrix}}_{C_p}\eta,\;\;
y_J = \underbrace{
\begin{bmatrix}
0 & 1 & 0
\end{bmatrix}}_{C_J}\eta.
\end{align}
Here, $\eta \triangleq [df; dp + 2 dx; dx]$, where $df$ is the frequency deviation in \mbox{Hz}, $dp$ is the change in the generator output per unit (\mbox{p.u.}), and $dx$ is the change in the valve position \mbox{p.u.}. The parameters of the plant are listed in Table \ref{param}. 
% The constants $T_{lm}, T_h$, and $T_g$ represent the time constants of load and machine, hydro turbine, and governor, respectively, and $R \,\mathrm{(Hz/p.u.)}$ is the speed regulation due to the governor action. The constant $K_{lm}$ represents the steady-state gain of the load and machine. 
The Discrete-Time system matrices $(A_p,B_p,C_p,D_p)$ are obtained by discretizing the plant \eqref{power_AB}-\eqref{power_C} using zero-order hold with a sampling time $T_s=0.1\mbox{s}$. 

\begin{table}
\centering
\begin{tabular}{||c | c || c | c|| c | c ||} 
 \hline
 $K_{lm}$ & 1 & $T_{lm}$ & 6 &  $T_g$ & 0.2 \\
 \hline
 $T_{h}$ & $4$ & $T_s$ & 0.1 & $R$ & 0.05\\
 \hline
\end{tabular}
\caption{System Parameters}
\label{param}
\end{table}


The plant is stabilized locally with a static output feedback controller with constant gain $D_c=19$. The gains in \eqref{eq:cntrl} are obtained by minimizing a quadratic cost, using the MATLAB command \emph{dlqr}, resulting in:
\begin{align}
    K&=\begin{bmatrix}
        0.1986  & -0.0913  & -0.1143
    \end{bmatrix}\\
    L &= \begin{bmatrix}
       0.2735 &  -0.0509 & -0.2035
    \end{bmatrix}^\top.
\end{align}
% The controller (detector) gain is obtained by minimizing a quadratic cost, which can be done in MATLAB using the \emph{dlqr} command. 

% %%% You can delete the following figure to save space. 
% \begin{figure}
%     \centering
%     \includegraphics[width=8.4cm]{Turbine.eps}
%     \caption{\ajg{Pictorial representation of power generating system with a hydro turbine under covert attack. The plant consists of the power generating system (governer, hydro-turbine,machine) and a stabilizing controller. The plant output is transmitted over the network to a controller for process monitoring and tracking command. The solid/dashed/red lines represent physical/cyber and covert attack components respectively.}}
%     \label{turbine}
% \end{figure}
\subsection{Initializing the mWM design algorithm}
We consider a mWM filter of state dimension $n_{\sigma}=2$. The mWM filter parameters are initialized as $A_q = 0.2I_2$, $B_q=0.7e_{2 \times 1}$, $C_q = 0.1 e_{1 \times 2}$, $B_h=0.2e_{2 \times 1}$, $C_h=0.05 e_{1 \times 2}$, $A_h=0.3I_2$, $D_q=0.15$, $D_h=0.1$ where $e_{a \times b}$ represents a unit matrix of size $a \times b$. 
The other mWM matrices are derived such that they satisfy \eqref{eq:WM:def}. 
All unspecified matrices are zero. Following Assumption~\ref{ass:param}, it is assumed that the filter parameters $\theta$ are known by the adversary. 
% Thus, the aim is to find the next-step mWM parameters $\theta^+$ minimizing the AEC-OOG. 
To ensure randomization, as mentioned in Theorem~\ref{thm:nonRepeat}, the parameters $D_h$ and $D_q$ are initialized in Algorithm~\ref{algo2} as random numbers within the range $[0.1,0.15]$. We fix the parameters of all the mWM filter parameters at their initial value except for the matrix $A_{\sigma}, \sigma \in \{q,w,h,g\}$, i.e., our aim is to find a diagonal $A_{\sigma}$ that minimizes the value of the AEC-OOG.

As discussed in Section~\ref{ch:design:algo}, $A_q$ and $A_h$ are matrices whose diagonal elements take values in $(-1,1)$.
The exhaustive search is performed with a grid size of $n_s = 0.3$, and the search is initialized with ${\epsilon_r = 1}, {\epsilon_a = 50}$. Furthermore, for numerical stability, we modify the objective function of \eqref{o1} to $\epsilon_r \gamma + \epsilon_a \gamma_a + \epsilon_p \mathrm{tr}(P)$, with ${\epsilon_p = 0.1}$.

% To this end, we set $A_q=\text{diag}(t_1,t_2)$, and $A_h=\text{diag}(t_3,t_4)$ where $-1 < t_{i} < 1, i\in \{1,2,3,4\}$. In other words $A_q$ and $A_h$ are matrices whose diagonal elements are allowed to take values between $-1$ and $+1$, to ensure stability of the filters. Then a grid search (with grid size $n_s$=0.3) on the matrices is employed as described in Algorithm \ref{algo2}. The grid search is initialized with ${\epsilon_r=1},{\epsilon_a=50}$ and ${\epsilon_p=0.1}$. Here $\epsilon_p$ represents the weight on the trace of the matrix $P$ in the objective function.  In other words, we modify the objective function in \eqref{o1} as $\epsilon_r\gamma+\epsilon_a\gamma_a+\epsilon_p\text{tr}(P)$, for the numerical stability of the algorithm. 

\subsection{Result of Algorithm \ref{algo2}}
The optimal value of the matrices from the grid search are $A_q^* = -0.05I_2$ and $A_h^*=-0.65 I_2$. 
The corresponding value of $\mathcal{L}$ is $111.03$. The value of $D_q$ and $D_h$ were $0.1479$ and $0.1482$ respectively. The simulation is performed using Matlab 2021a with \textit{Yalmip} \citep{lofberg2004yalmip} and \textit{SDPT3v4.0} solver \citep{toh2012implementation}.
%
In the remainder, we compare the results obtained by repeated computation of Algorithm~\ref{algo2} compared to defining constant and random parameters.
Consider 
an adversary injecting the signals shown in Fig.~\ref{fig:no:switch},
\begin{equation}\label{eq:step}
    \varphi_u[k] = \begin{cases}
        150 & \text{if}\;k\;\text{mod}\;2=0 \\
        0 & \text{otherwise}
    \end{cases}
   \end{equation}
into the actuators, and $\varphi_y$ following \eqref{eq:atk:cov}.
% Next, we compare our results to the scenario where the parameters are not switched,  and where they are updated randomly. 
    
\emph{Comparison with no parameter switching:}
% The adversary constructs an attack signal $\varphi_y$ through \eqref{eq:atk:cov} which is shown in Fig.~\ref{fig:no:switch}. 
The performance of the attack is shown in Fig.~\ref{fig:no:switch}, for the cases without switching and when switching happens at the attack onset with the optimal filter parameters.
Without switching $\theta$, although the performance is strongly degraded, the attack remains stealthy. Instead, if the mWM parameters are changed, it is detected after $15 \mbox{s}$.
% We can see that the performance degradation is high without the switching, and there is no attack detection since the adversary exactly knows the parameters. This also unveils the importance of detecting covert attacks. On the other hand, when the parameters of the watermarks switch the attack is successfully detected after $15\mbox{s}$. 

\begin{figure}
    \centering
    \includegraphics[width=7cm]{Resubmission_ajg.eps}
    \caption{\ajg{(Top) The attack signal $\varphi_u$ in \eqref{eq:step} and its equivalent $\varphi_y$ from \eqref{eq:atk:cov}; (Middle) $\Vert y_r \Vert_{\ell_2,[0,k]}^2$, compared to $\epsilon_r$; (Bottom) $\Vert y_J \Vert_{\ell_2,[0,k]}^2$ before and after the mWM parameters are updated.}}
    \label{fig:no:switch}
\end{figure}



\emph{Comparison with random parameter switching:}
In this scenario, we suppose the mWM parameters are updated $5$ times, by running Algorithm~\ref{algo2}, and compared against $5$ random updates of $A_\sigma$ -- though their structure remains diagonal.
% Next, Algorithm~\ref{algo2} is run, i.e., the filter parameters are updated, $5$ times. 
The results, shown in terms of values of $\mathcal L$ for both cases, are shown in Fig.~\ref{fig:switch}.
% The results are shown in Fig.~\ref{fig:switch} where we plot the values of $\mathcal{L}$.
% For comparison, instead of selecting the optimal matrices $A_\sigma$ from an exhaustive search, we choose the matrices randomly. That is, the diagonal elements of $A_h$ and $A_q$ are chosen random and the parameters are discarded if they yield an unstable inverse. 
% The corresponding value of  $\mathcal{L}$ is also depicted in Fig. \ref{fig:switch}. 
Here, the parameters of $D_h$ and $D_q$ are the same as used for selecting the optimal parameters. Since the parameters are not chosen optimally, the value of $\mathcal{L}$, the performance loss, is higher. 

\begin{figure}
    \centering
    \includegraphics[width=6.5cm]{Switch_new.eps}
    \caption{The values of $\mathcal{L}$ corresponding to the optimal and random values of the watermarking parameters.}
    \label{fig:switch}
\end{figure}

\emph{Time complexity:}
To conclude, let us discuss thecomplexity of Algorithm~\ref{algo2}. All mWM parameters are fixed, apart from $A_\sigma$, which is a diagonal matrix of dimension $n_\sigma$, and, for each diagonal element of $A_\sigma$, $n_s$ points of the interval $(-1,1)$ are searched.
Given \eqref{eq:WM:def}, only $A_h$ and $A_q$ must be defined, while $A_w, A_g$ are defined algebraically; thus, define $n_\varsigma = n_q + n_h$.
The complexity of the algorithm grows both in $n_\varsigma$ and in $n_s$. Specifically: for $n_s = n_s^*$, the complexity is $\mathcal O(n_s^{*x})$; for $n_\varsigma = n_\varsigma^*$, the complexity is $\mathcal O(x^{n_\varsigma^*})$. Thus, the complexity is exponential in the choice of $n_\varsigma$ and polynomial in $n_s$.
%
We highlight that the average time of solution can be improved upon in two major ways. 
The first is via parallelization, as all SDPs can be solved independently; this provides a speed-up which depends on the number of compute nodes used to solve the problem.
The second method relies on reducing the number of SDPs to be solved, by removing those values of $A_h, A_q$ which do not lead to stable inverses, as defined by \eqref{eq:sys:inv}.

For the results presented here, a computer with an Intel Core i7-6500U CPU with 2 cores and 8GB RAM was used. The algorithm was run both with and without parallelization (parallelization was achieved by using Matlab's \texttt{parfor} command). Without parallelization, the algorithm took $384.25 \mathrm{s}$ to provide a result, whilst with parallelization this was $261.65 \mathrm{s}$, a  $31.9 \%$ speedup.

% \subsection{Time complexity}
% The computation complexity of a design algorithm is important, and in this subsection we briefly comment on it. In particular, we comment on the expected time taken to perform the grid search in Algorithm \ref{algo2}. As adopted in this example, let us consider the design algorithm where all the mWM parameters are fixed except for $A_{\sigma}$, which is a diagonal matrix. Let $n_s$ denote the size of the grid search, $n_{\sigma}$ denote the size of the watermarking filter, $\mathbb{E}[\tau]$ denote the mean time taken by a solver to compute the optimal value of \eqref{o1} for any given value of the filter parameters. The time $\mathbb{E}[\tau]$ depends on the SDP solver and the hardware. Then, the mean time taken to perform the grid search, denoted by $\mathbb{E}[T]$ is bounded by 
% \begin{equation}\label{eq:bound}
%     \mathbb{E}[T] \leq \mathbb{E}[\tau] \left(\ceil[\Bigg]{\frac{2}{n_s}} \right)^{n_{\sigma}}
% \end{equation}
% where $\ceil{x}$ denotes the smallest integer greater than $x$. Thus, the time complexity increases quadratically in the grid size, and exponentially in the size of the filter state. The bound \eqref{eq:bound} also holds when the matrix $A_{g}$ and $A_h$ are traingular where the diagonal elements are the decision variables and the other elements are fixed. 

% In general, the bound in \eqref{eq:bound} is loose, as some filter parameters might yield an unstable inverse, and the grid search does not need to solve an SDP in that case (see step 5 in Algorithm \ref{algo2}). Thus, the bound \eqref{eq:bound} can be largely improved by pre-processing, where the set of all matrices which yield an unstable inverse is removed. Additionally, since the SDPs can be solved independently, the grid search is parallelizable, which reduces the time complexity even further. 