
\documentclass{article} % For LaTeX2e

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
\usepackage{arxiv}

\usepackage{hyperref}
\usepackage{url}
\usepackage{xspace}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}
\usepackage{xspace}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{listings}
\usepackage{caption}
\usepackage{tcolorbox}
\usepackage{cleveref}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{longtable}
\usepackage{array}
\usepackage{xcolor}
\usepackage{xcolor} 
\usepackage{authblk}
\usepackage{natbib}
\usepackage{wrapfig}

\clearpage

% Begin Example and Code Boxes
\newtcolorbox{exampleboxcode}{colback=black!5, colframe=black!50, arc=4pt, boxrule=1pt,   left=5pt, right=5pt, top=0pt, bottom=0pt % Fine-tune internal padding
}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.97,0.97,0.97}

\lstdefinestyle{codestyle}{
    % backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\scriptsize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    xleftmargin=10pt,                % Left margin
    xrightmargin=10pt                % Right margin
}
\lstset{style=codestyle}

% End Example and Code Boxes




\title{Minions: Cost-efficient Collaboration Between On-device and Cloud Language Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.







% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\system}{\textsc{Minion}$\mathcal{S}$\xspace}
\newcommand{\naive}{\textsc{Minion}\xspace}
\newcommand{\llama}{\textsc{Llama}\xspace}
\newcommand{\llamathree}{\textsc{Llama-3B}\xspace}
\newcommand{\llamaeight}{\textsc{Llama-8B}\xspace}
\newcommand{\llamaone}{\textsc{Llama-1B}\xspace}
\newcommand{\llamathreetwo}{\textsc{Llama-3.2}\xspace}
\newcommand{\llamathreeone}{\textsc{Llama-3.1}\xspace}
\newcommand{\qwenone}{\textsc{Qwen-1.5b}\xspace}
\newcommand{\qwenthree}{\textsc{Qwen-3b}\xspace}
\newcommand{\qwenseven}{\textsc{Qwen-7b}\xspace}
\newcommand{\gpt}{\textsc{GPT-4o}\xspace}
\newcommand{\qwen}{\textsc{Qwen2.5}\xspace}
\newcommand{\qasper}{\textsc{QASPER}\xspace}
\newcommand{\longhealth}{\textsc{LongHealth}\xspace}
\newcommand{\finance}{\textsc{FinanceBench}\xspace}
% method specific terms
% edge model
\newcommand{\locallm}{\mathrm{LocalLM}\xspace}
\newcommand{\remotelm}{\mathrm{RemoteLM}\xspace}
\newcommand{\systemmath}{\textsc{MinionS}\xspace}

\begin{document}


\renewcommand\Authands{, } % Ensures authors are separated by commas

% Define equal contribution symbol
\newcommand{\equalcontrib}{\textsuperscript{*}}
\newcommand{\affilmark}[1]{\textsuperscript{#1}} % To format affiliation markers

\author[1]{Avanika Narayan\equalcontrib}
\author[1,2,3]{Dan Biderman\equalcontrib}
\author[1]{Sabri Eyuboglu\equalcontrib}
\author[5]{Avner May}
\author[2,3]{\\Scott Linderman}
\author[4]{James Zou}
\author[1]{Christopher Ré}


\affil[1]{Department of Computer Science, Stanford University}
\affil[2]{Department of Statistics, Stanford University}
\affil[3]{Wu Tsai Neurosciences Institute, Stanford University}
\affil[4]{Departemnet of Biomedical Data Science, Stanford University}
\affil[5]{Together AI}

\affil[ ]{\texttt{\{avanikan,biderman,eyuboglu\}@stanford.edu}}

\date{}


\maketitle

\let\thefootnote\relax\footnotetext{\textsuperscript{*} Corresponding authors; equal contribution and random ordering for AN, SE, DB.}



% \renewcommand\Authands{, } % Ensures authors are separated by commas

% % Define equal contribution symbol
% \newcommand{\equalcontrib}{\textsuperscript{\textdagger}}

% \author[1]{Avanika Narayan\equalcontrib}
% \author[1]{Dan Biderman\equalcontrib}
% \author[1]{Sabri Eyuboglu\equalcontrib}
% \author[2]{Avner May}
% \author[1]{Scott Linderman}
% \author[3]{James Zou}
% \author[1]{Christopher Ré}

% \affil[1]{Department of Computer Science, Stanford University}
% \affil[2]{Together AI}
% \affil[3]{Department of Biomedical Data Science, Stanford University}

% \affil[ ]{\textsuperscript{\textdagger}Equal contribution.}

% \date{}



\begin{abstract}
We investigate an emerging setup in which a small, on-device language model (LM) with access to local data communicates with a frontier, cloud-hosted LM to solve real-world tasks involving financial, medical, and scientific reasoning over long documents. 
\textit{Can a local-remote collaboration reduce cloud inference costs while preserving quality?} 
First, we consider a naïve collaboration protocol where the local and remote models simply chat back and forth. 
Because only the local model reads the full context, this protocol achieves a $30.4\times$ reduction in remote costs, but recovers only 87\% of the performance of the frontier model.
% 
We identify two key limitations of this protocol:  the local model struggles to (1) follow the remote model's multi-step instructions and (2) reason over long contexts. 
% 
Motivated by these observations, we study an extension of this protocol, coined \system, in which the remote model decomposes the task into easier subtasks over shorter chunks of the document, that are executed locally in parallel. \system reduces costs by $5.7\times$ on average while recovering 97.9\% of the performance of the remote model alone.
Our analysis reveals several key design choices that influence the trade-off between cost and performance in local-remote systems.
\end{abstract}

\input{sections/introduction.tex}


\input{figures/main-tradeoff/main-tradeoff.tex}
\input{sections/related_works.tex}

\input{sections/prelim}


\input{sections/method.tex}

\input{sections/results.tex}
\input{sections/discussion}
\input{sections/ack_block}  
%\input{sections/impact_statement}

% \bibliography{references}
% \bibliographystyle{plain}

\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\appendix
\input{appendix/related-work}
\input{appendix/prelim}
\input{appendix/method}
\input{appendix/results}
\input{appendix/prompts}





% \subsubsection*{Author Contributions}
% If you'd like to, you may include  a section for author contributions as is done
% in many journals. This is optional and at the discretion of the authors.

% \subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments, including those to funding agencies, go at the end of the paper.


% \bibliography{iclr2025_conference}
% \bibliographystyle{iclr2025_conference}

% \appendix
% \section{Appendix}
% You may include other additional sections here.


\end{document}
