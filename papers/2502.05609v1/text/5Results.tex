% \input{table/main_table}
% \input{figure/token_len_and_task}

We now present the experimental results on Spec-Bench, along with an in-depth analysis of HD.

\subsection{Main Result}

Table~\ref{tab:main} presents our main results, averaged across all cases of Spec-Bench using three models, at both low temperature (\(T=0.0\)) and high temperature (\(T=1.0\)). First, our proposed method, HD, achieves the outperforming acceleration gain across all scenarios. In detail, when temperature is 0.0, HD achieves over 1.5x faster inference speed compared to autoregressive decoding, whereas the other methods fail to exceed a 1.4x speedup. Also, while the acceleration gain at \(T=1.0\) is slightly lower than \(T=0.0\), HD still achieves the fastest inference speed compared to all other methods across all models. These results demonstrate that our hierarchical framework effectively enhances inference speed by incorporating diverse token sources into three databases organized by temporal locality.

\input{figure/access_database_and_task_pattern}


Beyond acceleration gains, we analyze the additional latency caused by the drafting process, which adds overhead that is absent in autoregressive decoding, and also evaluate how accurately the drafting step retrieves tokens that align with the LLM’s output. 
Regarding drafting latency, LADE requires an extremely short time—under 0.01 ms per draft—whereas REST takes significantly longer, with latency close to 3.00 ms. 
However, drafting accuracy shows the opposite trend: LADE exhibits lower values for both the acceptance ratio (\(\alpha\)) and mean accepted tokens (\(\tau\)), while REST achieves higher values for both. 
Notably, our proposed method, HD, drafts slightly faster than REST, even though accessing the same extensive database, and accurately predicts 70\% of generated tokens, achieving the highest accuracy among all other methods. 
These results indicate that HD successfully balances increased accuracy with reduced drafting latency through hierarchical database access, resulting in significant acceleration gain.

\paragraph{Comparison with Non-Database Methods} 
We compare diverse database drafting methods with two non-database drafting methods, SpS~\cite{SpS} and MEDUSA~\cite{MEDUSA}, to confirm whether the performance is competitive without additional training. 
As shown in Figure~\ref{fig:temperature_and_task}, while other database drafting methods significantly underperform compared to non-database drafting methods, our proposed method, HD, outperforms SpS and substantially narrows the performance gaps with MEDUSA. 
This demonstrates that our proposed method shows the potential to achieve more significant acceleration gain without retraining the models by exploiting data resources common in real-world serving scenarios.

\paragraph{Robustness across Tasks} 
We evaluate the robustness of database drafting methods across various generation tasks, as illustrated on the right side of Figure~\ref{fig:temperature_and_task}. 
Relying on a single source results in variability in acceleration gains, causing most methods, except HD, to show inconsistent performance with concave regions in specific tasks. 
Specifically, PLD achieves significant acceleration in tasks like Summarization and RAG but offers minimal improvements in Translation and QA. 
Additionally, other methods exhibit varying acceleration gains depending on the model used—REST, for example, performs well with Llama-7b in summarization but shows weaker results with Vicuna-7b, nearly matching autoregressive decoding speeds. 
In contrast, our proposed method consistently achieves the highest acceleration across all tasks and models, occupying the largest area in each plot. This demonstrates that incorporating diverse sources enhances robustness, making database drafting methods more suitable for real-world scenarios.


\subsection{Analysis}

In this subsection, we provide an in-depth analysis of HD for investigating its effectiveness.

\paragraph{Analysis of Three Databases}
The left side of Figure~\ref{fig:access_database_and_task_pattern} depicts each database's verify success ratio and draft latency. 
The verify success ratio measures the proportion of accepted cases relative to total database accesses during the verifying step.
$\mathcal{D}_c$ achieves the highest verify success ratio over 30\% with the lowest draft latency, demonstrating its effectiveness in fetching context-relevant future tokens. However, $\mathcal{D}_m$ shows a lower verify success rate, 15.5\%, with slightly higher latency, indicating that while it performs decently, it is less aligned with specific contexts. $\mathcal{D}_s$ exhibits the lowest verify success rate under 10\% and the highest draft latency over 10ms due to its larger scale and lower locality. These highlight that draft tokens with higher locality are more frequently accepted, indicating alignment with our design objectives.


\paragraph{Access Pattern across Tasks}
We analyze how our proposed method, HD, achieves consistent acceleration gain across tasks with verify success ratio of databases for each task.
As shown in the right side of Figure~\ref{fig:access_database_and_task_pattern}, $\mathcal{D}_c$ excels in tasks such as Multi-turn Conversation or Summarization, where the context-specific tokens are highly repeated, leading to high verification success. However, for tasks like translation and QA, which offer fewer explicit cues from previous inputs or contexts, $\mathcal{D}_c$ achieves lower verification success. 
In these cases, $\mathcal{D}_m$ and $\mathcal{D}_s$ compensate for the weaknesses of $\mathcal{D}_c$ by showing higher verification success compared to other tasks where $\mathcal{D}_c$ outperforms.
These results highlight how our HD efficiently accesses the appropriate database for each task, effectively leveraging the distinct strengths of diverse sources.


\paragraph{Database Access Order}
We analyze the impact of access order within the hierarchical framework, as shown in Figure~\ref{fig:order}. 
As expected, our original access order ($cms$), which prioritizes databases from highest to lowest temporal locality, achieves the highest acceptance ratio and lowest draft latency. 
While other orders maintain an acceptance ratio above 50\%, sufficient for some acceleration gain, their actual speedup is significantly lower due to additional drafting latency, reaching up to 12ms for orders like $scm$ or $smc$.
These results demonstrate that hierarchical access fully leverages the potential of multiple databases with minimal drafting latency compared to other orders, underscoring the importance of temporal locality in drafting order.

We provide additional analysis in Appendix~\ref{app:additional_result}.