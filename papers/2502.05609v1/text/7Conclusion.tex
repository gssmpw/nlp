In this work, we explore the database drafting approaches in speculative decoding, which do not require additional training or fine-tuning. Existing methods rely on a single database from a single source, resulting in inconsistent and suboptimal acceleration gains. To address this, we propose Hierarchical Drafting (HD), which optimally utilizes diverse sources by constructing multiple databases based on temporal locality. Our method hierarchically accesses these databases, prioritizing those with the highest locality for optimal acceleration. Experimental results show that HD consistently and effectively accelerates LLM inference across various scenarios, outperforming other database drafting methods. These findings demonstrate that our hierarchical framework maximizes the strengths of each database with minimal overhead, expanding the directions exploiting multiple databases for lossless acceleration in speculative decoding.