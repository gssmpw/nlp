\section{IMPACTX framework}
\label{sec:method}
\subsection{Adopted assumptions and notation}
In its simplest form, a typical ML classification system $\mathcal{A}$ can be usually viewed as the composition of two main components: a feature extractor $M$ (for example, in a feed forward DNN model, it usually corresponds to the DNN first layers) and a classification component $Q$ (usually corresponding, in a feed forward model, to the remaining part of the classification process) s.t. $\hat{y}=\mathcal{A}(\vec{x})=Q\big(M(\vec{x})\big) \in \{1,\dots K\}$ is the estimated class of the input $\vec{x}\in \mathbb{R}^d$. Without losing in generality, in this paper, we consider $Q$ as just the final function to compute the inferred class from a given vectors of $K$ scores, i.e. $Q(\vec{m})=\arg\max\big(\text{softmax}(\vec{m})\big)$ with $\vec{m}\in \mathbb{R}^K$. After a proper learning procedure, $M$ is a model able to represent a given $\vec{x}$ in a $K$-component array where the $k$-th component with $1\leq k \leq K$ represents a score of $\vec{x}$ to belong to the $k$-th class. An example of $M$ can be all the layers of a DNN before the final softmax function. However, in general every model able to project $\vec{x}$ in a given feature space can be adopted as $M$ (such as a sequence of layers of a DNN able to extract features from an input $\vec{x}$).
We define with $y \in \{1,\dots,K\}$ a scalar representing the correct label of an input $\vec{x}$  in a $K$-class classification problem. Let $S^T$ be a training dataset of $N$ labeled instances, i.e. $S^T = \{(\vec{x}^{(i)}, y^{(i)})\}_{i=1}^N$, and $S^E$ a test dataset composed of $J$ instances used only to evaluate an ML model, i.e. $S^E =\{ (\vec{x}^{(j)}, y^{(j)}) \}_{j=1}^J$. % our objective is to predict the correct class using a neural network $M$ trained on $S^T$.


\subsection{General description}
IMPACTX is a double-branch architecture such that, when applied to a classifier $\mathcal{A}$, the resulting architecture outperforms the standalone $\mathcal{A}(\vec{x})=Q\big(M(\vec{x})\big)$), both appropriately trained. In addition, this enhanced architecture  also provides input attribution maps relative to the output obtained.

IMPACTX framework is composed of two branches that interact each other (see figure \ref{fig:IMPACTX_arch}): 
\begin{enumerate}
    \item The first branch (on the top) is composed of a Feature Extractor $M$, able to extract significant features from the input with the goal to classify the input $\vec{x}$, and a $K$-class classifier $C$, able to return an estimated class $\hat{y}$ of the input $\vec{x}$. 
    \item The second branch (at the bottom)     \textcolor{black}{
     is responsible for the attention mechanism of IMPACTX. It}
 is composed of a Latent Explanation Predictor (LEP) module, able to extract essential information from the input features with the goal to compute an attribution map of the input respect to the classification response, and a Decoder $D$, able to effectively produce an attribution  map of the input $\vec{x}$. 
\end{enumerate}

Thus, the goal of IMPACTX is to build an estimated class $\hat{y}=C(\vec{m},\vec{z})$ exploiting both the $\vec{m}=M(\vec{x})$ and $\vec{z}=LEP(\vec{x})$ outputs, and at the same time to obtain a predicted attribution map $\hat{\vec{r}}$ with respect to $\hat{y}$. 

%As we discuss in detail in Section \ref{sec:training}, during the inference phase the top-branch is influenced by the bottom branch, while the bottom branch is used to the during the training phase the bottom branch is influenced 
In the next section we will discuss in detail how IMPACTX can be trained to obtain this goal. 

%the LEP module extracts relevant information from the input. This is made exploiting during the training both inputs and explanations generated by a specific  method (see sec. \ref{} for further details). The output $\vec{z} = LEP (\vec{x})$, named 'latent attribution encoding', wants to capture essential information about the attribution of the input features $\vec{x}$ to the true class $y$. We assume that $\vec{z}$, when combined with the output $\vec{m}$ generated by $M(\vec{x})$, can effectively helps to classify the input $\vec{x}$ through the simple classifier $C$ properly trained. 


%IMPACTX framework is composed of four main components (see Fig. \ref{}): i) a feature extractor $M$, ii) a $LEP$ (Latent Explanation Predictor) module able to extract essential information from the input features, iii) a final $K$-class classifier $C$ able to provide the final estimated class, and iv) a Decoder $D$ able to product an attribution  map of the input $\vec{x}$. 


%Then,  Without loss of generalizabily, we can consider $M$ as a feature extractor, i.e. the   $\hat{y}_M=\arg\max\big({softmax}\big(\vec{m}\big)\big)$ is the estimated label of the sample $\vec{x}$. 



%Since our goal is to obtain attribution maps aligned with the correct label, we adopt the XAI SHAP method \citep{NIPS2017_7062} as $R$. Indeed, SHAP reveals the impact of different features on model predictions, offering a deeper understanding of the decision-making process. In particular, SHAP provides explanations not only for the predicted class, but also for each possible class \roberto{Questa e' una caratteristica solo di SHAP o di altri metodi XAI??} \sal{anche di altri}, which we denote as $SHAP(M, \vec{x})=\{\vec{r}_1, \vec{r}_2,\dots, \vec{r}_C\}$, where $C$ represents the number of classes involved in the classification problem addressed by $M$. Therefore, the attribution map corresponding to the true class label provided in the training data results $\vec{r}^{(i)}=\vec{r}_{y^{(i)}} \in SHAP(M, \vec{x}^{(i)})$.


\begin{figure*}[ht]
\centering
\includegraphics[width=1\textwidth]{./IMPACTX_ARK.png} 
\caption{An overview of the IMPACTX framework. In the training phase of IMPACTX, both $M$ and $LEP$ receive $\vec{x}$, generating $\vec{m}$ and $\vec{z}$ respectively. These are combined for classification by $C$. In particular, $LEP$ and $D$ exploit the $R\big(\mathcal{A}(\vec{x})\big),\vec{x}, y)$ explanations. The architecture is trained using a loss function that merges MSE and CE to optimize explanation reconstruction and improve classification performance. In the inference step of IMPACTX, $C(\vec{m}, \vec{z})$ predicts the class $\hat{y}$ and $LEP-D(\vec{x})$ reconstructs the explanation $\vec{r}$ of the input $\vec{x}$. 
%In the training phase of IMPACTX, both $M$ and $LEP$ receive $\vec{x}^{(i)}$, generating $\vec{m}^{(i)}$ and $\vec{z}^{(i)}$ respectively. These are combined for classification by $C$. While the weights of $M$ remain frozen, $LEP$ and $D$ exploit the $\vec{r}^{(i)}$ explanations to enhance $M$'s classification. The architecture is trained using a loss function that merges MSE and CE to optimize explanation reconstruction and improve classification performance.
}
\label{fig:IMPACTX_arch}
\end{figure*}
%Summarizing, the IMPACTX training framework comprises several key components:  (i) the Latent Explanation Predictor $LEP$ and a Decoder $D$ are trained to extract significant hidden information $\vec{z}^{(i)}$ related to the explanations and reconstructing the original attribution map  $\vec{r}^{(i)}$ from its encoding $\vec{z}^{(i)}$, and (ii) the final classifier $C$ designed to exploit $\vec{m}^{(i)}$ and $\vec{z}^{(i)}$ to predict the effective class $y^{(i)}$. Both $M$ and $LEP$ receive the input $\vec{x}^{(i)}$. The resulting outputs, $M(\vec{x}^{(i)})$ and $LEP(\vec{x}^{(i)})$, are concatenated and passed to $C$.


%\input{_alg}


\subsection{Training IMPACTX}
\label{sec:training}
The training phase of the IMPACTX approach is depicted in figure \ref{fig:IMPACTX_arch}.
%\textcolor{red}{ and outlined in the pseudocode presented in Algorithm  \ref{algo:method_main}}
Both $M$ and $LEP$ receive $\vec{x}$ as input, producing the corresponding outputs $\vec{m}$ and $\vec{z}$. These outputs are concatenated and forwarded to the classifier $C$. Additionally, $\vec{z}$ is decoded by the decoder $D$, responsible for reconstructing the explanation $\vec{r}$. In other words, $LEP$ and $D$ act as an Encoder-Decoder which is constrained to learn an encoding of the explanations by the internal variables $\vec{z}$. $C$ leverages the combined knowledge of $M$  and $LEP$. Therefore, for a new data point $\vec{x}^{(j)}$, the  estimated output $\hat{y}^{(j)}$ is defined as: $$\hat{y}^{(j)} = \arg\max\bigg( \text{softmax} \Big(C\big(M(\vec{x}^{(j)}), LEP(\vec{x}^{(j)})\big)\Big)\bigg).$$ %Assuming that $M$ can be any pre-trained neural network, learning the proposed framework requires the training of Predictor $P$, Decoder $D$, and classifier $C$ without utilizing unlabeled data $S^E$.
\\Consequently, IMPACTX wants to solve the classification task and, at the same time, to construct a predicted attribution map $\vec{r}$ using the decoder $D$ and the $LEP$ module. 

Importantly, the effective IMPACTX training can be made in at least two ways:

- \textit{Single-stage training}: All IMPACTX modules are trained simultaneously on $S^T$, with the attribution maps $\vec{r}^{(i)}$ for each sample in $S^T$ generated at the end of each training iteration. \textcolor{black}{In this case, classification performance can be improved by using increasingly accurate attribution maps, $\vec{r}^{(i)}$. Ideally, this creates a positive feedback loop where both the classification and the generation of attribution maps are mutually enhanced. Conversely, computing the attribution maps at each iteration can be computationally expensive and, at the same time, the generated attribution maps $\vec{r}^{(i)}$ may have very poor significance in the early learning epochs since $M$, $LEP$ and $D$ weights are initialised to random values. %This situation could also lead to the worst results in the $C$ classifier and in some cases, without special precautions, also in the last learning epochs. 
%Instead, the advantage of this strategy is obviously a single-stage training for all IMPACTX modules. In the optimal case, there's the possibility to improve the classification performance by using better and better attribution maps $\vec{r}^{(i)}$ and in an ideal loop, this enhances both the classification and the generation of attribution maps.
}

- \textit{Two-stage training}:  This training approach is divided into two stages. In the first stage, the parameters of the whole classifier  $\mathcal{A}(\cdot)$ are trained and initially evaluated on $S^T$. Then, at the end of the first training stage, the attribution maps $\vec{r}^{(i)}$ for each sample in $S^T$ are produced with respect the true class label. In the second training stage, the remaining modules $C$, $D$, and $LEP$ are trained while keeping $M$ frozen. In particular, the targets of the branch $LEP$-$D$ are the corresponding attribution maps previously computed at the end of the first stage.  Since the attribution maps are computed just one time, two-stage training results less expensive than single-stage training. 
%\textcolor{red}{The disadvantage of this approach is that only one generation of attribution maps $\vec{r}^{(i)}$ is used. This could limit the performance gain.}\textcolor{blue}{Andrea: ???} \sal{vorrei dire, che rispetto all'altro tipo di addestramento, qui vengono generate una sola volta le spiegazioni e per questo motivo (nel caso ideale) l'incremento di performance potrebbe essere inferiore. Se non va bene, per ogni finalità, si può anche togliere}

In both the training approaches, the architecture is trained using a loss function that combines together Mean Squared Error (MSE) between the true class attribution map $\vec{r}^{(i)}$ (see sec. \ref{sec:method_genR}) and the output of the $LEP$-$D$ branch, and the Cross Entropy (CE) loss between the true class label $y^{(i)}$ and the prediction from $C$. The resulting loss function can be formalized as follows: 
\begin{equation}
    L = CE\big(y^{(i)}, C(\vec{m}^{(i)}, \vec{z}^{(i)})\big) + \lambda \cdot MSE\big(\vec{r}^{(i)}, LEP-D(\vec{x}^{(i)})\big)
\label{eq:loss}
\end{equation} where $\lambda$ represents a regularization parameter. This approach lead $\vec{z}^{(i)}$ to be optimized respect to the attribution reconstruction error while maintaining robust classification performance simultaneously.



\subsection{Generating the attribution-based explanations} 
\label{sec:method_genR}
We use an XAI attribution method $R$ to generate attribution maps $\vec{r}$ on $\vec{x}$ about the true class label $y$ based on $\mathcal{A}(\vec{x})$. In particular, for each available training data $\vec{x}^{(i)}$ in $S^T$, an attribution map $\vec{r}^{(i)}$ corresponding to the true class label $y^{(i)}$ when $\vec{x}^{(i)}$ is the input of $\mathcal{A}(\vec{x}^{(i)})=Q\big(M(\vec{x}^{(i)})\big)$, is produced adopting $R$. 
The objective is to get an attribution map aligned with the true class label $y^{(i)}$ for each training data $\vec{x}^{(i)}$. Therefore, we adopt as $R$ an XAI method that provides explanations not only for the predicted class, but also for each possible class, which we denote as $R\big(\mathcal{A}, \vec{x}, k \big)=\vec{r}_k$, where $k$ represents the class for which we need the explanation. Therefore, the attribution map corresponding to the true class label provided in the training data results $\vec{r}^{(i)}=R\big(\mathcal{A}(\vec{x}^{(i)}), \vec{x}^{(i)}, y^{(i)}\big)$.