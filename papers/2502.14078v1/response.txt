\section{Related Work}
% % % % % % % % % % % % % % % % % %
% Learning Game Models from Data  %
% % % % % % % % % % % % % % % % % %
\subsection{Learning Game Models from Data}

\term{Empirical game-theoretic analysis} (EGTA) **Wellman, "Computing Equilibria for Two-Player Games"** is a framework which includes modeling complex, multi-agent interactions using data from an agent-based simulator and using game-theoretic analysis to approximate equilibria in the resulting \term{empirical game} (**Wilder, "Empirical Game Theory Using Multiagent Control Systems"**) (also called a simulation-based game **Dietz, "Black-Box Games: A Framework for Evaluating and Improving Automated Mechanism Design"**) or a black-box game **Hart, "A Framework for Evaluating the Effectiveness of Algorithmic Mechanisms in Complex Environments"**).
Given limited sampling resources, it is infeasible to estimate payoffs for every strategy profile individually from simulation data.
An alternative is to learn game models that generalize from the available data, for example using regression to learn pure-strategy payoff functions  **Hart, "Learning Pure-Strategy Payoff Functions with Regression"** or inducing compact game structures **Wellman, "Inducing Compact Game Structures through Clustering and Abstraction"**.
**Dietz, "Training Neural Networks to Learn Deviation Payoffs in Symmetric Games"** train a neural network to learn the \term{deviation payoff function}---the expected utility for a unilateral deviator---for symmetric normal-form game instances.
This technique leverages the compactness of payoff functions in games with symmetric players.
The learned deviation payoff function supports equilibrium computation without the combinatorial mixture summations required for direct payoff functions.
**Hart, "Learning Deviation Payoffs through Iterative Evolutionary Search"** learn deviation payoffs as part of a method to approximate mixed-strategy Bayes-Nash equilibria through iterative evolutionary search. 
**Wellman, "Learning Compact Models of Deviation Payoffs in Symmetric Games"** learn the deviation payoff function for families of related symmetric normal-form game instances, showing that this approach achieves higher payoff accuracy with less data than learning separate models for each game instance. 

% % % % % % % % % % % %
% Applications of EMD %
% % % % % % % % % % % %
\subsection{Applications of EMD}

**Dietz, "Optimal Storage Costs in Supply Chain Management"** study the effectiveness of storage costs in deterring large initial procurement in a supply chain management scenario.
They analyze five game instances with different storage costs, and find that none effectively deter large procurement without sacrificing profitability. 
**Wellman, "Reserve Scores in Online Advertising Auctions"** examine how reserve scores impact publisher revenue in online advertising auctions, analyzing fourteen game instances and identifying the revenue-maximizing reserve score. 
Finally, **Hart, "Optimal Clearing Intervals in Frequent Call Markets"** investigate the optimal clearing interval in a frequent call market to maximize allocative efficiency as other environment parameters, such as the number of agents and trade opportunities, are varied. 

% % % % % % % % % % 
% Methods for EMD %
% % % % % % % % % %
\subsection{Methods for EMD}

**Dietz, "Automated Mechanism Design through Black-Box Optimization"** present an automated mechanism design procedure, framing EMD as a black-box optimization problem compatible with any evaluation method.
Evaluating the objective function for a candidate mechanism setting is a subproblem that involves finding an approximate equilibrium in the induced game and computing the objective value in equilibrium. 
**Wellman, "PAC-Learning Framework for EMD"** introduce a PAC-learning framework for EMD that includes approximate equilibrium estimation and parameter search with Bayesian optimization.
**Hart, "Direct Learning of Equilibrium Objective Functions"** directly learn the equilibrium objective function in empirical all-pay auctions or crowdsourcing contests, bypassing player utility learning.
Their approach depends on direct equilibrium approximation in multiple game instances to generate the training set, which may pose challenges in a large empirical game family with a limited sampling budget. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % % % % % % %
% Background  %