@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@article{kim2024finer,
  title={Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models},
  author={Kim, Jeonghwan and Ji, Heng},
  journal={arXiv preprint arXiv:2402.16315},
  year={2024}
}

@article{geigle2024african,
  title={African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification},
  author={Geigle, Gregor and Timofte, Radu and Glava{\v{s}}, Goran},
  journal={arXiv preprint arXiv:2406.14496},
  year={2024}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{gu2021domain,
  title={Domain-specific language model pretraining for biomedical natural language processing},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={ACM Transactions on Computing for Healthcare (HEALTH)},
  volume={3},
  number={1},
  pages={1--23},
  year={2021},
  publisher={ACM New York, NY}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={665--673},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{tishby2000information,
  title={The information bottleneck method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}
@techreport{WahCUB_200_2011,
	Title = {CUB-200},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@inproceedings{KhoslaYaoJayadevaprakashFeiFei_FGVC2011,
author = "Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Li Fei-Fei",
title = "Novel Dataset for Fine-Grained Image Categorization",
booktitle = "First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition",
year = "2011",
month = "June",
address = "Colorado Springs, CO",
}
@article{wang2022text,
  title={Text embeddings by weakly-supervised contrastive pre-training},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2212.03533},
  year={2022}
}
@techreport{maji13fine-grained,
   title         = {Fine-Grained Visual Classification of Aircraft},
   author        = {S. Maji and J. Kannala and E. Rahtu
                    and M. Blaschko and A. Vedaldi},
   year          = {2013},
   archivePrefix = {arXiv},
   eprint        = {1306.5151},
   primaryClass  = "cs-cv",
}
@article{tschandl2018ham10000,
  title={The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions},
  author={Tschandl, Philipp and Rosendahl, Cliff and Kittler, Harald},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--9},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{kermany2018identifying,
  title={Identifying medical diagnoses and treatable diseases by image-based deep learning},
  author={Kermany, Daniel S and Goldbaum, Michael and Cai, Wenjia and Valentim, Carolina CS and Liang, Huiying and Baxter, Sally L and McKeown, Alex and Yang, Ge and Wu, Xiaokang and Yan, Fangbing and others},
  journal={cell},
  volume={172},
  number={5},
  pages={1122--1131},
  year={2018},
  publisher={Elsevier}
}
@misc{vipoooool_2020,
  author       = {Vipooool}, 
  title        = {New Plant Diseases Dataset}, 
  year         = {2020},
  howpublished = {\url{https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset}},
  note         = {Accessed: 2024-09-25}
}
@inproceedings{kwon2023efficient,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  pages={611--626},
  year={2023}
}
@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, T},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}
@misc{openai_2023,
  author       = {OpenAI},
  title        = {Hello GPT-4o},
  year         = {2023},
  howpublished = {\url{https://openai.com/index/hello-gpt-4o/}},
  note         = {Accessed: 2024-09-25}
}



@article{ding2022explainability,
  title={Explainability of artificial intelligence methods, applications and challenges: A comprehensive survey},
  author={Ding, Weiping and Abdel-Basset, Mohamed and Hawash, Hossam and Ali, Ahmed M},
  journal={Information Sciences},
  volume={615},
  pages={238--292},
  year={2022},
  publisher={Elsevier}
}

@article{schuff2022challenges,
  title={Challenges in explanation quality evaluation},
  author={Schuff, Hendrik and Adel, Heike and Qi, Peng and Vu, Ngoc Thang},
  journal={arXiv preprint arXiv:2210.07126},
  year={2022}
}
@article{mohseni2021multidisciplinary,
  title={A multidisciplinary survey and framework for design and evaluation of explainable AI systems},
  author={Mohseni, Sina and Zarei, Niloofar and Ragan, Eric D},
  journal={ACM Transactions on Interactive Intelligent Systems (TiiS)},
  volume={11},
  number={3-4},
  pages={1--45},
  year={2021},
  publisher={ACM New York, NY}
}

@inproceedings{nourani2019effects,
  title={The effects of meaningful and meaningless explanations on trust and perceived system accuracy in intelligent systems},
  author={Nourani, Mahsan and Kabir, Samia and Mohseni, Sina and Ragan, Eric D},
  booktitle={Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  volume={7},
  pages={97--105},
  year={2019}
}

@inproceedings{xu2023magic,
  title={Magic: Investigation of large language model powered multi-agent in cognition, adaptability, rationality and collaboration},
  author={Xu, Lin and Hu, Zhiyuan and Zhou, Daquan and Ren, Hongyu and Dong, Zhen and Keutzer, Kurt and Ng, See-Kiong and Feng, Jiashi},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year={2023}
}

@article{fan2020can,
  title={Can we trust your explanations? Sanity checks for interpreters in Android malware analysis},
  author={Fan, Ming and Wei, Wenying and Xie, Xiaofei and Liu, Yang and Guan, Xiaohong and Liu, Ting},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={16},
  pages={838--853},
  year={2020},
  publisher={IEEE}
}

@inproceedings{zhu2018texygen,
  title={Texygen: A benchmarking platform for text generation models},
  author={Zhu, Yaoming and Lu, Sidi and Zheng, Lei and Guo, Jiaxian and Zhang, Weinan and Wang, Jun and Yu, Yong},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={1097--1100},
  year={2018}
}

@article{liu2021generated,
  title={Generated knowledge prompting for commonsense reasoning},
  author={Liu, Jiacheng and Liu, Alisa and Lu, Ximing and Welleck, Sean and West, Peter and Bras, Ronan Le and Choi, Yejin and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2110.08387},
  year={2021}
}

@article{liu2024democratizing,
  title={Democratizing fine-grained visual recognition with large language models},
  author={Liu, Mingxuan and Roy, Subhankar and Li, Wenjing and Zhong, Zhun and Sebe, Nicu and Ricci, Elisa},
  journal={arXiv preprint arXiv:2401.13837},
  year={2024}
}

@article{zhou2024calibrated,
  title={Calibrated self-rewarding vision language models},
  author={Zhou, Yiyang and Fan, Zhiyuan and Cheng, Dongjie and Yang, Sihan and Chen, Zhaorun and Cui, Chenhang and Wang, Xiyao and Li, Yun and Zhang, Linjun and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2405.14622},
  year={2024}
}

@article{zhou2024aligning,
  title={Aligning modalities in vision large language models via preference fine-tuning},
  author={Zhou, Yiyang and Cui, Chenhang and Rafailov, Rafael and Finn, Chelsea and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2402.11411},
  year={2024}
}
@article{yuan2024self,
  title={Self-rewarding language models},
  author={Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason},
  journal={arXiv preprint arXiv:2401.10020},
  year={2024}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{yang2024synthetic,
  title={Synthetic continued pretraining},
  author={Yang, Zitong and Band, Neil and Li, Shuangping and Cand{\`e}s, Emmanuel and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2409.07431},
  year={2024}
}

@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}
@article{brown2024large,
  title={Large language monkeys: Scaling inference compute with repeated sampling},
  author={Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2407.21787},
  year={2024}
}

@article{li2024llava,
  title={Llava-med: Training a large language-and-vision assistant for biomedicine in one day},
  author={Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}
@article{wu2023language,
  title={From language modeling to instruction following: Understanding the behavior shift in llms after instruction tuning},
  author={Wu, Xuansheng and Yao, Wenlin and Chen, Jianshu and Pan, Xiaoman and Wang, Xiaoyang and Liu, Ninghao and Yu, Dong},
  journal={arXiv preprint arXiv:2310.00492},
  year={2023}
}

@inproceedings{yue2024mmmu,
  title={Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi},
  author={Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9556--9567},
  year={2024}
}

@misc{zhang2024lmmsevalrealitycheckevaluation,
      title={LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models}, 
      author={Kaichen Zhang and Bo Li and Peiyuan Zhang and Fanyi Pu and Joshua Adrian Cahyono and Kairui Hu and Shuai Liu and Yuanhan Zhang and Jingkang Yang and Chunyuan Li and Ziwei Liu},
      year={2024},
      eprint={2407.12772},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12772}, 
}

@inproceedings{lin2024vila,
  title={Vila: On pre-training for visual language models},
  author={Lin, Ji and Yin, Hongxu and Ping, Wei and Molchanov, Pavlo and Shoeybi, Mohammad and Han, Song},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26689--26699},
  year={2024}
}
@article{chen2024mllm,
  title={Mllm-as-a-judge: Assessing multimodal llm-as-a-judge with vision-language benchmark},
  author={Chen, Dongping and Chen, Ruoxi and Zhang, Shilin and Liu, Yinuo and Wang, Yaochen and Zhou, Huichi and Zhang, Qihui and Zhou, Pan and Wan, Yao and Sun, Lichao},
  journal={arXiv preprint arXiv:2402.04788},
  year={2024}
}
@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{deng2024enhancing,
  title={Enhancing Large Vision Language Models with Self-Training on Image Comprehension},
  author={Deng, Yihe and Lu, Pan and Yin, Fan and Hu, Ziniu and Shen, Sheng and Zou, James and Chang, Kai-Wei and Wang, Wei},
  journal={arXiv preprint arXiv:2405.19716},
  year={2024}
}
@article{gao2023g,
  title={G-llava: Solving geometric problem with multi-modal large language model},
  author={Gao, Jiahui and Pi, Renjie and Zhang, Jipeng and Ye, Jiacheng and Zhong, Wanjun and Wang, Yufei and Hong, Lanqing and Han, Jianhua and Xu, Hang and Li, Zhenguo and others},
  journal={arXiv preprint arXiv:2312.11370},
  year={2023}
}

@inproceedings{poole2019variational,
  title={On variational bounds of mutual information},
  author={Poole, Ben and Ozair, Sherjil and Van Den Oord, Aaron and Alemi, Alex and Tucker, George},
  booktitle={International Conference on Machine Learning},
  pages={5171--5180},
  year={2019},
  organization={PMLR}
}

@inproceedings{shi2023gigamae,
  title={Gigamae: Generalizable graph masked autoencoder via collaborative latent space reconstruction},
  author={Shi, Yucheng and Dong, Yushun and Tan, Qiaoyu and Li, Jundong and Liu, Ninghao},
  booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages={2259--2269},
  year={2023}
}

@article{brickentowards,
       title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
       author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
       year={2023},
       journal={Transformer Circuits Thread},
       note={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
    }

@article{rajamanoharan2024improving,
  title={Improving dictionary learning with gated sparse autoencoders},
  author={Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Lieberum, Tom and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2404.16014},
  year={2024}
}

@article{bills2023language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  journal={URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)},
  volume={2},
  year={2023}
}
@article{lieberum2024gemma,
  title={Gemma scope: Open sparse autoencoders everywhere all at once on gemma 2},
  author={Lieberum, Tom and Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Sonnerat, Nicolas and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Dragan, Anca and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2408.05147},
  year={2024}
}

@article{rajamanoharan2024jumping,
  title={Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders},
  author={Rajamanoharan, Senthooran and Lieberum, Tom and Sonnerat, Nicolas and Conmy, Arthur and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Nanda, Neel},
  journal={arXiv preprint arXiv:2407.14435},
  year={2024}
}

@article{liu2023mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2307.06281},
  year={2023}
}
@article{liu2024best,
  title={Best practices and lessons learned on synthetic data for language models},
  author={Liu, Ruibo and Wei, Jerry and Liu, Fangyu and Si, Chenglei and Zhang, Yanzhe and Rao, Jinmeng and Zheng, Steven and Peng, Daiyi and Yang, Diyi and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2404.07503},
  year={2024}
}

@article{chen2024self,
  title={Self-play fine-tuning converts weak language models to strong language models},
  author={Chen, Zixiang and Deng, Yihe and Yuan, Huizhuo and Ji, Kaixuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2401.01335},
  year={2024}
}

@article{luo2024mmevol,
  title={MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct},
  author={Luo, Run and Zhang, Haonan and Chen, Longze and Lin, Ting-En and Liu, Xiong and Wu, Yuchuan and Yang, Min and Wang, Minzheng and Zeng, Pengpeng and Gao, Lianli and others},
  journal={arXiv preprint arXiv:2409.05840},
  year={2024}
}

@misc{fu2023mme,
  title={MME: a comprehensive evaluation benchmark for multimodal large language models. CoRR abs/2306.13394 (2023)},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Qiu, Zhenyu and Lin, Wei and Yang, Jinrui and Zheng, Xiawu and others},
  year={2023}
}
@article{chen2024we,
  title={Are We on the Right Way for Evaluating Large Vision-Language Models?},
  author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Chen, Zehui and Duan, Haodong and Wang, Jiaqi and Qiao, Yu and Lin, Dahua and others},
  journal={arXiv preprint arXiv:2403.20330},
  year={2024}
}
@article{li2024seed,
  title={Seed-bench-2-plus: Benchmarking multimodal large language models with text-rich visual comprehension},
  author={Li, Bohao and Ge, Yuying and Chen, Yi and Ge, Yixiao and Zhang, Ruimao and Shan, Ying},
  journal={arXiv preprint arXiv:2404.16790},
  year={2024}
}

@inproceedings{liu2024mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  booktitle={European conference on computer vision},
  pages={216--233},
  year={2024},
  organization={Springer}
}