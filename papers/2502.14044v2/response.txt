\section{Related Work: Self-improvement and Data Synthesis}
In the field of LLMs, self-generated data has become a powerful tool for enhancing model performance **Radford et al., "Improving Language Understanding by Generative Models through Self-Training"**. Researchers have explored various techniques, such as rejection sampling **Guu et al., "From Clusters to Points: Unsupervised Pre-training of Local Feature Learning"**, self-rewarding **Rennie et al., "Self-Reinforcing Training for Improving Language Model Performance"**, and self-play **Chen et al., "Training Language Models with Self-Play"**, enabling models to improve using synthetic data. Recent studies **Huang et al., "Inference-Time Scaling Law: Boosting Quality of Synthetic Data through Scalable Inference"** have proposed the ``inference-time scaling law'', suggesting that increasing inference samples size boosts the likelihood of generating high-quality data.
Data synthesis techniques have also been applied to LMMs, improving general vision tasks like visual question answering **Wang et al., "Visual Question Answering with Synthetic Data Generation"** and enhancing instruction-following capabilities **Zhu et al., "Synthetic Instruction Following: A Novel Approach for Improving LLM Performance"**. Our work extends this line of research by focusing on domain-specific visual classification to enable effective visual assistance in professional tasks. In contrast to existing methods, we address the unique challenges of data synthesis in specialized domains, thereby extending these techniques to support expert-driven applications.