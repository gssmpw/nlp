
\setcounter{section}{0}
\renewcommand{\thesection}{\Alph{section}}

\section{Detailed Scenarios and Judge Criteria} \label{app:scenario}

We detail the ten scenarios currently supported by \modelname as well as their descriptions and judge criteria in this section.

\stitle{Question-answer Scenarios}

\etitle{(1) Close QA} 
Solve a problem that may involve professional knowledge or real-world inquiries, such as historical facts or scientific laws, and the problem has a standard/reference answer.

Judge criteria.   
1. \emph{Accuracy}: Answers must be accurate and factual, consistent with known scientific principles.
2. \emph{Relevance}: Answers should be direct and focused on the content of the question, avoiding unnecessary information and background.
3. \emph{Harmlessness}: Answers should avoid any potentially offensive content, ensuring appropriateness and cultural sensitivity, and adhere to ethical standards.
4. \emph{Completeness}: Answers should comprehensively cover all aspects of the question, with no key points omitted, while following user instructions.
5. \emph{Source credibility}: When providing factual information, authoritative, credible sources should be cited.
6. \emph{Clarity and structure}: Answers should be clearly structured and logical, making it easy for users to understand and follow the information.
7. \emph{Timeliness}: Information should be up-to-date, especially on questions in rapidly changing fields.
8. \emph{Adaptability to user level}: Answers should consider the user's knowledge level, ensuring the content is understandable to the user.

\etitle{(2) Open QA} Open dialogue instructions, usually asking an open-field question, and responses are also open-ended, such as casual chats, advice consultations, recommendations, etc.

Judge criteria.   
1. \emph{Accuracy}: Ensure the accuracy of the provided information, adhering to common sense and facts, avoiding misleading the user.
2. \emph{Relevance}: Answers must address the user's questions, avoiding irrelevant content, and ensuring the relevance of the information.
3. \emph{Cultural sensitivity}: Understand and respect the user's cultural background and differences, adhering to ethical standards, avoiding cultural bias and insensitive expressions, and avoiding potentially offensive content.
4. \emph{Information richness}: While ensuring accuracy, provide detailed information, especially background information that may not be explicitly requested by the user but is helpful in understanding the question.
5. \emph{Clarity}: Use clear and understandable language to answer questions, avoiding professional terms or complex constructions that could cause misunderstanding.
6. \emph{User engagement}: Encourage further interaction with the user, showing attention and thought to their questions, and promoting engagement through follow-up questions or feedback.
7. \emph{Empathy}: Consider the user's emotional state when responding, appropriately expressing empathy and understanding, especially when answering emotionally charged questions.
8. \emph{Constructive feedback}: Even when facing critical or negative questions, maintain a positive and constructive attitude, providing valuable responses and suggestions.

\etitle{(3) Math-related QA} Solve a problem involving mathematics, calculations, reasoning, etc., and the problem has a standard/reference answer.

Judge criteria.   
1. \emph{Accuracy}: Answers should be error-free, including the final result and every step of calculation and reasoning during the solution process.
2. \emph{Clarity}: The explanation of the solution process should be clear, easy to understand, unambiguous, and use correct mathematical terms and concepts.
3. \emph{Efficiency}: The solution should be direct and as concise as possible, avoiding unnecessary lengthy explanations while ensuring accuracy and completeness.
4. \emph{Instruction adherence}: Strictly follow the problem requirements and user instructions, including specific constraints and steps.
5. \emph{Formatting}: Mathematical symbols, formulas, and diagrams should comply with academic norms and maintain consistency and readability.
6. \emph{Methodological diversity}: Where possible, provide multiple solution methods and point out their respective advantages and disadvantages.
7. \emph{Answer structure}: First provide a clear answer, followed by steps and explanations, and finally summarize key points or common mistakes.

\stitle{Writing scenarios}

\etitle{(4) Creative writing} Writing that primarily expresses personalized imagination and emotions, focusing on literary quality and originality, such as creating essays, poems, lyrics, scripts, stories, speeches, social media posts, blogs, advertising materials, brainstorming, etc.

Judge criteria.   
1. \emph{Originality}: The work should reflect the author's independent thinking, include original views and ideas, avoiding plagiarism.
2. \emph{Emotional expression}: The work should effectively convey the author's emotions, resonating with the reader.
3. \emph{Creativity}: The work should exhibit creativity, including unique thinking, language use, and plot construction.
4. \emph{Cultural sensitivity}: The work should respect and consider cultural diversity, avoiding cultural bias, and ensuring the content is free from offensive, inappropriate, or discriminatory material.
5. \emph{Text coherence}: The work should be fluid and logically coherent, with a clear storyline for narrative works.
6. \emph{Stylistic adaptability}: The work should match its style or genre with appropriate writing style and language use.
7. \emph{Imagery and language}: The work should engage readers with expressive language and powerful imagery, enhancing visual and sensory experiences.
8. \emph{User-friendly}: The work should consider the background of the target readers, ensuring content is accessible and readable.

\etitle{(5) Informative and professional writing} Writing aimed at conveying key information and professional knowledge, focusing on accuracy, reliability, and authority, covering practical emails, job applications, product descriptions, user manuals, to in-depth academic papers, medical research, legal opinions, engineering design, industry analysis, economic forecasts, and other complex documents.

Judge criteria.   
1. \emph{Accuracy}: Content must be based on facts and reliable data, reflecting the latest research and real-world conditions to ensure accuracy.
2. \emph{Credibility}: Content should demonstrate authority in its scientific or professional field, supported by reliable sources to build credibility, and provide a detailed assessment framework to increase objectivity.
3. \emph{Harmlessness}: Writing content should meet ethical standards, avoid offensive, inappropriate, or discriminatory material, ensuring the text's harmlessness.
4. \emph{Clarity and coherence}: Information transmission should be clear, accurate, logically rigorous, and sound in arguments, ensuring all readers can easily and orderly understand the conveyed information.
5. \emph{Relevance}: Content should be directly relevant to the topic, focused on the target audience's needs and purposes, avoiding irrelevant information, and ensuring content is valuable to the audience.
6. \emph{Professionalism}: The text should correctly use professional terms and concepts, reflecting the author's deep knowledge and skills in the relevant field, and clearly articulated to suit readers of different levels.
7. \emph{Originality}: The text should reflect the author's original thinking, showcasing unique research, insights, or analysis, ensuring the content's uniqueness.
8. \emph{Formatting standards}: Documents should follow appropriate formatting and design standards, using appropriate professional terms, typesetting, and design elements to enhance content clarity and professional presentation.
9. \emph{Audience engagement}: The text should consider the audience's needs and interests, attract readers through content appeal, effective communication, and interactivity, expanding its impact and response among the audience.

\etitle{(6) Rewriting}  Includes text simplification, language optimization, rewriting text according to instructions, text correction, text summarization and expansion, etc.

Judge criteria.   
1. \emph{Accuracy}: The rewritten text should faithfully convey the original information, avoiding misleading content.
2. \emph{Compliance}: The rewriting should strictly follow the key steps and specific constraints required by the instructions.
3. \emph{Harmlessness}: The text should avoid offensive, inappropriate or discriminatory content.
4. \emph{Text quality}: The text should be grammatically correct, free of spelling errors, and maintain consistency in style, tone, and information.
5. \emph{Relevance}: The rewritten text should be relevant to the target audience and context, ensuring adaptability and targeting.
6. \emph{Conciseness}: The text should be concise and clear, avoiding unnecessary redundancy to convey information clearly.
7. \emph{Originality}: The rewritten text should demonstrate originality, avoiding plagiarism, and providing unique insights or expressions.
8. \emph{Cultural sensitivity}: The text should consider diverse cultural backgrounds, respecting different cultural values and expression habits.

\stitle{Professional scenarios}

\etitle{(7) Translation} Translate the given text into another language without changing the original meaning.

Judge criteria.   
1. \emph{Faithfulness}: The translation needs to maintain fidelity to the original content, ensuring accurate transmission of information, style, and cultural connotations, avoiding misunderstandings.
2. \emph{Fluency}: The translation should be natural and fluent, conforming to the linguistic habits of the target language and easy for readers to understand.
3. \emph{Accuracy}: Terminology and factual information in the translation should be accurate, especially professional terms and data.
4. \emph{Adaptability}: The translation should be adaptively adjusted according to different contexts and target audiences.
5. \emph{Coherence}: The translation should maintain internal logical consistency, ensuring the information's consistency throughout the text.
6. \emph{Cultural appropriateness}: The translation should respect and convey the original text's cultural characteristics while considering the target language's cultural acceptance.
7. \emph{Harmlessness}: The translation should avoid any potentially misleading or offensive content, ensuring cultural and contextual sensitivity.
8. \emph{Innovation}: Without violating the original meaning, the translation should demonstrate creativity, making the translation dynamic and closer to the target language's expression habits.


\etitle{(8) Reading comprehension and extraction} Read materials and complete directive tasks based on the materials, such as Q\&A, summarization, keyword extraction, topic extraction, title generation, fact-checking, etc.

Judge criteria.   
1. \emph{Accuracy}: Answers should strictly correspond to the given context information, correctly responding to the questions, even if the context information might be incorrect or outdated.
2. \emph{Relevance}: Answers should directly correspond to the text content or topic, avoiding irrelevant information, ensuring all provided information has a clear textual or thematic basis.
3. \emph{Instruction compliance}: The output should strictly follow the specific requirements of the instructions, including action steps and any constraints.
4. \emph{Text coherence}: Answers should have internal logical consistency and fluency, ensuring the consistency and coherence of the information.
5. \emph{User experience}: Answers should be presented in a user-friendly manner, easy to understand, and guide the user to obtain the needed information timely.
6. \emph{Contextual understanding}: The model should demonstrate the ability to understand complex contexts and implicit information.
7. \emph{Conciseness}: Information expression should be direct and concise, avoiding unnecessary elaboration or complexity.
8. \emph{Creativity}: In tasks requiring creative output (such as title or summary generation), answers should exhibit a certain degree of originality and appeal.

\etitle{(9) Role-playing} Pretend to be a particular person, character, profession, or identity, and complete the tasks in the instructions based on this role.

Judge criteria.   
1. \emph{Role fidelity}: Responses should strictly adhere to the role setting, reflecting the role’s background, behavior patterns, and characteristics.
2. \emph{Instruction compliance}: Ensure responses follow the requirements in the user's instructions, including key steps and constraints, with no omissions.
3. \emph{Safety}: Responses should avoid including any harmful or offensive content, whether overt or covert, ensuring the interaction is safe and positive.
4. \emph{Creativity}: Encourage innovative and personalized responses, showcasing the unique traits of the role while complying with the role setting and user instructions.
5. \emph{Information quality}: Responses should provide high-quality information, both professional and relevant, consistent with the role’s knowledge background.
6. \emph{Engagement}: Responses should encourage user participation and interaction, enhancing the immersive experience and user engagement in role playing.
7. \emph{Text clarity}: Text should be clear and accurate, free of grammatical errors or typos, with straightforward expressions.
8. \emph{Response efficiency}: Responses should be timely and concise, avoiding unnecessary delays, and improving interaction smoothness.

\etitle{(10) Programming-related}  Tasks related to computer code, including implementing code based on requirements, code modification and optimization, programming language conversion, analyzing code and responding to related questions, software development assistance, education, and learning, etc.

Judge criteria.   
1. \emph{Code correctness}: Code should strictly follow the requirements or specifications, free from syntax or logic errors, achieving the intended functionality.
2. \emph{Code maintainability}: Code should be easy to understand and modify, with good modularity, documentation comments, and adherence to coding standards.
3. \emph{Security and safety}: Code should not contain any potential security vulnerabilities or malicious behaviors, handle all types of input safely, and have a stable error-handling mechanism.
4. \emph{Performance efficiency}: Code should execute efficiently, with optimized resource utilization, considering the algorithm's complexity and data structure choice.
5. \emph{Analysis accuracy}: Code analysis should be thorough and accurate, correctly understanding the code logic, data flow, and structure.
6. \emph{Modularity}: The written code should be modular, clearly separating concerns. It should use appropriate functions, classes, and modules to facilitate reusability and maintainability.
7. \emph{Comprehensibility of explanations}: Explanations and analyses of the code should be clear, easy to understand by users, with appropriate terms and language style.
8. \emph{Problem-solving effectiveness}: In tasks involving code modification, optimization, and programming language conversion, the generated or analyzed code should effectively solve the specified problem.
9. \emph{Input/output adherence}: Code should handle input and output in accordance with user-specified requirements, including format, type, and size. In the absence of specific instructions, it should follow common standards.

\begin{table}[tbh!]
  \centering
  \caption{Scenario mapping between \modelname and Llama-3}
  \label{tab:scenarioComp}
  \begin{tabularx}{.47\textwidth}{X X}
    \toprule
    \textbf{\modelname scenarios} & \textbf{Llama-3 use cases} \\ \midrule
    (1*) Closed-QA & (1) Closed question answering \\ \midrule
    \multirow{3}{*}{(2*) Open-QA} & (2) Open question answering  \\
        & (3) Asking for advice  \\ 
        & (4) Brainstorming \\ \midrule
    (3) Math-related QA & (5) Reasoning  \\ \midrule 
    (4*) Creative writing & (6) Creative writing  \\ \midrule
    (5) Info. and prof. writing &  \texttt{NA} \\ \midrule
    (6*) Rewriting & (7) Rewriting  \\ \midrule
    (7) Translation & \texttt{NA} \\ \midrule
    \multirow{2}{*}{(8*) Reading compre. and extrac.} & (8) Extraction  \\
    & (9) Summarization  \\ \midrule
    (9*) Role-playing & (10) Inhabiting a character  \\ \midrule
    (10*) Programming-related & (11) Coding  \\ \midrule
    \texttt{NA} & (12) Classification  \\ 
    \bottomrule
  \end{tabularx}
\end{table}

\stitle{Justification for scenario design}
Table~\ref{tab:scenarioComp} illustrates the mapping between \modelname's scenarios and Llama-3's evaluation use cases~\cite{llama3tech}. 
From the table we can see that 7 out of \modelname's 10 scenarios, \ie those with *, have direct mapping to the ones of Llama-3. The remaining math-related QA, informative and professional writing, and translation are popular applications of LLMs and deserve context-specific evaluations.
On the other side, 11 out of Llama-3's 12 use cases, except for classification, are covered by \modelname.
As the scenario design of \modelname is independent with Llama-3, the above comparison could be regarded as an empirical justification for our scenario design through human-AI collaboration.



%Specifically, we fill in the following values:
%\begin{itemize}
%    \item \texttt{reference text} in Table~\ref{tab:prompt-qllm-train}
%\end{itemize}



\begin{table*}[tbh!]
  \caption{Prompt template for reference-guided grading. Difference with Table~\ref{tab:prompt} have been emphasized in bold.}
  \label{tab:prompt-with-ref}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        \emph{The same task description as in Table~\ref{tab:prompt}.}

        \ 
        
        \emph{The same grading guidelines as in Table~\ref{tab:prompt}.}
        
        \
        
        Regarding a user instruction of [\texttt{\{scenario name\}}] \textbf{and the corresponding reference answer}, we have collected the following AI assistant response. \textbf{Based on your understanding of the current evaluation standards, compare the reference answers and evaluate these responses comprehensively.  Note that the reference answer may not be the only possible one; it is merely used to demonstrate the standard for a high-level (specifically, at the 4th tier) response.} Below are the user instruction, \textbf{reference answer}, and the assistant's response data: 
        
        [Data Begin] 
        
        ***
        
        [User Instruction]: \texttt{\{instruction\}} 
        
        *** 

        \textbf{[Reference answer]: \texttt{\{reference answer\}}} 
        
        ***
        
        [Response]: \texttt{\{response\}}
        
        ***
        
        [Data End] 

        \
        
        You need to follow these steps to evaluate the above response: 
        
        1. Recall the relevant AI assistant response criteria and carefully read and understand the response to be evaluated.
        
        2. Identify from all criteria the key ones for the current user instruction and response, including those that performed well and those that did not. 
        
        3. Besides the given criteria, add any other important criteria that you think are necessary for evaluating the current user instruction response. 
        
        4. Based on your final selection of criteria, \textbf{compare the reference answer and} assign scores (between 1-5) to each criterion, and provide a comprehensive score after weighting all sub-scores. 

        \ 
        
        \emph{The same output requirement and format as in Table~\ref{tab:prompt}.}  \\
    \bottomrule
  \end{tabularx}
\end{table*}







\begin{table*}[tbh!]
  \caption{Prompt template for pairwise comparison. Difference with Table~\ref{tab:prompt} have been emphasized in bold.}
  \label{tab:prompt-pairwise}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        \emph{The same task description as in Table~\ref{tab:prompt}.}

        \ 
        
        \emph{The same grading guidelines as in Table~\ref{tab:prompt}.}
        
        \
        
        Regarding a user instruction of [\texttt{\{scenario name\}}] , we have collected \textbf{two responses from AI assistants. Based on your understanding of the current standards for responses, comprehensively evaluate and determine which response is better or if they are tied (including both being good or both being bad).} Below are the user instruction and the assistant's response data: 
        
        [Data Begin] 
        
        ***
        
        [User Instruction]: \texttt{\{instruction\}} 
        
        *** 
        
        \textbf{[Response 1]: \texttt{\{response 1\}}}
        
        ***

        \textbf{[Response 2]: \texttt{\{response 2\}}}

        ***
        
        [Data End] 

        \
        
        \emph{The same evaluation steps as in Table~\ref{tab:prompt}.}

        \ 
        
        Think carefully and then provide your conclusion. Your response should keep the `[[' and `]]' symbols in the output: 
        
        I believe \textbf{[[Response 1 is better]]/[[Response 2 is better]]/[[Both Responses are tied]], with the overall score for Response 1 being [[a score between 1 and 5]], and the overall score for Response 2 being [[a score between 1 and 5]], based on the following reasons:}
        
        \textbf{1. (Please detail your reasons in order of importance from high to low, each standard also attaching the [[scores]] for both responses under that standard...)}   \\
    \bottomrule
  \end{tabularx}
\end{table*}






\section{Prompts}
\label{app:prompts}

Prompts related to \modelname training and inference are summarized in this section, including the ones for reference-guided grading (Table~\ref{tab:prompt-with-ref}), pairwise comparison (Table~\ref{tab:prompt-pairwise}), reference-based question synthesis (Table~\ref{tab:prompt-qllm-train}), role-playing quizzing for three scenarios (Table~\ref{tab:prompt-rpq-math}--\ref{tab:prompt-rpq-reading}), and fint-tuning the sceanrio classification LLM (Table~\ref{tab:prompt-scenario-classification}). Note that \{\texttt{variable}\} represents a variable and should be filled in properly for all prompts. 

We also illustrate a complete evaluation record for supervised fine-tuning, with the evaluation input in Table~\ref{tab: math example} and the evaluation result by GPT-4 in Table~\ref{tab: gpt-4's response}. Evaluations by Qwen-max, Qwen-14B, \modelname are also presented (Tables~\ref{tab: qwenmax's response}--\ref{tab: themis' response}). Among the three, we find only \modelname makes a reasonable evaluation. 





\begin{table*}[tbh!]
  \caption{Prompt template for question synthesis to train the questioning model.} %  Note that the prompt used for fine-tuning and inference is the same except for generating one question-answer pair.
  \label{tab:prompt-qllm-train}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        Requirements for the scenario:

        Name: \{\texttt{scenario name}\}
        
        Definition: \{\texttt{scenario description}\}
        
        \ 
        
        Reference Text:
        
        \{\texttt{reference text}\}

        \ 
        
        Requirements:
        
        1. The generated questions and answers should be based on the article content and should meet the scenario requirements.
        
        2. Questions should be detailed, containing necessary information to encourage thorough answers.
        
        3. If the information in the reference text is insufficient to generate question-answer pairs, return the following: "Sorry, this article does not contain enough information related to \{\texttt{scenario name}\} to generate relevant questions and answers."

        4. The generated question-answer pairs need to simulate questions and answers people might consult the LLM about in real-life scenarios.
        
        5. Ensure the completeness and answerability of the questions independently; include the original content if necessary.
        
        6. Ensure the correctness of the answers.
        
        \ 
        
        Sample Questions:
            
            Example 1: \{\texttt{example 1}\}
            
            Example 2: \{\texttt{example 2}\}
            
            Example 3: \{\texttt{example 3}\}

        \

        Please generate 5 sets of question-answer pairs that meet the requirements:
        
        QUESTION: [The generated question based on article content]
        
        ANSWER: [The answer to the question, if possible, based on article content; otherwise, based on model's own knowledge]
        
        LEVEL: [The difficulty level of the question: easy/medium/difficult]
        
        [END OF QA PAIR] \\
    \bottomrule
  \end{tabularx}
\end{table*}






\begin{table*}[tbh!]
  \caption{Prompt template for question generation with role-playing quizzing: math-related QA.}
  \label{tab:prompt-rpq-math}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        I need to create exam questions to assess students' proficiency in mathematics. Please help me generate 10 \{\texttt{difficult level}\} questions for \{\texttt{audience}\} in the subject of \{\texttt{subject}\}. Each question should contain varying numbers of unknowns or mathematical symbols. Ensure the language, clarity, and accuracy of the questions: the problems must be described in \{\texttt{language}\} and be clear and unambiguous with precise definitions to ensure solvability and that a standard answer exists. Please strictly follow my instructions regarding the number of questions.

        \ 
        
        Please output all generated questions in jsonl format, with one question per line in a JSON description, and do not output any additional content. Here is an example of a question:
        
        \{"question": "[the generated question]", "level": "[the difficult level of the question]", "subject": "[the subject of the question]"\}  \\
    \bottomrule
  \end{tabularx}
\end{table*}


\begin{table*}[tbh!]
  \caption{Prompt template for question generation with role-playing quizzing: programming-related.}
  \label{tab:prompt-rpq-code}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        You are a senior recruitment expert with vast hands-on programming experience at 
        [Company: \{\texttt{company}\}]. For the upcoming recruitment season, you are designing a series of unique questions to assess candidates' programming skills. Now, please design 10 \{\texttt{difficult level}\} programming or code analysis questions for \{\texttt{audience}\}, under the theme of \{\texttt{topic}\}. Ensure each question is described in \{\texttt{language}\}, with clear, unambiguous language and well-defined concepts, and that content (code, description, etc.) is complete. Ensure the questions are solvable with a standard answer. The questions or answers should directly involve programming code, with the code ranging from 30 to 50 lines, neither too simple nor too difficult, to be solvable within a reasonable time. When necessary, provide clear code snippets in the questions.

        \ 
        
        Please output all generated questions in jsonl format, with one question per line in a JSON description, and do not output any additional content. Here is an example of a question:

        \{"question": "[the generated question]", "company": "[the company]", "level": "[the question difficult level]", "topic": "[the question topic]"\}

        Stick strictly to your role, think for a moment, and then start drafting the questions. \\
    \bottomrule
  \end{tabularx}
\end{table*}


\begin{table*}[tbh!]
  \caption{Prompt template for question generation with role-playing quizzing: reading comprehension and extraction.}
  \label{tab:prompt-rpq-reading}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        You are now a language expert preparing reading comprehension and extraction questions for a language proficiency test. The task definition is: read materials and complete directive tasks based on the materials, such as Q\&A, summarization, keyword extraction, topic extraction, title generation, fact-checking, etc.
        Please prepare 10 questions based on the following reading materials. The questions need to cover various task types, such as: [title generation, summary, theme keyword extraction], [key information and concept Q\&A], [content understanding, explanation, and fact-checking], [content comparison, analysis, and summary], [critical thinking and secondary creation]. Ensure a relatively balanced distribution across different task types. Ensure each question is described in \{\texttt{language}\}, clear and unambiguous with well-defined concepts, and the description is complete. Ensure the questions are solvable without exceeding the scope of the reading materials.
        
        \ 
        
        Please output all generated questions in jsonl format, with one question per line in a JSON description, in the following format:
        
        \{"question": "[the generated question]", "answer": "[your answer to the question]", "task": "[the task type]"\}

        Stick strictly to your role, think for a moment, and then start drafting the questions. The reading material is as follows:
        
        \{\texttt{reading material}\}\\
    \bottomrule
  \end{tabularx}
\end{table*}

\begin{table*}[tbh!]
  \caption{Prompt template for fine-tuning the scenario classification LLM.}
  \label{tab:prompt-scenario-classification}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        User queries for large language models can generally be categorized into the following 10 scenarios:

        1. Close QA: Solve a problem that may involve professional knowledge or real-world inquiries, such as historical facts or scientific laws, and the problem has a standard/reference answer.

        2. Open QA: Open dialogue instructions, usually asking an open-field question, and responses are also open-ended, such as casual chats, advice consultations, recommendations, etc.

        3. Math-related QA: Solve a problem involving mathematics, calculations, reasoning, etc., and the problem has a standard/reference answer.

        4. Creative writing: Writing that primarily expresses personalized imagination and emotions, focusing on literary quality and originality, such as creating essays, poems, lyrics, scripts, stories, speeches, social media posts, blogs, advertising materials, brainstorming, etc.
        
        5. Informative and professional writing: Writing aimed at conveying key information and professional knowledge, focusing on accuracy, reliability, and authority, covering practical emails, job applications, product descriptions, user manuals, to in-depth academic papers, medical research, legal opinions, engineering design, industry analysis, economic forecasts, and other complex documents.
        
        6. Rewriting:  Includes text simplification, language optimization, rewriting text according to instructions, text correction, text summarization and expansion, etc.
        
        7. Translation: Translate the given text into another language without changing the original meaning.
        
        8. Reading comprehension and extraction: Read materials and complete directive tasks based on the materials, such as Q\&A, summarization, keyword extraction, topic extraction, title generation, fact-checking, etc.
        
        9. Role-playing: Pretend to be a particular person, character, profession, or identity, and complete the tasks in the instructions based on this role.
        
        10. Programming-related:  Tasks related to computer code, including implementing code based on requirements, code modification and optimization, programming language conversion, analyzing code and responding to related questions, software development assistance, education, and learning, etc.
        
        \ 
        
        Now I have a user query as follows:
    
        [\{\texttt{user instruction}\}]
 
        Please determine which scenario this query belongs to based on the aforementioned 10 scenarios (if you cannot determine, you can classify it as "default").

        Please directly provide the name of the scenario.\\ \midrule
        \{\texttt{labeled scenario}\} \emph{Note: This output will be used for fine-tune.} \\ 
    \bottomrule
  \end{tabularx}
\end{table*}


\begin{table*}[tbh!]
  \caption{A complete prompt about answering mathematical questions.}
  \label{tab: math example}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
    Input \\ \midrule
    Your task is to rate the quality of responses provided by the AI intelligent assistant.\\
    You are very clear that when a user issues an instruction in a scenario about "answering mathematical questions" (defined as: solving a problem involving mathematics, calculation, reasoning, etc., with a standard/reference answer), the response of an AI intelligent assistant should meet the following standards (listed from most to least important):\\
    
    [Standards Start]\\
    
    1. Accuracy: The response should be accurate, including every step of calculations and reasoning involved in the solving process.\\
    2. Clarity: The explanation of the solving process should be clear, easy to understand, unambiguous, and use mathematical terms and concepts correctly.\\
    3. Efficiency: The response should be direct and as concise as possible, avoiding unnecessary lengthy explanations, while ensuring accuracy and completeness.\\
    4. Command Compliance: Strictly follow the problem requirements and user instructions, including handling specific restrictions and steps.\\
    5. Formatting Standards: The use of mathematical symbols, formulas, and diagrams should adhere to academic norms and be consistent and readable.\\
    6. Method Diversity: Where possible, provide multiple solving methods and indicate their respective pros and cons.\\
    7. Answer Structure: Present a clear answer first, followed by steps and explanations, and finally summarize key points or common mistakes.\\
    
    [Standards End]\\
    
    The scoring is on a 5-level scale (1-5), with each score level meaning the following:\\
    
    [Score Levels Start]\\
    
    1 Response has major flaws, completely diverts from standards, and should not appear in practice;\\
    2 Response has some content that meets the standards, can be adopted, but as a whole, the quality of the response is not acceptable;\\
    3 Response has both pros and cons, overall pros outweigh the cons within the required evaluation standards;\\
    4 Response quality is satisfactory, generally meets the standards, with a few minor issues that could be improved. This level represents the response quality as shown in the given reference answer;\\
    5 Response is perfect in all aspects, strictly adheres to the standards. This level represents a response quality better than the reference answer.\\
    
    [Score Levels End]\\
    
    \\
    In response to a user instruction in an "answering mathematical questions" scenario, we collected the following reply from an AI intelligent assistant.\\
    Please assess the response based on your knowledge of the current scenario’s standards for intelligent assistant responses, and provide an evaluation. Here are the user instruction and assistant response data:\\
    
    [Data Start]\\
    
    ***\\
    
    [User Instruction]: Which is greater, 9.11 or 9.9 \\
    
    ***\\
    
    [Response]: First, we need to compare the two numbers 9.9 and 9.11.\\
    
    \\
    The integer part of 9.9 is 9.\\
    The integer part of 9.11 is also 9.\\
    Since the integer parts are the same, we need to compare the decimal parts.\\
    \\
    The decimal part of 9.9 is 0.9.\\
    The decimal part of 9.11 is 0.11.\\
    Comparing the decimal parts, 0.9 is greater than 0.11.\\
    \\
    \textcolor{red}{Therefore, 9.11 is greater than 9.9.}\\
    ***\\
    
    [Data End]\\
    
    \\
    You need to follow the process below to assess the above response:\\
    1. Recall the relevant standards for intelligent assistant responses, and carefully read and understand the response to be assessed.\\
    2. Identify key standards from all standards for the current user instruction and response, including good and insufficient points.\\
    3. In addition to the given standards, add other important standards you think are necessary for evaluating the current user instruction response.\\
    4. Based on your final selection of standards, score the response (between 1-5), and after weighting all minor scores, give an overall score for the response.\\
    Think carefully for a moment, then give your conclusion. Your return template should be as follows, note to retain the '[' and ']' in the output:\\
    ***\\
    I believe the overall score of this response is [[a score between 1-5]], for the following reasons.\\
    Current response strengths:\\
    1. (Please list in sequence what you think are the strengths of the current response, and give [[a score between 1-5]] for each...)\\
    Current response weaknesses:\\
    1. (Please list in sequence what you think are the weaknesses of the current response, and give [[a score between 1-5]] for each...)\\
    ***\\ 
    \bottomrule
  \end{tabularx}
\end{table*}

\begin{table*}[tbh!]
  \caption{Evaluation result from GPT-4 to the prompt in Table~\ref{tab: math example}.}
  \label{tab: gpt-4's response}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        GPT-4's response \\ \midrule

        I believe the overall rating for this reply is [[1]] for the following reasons:\\
        Advantages of the current reply:\\
        1. Clarity: The explanation process is relatively clear, comparing integer parts and decimal parts in steps, which is easy to understand. [[3]]\\
        \\
        Shortcomings of the current reply:\\
        1. Accuracy: The final conclusion of the reply is incorrect; in fact, 9.9 is greater than 9.11, not as stated in the reply that "9.11 is greater than 9.9." [[1]]\\
        2. Efficiency: Although a comparison process is provided, the efficiency becomes meaningless after presenting an incorrect conclusion. [[1]]\\
        3. Instruction Compliance: It fails to correctly follow the command to provide an accurate answer and does not provide the correct comparison result as per the user’s request. [[1]]\\
        4. Method Diversity: It does not offer different comparison methods, such as direct numerical comparison, and only uses a part-by-part comparison approach. [[2]]\\
        5. Answer Structure: Although the structure is clear, comparing integer parts first and then decimal parts, this structure has not effectively served to present the correct answer due to the incorrect final answer. [[1]]\\
        \\
        Considering the above ratings, due to the core issue of accuracy, even though other aspects are passable, the overall rating remains at the lowest tier [[1]].\\
    \bottomrule
  \end{tabularx}
\end{table*}


\begin{table*}[tbh!]
  \caption{Evaluation result from Qwen-Max to the prompt in Table~\ref{tab: math example}.}
  \label{tab: qwenmax's response}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        Qwen-Max's response \\ \midrule

        I believe that the overall rating for this reply is [[3]], for the following reasons.\\
        \\
        Strengths of the current reply:\\
        1. Accuracy: Although the final conclusion is incorrect, the decomposition of numbers during the problem-solving process is quite clear, showing a comparative thought process. [[3]]\\
        2. Clarity: The steps of the solution are clearly articulated, and the logical sequence is easy to understand. [[4]]\\
        3. Compliance with instructions: It directly answered the user's instruction to compare the sizes of two numbers. [[4]]\\
        \\
        Weaknesses of the current reply:\\
        1. Accuracy: The final conclusion is erroneous, stating that 9.11 is larger than 9.9 is incorrect; \textcolor{red}{in reality, 9.9 is less than 9.11}. This is a core error and significantly affects the rating. [[1]]\\
        2. Formatting standards: Although no complex mathematical symbols or formulas were used, the basic comparison symbols should be used correctly. [[2]]\\
        3. Answer structure: The structure of the answer, steps, and explanation is fundamentally reasonable, but the incorrect conclusion impacts the overall effectiveness of the structure. [[2]]\\
        \\
        Taking everything into consideration, despite the reply’s acceptable performance in terms of clarity and following instructions, the core error in accuracy cannot be overlooked, therefore a rating of 3 is given for the overall evaluation.\\
    \bottomrule
  \end{tabularx}
\end{table*}

\begin{table*}[tbh!]
  \caption{Evaluation result from Qwen-14B to the prompt in Table~\ref{tab: math example}.}
  \label{tab: qwenturbo's response}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
        Qwen-Turbo's response \\ \midrule
        I believe the \textcolor{red}{overall rating for this response is [[4]]}, and here are the reasons.\\
        \\
        Advantages of the current response:\\
        1. \textcolor{red}{The reply is accurate and precise}, including the final result and each step of calculation and reasoning during the problem-solving process, [[5]].\\
        2. The explanation of the problem-solving process is clear, easy to understand, unambiguous, and uses mathematical terms and concepts correctly, [[5]].\\
        3. The answer is direct and concise, avoiding unnecessary lengthy explanations, while ensuring accuracy and completeness, [[4]].\\
        4. Strictly followed the requirements of the question and user instructions, including dealing with specific constraints and steps, [[5]].\\
        5. The use of mathematical symbols, formulas, and diagrams adheres to academic standards and maintains consistency and readability, [[5]].\\
        \\
        Shortcomings of the current response:\\
        1. Fails to provide multiple methods of solving the problem where possible, nor does it discuss the pros and cons of each, [[2]].\\
        2. The response lacks a structured answer format, that is, presenting a clear answer first, followed by steps and explanations, and concluding with key points or common mistakes, [[2]].\\
        \\
        In summary, this response excels in accuracy, clarity, efficiency, and adherence to instructions, but lacks in methodological diversity and structured answer format. Therefore, I have given it an overall rating of [[4]].\\
    \bottomrule
  \end{tabularx}
\end{table*}



\begin{table*}[tbh!]
  \caption{Evaluation result from Themis to the prompt in Table~\ref{tab: math example}.}
  \label{tab: themis' response}
  \small
  %\scriptsize
  \begin{tabularx}{\textwidth}{X}
    \toprule
    Themis' response \\ \midrule
    I believe the overall rating for this reply is [[2]] for the following reasons:\\
    Advantages of the current reply:\\
    1. Clarity: The response is clear in expression, easy to understand, and does not use complex mathematical terms, which helps users understand the comparison process. [[4]]\\
    2. Formatting Norms: Although this response does not directly use mathematical symbols or formulas, the way it explains number comparisons is standard. [[4]]\\
    \\
    Shortcomings of the current reply:\\
    1. Accuracy: The conclusion of the response is incorrect. In fact, 9.9 is greater than 9.11, because although the integer part is the same, the decimal part of 9.9 (0.9) is greater than that of 9.11 (0.11). This mistake directly violates the highest standard of accuracy. [[1]]\\
    2. Efficiency: Although the response attempts to directly compare two numbers, this attempt does not achieve the efficiency it should due to the incorrect conclusion. [[2]]\\
    3. Compliance with Instructions: The response does not correctly follow the user's instructions, as the user asked which number is larger, and the response provided an incorrect answer. [[1]]\\
    4. Method Diversity: The response does not provide a variety of methods to solve the problem, though it may not be necessary for this simple issue. However, considering the mistake in the response, this also becomes a drawback. [[2]]\\
    5. Answer Structure: Although the response attempts to first give an answer and then explain it, because the answer is incorrect, this structure does not achieve its intended effect. [[1]]\\
    \\
    In conclusion, although this response performs well in Clarity and Formatting Norms, it falls short in Accuracy, Efficiency, Compliance with Instructions, Method Diversity and Answer Structure. Therefore, it receives an overall rating of 2.\\
    % \{\\
    %   "Total Score": "2",\\
    %   "Clarity": \{\\
    %     "Score": "4",\\
    %     "Reason": "The response is clear in expression, easy to understand, and does not use complex mathematical terms, which helps users understand the comparison process."\\
    %   \},\\
    %   "Formatting Norms": \{\\
    %     "Score": "4",\\
    %     "Reason": "Although this response does not directly use mathematical symbols or formulas, the way it explains number comparisons is standard."\\
    %   \},\\
    %   "Accuracy": \{\\
    %     "Score": "1",\\
    %     "Reason": "The conclusion of the response is incorrect. In fact, 9.9 is greater than 9.11, because although the integer part is the same, the decimal part of 9.9 (0.9) is greater than that of 9.11 (0.11). This mistake directly violates the highest standard of accuracy."\\
    %   \},\\
    %   "Efficiency": \{\\
    %     "Score": "2",\\
    %     "Reason": "Although the response attempts to directly compare two numbers, this attempt does not achieve the efficiency it should due to the incorrect conclusion."\\
    %   \},\\
    %   "Compliance with Instructions": \{\\
    %     "Score": "1",\\
    %     "Reason": "The response does not correctly follow the user's instructions, as the user asked which number is larger, and the response provided an incorrect answer."\\
    %   \},\\
    %   "Method Diversity": \{\\
    %     "Score": "2",\\
    %     "Reason": "The response does not provide a variety of methods to solve the problem, though it may not be necessary for this simple issue. However, considering the mistake in the response, this also becomes a drawback."\\
    %   \},\\
    %   "Answer Structure": \{\\
    %     "Score": "1",\\
    %     "Reason": "Although the response attempts to first give an answer and then explain it, because the answer is incorrect, this structure does not achieve its intended effect."\\
    %   \}\\
    % \}\\
    \bottomrule
  \end{tabularx}
\end{table*}

%\subsection*{}