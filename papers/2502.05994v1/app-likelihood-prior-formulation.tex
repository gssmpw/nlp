In this appendix, for each likelihood in the one-parameter exponential family distributions we obtain the corresponding natural conjugate prior. The results of this appendix are also summarized in Table~\ref{tab:data-distributions-details}.

Let the likelihood of ${y}_{i,j}$ conditioned on parameters $\theta_j$ be given by
\begin{equation*}
p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = h_{{y}}({y}_{i,j})   \exp \left( {\eta}({\theta}_j)^{\top} {T}_{{y}}({y}_{i,j}) - {A}_{{y}}({\eta}({\theta}_j)) \right),
\end{equation*}
for all $i = 1, \ldots, N$ and $j = 1, \dots, d$. Notice that the likelihood of $\mathbf{y} = \{y_{i,j}\}_{i = 1, \ldots, N;\: j = 1, \ldots, d}$ conditioned on the parameters $\boldsymbol{\theta} = (\theta_1, \ldots, \theta_d)$ can be found using Proposition~\ref{prop:expfam_form_independent_variables} and~\ref{prop:expfam_form_independent_multivariate_variables}. 

Further, let the natural conjugate prior of $\theta_j$ conditional on hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ be given by, 
\begin{align*} 
    p_{{\theta}|\boldsymbol{\zeta}}({\theta}_j|\boldsymbol{\zeta}_j) = h_{{\theta}}(\theta_j) \exp \left(\boldsymbol{\zeta}_j^\top \mathbf{T}_{\theta}(\theta_j) - A_{{\theta}}({\nu}_j,  {\tau}_j)) \right).
\end{align*}
where $ \mathbf{T}_{\theta}(\theta_j)= ({\eta}({\theta}_j), -{A}_{{y}}({\eta}({\theta}_j))$. The form of the natural conjugate prior of  $\boldsymbol{\theta} = (\theta_1, \ldots, \theta_d)$ conditioned on hyperparameters $\boldsymbol{\zeta} = (\boldsymbol{\nu}, \boldsymbol{\tau})$  for $\boldsymbol{\nu} = (\nu_1, \ldots,\nu_d)$ and $\boldsymbol{\tau} = (\tau_1, \ldots,\tau_d)$ can be found using Proposition~\ref{prop:expfam_form_independent_parameters}.

%
% Likelihood with Gaussian conjugate prior
%

\subsection{Likelihood Distribution with Gaussian Conjugate Prior}

\paragraph{Observations following a Normal distribution with fixed variance.}
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \mathcal{N}({y}_{i,j};{\theta}_j, \sigma^2)$ with known variance $\sigma^2$ and with mean $\theta_j$, the likelihood can be expressed as an exponential family distribution with
\begin{equation*}
h_{y}({y}_{i,j} ) = \frac{1}{\sqrt{2\pi}\sigma} \exp\left(-\frac{{y}_{i,j} ^{2}}{2\sigma^{2}}\right),\quad
\eta(\theta_j) = \frac{\theta_j}{\sigma^{2}},\quad
T_{y}({y}_{i,j} ) = {y}_{i,j}  ,\quad
A_{y}(\eta(\theta_j)) = \frac{\theta_j^2}{2\sigma^{2}}
\end{equation*}
Let $\boldsymbol{\Sigma} = \mathbf{I}_{d} \sigma^2$, where $\mathbf{I}_{d}$ is the identity matrix of dimension $d\times d$. For the discussion that follows it is convenient to consider the joint distribution $p_{\boldsymbol{y}|\boldsymbol{\theta}}(\boldsymbol{y}_i|\boldsymbol{\theta}) = \mathcal{N}_d(\boldsymbol{\theta}, \boldsymbol{\Sigma})$ for all $i = 1, \ldots, N$. The multivariate prior $p_{\boldsymbol{\theta}}(\boldsymbol{\theta}\vert \boldsymbol{\zeta})$ conditional on $\boldsymbol{\zeta} = (\boldsymbol{\nu}, \boldsymbol{\tau})$, where $\boldsymbol{\nu} \in \mathbb{R}^d$ and $\boldsymbol{\tau} \in \mathbb{R}^{d}$, which is conjugate to $p_{\boldsymbol{y}|\boldsymbol{\theta}}(\boldsymbol{y}_i|\boldsymbol{\theta})$ is of the form
\begin{equation} \label{eq:conjugate_prior_normal_fixed_variance}
        \begin{aligned}
        &p_{\boldsymbol{\theta}|\boldsymbol{\zeta}}(\boldsymbol{\theta}|\boldsymbol{\zeta}) = h_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \exp \left(
        \boldsymbol{\nu}^\top \boldsymbol{\eta}(\boldsymbol{\theta}) - \frac{1}{2} \left(\boldsymbol{\tau} \boldsymbol{\theta}\right)^\top  \boldsymbol{\Sigma}^{-1} \boldsymbol{\theta} - A_{\boldsymbol{\theta}}(\boldsymbol{\nu}, \boldsymbol{\tau})  \right) \\
        &\boldsymbol{\eta}(\boldsymbol{\theta}) 
    = \boldsymbol{\Sigma}^{-1}\boldsymbol{\theta},\quad
        h_{\boldsymbol{\theta}}(\boldsymbol{\theta}) = (2\pi)^{-\frac{d}{2}}, \\
        &A_{\boldsymbol{\theta}}(\boldsymbol{\nu}, \boldsymbol{\tau}) = \frac{1}{2} \left(\boldsymbol{\tau}^{-1} \boldsymbol{\nu}\right)^\top \left( \boldsymbol{\Sigma}^{-1} \boldsymbol{\tau}\right) \left(\boldsymbol{\tau}^{-1} \boldsymbol{\nu}\right) - \frac{1}{2} \log \text{det}\left(\boldsymbol{\Sigma}^{-1} \boldsymbol{\tau} \right).
            \end{aligned}
\end{equation}
Notice that $p_{\boldsymbol{\theta}|\boldsymbol{\zeta}}(\boldsymbol{\theta}|\boldsymbol{\zeta}) = \mathcal{N}_d(\boldsymbol{\theta}; \boldsymbol{\mu}_0, \boldsymbol{\Sigma}_0)$ where $(\boldsymbol{\nu},\boldsymbol{\tau})$ and $(\boldsymbol{\mu}_0,  \boldsymbol{\Sigma}_0)$ are related through $\boldsymbol{\nu} = \boldsymbol{\Sigma} \boldsymbol{\Sigma}_0^{-1} \boldsymbol{\mu}_0$ and $\boldsymbol{\tau} = \boldsymbol{\Sigma} \boldsymbol{\Sigma}_0^{-1} $.  It follows from the fact that $\boldsymbol{\Sigma}$ is a diagonal matrix, that also  $\boldsymbol{\Sigma}_{0}$ is diagonal and the components of $\boldsymbol{\theta}$ are independent. We remark that it is possible to construct a prior for $p_{\boldsymbol{y}|\boldsymbol{\theta}}(\boldsymbol{y}_i|\boldsymbol{\theta})$ whose covariance matrix is not diagonal. This can be accomplished by utilizing the same form as in \eqref{eq:conjugate_prior_normal_fixed_variance}, but with $\boldsymbol{\tau}\in\mathbb{R}^{d\times d}$.  We remark the similitude from the natural conjugate prior by noticing that $\mathbf{A}_{\boldsymbol{y}}( \boldsymbol{\eta}(\boldsymbol{\theta}) ) = - \frac{1}{2} \boldsymbol{\theta}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\theta}$. 
%In the case of the normal likelihood, there exists a multivariate conjugate prior that differs from the natural conjugate prior. 
% For convenience, we denote $\boldsymbol{\Sigma} = \mathbf{I}_{d} \sigma^2$, where $\mathbf{I}_{d}$ is the identity matrix of dimension $d\times d$, such that we can write $p_{\boldsymbol{y}|\boldsymbol{\theta}}(\boldsymbol{y}_i|\boldsymbol{\theta}) = \mathcal{N}_d(\boldsymbol{\theta}, \boldsymbol{\Sigma})$ for all $i = 1, \ldots, N$.
% The multivariate conjugate prior $p_{\boldsymbol{\theta}}(\boldsymbol{\theta}\vert \boldsymbol{\zeta})$ conditional on $\boldsymbol{\zeta} = (\boldsymbol{\nu}, \boldsymbol{\tau})$, where $\boldsymbol{\nu} \in \mathbb{R}^d$ and $\boldsymbol{\tau} \in \mathbb{R}^{d\times d}$, is of the form
%     \begin{equation} \label{eq:conjugate_prior_normal_fixed_variance}
%         \begin{aligned}
%         &p_{\boldsymbol{\theta}|\boldsymbol{\zeta}}(\boldsymbol{\theta}|\boldsymbol{\zeta}) = h_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \exp \left(
%         \boldsymbol{\nu}^\top \boldsymbol{\eta}(\boldsymbol{\theta}) - \frac{1}{2} \left(\boldsymbol{\tau} \boldsymbol{\theta}\right)^\top  \boldsymbol{\Sigma}^{-1} \boldsymbol{\theta} - A_{\boldsymbol{\theta}}(\boldsymbol{\nu}, \boldsymbol{\tau})  \right) \\
%         &\boldsymbol{\eta}(\boldsymbol{\theta}) 
%     = \boldsymbol{\Sigma}^{-1}\boldsymbol{\theta},\quad
%         h_{\boldsymbol{\theta}}(\boldsymbol{\theta}) = (2\pi)^{-\frac{d}{2}}, \\
%         &A_{\boldsymbol{\theta}}(\boldsymbol{\nu}, \boldsymbol{\tau}) = \frac{1}{2} \left(\boldsymbol{\tau}^{-1} \boldsymbol{\nu}\right)^\top \left( \boldsymbol{\Sigma}^{-1} \boldsymbol{\tau}\right) \left(\boldsymbol{\tau}^{-1} \boldsymbol{\nu}\right) - \frac{1}{2} \log \text{det}\left(\boldsymbol{\Sigma}^{-1} \boldsymbol{\tau} \right).
%             \end{aligned}
%     \end{equation} 
% We note that $p_{\boldsymbol{\theta}|\boldsymbol{\zeta}}(\boldsymbol{\theta}|\boldsymbol{\zeta}) = \mathcal{N}_d(\boldsymbol{\theta}; \boldsymbol{\mu}_0, \boldsymbol{\Sigma}_0)$ for $\boldsymbol{\nu} = \boldsymbol{\Sigma} \boldsymbol{\Sigma}_0^{-1} \boldsymbol{\mu}_0$ and $\boldsymbol{\tau} = \boldsymbol{\Sigma} \boldsymbol{\Sigma}_0^{-1} $.
% Finally, it must be noticed that 



\paragraph{Observations following a Log-Normal distribution with fixed variance.}
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Log-Normal}({y}_{i,j};{\theta}_j, \sigma^2)$ with known logarithm of scale $\sigma$ and with logarithm of location $\theta_j$, the likelihood can be expressed as an exponential family distribution with
\begin{equation*}
h_{y}({y}_{i,j} ) = \frac{1}{\sqrt{2\pi}\sigma{y}_{i,j}} \exp\left(-\frac{\log({y}_{i,j})^{2}}{2\sigma^{2}}\right),\quad
\eta(\theta_j) = \frac{\theta_j}{\sigma^{2}},\quad
T_{y}({y}_{i,j} ) = \log {y}_{i,j}  ,\quad
A_{y}(\eta(\theta_j)) = \frac{\theta_j^2}{2\sigma^{2}}
\end{equation*}
The multivariate conjugate prior $p_{\boldsymbol{\theta}}(\boldsymbol{\theta}\vert \boldsymbol{\zeta})$ conditional on $\boldsymbol{\zeta} = (\boldsymbol{\nu}, \boldsymbol{\tau})$ where $\boldsymbol{\nu} \in \mathbb{R}^d$ and $\boldsymbol{\tau} \in \mathbb{R}^{d\times d}$ is the same as that of the Normal distribution case presented in~\eqref{eq:conjugate_prior_normal_fixed_variance}.

%
% Likelihood with Gamma conjugate prior
%


\subsection{Likelihood Distribution with Gamma Conjugate Prior}
\paragraph{Observations following a Poisson distribution.} 
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Poisson}({y}_{i,j};{\theta}_j)$ with rate $\theta_j$, the likelihood can be expressed as an exponential family distribution with
\begin{align*}
&h_{{y}}({y}_{i,j}) =  \frac{1}{y_{i,j}!},\quad
{\eta}({\theta}_j) = \log(\theta_j),\quad {T}_{{y}}({y}_{i,j}) = y_{i,j}, \quad
{A}_{{y}}({\eta}({\theta}_j)) = \theta_j.
\end{align*}
The natural conjugate prior for ${\theta}_j$ conditioned on the hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distribution with
\begin{equation*} 
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma(\nu_j + 1) - (\nu_j+1)\log(\tau_j).
\end{equation*}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Gamma}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=\alpha_j-1$ and $\tau_j=\beta_j$.

\paragraph{Observations following an Exponential distribution.}
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Exponential}({y}_{i,j};{\theta}_j)$ with rate $\theta_j$, the likelihood can be expressed as exponential family distribution with
\begin{equation*}
h_y({y}_{i,j}) = 1,\quad \eta(\theta_j) = -\theta_j,\quad T_y({y}_{i,j}) = {y}_{i,j},\quad {A}_{{y}}({\eta}({\theta}_j)) = - \log \theta_j.
\end{equation*}
The natural conjugate prior for ${\theta}_j$ conditioned on the hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distribution with 
\begin{equation*}
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma(\tau_j + 1) - (\tau_j+1)\log(\nu_j).
\end{equation*}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Gamma}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=\beta_j$ and $\tau_j= \alpha_j-1$.

\paragraph{Observations following a Gamma distribution with fixed shape.}
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Gamma}({y}_{i,j};a, {\theta}_j)$ with known shape $a$ and with rate ${\theta}_j$, the likelihood can be expressed as an exponential family distribution with
\begin{equation*}
h_y({y}_{i,j}) = \frac{1}{\Gamma(a)}{y}_{i,j}^{a-1} ,\quad \eta(\theta_j) = -\theta_j ,\quad T_y({y}_{i,j}) = {y}_{i,j},\quad {A}_{{y}}({\eta}({\theta}_j)) =  - a \log(\theta_j).
\end{equation*}
The natural conjugate prior for ${\theta}_j$ conditioned on hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distribution with 
\begin{equation*} 
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma(\tau_j \: a + 1) - (\tau_j \: a+1)\log(\nu_j).
\end{equation*}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Gamma}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=\beta_j$ and $\tau_j= (\alpha_j-1) / a$.



\paragraph{Observations following a Pareto distribution with fixed scale.}
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Pareto}({y}_{i,j};x_m, {\theta}_j)$ with known scale $x_m$ and with shape ${\theta}_j$, the likelihood can be expressed as an exponential family distribution with
\begin{equation*}
h_y({y}_{i,j}) = 1 ,\quad \eta(\theta_j) = -\theta_j -1,\quad T_y({y}_{i,j}) = \log({y}_{i,j}),\quad {A}_{{y}}({\eta}({\theta}_j)) =  - \log(\theta_j) - \theta_j \log(x_m) .
\end{equation*}
The natural conjugate prior for ${\theta}_j$ conditioned on the hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distribution with 
\begin{equation*} 
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma(\tau_j + 1) - \nu_j  - (\tau_j +1)\log(\nu_j - \tau_j \log(x_m)).
\end{equation*}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Gamma}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=(\alpha_j-1)\log(x_m) + \beta_j$ and $\tau_j=  \alpha_j-1$.


%
% Likelihood with Beta conjugate prior
%


\subsection{Likelihood Distribution with Beta Conjugate Prior}
\paragraph{Observations following a Binomial or Bernoulli distribution.} 
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Binomial}({y}_{i,j};n, {\theta}_j)$ with known number of trials $n$ and with success probability $\theta_j$, the likelihood can be expressed as an exponential family distribution with
\begin{equation*}
h_y({y}_{i,j}) =  \binom{n}{{y}_{i,j}}  ,\quad \eta(\theta_j) = \log \frac{\theta_j}{1-\theta_j} ,\quad T_y({y}_{i,j}) = {y}_{i,j},\quad {A}_{{y}}({\eta}({\theta}_j)) =  - n \log(1-\theta_j).
\end{equation*}
The Bernoulli distribution has the same components with $n=1$.
The natural conjugate prior for ${\theta}_j$ conditioned on the hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distribution with 
\begin{equation*} 
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma(\nu_j  + 1)+ \log \Gamma(\tau_j \: n - \nu_j + 1) - \log \Gamma(\tau_j \: n + 2) .
\end{equation*}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Beta}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=\alpha_j-1$ and $\tau_j= (\alpha_j + \beta_j -2) / n$.

\paragraph{Observations following a Negative-Binomial distribution.} 
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Negative Binomial}({y}_{i,j};r, {\theta}_j)$ with known number of successes $r$ and with success probability $\theta_j$, the likelihood of ${y}_{i,j}$ failures can be expressed as an exponential family distribution with
\begin{equation*}
h_y({y}_{i,j}) =  \binom{{y}_{i,j} + r -1}{{y}_{i,j}}  ,\quad \eta(\theta_j) = \log (1-\theta_j) ,\quad T_y({y}_{i,j}) = {y}_{i,j},\quad {A}_{{y}}({\eta}({\theta}_j)) =  - r \log(\theta_j).
\end{equation*}
The natural conjugate prior for ${\theta}_j$ conditioned on the hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distribution with
\begin{equation*} 
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma(\tau_j \: r + 1) + \log \Gamma(\nu_j  + 1) - \log \Gamma(\tau_j \: r + \nu_j + 2) .
\end{equation*}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Beta}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=\beta_j-1$ and $\tau_j= (\alpha_j -1) / r$.


\paragraph{Observations following a Geometric distribution.} 
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Geometric}({y}_{i,j};{\theta}_j)$ with success probability $\theta_j$, the likelihood of ${y}_{i,j}$ failures can be expressed as an exponential family distribution with
\begin{equation*}
h_y({y}_{i,j}) = 1  ,\quad \eta(\theta_j) = \log (1-\theta_j) ,\quad T_y({y}_{i,j}) = {y}_{i,j},\quad {A}_{{y}}({\eta}({\theta}_j)) =  -  \log(\theta_j).
\end{equation*}
The natural conjugate prior for ${\theta}_j$ conditioned on the hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distribution with
\begin{equation*} 
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma(\tau_j  + 1) + \log \Gamma(\nu_j  + 1) - \log \Gamma(\tau_j  + \nu_j + 2) .
\end{equation*}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Beta}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=\beta_j-1$ and $\tau_j= \alpha_j -1$.


%
% Likelihood with Inverse gamma conjugate prior
%


\subsection{Likelihood Distribution with Inverse Gamma Conjugate Prior}
\paragraph{Observations following a Normal distribution with fixed mean.} 
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \mathcal{N}({y}_{i,j};\mu, {\theta}_j)$ with known mean $\mu$ and with variance ${\theta}_j$, the likelihood can be expressed as an exponential family distribution with
\begin{align*}
&h_{{y}}({y}_{i,j}) =  \frac{1}{\sqrt{2\pi}},\quad
{\eta}({\theta}_j) = \frac{1}{\theta_j},\quad {T}_{{y}}({y}_{i,j}) = \left(-\frac{y_{i,j}^2}{2} + \mu \: y_{i,j}\right), \quad
{A}_{{y}}({\eta}({\theta}_j)) = \frac{\mu^2}{2\theta_j} - \frac{1}{2}\log\left(\frac{1}{\theta_j}\right).
\end{align*}
The natural conjugate prior for ${\theta}_j$ conditioned on the hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distribution with
\begin{equation}
\label{eq:conjugate_prior_normal_fixed_mean}
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma\left(\frac{\tau_j}{2} - 1\right) - \left(\frac{\tau_j}{2} - 1\right)\log\left(\frac{\tau_j\:\mu^2}{2} - \nu_j\right).
\end{equation}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Inverse-Gamma}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=\mu^2(\alpha_j+1) - \beta_j$ and $\tau_j=2(\alpha_j+1)$.


\paragraph{Observations following a Log-Normal distribution with fixed mean.} 
For $p_{{y}\vert{\theta_j}}({y}_{i,j} \vert {\theta}_j) = \text{Log-Normal}({y}_{i,j};\mu, {\theta}_j)$ with known logarithm of location $\mu$ and with logarithm of scale $\sqrt{\theta}_j$, the likelihood can be expressed as an exponential family distribution with
\begin{align*}
&h_{{y}}({y}_{i,j}) =  \frac{1}{\sqrt{2\pi} {y}_{i,j}},\quad
{\eta}({\theta}_j) = \frac{1}{\theta}_j,\quad {T}_{{y}}({y}_{i,j}) = \left(-\frac{\log(y_{i,j})^2}{2} + \mu \log(y_{i,j})\right), \quad
{A}_{{y}}({\eta}({\theta}_j)) = \frac{\mu^2}{2\theta_j} - \frac{1}{2}\log\left(\frac{1}{\theta_j}\right).
\end{align*}
The natural conjugate prior of ${\theta}_j$ conditioned on hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ has the same form as that of the Normal distribution presented in~\eqref{eq:conjugate_prior_normal_fixed_mean}.

\paragraph{Observations following a Weibull distribution with fixed shape.} 
For $p_{{y}\vert{\theta}}({y}_{i,j} \vert {\theta}_j) = \text{Weibull}({y}_{i,j};{\theta}_j^{1/k}, k)$ with known shape $k$ and with scale parameter ${\theta}_j^{1/k}$, the likelihood can be expressed as an exponential family distribution with
\begin{align*}
&h_{{y}}({y}_{i,j}) = k \: y_{i,j}^{k-1} \quad
{\eta}({\theta}_j) = -\frac{1}{\theta_j},\quad {T}_{{y}}({y}_{i,j}) = y_{i,j}^k, \quad
{A}_{{y}}({\eta}({\theta}_j)) = \log(\theta_j).
\end{align*}
The natural conjugate prior for ${\theta}_j$ conditioned on the hyperparameters $\boldsymbol{\zeta}_j = (\nu_j, \tau_j)$ is an exponential family distirbution with
\begin{equation*}
h_{{\theta}}({\theta}_j) = 1, \quad A_{\theta}({\nu}_j, {\tau}_j) = \log \Gamma\left(\tau_j - 1\right) - \left(\tau_j - 1\right)\log\left(\nu_j  \right).
\end{equation*}
We note that $p_{\theta\vert \boldsymbol{\zeta}}(\theta_j\vert \boldsymbol{\zeta}_j)= \text{Inverse-Gamma}(\theta_j;\alpha_j,\beta_j)$ for $\nu_j=\beta_j$ and $\tau_j=\alpha_j+1$.





