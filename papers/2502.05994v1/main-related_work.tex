Since our work focuses on addressing inverse problems with non-Gaussian observations, we review several approaches that have also attempted to solve this problem.

\paragraph{Markov Chain Monte Carlo.} MCMC is the most commonly used posterior sampling method for performing Bayesian inference on inverse problems.  A key characteristic of MCMC methods is the need to evaluate the prior to compute the acceptance rate for candidate samples generated by the proposal distribution. This requirement presents a significant limitation compared to diffusion-based approaches, which only require the ability to sample from the prior distribution. Therefore, diffusion-based methods accommodate a much broader range of prior distributions.


\paragraph{Gaussian Process and Gaussian Markov Random Field.} GPs are widely used for modeling latent functions in tasks where capturing uncertainty is crucial but are computationally expensive due to the worst-case cubic complexity of inverting large covariance matrices \citep{Rasmussen_GP, Adams2009}. For non-Gaussian observations, Bayesian inference can only be performed via MCMC sampling, which suffers from autocorrelation and slow mixing, making it impractical for large-scale experiments. Given our dataset size and parameter dimensionality, MCMC-based GP inference was infeasible.

As an alternative to MCMC, the most popular approximate method is the integrated nested Laplace approximation (INLA) \cite{Rue2005}, combined with GMRFs. INLA enables sparse computations and avoids MCMC’s mixing issues through an optimization-based approach. However, INLA has limitations: it restricts covariance functions to stationary ones, struggles with high spectral frequencies \cite{Stein2014-hc}, lacks posterior accuracy guarantees, and makes obtaining posterior samples challenging.


% Finally, conditional simulation and sampling can also be challenging~\cite{Rasmussen_GP}.




\paragraph{Diffusion Posterior Sampling.} Among existing diffusion models-based methodologies, we mention DPS, the work of~\citet{chung2023}, who proposed to approximate $p_{\mathbf{x}_{0}\vert\mathbf{x}_t}(\mathbf{x}_0 \vert \mathbf{x}_t)$ as a Dirac delta distribution centered at the posterior mean $\mathbb{E}_{\mathbf{x}_{0}\sim p_{\mathbf{x}_{0}\vert\mathbf{x}_t}}[\mathbf{x}_0]$.
The latter is determined using Tweedie’s formula. Although their method was originally designed for linear inverse problems with Gaussian likelihoods, the authors also extended it to address inverse problems involving Poisson-distributed observations. 
This approach relies on the assumption that Gaussian distributions can effectively approximate Poisson-distributed data when the rate is sufficiently high. However, as noted in \citep[Appendix C.4]{chung2023} and illustrated in the experiment presented in Section~\ref{sec-1d-synthetic-data}, the method faces numerical instabilities and produces poor approximations when the observations come from a low-rate Poisson distribution. Furthermore, the method depends on Tweedie’s formula, which is known to exhibit high variance at high noise levels during the reverse diffusion process (see Section 1.2 of~\citet{target_score_matching}).


\paragraph{Simulation-Based Inference (SBI).} 
SBI avoids the need for a tractable likelihood by relying on simulated observations. Diffusion models enable SBI by approximating the likelihood score function through a Conditional Denoising Estimator (CDE) in the form of a neural network. The CDE directly estimates the likelihood score function by conditioning on three inputs: the observations $\mathbf{y}$, the noise-corrupted latent variable $\mathbf{x}_t$ and the diffusion timestep $t$~\citep{batzolis2021,simons2023}.

Existing approaches face three critical limitations. First, using observations 
$\mathbf{y}$ as network input requires retraining for each new dataset, incurring high computational costs.
Second, in a multiple samples regime ($N>1$), the likelihood score function depends on both the prior and the likelihood score networks~\citep{geffner23a}, causing errors from the prior network to propagate into the likelihood approximation. Third, these methods struggle to accommodate heterogeneous missing data patterns across observations. This limitation stems from their reliance on a fixed input structure for $\mathbf{y}$: missing observations can only be processed if they conform to the network's predefined input format, restricting their applicability to real-world datasets with variable or unanticipated missingness. In contrast, our approach trains a single network given a choice of likelihood, decoupling it from the specific missing-data pattern and the observations themselves. 
%This ensures robustness to heterogeneous missingness and eliminates computational overhead from repeated training, achieving both efficiency and real-world applicability.





