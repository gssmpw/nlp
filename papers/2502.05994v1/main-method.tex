The results presented in this section are derived using the theoretical framework and properties of exponential family distributions, which are thoroughly reviewed in Appendix~\ref{app-exponential-family}. 
% The relevant assumptions underlying this framework are also discussed in detail in the appendix.

\subsection{Setup}
The dataset $\mathbf{y} = \{ \boldsymbol{y}_i \}_{i=1}^N$ is assumed to consist of $N$ independent and identically distributed (i.i.d.) observations. Each observation $\boldsymbol{y}_i \in \mathcal{Y}^d \subseteq \mathbb{R}^d$ is derived from a parameter vector $\boldsymbol{\theta} \in \Theta^d \subseteq \mathbb{R}^d$ through the conditional distribution $p_{\boldsymbol{y} \vert \boldsymbol{\theta}}(\boldsymbol{y}_i \vert \boldsymbol{\theta})$ for $i = 1, \ldots, N$. 
The components of $\boldsymbol{y}_i$ and $\boldsymbol{\theta}$ are denoted by $\boldsymbol{y}_i = (y_{i,1}, y_{i,2}, \ldots, y_{i,d})$ and $\boldsymbol{\theta} = (\theta_1, \theta_2, \ldots, \theta_d)$, respectively. 
Henceforth we will work under the following assumptions. 
\begin{assumption}[Conditional Independence of Variables]
\label{ass-independence-y}
The variable $y_{i,j}|\boldsymbol{\theta}$ is independent of $y_{i,k}|\boldsymbol{\theta}$ for all $j \neq k$ and for all $i = 1, \ldots, N$. Furthermore, we assume that $y_{i,j}| \theta_j$ is independent of $\theta_{k}$ for all $j \neq k$.
\end{assumption}
\begin{assumption}[Exponential Family Distribution]
\label{ass-exponential-distribution}
The distribution $p_{{y} \vert {\theta}}(y_{i,j} \vert {\theta}_j)$ belongs to the univariate one-parameter exponential family with natural parameter $\eta(\theta_j)$, base measure $h_{y}(y_{i,j})$, sufficient statistics $T_{y}(y_{i,j})$ and log-partition function $A_y(\eta(\theta_j))$ for $j = 1, \ldots, d$ and $i = 1, \ldots, N$.
\end{assumption}
Given Assumptions~\ref{ass-independence-y} and~\ref{ass-exponential-distribution}, it follows that the distribution $p_{\boldsymbol{y} \vert \boldsymbol{\theta}}(\boldsymbol{y}_i \vert \boldsymbol{\theta})$ belongs to the multivariate exponential family with the form
\begin{multline*}
p_{\boldsymbol{y}\vert\boldsymbol{\theta}}(\boldsymbol{y}_i \vert \boldsymbol{\theta}) =\\  h_{\boldsymbol{y}}(\boldsymbol{y}_i)   \exp \left( \boldsymbol{\eta}(\boldsymbol{\theta})^{\top} \mathbf{T}_{\boldsymbol{y}}(\boldsymbol{y}_i) - \mathbf{1}_d^\top \mathbf{A}_{\boldsymbol{y}}(\boldsymbol{\eta}(\boldsymbol{\theta})) \right),
\end{multline*}
for $i = 1, \ldots, N$ and where $\mathbf{1}_d$ is a vector of ones of dimension $d$ and
\begin{equation*}
\begin{aligned}
&h_{\boldsymbol{y}}(\boldsymbol{y}_i) = \prod_{j = 1}^d h_{y}\left(y_{i,j}\right), \\ 
&\boldsymbol{\eta}(\boldsymbol{\theta}) = \left(\eta(\theta_1), \dots, \eta(\theta_d)\right), \\
&\mathbf{T}_{\boldsymbol{y}}(\boldsymbol{y}_i) = \left(T_y(y_{i,1}), \ldots, T_y(y_{i,d})\right), \\
&\mathbf{A}_{\boldsymbol{y}}\left(\boldsymbol{\eta}\left(\boldsymbol{\theta}\right)\right) = \left(A_y\left(\eta\left(\theta_1\right)\right), \ldots, A_y\left(\eta\left(\theta_d\right)\right)\right).
\end{aligned}
\end{equation*}
Furthermore, since 
$\mathbf{y}$ consists of $N$ i.i.d observations, then the distribution $p_{\mathbf{y}|\boldsymbol{\theta}}(\mathbf{y}|\boldsymbol{\theta})$ can be written as, 
\begin{multline}
    \label{eq:likelihood_y_phi}
    p_{\mathbf{y}|\boldsymbol{\theta}}(\mathbf{y}|\boldsymbol{\theta}) = \\
    h_{\mathbf{y}}(\mathbf{y}) \exp \left(\boldsymbol{\eta}(\boldsymbol{\theta})^{\top}\mathbf{T}_{\mathbf{y}}(\mathbf{y}) - N  \mathbf{1}_d^\top \mathbf{A}_{\boldsymbol{y}}(\boldsymbol{\eta}(\boldsymbol{\theta})) \right),
\end{multline}
where $h_{\mathbf{y}}(\mathbf{y}) = \prod_{i=1}^N h_{\boldsymbol{y} }(\boldsymbol{y}_i)$  and $\mathbf{T}_{\mathbf{y} }(\mathbf{y}) = \sum_{i = 1}^N \mathbf{T}_{\boldsymbol{y} }(\boldsymbol{y}_i)$.


\subsection{Sampling with a Link Function}
\label{sec-sampling-link-function}
We introduce a deterministic \textit{link function}, denoted as $g(\cdot)$. The following assumption is imposed on the link function:
\begin{assumption}
\label{ass-link-function}
    The link function $g: \Theta \to \mathbb{R}$ is assumed to be continuously differentiable, one-to-one and with ${\mathrm{d}g}/{\mathrm{d}\theta}\neq~0$ for all $\theta\in\Theta$.
\end{assumption}
These properties are standard assumptions and are consistent with those typically used in the context of the change-of-variable technique in probability and statistics (see Theorem 17.2 in \citet{billingsley_prob}).
We write $g(\boldsymbol{\theta})$ to denote the entry-wise application of $g(\cdot)$ to $\boldsymbol{\theta}$. 
The link function maps each parameter $\boldsymbol{\theta}\in \Theta^{d}$ to a transformed variable $\mathbf{x}_{0}= (x_{0,1}, x_{0,2}, \dots, x_{0,d}) \in \mathbb{R}^d$ satisfying the relation 
\begin{equation} \label{eq:transformation_parameter}
    \mathbf{x}_0   = g(\boldsymbol{\theta}).
\end{equation}
Our goal is to generate samples from the posterior distribution $p_{\boldsymbol{\theta} \vert \mathbf{y}}(\boldsymbol{\theta} \vert \mathbf{y})$, or a suitable approximation thereof. Instead of sampling directly from $p_{\boldsymbol{\theta} \vert \mathbf{y}}(\boldsymbol{\theta} \vert \mathbf{y})$, this can be achieved by sampling $\mathbf{x}_0$ from the transformed posterior $p_{\mathbf{x}_0 \vert \mathbf{y}}(\mathbf{x}_0 \vert \mathbf{y})$ using diffusion models as per the methodology described in Section~\ref{sec-diffusion-posterior-sampling} and applying the inverse link function 
\begin{equation*}
    \boldsymbol{\theta} = g^{-1}(\mathbf{x}_0).
\end{equation*}
Figure~\ref{fig-graphical-model} illustrates our approach as a hierarchical probabilistic model.
To streamline the presentation of our results, we defer the discussion in the presence of a linear measurement operator $\mathbf{H} \in \mathbb{R}^{d_y \times d_x}$ to Appendix~\ref{app-observation-operator-H}.
Proposed link functions for mapping the likelihood parameters $\boldsymbol{\theta}$ to the latent variable  $\mathbf{x}_0 $ are provided in Appendix~\ref{app-proposed_link_distributions}.
\begin{figure}[t!]
\centering
\input{graphical_model}
\caption{\textbf{Hierarchical Probabilistic Model.} The dotted arrow represents a deterministic relationship, while the solid arrow indicates a probabilistic relationship.}
\label{fig-graphical-model}
\end{figure}




\subsection{The Evidence Trick}
To approximate the likelihood $p_{\mathbf{y} \vert \mathbf{x}_t}(\mathbf{y} \vert \mathbf{x}_t)$ as defined in~\eqref{eq-likelihood-y-xt}, we propose a simple yet effective approach that we call the \textit{evidence trick}. Given the assumption that the likelihood $p_{\mathbf{y}|\boldsymbol{\theta}}(\mathbf{y}|\boldsymbol{\theta})$ belongs to the exponential family, there always exists a natural conjugate prior distribution $q_{\boldsymbol{\theta}|\boldsymbol{\zeta}}(\boldsymbol{\theta}|\boldsymbol{\zeta})$ with hyperparameters $\boldsymbol{\zeta}$ for which the integral
\begin{equation*}
\int p_{\mathbf{y}|\boldsymbol{\theta}}(\mathbf{y}|\boldsymbol{\theta}) q_{\boldsymbol{\theta}|\boldsymbol{\zeta}}(\boldsymbol{\theta}|\boldsymbol{\zeta}) \mathrm{d}\boldsymbol{\theta} 
\end{equation*}
can be computed in closed-form and corresponds to the \textit{evidence} of $p_{\mathbf{y}|\boldsymbol{\theta}}(\mathbf{y}|\boldsymbol{\theta})$.
As shown in Proposition~\ref{prop:expfam_form_independent_parameters}, the natural conjugate prior distribution also belongs to the exponential family and takes the form:
\begin{equation}
\label{eq-prior-q-theta}
q_{\boldsymbol{\theta}|\boldsymbol{\zeta}}(\boldsymbol{\theta}|\boldsymbol{\zeta}) = h_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \exp \left(\boldsymbol{\zeta}^T \mathbf{T}_{\boldsymbol{\theta}}(\boldsymbol{\theta}) - A_{\boldsymbol{\theta}}(\boldsymbol{\nu},  \boldsymbol{\tau}) \right),
\end{equation}
with hyperparameters $\boldsymbol{\zeta} = \left(\boldsymbol{\nu} ,\boldsymbol{\tau}\right)$, $\boldsymbol{\nu}, \boldsymbol{\tau}  \in \mathbb{R}^d$, base measure $h_{\boldsymbol{\theta}}(\boldsymbol{\theta})$, sufficient statistics $\mathbf{T}_{\boldsymbol{\theta}}(\boldsymbol{\theta}) = (\boldsymbol{\eta}(\boldsymbol{\theta}), -\mathbf{A}_{\boldsymbol{y}}(\boldsymbol{\eta}(\boldsymbol{\theta})))$ and log-partition function $A_{\boldsymbol{\theta}}(\boldsymbol{\nu},  \boldsymbol{\tau})$. The specific form of the natural conjugate prior distribution's base measure and log-partition function is provided in Appendix~\ref{app-table_distributions}.

On this basis, we propose approximating $p_{\boldsymbol{\theta}|\mathbf{x}_t}(\boldsymbol{\theta}|\mathbf{x}_t)$ using the variational distribution $q_{\boldsymbol{\theta}|\boldsymbol{\zeta}(\mathbf{x}_t)}(\boldsymbol{\theta}|\boldsymbol{\zeta}(\mathbf{x}_t))$, as expressed below:
\begin{equation*}
%\label{eq-mean-field-variational-approx}
p_{\boldsymbol{\theta}|\mathbf{x}_t}(\boldsymbol{\theta}|\mathbf{x}_t) \approx q_{\boldsymbol{\theta}|\boldsymbol{\zeta}(\mathbf{x}_t)}(\boldsymbol{\theta}|\boldsymbol{\zeta}(\mathbf{x}_t)),
\end{equation*}
where the dependence of the hyperparameters $\boldsymbol{\zeta}(\mathbf{x}_t)  = \left(\boldsymbol{\nu}(\mathbf{x}_t) ,\boldsymbol{\tau}(\mathbf{x}_t)\right)$ on the input $\mathbf{x}_t$ is explicitly indicated.
This allows us to treat the density $p_{\mathbf{y}|\mathbf{x}_t}(\mathbf{y}|\mathbf{x}_{t})$ as the \textit{evidence} and approximate it with:
\begin{equation}
\label{eq:likelihood_t}
     p_{\mathbf{y}|\mathbf{x}_t}(\mathbf{y}|\mathbf{x}_{t})
     \approx\int p_{\mathbf{y}|\boldsymbol{\theta}}(\mathbf{y}|\boldsymbol{\theta}) q_{\boldsymbol{\theta}|\boldsymbol{\zeta}(\mathbf{x}_t)}(\boldsymbol{\theta}|\boldsymbol{\zeta}(\mathbf{x}_t)) \mathrm{d}\boldsymbol{\theta}.
\end{equation}
As shown in Proposition~\ref{prop:conjugacy}, the integral in \eqref{eq:likelihood_t} has a closed form expression which is given by 
\begin{multline}
\label{eq:likelihood_t-closed-form}
     p_{\mathbf{y}|\mathbf{x}_t}(\mathbf{y}|\mathbf{x}_{t}) \approx \\ h_{\mathbf{y}}(\mathbf{y}) \frac{\exp\left(-A_{\boldsymbol{\theta}}(\boldsymbol{\nu}(\mathbf{x}_t), \boldsymbol{\tau}(\mathbf{x}_t))\right)}{\exp\left(-A_{\boldsymbol{\theta}}(\mathbf{T}_{\mathbf{y}}(\mathbf{y}) + \boldsymbol{\nu}(\mathbf{x}_t), \boldsymbol{\tau}(\mathbf{x}_t) + N \mathbf{1}_d)\right)}.
\end{multline}

\subsection{Approximate Inference of  
$p_{\protect\boldsymbol{\theta}|\mathbf{x}_t}(\protect\boldsymbol{\theta}|\mathbf{x}_t)$}

In this section, we outline the process of finding the optimal approximation to $p_{\boldsymbol{\theta}|\mathbf{x}_t}(\boldsymbol{\theta}|\mathbf{x}_{t})$ by minimizing the KL divergence relative to $q_{\boldsymbol{\theta}\vert \boldsymbol{\zeta}(\mathbf{x}_t)}(\boldsymbol{\theta}\vert \boldsymbol{\zeta}(\mathbf{x}_t))$. For the next result, it is convenient to denote the log-partition function of the conjugate prior defined in~\eqref{eq-prior-q-theta} with $A_{\boldsymbol{\theta}}(\boldsymbol{\zeta}(\mathbf{x}_t)) := A_{\boldsymbol{\theta}}(\boldsymbol{\nu}(\mathbf{x}_t), \boldsymbol{\tau}(\mathbf{x}_t))$.
\begin{lemma}[KL Divergence of $p_{\boldsymbol{\theta}\vert \mathbf{x}_t}$ from $q_{\boldsymbol{\theta}\vert \boldsymbol{\zeta}(\mathbf{x}_t)}$]
\label{lemma-KL-divergence}
Let~$\boldsymbol{\theta} = g^{-1}(\mathbf{x}_0)$.
Furthermore, let
$q_{\boldsymbol{\theta}\vert \boldsymbol{\zeta}(\mathbf{x}_t)}(\boldsymbol{\theta}\vert \boldsymbol{\zeta}(\mathbf{x}_t))$ be defined as in~\eqref{eq-prior-q-theta} and be part of the exponential family with
hyperparameters $\boldsymbol{\zeta}(\mathbf{x}_t)$, base measure $h_{\boldsymbol{\theta}}(\boldsymbol{\theta})$, sufficient statistics $\mathbf{T}_{\boldsymbol{\theta}}(\boldsymbol{\theta})$ and
log-partition function $A_{\boldsymbol{\theta}}(\boldsymbol{\zeta}(\mathbf{x}_t))$.  
The KL divergence of $p_{\boldsymbol{\theta}\vert \mathbf{x}_t}$ from $q_{\boldsymbol{\theta}\vert \boldsymbol{\zeta}(\mathbf{x}_t)}$ is given by
\begin{equation}
\label{eq-kl-divergence-exp}
    D_{\text{KL}}(p_{\boldsymbol{\theta}\vert \mathbf{x}_t} \vert\vert q_{\boldsymbol{\theta}\vert \boldsymbol{\zeta}(\mathbf{x}_t)}) =  C(\mathbf{x}_t)  +\mathcal{L}_{\text{AVI}}(\boldsymbol{\zeta}, \mathbf{x}_t)
\end{equation}
where 
\begin{multline*}
\mathcal{L}_{\text{AVI}}\left(\boldsymbol{\zeta},\mathbf{x}_t\right) =\\  A_{\boldsymbol{\theta}}(\boldsymbol{\zeta}(\mathbf{x}_t)) -\boldsymbol{\zeta}(\mathbf{x}_t)^{\top}\mathbb{E}_{p_{\tilde{\mathbf{x}}_{0}\vert\mathbf{x}_t}}[\mathbf{T}_{\boldsymbol{\theta}}(g^{-1}(\tilde{\mathbf{x}}_{0}))]
\end{multline*}
and for a function $C(\mathbf{x}_t)$ that does not depend on $\boldsymbol{\zeta}$.
\end{lemma}
The proof of Lemma \ref{lemma-KL-divergence} is postponed to Appendix \ref{sec:proof_lemma-KL-divergence}.
We define $\boldsymbol{\zeta}^{\star}(\mathbf{x}_t)$ as the set of hyperparameters that minimizes the KL divergence in~\eqref{eq-kl-divergence-exp} for a given input $\mathbf{x}_t$. Furthermore, let  $\boldsymbol{\zeta}^{\star}(\cdot)$ denote the function that minimizes the expected KL divergence, as specified by the objective
\begin{equation}
\label{eq-kl-expectation}
\mathcal{J}_{\text{AVI}}(\boldsymbol{\zeta}) = \mathbb{E}_{t\sim U(\epsilon, 1), \mathbf{x}_t \sim p_{\mathbf{x}_t}}\Big[ \mathcal{L}_{\text{AVI}}(\boldsymbol{\zeta},\mathbf{x}_t,t)\Big].
\end{equation}
where the function $C(\mathbf{x}_t)$ in~\eqref{eq-kl-divergence-exp} has been excluded from the optimization, as it does not depend on $\boldsymbol{\zeta}$. 
A significant challenge in optimizing~\eqref{eq-kl-expectation} arises from the term $\mathbb{E}_{p_{\tilde{\mathbf{x}}_{0}|\mathbf{x}_t}}[\mathbf{T}_{\boldsymbol{\theta}}(g^{-1}(\tilde{\mathbf{x}}_{0}))]$. This term requires computing expectations under the reverse process distribution $p_{\tilde{\mathbf{x}}_{0}|\mathbf{x}_t}$, which is generally intractable. To address this issue, our next result demonstrates that the objective in~\eqref{eq-kl-expectation} can be reformulated in a way that entirely avoids this explicit evaluation.
\begin{theorem}
\label{prop-new-objective}
Let $p_{\boldsymbol{\theta}}(\boldsymbol{\theta})$ be the marginal distribution of $\boldsymbol{\theta}$.  Moreover, assume that $\boldsymbol{\zeta}(\cdot)$ is a Lipschitz continuous function and that the following conditions hold:
\begin{equation*}
%\label{eq-condition-theorem}
\begin{aligned}
\mathbb{E}_{\boldsymbol{\theta}\sim  p_{\boldsymbol{\theta}}}[\norm{\mathbf{T}_{\boldsymbol{\theta}}(\boldsymbol{\theta}) }] &< \infty,\\
\mathbb{E}_{\boldsymbol{\theta}\sim  p_{\boldsymbol{\theta}}}[\norm{g(\boldsymbol{\theta})}\norm{\mathbf{T}_{\boldsymbol{\theta}}(\boldsymbol{\theta}) }] &< \infty 
\end{aligned}
\end{equation*}
Then, the objective in~\eqref{eq-kl-expectation} can be equivalently expressed as:
% \begin{multline}
%  \boldsymbol{\zeta}^{\star}(\cdot) = \argminA_{\boldsymbol{\zeta}(\cdot)} \mathbb{E}_{t\sim U(\epsilon, 1), \mathbf{x}_0\sim  p_{\mathbf{x}_0}, \mathbf{x}_t \sim p_{\mathbf{x}_t|\mathbf{x}_0}}\Big[ A_{\boldsymbol{\theta}}(\boldsymbol{\zeta}(\mathbf{x}_t)) \\ - \boldsymbol{\zeta}(\mathbf{x}_t)^{\top}\mathbf{T}_{\boldsymbol{\theta}}(g^{-1}(\mathbf{x}_{0}))\Big].
% \end{multline}
\begin{multline}
\label{eq-amortized-objective}
\mathcal{J}_{\text{AVI}}(\boldsymbol{\zeta}) = \\  \mathbb{E}_{t\sim U(\epsilon, 1), \mathbf{x}_0\sim  p_{\mathbf{x}_0}, \mathbf{x}_t \sim p_{\mathbf{x}_t|\mathbf{x}_0}}\Big[ \tilde{\mathcal{L}}_{\text{AVI}}(\boldsymbol{\zeta}, \mathbf{x}_0,\mathbf{x}_t)\Big]
\end{multline}
where
\begin{multline*}
\tilde{\mathcal{L}}_{\text{AVI}}(\boldsymbol{\zeta}, \mathbf{x}_0,\mathbf{x}_t) =  A_{\boldsymbol{\theta}}(\boldsymbol{\zeta}(\mathbf{x}_t))  - \boldsymbol{\zeta}(\mathbf{x}_t)^{\top}\mathbf{T}_{\boldsymbol{\theta}}(g^{-1}(\mathbf{x}_{0})).
\end{multline*}
\end{theorem}
The proof of Theorem~\ref{prop-new-objective} is deferred to Appendix~\ref{proof-prop-new-objective}. 
To approximate $\boldsymbol{\zeta}^{\star}(\cdot)$, we adopt the framework of \textit{amortized variational inference} (AVI).
We use a neural network, denoted by $\boldsymbol{\zeta}_{\boldsymbol{\rho}}(\mathbf{x}_t, t)$ where $\boldsymbol{\rho}$ represents the trainable parameters of the network. We train the neural network such that the parameters $\boldsymbol{\rho}^{*}$ are a minimizer of the following amortized objective:
\begin{multline*}
%\label{eq-amortized-objective}
\mathcal{J}_{\text{AVI}}(\boldsymbol{\rho}) = \\ \mathbb{E}_{t\sim U(\epsilon, 1), \mathbf{x}_0\sim  p_{\mathbf{x}_0},\mathbf{x}_t \sim p_{\mathbf{x}_t|\mathbf{x}_0}}\Big[ \tilde{\mathcal{L}}_{\text{AVI}}(\boldsymbol{\rho},\mathbf{x}_0,\mathbf{x}_t, t)\Big]
\end{multline*}
where
\begin{multline*}
\tilde{\mathcal{L}}_{\text{AVI}}(\boldsymbol{\rho},\mathbf{x}_0,\mathbf{x}_t, t) =  \\  A_{\boldsymbol{\theta}}(\boldsymbol{\zeta}_{\boldsymbol{\rho}}(\mathbf{x}_t, t))  -\boldsymbol{\zeta}_{\boldsymbol{\rho}}(\mathbf{x}_t, t)^{\top}\mathbf{T}_{\boldsymbol{\theta}}(g^{-1}(\mathbf{x}_{0})).
\end{multline*}
\begin{remark}[Inference Network]
The function $\boldsymbol{\zeta}_{\boldsymbol{\rho}}(\mathbf{x}_t,t)$ serves as an \textit{inference network} that infers a posterior distribution over the original (denoised) parameter vector $\boldsymbol{\theta}$, conditioned on its progressively noised counterpart 
$\mathbf{x}_t$ at diffusion time step $t$. Implemented via a neural network, $\boldsymbol{\zeta}_{\boldsymbol{\rho}}$  maps the noisy input $\mathbf{x}_t$ and timestep $t$ to the parameters of this posterior distribution, effectively approximating the inverse of the forward noising process.
\end{remark}




%% TODO UPDATE THIS REMARK
% \begin{remark}[Conditions for Gaussian prior distribution]
% Assuming $p_{\boldsymbol{\theta}}(\boldsymbol{\theta})$ is a multivariate Gaussian distribution and $g(
% \boldsymbol{\theta}) = \boldsymbol{\theta}$, the conditions in~\eqref{eq-condition-theorem} reduce to 
% \begin{equation}
% \begin{aligned}
% \mathbb{E}_{p_{\boldsymbol{\theta}}}[\vert\boldsymbol{\theta} \vert ] &< \infty \\
% \mathbb{E}_{p_{\boldsymbol{\theta}}}[||\boldsymbol{\theta}||^{2} ] &< \infty,
% \end{aligned}
% \end{equation}
% which are trivially satisfied for any multivariate Gaussian distribution.
% \end{remark}

\subsection{Computing the Score of $p_{\mathbf{y}|\mathbf{x}_t}(\mathbf{y}|\mathbf{x}_{t})$}
To sample from the posterior using diffusion models, it is necessary to approximate the likelihood score function, $\nabla_{\mathbf{x}_t} \log p_{\mathbf{y} \vert \mathbf{x}_t}(\mathbf{y} \vert \mathbf{x}_t)$, as defined in~\eqref{eq:score_posterior}. 
From~\eqref{eq:likelihood_t-closed-form}, the log-density $\log p_{\mathbf{y}|\mathbf{x}_t}(\mathbf{y}|\mathbf{x}_t)$ can be directly approximated with
\begin{multline*}
    \log p_{\mathbf{y}|\mathbf{x}_t}(\mathbf{y}|\mathbf{x}_{t})
     \approx \log h_{\mathbf{y}}(\mathbf{y}) - A_{\boldsymbol{\theta}}(\boldsymbol{\nu}(\mathbf{x}_t), \boldsymbol{\tau}(\mathbf{x}_t)) \\+ A_{\boldsymbol{\theta}}(\mathbf{T}_{\mathbf{y}}(\mathbf{y}) + \boldsymbol{\nu}(\mathbf{x}_t), \boldsymbol{\tau}(\mathbf{x}_t) + N \mathbf{1}_d).
\end{multline*}
The gradient of the log-density,~$\nabla_{\mathbf{x}_t} \log  p_{\mathbf{y}|\mathbf{x}_t}(\mathbf{y}|\mathbf{x}_{t})$ with respect to $\mathbf{x}_t$ can be efficiently computed using automatic differentiation.  

