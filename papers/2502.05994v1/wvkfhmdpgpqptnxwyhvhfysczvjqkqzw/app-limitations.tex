Our methodology inherits the characteristics of diffusion model-based methods, which tend to be relatively slow in terms of sampling speed (see Appendix~\ref{app-implementation}). This limitation could potentially be mitigated by incorporating advanced samplers.
Due to the inherent stochasticity in the posterior sampling, as observed in~\citet{chung2023}, we encountered failures among the posterior samples when the signal-to-noise ratio was not properly tuned. To ensure numerical stability, we also had to apply gradient clipping on the approximated posterior gradients (see Appendix~\ref{app-implementation}). Developing more robust techniques to stabilize the sampling process presents an interesting avenue for future research.
To the best of our knowledge, among methods that explicitly approximate the measurement-matching term $\nabla_{\mathbf{x}_t}\log p_{\mathbf{y}\vert\mathbf{x}_t}(\mathbf{y}\vert\mathbf{x}_t)$, our approach is the only one capable of handling observations following non-Gaussian distributions (see \citet{Daras2024} for a comprehensive survey on the subject). However, compared to existing Gaussian-based methodologies, this flexibility comes at the additional cost of training a separate neural network. Notably, though, both networks can be trained in parallel, potentially mitigating computational overhead.







