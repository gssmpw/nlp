\paragraph{Architecture for experiment in Section~\ref{sec-1d-synthetic-data}.}
We employed a feedforward neural network with six hidden layers, each containing 96 neurons and using SiLU activations. Prior to being input into the network, the diffusion timestep was transformed using sinusoidal positional embeddings of length 64, as described in~\citet{Vaswani2017}.
The networkâ€™s final layer was designed to reduce the output dimensionality to $d$ for the score network and $2\times d$ for the inference network. Training was conducted with a batch size of $1,000$, using a learning rate of 
$1\text{e}{-4}$ for the score network and $1\text{e}{-3}$ for the inference network. The training process spanned $100,000$ epochs.


\paragraph{Architecture for experiments in Sections~\ref{sec-experiment-cox-process}-\ref{sec-experiment-malaria}.}
We employed the same U-Net architecture as~\citet{ho_denoising} for both the score network~\eqref{eq:phi_star} and inference network~\eqref{eq-amortized-objective}, with a key modification: the number of convolutional channels is reduced from 128 to 64 to align with our single-channel input data (one vs. three-channel in~\citet{ho_denoising}), optimizing efficiency while preserving performance. The network features a symmetric encoder-decoder structure with six residual layers, where the encoder progressively downsamples spatial resolution via strided convolutions and the decoder upsamples via transposed convolutions, interconnected by skip channels between matching resolution stages. Each residual layer contains two convolutional blocks with SiLU activations, batch normalization, and diffusion timestep conditioning --- achieved by injecting Transformer-style sinusoidal positional embeddings~\citep{Vaswani2017} of length 64 into each block. A single-head global attention layer is incorporated at the $16\times16$ resolution. 
The final layer is a $1\times1$ convolution which fuses the concatenated features via channel-wise linear combination, reducing the output dimensionality to one channel for the score network and two channels for the inference network. 

Note that we were unable to leverage pre-trained weights for the score network, as done in \citet{chung2023} or \citet{boys2024}, because the pre-trained U-Nets used in these studies were trained on three-channel RGB images.

Our score network model had $33,766,529$ parameters, and inference network had $33,943,234$ parameters. To train the networks, we used a batch size of $128$ images, a learning rate of $1\text{e}{-4}$ for both networks. We ran the training of the score network for $100,000$ epochs and the training of the inference network for $50,000$ epochs.


\paragraph{SDE.}
We adopted the standard VP-SDE setup with $\beta(t) = \beta_0 + t (\beta_1 - \beta_0)$, $\beta_1 = 20$ and $\beta_0 = 0.001$.

\paragraph{Sampling algorithm.}
To sample from the posterior, we employed the \textit{Predictor-Corrector} (PC) sampling algorithm proposed by~\citet[Algorithm 1, 3, 5]{song2021scorebased}. The predictor step was implemented using the Euler-Maruyama solver, while the corrector step used the annealed Langevin dynamics. The gradients, used by the Predictor and Corrector are defined by
\begin{align*}
&\mathbf{g} = \mathbf{g}_{\text{prior}} + \mathbf{g}_{\text{likelihood}} \\
&\mathbf{g}_{\text{prior}} \simeq \nabla_{\mathbf{x}_t}  \log p_{\mathbf{x}_t}(\mathbf{x}_t), \quad \mathbf{g}_{\text{likelihood}} \simeq \nabla_{\mathbf{x}_t} \log p_{\mathbf{y}|\mathbf{x}_t}(\mathbf{y}|\mathbf{x}_{t})
\end{align*}
where 
\begin{align*}
&\mathbf{g}_{\text{prior}} = \mathbf{s}_{\boldsymbol{\phi}^\star}(\mathbf{x}_t, t) \label{eq:gradient_sampling} \\
& \mathbf{g}_{\text{likelihood}}  = \nabla_{\mathbf{x}_t} \left(h_{\mathbf{y}}(\mathbf{y}) - A_{\boldsymbol{\theta}}(\boldsymbol{\nu}^\star(\mathbf{x}_t), \boldsymbol{\tau}^\star(\mathbf{x}_t)) + A_{\boldsymbol{\theta}}(\mathbf{T}_{\mathbf{y}}(\mathbf{y}) + \boldsymbol{\nu}^\star(\mathbf{x}_t), \boldsymbol{\tau}^\star(\mathbf{x}_t) + N \mathbf{1}_d)\right)
\end{align*}
with $(\boldsymbol{\nu}^\star, \boldsymbol{\tau}^\star) = \boldsymbol{\zeta}_{\boldsymbol{\rho}^\star}(\mathbf{x}_t, t)$ and where $\mathbf{s}_{\boldsymbol{\phi}^\star}(\mathbf{x}_t, t)$ and $\boldsymbol{\zeta}_{\boldsymbol{\rho}^\star}(\mathbf{x}_t, t)$ are the trained score and inference networks, respectively. To prevent numerical instabilities, we clip the gradients $\mathbf{g}$ to the range $[-10,10]$.
Following~\citet{song2021scorebased}, we used $1,000$ noise scales for the sampling process. Through experimentation, we found that the best results were achieved with a \textit{signal-to-noise ratio} of $r = 0.1$. 
Lastly, we generated $500$ posterior samples to compute summary statistics such as posterior medians and quantiles.


\paragraph{Compute time.} 
The experiments in Section~\ref{sec-1d-synthetic-data} required 40 minutes to run the score and inference networks in a multi-CPU environment.
The experiments in Sections~\ref{sec-experiment-cox-process}-\ref{sec-experiment-malaria} were performed on a single NVIDIA A100-SXM4-80GB GPU. The score and inference networks took 30 hours to train. Sampling 128 posterior samples concurrently on a single GPU took 30 minutes per image. This process was repeated until the required 500 posterior samples were obtained.


\paragraph{Code availability.} The code and data are available on the GitHub repository \url{https://github.com/MLGlobalHealth/score-sde-expfam/}.