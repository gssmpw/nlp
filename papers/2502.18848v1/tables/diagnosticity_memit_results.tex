\begin{table*}[t!]
        \centering
        \resizebox{0.8\linewidth}{!}{
        \begin{tabular}{lcccc}
        \toprule
        \textbf{Metric} & \textbf{FactCheck} & \textbf{Analogy} & \textbf{Object Counting} \\
        \midrule

        \multicolumn{4}{l}{\textbf{Post-hoc}} \\
        \quad CC-SHAP & \textbf{\underline{0.541}} & \textbf{0.130} & \textbf{\underline{0.580}}   \\
                \quad Simulatability & 0.019 & 0.022 & 0.000   \\
                \quad Counterfact. Edits & 0.000 & 0.000 & 0.000   \\
                \midrule

        \multicolumn{4}{l}{\textbf{CoT}} \\
        \quad Early Answering & 0.484 & 0.356 & 0.478   \\
                \quad Filler Tokens & 0.459 & \textbf{\underline{0.715}} & 0.487   \\
                \quad Adding Mistakes & 0.468 & \underline{0.553} & 0.471   \\
                \quad Paraphrasing & 0.478 & \underline{0.683} & 0.487   \\
                \quad CC-SHAP & \textbf{0.493} & 0.246 & \textbf{\underline{0.580}}   \\
                \bottomrule
        \end{tabular}
        }
        \caption{The diagnosticity scores of each metric across three tasks using \texttt{qwen2.5-7b} as model and \textbf{MEMIT as knowledge editing method}. Bold numbers indicate the highest scores on each task across the two categories of faithfulness
metrics: post-hoc and CoT. Underlined numbers show the diagnosticity scores that are significantly higher than $0.5$ (Binomial, $p < 0.05$).}
        \label{tab:diagnosticity_memit}
    \end{table*}
