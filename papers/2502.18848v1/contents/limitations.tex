\methodname substantially depends upon the efficacy of the knowledge editing method. Our framework presupposes that the applied edits are capable of generalizing across diverse surface forms and reasoning processes while maintaining compositionality. Previous research on knowledge editing assesses the \textit{portability} of edits by employing various benchmarks \citep{yao-etal-2023-editing, Zhong2023MQuAKEAK, cohen2024evaluating}, wherein they curate downstream applications for each specific edit. Nevertheless, the creation of such benchmarks pertinent to our tasks necessitates substantial effort, which is not within the scope of this study. Consequently, we utilize the perplexity relationship between edits and synthetically generated explanations as an indicative measure of model editing success. Furthermore, while we undertake an ablation study employing MEMIT, the potential benefits of model-generated explanations and more extensive models employing alternative editing techniques remain largely unexamined. This oversight is primarily attributed to the considerable computational expense associated with resolving issues in model-generated explanations, which involve the use of parameter-updating editing methods or memory-based approaches that necessitate extended contexts. Additionally, our scaling experiments exclude CC-SHAP owing to its slow execution. Specifically, memory-based methods considerably extend the duration of experiments involving CC-SHAP as they increase context length.
