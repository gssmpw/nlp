\paragraph{Task} This task focuses on simple fact-checking, where a fact is presented alongside two counterfactual answers. For any relation $(s_i, r_i, o_i)$, we present a question that checks its correctness, accompanied by two counterfactuals: $(s_i, r_i, \bobject{i})$ and $(s_i, r_i, \oobject{i})$. These counterfactuals yield the same answer but are based on different reasoning. For instance, given the knowledge triplet $(s_i = \text{"Rihanna"}, r_i = \text{"is"}, o_i = \text{"a singer"})$, the corresponding question would be "Is Rihanna a singer?" Let the counterfactual objects be $\bobject{i} = \text{"researcher"}$ and $\oobject{i} = \text{"lawyer"}$. Both counterfactuals would result in the answer "No," but for different reasons.\\
\noindent \textbf{Dataset} We construct our dataset from \textsc{CounterFact}  \citep{Meng2022LocatingAE}, which consists of knowledge triplets. We use \texttt{Mistral-7B-Instruct-v0.2} to convert these triplets to yes/no questions. Then, for each object $o_i$, we fetch sibling entities from WikiData to create counterfactuals. Finally, we generate synthetic explanations corresponding to each counterfactual. For example, the corresponding explanation \bepsilon{i} would be "Joe Biden is a researcher, not the president of the United States" for \bobject{i}.  Further details about dataset generation can be found in Appendix~\ref{appendix:dataset}.
