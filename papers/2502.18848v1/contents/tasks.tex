\begin{figure*}[t]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/All-Tasks.pdf}
    \caption{Overview of the four tasks: Fact Check, Analogy, Object Counting, and Multi-hop Reasoning, illustrated with example questions, answers, and explanations from the edited models. The explanations can either be generated by the model or synthetically constructed to align with specific edits, enabling the evaluation of diagnosticity. The blue and orange robots represent models $\BModel$ and $\OModel$, respectively, while the color-matched boxes below each model indicate the counterfactual knowledge injected through editing. Speech bubbles next to each model display their outputs, consisting of the answer ($\vy$) and explanation ($\bepsilon{}$ or $\oepsilon{}$). Although both models in each pair generate the same answers, their reasoning differs, as reflected in the explanations.
    }
    
    \label{fig:tasks}
\end{figure*}
We evaluate faithfulness metrics using four controlled tasks in the \methodname framework: (1) fact-checking, (2) analogy, (3)  object counting, and (4) multi-hop reasoning. These tasks assess causal diagnosticity by using counterfactual models with faithful and unfaithful explanations. While the altered models should reason differently, their explanations may not always reference the modifications. To ensure valid faithfulness comparisons, we synthetically generate explanations that emphasize model differences. Figure \ref{fig:tasks} provides an overview of these tasks, including example inputs, outputs, and explanations.


\subsection{Fact Check Task}
\input{contents/tasks/fact_check}

\subsection{Analogy Task}
\input{contents/tasks/analogy}

\subsection{Object Counting Tasks}
\input{contents/tasks/object_counting}

\subsection{Multi-hop Reasoning Task}
\input{contents/tasks/multihop}