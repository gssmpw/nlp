% !TeX root = ../main.tex

\section{Introduction}
\label{sec:introduction}

% What are attribution tags and why are they important
Attribution tags, which link pseudo-anonymous cryptoasset addresses to identifying information about real-world entities and services (e.g., cryptoasset exchanges), form the foundation of modern cryptoasset forensics~\cite{Meiklejohn2013}. Over the past decade, a multibillion-dollar industry has emerged, providing blockchain tracing tools for law enforcement investigations. These tools allow users to ``follow the money'', ultimately leading to the identification and potential conviction of perpetrators. As cryptoassets have gained increasing relevance across various crime sectors, these tools are now used in investigations related to ransomware~\cite{Huang2018, PaquetCloustonRansomware2019}, sextortion~\cite{PaquetCloustonSextortion2019}, and malware~\cite{Gomez2022}. Attribution tags have also been employed to train machine learning models for automatically categorizing service providers, such as exchanges~\cite{Harlev2018, Gomez2022, Liu2022, Zhou2022}, miners~\cite{Harlev2018, Liu2022, Zhou2022}, and ICO wallets~\cite{Liu2022, Zhou2022}. Moreover, these models are used to classify addresses or transactions as illicit~\cite{Liu2022, Zhou2022, Wu2022, Li2022, Hu2023, Chen2019, Bartoletti2020}. Consequently, the accuracy of attribution tags becomes a critical success factor in all these application domains.

% What is the problem -> attributon data quality
Imprecise or incorrect tags can mislead investigations, result in inaccurate model predictions, or, in the worst case, lead to false accusations. As a result, the concept of \emph{attribution tag quality} is gaining increased attention, especially as the scientific validity of crypto-tracing techniques is being more frequently questioned and scrutinized~\cite{Change:2023}. As with any digital forensic investigation that forms the basis for legal decisions, the collected evidence must be reliable~\cite{Frwis2020}, since poor data quality can lead to incorrect conclusions. Ensuring high data quality also guarantees that the methodologies used in digital forensics can be consistently tested and verified.

% Our focus
Since attribution tags originate from and are often shared among multiple stakeholders, data consistency becomes a critical aspect of data quality. A key challenge, for instance, is the inconsistent referencing of real-world entities across different parties~\cite{Frwis2020,Gomez2022}. For example, one party might refer to a specific exchange as \emph{btc-e}, while another uses \emph{btc-e.com}. While a human can easily recognize that both tags refer to the same entity, different tracing tools may interpret them as referring to two distinct entities. To harmonize their representation, reuse, and interpretation in forensic investigations or machine learning tasks, a suitable data format and a computational approach are needed to automatically eliminate potential data inconsistencies.

% General approach and most relevant related work
Given the semantic nature of this practical problem, knowledge graphs offer an effective solution. They represent entities as identifiable semantic concepts rather than plain strings and are widely used in search engines~\cite{GoogleKG2012} and large knowledge bases~\cite{vrandevcic2014wikidata}. The process of linking data to these well-defined entities is known as record linkage~\cite{Elmagarmid2007} or entity linking~\cite{Shen2015}. However, existing approaches often rely on heuristics or heavily labeled, domain-specific training datasets, which are not readily available in the context of cryptoasset attribution tags.

% Our goal and specific contributions
Therefore, in this paper, we present a novel computational approach based on Large Language Models (LLMs) that enables the linking of attribution tag datasets to well-defined knowledge graph concepts without requiring domain-specific fine-tuning. We implemented this approach by integrating several cutting-edge techniques --- such as filtering, blocking, and LLMs --- into an end-to-end pipeline. Our experiments, conducted on three datasets, demonstrate that:

\begin{enumerate}

    \item Our end-to-end entity linking approach outperforms baseline methods across all three datasets, achieving up to a 37.4\% improvement in F1-scores.

    \item $\text{BM25}_3$ blocking and related-concept filtering reduce the number of candidates per tag to 5, with a recall of 93\%, without requiring labeled data.

    \item GPT-4o-based candidate selection achieves a 94\% F1-score, while Mistral 7B-Instruct, which can run locally, achieves a 90\% F1-score.

    \item Using the most cost-effective prompt template reduces costs by 90\%, with only a 1\% drop in performance.

\end{enumerate}

Our method not only enhances the quality of attribution tags but also seeks to inspire broader efforts toward improving data quality, ensuring accurate and reliable evidence in forensic investigations. To ensure reproducibility, we have made our code and datasets publicly available in the following GitHub repository: \url{https://github.com/ravice234/cryptoasset-attribution-tag-linker}.