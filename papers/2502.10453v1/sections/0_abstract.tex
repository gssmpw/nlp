% !TeX root = ../main.tex
% Background and Motivation
Attribution tags form the foundation of modern cryptoasset forensics. However, inconsistent or incorrect tags can mislead investigations and even result in false accusations.
% Approach
To address this issue, we propose a novel computational method based on Large Language Models (LLMs) to link attribution tags with well-defined knowledge graph concepts. We implemented this method in an end-to-end pipeline and conducted experiments showing that
% Results
our approach outperforms baseline methods by up to 37.4\% in F1-score across three publicly available attribution tag datasets. By integrating concept filtering and blocking procedures, we generate candidate sets containing five knowledge graph entities, achieving a recall of 93\% without the need for labeled data. Additionally, we demonstrate that local LLM models can achieve F1-scores of 90\%, comparable to remote models which achieve 94\%. We also analyze the cost-performance trade-offs of various LLMs and prompt templates, showing that selecting the most cost-effective configuration can reduce costs by 90\%, with only a 1\% decrease in performance.
% Take away and impact
Our method not only enhances attribution tag quality but also serves as a blueprint for fostering more reliable forensic evidence.