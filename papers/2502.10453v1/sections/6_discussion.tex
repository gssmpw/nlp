% !TeX root = ../main.tex

\section{Discussion and Conclusions}

% Summary and Key Takeaways
In this paper, we addressed the issue of \emph{attribution tag quality}, with a particular focus on data inconsistencies that arise when attribution tags are shared among different parties. We argue that data quality issues can mislead forensic investigations and even result in false convictions if addresses are labeled incorrectly. To solve this, we proposed a novel computational approach based on Large Language Models (LLMs) that automatically links attribution tags to well-defined concepts in knowledge graphs, addressing the semantic nature of the problem. We implemented our approach in an end-to-end pipeline and demonstrated that, when combined with filtering and blocking techniques, it outperforms existing methods. Additionally, we showed that pre-trained LLMs running locally on consumer-grade hardware achieve performance comparable to remote models. Furthermore, we demonstrated that carefully designed prompts can significantly reduce costs with only a marginal decrease in performance. Overall, we believe our approach not only addresses the pressing issue of inconsistent attribution tags but also has the potential to inspire broader efforts to improve data quality in other forensic investigation tools and platforms.

% Limitations
One limitation of our approach is its binding to specific application domains; so far, we lack evidence that our method is generally applicable to all record linkage problems. However, we believe that a data- and measurement-driven approach would be valuable for assessing the broader suitability of this method. Another limitation is the assumption that different parties (e.g., exchanges, investigators) use the same knowledge graph when exchanging attribution tag records. If this is not the case, our approach does not harmonize the data but merely shifts the problem to a different abstraction level. However, significant efforts are being made to harmonize and adopt shared knowledge graphs within the field. For example, the Darkweb and Virtual Assets taxonomy developed by INTERPOL has been integrated into the Malware Information Sharing Platform (MISP) Galaxy\footnote{\url{https://misp-galaxy.org/interpol-dwva/}}. This taxonomy helps categorize and enrich threat intelligence, with MISP Galaxies organizing related data clusters to describe higher-level concepts such as adversary groups, malware families, and vulnerabilities, simplifying complex data analysis for organizations.

% Future work
Future work could include fine-tuning pre-trained LLMs to the cryptoasset domain, improving performance by recognizing semantically related terms that are syntactically different. Additionally, leveraging relationships like hypernyms and hyponyms in knowledge graphs could refine candidate matching. Extending the approach to automatically categorize cryptoasset addresses based on well-defined categories would also provide a more comprehensive solution.