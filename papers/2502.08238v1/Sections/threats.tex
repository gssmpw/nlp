\section{Threats to Validity}
\label{sec:threats}
\noindent \textbf{Internal Validity}
Our selection of 2,828 GitHub projects based on our sampling method threatens internal validity. GitHub hosts over 284 million projects, and mining all of them is infeasible. We defined six filtering criteria to reduce this sample space to 89k without excluding projects with significant communication and collaboration. A lower threshold for the number of contributors or stars would increase the number of projects in this sample and may potentially change our results. 
We applied a stratified sampling strategy to categorize the projects according to PR activity to encounter this threat. Therefore, threats due to threshold selection are more likely to influence only the PRF(L) group since most of the projects with a lower number of contributors or stars would fall under this group. However, there is no evidence that changing these thresholds would significantly alter the results, even for the PRF(L). Our selection of the list of attributes represents another threat to internal validity. Prior studies have found various factors such as politics or ideology triggering toxicity~\cite{miller2022did}. However, we could not investigate those factors due to the unavailability of automated mechanisms to identify such scenarios at a large scale.  This study only investigates automatically measurable factors that may be associated with toxicity. 


%with the recommendation of Kalliamvakou \textit{et} al~\cite{kalliamvakou2016depth}, and a recent empirical study~\cite{sultana2022code}. Our selection excludes projects that do not use popular programming language have less than 20 contributors and have not been highly active in the last three months. 
%It is nearly impossible to calculate some context attributes associated with toxicity. For instance, Miller \textit{et} al. found that politics or ideology can trigger toxicity in issue discussion in their qualitative study~\cite{miller2022did}.  



\vspace{2pt} \noindent \textbf{Construct Validity}
Our \textit{(first)} threat in this category is due to using ToxiCR~\cite{sarker2022automated} to identify toxic comments automatically. 
Our validation of ToxiCR found 88.88\% precision, which is within the sampling error margin reported by ToxiCR's authors. ToxiCR has false positives in approximately one out of 10 cases. Similarly, ToxiCR has a false negative rate of between 10-14\%. Hence, these false positives and negatives may have influenced our results if ToxiCR is biased for/against any particular attributes (e.g., review interval or woman) included in our study. However, we do not have any evidence of such biases.
\textit{(Second)}, our manual labeling scheme to identify the nature of toxicities to answer RQ1 is a threat. Although multiple SE studies have studied antisocial behaviors, no agreed-upon scheme exists. Moreover, researchers from NLP and SE domains have used different terminologies to characterize similarly subjective concepts.
To mitigate this threat, we have analyzed existing studies~\cite{sarker2022automated,miller2022did, ferreira2021shut,egelman2020predicting,ferreira2022heated} and aggregated their categories to build our scheme. We acknowledge the subjectivity bias, where another set of researchers disagree with our scheme and definitions. \textit{(Third)}, our manual labeling process may have subjectivity biases. We prepared a scheme with category definitions and examples to mitigate this threat. The labelers had a discussion session before starting to build an agreed-upon understanding. We also measured inter-rater reliability to assess your labeling process. 
\textit{(Finally)}, automated gender resolution is another threat. We followed a procedure as the ones in multiple recent empirical studies~\cite{sultana2022code,santamaria2018comparison,bosu2019diversity}. We used multiple gender resolution tools, considered users' location and profile photos, and searched LinkedIn to improve resolution accuracy. This resolution process may be subject to misclassification. We did not attempt to identify
non-binary genders since we are unaware of any automated resolution of those without users' inputs.


\vspace{2pt} \noindent \textbf{External Validity}
The nature of toxicities in an OSS project may depend on factors such as project domain, governance, the number of contributors, and project age. 
We used a stratified random sampling strategy to select 2,828 projects representing diverse demographics, including the top OSS projects on GitHub, such as Kubernetes, Odoo, PyTorch, Rust, Ansible, pandas, rails, Django, numpy, angular, flutter, CPython, and node.js. 
Yet, our sample and its results may not adequately represent the entire OSS spectrum.
 

\vspace{2pt} \noindent \textbf{Conclusion Validity}
%We used recommended practices and well-known libraries such as \emph{rms}, \emph{stats}, and \emph{nnet}  to build our regression models. 
%We assess multicollinearity and drop redundant variables. 
We assess the reliability of our models using goodness-of-fit metrics and log-likelihood tests. Hence, we do not anticipate any threats from the results obtained from our models.  Although our models account for various confounding variables, these models identified associations between dependents and predictors, and no causal relationships can be implied.
%to find the correlation between the outcome variables and independent variables. We used well-known \textbf{stats, rms} to train our models. Moreover, we choose a co-efficient ($z$) for linear regression and an odds ratio for logistic regression to present the estimated effects. Hence, it is unlikely to threaten our correlation analysis using regression.
%models. 