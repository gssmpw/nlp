
\section{Research Method}
\label{sec:research-method}
Figure~\ref{fig:method_overview} provides an overview of our research methodology, detailed in the following subsections.
\begin{figure}[t!]
	\centering  
\includegraphics[width=1\linewidth, trim=0 290 0 0, clip]{Sections/Figures/research-method-overview.pdf}
	\caption{An overview of our research method}
	\label{fig:method_overview}	
\end{figure}

\subsection{Project Selection}
We leverage the GitHub search tool developed by ~\citet{Dabic:msr2021data}, which enables filtering based on various criteria such as the number of contributors, programming language, forks, commits, and stars to select candidate projects. Following recommendations by~\citet{kalliamvakou2016depth}, we searched for projects satisfying the following six criteria: i) uses one of the top ten programming languages on GitHub:  Java, C, C++, Python, JavaScript, C{\#}, Go, PHP, Typescript, and Ruby; ii) has at least 20 contributors, iii) is publicly available with an OSS license; iv) at least two years old, v) has at least 20 PRs; vi) and has at least 10 stars. 
The first five criteria ensure the selection of OSS projects with adequate analyzable interpersonal communication among the contributors. 
The last criterion reduces the search space; without this filter, the number of projects grows exponentially but adds only trivial OSS projects.


 


Our search conducted in September 2022 found 89,744 projects. We exported the results as a CSV file and categorized the projects into the following three groups based on project activity, which we measured using monthly Pull Request Frequency (PRF) on GitHub. 
\begin{itemize}
    \item \emph{Low PRF (PRF-L)}: A project belongs to this group if it has less than 8 PRs per month (i.e., less than 2 PRs/week). Total 66,791(~74.5\%) projects belong to this group. 
    \item  \emph{Medium PRF (PRF-M)}: A project belongs to this group if it has between 8 -31 PRs per month (i.e., 2-8 PRs/week). Total 14,694  (16.3\%) projects belong to this group. 
    \item \emph{High PRF (PRF-H)}:  A project belongs to this group if it has more than 32 PRs per month (i.e., $>$8 PRs/week). Total 8,259  (9.2\%) projects belong to this group.
\end{itemize}

These two chosen grouping thresholds, 8 and 32, represent approximately 75 and 90 percentiles based on PRF. We chose PRF instead of commit frequency because we noticed that many popular projects use GitHub as a mirror (e.g., the Linux kernel) while development activities predominantly use other platforms. 
Next, we randomly selected 800 projects from each of the three groups.
 This stratified sampling is necessary since three-fourths of the projects found based on our search criteria belong to the PRF-L  group. Hence, a random selection will have been dominated by PRF-L projects and will fail to adequately capture the characteristics of the remaining two groups. Our sample size of 800 is adequate to obtain results within a 3\% margin of error with a 95\% confidence interval~\cite{cochran1977sampling}. 


Since prior studies have suggested higher occurrences of toxicity among gaming projects~\cite{miller2022did}, we also added projects with the topic `game' and at least 10 stars. The search result found 6.1k projects. However,  most projects did not satisfy criteria such as a minimum number of participants or PRs. Hence, the gaming group includes 439 projects, adequate for  95\% confidence interval (CI) and a 5\% Margin of Error~\cite{cochran1977sampling}. We include the gaming projects in our RQ2 analysis only to investigate project characteristics associated with toxicity. However, some projects were no longer available for mining (e.g., deleted or moved). Therefore, our final dataset contains 2,828 projects.








\subsection{Dataset Preparation}

 We wrote a Python Script using the PyGithub library~\cite{pygit} to mine all the PR details, metadata, PR labels, user information, inline review comments, and PR discussions from the selected projects and store them in a MySQL database. Our data mining started in October 2022 and completed in January 2023. Our dataset requires approximately 172 GB of storage.
Our dataset includes approximately 16.1 million (M) PRs, 101.5 M comments, and 1.3 M unique users.  We also mined all publicly available user information, including profile photos, emails, full names, and user types. We exclude all the interactions from Bot accounts (i.e., userType=`Bot'). However, we also noticed many bot accounts using incorrect flags (i.e., userType =`User'). Therefore, we filtered accounts with bot-specific keywords (bot, robot, auto, Jenkins, static, etc.) in user names and full names. We manually inspected the filtered accounts to make a final determination.

\subsection{Toxicity Classification Scheme}
\label{sec:classification-scheme}
Multiple recent studies have investigated toxicity and other antisocial behaviors within OSS communities~\cite{sarker2022automated,miller2022did,rahman2024words,raman2020stress,ferreira2021shut,sultana2022identifying,gunawardena2022destructive,egelman2020predicting}. These studies enumerate several prevalent forms of such behaviors and conclude that toxicity in the OSS context are different from a non-SE domain such as social media~\cite{miller2022did}. To answer RQ1, we focused on aggregating various categories of anti-social behaviors to prepare our manual labeling scheme. We started with consolidating categories derived from studies on `toxicity'~\cite{raman2020stress,miller2022did,sarker2022automated,qiu2022detecting}. During this process, we identified overlapping concepts based on definitions included in those papers and merged those into a single category. We noticed a conflict as `self-deprecation' was marked as non-toxic by~\citet{sarker2022automated}, while~\citet{miller2022did} marks `self-directed pejorative', a similar concept as toxic. We follow ~\citet{sarker2022automated}'s definition, marking such texts as toxic only if they involve profanity since we use their tool.
Additionally,~\citet{ferreira2021shut}'s incivility lens, which encompasses a broader spectrum of anti-social behaviors, including toxicity, also includes frustration, impatience, irony, mocking, name-calling, threat, and vulgarity. Based on their definitions, `name-calling, threat, mocking, and vulgarity' overlap with existing categories identified by ~\citet{miller2022did} and ~\citet{sarker2022automated}. As such, these were considered toxic. Although `irony,' `frustration,' and `impatience' are not a part of these toxicity schemes, they may fit existing categories, such as trolling, arrogance, and insult, depending on context. It's worth noting that existing SE studies have used different terminologies to study these subjective social constructs, and an agreed-upon standard scheme or definition is currently missing and perhaps challenging to establish. 
At the end of this step, we prepared our manual labeling scheme of 10 categories (Table~\ref{tab:toxicity_types}) with a broader definition for each group.




\subsection{Automated identification of toxic comments}
\label{sec:validation-toxicr}
  We select ToxiCR~\cite{sarker2022automated} for automated classification since it is i) trained on large-scale training data, ii) developed as a reusable standalone tool, iii) is publicly available on GitHub, iv) provides a well-defined interface to conduct a large-scale classification required by this study,  v) trained on Code review data which is similar to pull requests that this study aims to analyze, and vi) reports the best performance according to its evaluation with $95.8\%$ accuracy, $90.7\%$ precision, $87.4\%$ recall, and an $88.9\%$ F1-score. ToxiCR provides the toxicity probability of a text from 0 to 1, and its authors recommend using a threshold $>=0.5$ to consider a text as toxic. Using ToxiCR's best-performing configuration~\cite{sarker2022automated}, we classified all the PR comments, totaling 101.5 million. ToxiCR found approximately 756K toxic comments (0.74\%) from our dataset.

\emph{Evaluation of ToxiCR:} Prior research on SE domain-specific NLP tools~\cite{novielli2018benchmark,novielli2021assessment} recommends independent assessments before application on new settings. Therefore, we conducted an empirical evaluation to assess ToxiCR's reliability on our dataset. To achieve this goal, we randomly selected 600 PR comments marked as toxic by ToxiCR. This sample adequately provides results within a 2.6\%  margin of error and 95\%  confidence interval~\cite{cochran1977sampling}.  We also use this sample to investigate the frequencies of various forms of toxicity on GitHub (Section~\ref{sec:manual}). 



\emph{Precision:}
Two raters independently labeled those 600 samples as toxic or non-toxic and resolved the conflicts after a discussion. To mitigate the bias of the labeling process, two labelers follow the toxicity rubric from~\citet{sarker2022automated}. The agreement between the two labelers is 95.8\%, and Cohenâ€™s kappa~\cite{cohen1960coefficient} value is \emph{$\kappa$ = 0.80}, which is `substantial'.  After conflict resolution, 532 comments were labeled toxic, suggesting $88.8\%$  precision.  
This result is within the margin of error (i.e., 2.6\%) of ToxiCR's claimed precision (90.7\%)~\cite{sarker2022automated}.

\emph{Recall:}
Evaluation of recall is also essential to ensure that ToxiCR does not miss many positive instances. On this goal, we focused on finding existing labeled toxicity datasets curated from GitHub issue requests.   
We did not use~\citet{raman2020stress}'s dataset since it has only 106 toxic instances.
We chose ~\citet{ferreira2022heated}'s dataset of locked GitHub issues, which includes 896 uncivil sentences out of 1,364.  According to ~\citet{ferreira2021shut}, incivility is a super-set of toxicity. While all toxic comments are uncivil, some uncivil comments (e.g., irony and impatience) may not fit the toxicity lens. To encounter this challenge, two authors relabeled the 896 uncivil comments based on ~\citet{sarker2022automated}'s toxicity labeling rubric. The raters achieved an inter-rater agreement of $\kappa=0.76$ and resolved the conflicts through a mutual discussion. On this dataset, ToxiCR achieved 87\% recall, which is also within the sampling margin of error of ToxiCR's reported recall (i.e., 87.4\%).





\subsection{Manual Categorization of Toxic Comments}
\label{sec:manual}
Using the 10 class classification scheme described in Section~\ref{sec:classification-scheme}, two of the authors independently placed the 532 toxic comments identified during ToxiCR's evaluation (Section~\ref{sec:validation-toxicr}) into one or more groups. We also included the `Others' category to label toxic comments that do not fit the existing ten categories. We measured the inter-rater reliability of this multiclass labeling using Krippendorff's alpha, which was 0.35, indicating a `Fair' agreement. We noticed higher ratios of disagreements since, theoretically, the number of possible labeling for a single instance is $2^{11}$. Conflicting labels were resolved through mutual discussions.
After conflict resolution, the raters reviewed the 34 instances from the `Others' group to identify missing categories. The new category identified is `Object-Directed Toxicity', which includes anger, frustration, or profanity directed toward software, products, or artifacts. 
For example, \textcolor{brown}{``also the mask sprite is beyond horrid, I might have something that could do better..''} represents this form.
With this category, they went through the labeled instances again to identify other cases that may also fall under this category since a text can fall under multiple categories. We found a total of 49 instances belonging to this new category.




\begin{table*}
    \caption{The list of attributes selected to investigate their association with project characteristics (RQ2), Pull request context (RQ3), and participants' characteristics (RQ4). We selected this set of attributes since prior studies on code reviews and anti-social behaviors suggest the likelihood of association with toxicity or conflict-instigating contexts. * -indicates attributes that were investigated in prior studies.}
    \label{tab:rq-attributes}
    \centering
    \vspace{-12pt}
    \input{Sections/Tables/combined_attributes}
\end{table*}


\subsection{Attribute Selection}
Table~\ref{tab:rq-attributes} lists attributes selected to answer RQ2, RQ3, and RQ4 introduced in Section \ref{sec:intro}. In addition to each attribute's definition, Table~\ref{tab:rq-attributes} hypothesizes why an attribute may be associated with toxicity.

\emph{RQ2: Project }
 We select eleven project characteristics attributes based on prior studies on toxicity and incivility~\cite{raman2020stress,miller2022did,ferreira2022heated,ferreira2021shut}. These 11 attributes characterize a project's activity, popularity, domain, governance, and age. 

\emph{RQ3: PR Context }
We select nine contextual attributes based on prior studies~\cite{miller2022did,thongtanunam2017review,raman2020stress,sultana2022code,egelman2020predicting,rahman2024words}. 
These attributes characterize the type of change, outcome, complexity, required review /resolution efforts, completion time, and number of identified issues in a PR.


 \emph{RQ4: Participant}
 We select six participant attributes based on prior studies~\cite{miller2022did,sultana2022identification,cohen2021contextualizing,murphy2022pushback,rahman2024words,ferreira2022heated}. These attributes represent a participant's GitHub tenure, project experience, gender, and communication history. We compute each attribute for both the author and the target of a comment; therefore, we have 12 attributes from this category. 

    
\subsection{Attribute Calculation}

To investigate RQ3 and RQ4, it is necessary to compute attributes at pull request (PR) and comment levels, respectively. Given that our dataset comprises 16 M PRs and 101.5 M comments, calculating the PR and comment-level attributes listed in Table~\ref{tab:rq-attributes} 
for the entire dataset would be exceedingly time-consuming and resource-intensive. Therefore, we reduced the sample size for RQ3 and RQ4 by randomly selecting 385 projects from the three project groups (i.e., `PRF-L', `PRF-M', and `PRF-H'). 
We choose this sample size to satisfy a 5\% error margin and 95\% confidence interval~\cite{cochran1977sampling}. This sample of 1,155 projects includes 6.3 M PRs, 30 M comments, and 416 K users. We exclude gaming projects from this analysis since they have a higher prevalence of toxicity, and many such projects do not consider profanities offensive. Therefore, contexts and participants of toxicity among gaming projects are not representative of non-gaming ones.
We wrote Python scripts and MySQL queries to compute the 32 attributes listed in Table~\ref{tab:rq-attributes} based on their definitions. While most attributes are straightforward to calculate, five require additional heuristics, as defined in the following.


    \textbf{Gender: }
    We adopted a similar protocol to~\citet{sultana2022code} to automatically predict users' genders. We have used genderComputer~\cite{vasilescu2014gender} and Wiki-Gendersort~\cite{berube2020wiki} tools to resolve the gender from a user's name, preferred pronoun, and location if available. We have also downloaded a user's GitHub avatar and applied an automated human face detection model~\cite{goyal2017face}. Further, we used a pre-trained photo to gender-resolution model~\cite{eidinger2014age} to predict the user's gender. Conflicts between the two approaches were resolved by manually investigating users' profiles.
 Finally, we successfully resolved 75.4\% of the total users (92\% with full names). We only include gender-resolved users for RQ4. 

 \textbf {Project Member:}
 Following the recommendation of ~\citet{gousios2012ghtorrent}, we consider a user a project member if that user has write access (i.e., merged at least one PR or created an intra-branch PR) to the repository.


 \textbf{GitHub Tenure and Project Tenure:}
We compute a user's GitHub tenure at an event as the months between their account creation and the event's timestamp. Similarly, we calculate a developer's project tenure during each project interaction (e.g., commit, pull request, or comment). 

 \textbf {Newcomer:}
Following the definitions of prior studies~\cite{steinmacher2013newcomers,subramanian2020analyzing}, we consider a user as a newcomer to an OSS project until they have got their first PR accepted to this project.


\subsection{Regression Modeling}

Regression analysis offers a robust statistical method for examining the influence of one or multiple independent variables on a dependent variable \cite{foley2018regression}. Two categories of regression models are used: (i) \textit{Predictive analysis}: involves creating a formula to forecast the value of a dependent variable based on the values of one or more independent variables; and (ii) \textit{Inferential analysis}: seeks to establish whether a specific independent variable affects the dependent variable and to quantify that impact if present \cite{allison2014prediction}. An inferential analysis differs from a predictive analysis in two key aspects. First, \emph{multicollinearity}: when two or more independent variables are highly correlated, incorporating all correlated variables simultaneously in inferential analysis can lead to an overfitting problem. However, in predictive analysis, multicollinearity is not a concern. Second, the importance of $R^2$ -- the goodness of fit of a regression model \cite{helland1987interpretation}. While a higher \emph{$R^2$} is desirable, it holds greater importance in predictive analysis. In inferential analysis, even with a low $R^2$, the regression model can provide valuable insights into the relationships between the independent and dependent variables \cite{allison2014prediction}. 
We train multivariate inferential regression models to analyze associations between the toxicity and the 32 attributes listed in Table~\ref{tab:rq-attributes}. The following subsections detail the regression models to answer RQ2, RQ3, and RQ4.


\subsubsection{Multinomial Logistic Regression for RQ2}
We found training a regression model for RQ2 challenging since computing various project characteristics variables at the creation timestamp of a comment requires the entire event log for a project (e.g., when a new star was added), which is resource-intensive to mine due to the enormous size of our dataset. While Google's BigQuery hosts a dataset of  GitHub events, it would be expensive to query this service. Therefore, we used aggregated attributes over the lifetime of a project. We calculated toxicity per hundred comments ($percent\_toxic$) for each project over its lifetime and used it as the dependent variable for RQ2. However,  if the dependent variable is a ratio, a model can identify spurious associations~\cite{richard-spurious}. 
Following the recommendation of ~\citet{long2006regression}, we transform the $percent\_toxic$ variable into a three-level categorical variable named $toxicity\_group$. 
We selected the number of categories and thresholds for this grouping based on the inflection points\footnote{points of a curve at which a change in the direction of curvature occurs} in the cumulative distribution curve.
The `Low toxic' group includes 324 projects with $percent\_toxic < $ 0.02\%. The 2,082 projects from the `Medium toxic' group have  0.02 $ \leq percent\_toxic < $ 1\%. The remaining 421 projects belong to the `High toxic' group with $percent\_toxic \geq $ 1\%. 
Since $ toxicity\_group$ has three levels, we use a Multinomial Logistic Regression (MLR) model, where $ toxicity\_group$ is the dependent variable and 11 project characteristics attributes are independents. 


\subsubsection{Bootstrapped Logistic Regression for RQ3 and RQ4}
For RQ3, the dependent variable is \textit{HasToxicComment}, set to 1 if a PR has at least one toxic comment and 0 otherwise.
For RQ4, we use participant attributes computed at the comment level as independents. We use \textit{isToxic} as the dependent, $1$ if the comment is toxic, and 0 otherwise. 
We train two models for RQ4, one with the author's attributes as the independents and the other with the target's attributes.
Since the dependents are binary for RQ3 and RQ4, we use Logistic Regression models. 
As the dataset of RQ3 and RQ4 consist of a rare binary outcome variable (i.e., \textit{HasToxicComment}, \textit{isToxic}), we use a bootstrapped regression modeling technique~\cite{xu2020applications}. In this technique, we choose a desired ratio between the minority and the majority. We randomly downsample the majority until the desired ratio is reached. We fit a logistic regression model with each bootstrapped sample, measure its fit, and compute regression coefficients. This process is repeated 100 times, and we record the results of each iteration in a dataset. We report median and 95\% confidence interval for model fit and regression coefficients.  We also explored various ratios between the minority and the majority and found that the model's goodness of fit (i.e., $R^2$) reduces with the increment of the majority's share. We chose a ratio of 1:10 since increasing the majority's share beyond that produced unreliable models in a few cases, according to the Log-likelihood test (\textit{lrtest}).



\subsubsection{Correlation and Redundancy Analysis}
For an inferential regression model, multicollinearity poses a threat to validity.  We used the variable clustering approach suggested by \citet{sarle1990sas} to identify multicollinearity. With this approach, we create a hierarchical cluster representation of independents using Spearman's rank-order correlation test \cite{statistics2013spearman}. As recommended by ~\citet{hinkle1998applied}, we set the cutoff value at $|\rho| = 0.7$ for the correlation coefficient. Only the explanatory variable with the strongest correlation with the dependent was chosen from a cluster of variables with $|\rho| \geq 0.7$. 


\begin{table*}
    \caption{For the bootstrapped logistic regression models, model fit measured using Vealll-Zimmermann Psuedo $R^2$.  A 95\% confidence interval is also reported for $R^2$ values. All models are significantly better than null models ($p<0.001$).}
    \label{tab:model_fit}
    \centering
   \vspace{-10pt}
    \input{Sections/Tables/model-fit}
    \vspace{-10pt}
\end{table*}






\subsubsection{Model analysis}
We also use the Log-likelihood test (\textit{lrtest})  to assess whether a model significantly differs (Chi-Square, $p<0.05$) from a null model and can be reliably used for inference.
We evaluate each model's goodness-of-fit using Veall-Zimmermann Psuedo-$R^2$~\cite{veall1994evaluating} since prior research~\cite{smith2013comparison} found this measure having closer correspondence to ordinary least square $R^2$.  A higher $R^2$ value indicates a better fit.  
We use the Odds ratio (OR) to quantify the association between the dependent and independents and estimate effect size. 
For a binary independent (e.g., $isGame$), OR indicates the odds of an outcome if the independent variable changes from 0 to 1, while all other factors remain constant. For a continuous variable (e.g., project age), OR indicates an increase or decrease in odds for the dependent with one unit change in the factor. In simple terms, OR $>$1 indicates a positive association and vice versa. We use the p-value of the regression coefficient to assess the significance of an association, with $p<0.05$ indicating a statistical significance.
Table~\ref{tab:model_fit} shows goodness-of-fit measured with Pseudo-$R^2$  for the regression models trained for RQ3 and RQ4. Since we bootstrapped each model 100 times, we report median and 95\% confidence intervals for each model. The results of \textit{lrtest} indicate that all models are significantly better than a null model ($p<0.001$) and are reliable to infer insights to answer our RQs. However, although models for RQ4 are significant, they have low $R^2$ values, which we further explain in Section \ref{sec:res-rq4}.

