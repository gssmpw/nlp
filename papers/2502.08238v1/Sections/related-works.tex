\section{Related Works}
\label{sec:background}
\textbf{Antisocial Behaviors in OSS:} While internet-based communication mediums help people across multiple geographical regions to collaborate with ease, these interactions can turn negative due to various anti-social behaviors such as toxicity~\cite{bhat2021say}, harassment~\cite{lindsay2016experiences}, cyberbullying~\cite{kowalski2014bullying}, trolling, and hate speech~\cite{del2017hate, gagliardone2015countering}.
Although these behaviors are less frequent among professional work-focused communities such as OSS projects than social mediums~\cite{miller2022did}, they may have severe repercussions on the productivity and even the sustainability of an OSS project~\cite{raman2020stress,toxic-open-source-maintainer,perl-toxicity}.
Among the various lenses studied by SE researchers, 
`toxicity,' which is `behaviors that are likely to make someone leave,' has been investigated most frequently~\cite{raman2020stress, sarker2020benchmark, sarker2022automated, qiu2022detecting}. Toxicity among OSS projects on GitHub differs from other social communication platforms 
such as Reddit, Wikipedia, Twitter, and Stack Overflow~\cite{miller2022did}. 
`Incivility,' defined as a broader superset including toxicity, is a text with an unnecessary disrespectful tone~\cite{ferreira2021shut}.
`Destructive criticism'  is another lens characterized by negative feedback during code reviews~\cite{gunawardena2022destructive}. Interactions during code reviews may also cause interpersonal conflicts among the parties, which can be termed as `pushback'~\cite{murphy2022pushback, egelman2020predicting}. 

\vspace{3pt}
\noindent \textbf{Automated identification of toxicity and other anti-social behaviors:}
To identify and mitigate online toxic interactions, researchers from the Natural Language Processing (NLP) domain have published datasets and classifiers, where several come from Kaggle challenges \cite{zaheri2020toxic,bhat2021say,kumar2021designing,zhao2021comparative}. For the SE domain,  \citet{raman2020stress} proposed the first customized toxicity detector. However, this classifier performed poorly during subsequent benchmarks~\cite{sarker2020benchmark, miller2022did, qiu2022detecting}. ~\citet{qiu2022detecting}'s classifier aims to detect interpersonal conflicts by combining pushback~\cite{egelman2020predicting} and toxicity~\cite{raman2020stress} datasets. 
\citet{cheriyan2021towards} proposed an offensive language detector that considers a subset of toxicity, such as swearing or cursing. ~\citet{sarker2022automated} developed a rubric for toxicity in the SE domain and developed a toxicity classifier (ToxiCR) with their manually labeled 19,651 code review texts, which achieved 88.9\% F1-score for the toxic class. Two recent studies have proposed classifiers to identify uncivil comments, where \citet{ferreira2024incivility} used their dataset of locked issue comments and ~\citet{rahman2024words} augmented ToxiCR dataset with ChatGPT generated instances to improve identification of mockery and flirtation.


\vspace{3pt}
\noindent \textbf{Contexts and consequences of anti-social behaviors among OSS:}
Prior SE studies investigated contexts and consequences of anti-social behaviors using surveys and qualitative analyses. 
These studies suggest toxic interactions among OSS developers as a `poison'  that not only degrades their mental health but~\cite{carillo2016towards} also can cause stress and {burnout}~\cite{raman2020stress}.  
The threat of an OSS community disintegrating rises with the levels of toxicity due to developers' turnover~\cite{carillo2016towards}. 
\citet{miller2022did}'s investigation found toxicity originated from both newcomers and experienced contributors due to various causes, which include technological disagreements, frustrations with a system, and past interactions with the target.
Project sponsorship and domain may influence toxicity as corporate projects are less toxic than non-corporate projects. On the other hand, gaming projects are more toxic than non-gaming ones~\cite{raman2020stress}. A project's toxicity may also decrease with age~\cite{raman2020stress}.
While uncivil discussions may arise in various locked issue contexts, they are more common among versioning and licensing discussions~\cite {ferreira2022heated}. On the Linux kernel mailing list, inappropriate feedback from maintainers and violation of community conventions are the top causes of incivility~\cite{ferreira2021shut}. On the other hand, among industrial developers, excessive workloads and poor-quality code are top factors~\cite{rahman2024words}.
Two lenses of antisocial behaviors, destructive criticism, and pushback, are specific to code reviews. They occur due to unnecessary harsh critiques of code and interpersonal conflicts caused by disagreements over development directions~\cite{egelman2020predicting,murphy2022pushback,gunawardena2022destructive}. 
Both pushback and destructive criticisms not only decrease productivity and degrade interpersonal relationships~\cite{murphy2022pushback,egelman2020predicting}, they disproportionately harm underrepresented minorities and cause barriers to promoting DEI~\cite{gunawardena2022destructive}.
Besides these academic works, several gray literature have also documented {burnout} and turnover of long-term OSS contributors due to toxicity~\cite{toxic-blog-linux1,toxic-blog-linux2,toxic-blog-linux3,toxic-open-source-maintainer,perl-toxicity,leaving-for-toxicity,perl-toxic-2}.


\vspace{3pt}
\noindent \textbf{Novelty:} This study differs from prior empirical investigations of antisocial behaviors in three ways. First, prior studies focused on communication from specific contexts
such as locked issues~\cite{miller2022did,raman2020stress} or rejected patches~\cite{ferreira2021shut}. Therefore, characteristics of toxicity outside these known negative contexts are missing. Second, these investigations are qualitative. While these investigations are crucial to forming hypotheses, whether these hypotheses apply to a broader spectrum of OSS projects remains unanswered. Finally, these studies explored a limited set of factors, whether other plausible factors, such as community size, project popularity, code complexity, and unresolved defects associated with toxicity, remain unanswered. For example, we investigated the association between toxicity and 32 different factors, where 21 are unique to our study.

