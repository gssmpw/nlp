\section{Related Work}
Our work intersects with three major research areas: \textbf{1) Non-OOD-Exposure OOD Detection} that purely relies on ID data for detecting OOD instances, this involves score-based methods, feature learning, and techniques specific for graph-structured data**Chen et al., "Out-of-Distribution (OOD) Exposure-Based Out-of-Distribution Detection"**; \textbf{2) OOD Exposure-Based OOD Detection}, a prominent line of work that adopts auxiliary OOD data to assist training, often achieving higher performance than non-OOD-exposure based methods**Sagawa et al., "Distributionally Robust Neural Networks for Inference with Exponentially Many Weighted Loss Functions"**; and \textbf{3) OOD Generation,} a more recent field that aims to synthesise OOD-like data to assist OOD detection**Anoosheh et al., "Mixup for Generative Adversarial Networks"**. Notably for graph data, **Chen et al., "Graph Neural Network Safe"** considers the inter-dependence nature of node instances and proposes an energy propagation schema, and explores an OOD-exposed variant **Chen et al., "Graph Neural Network Safe++"**. **Sagawa et al., "NODESafe"** builds upon **Chen et al., "Graph Neural Network Safe++"** and proposes additional regularisation terms to reduce and bound the generation of extreme energy scores. **Guo et al., "Energy-based Out-of-Distribution Detection for Graphs"** proposes a generalised Dirichlet energy score for graph OOD detection. A detailed review of related work is provided in Appendix~\ref{Appendix:related_work}.

% \paragraph{Non-OOD-Exposure OOD Detection.} OOD detection is a fundamental task extensively studied in diverse machine learning domains**Sagawa et al., "Distributionally Robust Neural Networks for Inference with Exponentially Many Weighted Loss Functions"**. A representative line of work that relies on purely ID data is based on the model's output including using softmax score**Dziugaite et al., "Computing Nonvacuous Generalization Bounds for Deep (Deep) Neural Networks Using a Novel Concentration Bound"**, using energy score**Chen et al., "Graph Neural Network Safe"**, and activation pruning-based methods**Bai et al., "Pruning Activations to Mitigate Adversarial Attacks on Neural Networks"**. Other approaches involve confidence enhancement**Guo et al., "Enhancing Confidence in Out-of-Distribution Detection for Graphs"**, feature learning**Sagawa et al., "Distributionally Robust Neural Networks for Inference with Exponentially Many Weighted Loss Functions"**, and adversarial strategies**Wong et al., "Scaling Adversarial Training for 4D Convolutional Neural Networks"**. More recent studies have applied OOD detection to graph-structured data**Chen et al., "Graph Neural Network Safe"**. For node-level detection, **Chen et al., "Graph Neural Network Safe"** considers the inter-dependence nature of node instances and proposes an energy propagation schema. **Sagawa et al., "NODESafe"** builds upon **Chen et al., "Graph Neural Network Safe"** and proposes additional regularisation terms to reduce and bound the generation of extreme energy scores. **Anoosheh et al., "Uncertainty Estimation in Graph Neural Networks via Kernel Density Estimation"** proposes a multi-source uncertainty framework to estimate the node-level Dirichlet distributions to assist OOD detection. **Hendrycks et al., "Deep Anomaly Detection with Outlier Exposure"** applies Bayesian posterior and density estimation to estimate the uncertainty for each node. For graph-level detection, recent methods includes modelling distribution shifts through a graph generative process, overseeing from a data-centric perspective, and unsupervised methods**Sagawa et al., "Distributionally Robust Neural Networks for Inference with Exponentially Many Weighted Loss Functions"**. **Chen et al., "GraphDE"** proposes to model the distribution shifts through a graph generative process and derives a posterior distribution for graph-level OOD detection. Additionally, **Wang et al., "Anomaly Detection via Autoencoders on Data-Dependent Metrics"** presents a data-centric method for detecting graph-level OOD.
% % which aims to learn structural patterns in the graph data through a learnable amplifier matrix
% %GOOD-D is an unsupervised method that considers purely the performance of graph-level OOD detection by applying contrastive learning**Tian et al., "Contrastive Learning with Local Aggregation"**. Other uncertainty estimation-based approaches have also been proposed for OOD detection**Sagawa et al., "Distributionally Robust Neural Networks for Inference with Exponentially Many Weighted Loss Functions"**.

% \paragraph{OOD Exposure-Based OOD Detection.}
% OOD exposure is another prominent line of work that adopts auxiliary OOD data to assist training**Sagawa et al., "Distributionally Robust Neural Networks for Inference with Exponentially Many Weighted Loss Functions"**. The aforementioned **Chen et al., "Graph Neural Network Safe"** model also considers an additional version **Chen et al., "Graph Neural Network Safe++"** to adopt OOD exposure and has shown greater performance than standard model**Sagawa et al., "Distributionally Robust Neural Networks for Inference with Exponentially Many Weighted Loss Functions"**. **Sagawa et al., "NODESafe++"** also presents \textsc{NODESafe++} as an extended OOD exposed version. **Guo et al., "Energy-based Out-of-Distribution Detection for Graphs"** proposes a generalised Dirichlet energy score for OOD detection. Our proposed GOLD method attempts to take advantage of the effectiveness of OOD exposure through synthesising samples that exhibit OOD characteristics. Thus, avoiding the necessity of real OOD data during training.

% \paragraph{OOD Generation.}
% Recent studies begin to work on synthesising OOD data**Anoosheh et al., "Mixup for Generative Adversarial Networks"**. A GAN-based approach is proposes to generate OOD data by jointly training a confidence classifier**Dziugaite et al., "Computing Nonvacuous Generalization Bounds for Deep (Deep) Neural Networks Using a Novel Concentration Bound"**. **Kumar et al., "VOS: Outlier Exposure with Variational Autoencoders"** generates synthetic outliers from low-probability regions of multivariate Gaussian distributions. Recently, pre-trained diffusion models have been widely employed for OOD generation including **Liu et al., "DFDD: Diffusion-based Feature Disentanglement"**, **Anoosheh et al., "Dream-OOD: Dreaming to Detect Out-of-Distribution Samples"**. Several initial graph-level OOD studies have been initiated, predominantly for molecule**Li et al., "Molecule Generation via Conditional Variational Autoencoders"**. A score-based OOD molecule generation model is proposed by **Guo et al., "MOOD: Molecule Outlier Detection via Score-Based Generative Model"**, which employs an OOD-controlled reverse-time diffusion. A recent work **Liu et al., "PGR-MOOD: Pre-trained Graph Regularized Molecular Outlier Detection"** proposes to rely on a pre-trained molecule diffusion for generation. These methods typically rely on pre-trained models that are trained with additional data. In contrast, GOLD does not rely on pre-trained generative models to synthesise pseudo-OOD data.