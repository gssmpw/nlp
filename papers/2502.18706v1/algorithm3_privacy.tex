

\begin{algorithm}[H]
\caption{The \algasgo Method in Our Time-adaptive DP-FL Framework}
\textbf{Inputs:} No. clients $N$, No. global rounds $T$, local privacy budgets $\{\eps_n\}_{n\in [N]}$, sampling rate $q$, average clip norm $c$, modes $\{M_n^t \in\{0,1\}\}_{n\in [N], t\in [T]}$, sampling rates for saving mode $\{q_n\}_{n\in [N]}$, probability of violating $\delta$. \\ \\ 
\label{alg:tidpfl:privacy}
\textbf{Def} \texttt{SetPrivacyParams}$\left(c, q,  \{q_n\}_{n\in [N]}, \{\eps_n\}_{n\in [N]}, \{M_n^t\}_{n\in [N], t\in [T]}, T, \delta\right)$
\begin{algorithmic}[1]
\State \textbf{Initialize} $\eps_n^0 = \eps_n$  and $\bar{\eps}_{\text{rdp},n}^0=0$
for all $n\in [N]$
\For{each global round $t\in [T]$}
\For{each client $n \in [N]$}
\State Set local noise multiplier $\noisem_n^t=$\texttt{GetNoise}$\left(\eps_n^{t-1},\delta, q, T-t\right)$
\State \textbf{If} $M_n^t=0$, \textbf{then} $q_n^t = q_n$, \textbf{Else}, $q_n^t = q$.
\State $\reps{n}^t=$\texttt{Compute\_rdp}$\left(q_n^t,\noisem_n^t, \alpha\right)$
\State $\bar{\eps}_{\text{rdp},n}^t = \bar{\eps}_{\text{rdp},n}^{t-1} +  \reps{n}^t$
\State $\eps_n^t=\eps_n-$\texttt{get\_privacy\_spent}$\left(\alpha, \bar{\eps}_{\text{rdp},n}^t,\delta\right)$
\EndFor
\State Compute $\noisem^t \gets \left(\frac{1}{N}\sum_{n\in [N]}\frac{1}{\noisem_n^t}\right)^{-1}$
\For{each client $n \in [N]$}
\State Set local clip norm $c_n^t=\frac{c\noisem^t}{\noisem_n^t}$
\EndFor
\EndFor
\State $q^t = \frac{1}{N} \sum_{n=1}^N q_n^t$
\State Return $q^t, \noisem, \{q_n^t, c_n^t\}_{n\in [N]}$
\end{algorithmic}
\end{algorithm}