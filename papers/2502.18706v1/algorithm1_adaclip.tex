

\begin{algorithm}[H]
   \scriptsize
\caption{DP-FedAvg-M with Adaptive Clipping~\citep{andrew2021differentially}}
\textbf{Inputs:} No. clients $N$, No. global rounds $T$, No. local iterations $L$, noise multiplier $\noisem$, clip norm $c$, sampling rate $q$, loss functions $\{\loss_n\}_{n\in [N]}$, local datasets $\{\train_n\}_{n\in [N]}$, client-side learning rate $\lr$, server-side learning rate $\lr_\text{s}$, clip-related learning rate $\lr_\text{b}$, $\gamma$ quantile, batch size $\bs$, probability of violating $\delta$,
\\
\label{alg:quantile}
\begin{algorithmic}[1]
\State $\noisem=$\texttt{SetSigma}$\left(q, \eps, T, \delta, \noisem_{\text{b}} \right)$
\State \textbf{Initialize} global model $\model^0$
\For{each global round $t \in [T]$} 
\State $\gC^t \gets$ Sample $qN$ clients uniformly.
\For{each client $n\in \gC^t$ in parallel}
\State $(b_n^t,\tilde{\Delta}\model_n^t)$ =  
\texttt{ClientUpdate}$\left(t, n,\model^{t-1}, c^t\right)$.
\EndFor
\State Aggregate $\tilde{\Delta}\model^t = \sum_{n\in \gC^t} \tilde{\Delta}\model_n^t$
\State Add noise $\tilde{\Delta}\model^t \gets \tilde{\Delta}\model^t + \gN(0,(c^t)^2\noisem^2\sI)$
\State Average $\tilde{\Delta}\model^t \gets \frac{1}{qN} \tilde{\Delta}\model^t$
\State Compute $\tilde{\Delta}\model^t \gets \beta_{\text{s}} \tilde{\Delta}\model^{t-1} + (1-\beta_{\text{s}})\tilde{\Delta}\model^t$
\State Update $\model^{t} = \model^{t-1} + \lr_{\text{s}}\tilde{\Delta}\model^t$
\State $c^{t+1}$=\texttt{SetClippig}$\left(\{b_n^t\}_{n\in \gC^t}, \noisem_{\text{b}},q, \gamma, \lr_{\text{b}}, c^t\right)$
\EndFor
\Statex
\end{algorithmic}
\textbf{Def} \texttt{ClientUpdate}$\left(t, n,\model^{t}, c^t\right)$
\begin{algorithmic}[1]
\State \textbf{Initialize} local model $\model_n^{t,0}=\model^t$
\For{local iteration $l \in [l]$}
\State $\{\batch_i\}_{i=1}^{|\train_n|/B} \gets$ Split $\train_n$ to size $B$ batches
\For{each batch $\batch_i$}
\State $\model_n^{t,l} = \model_n^{t,l-1}-\frac{\lr \sum_{(\rvx,y)\in \batch_i} \nabla\loss_n\left(\model_n^{t,l-1};(\rvx,y)\right)}{\bs}$
\EndFor
\EndFor
\State Compute $\Delta\model_n^t = \model_n^{t,L} - \model_n^{t,0}$
\State Compute $b = \gI_{\left\|\Delta\model_n^t \right\|\leq c^t}$
\State Clip $\tilde{\Delta}\model_n^{t} = \Delta\model_n^t\min\left(1,\frac{c^t}{\left\|\Delta\model_n^{t}\right\|_2}\right)$  
\State Return $b, \tilde{\Delta}\model_n^{t}$ 
\Statex
\end{algorithmic}
\textbf{Def} \texttt{SetSigma}$\left(q, \eps, T, \delta, \noisem_{\text{b}} \right)$
\begin{algorithmic}[1]
\State $\bar{\noisem}=$\texttt{GetNoise}$\left(\eps,\delta, q, T\right)$
\State $\noisem = \left(\frac{1}{\bar{\noisem}^{2}} - \frac{1}{(2\noisem_{\text{b}})^2}\right)^{-1/2}$
\State Return $\noisem$
\Statex
\end{algorithmic}
\textbf{Def} \texttt{SetClippig}$\left(\{b_n^t\}_{n\in \gC^t}, \noisem_{\text{b}},q, \gamma, \lr_{\text{b}}, c^t\right)$
\begin{algorithmic}[1]
\State Aggregate $\tilde{b}^t = \sum_{n\in \gC^t} b_n^t$
\State Add noise $\tilde{b}^t \gets \tilde{b}^t + \gN(0,\noisem_{\text{b}}^2\sI)$ 
\State Average $\tilde{b}^t \gets \frac{1}{qN}\tilde{b}^t $
\State Update $c^{t+1}=c^t \exp \left(-\lr_{\text{b}}
(\tilde{b}^t-\gamma)\right)$
\State Return $c^{t+1}$
\end{algorithmic}
\end{algorithm}
