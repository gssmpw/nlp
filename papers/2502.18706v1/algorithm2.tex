\begin{algorithm}[H]
\caption{Individualized DP-FedAvg (IDP-FedAvg), a natural integration of IDP~\citep{boenisch2024have} to FL}
\textbf{Inputs:} No. clients $N$, No. global rounds $T$, No. local iterations $L$, local privacy budgets $\{\eps_n\}_{n\in [N]}$, average clip norm $c$, sampling rate $q$, loss functions $\{\loss_n\}_{n\in [N]}$, local datasets $\{\train_n\}_{n\in [N]}$, learning rate $\lr$, batch size $\bs$, probability of violating $\delta$ 
%\State \textbf{Results:} Final global model $\model^T$
\label{alg:idpfl}
\begin{algorithmic}[1]
\State $\noisem, \{c_n\}_{n\in [N]}=$\texttt{SetPrivacyParams}$\left(c, q, \{\eps_n\}_{n\in [N]}, T, \delta\right)$
\State \textbf{Initialize} global model $\model^0$
\For{each global round $t \in [T]$} 
\State $\gC^t \gets$ Sample clients with probability $q$.
\For{each client $n\in \gC^t$ in parallel}
\State $\tilde{\Delta}\model_n^t$ =  
\texttt{ClientUpdate}$\left(t, n,\model^{t-1}, c_n\right)$.
\EndFor
\State Aggregate $\tilde{\Delta}\model^t = \sum_{n\in \gC^t} \tilde{\Delta}\model_n^t$
\State Add noise $\tilde{\Delta}\model^t \gets \tilde{\Delta}\model^t + \gN(0,c^2\noisem^2\sI)$
\State Update $\model^{t} = \model^{t-1} + \frac{\tilde{\Delta}\model^t}{qN}$
\EndFor
\Statex
\end{algorithmic}
\textbf{Def} \texttt{ClientUpdate}$\left(t, n,\model^{t}, c_n\right)$
\begin{algorithmic}[1]
\State \textbf{Initialize} local model $\model_n^{t,0}=\model^t$
\For{local iteration $l \in [l]$}
\State $\{\batch_i\}_{i=1}^{|\train_n|/B} \gets$ Split $\train_n$ to size $B$ batches
\For{each batch $\batch_i$}
\State $\model_n^{t,l} = \model_n^{t,l-1}-\frac{\lr}{\bs}\sum_{(\rvx,y)\in \batch_i} \nabla\loss\left(\model_n^{t,l-1};(\rvx,y)\right)$
\EndFor
\EndFor
\State Compute $\Delta\model_n^t = \model_n^{t,L} - \model_n^{t,0}$
\State Clip $\tilde{\Delta}\model_n^{t} = \Delta\model_n^t\min\left(1,\frac{c_n}{\left\|\Delta\model_n^{t}\right\|_2}\right)$  
\State Return $\tilde{\Delta}\model_n^{t}$ 
\Statex
\end{algorithmic}
\textbf{Def} \texttt{SetPrivacyParams}$\left(c, q, \{\eps_n\}_{n\in [N]}, T, \delta\right)$
\begin{algorithmic}[1]
\For{each client $n \in [N]$}
\State Set local noise multiplier $\noisem_n=$\texttt{GetNoise}$\left(\eps_n,\delta, q, T\right)$
\EndFor
\State Compute $\noisem \gets \left(\frac{1}{N}\sum_{n\in [N]}\frac{1}{\noisem_n}\right)^{-1}$
\For{each client $n \in [N]$}
\State Set local clip norm $c_n=\frac{c\noisem}{\noisem_n}$
\EndFor
\State Return $\noisem, \{c_n\}_{n\in [N]}$
\end{algorithmic}
\end{algorithm}