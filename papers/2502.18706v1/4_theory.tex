\section{Theoretical Analysis}\label{sec:theory}
For the DP-FL framework (described in Sec.~\ref{sec:propose}), we now develop the theory that underlies our privacy accounting (Sec.~\ref{sec:theory:privacy}), and optimize the sampling rates to improve utility (Sec.~\ref{sec:theory:permutation}). 

\subsection{Privacy Accounting} \label{sec:theory:privacy}
In this section, we calculate the RDP bounds for each client $n\in [N]$ at round $t\in [T]$. The results will support the general idea of save-to-spend in our framework. Since we use RDP to perform privacy accounting, we convert each client's privacy budgets $\{\eps_n\}_{n\in [N]}$ into the RDP equivalent, denoted $\{\reps{n}\}_{n\in [N]}$, at a fixed order $\alpha$. For client $n$, we use $\reps{n}^t$ and $\rreps{n}^t$ to denote, respectively, the RDP privacy spent in round $t$ and the ``go-forward'' RDP privacy budget remaining for round $t$ onwards.

The privacy accounting for the \algasgo method first involves calculating each $\reps{n}^t$ (cf.~line~6 of Alg.~\ref{alg:tidpfl:privacy}). Next, the total RDP privacy spent during the first $t$ rounds is calculated as $\sum_{\tau = 1}^{t-1} \reps{n}^{\tau}$ (Line~7 of Alg.~\ref{alg:tidpfl:privacy}), with  budget remaining $\rreps{n}^t=\reps{n}-\sum_{\tau = 1}^{t-1} \reps{n}^{\tau}$. Recalling from Sec.~\ref{sec:proposed:alg:privacy}, client $n$ selects the noise multiplier $\noisem_n^t$ assuming that $\rreps{n}^t$ will be spent uniformly across the remaining $T-t+1$ rounds subject to using sampling rate $q$. As shown by~\cite{mironov2019r}, under this uniform assumption $\noisem_n^t$ should satisfy $\frac{\rreps{n}^t}{T-t+1}= \frac{2\alpha q^2}{\noisem_n^t}$. When $t<T_n$, the sampling rate $q_n$ reduces the RDP expenditure to $\reps{n}^t=\frac{\rreps{n}^t(q_n)^2}{(T-t+1)(q)^2}$. When $t\geq T_n$, the full allocated budget is used in round $t$. The RDP privacy spend $\reps{n}^t$ can be computed recursively as
\begin{align}\label{eq:recursive}
    \reps{n}^t = \left(\frac{\reps{n}-\sum_{\tau = 1}^{t-1} \reps{n}^{\tau}}{T-t+1}\right)\left(\1{t<T_n}\left(\frac{q_n^t}{q}\right)^2 + \1{t\geq T_n}\right).
\end{align}
Lemma~\ref{thm:recursive} solves the recursive formula~(\ref{eq:recursive}) for the RDP spent. Theorem~\ref{thm:privacyspent} shows the RDP spent is non-decreasing over time. The proofs of Lem.~\ref{thm:recursive} and Thm.~\ref{thm:privacyspent} are respectively provided in App.~\ref{app:thm:recursive} and~\ref{app:thm:privacyspent}.
\begin{lem} Given any $n\in [N], t\in [T]$, and $T_n\in [T]$, we have
    \begin{align}\label{eq:thm:recursive}
        \reps{n}^t = \begin{cases} \frac{\reps{n}}{T-t+1}\left(\frac{q_n}{q}\right)^2\prod_{i=1}^{t-1} \left(1-\frac{1}{T-t+1+i}\left(\frac{q_n}{q}\right)^2\right) & \text{if } t<T_n \\
        \frac{\reps{n}}{T-T_n+1}\prod_{i=1}^{T_n-1} \left(1-\frac{1}{T-T_n+1+i}\left(\frac{q_n}{q}\right)^2\right) & \text{ow}\end{cases}.
    \end{align}
    \label{thm:recursive}
\end{lem}

\begin{theorem}\label{thm:privacyspent}
For $(n,t,T_n)\in [N]\times[T]\times [T]$, $\reps{n}^t \geq \reps{n}^{t-1}$ if $t\leq T_n$, and $\reps{n}^t = \reps{n}^{t-1}$ if $t> T_n$.
\end{theorem}


\begin{remark}
The non-decreasing result of Thm.~\ref{thm:privacyspent} indicates that during saving rounds ($M_n^t = 0$) clients spend at least as much of their privacy budget in each round as in the previous round. In other words, saving decreases over time. During spending rounds ($M_n^t = 1$)  clients expend privacy budget at a constant rate.  If budget savings are accumulated than $\reps{n}^{T_n} > \reps{n}^{T_n-1}$ and clients will have access to a larger budget to spend.
\end{remark}


\subsection{Optimal Permutation of Saving-based Sampling Rates} \label{sec:theory:permutation}
We now optimize the selection of sampling rates. We start from a pre-defined set of $N$ sampling rates.  We then choose a permutation that assigns each of the $N$ rates to a distinct client. The permutation is selected to minimize the per-round difference between the utility achieved when DP perturbation is not applied (which generally will maximize utility), and the utility achieved when our DP-FL framework is used. In the first case, the server aggregates the unperturbed local updates $\Delta \model_n^t$ (i.e., no clipping or noise addition) for all clients $n\in [N]$ (i.e., no  sub-sampled), and updates the global model as $\model^t = \model^{t-1} + \Delta \model^t$ where 
\begin{align}
\Delta \model^t = \frac{1}{N}\sum_{n=1}^N \Delta \model_n^t. 
\end{align} 

In our DP-FL framework, local updates undergo the DP mechanism detailed in Sec.~\ref{sec:propose}. Factoring into the (modified) global update $\tilde{\Delta}\model^t$ the clipping norms $c_n^t$, the additive noise multipliers $\sigma_n^t$, and the sampling rates $q_n^t$, we get
\begin{align}
\tilde{\Delta} \model^t = \frac{1}{Nq^t}\sum_{n=1}^N \left(\rb_n^t \left(\clip{{\Delta \model_n^t}}{c_n^t}+\rz_n^t\right)+ (1-\rb_n^t)\tilde{\rz}_n^t\right),
\end{align} 
where $q^t=\frac{1}{N}\sum_{n=1}^N q_n^t$, $\rz_n^t,\tilde{\rz}_n^t \sim \noise{0}{\frac{\left(\sigma_n^tc_n^t\right)^2}{N}}$ are identically and independently distributed (IID), and $\rb_n^t\sim \bern{q_n^t}$ are also IID. The optimization problem is to choose the $\{q_n^t\}_{n\in [N]}$ so that $\tilde{\Delta} \model^t$ closely approximates an unbiased estimate of $\Delta \model^t$. We define the difference between the respective model updates as
\begin{align}
\error^t:= \Delta \model^t - \tilde{\Delta} \model^t.
\end{align}

$\error^t$ has four sources of randomness: 
\begin{itemize}
\item[(i)] \textbf{Local dataset randomness}: the randomness of local datasets $\train_n$, which are sampled from distributions $P_n$.  This randomness is reflected in the local updates $\Delta \model_n^t$.
\item[(ii)] \textbf{Client sampling randomness:} the sampling of clients, represented by the use of random variables $\rb_n^t$.  These determine whether a client $n$ contributes to the round $t$'s local training. 
\item[(iii)] \textbf{Noise addition randomness:} the addition of the Gaussian noises $\rz_n^t$ and  $\tilde{\rz}_n^t$.
\item[(iv)] \textbf{Privacy budget assignment randomness:}  the matching of clients with different datasets $\train_n$ and data distributions $P_n$ to different privacy budgets $\eps_{n}$. Here, $\{\eps_{n}\}_{n\in [N]}$ are considered as a random permutation of a predefined set of privacy budgets $\{\hat{\eps}_n\}_{n\in [N]}$.
\end{itemize}
 
To optimize the sampling rates, we first develop two upper bounds on the bias term $\left\| \expect{\error^t}\right\|$. Both bounds build on the clipping bias lemma~\citep{das2023beyond}, cf., Lem.~\ref{app:prior:clipbias} in App.~\ref{app:prior:lemma}. Our theorems extend the results of that lemma to the situation where clients have individualized privacy budgets and use time-varying clip norms $c_n^t$ and sampling rates $q_n^t$.

Our first theorem, Thm.~\ref{THM:clip_aware1}, bounds the expected bias with respect to (w.r.t.) three sources of randomness: (i), (ii), and (iii). We denote this expectation as $\left\| \expectation{(i), (ii), (iii)}{\error^t}\right\|$.  The proof of Thm.~\ref{THM:clip_aware1} is given in App.~\ref{app:THM:clip_aware1}. 
 
\begin{theorem}\label{THM:clip_aware1} Taking the expectation w.r.t. (i), (ii), and (iii), and for any $\rho>1$, we have
\begin{align}\label{eq:THM:clip_aware1:1}
\left\| \expectation{(i), (ii), (iii)}{\error^t}\right\| \leq \frac{1}{N} \left\| \sum_{n=1}^N \left(1 - \frac{q_n^t}{q^t}\right)\expectation{(i)}{{\Delta \model_n^t}}\right\| + \frac{1}{N}\sum_{n=1}^N \frac{q_n^t}{q^t}  \frac{\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}}{\left(c_n^t\right)^{\rho-1}}.
\end{align}
\end{theorem}

To minimize this bias term in a reasoned fashion we select the $q_n^t$ to minimize the upper bound. The upper bound in (\ref{eq:THM:clip_aware1:1}) contains terms that couple $q_n^t$ with the pure local updates $\Delta \model_n^t$.  The latter are not accessible to the server who is responsible for sampling clients. If clients were to select their own $q_n^t$ based on their local updates, this could lead to privacy leakage and would require additional privacy protection. The coupling between $q_n^t$ and $\Delta \model_n^t$ can be removed from the first term of the upper bound in (\ref{eq:THM:clip_aware1:1}) under certain conditions. For example, if all clients are sampled at the same rate ($q_n^t=q^t$) or if $\expectation{(i)}{\Delta \model_n^t}$ is equal across all $n\in [N]$, the first term becomes zero. In such cases, the upper bound reduces to the second term, which still couples  $q_n^t$ with $\Delta \model_n^t$ and the clip norms $c_n^t$. 

In contrast to Thm.~\ref{THM:clip_aware1}, in Thm.~\ref{THM:clip_aware2} we take the expectation w.r.t.~the additional source of randomness, (iv).  This results in a bound that depends solely on clipping norms, which makes optimizing the sampling rates, $q_n^t$, easier to accomplish.  As we now bound the expected bias w.r.t. all four sources of randomness -- (i), (ii), (iii), and (iv) -- we denote the expectation as $\left\| \expectation{(i), (ii), (iii), (iv)}{\error^t}\right\|$. The proof of Thm.~\ref{THM:clip_aware2} is given in App.~\ref{app:THM:clip_aware2}.
 
\begin{theorem}\label{THM:clip_aware2} Taking the expectation w.r.t. (i), (ii), (iii), and (iv), and for any $\rho>1$, we have:
\begin{align}
\left\| \expectation{(i), (ii), (iii), (iv)}{\error^t}\right\| \leq \frac{1}{N^2}\left(\sum_{n=1}^N\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\right)\sum_{n=1}^N \left( \frac{q_n^t}{q^t}  \frac{1}{\left(c_n^t\right)^{\rho-1}}\right).
\end{align}
\end{theorem}


The main step in the proofs of Thm.~\ref{THM:clip_aware2} builds on the common assumption in FL that the sampling from $P_n$ and of $\eps_n$ is independent. This assumption is made without significant loss of generality as privacy budgets are often assigned based on clients' personal preferences and policy requirements.  In contrast, the data distribution is influenced by external factors such as geographical locations. Such decoupling of privacy budgets and data distributions simplifies the proof of Thm.~\ref{THM:clip_aware2}.  It avoids the need to model potential correlations between the client's data and privacy preferences.  These are often unknown or irrelevant in practice. 

As per Thm.~\ref{THM:clip_aware2}, to minimize $\left\| \expectation{(i), (ii), (iii), (iv)}{\error^t}\right\|$ w.r.t. the sampling rates $q_n^t$, we solve the following optimization problem:

\begin{equation}\label{eq:way3:opt}
\begin{aligned}
\min_{\{\Pi_t\}_{t=1}^T} \quad &
\sum_{n=1}^N \frac{q_n^t}{q^t}  \frac{1}{\left(c_n^t\right)^{\rho-1}}
\\
\textrm{s.t.} \quad & q_n^t = q_{\Pi_t^{-1}(n)}, n \in [N]
\end{aligned},
\end{equation}
where the $\{\Pi_t\}$ are a set of (bijective) permutation maps $\Pi_t: [N] \rightarrow [N]$.  Each permutation maps each element of the index set $[N]$ to a distinct element of $[N]$.  We apply the permutation to the indices of the fixed set of sampling rates $\{q_1,\ldots,q_N\}$ to get $\{q_1^t,\ldots,q_N^t\}$. The set $\{q_1,\ldots,q_N\}$ is a hyperparameter in our problem, which is constrained by the condition $q_n\leq q$ for every $n\in [N]$. The optimized choice of the set of sampling rates $\{q_1,\ldots,q_N\}$ is reserved for future work. Per (\ref{eq:way3:opt}), the optimal choice for $\{q_1^t,\ldots,q_N^t\}$ is to assign clients with smaller clip norms $c_n^t$ (which will contribute highly perturbed model updates) to have lower sampling rates $q_n^t$, and vice versa. The intuition is that by matching the $q_n^t$ to the $c_n^t$, we prevent clients who contribute a highly perturbed model update from deteriorating other clients' performance during saving rounds. This reduces clipping bias and allows these clients to preserve more of their privacy budget compared, with the subsequent benefit of enabling them to contribute more in future rounds.
 
