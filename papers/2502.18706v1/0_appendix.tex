\section{Appendix}

\subsection{
{Summary of Notations} and  Benchmarking Schemes}\label{app:benchmark}
{We summarize the important notations (including the hyperparameters shown in Table~\ref{sec3:notations}) in Table~\ref{app:summary_table}. We formally depict the baselines: FedAvg~\citep{mcmahan2017communication} as Alg.~\ref{alg:fedavg}, DP-FedAvg as Alg.~\ref{alg:dpfl}, IDP-FedAvg as Alg.~\ref{alg:idpfl}, and adaptive clipping~\citep{andrew2021differentially} as Alg.~\ref{alg:quantile}. Next, we provide further details to explain the adaptive clipping baseline in comparison with our proposed approach.}


\begin{table*}[ht]
\begin{threeparttable}
\caption{
{A Summary of Notation and Hyperparameters\tnote{1}.}}
\centering\label{app:summary_table}
\begin{tabular}{|c|l||c|c|}
\hline
$N$ & No. of Clients & $\train_n$ & Dataset of Client $n$ 
\\ \hline
$\gC^t$ & Client set in R. $t$ & $\batch_i$ & Batch $i$ 
\\ \hline
$T$ & No. of rounds & $B$ & Batch size 
\\ \hline
$L$ & No. of local iterations & $\eps_n$ & DP privacy budget of Client $n$
\\ \hline
$\model^t$ & Global model at R. $t$ & $\reps{n}^t$ & RDP privacy spent of Client $n$ in R. $t$ \\ \hline
$\Delta\model^t$ & Global model update at R. $t$& $\rreps{n}^t$ & RDP budget RE. of Client $n$ for R. $t$ onwards \\ \hline
$\model_n^{t,l}$ & Model of Client $n$ at R. $t$, I. $l$ & $\bar{\eps}_{\text{rdp},n}^t$ & RDP privacy spend of Client $n$ up to R. $t+1$ \\ \hline
$\Delta\model_n^t$ & Model update of Client $n$ at R. $t$& $\eps_n^t$ & DP budget RE. of Client $n$ for R. $t$ onwards \\ \hline
$\tilde{\Delta}\model_n^t$ & Perturbed update of Client $n$ at R. $t$& $\noisem^t$ & Global noise multiplier in R. $t$ \\ \hline
$\text{Error}_t$ & $\Delta \model^t - \tilde{\Delta} \model^t$ & $\noisem_n^t$ & Noise multiplier of Client $n$ in R. $t$ \\ \hline
$\lr$ & Learning rate  & $c$ & Average clipping norm \\ \hline
$\alpha$ & R\'{e}nyi order in RDP & $c_n^t$ & Clipping norm of Client $n$ in R. $t$ \\ \hline
$\delta$ & Probability of violating in DP  & $q$ & Spending-based sampling rate \\ \hline
$T_n$ & Saving-to-spending transition R.  & $q_n$ & Saving-based sampling rate of Client $n$ \\ \hline
$M_n^t$ & Saving-or-spending mode  & $q_n^t$ & Sampling rate of Client $n$ in R. $t$ \\ \hline
$\loss_n$ & Loss function of Client $n$  & $q^t$ & Average sampling rate in R. $t$ \\ \hline
\end{tabular}
 \begin{tablenotes}
	\item[1] Table's abbreviations: ``No.'' for ``Number'', ``RE.'' for ``Remaining'', ``I.'' for ``Iteration'', and ``R.'' for ``Round''.     
   \end{tablenotes}
\end{threeparttable}
\end{table*}

\input{algorithms12_merge}

{\textbf{The Adapting Clipping Baseline}. In this paper, we consider the adaptive clipping method~\citep{andrew2021differentially} as a baseline for our time-adaptive DP-FL approach. In the extended simulations (cf. App.~\ref{app:extendedresults}), we benchmark that method against our approach. The method is formally presented as Alg.~\ref{alg:quantile}. As shown in Line 13, the server dynamically adjusts the clipping norm based on a specified quantile $\gamma$ of the distribution of clients’ updates. The goal of this method is to minimize the difference between the clipping norm and the quantile in the distribution, aiming to achieve the same objective as ours: improving the privacy-utility tradeoff. In contrast to our time-adaptive approach, which is independent of the client's data and can be done prior to training, the method~\citep{andrew2021differentially} introduces privacy risks during the quantile approximation. To mitigate these risks, and as is shown in Line 2 of the \texttt{SetClipping} function in Alg.~\ref{alg:quantile}, the method~\citep{andrew2021differentially} incorporates a supplementary DP mechanism that allocates part of the privacy budget to preserve privacy during quantile estimation. However, this results in a lower remaining privacy budget, requiring a larger noise multiplier $\sigma$, as computed in Line 2 of \texttt{SetSigma} in Alg.\ref{alg:quantile}, in comparison to our approach. }


\input{algorithm45_merge}

\subsection{Proof of Lemma~\ref{thm:recursive}}\label{app:thm:recursive}
We use induction to solve the recursive formula (\ref{eq:recursive}). According to (\ref{eq:recursive}), when $t=1<T_n$, $\reps{n}^1=\frac{\reps{n}(q_n)^2}{T(q)^2}$, and when $t=2<T_n$, client $n$ spends $\reps{n}^2 = \frac{\reps{n}-\reps{n}^1}{T-1} \left(\frac{q_n}{q}\right)^2$. By substituting $\reps{n}^1$ in $\reps{n}^2$, we obtain $\reps{n}^2 = \frac{\reps{n}}{T-1}\left(1-\frac{1}{T}\left(\frac{q_n}{q}\right)^2\right)\left(\frac{q_n}{q}\right)^2$. We now assume $\reps{n}^{t-1}$ satisfies in (\ref{eq:thm:recursive}) for every $2 \leq t<T$. If $t< T_n$, by substituting $\reps{n}^{t-1}$ in (\ref{eq:recursive}), we obtain
\begin{align}
    \reps{n}^t &= \left(\frac{\reps{n}-\sum_{\tau = 1}^{t-1} \reps{n}^{\tau}}{T-t+1}\right)\left(\frac{q_n}{q}\right)^2
    = \left(\frac{\reps{n}^{t-1}(T-t+2)\left(\frac{q}{q_n}\right)^2- \reps{n}^{t-1}}{T-t+1}\right)\left(\frac{q_n}{q}\right)^2
    \\
    &= \reps{n}^{t-1}\frac{\left(T-t+2-\left(\frac{q_n}{q}\right)^2\right)}{T-t+1}
    \\
    &= 
    \frac{\reps{n}}{T-t+2}\left(\frac{q_n}{q}\right)^2\left(\prod_{i=1}^{t-2} \left(1-\frac{1}{T-t+2+i}\left(\frac{q_n}{q}\right)^2\right)\right)\frac{\left(T-t+2-\left(\frac{q_n}{q}\right)^2\right)}{T-t+1}
    \\
    &=
    \frac{\reps{n}}{T-t+1}\left(\frac{q_n}{q}\right)^2\prod_{i=1}^{t-1} \left(1-\frac{1}{T-t+1+i}\left(\frac{q_n}{q}\right)^2\right).
\end{align}
If $t= T_n$, by substituting $\reps{n}^{t-1}$ in (\ref{eq:recursive}), we obtain
\begin{align}
    \reps{n}^{T_n} &= \left(\frac{\reps{n}-\sum_{\tau = 1}^{T_n-1} \reps{n}^{\tau}}{T-T_n+1}\right)
    = \left(\frac{\reps{n}^{T_n-1}(T-T_n+2)\left(\frac{q}{q_n}\right)^2- \reps{n}^{T_n-1}}{T-T_n+1}\right)
    \\
    &= \reps{n}^{T_n-1}\frac{\left(T-T_n+2-\left(\frac{q_n}{q}\right)^2\right)}{T-T_n+1}\left(\frac{q}{q_n}\right)^2
    \\
    &= 
    \frac{\reps{n}}{T-T_n+2}\left(\prod_{i=1}^{T_n-2} \left(1-\frac{1}{T-T_n+2+i}\left(\frac{q_n}{q}\right)^2\right)\right)\frac{\left(T-T_n+2-\left(\frac{q_n}{q}\right)^2\right)}{T-T_n+1}
    \\
    &=
    \frac{\reps{n}}{T-T_n+1}\prod_{i=1}^{T_n-1} \left(1-\frac{1}{T-T_n+1+i}\left(\frac{q_n}{q}\right)^2\right).
\end{align}

If $t> T_n$, by substituting $\reps{n}^{t-1}$ in (\ref{eq:recursive}), we obtain
\begin{align}
    \reps{n}^{t} &= \left(\frac{\reps{n}-\sum_{\tau = 1}^{t-1} \reps{n}^{\tau}}{T-t+1}\right)
    = \left(\frac{\reps{n}^{t-1}(T-t+2)- \reps{n}^{t-1}}{T-t+1}\right)
    \\
    &= \reps{n}^{t-1} = 
     \frac{\reps{n}}{T-T_n+1}\prod_{i=1}^{T_n-1} \left(1-\frac{1}{T-T_n+1+i}\left(\frac{q_n}{q}\right)^2\right). 
\end{align}



\subsection{Proof of Theorem~\ref{thm:privacyspent}}\label{app:thm:privacyspent}
We use the explicit solutions of the recursive formula (\ref{eq:recursive}), presented in Lem.~\ref{thm:recursive}, to prove this theorem. When $t< T_n$, 
\begin{align}
    \reps{n}^t - \reps{n}^{t-1} &=  \frac{\reps{n}}{T-t+1}\left(\frac{q_n}{q}\right)^2\prod_{i=1}^{t-1} \left(1-\frac{1}{T-t+1+i}\left(\frac{q_n}{q}\right)^2\right)  
    \\
    &-
    \frac{\reps{n}}{T-t+2}\left(\frac{q_n}{q}\right)^2\prod_{i=1}^{t-2} \left(1-\frac{1}{T-t+2+i}\left(\frac{q_n}{q}\right)^2\right)
    \\
    &=\reps{n}\left(\frac{q_n}{q}\right)^2\left(\prod_{i=1}^{t-2} \left(1-\frac{1}{T-t+2+i}\left(\frac{q_n}{q}\right)^2\right)\right)
    \\
    &\times \left(\frac{1}{T-t+1}\left(1-\frac{1}{T-t+2}\left(\frac{q_n}{q}\right)^2\right) - \frac{1}{T-t+2}\right)
    \\
    &=\reps{n}\left(\frac{q_n}{q}\right)^2\left(\prod_{i=1}^{t-2} \left(1-\frac{1}{T-t+2+i}\left(\frac{q_n}{q}\right)^2\right)\right) \frac{1-\left(\frac{q_n}{q}\right)^2}{(T-t+1)(T-t+2)}.\label{app:app:thm:privacyspent:1}
\end{align}
The right-hand side of (\ref{app:app:thm:privacyspent:1}) is larger than equal to zero because $q_n \leq q$. Therefore, in this case $\reps{n}^t \geq \reps{n}^{t-1}$. When $t= T_n$,
\begin{align}
    \reps{n}^{T_n} - \reps{n}^{T_n-1} &=  \frac{\reps{n}}{T-T_n+1}\prod_{i=1}^{T_n-1} \left(1-\frac{1}{T-T_n+1+i}\left(\frac{q_n}{q}\right)^2\right)  
    \\
    &-
    \frac{\reps{n}}{T-T_n+2}\left(\frac{q_n}{q}\right)^2\prod_{i=1}^{T_n-2} \left(1-\frac{1}{T-T_n+2+i}\left(\frac{q_n}{q}\right)^2\right)
    \\
    &=\reps{n}\left(\prod_{i=1}^{T_n-2} \left(1-\frac{1}{T-T_n+2+i}\left(\frac{q_n}{q}\right)^2\right)\right)
    \\
    &\times \left(\frac{1}{T-t+1}\left(1-\frac{1}{T-T_n+2}\left(\frac{q_n}{q}\right)^2\right) - \frac{\left(\frac{q_n}{q}\right)^2}{T-T_n+2}\right)
    \\
    &=\reps{n}\left(\prod_{i=1}^{T_n-2} \left(1-\frac{1}{T-T_n+2+i}\left(\frac{q_n}{q}\right)^2\right)\right) \frac{1-\left(\frac{q_n}{q}\right)^2}{(T-T_n+1)}.\label{app:app:thm:privacyspent:2}
\end{align}
The right-hand side of (\ref{app:app:thm:privacyspent:2}) is again larger than equal to zero because. Therefore, in this case we also have $\reps{n}^{T_n} \geq \reps{n}^{T_n-1}$.  Lem.~\ref{thm:recursive} also shows $\reps{n}^{t} = \reps{n}^{t-1}$ when $t>T_n$.


\subsection{Proof of Theorem~\ref{THM:clip_aware1}}\label{app:THM:clip_aware1}
%In Thm.~\ref{THM:clip_aware1}, the expectation is taken with respect to (w.r.t.) (i), (ii), and (iii). Thus, we denote this as $\left\| \expectation{(i), (ii), (iii)}{\error^t}\right\|$.


If the expectation is taken w.r.t. (i) the randomness of local datasets, (ii) the sampling of clients, and (iii) the randomness of injected Gaussian noise, then the bias
is simplified as follows:
\begin{align}
&\left\| \expectation{(i),(ii),(iii)}{\error^t}\right\| \nonumber 
\\
&= \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i),(ii),(iii)}{\Delta \model_n^t -  \frac{1}{q^t}\left(\rb_n^t \left(\clip{{\Delta \model_n^t}}{c_n^t}+\rz_n^t\right)+ (1-\rb_n^t)\tilde{\rz}_n^t\right)} \right\|
\nonumber
\\
&= \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i),(ii)}{\Delta \model_n^t -  \frac{1}{q^t}\rb_n^t \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|
\label{app:THM:clip_aware1:2}
\\
& = \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i)}{{\Delta \model_n^t} -  \frac{q_n^t}{q^t} \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|
\label{app:THM:clip_aware1:4}
\\
& = \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i)}{{\Delta \model_n^t}\left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t} + \frac{q_n^t}{q^t}\right) -  \frac{q_n^t}{q^t} \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|
\label{app:THM:clip_aware1:5}
\\
& = \frac{1}{N} \left\| \sum_{n=1}^N \left(\left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t}\right)\expectation{(i)}{{\Delta \model_n^t}} + \frac{q_n^t}{q^t} \expectation{(i)}{{\Delta \model_n^t}-   \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)}\right) \right\|
\label{app:THM:clip_aware1:6}
\\
&\leq \frac{1}{N} \left\| \sum_{n=1}^N \left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t}\right)\expectation{(i)}{{\Delta \model_n^t}}\right\| + \frac{1}{N}\sum_{n=1}^N\left\|\frac{q_n^t}{q^t} \expectation{(i)}{{\Delta \model_n^t}-   \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|
\label{app:THM:clip_aware1:7}
\\
&\leq \frac{1}{N} \left\| \sum_{n=1}^N \left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t}\right)\expectation{(i)}{{\Delta \model_n^t}}\right\| + \frac{1}{N}\sum_{n=1}^N \frac{q_n^t}{q^t}  \frac{\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}}{\left(c_n^t\right)^{\rho-1}}. \label{app:THM:clip_aware1:8}
\end{align}
The equality~(\ref{app:THM:clip_aware1:2}) is due to $\expectation{(iii)}{\rz_n^t}=\expectation{(iii)}{\tilde{\rz}_n^t}=0$. The equality~(\ref{app:THM:clip_aware1:4}) is due to $\expectation{(ii)}{\rb_n^t}=q_n^t$. The inequality~(\ref{app:THM:clip_aware1:7}) is due to triangle inequality. The inequality~(\ref{app:THM:clip_aware1:8}) is due to the clipping bias lemma~\citep{das2023beyond}, given any $\rho>1$.   


\subsection{Proof of Theorem~\ref{THM:clip_aware2}}\label{app:THM:clip_aware2}

If the expectation is taken w.r.t. (i) the randomness of local datasets and (ii) the sampling of clients, (iii) the randomness of injected Gaussian noise, and (iv) privacy budget assignment randomness, then the bias is simplified as follows:

\begin{align}
&\left\| \expectation{(i),(ii),(iii), (iv)}{\error^t}\right\| \nonumber 
\\
&= \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i),(ii),(iii), (iv)}{\Delta \model_n^t -  \frac{1}{q^t}\left(\rb_n^t \left(\clip{{\Delta \model_n^t}}{c_n^t}+\rz_n^t\right)+ (1-\rb_n^t)\tilde{\rz}_n^t\right)} \right\|
\nonumber
\\
&= \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i),(ii), (iv)}{\Delta \model_n^t -  \frac{1}{q^t}\rb_n^t \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|
\label{app:THM:clip_aware2:2}
\\
& = \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i),(ii), (iv)}{{\Delta \model_n^t} -  \frac{\rb_n^t}{q^t} \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|
\label{app:THM:clip_aware2:3}
\\
& = \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i), (iv)}{{\Delta \model_n^t} -  \frac{q_n^t}{q^t} \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|
\label{app:THM:clip_aware2:4}
\\
& = \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(i), (iv)}{\frac{\Delta \model_n^t}{1}\left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t} + \frac{q_n^t}{q^t}\right) -  \frac{q_n^t}{q^t} \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|
\label{app:THM:clip_aware2:5}
\\
& = \frac{1}{N} \left\| \sum_{n=1}^N \left(\expectation{(i),(iv)}{\left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t}\right){\Delta \model_n^t}} + \expectation{(i),(iv)}{{q_n^t}{q^t} {\Delta \model_n^t}-   \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)}\right) \right\|
\label{app:THM:clip_aware2:6}
\\
&\leq \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(iv)}{\left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t}\right)\expectation{(i)}{{\Delta \model_n^t}}}\right\| + \nonumber
\\
&+ \frac{1}{N}\sum_{n=1}^N\left\|\expectation{(iv)}{\frac{q_n^t}{q^t} \expectation{(i)}{{\Delta \model_n^t}-   \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)}} \right\|
\label{app:THM:clip_aware2:7}
\\
&\leq \frac{1}{N} \left\| \sum_{n=1}^N \expectation{(iv)}{\left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t}\right)\expectation{(i)}{{\Delta \model_n^t}}}\right\| + \nonumber
\\
&+ \frac{1}{N}\sum_{n=1}^N\expectation{(iv)}{\left\|\frac{q_n^t}{q^t} \expectation{(i)}{{\Delta \model_n^t}-   \left(\clip{{\Delta \model_n^t}}{c_n^t}\right)} \right\|}
\label{app:THM:clip_aware2:8}
\\
&\leq \frac{1}{N} \left\| \sum_{n=1}^N\expectation{(iv)}{ \left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t}\right)\expectation{(i)}{{\Delta \model_n^t}}}\right\| + \frac{1}{N}\sum_{n=1}^N \expectation{(iv)}{\frac{q_n^t}{q^t}  \frac{\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}}{\left(c_n^t\right)^{\rho-1}}}. \label{app:THM:clip_aware2:9}
\end{align}

The equality~(\ref{app:THM:clip_aware2:2}) is due to $\expectation{(iii)}{\rz_n^t}=\expectation{(iii)}{\tilde{\rz}_n^t}=0$. The equality~(\ref{app:THM:clip_aware2:3}) is due to $\expectation{(ii)}{\rb_n^t}=q_n^t$. The inequality~(\ref{app:THM:clip_aware2:7}) is due to triangle inequality. The inequality~(\ref{app:THM:clip_aware2:9}) is due to the clipping bias lemma~\citep{das2023beyond} given any $\rho>1$.

We next further simplify the first and second terms on the right-hand side of (\ref{app:THM:clip_aware2:9}).

The first term equals zero:
\begin{align}
&\expectation{(iv)}{ \left(\frac{q^t}{q^t} - \frac{q_n^t}{q^t}\right)\expectation{(i)}{{\Delta \model_n^t}}} \nonumber
\\
&= \expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\expectation{(iv)}{1 - \frac{q_n^t}{q^t}}
\label{app:THM:clip_aware2:1:1}
\\
&= \expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\left(\sum_{i\in [N]} \pr{\eps_n=\hat{\eps}_i}\expectation{(iv)}{\left.1 - \frac{q_n^t}{q^t}\right| \eps_n=\hat{\eps}_i}\right)
\label{app:THM:clip_aware2:1:2}
\\
&=\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\left(\frac{1}{N}\sum_{i\in [N]}\left(1 - \frac{\hat{q}_i^t}{q^t} \right) \right)
\label{app:THM:clip_aware2:1:3}
\\&=\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\left(\frac{1}{N}\sum_{n\in [N]}\left(1 - \frac{q_n^t}{q^t} \right) \right)\label{app:THM:clip_aware2:1:4}
\\
&=
\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\left(\frac{1}{N}\left(N - \frac{q^tN}{q^t} \right) \right) = 0.\label{app:THM:clip_aware2:1:5}
\end{align}

Equality (\ref{app:THM:clip_aware2:1:1}) is due to the independency of randomness between (i) and (iv). Equality (\ref{app:THM:clip_aware2:1:3}) is because of our assumption that the sampling from $P_n$ and of $\eps_n$ is independent. Equality (\ref{app:THM:clip_aware2:1:5}) is because $\sum_{n=1}^N q_n^t = q^t$.

The second term on the right-hand side of (\ref{app:THM:clip_aware2:9}) can be further simplified into:
\begin{align}
&\expectation{(iv)}{\frac{q_n^t}{q^t} \frac{\expectation{(i)}{\left\|{\Delta \model_n^t}{}\right\|^{\rho}}}{\left(c_n^t\right)^{\rho-1}}} \nonumber
\\
&= \expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\expectation{(iv)}{\frac{q_n^t}{q^t} \frac{1}{\left(c_n^t\right)^{\rho-1}}}
\label{app:THM:clip_aware2:2:1}
\\
&= \expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\left(\sum_{i\in [N]} \pr{\eps_n=\hat{\eps}_i}\expectation{(iv)}{\left.\frac{q_n^t}{q^t} \frac{1}{\left(c_n^t\right)^{\rho-1}}\right| \eps_n=\hat{\eps}_i}\right)
\label{app:THM:clip_aware2:2:2}
\\
&=\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\left(\frac{1}{N}\sum_{i\in [N]}\frac{\hat{q}_i^t}{q^t} \frac{1}{\left(\hat{c}_i^t\right)^{\rho-1}} \right)
\label{app:THM:clip_aware2:2:3}
\\
&=\expectation{(i)}{\left\|{\Delta \model_n^t}\right\|^{\rho}}\left(\frac{1}{N}\sum_{n\in [N]}\frac{q_n^t}{q^t} \frac{1}{\left(c_n^t\right)^{\rho-1}} \right).\label{app:THM:clip_aware2:2:4}
\end{align}

Equality (\ref{app:THM:clip_aware2:2:1}) is due to the independency of randomness between (i) and (iv). Equality (\ref{app:THM:clip_aware2:2:2}) is because of our assumption that the sampling from $P_n$ and of $\eps_n$ is independent. Combining (\ref{app:THM:clip_aware2:9}), (\ref{app:THM:clip_aware2:1:5}), and (\ref{app:THM:clip_aware2:2:4}), Thm.~\ref{THM:clip_aware2} is proved.


\subsection{%\tcb
{Extended Background}}
\subsubsection{Some Useful Lemmas  from Prior Works}\label{app:prior:lemma}

\begin{lem}\label{app:prior:clipbias}
\textbf{[Clipping bias~\citep{das2023beyond}} Suppose $\phi(\xi)$ (where $\xi$ denotes the source of randomness) is an unbiased estimator of $\phi$, i.e., $\expectation{\xi}{\phi(\xi)}=\phi$. Let $b(\xi)$ denote the clipping bias of $\clip{\phi(\xi)}{c}$, i.e., $b(c)=\left\|\phi - \expectation{\xi}{\clip{\phi(\xi)}{c}} \right\|$.
Then for any $\rho>1$,
\begin{align}
    b(c)\leq \frac{\expectation{\xi}{\left\|\phi(\xi) \right\|^{\rho}}}{c^{\rho-1}}.
\end{align}
\end{lem}


\subsubsection{Differential Privacy}\label{app:prior:rdp}


{
\begin{definition}[$(\eps, \delta)$-DP~\cite{dwork2014algorithmic}]\label{app:epsdeltaDP}
The randomized algorithm $\gA:\chi\rightarrow \calR$ with domain $\chi$ and range $\calR$ satisfies $(\eps, \delta)$-DP iff for any two {\em neighboring} inputs $\train,\train'\in \chi$ that differ by at most one record, and any measurable subset of outputs $\gS \subseteq \calR$,
\begin{align}\label{ch2:eq:eps_delta_dp}
\pr{\gA(\train)\in \gS} \leq e^{\eps}\pr{\gA(\train')\in \gS} + \delta.
\end{align} 
\end{definition}
}

{In (\ref{ch2:eq:eps_delta_dp}), the privacy budget $\eps \in \sR_{+}$ controls the extent to which the output distributions induced by two neighboring inputs may differ. The $\delta\in [0,1]$ quantifies the probability of violating the privacy guarantee. Allowing a larger $\delta\in [0,1]$  improves utility at the cost of a more relaxed (weaker) privacy guarantee. One way to relax the DP guarantee is to use $(\evalpha,\eps)$-Rényi DP (RDP)~\citep{mironov2017renyi}. The $\evalpha>1$ is the order of R\'{e}nyi divergence between distributions $P:=\pr{\gA(\train)}$ and $P':=\pr{\gA(\train')}$, defined as 
\begin{align}
\ren{\evalpha}{P}{P'}:=\frac{1}{1-\evalpha}\log \mathbb{E}_{\rx\sim P'}\left(\frac{P}{P'}\right)^{\evalpha}.
\end{align}
}
{
While the R\'{e}nyi divergence can be defined for $\alpha < 1$, including negative orders, the RDP definition~\cite{mironov2017renyi} is based on $\alpha \geq 1$ and is outlined as follows.
}
{
\begin{definition}[R\'{e}nyi DP (RDP)~\cite{mironov2017renyi}]\label{def:RDP}
The randomized algorithm $\gA:\chi\rightarrow \calR$ with domain $\chi$ and range $\calR$ is $(\alpha,\epsilon)$-RDP iff for any neighboring inputs ${\calD} , {\calD'}\in \chi$,  we have
\begin{align}
 \ren{\evalpha}{\pr{\gA(\train)}}{\pr{\gA(\train')}}\leq \eps.
\end{align}
\end{definition}
}

When accounting for total privacy consumption over an iterative algorithm, RDP offers a smoother composition property than DP. RDP allows the privacy budget to accumulate linearly with the number of training rounds~\citep{mironov2017renyi}. This simplifies the tracking and management of privacy budgets over time. We next recall a lemma from~\citep{mironov2017renyi}. Lemma~\ref{app:prior:rdp:lem} shows how RDP can be converted to DP when needed.  


\begin{lem}\label{app:prior:rdp:lem}
If $\gA$ is an $(\evalpha,\eps_{\text{rdp}})$-RDP algorithm, it also satisfies $\left(\eps, \delta \right)$-DP for any $0<\delta<1$, where
\begin{align}
    \eps= \eps_{\text{rdp}}+\log \frac{\evalpha-1}{\evalpha}-\frac{\log \delta + \log \evalpha}{\evalpha - 1}.
\end{align}
\end{lem}

{
To implement privacy guarantees, we use the sampled Gaussian mechanism (SGM)~\cite{mironov2019r}, formally defined as follows.
}


{
\begin{definition}[SGM~\cite{mironov2019r}]
Consider the algorithm $\gA$ which maps a subset $\calD\subseteq\chi$ to $\mathbb{R}^w$ and has $\ell_2$-sensitivity $c$. The sampled Gaussian mechanism parameterized by the sampling rate $q \in [0,1]$, $c$, and noise multiplier $\sigma>0$ is defined as 
\begin{align}
\gG_{\sigma, c, q}(\calD) := \gA(\{x \;| \; x\in \calD \text{ is sampled with Probability } q \}) + \gN(0,c^2\sigma^2\sI_w),
\end{align}
where each element of $\calD$ is (Poisson) sampled independently at random with probability $q$, and $\gN(0,c^2\sigma^2\sI_w)$ is spherical $w$-dimensional Gaussian noise with per-coordinate variance $c^2\sigma^2$.
\end{definition}
}
{
\begin{lem}[\cite{mironov2019r}]\label{lem:rdpsGM} 
The SGM $\gG_{\sigma,c,q}$ with $c=1$ guarantees $(\alpha, \eps)$-RDP, where $\eps\leq \frac{2\alpha q^2}{\sigma^2}$.
\end{lem}
}



\subsection{Extended Experimental Setup}\label{app:extendedExpSetup}
We conduct our experiments in Python 3.11 using Pytorch leveraging the 4 $\times$ L4 24 GB GPU. 
Below, we provide additional details on the experimental setups used in Sec.~\ref{sec:simulation} to analyze how our time-adaptive DP-FL framework enhances the privacy-utility tradeoff and in Appendix~\ref{app:extendedresults} which extends experiments for further analysis.


\textbf{Details on Datasets.} For our experiments, we use FMNIST, MNIST, Adult Income, and {CIFAR10} datasets. Both FMNIST and MNIST datasets have a training set of 60,000 and a test set of 10,000 28 $\times$ 28 images, associated with 10 labels. The Adult Income dataset consists of 48,842 samples with 14 features and is split into a training set of 32,561 samples and a test set of 16,281 samples. {The CIFAR10 dataset consists of 60,000 32 $\times$ 32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images. }
 
{\textbf{Simulation Parameters.} Throughout our simulations, we use SGD optimizer and momentum equal to 0.9. We also use a CosineAnnealing learning rate scheduler from~\citep{inproceedings} for faster convergence. In Sec.\ref{sec:simulation}, we fix the spending-based sample rate (during spend mode) to $q= 0.9$ and the average clipping norm to $c=250$. We consider the transition from saving round to spending round occurs in the middle of training. I.e., given the total number of rounds $T=25$, we set $T_{\text{group},1}= T_{\text{group},2}, T_{\text{group},3}=13$. The obtained results are averaged over three runs. In Table~\ref{tab:hyperparamstable} we summarize other hyperparameters, including learning rate ($\lr$), number of clients ($N$), batch size ($\bs$), number of local epochs ($L$), and the saving-based sampling rates of clients from privacy groups 1, 2, and 3 ($q_{\text{group},1}, q_{\text{group},2}, q_{\text{group},3}$). 

\begin{table}[htbp]
    \centering
    \caption{Parameters for different datasets, used in Table~\ref{tab:cmptable} and Figure~\ref{fig:privacyparams}. We set $T=25$, $T_{\text{group},1}= T_{\text{group},2}, T_{\text{group},3}=13$, $q=0.9$, and $c=250$. }
    \label{tab:hyperparamstable}
    \begin{tabular}{p{2.5cm}p{2.8cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.7cm}p{2.8cm}}
        \toprule
        \textbf{Dataset} &  {\scriptsize $(\eps_{\text{group},1}, \eps_{\text{group},2}, \eps_{\text{group},3})$} & $\lr$ & $N$ & $\bs$  & $L$ & {\scriptsize $(q_{\text{group},1},q_{\text{group},2},q_{\text{group},3})$} \\
        \midrule
        FMNIST  & $(10,20,30)$ & 0.001  & 100 & 125  & 30 & $(0.5,0.6,0.7)$   \\
        MNIST & $(10,15,20)$   & 0.001  & 100 & 125  & 30 & $(0.5,0.6,0.7)$  \\
        Adult Income & $(10,20,30)$ & 0.01 & 80 & 32 & 5 & $(0.6,0.7,0.8)$   \\
        \bottomrule
    \end{tabular}
\end{table}



\begin{figure}[!htbp]
    \centering
    
    \vspace{5pt}
        \centering
        \includegraphics[width=0.45\textwidth]{images/pdfs/p_4_fmnist_train_loss_epsilons_10_20_30_clients_100_sigma_0.30_clip_250.00_srate_0.90_runs_1_rounds_25_epochs_30final_aid.pdf} 
        \caption{
        {Average Training loss of clients in our time-adaptive DP-FL scheme plotted versus the IDP-FedAvg baseline with FMNIST dataset in training rounds T = 25. We set $(\eps_{\text{group},1}, \eps_{\text{group},2}, \eps_{\text{group},3})=(10,20,30)$ in our scheme and IDP-FedAvg.}}
        \label{fig:trainloss}  
\end{figure}


\subsection{Extended Experimental Results} \label{app:extendedresults}
\textbf{Impact of Training Rounds on Model Convergence.} We extend experiments to more training rounds--- $T\in \{25, 50, 100\}$. For example, in Figure~\ref{fig:morerounds}, we set $T=50$, and plot the global test accuracy vs. communication rounds.
It is evident from Figure~\ref{fig:morerounds} that for our time-adaptive DP-FL framework, as the number of training rounds increases, the upward trend in the accuracy starts slowing down. 
{However, increasing the number of communication rounds does not always improve accuracy. This is because, with more rounds, the privacy budget is distributed across more rounds, resulting in a lower budget per round. Consequently, the increased effect of perturbation can degrade the privacy-utility tradeoff. This is demonstrated in our FMNIST and MNIST experiments, as shown in Table~\ref{tab:clientstable_rounds}, in which we report the final-round test accuracy across different schemes. As shown in the third column of Table~\ref{tab:clientstable_rounds}, when training rounds increase from 25 to 50 and from 50 to 100, FedAvg (the non-DP baseline scheme) consistently demonstrates an upward trend in both MNIST and FMNIST experiments. However, our scheme (fifth column of Table~\ref{tab:clientstable_rounds}) and IDP-FedAvg (fourth column), which operate under limited group privacy budgets $(\eps_{\text{group},1}, \eps_{\text{group},2}, \eps_{\text{group},3})=(10, 20, 30)$, do not exhibit the same consistent improvement. They exhibit an upward trend from 25 to 50 rounds but not consistently from 50 to 100 rounds. Notably, the best performance amongst the DP experiments of Table~\ref{tab:clientstable_rounds}) is achieved by our scheme, reaching $75.63\%$ after $T=100$ rounds for the FMNIST dataset, and $90.78\%$ at $T=50$ rounds for the MNIST dataset.}


\begin{figure}[!ht]
    \centering
    \vspace{5pt}  
        \centering
        \includegraphics[width=0.45\textwidth]{images/pdfs/p_4_fmnist_global_test_acc_epsilons_20_20_20_clients_100_sigma_0.30_clip_250.00_srate_0.80_runs_2_rounds_50_epochs_30final.pdf} 
        \caption{\textbf{Global test accuracy for increasing number of communication rounds.} In this figure, we use the FMNIST dataset, $N=100$ clients, $L=30$ local iterations, $(\eps_{\text{group},1}, \eps_{\text{group},2}, \eps_{\text{group},3})=(20, 20, 20)$, $c=250$, and $q=0.8$.} 
        \label{fig:morerounds}  
\end{figure}

\begin{table}[h!]
\centering
\caption{
{Benchmarking our time-adaptive DP-FL scheme against the baselines in terms of global test accuracy and across varying datasets and number of training rounds (T). We set $(\eps_{\text{group},1}, \eps_{\text{group},2}, \eps_{\text{group},3})=(10,20,30)$ in our scheme and IDP-FedAvg.}}
\small 
\setlength{\tabcolsep}{8pt} 
\renewcommand{\arraystretch}{1.2} 
\begin{tabular}{cccccc}
\toprule
\textbf{Dataset} & \textbf{T} & \makecell[tl]{\textbf{FedAvg} \\ (non-DP)} & \textbf{IDP-FedAvg} & \textbf{Ours}  \\ 
\midrule
\multirow{2}{*}{FMNIST} & 25 & 72.95 & 62.57  & \textbf{66.55} \\

& 50  & 76.00 & 71.80  & \textbf{75.51} \\  
                        & 100 & 80.14 & 71.29  & \textbf{75.63} \\  

                        
\midrule
\multirow{2}{*}{MNIST}  & 25  & 90.23 & 64.53  & \textbf{74.69} \\  

& 50  & 93.42 & 89.57  & \textbf{90.78} \\  
                        & 100 & 95.91 & 87.00  & \textbf{90.15} \\  
\bottomrule
\end{tabular}
\label{tab:clientstable_rounds}
\centering \vspace{-2ex}
\end{table}


\begin{figure}[!ht]
    \centering
    \vspace{5pt} 
        \centering
        \includegraphics[width=0.45\textwidth]{images/pdfs/p_4_mnist_global_test_acc_epsilons_2_5_10_clients_100_sigma_0.30_clip_250.00_srate_0.80_runs_2_rounds_50_epochs_30.pdf} 
        \caption{\textbf{Test accuracy for our time-adaptive DP-FL framework vs. IDP-FedAvg, using stricter privacy budgets $(\eps_{\text{group},1},\eps_{\text{group},2},\eps_{\text{group},3})=(2,5,10)$.} In this figure, we use $N=100$ clients, $T=50$ global rounds, $L=30$ local iterations, $c=250$, and $q=0.8$.} 
        \label{fig:lowprivacybudgets}
\end{figure}


\textbf{Impact of Different Privacy Budgets on Model Utility.} {We present additional experimental results to evaluate the impact of stricter privacy budgets $(\eps_{\text{group},1}, \eps_{\text{group},2}, \eps_{\text{group},3}) = (2,5,10)$ and $(5,5,5)$ on model utility (test accuracy). The results are presented in Figure~\ref{fig:lowprivacybudgets} and Tables~\ref{tab:strictprivacybudgetstable} and~\ref{tab:strictprivacybudgetstable2}. As expected, we observe that lower privacy budgets hamper utility. In particular, in Table~\ref{tab:strictprivacybudgetstable}, we benchmark our scheme against the IDP-FedAvg baseline using two sets of non-uniform privacy budgets, $(10,20,30)$ and $(2,5,10)$, evaluated across two datasets. Our findings suggest that the time-adaptive DP-FL framework yields considerably higher utility than IDP-FedAvg, also under stringent privacy constraints. Similarly, Table~\ref{tab:strictprivacybudgetstable2} focuses on uniform privacy budgets and further confirms that even with a reduction in privacy budgets from $(10,10,10)$ to $(5,5,5)$, our scheme consistently outperforms the corresponding baselines. }


\begin{table}[h!]
\centering
\caption{
{Benchmarking our time-adaptive DP-FL scheme against the baselines in terms of the final-round test accuracy and across varying privacy budgets $(\eps_{\text{group},1}, \eps_{\text{group},2}, \eps_{\text{group},3})$. We set $T=25$ and $L=30$ for $\epsilon = \{10,20,30\}$ and $T=25$ and $L=50$ for $\epsilon = \{2,5,10\}$, $(q_{\text{group},1},q_{\text{group},2},q_{\text{group},3})=(0.3,0.5,0.7)$}.}
\small
\setlength{\tabcolsep}{10pt} 
\renewcommand{\arraystretch}{1.2} 
\begin{tabular}{cccc}
\toprule
\textbf{Dataset} & \textbf{Privacy Budgets} &    \makecell[tl]{\textbf{IDP-FedAvg}\\ Non-uniform} &   \makecell[tl]{\textbf{Ours}\\ Non-uniform} \\ 
\midrule
FMNIST & $(10, 20, 30)$ & 62.57  &  \textbf{66.55} \\  
FMNIST & $(2, 5, 10)$ &  60.99  & \textbf{65.75} \\  
\hline
MNIST & $(10, 20, 30)$ & 64.53 &  \textbf{77.38} \\  
MNIST & $(2, 5, 10)$ &  63.35 &  \textbf{66.50} \\  
\bottomrule
\end{tabular}
\label{tab:strictprivacybudgetstable}
\vspace{-2ex} 
\end{table}


\begin{table}[h!]
\centering
\caption{
{Benchmarking our time-adaptive DP-FL scheme against the baselines in terms of the final-round test accuracy and across varying uniform privacy budgets $\eps_{\text{group},1}= \eps_{\text{group},2}= \eps_{\text{group},3}$. We set $T=25$ and $L=30$.}}
\small 
\setlength{\tabcolsep}{10pt} 
\renewcommand{\arraystretch}{1.2} 
\begin{tabular}{cccccc}
\toprule
\textbf{Dataset} & \makecell[tl]{\textbf{Privacy} \\ {Budgets}} & \makecell[tl]{\textbf{Adaptive Clipping} \\ $(\beta_{\text{s}},\lr_{\text{s}})=(0, 1.0)$} & \textbf{DP-FedAvg} & \makecell[tl]{\textbf{Adaptive Clipping} \\ optimal $(\beta_{\text{s}},\lr_{\text{s}})$} & \textbf{Ours} \\ 
\midrule
FMNIST & $(10,10, 10)$ & 60.23 & 64.8 & 67.64 & \textbf{67.90} \\  
FMNIST & $(5,5, 5)$ & 52.39 & 51.06 & 52.39 & \textbf{60.79} \\  
\hline
MNIST & $(10, 10, 10)$ & 65.59 & 76.79 & 78.04 & \textbf{80.2} \\  
MNIST & $(5, 5, 5)$ & 55.48 & 61.45 & 55.48 & \textbf{69.07} \\  
\bottomrule
\end{tabular}
\label{tab:strictprivacybudgetstable2}
\vspace{-2ex}
\end{table}

\textbf{Additional Baseline.} 
{We benchmark our scheme against the adaptive clipping method~\cite{andrew2021differentially}, with pseudocode provided in Algorithm~\ref{alg:quantile}. We present results in the third and fifth columns of Table~\ref{tab:strictprivacybudgetstable2}. This baseline is designed for uniform privacy budgets and is parameterized by the server-side learning rate $\lr_{\text{s}}$ and momentum parameter $\beta_{\text{s}}$, which are not privacy-specific. To ensure a fair comparison with our scheme and other baselines in our paper, we set these parameters to $\lr_{\text{s}}=1.0$ and $\beta_{\text{s}}=0.0$. In column 3, we use these default values, while in column 5, we select the optimal values from a set of possible choices. As shown in the table, our scheme consistently outperforms adaptive clipping, even when the baseline’s parameters are optimally tuned. 
}






\textbf{Effect of Number of Clients on Model Utility.} We experiment with different numbers of clients---$N\in\{30, 60, 75\}$---for the MNIST dataset to validate the applicability of our time-adaptive DP-FL framework across various scenarios. Additionally, we also perform experiments to analyze if our framework outperforms the baselines, in terms of the utility of the trained model. Our results in Table~\ref{tab:clientstable} indicate that for all the different numbers of clients that we consider, our framework remarkably surpasses the utility of the baseline. 



\begin{table}[h!]
\caption{Comparison of model utility on a varying number of clients and comparison of model utility for time-adaptive DP-FL with baselines for a varying number of clients}
\centering
\small 
\setlength{\tabcolsep}{10pt} 
\renewcommand{\arraystretch}{1.2}  
\begin{tabular}{cccccc}
\toprule
\textbf{Number of clients} & \makecell[tl]{\textbf{SETUP} \\ Privacy Budgets} &  \makecell[tl]{\textbf{IDP-FedAvg} \\ Non-uniform} & \makecell[tl]{\textbf{Ours}\\ Non-uniform}  \\ 
\midrule
30& $(10, 20, 30)$  & 72.35  & \textbf{73.34}  \\  
\midrule
60 & $(10, 20, 30)$    & 78.69   & \textbf{83.83} \\
\midrule
75 & $(10, 20, 30)$  &  70.93    & \textbf{77.53}\\ 
\bottomrule
\end{tabular}
\label{tab:clientstable}
\centering \vspace{-2ex}
\end{table}

\textbf{The Choice of Hyperparameters.} %\tcb
{We evaluate our DP-FL framework with different choices of hyperparameters---different saving-based sampling rates ($q_{\text{group},1},q_{\text{group},2},q_{\text{group},3}$) and different saving-to-spending transition rounds  ($T_{\text{group},1},T_{\text{group},2},T_{\text{group},3}$). The final-round test accuracies for different choices of $(q_{\text{group},1},q_{\text{group},2},q_{\text{group},3})$, and across both MNIST and FMNIST datasets, are presented in Table~\ref{tab:saving_sampling_ratestable}. In this table, in Column 3 we set these rates as (0.5,0.6,0.7), in Column 4 as $(0.3,0.5,0.7)$, and in Column 5 as $(0.6,0.6,0.6)$. As shown in the table, our scheme, which uses lower sampling rates during saving---e.g., for all $i\in [3]$, $q_{\text{group},1}$ is smaller than $q=0.9$ in this table---outperforms the IDP-FedAvg baseline (Column 6) that uses a uniform sampling rate $q$ over time. This table also shows that our method is relatively robust against the clients' choice of saving-based sampling rates, consistently achieving performance between that of IDP-FedAvg and the ideal case of FedAvg without DP (Column 2).}


\begin{table}[h!]
\centering
\caption{
{Evaluating the impact of saving-based sampling rates of different privacy groups, ($q_{\text{group},1},q_{\text{group},2},q_{\text{group},3}$), on our time-adaptive DP-FL scheme in comparison with the baseline. We set $(\eps_{\text{group},1},\eps_{\text{group},2},\eps_{\text{group},3}) = (10,20,30)$, $T=25, L=30$ and $N=100$, $T_{\text{group},1}=T_{\text{group},2}=T_{\text{group},3}=13$, $q=0.9$, $c=250$, $\lr=0.001$, and $B=125$.}}
\small 
\setlength{\tabcolsep}{10pt} 
\renewcommand{\arraystretch}{1.2}  
\begin{tabular}{cccccc}
\toprule
{ \textbf{DATASET}}  &  \makecell[t]{{\scriptsize\textbf{FedAvg}} \\ {\scriptsize non-DP}} &\makecell[t]{{\scriptsize\textbf{Ours}} \\ {\scriptsize $(0.5,0.6,0.7)$}} & \makecell[t]{{\scriptsize\textbf{Ours}} \\ {\scriptsize $(0.3,0.5,0.7)$}} & \makecell[t]{{\scriptsize\textbf{Ours}} \\ {\scriptsize $(0.6,0.6,0.6)$}}  & {\scriptsize \textbf{IDP-FedAvg}}\\ 
\midrule
MNIST & 90.23 & \textbf{72.72} & \textbf{77.39} & \textbf{71.6} & 64.53 \\  
\midrule
FMNIST & 72.95 & \textbf{70.57}  & \textbf{66.55}  & \textbf{67.75} & 62.57   \\  
\midrule
\end{tabular}
\label{tab:saving_sampling_ratestable}
\end{table}

{The final-round test accuracies for different choices of saving-to-spending transition rounds $(T_{\text{group},1},T_{\text{group},2},T_{\text{group},3})$, for both MNIST and FMNIST datasets, are presented in Table~\ref{tab:privacy_spending_roundtable}. We set the total number of rounds as $T=25$. In this table, in Column 3 we set the transition rounds as (7,7,7), in Column 4 as $(7,13,19)$, in Column 5 as $(19,13,7)$, and in Column 6 as $(19,19,19)$. As shown in the table, our scheme, which transitions from saving to spend mode sometime between the first and final round---i.e., for all $i\in [3]$, $1<T_{\text{group},1}<25$---outperforms the IDP-FedAvg baseline (Column 7) which can be viewed as a special case of ours with transition rounds set to $(1,1,1)$. This table shows the robustness of our method to the client's choice of transition rounds, showing less than a $2\%$ variation in accuracy across different choices  while consistently achieving performance between that of IDP-FedAvg and the ideal-case of FedAvg without DP (Column 2).}


\begin{table}[h!]
\centering
\caption{
{Evaluating the impact of saving-to-spending transition rounds of different privacy groups, ($T_{\text{group},1}, T_{\text{group},2}, T_{\text{group},3}$), on our time-adaptive DP-FL scheme in comparison with the baseline. We set $(\eps_{\text{group},1},\eps_{\text{group},2},\eps_{\text{group},3})=(10,20,30)$, $T=25, L=30$, $N=100$, $(q_{\text{group},1},q_{\text{group},2},q_{\text{group},3})=(0.3,0.5,0.7)$, $q=0.9$, $c=250$, $\lr=0.001$, and $B=125$.}}
\small
\setlength{\tabcolsep}{10pt} 
\renewcommand{\arraystretch}{1.2}  
\begin{tabular}{ccccccc}
\toprule
{ \textbf{DATASET}} & \makecell[t]{{\scriptsize\textbf{FedAvg}} \\ {\scriptsize non-DP}} &  \makecell[t]{{\scriptsize\textbf{Ours}} \\ {\scriptsize $(7,7,7)$}} & \makecell[t]{{\scriptsize\textbf{Ours}} \\ {\scriptsize $(7,13,19)$}} & \makecell[t]{{\scriptsize\textbf{Ours}} \\ {\scriptsize $(19,13,7)$}} & \makecell[t]{{\scriptsize\textbf{Ours}} \\ {\scriptsize $(19,19,19)$}} & {\scriptsize \textbf{IDP-FedAvg}}\\ 
\midrule
MNIST & 90.23 & \textbf{74.38}  & \textbf{74.69}  & \textbf{72.24} & \textbf{73.88} & 64.53  \\  
\midrule
FMNIST & 72.95 & \textbf{66.72}  & \textbf{65.29}  & \textbf{65.34} & \textbf{67.5} & 62.57  \\  
\midrule
\end{tabular}
\label{tab:privacy_spending_roundtable}
\end{table}


\textbf{Experiments on The CIFAR10 Dataset.}
{We run experiments on the CIFAR10 dataset. The  
final-round test accuracies of our time-adaptive DP-FL framework in comparison with the FedAvg (non-DP) and IDP-FedAvg baselines
are presented in Table~\ref{tab:cifar10}. The results suggest that our proposed approach surpasses IDP-FedAvg, by lowering the gap to the ideal case of FedAvg by about $9\%$. We note that the test accuracies reported for all schemes in this table are relatively lower than those we reported earlier in this paper for the MNIST, FMNIST, and Adult Income datasets. We hypothesize that this happens due to the increased complexity of the CIFAR10 dataset, particularly when distributed in a non-iid manner in an FL setting with $N=100$ clients.   
}

\begin{table}[h!]
\centering
\caption{
{Benchmarking our time-adaptive DP-FL framework against the baselines using the CIFAR10 dataset. We set $(\eps_{\text{group},1},\eps_{\text{group},2},\eps_{\text{group},3})=(100,50,25)$, $T=50, L=30$, $N=100$, $(q_{\text{group},1},q_{\text{group},2},q_{\text{group},3})=(0.5,0.5,0.5)$, $q=0.9$, $c=250$, $\lr=0.001$, and $B=125$.}}
\begin{tabular}{cccc}
\toprule
\textbf{DATASET}  &  \textbf{FedAvg} & \textbf{IDP-FedAvg} & \textbf{Ours} \\
\midrule 
CIFAR10 & 44.42 & 34.97 & 35.41 \\
\midrule
\end{tabular}
\label{tab:cifar10}
\end{table}