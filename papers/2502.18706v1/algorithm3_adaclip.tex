\begin{minipage}{0.47\textwidth} 
\include{algorithm1_adaclip}
\end{minipage}%
\hspace{1em} 
\begin{minipage}{0.50\textwidth}  %
  \raggedright  % Left-align
 \begin{algorithm}[H]
   \scriptsize
\caption{Our Time-adaptive DP-FL Framework, integrated with Adaptive Clipping}
\textbf{Inputs:} No. clients $N$, No. global rounds $T$, No. local iterations $L$, local privacy budgets $\eps_n$, sampling rate $q$, average clip norm $c$, modes $M_n^t \in\{0,1\}$, sampling rates for saving mode $q_n$, loss functions $\loss_n$, datasets $\train_n$, learning rate $\lr$, batch size $\bs$, probability of violating $\delta$, $\gamma$ quantile, clip-related learning rate $\lr_\text{b}$ \\ 
\label{alg:tidpfl:train}
\begin{algorithmic}[1]
\State \textbf{Initialize} global model $\model^0$, $c^1 = c$
\State \textbf{Initialize} $\eps_n^0 = \eps_n$  and $\bar{\eps}_{\text{rdp},n}^0=0$ for all $n\in [N]$
\For{each global round $t \in [T]$} 
\State \tcb{$q^t, \noisem^t, \{q_n^t, c_n^t, \noisem_n^t, \eps_n^{t}, \bar{\eps}_{\text{rdp},n}^{t}\}_{n\in [N]}$\ $=$\texttt{SetParams}$\left(c^t, q,  \{q_n, M_n^t, \eps_n^{t-1}, \bar{\eps}_{\text{rdp},n}^{t-1}\}_{n\in [N]}, T, \delta, t \right)$}
\State $\gC^t \gets$ Sample clients with probability $\{q_n^t\}$.
\For{each client $n\in [N]$ in parallel}
\State $(b_n^t,\tilde{\Delta}\model_n^t)$ =  
\texttt{ClientUpdate}$\left(t, n,\model^{t-1}, c_n^t, \noisem_n^t, c^t\right)$.
\State
\EndFor
\State $\tilde{\Delta}\model^t = \sum_{n\in \gC^t} \tilde{\Delta}\model_n^t +  \sum_{n\in  [N]\backslash \gC^t} \gN\left(0,\frac{c^2(\noisem^t)^2}{N}\sI\right)$
\State Update $\model^{t} = \model^{t-1} + \frac{\tilde{\Delta}\model^t}{q^tN}$
\State \tcb{$c^{t+1}$=\texttt{SetClippig}$\left(\{b_n^t\}_{n\in \gC^t}, \noisem_{\text{b}},q, \gamma, \lr_{\text{b}}, c^t\right)$}
\EndFor
\Statex
\end{algorithmic}
\textbf{Def} \texttt{ClientUpdate}$\left(t, n,\model^{t}, c_n^t, \noisem_n^t, c^t\right)$
\begin{algorithmic}[1]
\State \textbf{Initialize} local model $\model_n^{t,0}=\model^t$
\For{local iteration $l \in [l]$}
\State $\{\batch_i\}_{i=1}^{|\train_n|/B} \gets$ Split $\train_n$ to size $B$ batches
\For{each batch $\batch_i$}
\State $\model_n^{t,l} = \model_n^{t,l-1}-\frac{\lr \sum_{(\rvx,y)\in \batch_i} \nabla\loss_n\left(\model_n^{t,l-1};(\rvx,y)\right)}{\bs}$
\EndFor
\EndFor
\State Compute $\Delta\model_n^t = \model_n^{t,L} - \model_n^{t,0}$
\State \tcb{Compute $b = \gI_{\left\|\Delta\model_n^t \right\|\leq c^t}$}
\State Clip $\tilde{\Delta}\model_n^{t} = \Delta\model_n^t\min\left(1,\frac{c_n^t}{\left\|\Delta\model_n^{t}\right\|_2}\right)$  
\State Add noise $\tilde{\Delta}\model_n^t \gets \tilde{\Delta}\model_n^t + \gN\left(0,\frac{(c_n^t)^2(\noisem_n^t)^2}{N}\sI\right)$
\State \tcb{Return $b, \tilde{\Delta}\model_n^{t}$} 
\Statex
\end{algorithmic}
\textbf{Def} \texttt{SetParams}$\left(c, q,  \{q_n, M_n^t, \eps_n^{t-1}, \bar{\eps}_{\text{rdp},n}^{t-1}\}_{n\in [N]}, T, \delta, t \right)$
\begin{algorithmic}[1]
%\State \textbf{Initialize} $\eps_n^0 = \eps_n$  and $\bar{\eps}_{\text{rdp},n}^0=0$ for all $n\in [N]$
%\For{each global round $t\in [T]$}
\For{each client $n \in [N]$}
\State  $\bar{\noisem}_n^t=$\texttt{GetNoise}$\left(\eps_n^{t-1},\delta, q, T-t\right)$
\State \tcb{$\noisem_n^t = \left(\frac{1}{(\bar{\noisem}_n^t)^{2}} - \frac{1}{(2\noisem_{\text{b}})^2}\right)^{-1/2}$}
\State \textbf{If} $M_n^t=0$, \textbf{then} $q_n^t = q_n$, \textbf{Else}, $q_n^t = q$.
\State $\reps{n}^t=$\texttt{Compute\_rdp}$\left(q_n^t,\bar{\noisem}_n^t, \alpha\right)$
\State $\bar{\eps}_{\text{rdp},n}^t = \bar{\eps}_{\text{rdp},n}^{t-1} +  \reps{n}^t$
\State $\eps_n^t=\eps_n-$\texttt{get\_privacy\_spent}$\left(\alpha, \bar{\eps}_{\text{rdp},n}^t,\delta\right)$
\EndFor
\State Compute $\noisem^t \gets \left(\frac{1}{N}\sum_{n\in [N]}\frac{1}{\noisem_n^t}\right)^{-1}$
\For{each client $n \in [N]$}
\State Set local clip norm $c_n^t=\frac{c\noisem^t}{\noisem_n^t}$
\EndFor
\State $q^t = \frac{1}{N} \sum_{n=1}^N q_n^t$
%\EndFor
\State \tcb{Return $q^t, \noisem^t, \{q_n^t, c_n^t, \noisem_n^t, \eps_n^{t}, \bar{\eps}_{\text{rdp},n}^{t}\}_{n\in [N]}$}
\Statex
\end{algorithmic}
\tcb{
\textbf{Def} \texttt{SetClippig}$\left(\{b_n^t\}_{n\in \gC^t}, \noisem_{\text{b}},q, \gamma, \lr_{\text{b}}, c^t\right)$}
\begin{algorithmic}[1]
\State \tcb{Aggregate $\tilde{b}^t = \sum_{n\in \gC^t} b_n^t$}
\State \tcb{Add noise $\tilde{b}^t \gets \tilde{b}^t + \gN(0,\noisem_{\text{b}}^2\sI)$ }
\State \tcb{Average $\tilde{b}^t \gets \frac{1}{qN}\tilde{b}^t $}
\State \tcb{Update $c^{t+1}=c^t \exp \left(-\lr_{\text{b}}
(\tilde{b}^t-\gamma)\right)$}
\State \tcb{Return $c^{t+1}$}
\end{algorithmic}
\end{algorithm}
\end{minipage}