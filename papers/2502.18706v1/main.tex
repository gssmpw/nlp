
\documentclass{article} 
\usepackage{iclr2024_conference,times}

\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{array}
\usepackage{float}
\usepackage{makecell}
\usepackage{threeparttable}
\usepackage{enumitem}

\usepackage{cleveref}

%\input{macros}
% \usepackage[textsize=tiny]{todonotes}
% % COMMENTS
% \ifdraft
% \newcommand{\mynote}[1]{\textcolor{red}{[note: #1]}}
% \newcommand{\franzi}[1]{\textcolor{purple}{[Franzi: #1]}}

% \else
% \newcommand{\franzi}[1]{}

\newif\ifdraft % Defining the draft mode
\drafttrue     % Uncomment this to enable draft mode
%\draftfalse   % Uncomment this to disable draft mode

\usepackage[textsize=tiny]{todonotes}
% COMMENTS
\ifdraft
    \newcommand{\mynote}[1]{\textcolor{red}{[note: #1]}}
    \newcommand{\franzi}[1]{\textcolor{purple}{[Franzi: #1]}}
\else
    \newcommand{\mynote}[1]{}
    \newcommand{\franzi}[1]{}
\fi


\title{Differentially Private Federated Learning \\ with Time-Adaptive Privacy Spending}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\iclrfinalcopy
\author{Shahrzad Kiani\textsuperscript{1}\thanks{%Emails: Shahrzad Kiani \texttt{shahrzad.kianidehkordi@mail.utoronto.ca}, Nupur Kulkarni \texttt{nuku00001@stud.uni-saarland.de}, Adam Dziedzic \texttt{adam.dziedzic@cispa.de}, Stark Draper \texttt{stark.draper@utoronto.ca}, and Franziska Boenisch \texttt{boenisch@cispa.de}. 
correspondence to shahrzad.kianidehkordi@mail.utoronto.ca. Part of the work was done while Shahrzad Kiani visited CISPA.}, Nupur Kulkarni\textsuperscript{2}, Adam Dziedzic\textsuperscript{2}, Stark Draper\textsuperscript{1}, \& Franziska Boenisch\textsuperscript{2} %Antiquus S.~Hippocampus, Natalia Cerebro \& Amelie P. Amygdale \thanks{ Use footnote for providing further information about author (webpage, alternative address)---\emph{not} for acknowledging funding agencies.  Funding acknowledgements go at the end of the paper.} 
\\
\textsuperscript{1} Department of Electrical and Computer Engineering, University of Toronto \\
\textsuperscript{2} CISPA Helmholtz Center for Information Security 
%Department of Computer Science\\
%Cranberry-Lemon University\\
%Pittsburgh, PA 15213, USA 
%\\
%\textsuperscript{3}\texttt{\{shahrzad.kianidehkordi@mail, stark.draper@\}.utoronto.ca}
%\\
%\textsuperscript{4}\texttt{\{ adam.dziedzic, boenisch\}.cispa.de}
%\texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
%\And
%Ji Q. Ren \& Yevgeny LeNet \\
%Department of Computational Neuroscience \\
%University of the Witwatersrand \\
%Joburg, South Africa \\
%\texttt{\{robot,net\}@wits.ac.za} \\
%\AND
%Coauthor \\
%Affiliation \\
%Address \\
%\texttt{email}
%
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\begin{document}

\maketitle

\begin{abstract}


Federated learning (FL) with differential privacy (DP) provides a framework for collaborative machine learning, enabling clients to train a shared model while adhering to strict privacy constraints.
The framework allows each client to have an individual privacy guarantee, e.g., by adding different amounts of noise to each client's model updates. One underlying assumption is that all clients spend their privacy budgets uniformly over time (learning rounds). However, it has been shown in the literature that learning in early rounds typically focuses on more coarse-grained features that can be learned at lower signal-to-noise ratios while later rounds learn fine-grained features that benefit from higher signal-to-noise ratios.
Building on this intuition, we propose a {\em time-adaptive} DP-FL framework that expends the privacy budget non-uniformly across both time and clients. 
Our framework enables each client to save privacy budget in early rounds so as to be able to spend more in later rounds when additional accuracy is beneficial in learning more fine-grained features. 
We theoretically prove utility improvements in the case that clients with stricter privacy budgets spend budgets unevenly across rounds, compared to clients with more relaxed budgets, who have sufficient budgets to distribute their spend more evenly. Our practical experiments on standard benchmark datasets support our theoretical results and show that, in practice, our algorithms improve the privacy-utility trade-offs compared to baseline schemes.


\end{abstract}

\input{1_introduction}
\input{2_background}
\input{3_problem}
\input{4_theory}
\input{5_simulation}
\input{6_conclusion_futurework}


\subsubsection*{Acknowledgments}
We would like to acknowledge our sponsors. This work was supported in part by a Discovery Research Grant from the Natural Sciences and Engineering Research Council of Canada (NSERC), by an NSERC Alexander Graham Bell Canada Graduate Scholarship-Doctoral (CGS D3), by a DiDi graduate award, and by the Mitacs Globalink research award.

\bibliography{references}
\bibliographystyle{iclr2024_conference}
\newpage
\appendix
\input{0_appendix}

\end{document}
