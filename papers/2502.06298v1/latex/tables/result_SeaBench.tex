\begin{table*}[!ht]
    \centering
    \small
    \setlength\tabcolsep{5pt}
    \begin{tabular}{lllllllllllllll}
        \toprule
         \multirow{2}{*}{model}& \multicolumn{4}{c}{SeaBench} & & \multicolumn{4}{c}{MT-bench-SEA} & & \multicolumn{4}{c}{MT-bench-SEA-human}\\ 
         \cmidrule{2-5} \cmidrule{7-10} \cmidrule{12-15}
         & id & th & vi & avg & & id & th & vi & avg & & id & th & vi & avg \\ 
        \midrule
        gemma-2-9b-it & 8.30 & 7.37 & 7.78 & 7.82 & & 7.68 & 7.29 & 7.63 & 7.53 & & 7.46 & 7.38 & 7.46 & 7.43 \\ 
        SeaLLMs-v3-7B-Chat & 6.77 & 6.62 & 6.32 & 6.57 & & 6.61 & 5.84 & 6.57 & 6.34 & & 6.46 & 5.73 & 6.58 & 6.26 \\ 
        llama3-8b-cpt-sealionv2-instruct & 6.22 & 6.06 & 6.14 & 6.14 & & 5.52 & 4.96 & 5.04 & 5.17 & & 5.31 & 5.23 & 5.24 & 5.26 \\ 
        Qwen2-7B-Instruct & 6.42 & 5.68 & 6.19 & 6.09 & & 6.61 & 6.04 & 6.50 & 6.38 & & 6.63 & 6.03 & 6.73 & 6.46 \\ 
        glm-4-9b-chat & 6.33 & 5.06 & 6.88 & 6.09 & & 5.84 & 4.94 & 6.36 & 5.71 & & 6.07 & 5.38 & 6.36 & 5.94 \\ 
        Meta-Llama-3.1-8B-Instruct & 6.76 & 5.05 & 5.62 & 5.81 & & 5.89 & 4.93 & 5.69 & 5.51 & & 5.94 & 5.18 & 5.58 & 5.56 \\ 
        Sailor-7B-Chat & 4.70 & 3.98 & 4.45 & 4.37 & & 4.65 & 3.45 & 4.49 & 4.20 & & 4.89 & 3.41 & 4.54 & 4.28 \\ 
        aya-23-8B & 5.37 & 2.25 & 5.26 & 4.29 & & 5.39 & 2.18 & 5.06 & 4.21 & & 5.11 & 2.23 & 5.11 & 4.15 \\ 
        Mistral-7B-Instruct-v0.3 & 4.61 & 2.73 & 4.23 & 3.85 & & 4.59 & 3.11 & 4.43 & 4.04 & & 4.88 & 3.24 & 4.28 & 4.13 \\ 
        \bottomrule
    \end{tabular}
    \caption{Performances on SeaBench, MT-bench-SEA and  MT-bench-SEA-human. The models are sorted based on the average performance on SeaBench.}
    \label{tab:SeaBench_results}
\end{table*}


