\section{Mathematical Hypothesis}
\label{sec:hypothesis}
As previously mentioned, SIRR is inherently an ill-posed problem. To this end, researchers have proposed various hypotheses.

\subsection{Linear Hypothesis}
The linear hypothesis posits that a captured image $I$ is perceived as the superimposition of a transmission layer and a reflection layer, a concept inspired by the human visual system~\cite{levin2002learning}.

Early studies, mainly non-learning approaches~\cite{li2014single, levin2007user} and early deep learning works~\cite{zhang2018single, fan2017generic, hu2021trash}, adopted this hypothesis, assuming that an image containing reflections can be mathematically modeled as the sum of the transmission and reflection layers, i.e., $I = T + R$. However, this assumption is heuristic; the reflection and transmission layers are likely to degrade due to diffusion during the superposition process~\cite{hu2023single, wan2020reflection}, and it may not hold true in cases involving intense and bright reflections~\cite{li2023two}.

Furthermore, researchers~\cite{wan2018crrn, yang2018seeing, li2020single} introduced blending scalars to build a more nuanced model, $I = \alpha T + \beta R$, where $\alpha$ and $\beta$ represent scaling factors for the transmission and reflection layers, respectively. For instance, Li et al.~\cite{li2020single} assumes $I = \alpha T + R$, while Yang et al.~\cite{yang2018seeing} assumes that $I = \alpha T + (1-\alpha)R$, and Wan et al.~\cite{wan2018crrn} treats $\alpha$ and $\beta$ as mixing coefficients balancing the transmission and reflection layers. 

Despite these improvements, blending two images using constant values does not accurately simulate the complex real-world reflection process. The formation of the reflected image depends on factors such as the relative position of the camera to the image plane and the lighting conditions~\cite{wen2019single}.

\subsection{Non-linear Hypothesis}
To address the complex process of image reflection, some studies have leveraged the full potential of deep learning to efficiently incorporate prior information mined from labeled training data into network structures. These studies also introduced non-linearity to develop more sophisticated models that better approximate the physical mechanisms involved in image formation~\cite{dong2021location, li2020single, wei2019single}. One such approach utilizes alpha matting~\cite{dong2021location} to model the blending process. In this formulation, an alpha blending mask $W$ is introduced to represent the relative contribution of the transmission layer at each pixel. The synthesis process is then represented as: $I = W \circ T + R$, where $\circ$ denotes the element-wise multiplication. Similarly, Wen et al.~\cite{wen2019single} approximates the reflection mechanisms as: $I = W \circ T + (1 - W) \circ R$. This approach enables a more flexible and accurate separation of the scene and reflection layers, particularly in cases involving complex light interactions or semi-transparent surfaces. 

Additionally, Zheng et al.~\cite{zheng2021single} proposed the model $I = \Omega T + \Phi R$, where $\Omega$ and $\Phi$ represent refractive and reflective amplitude coefficient maps, respectively. Likewise, Wan et al.~\cite{wan2020reflection} considered degradation in both $T$ and $R$, expressing the formation of a mixed image as $I = g(T) + f(R)$, where $g(\cdot)$ and $f(\cdot)$ represent the various degradation processes learned by the network structure. More recently, Hu and Guo~\cite{hu2023single} deliver a more general formulation as: $I = T + R + \Phi(T, R)$, where $\Phi(T, R)$ represents the residue in the reconstruction process, which may arise due to factors such as attenuation, overexposure, etc.
