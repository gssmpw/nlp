The \ours{} reward satisfies the two desiderata for a sequence-matching reward function (Sec.~\ref{sec:desiderata}), overcoming the failure modes of frame-level matching algorithms. In the following analysis, we define a subgoal $\od_{j}$ to be \textit{occupied} if $P_{t, j} \approx 1$.

\begin{proposition}[\textbf{\orca{} enforces subgoal ordering}]
Let $\xi^{-}$ be a trajectory that is out of order; specifically, there exists a subgoal $\od_{j}$ such that $\od_{j}$ is occupied at time $t$ but $\od_{j-1}$ is not yet occupied. Let $\xi^{+}$ be a trajectory that is identical to $\xi^{-}$, except that it occupies $\od_{j-1}$ before time $t$. Then, $\mathcal{R}_{\text{ORCA}}(o^{+}_t, \xid) > \mathcal{R}_{\text{ORCA}}(o^{-}_t, \xid)$.
 
 \label{prop:ordering}
\end{proposition}
 % \ours{} assigns higher reward to a trajectory that completes subgoals in the correct order than a trajectory that completes them in the incorrect order.  

By (\ref{eq:coverage_recursive}), at a timestep, the ordered coverage of the current subgoal can be no greater than the coverage of the previous subgoal. Since $\xi^{+}$ occupies $\od_{j-1}$ before $t$ and $\xi^{-}$ does not, $\xi^{+}$ achieves a greater coverage of the subgoal $\od_{j-1}$ than $\xi^{-}$. The trajectories are otherwise equivalent, so $\xi^{+}$ must achieve a higher \orca{} reward at time $t$. A formal proof is given in Appendix~\ref{proof:ordering}. This overcomes OT's failure mode (Sec.~\ref{subsec:ot_fail}).

\begin{proposition}[\textbf{\ours{} enforces subgoal coverage}]
Let $\xi^{-}$ be a trajectory that occupies $\od_{j-1}$ at time $t-1$ and continues to occupy $\od_{j-1}$ at time $t$, instead of progressing towards $\od_{j}$. Let $\xi^{+}$ be an identical trajectory that progresses towards $\od_{j}$ at $t$, and assume that neither trajectory has been closer to $\od_{j}$ before. $\mathcal{R}_{ORCA}(o^{+}_t, \xid) > \mathcal{R}_{ORCA}(o^{-}_t, \xid)$.
\label{prop:progress}
\end{proposition}
Both trajectories achieve the same coverage of subgoals up to $\od_{j-1}$. Since $\xi^{+}$ moves closer to the next subgoal $\od_{j}$ than $\xi^{-}$, it achieves a higher probability of occupying $\od_{j}$ and gets higher coverage of $\od_{j}$. The trajectories are otherwise equivalent, so $\xi^{+}$ must achieve a higher \orca{} reward at time $t$. A formal proof is given in Appendix~\ref{proof:progress}. This overcomes the failure modes of DTW and TemporalOT in Sec.~\ref{subsec:dtw_fail} and~\ref{subsec:tot_fail}. Appendix~\ref{app:toy_orca_success} visualizes how the \ours{} reward avoids the example failures of these frame-level matching algorithms. 