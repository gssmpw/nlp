
\subsection{How well does \orca{} perform under varying levels of temporal misalignment?\label{sec:exp_random_mismatched}}
\textbf{Setup.} 
We identify two types of temporal misalignment: either the demonstration contains pauses and is slower, or the demonstration accelerates through a segment and is faster.
For each misalignment type, we randomly perturb the original demonstrations of three Meta-world tasks (\textit{Door-open}, \textit{Window-open}, \textit{Lever-pull}), generating 3 demonstrations per task per misalignment level.
The misalignment level controls the intensity of the perturbation, i.e., how varied and nonlinear speed changes are. 
% For each misalignment level, we generate 3 altered demonstrations, where we evenly split the original demonstration into 5 segments, randomly selects the segments to alter, and randomly change their speed. 
See appendix~\ref{app:random_mismatch_setup} for details.
% We compare \orca{} against the most competitive distribution-matching approach: \tot{}.

\textbf{Analysis.}
In Fig.~\ref{fig:meta_random_mismatched}, \orca{} consistently maintains a higher cumulative return compared to \tot{} as the demonstrations become more misaligned. 
When the demonstrations are sped up, because \tot{} encourages agents to spend an equal amount of time at each subgoal (as discussed in Sec~\ref{exp:progress}), \tot{} agents often cannot finish the task in time, and their performance worsens as the misalignment level increases. 
Meanwhile, when the demonstrations are slowed down and longer than the learner trajectory, \tot{}'s coupling matrix often matches one learner frame to multiple subgoals. 
Then, the \tot{} reward function effectively forces the agent to reach multiple subgoals simultaneously, which creates a difficult optimization problem. 
\orca{} has a more varied performance given slower, misaligned demonstrations. 
When \orca{} agents fail, they are able to successfully follow the general motions of the video demonstration, but they have missed details (e.g., aligning the gripper with the object of interest). 
We hypothesize that this behavior is caused by the visual frame-level distance metric, which pays more attention to the general robot arm motions than details, allowing most subgoals to achieve relatively good coverage. 
% slow 1: opened all door quickly. opened the window: got the general movement, but miss the detail. Lever-pull: goes to the end but miss the detail.
% slow 3: door: one missing detail, window: 2 out of 3 missing details. lever-pull: 2 runs just did random behavior (1 stay hover near origin). didn't optimize. one succeeded but miss the fine-grained detail. 
% slow 5: door: 2 degenerates, 1 succeed window: one stay at the original lever-pull: 2 runs did random behavior (1 stay. didn't optimize. one succeeded but a bit slower. 
