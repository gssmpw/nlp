%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\PassOptionsToPackage{sort&compress}{natbib}

\input{miscs/imports}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{miscs/math_commands}
\input{miscs/macros}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}
\usepackage[accepted]{icml2025}

% For table of content in the appendix
\usepackage[toc,page,header]{appendix}
\usepackage{minitoc}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2025}

% \input{miscs/authors_list}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Imitation Learning from a Single Temporally Misaligned Video}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}
\doparttoc % Tell to minitoc to generate a toc for the parts
\faketableofcontents % Run a fake tableofcontents command for the partocs

\twocolumn[
\icmltitle{Imitation Learning from a Single Temporally Misaligned Video}

% \yw{Who should be audience: VLM people? RL people (they might not buy in the motivation. there isn't a lot of other papers in RL domain.)? In the middle: VLM crowd that's more on the algorithm side (their criticism will be more: why no human video?).}

% Learning rewards from misaligned videos
% Rewards from misaligned videos
% Misaligned videos to rewards
% Imitation learning from temporally misaligned videos

% Learning from a single misaligned video
% Themes: video, time
% A challenge: although the problem is important, it's not
% Instead of "mis
% Time and temporal 

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{William Huey}{equal,c}
\icmlauthor{Huaxiaoyue Wang}{equal,c}
\icmlauthor{Anne Wu}{c}
\icmlauthor{Yoav Artzi}{c}
\icmlauthor{Sanjiban Choudhury}{c}
% \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \icmlauthor{Firstname7 Lastname7}{comp}
%\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{c}{Cornell University}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{William Huey}{wph52@cornell.edu}
\icmlcorrespondingauthor{Huaxiaoyue (Yuki) Wang}{yukiwang@cs.cornell.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Learning from Videos, Inverse Reinforcement Learning, Reward Formulation}

\vskip 0.3in
]

% \printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
We examine the problem of learning sequential tasks from a single visual demonstration.
A key challenge arises when demonstrations are \emph{temporally misaligned} due to variations in timing, differences in embodiment, or inconsistencies in execution. Existing approaches treat imitation as a distribution-matching problem, aligning individual frames between the agent and the demonstration. However, we show that such frame-level matching fails to enforce temporal ordering or ensure consistent progress.
Our key insight is that matching should instead be defined at the level of sequences. 
We propose that perfect matching occurs when one sequence successfully covers all the subgoals in the same order as the other sequence. 
We present \orca{} (ORdered Coverage Alignment), a dense per-timestep reward function that measures the probability of the agent covering demonstration frames in the correct order. 
On temporally misaligned demonstrations, we show that agents trained with the \orca{} reward achieve $4.5$x improvement ($0.11 \rightarrow 0.50$ average normalized returns) for Meta-world tasks and $6.6$x improvement ($6.55 \rightarrow 43.3$ average returns) for \texttt{Humanoid-v4} tasks compared to the best frame-level matching algorithms. 
We also provide empirical analysis showing that \orca{} is robust to varying levels of temporal misalignment.
Our code is available at \url{https://github.com/portal-cornell/orca/}
\end{abstract}

\input{input_tex/introduction}
\input{input_tex/problem_formulation}
\input{input_tex/approach}
\input{input_tex/experiments}
\input{input_tex/related_works}
\input{input_tex/discussion}
\input{input_tex/ack_and_contribution}

% \bibliography{bibs/vlm_rewards, bibs/sequence_matching, bibs/others, bibs/post_workshop}
\bibliography{bibs/consolidated}
\bibliographystyle{icml2025}

\newpage
\appendix
\onecolumn % Having one column is ok for the appendix.
\input{input_tex/appendix}

% \clearpage
% \input{input_tex/post_workshop_proofs}

\end{document}
