\begin{figure}[h] % 'r' for right, '0.5\textwidth' for half the width
    \centering
    \includegraphics[width=\linewidth]{figs/vit_rewards_final.png}
    \caption{\small \textbf{Goal-reaching rewards of (left) two pretrained models and (right) our joint prediction model on an example learner trajectory, with the goal of raising the left arm to the side}. To emphasize their shape, all rewards are normalized along the trajectory dimension. Rewards using the pretrained SigLIP-ViT-B-16 \cite{zhai2023sigmoid} and DINOv2-ViT-B-14-reg \cite{oquab2023dinov2} models are calculated as the cosine similarity between the learner and demonstration embeddings. The fine-tuned joint prediction model provides a smoother reward curve. The trajectories are in the MuJoCo \texttt{Humanoid-v4} environment~\citep{mujoco,humanoidgym}, which is visually modified to mimic the setup of~\cite{rocamonde2024visionlanguage}.}
    \label{fig:vit_rewards}
\end{figure}
