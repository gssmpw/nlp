\section{Conclusion}
We present Agentic LLM Unlearning (\texttt{ALU}), the first unlearning framework that employs multiple LLM agents to remove traces of unlearning targets from a response at inference time. \texttt{ALU} adapts to new unlearning targets in real-time without compromising on unlearning efficacy and model utility, offering significant improvements in time and computational efficiency compared to existing methods. We conduct extensive experiments and show that \texttt{ALU} consistently outperforms existing optimization-based and post hoc state-of-the-art methods across model sizes and perturbations. Notably, we highlight the importance of scalability in unlearning frameworks for their deployment in the real world and exhibit the superior performance of \texttt{ALU} against other methods when scaled to 1000 unlearning targets. We are excited to witness the progress of agentic frameworks in unlearning and further research to improve on the overall architecture, response utility, and tackling entangled subjects, given the proof of their efficacy in our work.

\section*{Acknowledgment}
This research is supported by the Anusandhan National Research Foundation (ANRF) (erstwhile, Science and Engineering Research Board (SERB)) India, under grant SRG/2023/001686. 
