% \documentclass[sigconf]{acmart}
\documentclass[sigconf]{acmart} % 必须添加 nonacm 选项
% \settopmatter{licenses=cc-by}

\copyrightyear{2025}
\acmYear{2025}
\setcopyright{cc}
\setcctype{by}
\acmConference[WWW Companion '25]{Companion Proceedings of the ACM Web
Conference 2025}{April 28-May 2, 2025}{Sydney, NSW, Australia}
\acmBooktitle{Companion Proceedings of the ACM Web Conference 2025 (WWW
Companion '25), April 28-May 2, 2025, Sydney, NSW, Australia}
\acmDOI{10.1145/3701716.3715508}
\acmISBN{979-8-4007-1331-6/25/04}



\usepackage{multirow}
\usepackage{enumitem}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{bm}
% \usepackage{subfig}
\usepackage{xspace}
\newcommand{\model}{\textsf{RALLRec}\xspace}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{url}
\usepackage{balance}
\newcommand{\lsc}[1]{\textcolor{cyan}{[sc: #1]}}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}

% \acmConference[]{}{}

% \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}

\begin{document}


\title[RALLRec]{RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning}



% \email{guanzdeng2-c@my.cityu.edu.hk}
% \thanks{\textsuperscript{$\ast$}Equal Contribution\quad $^{\dagger}$Corresponding Author}

\author{Jian Xu\textsuperscript{$\ast$}}
% \thanks{
% % \parbox{\linewidth}{\textsuperscript{*}Equal Contribution\\$^{\dagger}$Corresponding Author}}
% }
\affiliation{%
% \department{Department of Computer Science}
  \institution{Tsinghua University}
  % \streetaddress{P.O. Box 1212}
  \city{Beijing}
  % \state{Ohio}
  \country{China}
  % \postcode{43017-6221}
}
\email{xujian20@mails.tsinghua.edu.cn}

\author{Sichun Luo\textsuperscript{$\ast$}}
% \thanks{
% % \parbox{\linewidth}{\textsuperscript{*}Equal Contribution\\$^{\dagger}$Corresponding Author}}
% }

\affiliation{%
  \institution{City University of Hong Kong}
  \city{Hong Kong}
  % \state{State}
  \country{China}
}
\affiliation{%
% \department{Department of Computer Science}
  \institution{City University of Hong Kong Shenzhen Research Institute}
  % \streetaddress{P.O. Box 1212}
  \city{Shenzhen}
  % \state{Ohio}
  \country{China}
  % \postcode{43017-6221}
}
\affiliation{%
  \institution{
Dongguan University of Technology}
  \city{Dongguan}
  % \state{State}
  \country{China}
}
\email{sichun.luo@my.cityu.edu.hk}

\author{Xiangyu Chen}
% \thanks{
% % \parbox{\linewidth}{\textsuperscript{*}Equal Contribution\\$^{\dagger}$Corresponding Author}}
% }
\affiliation{%
  \institution{Tsinghua University}
  \city{Beijing}
  % \state{State}
  \country{China}
}
\email{xy-c21@mails.tsinghua.edu.cn}


\author{Haoming Huang}
% \thanks{
% % \parbox{\linewidth}{\textsuperscript{*}Equal Contribution\\$^{\dagger}$Corresponding Author}}
% }
\affiliation{%
  \institution{Alibaba Group}
  \city{Shenzhen}
  % \state{State}
  \country{China}
}
\email{huanghaoming.hhm@alibaba-inc.com}


\author{Hanxu Hou$^{\dagger}$}
% \thanks{
% % \parbox{\linewidth}{\textsuperscript{*}Equal Contribution\\$^{\dagger}$Corresponding Author}}
% }
\affiliation{%
  \institution{Dongguan University of Technology}
  \city{Dongguan}
  % \state{State}
  \country{China}
}
\email{houhanxu@163.com}


\author{Linqi Song$^{\dagger}$}
\thanks{
\parbox{\linewidth}{\textsuperscript{*}Equal Contribution\\$^{\dagger}$Corresponding Author}}
\affiliation{%
  \institution{City University of Hong Kong}
  \city{Hong Kong}
  % \state{State}
  \country{China}
}
\affiliation{%
% \department{Department of Computer Science}
  \institution{City University of Hong Kong Shenzhen Research Institute}
  % \streetaddress{P.O. Box 1212}
  \city{Shenzhen}
  % \state{Ohio}
  \country{China}
  % \postcode{43017-6221}
}
\email{linqi.song@cityu.edu.hk}

% \author{Jian Xu\textsuperscript{1 2$\ast$}, 
% Sichun Luo\textsuperscript{1$\ast$}, 
% Xiangyu Chen\textsuperscript{2}, 
% Haoming Huang, 
% Hanxu Hou\textsuperscript{3}, 
% Linqi Song$^{1{\dagger}}$}
% % \email{xujian9512@gmail.com}
% % \author{}
% % \email{sichun.luo@my.cityu.edu.hk}
% % \thanks{\textsuperscript{$\ast$}Equal Contribution}
% % \thanks{
% % % \parbox{\linewidth}{\textsuperscript{*}Equal Contribution\\$^{\dagger}$Corresponding Author}}
% % }
% \thanks{\textsuperscript{$\ast$}Equal Contribution\quad $^{\dagger}$Corresponding Author}
% \affiliation{%
%   \institution{\textsuperscript{1}City University of Hong Kong\\
%   \textsuperscript{2}Tsinghua University
%   \textsuperscript{3}Dongguan University of Technology
%   }
%   % \city{Hong Kong}
%   % % \state{State}
%   \country{}
% }
% \affiliation{%
% % \department{Department of Computer Science}
%   \institution{City University of Hong Kong Shenzhen Research Institute}
%   % \streetaddress{P.O. Box 1212}
%   \city{Shenzhen}
%   % \state{Ohio}
%   \country{China}
%   % \postcode{43017-6221}
% }
% \email{{sichun.luo@my.,linqi.song@}cityu.edu.hk}


% \author{}
% \affiliation{%
% \department{School of Electrical Engineering and Intelligentization}
%   \institution{Dongguan University of Technology}
%   \city{Dongguan}
%   \country{China}
%   }
% \email{chenma@cityu.edu.hk}




% \author{Linqi Song$^{\dagger}$}

% % \author{, }
% \thanks{\textsuperscript{$\ast$}Equal Contribution\quad $^{\dagger}$Corresponding Author}
% % \thanks{
% % % \parbox{\linewidth}{\textsuperscript{*}Equal Contribution\\$^{\dagger}$Corresponding Author}}
% % }
% \affiliation{%
%   \institution{Department of Computer Science,\\City University of Hong Kong}
%   \city{Hong Kong}
%   % \state{State}
%   \country{China}
% }
% \affiliation{%
% % \department{Department of Computer Science}
%   \institution{City University of Hong Kong Shenzhen Research Institute}
%   % \streetaddress{P.O. Box 1212}
%   \city{Shenzhen}
%   % \state{Ohio}
%   \country{China}
%   % \postcode{43017-6221}
% }
% \email{linqi.song@cityu.edu.hk}
% \pagestyle{empty}
% \settopmatter{printacmref=false} 
% \renewcommand\footnotetextcopyrightpermission[1]{} 

\begin{abstract}
Large Language Models (LLMs) have been integrated into recommendation systems to enhance user behavior comprehension. The Retrieval Augmented Generation (RAG) technique is further incorporated into these systems to retrieve more relevant items and improve system performance. However, existing RAG methods rely primarily on textual semantics and often fail to incorporate the most relevant items, limiting the effectiveness of the systems.

In this paper, we propose \textbf{R}epresentation learning for retrieval-\textbf{A}ugmented \textbf{L}arge \textbf{L}anguage model \textbf{Rec}ommendation (\model). Specifically, we enhance textual semantics by prompting LLMs to generate more detailed item descriptions, followed by joint representation learning of textual and collaborative semantics, which are extracted by the LLM and recommendation models, respectively. Considering the potential time-varying characteristics of user interest, a simple yet effective reranking method is further introduced to capture the dynamics of user preference. We conducted extensive experiments on three real-world datasets, and the evaluation results validated the effectiveness of our method. Code is made public at \url{https://github.com/JianXu95/RALLRec}.
% \lsc{add code link}
% \vspace{-3ex}
\end{abstract}



\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002951.10003317.10003347.10003350</concept_id>
       <concept_desc>Information systems~Recommender systems</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Recommender systems}

\keywords{Retrieval-augmented generation, Large language model, Recommender system}

\maketitle

% \renewcommand{\baselinestretch}{0.97}



\section{Introduction}

% Recommendation systems are widely utilized across various domains \cite{lu2015recommender}. 
Recently, large language models (LLMs) have demonstrated significant potential and have been integrated into recommendation tasks \cite{luo2024recranker,luo2024integrating,luo2024large,wu2024survey}. One promising direction for LLM-based recommendations, referred to as LLMRec, involves directly prompting the LLM to perform recommendation tasks in a text-based format \cite{bao2023tallrec,zhang2023chatgpt}.

However, simply using prompts with recent user history can be suboptimal, as they may contain irrelevant information that distracts the LLMs from the task at hand. To address this challenge, ReLLa \cite{lin2024rella} incorporates a retrieval augmentation technique, which retrieves the most relevant items and includes them in the prompt. This approach aims to improve the understanding of the user profile and improve the performance of recommendations. Furthermore, GPT-FedRec \cite{zeng2024federated} proposes a hybrid Retrieval Augmented Generation mechanism to enhance privacy-preserving recommendations by using both an ID retriever and a text retriever.
% addressing data sparsity and heterogeneity 

\begin{figure}[t]
\centering
\includegraphics[width=0.4\textwidth]{p5.png}
\vspace{-3ex}
    \caption{\model with embedding, retrieval and reranker.}
\label{fig:pipeline}
% \vspace{-6ex}
\end{figure}

Despite the advancements, current methods have limitations. ReLLa relies primarily on text embeddings for retrieval, which is suboptimal as it overlooks collaborative semantic information from the item side in recommendations. The semantics learned from text are often inadequate as they typically only include titles and limited contextual information. 
% Furthermore, the collaborative semantics from the user side remain underutilized.
GPT-FedRec does not incorporate user's recent interest, and the ID based retriever and text retrieval are in a separate manner, which may not yield the best results.
The integration of text and collaborative information presents challenges as these modalities are not inherently aligned.

In this work, we propose Representation Learning enhanced Retrieval-Augmented Large Language Models for Recommendation (\model). Our objective is to enhance the performance of retrieval-augmented LLM recommendations through improved representation learning.
Specifically, instead of solely relying on abbreviated item titles to extract item representations, we prompt the LLM to generate detailed descriptions for items utilizing its world knowledge. These generated descriptions are used to extract improved item representations. This representation is concatenated with the abbreviated item representation.
Subsequently, we obtain collaborative semantics for items using a recommendation model. This collaborative semantic is aligned with textual semantics through self-supervised learning to produce the final representation. This enhanced representation is used to retrieve items, thereby improving Retrieval-Augmented Large Language Model recommendations.

In a nutshell, our contribution is threefold.
\vspace{-1ex}
\begin{itemize}[left=0em]
    \item We propose \model, which incorporates collaborative information and learns joint representations to retrieve more relevant items, thereby enhancing the retrieval-augmented large language model recommendation.
    
    % \item We utilize contrastive learning to align text semantics with collaborative semantics, leveraging user-side collaborative information to improve model performance.

    \item We design a novel reranker that takes into account both the semantic similarity to the target item and the timestamps for boosting the validness of RAG.
    
    \item With extensive explorations of the training and prompting strategies, the experiments reveal several interesting findings and validate the effectiveness of our method.
\end{itemize}






% \section{Related work}

% \subsection{Large Language Model Recommendation}

% \subsection{Representation Learning in Recommendation}
% In recommendation, MF learns collaborative representations. Subsequently, a graph structure is employed to model more complex and higher-order collaborative representations. Contrastive learning is integrated into the recommendation process by using contrastive loss to develop more uniform representations.
% More recently, LLMs have been incorporated into representation learning. Concurrent with our work, [XXX] aligns collaborative and textual information. However, these efforts do not specifically target Retrieval-Augmented Large Language Model recommendations.




\section{Methodology}

\subsection{Framework Pipeline}

% In this paper, we focus on the click-through rate (CTR) prediction \cite{lin2024rella}. 
The pipeline of the developed framework is illustrated in Figure~\ref{fig:pipeline}.
The \model encompasses both the retrieval and generation processes.
In the retrieval process, we first learn a joint representation of users and items, allowing us to retrieve the most relevant items in semantic space. These items are then fused with the most recent items by a reranker and incorporated into the prompts. The constructed prompts can be used solely for inference or to train a more effective model through instruction tuning (IT).
For the generation phase, the base LLM responses to the prompt for inference. The base LLM could be standard or customized.
% instruction-tuned
% \lsc{Need polish this part}





\begin{figure}[t]
\centering
\includegraphics[width=0.43\textwidth]{text.png}
\vspace{-2ex}
    \caption{Comparison of textual descriptions with fixed template (upper) and automatic generation (blow).}
\label{fig:text_desc}
\vspace{-3ex}
\end{figure}



\subsection{Representation Learning}
To learn better item embeddings \footnote{We interchangeably use the representation and embedding to denote the extracted item feature considering the habits in deep learning and information retrieval domains.} for reliable retrieval, we propose to integrate both the text embedding from textual description and collaborative embedding from user-item interaction, as well as the joint representation through self-supervised training.

\subsubsection{Textual Representation Learning}

% \subsubsection{Item-side Textual Information Enrichment}

In previous work \cite{lin2024rella}, only the fixed text template with basic information such as item title was utilized to extract textual information. However, we argue that relying solely on the fixed text format is inadequate, as it may not capture sufficient semantic depth, e.g., two distinct and irrelevant items may probably have similar names. To enhance this, we take advantage of the LLMs to generate a more comprehensive and detailed description containing the key attributes of the item (e.g., Figure~\ref{fig:text_desc}), which can be denoted as
\begin{equation}
    t^{i}_{\text{desc}} = \text{LLM}(b^{i}|p),
\end{equation}
where $b^{i}$ is the basic information of the $i$-th item and the $p$ is the template for prompting the LLMs.
Subsequently, we derive textual embeddings by feeding the text into LLMs and taking the hidden representation as in \cite{lin2024rella}, represented as 
\begin{equation}
    \mathbf{e}_{\text{desc}}^i = {{\text{LLM}}}_{emb}(t^{i}_{\text{desc}}).
    \label{eq:llm_emb}
\end{equation}
Since the plain embedding of item title $e_{\text{title}}^i$ could also be useful, we aim to directly concatenate these two kinds of embeddings to obtain the final textual representations, denoted by
\begin{equation}
    \mathbf{e}_{\text{text}}^i = [\mathbf{e}_{\text{title}}^i \| \mathbf{e}_{\text{desc}}^i].
    \label{eq:llm_emb}
\end{equation}
It is worth noting that those textual embeddings are reusable after being extracted and they already contain affinity information attributed to the rich knowledge of LLMs.

% \begin{figure}[t]
%     \centering
%     % First subplot
%     \subfigure[Basic film information]{
%         \includegraphics[width=0.9\columnwidth]{text1.png} % Replace with your image file
%     }\\
%     \hfill
%     % Second subplot
%     \subfigure[Enriched Film Description]{
%         \includegraphics[width=0.9\columnwidth]{text2.png} % Replace with your image file
%         % \label{fig:subplot2}
%         }
%     \caption{Comparison of textual descriptions with fixed template and automatic generation.}
%     \label{fig:text_desc}
% \end{figure}



\subsubsection{Collaborative Representation Learning}

% \subsubsection{Item-side Collaborative Information}
A notable shortcoming of previous LLM-based approaches is their failure to incorporate collaborative information, which is directed learned from the user-item interaction records and thus can be complementary to the text embeddings. To this end, we utilize conventional recommendation models to extract collaborative semantics, denoted as
\begin{equation}
    \{\mathbf{e}_{\text{colla}}^i\}_{i=1}^{n} = \text{RecModel}(\{(u, i)\in \mathcal{V}\}),
\end{equation}
where $n$ is the total number of items and $\mathcal{V}$ is the interaction history.






\begin{table*}[!t]
\caption{
% The performance of different models in \emph{zero-shot}, \emph{full-shot} and \emph{few-shot} settings. 
% In \emph{full-shot} setting, the baselines are trained on the entire training set. 
% In \emph{few-shot} setting, the number of training shots $N$ is selected from $\{256 (<1\%), 1024(<10\%)\}$ on BookCrossing dataset, and $\{8192 (<1\%), 65536 (<10\%)\}$ on MovieLens-1M and MovieLens-25M datasets. 
% The user behavior sequence length $K$ is set to 60 on BookCrossing and 30 on both MovieLens-1M and MovieLens-25M. 
The performance of different models in default settings. The best results are highlighted in boldface. 
The symbol $\ast$ indicates statistically significant improvement of \model over the best baseline
with $p$-value < 0.01.
}
\vspace{-8pt}
\label{tab:zero & few shot performance}
\resizebox{0.95\textwidth}{!}{
\renewcommand\arraystretch{1.0}
\begin{tabular}{c|c|ccc|ccc|ccc}
\toprule
% \hline

\multicolumn{2}{c|}{\multirow{2}{*}{Model}} & \multicolumn{3}{c|}{BookCrossing} & \multicolumn{3}{c|}{MovieLens} & \multicolumn{3}{c}{Amazon} \\ 
\multicolumn{2}{c|}{} & AUC $\uparrow$  & Log Loss $\downarrow$& ACC $\uparrow$& AUC $\uparrow$ & Log Loss $\downarrow$& ACC $\uparrow$& AUC $\uparrow$ & Log Loss $\downarrow$& ACC $\uparrow$\\ 
   \hline 
   
\multicolumn{1}{c|}{\multirow{4}{*}{ID-based}} & DeepFM & 0.5480&0.8521&0.5212& 0.7184&0.6205&0.6636 &0.6419&0.8281&0.7760\\
\multicolumn{1}{c|}{\multirow{4}{*}{}} & xDeepFM & 0.5541&0.9088&0.5304& 0.7199&0.6210&0.6696&0.6395&0.8055&0.7711 \\
\multicolumn{1}{c|}{\multirow{4}{*}{}} & DCN  & 0.5532&0.9356&0.5189 & 0.7212&0.6164&0.6681&0.6369&0.7873&0.7744 \\
\multicolumn{1}{c|}{\multirow{4}{*}{}} & AutoInt  & 0.5478&0.9854&0.5246& 0.7138&0.6224&0.6613 &0.6424&0.7640&0.7543\\
   \hline  


\multicolumn{1}{c|}{\multirow{3}{*}{LLM-based}} & Llama3.1 & 0.5894 & 0.6839 & 0.5418 & 0.5865 & 0.6853 & 0.5591 & 0.7025 & 0.7305 & 0.4719 \\ 
\multicolumn{1}{c|}{\multirow{4}{*}{}} & ReLLa & 0.7125 & 0.6458 & 0.6368 & 0.7524 & 0.6182 & 0.6804 & 0.8401 & 0.5074 & 0.8224  \\ 
\multicolumn{1}{c|}{\multirow{4}{*}{}} & Hybrid-Score & 0.7096 & 0.6409 & 0.6334 & 0.7646 & 0.6149 & 0.6843 & 0.8405 & 0.5065 & 0.8256 \\
\hline

\multicolumn{1}{c|}{\multirow{2}{*}{Ours}} & \model & \textbf{0.7151$^*$} & \textbf{0.6359$^*$} & \textbf{0.6483$^*$} & \textbf{0.7772$^*$} & \textbf{0.6102$^*$} & \textbf{0.6904$^*$} & \textbf{0.8463$^*$} & \textbf{0.4914$^*$} & \textbf{0.8280$^*$} \\ 
\multicolumn{1}{c|}{\multirow{2}{*}{}} 
% & \textit{p-value} & \textit{<0.0009} & \textit{<0.0024} & \textit{<0.0013} & \textit{<0.0001} & \textit{<0.0001} & \textit{<0.0026} & \textit{<0.0002} & \textit{<0.0001} & \textit{<0.0039} \\ 
& \textit{p-value} & \textit{8.69e-4} & \textit{2.35e-3} & \textit{1.22e-3} & \textit{3.00e-6} & \textit{2.05e-5} & \textit{2.58e-3} & \textit{1.39e-4} & \textit{1.96e-5} & \textit{3.88e-3}\\ 
% & \textit{p-value} & {0.000869} & {0.00235} & {0.00122} & {0.000003} & {2.051616654292588e-05} & {0.002577} & {0.000139} & {1.96e-05} & {0.00388}\\ 
  
   % \hline  
   \bottomrule          
\end{tabular}
\vspace{-5ex}
}
\end{table*}



\subsubsection{Joint Representation Learning}

A straightforward approach for integrating above two representations is to directly concatenate the textual and collaborative representations. However, since these representations may not be on the same dimension and scale, this might not be the best choice. Inspired by the success of contrastive learning in aligning different views in recommendations \cite{zou2022multi}, we employ a self-supervised learning technique to effectively align the textual and collaborative representations.
Specifically, we adopt a simple two-layer MLP as the projector for mapping the original text embedding space into a lower feature space and use the following self-supervised training objective
\begin{equation} \footnotesize
    \mathcal{L}_{ssl}^{}=-\mathbb{E} \left\{\log \left[\frac{f\left(\mathbf{e}_{\text{text}}^i, \mathbf{e}_{\text{colla}}^i\right)}{\sum_{v \in \mathcal{V}} f\left(\mathbf{e}_{\text{text}}^i, \mathbf{e}_{\text{colla}}^v\right)}\right] + \log \left[ \frac{f\left(\mathbf{e}_{\text{colla}}^i, \mathbf{e}_{\text{text}}^i\right)}{\sum_{v \in \mathcal{V}} f\left(\mathbf{e}_{\text{colla}}^i, \mathbf{e}_{\text{text}}^v\right)}\right]\right\},
    \label{eq:loss_ssl}
\end{equation}
where $f\left(\mathbf{e}_{\text{text}}^i, \mathbf{e}_{\text{colla}}^v\right)=exp(sim(\text{MLP}(\mathbf{e}_{\text{text}}^i), \mathbf{e}_{\text{colla}}^v))$ and $sim(\cdot)$ is the cosine similarity function. After the joint representation learning, we can get the aligned embedding for each item $i$ as
\begin{equation}
    \mathbf{e}_{\text{ssl}}^i = \text{MLP}(\mathbf{e}_{\text{text}}^i).
\end{equation}

\subsubsection{Embedding Mixture}
Instead of retrieval using different embeddings separately, we find that integrating those embeddings before retrieval can present better performance, therefore we directly concat them after magnitude normalization
\begin{equation}
    \mathbf{e}_{\text{item}} = [\mathbf{\bar{e}}_{\text{text}}||\mathbf{\bar{e}}_{\text{colla}}||\mathbf{\bar{e}}_{\text{ssl}}],
\end{equation}
where $\mathbf{\bar{e}} := \mathbf{{e}}/\|\mathbf{{e}}\|$. With the final item embeddings, we can retrieve the most relevant items to the target item by simply comparing the dot-production for downstream recommendation tasks.


% \subsection{User-side Collaborative Information Incorporation}

% \subsection{Data Augmentation}

% Data sparsity is a longstanding problem in recommender systems. In some cases, user history may not be relevant to the target item, potentially due to this sparsity. However, there may be instances where similar users have records that are more aligned with the target items. In such cases, we believe that incorporating information from these similar users can enhance model performance. Specifically, we aim to include similar user records in the prompt to enrich the information provided. The prompt template is as follows:



\subsection{Prompt Construction}
To form a prompt message that LLMs can understand, we use a similar template as in \cite{lin2024rella} by filling the user profile, listing the relevant behavior history and instructing the model to give a prediction. We also observed that the pre-trained base LLMs may perform poorly in instruction following. Therefore, we collect a small amount of training data for instruction tuning, where the prompts are constructed with similarity-based retrieval and a \textit{data augmentation} technique is also employed by re-arranging the retrieved sequence according to the timestamp to reduce the impact of item order.

% We observed that the pre-trained base LLMs may perform poorly in the recommendation tasks as the new input and output format is not well aligned. To this end, we collect a small amount training data for supervised fine-tuning (Instruction Tuning). The training data is constructed by embedding-based history retrieval without re-ranking while the inference process can be boosted by re-ranking technique. Further, we re-rank the retrieved sequence according to the timestamps as a kind of data augmentation.


\subsection{Reranker}
Since we can retrieve the most recent $K$ items as well as the most relevant $K$ items, relying solely on one of them may not be the optimal choice. During the inference stage, we further innovatively design a reranker to merge these two different channels. The reranker can be either learning-based or rule-based; in this case, we utilize a heuristic rule-based reranker. For each item, we assign a channel score $\text{S}_{c}$ and a position score $\text{S}_{pos}$. We assign the channel score as $\alpha$ and $(1-\alpha)$ for embedding-based and time-based channel, respectively. The position score is inversely proportional to the position in the original sequence, i.e., $\{1, \frac{1}{2^{\beta}}, ..., \frac{1}{K^{\beta}}\}$. The hyper-parameters $\alpha$ and $\beta$ are tunable. The total score for each item is calculated as the production of these two scores 
\begin{equation}
    \text{Score}^i = \text{S}^{i}_{c} * \text{S}^{i}_{pos}.
\end{equation}
By taking the items with top-$K$ scores, we can obtain a refined retrieval result to maximize the prediction performance.

% \subsection{Evaluation Metric}
% We use the logits of the positions of "Yes" and "No" to compute the relative probability of the CTR prediction...





\section{Experiment}


% In this section, we assess the performance of our framework and aim to answer the following research questions:

% \begin{itemize}
%     \item \textbf{RQ1:} How does our proposed \model framework compare with both the conventional recommendation models and the state-of-the-art LLM-based RAG recommendation methods?  
%     \item \textbf{RQ2:} Do the designed components of our model, including the representation learning and alignment, embedding mixture and re-ranking module, function effectively?  
%     \item \textbf{RQ3:} How do different hyper-parameters and training/inference settings affect the final recommendation performance?  
% \end{itemize}


\subsection{Dataset}
In this paper, we focus on the click-through rate (CTR) prediction \cite{lin2024rella}. 
We utilize three widely used public datasets: BookCrossing \cite{ziegler2005improving}, MovieLens \cite{harper2015movielens},  and Amazon \cite{ni2019justifying}.
For the MovieLens dataset, we select the MovieLens-1M subset, and for the Amazon dataset, we focus on the Movies \& TV subset. We apply the 5-core strategy to filter out long-tailed users/items with less than 5 records. Some statistics are shown in Table~\ref{tab:datasets}. Similar to ReLLa \cite{lin2024rella}, we collect the user history sequence before the latest item and the ratings to construct the prompting message and ground-truth. 




\begin{table}[!t]
    \caption{The dataset statistics.}
    \vspace{-8pt}
    \centering
    \resizebox{0.45\textwidth}{!}{
    \renewcommand\arraystretch{1.1}
    \begin{tabular}{c|cccccc}
    \toprule
     Dataset   & \#Users & \#Items & \#Samples & \#Fields & \#Features \\ 
     \midrule
     BookCrossing  & 8,723 & 3,547 & 227,735 & 10 & 14,279 \\
     MovieLens & 6,040 & 3,952 & 970,009 & 9 & 15,905 \\
     Amazon & 14,386 & 5,000 & 141,829 & 6 & 22,387 \\ 
     \bottomrule
    \end{tabular}
    }
    \vspace{-5pt}
    \label{tab:datasets}
\end{table}

\begin{table*}[t]
\caption{ The performance of different variants of \model. We remove different components of \model to evaluate the contribution of each part to the model. 
The best results are highlighted in boldface.
% given in bold, and the second-best value is underlined. 
}
\vspace{-6pt}
\label{tab:ablation_train}
\resizebox{0.88\textwidth}{!}{
\renewcommand\arraystretch{1.0}
\begin{tabular}{r|ccc|ccc|ccc}
\toprule
% \multicolumn{2}{c|}{\multirow{2}{*}{Model}} & \multicolumn{4}{c}{MovieLens-1M} \\ 
% \multicolumn{2}{c|}{} & AUC  & Log Loss & ACC & Rel.Impr\\ 
\multicolumn{1}{c|}{\multirow{2}{*}{Model Variant}} & \multicolumn{3}{c|}{BookCrossing} & \multicolumn{3}{c|}{MovieLens} & \multicolumn{3}{c}{Amazon} \\ 
\multicolumn{1}{c|}{} & AUC $\uparrow$  & Log Loss $\downarrow$& ACC $\uparrow$ & AUC $\uparrow$  & Log Loss $\downarrow$& ACC $\uparrow$ & AUC $\uparrow$  & Log Loss $\downarrow$& ACC $\uparrow$ \\ 
\hline 
\model (Ours) & \textbf{0.7151} & \textbf{0.6359} & \textbf{0.6483} & \textbf{0.7772} & \textbf{0.6102} & \textbf{0.6904} & \textbf{0.8463} & \textbf{0.4914} & \textbf{0.8280} \\ 
- \textit{w/o} Data Aug. & 0.7108 & 0.6460 & 0.6460 & 0.7563 & 0.6394 & 0.6452 & 0.8453 & 0.4978 & 0.8226 \\ 
- \textit{w/o} Retrieval & 0.6960 & 0.6425 & 0.6414 & 0.7687 & 0.6199 & 0.6697 & 0.8404 & 0.5037 & 0.8194 \\ 
% ReLLa ($\frac{1}{2}N$-shot) & \underline{0.7415} & 0.6268 & 0.6462 & \underline{0.7862} & 0.5781 & 0.6964 & \underline{0.8231} & 0.5157 & 0.7672 \\ 
- \textit{w/o} IT & 0.5857 & 0.6860 & 0.5441 & 0.5865 & 0.6853 & 0.5591 & 0.7120 & 0.7272 & 0.4765 \\ 
% \model (w/o IT \& Retrieval) & 0.6197 & 0.6846 & 0.5413 & 0.5788 & 0.6947 & 0.5235 & 0.7025 & 0.7305 & 0.4179 \\ 
\bottomrule          
\end{tabular}
}
% \vspace{-1ex}
\end{table*}

% \lsc{Introduce more about data processing}

\subsection{Baseline}
We compare our approach with baseline methods, which include both ID-based and LLM-based recommendation systems.
For ID-based methods, we select DeepFM \cite{guo2017deepfm}, xDeepFM \cite{lian2018xdeepfm}, DCN \cite{wang2017deep}, and AutoInt \cite{song2019autoint} as our baseline models. We utilize Llama3.1-8B-Instruct \cite{dubey2024llama} as the base model and LightGCN \cite{He2020LightGCN} to learn collaborative embeddings in our comparisons.
For LLM-based methods, we consider ReLLa \cite{lin2024rella} and a Hybrid-Score based retrieval as in \cite{zeng2024federated}. By default, we apply the LoRA method and 8-bit quantization to conduct instruction-tuning as in \cite{lin2024rella} and the maximum length of history is $K=30$. For the reranker in our method, we search the $\alpha$ over $\{\frac{1}{2}, \frac{2}{3}, \frac{4}{5}\}$ and fix $\beta=1$ in the experiments.



\begin{figure}[t]
\centering
\includegraphics[width=0.48\textwidth]{comparison_plot_new.pdf}
\vspace{-5ex}
    \caption{The impact of history sequence length K on AUC.}
\label{fig:ablation_K}
% \vspace{-5ex}
\end{figure}







%     \item \textbf{RQ2:} Do the designed components of our model, including the representation learning and alignment, embedding mixture and re-ranking module, function effectively?  
%     \item \textbf{RQ3:} How do different hyper-parameters and training/inference settings affect the final recommendation performance?  




% \subsubsection{Data Efficiency}




% \begin{table}
%     \caption{The impact of history sequence length K on AUC.}
%     \vspace{-5pt}
%     \centering
%     \resizebox{0.48\textwidth}{!}{
%     \renewcommand\arraystretch{1.0}
%     \begin{tabular}{c|c|ccccc}
%     \toprule
%      \textbf{Dataset}   & \textbf{K} & \textbf{Ours}& \textbf{ReLLa} & \textbf{Zero-shot} & \textbf{w/o ReR} \\ 
%      \midrule
%      \multirow{7}{*} {BookCrossing} & 5 & 0.7035 & 0.6952 & 0.6365 & 0.6941 \\
%                                  & 10 & 0.7136 & 0.7118 & 0.6364  & 0.7158 \\
%                                  & 15 & 0.7225 & 0.7093 & 0.6193  & 0.7164 \\
%                                  & 20 & 0.7160 & 0.7093 & 0.6206  & 0.7181 \\
%                                  & 25 & 0.7171 & 0.7089 & 0.6159  & 0.7145 \\
%                                  & 30 & 0.7167 & 0.7125 & 0.6159  & 0.7141 \\
%                                  % & 40 & -- & -- & -- \\
%      \midrule
%      \multirow{6}{*}{Movielens-1M} & 5 & 0.7472 & 0.7084 & 0.5882 & 0.7287 \\
%                                  & 10 & 0.7622 & 0.7240 & 0.5898  & 0.7470 \\
%                                  & 15 & 0.7671 & 0.7268 & 0.5794  & 0.7551 \\
%                                  & 20 & 0.7708 & 0.7410 & 0.5730  & 0.7593 \\
%                                  & 25 & 0.7743 & 0.7480 & 0.5893  & 0.7621 \\
%                                  & 30 & 0.7772 & 0.7524 & 0.5865  & 0.7653 \\
%     \midrule
%      \multirow{6}{*}{Amazon-movies}& 5 & 0.8380 & 0.8269 & 0.7272  & 0.8342 \\
%                                  & 10 & 0.8451 & 0.8366 & 0.7241  & 0.8409\\
%                                  & 15 & 0.8476 & 0.8385 & 0.7186  & 0.8427\\
%                                  & 20 & 0.8463 & 0.8397 & 0.7146  & 0.8436 \\
%                                  & 25 & 0.8462 & 0.8402 & 0.7091  & 0.8438\\
%                                  & 30 & 0.8463 & 0.8401 & 0.7025  & 0.8442\\
%      \bottomrule
%     \end{tabular}
%     }
%     \label{tab:ablation_k}
% \end{table}






\begin{table*}[t]
\caption{The comparison of different embeddings used for historic behavior retrieval during inference. For fair comparisons, the model is instruction-tuned using the RAG-enhanced training data, while the inference prompt is constructed based on the embedding similarity without re-ranking. The best results are highlighted in boldface.
}
\vspace{-8pt}
\label{tab:ablation_emb}
\resizebox{0.85\textwidth}{!}{
\renewcommand\arraystretch{1.0}
\begin{tabular}{c|ccc|ccc|ccc}
\toprule
% \multicolumn{2}{c|}{\multirow{2}{*}{Model}} & \multicolumn{4}{c}{MovieLens-1M} \\ 
% \multicolumn{2}{c|}{} & AUC  & Log Loss & ACC & Rel.Impr\\ 
\multicolumn{1}{c|}{\multirow{2}{*}{Embedding Variant}} & \multicolumn{3}{c|}{BookCrossing} & \multicolumn{3}{c|}{MovieLens} & \multicolumn{3}{c}{Amazon} \\ 
\multicolumn{1}{c|}{} & AUC $\uparrow$  & Log Loss $\downarrow$& ACC $\uparrow$ & AUC $\uparrow$  & Log Loss $\downarrow$& ACC $\uparrow$ & AUC $\uparrow$  & Log Loss $\downarrow$& ACC $\uparrow$ \\ 
   \hline 
% Plain Text & -- & -- & -- & -- & {--} & -- & -- & -- & {--} \\ 
Text-based & 0.7034 & 0.6434 & 0.6426 & 0.7583 & 0.6188 & 0.6798 & 0.8408 & 0.4931 & 0.8222 \\ 
ID-based & 0.7084 & 0.6414 & 0.6357 & 0.7580 & 0.6153 & 0.6867 & 0.8431 & 0.4930 & 0.8244 \\ 
Concat. w/o SSL & 0.7127 & 0.6411 & 0.6391 & 0.7633 & 0.6153 & 0.6828 & 0.8439 & 0.4925 & 0.8244 \\ 
Concat. w/ SSL & \textbf{0.7141} & \textbf{0.6413} & \textbf{0.6471} & \textbf{0.7653} & \textbf{0.6144} & \textbf{0.6850} & \textbf{0.8442} & \textbf{0.4924} & \textbf{0.8269} \\  
\bottomrule          
\end{tabular}
}
% \vspace{-3ex}
\end{table*}




\subsection{Result Analysis}

\textbf{Sequential Behavior Comprehension.} From the numerical results presented in Table~\ref{tab:zero & few shot performance}, several noteworthy observations emerge. Firstly, the vanilla ID-based methods generally underperform LLM-based methods, demonstrating that LLMs can better leverage textual and historical information for preference understanding. 
% Notably, these conventional methods fail to capture fine-grained semantic associations from item descriptions and user history presented in a natural language format, which limits their performance.
Secondly, among LLM-based baselines, ReLLa effectively incorporates a retrieval-augmented approach but relies predominantly on simple textual semantics for item retrieval. Hybrid-Score, which considers both ID-based and textual features, also improves over the zero-shot LLM setting (Llama3.1). However, both ReLLa and Hybrid-Score still fail to fully leverage the rich collaborative semantics and the alignment between textual and collaborative embeddings. In contrast, \model consistently achieves the best results across all three datasets, outperforming both ID-based and LLM-based baselines. 
% For instance, on the BookCrossing dataset, \model improves the AUC by more than 0.27 over Llama3.1 and about 0.26 over DeepFM. On the larger MovieLens and Amazon datasets, \model also achieves significant performance gains. 
The improvements are statistically significant with $p$-values less than 0.01, emphasizing the robustness of our approach.

% These results validate the efficacy of our representation learning and retrieval augmentation strategies. By enriching textual descriptions (Figure~\ref{fig:text_desc}) and aligning them with collaborative embeddings, \model retrieves more relevant historical behaviors. Consequently, it provides the LLM with a more informative and refined context, enabling it to predict user preferences more accurately.

\noindent \textbf{Impact of sequence length K.} We change the history length $K$ during the inference stage and collect the final performance in Figure~\ref{fig:ablation_K}. It can be found that as $K$ increases, both \model and ReLLa benefit from longer historical sequences to gain richer insights into user preferences, while the zero-shot LLM baseline suffers from noise and thus does not improve. This phenomenon underscores the importance of carefully selecting and structuring historical user behaviors to assist LLMs in recommendation.
\vspace{-1ex}

% \subsubsection{Sequential Behavior Comprehension} As demonstrated by the numerical results in Table~\ref{tab:zero & few shot performance}, our proposed \model framework consistently achieved the best overall performance compared with both the conventional recommendation models and the state-of-the-art LLM-based RAG recommendation methods. 

% \subsubsection{Impact of sequence length K} Since the fine-tuning data contain various lengths equal or less than 30, we also change the value of $K$ during the inference-time prompting to study its impact on the results. It is interesting to observe that the performance of our Rec-RAG and ReLLa is positively related to the history length while the Zero-shot performance on pre-trained model decreased instead.
% \lsc{shall we cite figure 3 here}



\subsection{Ablation Studies}

% To further dissect the effectiveness of each component in \model, we conduct a series of ablation studies.

\subsubsection{Fine-tuning and Data Construction.} We examine the influence of instruction tuning (IT) and data augmentation in Table~\ref{tab:ablation_train}. Removing IT significantly degrades performance, reverting the model to near zero-shot levels, as it struggles to follow the given instructions and task format. Similarly, removing the data augmentation strategy leads to a non-negligible performance drop. This confirms the importance of carefully crafted training data and instruction tuning for aligning the LLM with recommendation objectives.

\vspace{-1ex}
\subsubsection{Reranking and Retrieval Methods.} Figure~\ref{fig:ablation_prompt} compares different retrieval and prompt construction approaches on the MovieLens.
% Without fine-tuning, using embedding-based retrieval alone provides limited gains. Once fine-tuned, integrating retrieval with reranking yields consistent improvements. 
Our reranker, which balances semantic relevance and temporal recency, outperforms both plain recent-history-based prompts and simple hybrid retrieval strategies. These results emphasize the necessity of refining retrieved items through post-processing rather than relying solely on a single retrieval strategy.

\vspace{-1ex}
\subsubsection{Embedding Strategies.} In Table~\ref{tab:ablation_emb}, we contrast various embedding schemes for retrieval. Text-based embeddings provide a decent performance, but they are weaker than the mixture with ID-based embeddings. By aligning textual and collaborative semantics through SSL, we achieve further improvements. 
% The integrated embedding approach (Concat. w/ SSL) yields the highest AUC and ACC, demonstrating that collaborative information and well-aligned representations are crucial for improving item retrieval quality.

% \subsubsection{Inference-time Retrieval} We conduct an investigation on the MovieLens dataset to study the impact of the inference-time retrieval methods with both the simple and enhanced model fine-tuning. Specifically, we respectively use the recent history and RAG-enhanced history to construct the training data while the inference-time prompts can be constructed by various ways, including the Timestamp (Recent), mixing retrieval results of different embeddings (Retri.-then-Mix),  mixing embeddings before retrieval (Mix-then-Retri.), and Re-ranking (ReRank) based retrieval methods. From the results in Figure~\ref{fig:ablation_prompt}, it can be found that (i) simply using the recent history as the training data is generally insufficient and (ii) the re-ranking method achieved the best performance on both the AUC and ACC metrics.


% \subsubsection{Item Embedding Construction.} As we have integrated the text- and ID-based embeddings as well as the aligned embedding in the default setting, it is interesting to verify the individual efficacy of them. With the ablation results reported in Table~\ref{tab:ablation_emb}, we can easily conclude that even the single embedding can already lead to promising results, combining different embeddings is generally helpful especially for the recommendation tasks where relatively even the small improvements would also make a difference. 

\vspace{0.5ex}
Overall, the ablation studies confirm that {\textbf{{(i)}}} instruction tuning and data augmentation are essential for aligning the LLM to recommendation tasks, 
% \raisebox{0.1ex}
{\textbf{{(ii)}}} embedding alignment of textual and collaborative semantics consistently improves retrieval quality, and \textbf{(iii)} a reranking strategy that considers both item relevance and temporal factors enhances the final recommendation performance. Combining these insights, \model presents a robust and effective framework for retrieval-augmented LLM-based recommendation.

% In this work, we have designed a two-level hybrid strategy during the retrieval, including the embedding mixture for item similarity computing and the the history reranking. Here we further conduct some ablation experiments to verify the individual effectiveness of each designed component. We also consider different combination of prompt construction during the fine-tuning and inference stages, respectively.

% Do the designed components of our model, including the representation learning and alignment, embedding mixture and re-ranking module, function effectively?  

% \subsubsection{Model Fine-tuning} To verify the impact of training data construction, we conduct a set of ablation studies with training data consists of the simple recent history, the simple retrieval and also test the frozen base model. It could be seen from Table~\ref{tab:ablation_train} that: 1) if the model is not fine-tuned, the inference-time retrieval would not lead to a better result than the simple recent history; 2) the embedding-based retrieval combined with re-ranking can make the model better in response to the recommendation task. 




\begin{figure}[t]
\centering
\includegraphics[width=0.49\textwidth]{improved_comparison_plot.pdf}
\vspace{-5ex}
    \caption{Comparison of fine-tuning and inference settings.}
\label{fig:ablation_prompt}
% \vspace{-3ex}
\end{figure}




% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.88\textwidth]{case.png}
% \vspace{-2ex}
%     \caption{Comparison of retrieval results of ours (left) and ReLLa (right) for a testing example from MovieLens. After careful human examination, the red items are more related to the target item while the blue items are highly irrelevant.}
% \label{fig:case}
% \vspace{-3ex}
% \end{figure*}







% \begin{table}
%     \caption{The comparison of fine-tuning and inference settings on MovieLens-1M, including the Timestamp (Recent), Hybrid Retrieval (HybRet), Mixed embedding (MixEmb), and Re-ranking (ReRank) based retrieval methods.}
%     \vspace{-5pt}
%     \centering
%     \resizebox{0.46\textwidth}{!}{
%     \renewcommand\arraystretch{1.1}
%     \begin{tabular}{c|c|cccc}
%     \toprule
%      \textbf{Fine-tuning}   & \textbf{Inference} & \textbf{AUC}& \textbf{LogLoss} & \textbf{ACC} \\ 
%      \midrule
%      \multirow{3}{*} {Recent Behavior} & Recent & \textbf{0.7687} & 0.6200 & 0.6697 \\
%                                  & HybRet & 0.7514 & 0.6201 & 0.6720 \\
%                                  & MixEmb & 0.7531 & 0.6211 & 0.6724 \\
%                                  & ReRank & \underline{0.7679} & \textbf{0.6158} & \textbf{0.6792} \\
%      \midrule
%      \multirow{3}{*}{RAG-enhanced} & Recent & \underline{0.7764} & 0.6120 & 0.6846 \\
%                                  & HybRet & 0.7614 & 0.6157 & 0.6842 \\
%                                  & MixEmb & 0.7653 & 0.6144 & 0.6850 \\
%                                  & ReRank & \textbf{0.7772} & \textbf{0.6102} & \textbf{0.6904} \\
%     % \midrule
%     %  \multirow{3}{*}{Re-ranking} & T & -- & -- & -- & 0.0\% \\
%     %                              & S & -- & -- & -- & 0.0\% \\
%     %                              & R & -- & -- & -- & 0.0\% \\
%      \bottomrule
%     \end{tabular}
%     }
%     \label{tab:ablation_prompt}
% \end{table}





% \vspace{-2ex}
% \subsection{Case Study}
% \vspace{-1ex}
% In this part, we conduct a case study to further analyze how can Rec-RAG help LLM better understand the user preference and make a reliable prediction. As shown in Figure~\ref{fig:case}, we select a testing sample from MovieLens dataset, and list the retrieval results under the ReLLa and our Rec-RAG. Equipped with enhanced-RAG and reranker, we can reduce the noise of user behavior sequence and bring in more relevant items to help LLM to correctly grasp the correlation between the target item and historical items.

% \vspace{-2ex}

\section{Conclusion}
\vspace{-0.5ex}
In this paper, we introduce a new representation learning framework of item embeddings for LLM-based Recommendation (\model), which improves item description generation and enables joint representation learning of textual and collaborative semantics. Experiments on three datasets demonstrate its capability to retrieve relevant items and improve overall performance. 
% An interesting future direction is incorporating the user-side collaborative semantics to address data sparsity issues and enhance user preference understanding. 
% \lsc{seems like we don't need to mention future direction}
% \vspace{-1ex}
% \setlength{\bibsep}{0pt}
% \renewcommand{\bibfont}{\footnotesize}

\begin{acks}
This work was supported in part by the National Natural Science Foundation of China under Grant 62371411, the Research Grants Council of the Hong Kong SAR under Grant GRF 11217823, the Collaborative Research Fund C1042-23GF, and InnoHK initiative, the Government of the HKSAR, Laboratory for AI-Powered Financial Technologies.
\end{acks}


\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{ref}



\end{document}
