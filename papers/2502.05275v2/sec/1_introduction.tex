\section{Introduction}
% Introduce prevalence of large vision-language models and zero-shot performance
Vision-language models have demonstrated impressive capability across diverse visual recognition domains~\cite{Radford2021LearningTV,Jia2021ScalingUV,Singh2021FLAVAAF,Li2022BLIPBL, Li2023BLIP2BL}.
However, when it comes to safe deployment in high-stake applications, it is of paramount importance for a model to be self-aware of its own shortcomings.
For instance, in monitoring for natural disasters such as floods or wildfires, the AI system must signal for human intervention upon encountering scenarios where its confidence is low. 
Such self-awareness ensures that preemptive measures can be taken to mitigate disaster impacts on communities and ecosystems.
Therefore, it is imperative not only to detect failures accurately but also to understand the reasons behind them.

Traditional methods~\cite{Hendrycks2016ABF, Granese2021DOCTORAS, Zhu2023OpenMixEO, Zhu2023RethinkingCC, liang2020enhancing} rely on category-level information to detect misclassifications, performing confidence estimation on the class logits.
However, neural networks are known to produce overconfident predictions for misclassified samples due to factors like spurious correlations~\cite{Arjovsky2019InvariantRM, Sagawa2019DistributionallyRN}, thus existing confidence scoring functions (CSFs) fall short in such cases.
Besides, the model confidence depicted through category-level information impedes the ability for humans to interpret \textit{why} it fails. % failure interpretation
To this end, we ask the following question: \textit{``What other sources of information can we leverage to enhance failure detection?"}

% \footnotetext{False Positive Rate refers to the probability that a model assigns high confident values to misclassified predictions.}

We present a novel perspective on detecting failures by leveraging human-level concepts, or visual attributes.
With the flexibility to incorporate free-form language to VLMs (\ie CLIP), we can represent a category with a set of predefined concepts~\cite{Menon2022VisualCV, Oikarinen2023LabelFreeCB,li2024beyond,li2024deal}.
Instead of only prompting the model \textit{``Do you recognize a camel?"}, we collectively ask \textit{``Do you recognize humps on back?''}, or \textit{``Do you recognize shaggy coat?"}.
The purpose is to measure the model's confidence in the object's detailed visual attributes in addition to the holistic category.
We thus achieve a more \textit{accurate} confidence estimate to detect failures more effectively (Fig.~\ref{fig:title-figure})

Ideally, a VLM that can recognize a image of a camel should also recognize all the associated visual attributes, such as \textit{humps on back}, \textit{shaggy coat}, \etc
Such visual attributes should yield higher confidence scores compared to those associated with the absent categories.
Conversely, if the model shows high confidence in concepts from multiple unrelated categories at the same time, it could indicate a failure in its recognition process.
Based on such intuition, we present a simple but effective approach using the \textbf{O}rdinal \textbf{R}anking of \textbf{C}oncept \textbf{A}ctivation (ORCA) to detect failures.
Additionally, these human-understandable concepts allow users to understand the reasons behind such failures, thereby aiding them in refining the training process.

We rigorously validate our method's efficacy in detecting incorrect samples across both natural and remote sensing image benchmarks, which mirror the complexity in real-world scenarios. 
ORCA demonstrates a significant capability to mitigate the issue of overly confident misclassifications.
% effectively reducing the false positive rate, as illustrated in the bottom half of Fig.~\ref{fig:title-figure}.
In summary, our contributions are threefold:
\begin{enumerate}
    \item We leverage human-level concepts to detect \textit{when} and interpret \textit{why} a model fails using vision-language models.
    \item We present a simple but effective approach, called ORCA, to estimate more reliable confidence via the ordinal ranking of the concepts' activation.
    \item We empirically demonstrate that the concept-based methods enhance failure prediction performance across a wide range of classification benchmarks.
\end{enumerate}