% \begin{figure*}[!t]
%     \centering
%     \includegraphics[width=0.75\linewidth]{fig/title-a.pdf}
%     \caption{Comparison between standard (MSP) and our approaches. MSP relies solely on class logits to predict failures, which is problematic in detecting overconfident but incorrect predictions. To tackle this problem, we propose to deconstruct each category into its associated human-level concepts for a \textit{finer-grained} estimate of confidence. Our method, ORCA, improves significantly on FPR@95TPR\protect\footnotemark.}
%     \label{fig:title-figure}
% \end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.6\linewidth]{fig/title-new.pdf}
    \captionof{figure}
    {
    Comparison between standard (MSP) and our approaches. MSP relies solely on class logits to predict failures, which is problematic in detecting overconfident but incorrect predictions. To tackle this problem, we propose to deconstruct each category into its associated human-level concepts for a \textit{finer-grained} estimate of confidence. 
    % Our method, ORCA, improves significantly on FPR@95TPR\protect\footnotemark.
    }
    \label{fig:title-figure}
\end{figure*}

\begin{abstract}
Reliable failure detection holds paramount importance in safety-critical applications.
Yet, neural networks are known to produce overconfident predictions for misclassified samples. 
As a result, it remains a problematic matter as existing confidence score functions rely on category-level signals, the logits, to detect failures. 
This research introduces an innovative strategy, leveraging human-level concepts for a dual purpose: to reliably detect \textit{when} a model fails and to transparently interpret \textit{why}.
By integrating a nuanced array of signals for each category, our method enables a finer-grained assessment of the model's confidence.
We present a simple yet highly effective approach based on the ordinal ranking of concept activation to the input image. 
Without bells and whistles, our method significantly reduce the false positive rate across diverse real-world image classification benchmarks, specifically by $3.7\%$ on \textit{ImageNet} and $9\%$ on \textit{EuroSAT}.
\end{abstract}
