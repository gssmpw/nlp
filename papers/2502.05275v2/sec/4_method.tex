\section{Methods}
Traditional methods rely on the category-level signals to estimate the model's confidence.
This leads to unreliable confidence estimate as neural networks are prone to overconfident misclassification. 
To address this issue, we suggest exposing the model to diverse viewpoints via human-level concepts. 
Rather than inquiring about the model's certainty regarding an image being a camel, we also query its confidence regarding specific attributes like the presence of humps on the camel's back, a shaggy coat, \etc

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{fig/overview.pdf}
    \caption{Overview of the ORCA framework. We first prompt GPT-3.5 to construct the concept collection $\mathcal{A}$. We then pass the image and all the concepts into CLIP to retrieve the concept similarity scores, represented by the number above each bar, and sort them in descending order. Based on the top-$K$ responses, we analyze the interaction among concept activations through ordinal ranking to predict the model's failures, and interpret why it fails. ``Detect failures'' is triggered when the confidence falls below a predefined threshold. Best viewed in color.}
    \label{fig:overview}
\end{figure*}

Recent advancements in VLMs enable such integration of human-level concepts as free-form language into the pipeline~\cite{Menon2022VisualCV, Yang2022LanguageIA, Oikarinen2023LabelFreeCB}. 
In this section, we describe the integration of the work by Menon and Vondrick~\cite{Menon2022VisualCV} which employs concept aggregation to establish a baseline concept-based method for failure detection. Subsequently, we introduce ORCA, our novel approach that captures the interaction among concept activations through ordinal ranking, enhancing the reliability of failure detection.
% \vspace{-8pt}
\subsection{Human-Level Concepts for Failure Detection} \label{sec:desc-clip}
Given $K$ concepts per category, we define $\mathcal{A}$ as a collection of all concepts, where $|\mathcal{A}| = C \times K$. 
We obtain the vector of similarity scores (or logits), $S_{\text{conc}} = [s_{1,1}, \dots, s_{1,K}, s_{2,1}, \dots, s_{C, K}]$, between the image embedding and all the concepts using Eq.~\ref{eq:simscore}.
DescCLIP then calculates the mean similarity score among all concepts for each category $c$ to retrieve the logits and output the prediction:
\begin{equation}
    f(\mathbf{x}) = \operatorname{argmax}_{c\in\mathcal{Y}} \frac{1}{K} \sum_{k=1}^K s_{c, k}
\end{equation}

Finally, we apply the softmax function (Eq.~\ref{eq:softmax}) on the logits to get the class probabilities and employ MSP to obtain the model's confidence score.

\subsection{Ordinal Ranking of Concept Activation}

DescCLIP's concept aggregation leads to a coarse-grained confidence estimation procedure. We propose a fine-grained approach that models the interaction among concepts via ordinal ranking to estimate confidence more reliably. 
% We demonstrate that our method works well empirically in Sec.~\ref{sec:experiment} and enables failure interpretation in Sec.~\ref{sec:interpretation}.

Ideally, if a model is confident about predicting a category $\hat{c}$ then the concepts associated with $\hat{c}$ should yield the strongest activations. 
In other words, the similarity scores of all concepts belonging to $\hat{c}$, $\{s_{\hat{c}, k}\}_{k=1}^K$, should belong to the top-$K$ ranking.
Conversely, we would see a mixture of concepts from different categories in the top-$K$ ranking if the model is likely to make an incorrect prediction. 
With such information, we can separate correct and incorrect predictions more reliably.
Next, we describe two variants of our proposed method: baseline and rank-aware ORCA.
In brevity, the former builds upon simple counting mechanisms, while the latter weighs the concept contributions to the confidence estimate based on their ranks.

\vspace{5pt}
\noindent\textbf{Baseline ORCA.}
We first sort $S_{\text{conc}}$ in descending order and retrieve the set of the top-$K$ concepts, denoted as an ordered set $\mathcal{A}_{\text{top-}K}$.
After that, we derive the confidence based on the number of different categories whose concepts belong in $\mathcal{A}_{\text{top-}K}$.
The rationale is straightforward: the model is at a higher risk of failure as there are more categories featuring in $\mathcal{A}_{\text{top-}K}$.
The prediction is determined as follows:
\begin{equation} \label{eq:orca-b-pred}
    \begin{aligned}
    f(\mathbf{x}) &= \operatorname{argmax}_{c\in\mathcal{Y}} \lvert \mathcal{A}_{\text{top-}K} \cap \mathcal{A}_c \rvert,
\end{aligned}
\end{equation}
where $\mathcal{A}_c$ denotes the set of concepts of an arbitrary category $c$'s concepts, and $\lvert \cdot \rvert$ denotes the set cardinality.
The confidence of the prediction is the ratio between the number of the predicted category's concepts appearing in $\mathcal{A}_{\text{top-}K}$ over $K$:
\begin{equation} \label{eq:orca-b-conf}
    g(f, \mathbf{x}) = \frac{\lvert \mathcal{A}_{\text{top-}K} \cap \mathcal{A}_{\hat{c}}\rvert}{K} 
\end{equation}
where $\hat{c} = f(\mathbf{x})$ is the prediction. 
We dub this variant ORCA-B in the text.

% \begin{algorithm}[t]
% \footnotesize
% \caption{\footnotesize The proposed ORCA algorithm.}
% \LinesNumbered
% \label{alg:orca}
% \KwIn{image $\mathbf{x}$; concept collection $\mathcal{A}$}
% \KwOut{prediction $f(\mathbf{x})$; confidence $g(\mathbf{x})$}
% Obtain similarity scores $S_{\text{conc}} \leftarrow \texttt{CLIP}(\mathbf{x}, \mathcal{A})$ \\
% Get top-$K$ concepts $\mathcal{A}_{\text{top-}K} \leftarrow \texttt{DescendSort}(S_{\text{conc}})$ \\
% \uIf{ORCA-B}{
% Calculate $f(\mathbf{x})$ via Eq.~\ref{eq:orca-b-pred} \\
% Derive $g(\mathbf{x})$ via Eq.~\ref{eq:orca-b-conf}
% }
% \uElseIf{ORCA-R}{
% Calculate $f(\mathbf{x})$ via Eq.~\ref{eq:orca-r-pred} \\
% Derive $g(\mathbf{x})$ via Eq.~\ref{eq:orca-r-conf}
% }

% \end{algorithm}

\noindent\textbf{Rank-aware ORCA.}
While ORCA-B provides a fundamental approach, its reliance solely on rudimentary counting mechanisms limits its ability to capture nuanced distinctions.
To enhance our approach, we introduce a rank-aware variant that uses ordinal ranking information to deliver more accurate failure detection.
In detail, we construct a rank-aware weight vector $\mathbf{w}$ where the value of each element is proportional to the ordinal ranking.
First, we define the ordinal ranking vector $\mathbf{r} = [K, K-1, \dots, 1]$ with $K$ elements in descending order.
Then, we apply a logarithmic weighting function to assign each rank in $\mathbf{r}$ a weight $w_i \in \mathbf{w}$, resulting in a decreasing vector whose elements sum up to $1$. 
Logarithmic ensures a smooth distribution of weights among the ranks of each concept, enabling a more nuanced estimation of the confidence level.
Specifically, the logarithmic scaling equation is defined as $w_i = \frac{\log(1 + r_i)}{\sum_{j=1}^{K} \log(1 + r_j)}$, with the normalization of each weight $w_i$ in $\mathbf{w}$. 
% We provide an ablation study comparing different scaling functions in Sec.~\ref{ablate}.
Finally, for each category $c$ with its concepts featuring in $\mathcal{A}_{\text{top-}K}$, we calculate the prediction and the confidence of the model as follows:
\begin{equation} \label{eq:orca-r-pred}
    f(\mathbf{x}) = \operatorname{argmax}_{c\in\mathcal{Y}} \sum_{k=1}^K \mathbb{I}(a_k \in \mathcal{A}_c) \cdot w_k 
\end{equation}
\begin{equation} \label{eq:orca-r-conf}
    g(f, \mathbf{x}) = \operatorname{max}_{c\in\mathcal{Y}} \sum_{k=1}^K \mathbb{I}(a_k \in \mathcal{A}_c) \cdot w_k 
\end{equation}

\noindent where $a_k$ is the $k^{\text{th}}$ concept in the ordered set $\mathcal{A}_{\text{top-}K}$, and $\mathbb{I}(\cdot)$ denotes the indicator function that returns $1$ if the condition is true. We refer to this variant as ORCA-R.