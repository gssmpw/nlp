\section{Enhancing Unlearning Robustness: From SAM to Broader Smoothness Optimization}
\label{sec: method}


In this section, we delve into the optimization process of SAM, revealing its connection to curvature-aware smoothness optimization in improving unlearning robustness. 

%Building on this insight, we present additional smooth optimization techniques and explore their integration into LLM unlearning for defending against relearning attacks.




\paragraph{SAM facilitates curvature regularization of forget loss.}
As shown by \eqref{eq: prob_LLM_MU_SAM}, SAM promotes the \textit{flatness} of the forget loss landscape since it seeks a minimum that maintains a uniformly low loss across the neighborhood of the model. Therefore, SAM facilitates smoothness optimization in LLM unlearning. 
% As will become evident later, this can be empirically demonstrated by visualizing the loss landscape at the unlearned model. 
% Prior to that, we first provide a theoretical analysis below.
%
%
Based on the SAM algorithm \citep{foret2021sharpnessaware}, the \textit{inner maximization} in \eqref{eq: prob_LLM_MU_SAM} can be solved in \textit{closed form} using linear approximation:
\begin{align}
    \bdelta^*(\btheta) \Def & \displaystyle \argmax_{\| \bdelta \|_2 \leq \rho} \ell_{\mathrm{f}} (\btheta + \bdelta) \overset{(a)}{\approx} \displaystyle \argmax_{\| \bdelta \|_2 \leq \rho} \ell_{\mathrm{f}} (\btheta ) + \bdelta^\top \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) 
    %\nonumber \\
  =  %&
  \displaystyle \argmax_{\| \bdelta \|_2 \leq \rho}   \bdelta^\top \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \overset{(b)}{=} \rho \frac{\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta )}{ \| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2},
  \label{eq: inner_max_sol}
\end{align}
where for simplicity, 
we omit $\Df$ in the notation of the forget loss, $^\top$ denotes the transpose operation, and $\nabla_{\btheta}$ represents the first-order derivative with respect to (w.r.t.) $\btheta$. In \eqref{eq: inner_max_sol}, the approximation (a) is derived from the first-order Taylor expansion of $\ell_{\mathrm{f}} (\btheta + \bdelta)$ w.r.t. $\bdelta$ around $\mathbf{0}$. And the equality (b) follows from the fact the maximum cosine similarity is achieved when $\bdelta$ is aligned with the direction of  $\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta)$ and has the largest allowable magnitude $\rho$. 

By substituting the weight perturbation $\bdelta^*(\btheta)$ into the SAM-based forget loss, we can turn the min-max optimization problem  into the min-only problem:
\begin{align}
 \min_{\btheta} \ell^{\mathrm{SAM}}_{\mathrm{f}} (\btheta) = \min_{\btheta} \ell_{\mathrm{f}} \left (\btheta + \rho \frac{\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta )}{ \| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2} \right ).
 \label{eq: min-only}
\end{align}
To solve \eqref{eq: min-only}, it can be observed that the gradient of $\ell^{\mathrm{SAM}}_{\mathrm{f}}$ implicitly depends on the second-order derivative of $\ell_{\mathrm{f}} (\btheta)$, \textit{i.e.}, the Hessian of $\ell_{\mathrm{f}}$. This then links \eqref{eq: min-only} with the curvature
of the forget loss landscape w.r.t. $\btheta$. We elaborate on this insight by approximating $\ell_{\mathrm{f}}$ in \eqref{eq: min-only} by its first-order
Taylor expansion at $\rho = 0$ \citep{dauphin2024neglected}, 
\begin{align}
\raisetag{6mm}
       & \ell^{\mathrm{SAM}}_{\mathrm{f}} (\btheta) =  \ell_{\mathrm{f}} \left (\btheta + \rho \frac{\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta )}{ \| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2} \right ) %\nonumber\\ 
   \approx % & 
   \ell_{\mathrm{f}} (\btheta) + \rho \frac{\nabla_{\btheta} \ell_{\mathrm{f}}(\btheta)^\top  
 \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta )}{ \| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2}  = \ell_{\mathrm{f}} (\btheta) + \rho \| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2.
  \label{eq: min-only-linear}
\end{align}
Solving the above problem \eqref{eq: min-only-linear} with a first-order optimizer then involves the Hessian of $\ell_{\mathrm{f}}$, which arises through the derivative of $ 
\| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2$:
\begin{align}
&\frac{d \| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2}{d \btheta} = \frac{d (\| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2^2)^{1/2}}{d \btheta} 
%\nonumber \\
=  % & 
\frac{1}{2} (\| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2^2)^{-1/2} (2 \mathbf H  \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) ) = \mathbf H \mathbf v,
\label{eq: curvature_reg}
\end{align}
where $\mathbf H = \nabla_{\btheta, \btheta} \ell_{\mathrm{f}}(\btheta)$ is the Hessian matrix of the forget loss $\ell_{\mathrm{f}}$ w.r.t. $\btheta$, and $\mathbf v = \frac{   \nabla_{\btheta} \ell_{\mathrm{f}}  (\btheta )}{\| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2}$ indicates the gradient's direction. And we assume that $\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) $ is not a zero vector.
% {\red[we need to say that assuming $\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) $ is not a zero vector. Otherwise the gradient does not exist. ]}

It is worth noting that
the quantity $\mathbf{H} \mathbf{v}$ in \eqref{eq: curvature_reg} is also employed in the \textit{curvature regularization} method \citep{moosavi2019robustness} to enhance adversarial robustness of discriminative models against (input-level) adversarial attacks. However, in such a context, the Hessian $\mathbf{H}$ and the gradient $\mathbf{v}$ are defined w.r.t. the model's input, rather than the model's weights as in \eqref{eq: curvature_reg}.
By using a finite difference approximation of the Hessian, we can express $\mathbf{H} \mathbf{v}$ as 
\begin{align}
    \mathbf{H} \mathbf{v} \approx \frac{\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta + \mu \mathbf v ) -\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) }{\mu},
    \label{eq: curvature_reg_finite_diff}
\end{align}
where $\mu > 0$  represents the discretization step, controlling the scale at which gradient variations are constrained to remain small. 
Based on \eqref{eq: curvature_reg} and \eqref{eq: curvature_reg_finite_diff}, solving the problem \eqref{eq: min-only} drives convergence toward a stationary point, which consequently reduces the curvature, \textit{i.e.},   $\| \mathbf{H} \mathbf{v} \|_2 \to 0$.
This suggests that \textit{reducing curvature}, and thereby \textit{increasing the smoothness} of the forget loss surface, is beneficial to the resilience of LLM unlearning against relearning attacks.


% \begin{figure*}[htb] % 或者 [htbp], 视排版需求
% \centering
% %============= 第一行：3 幅图 =============
% \begin{tabular}{ccc}
% \hspace*{-3mm}
% \includegraphics[width=0.55\textwidth,height=!]{figs/npo_unlearn.pdf}
% &
% \hspace*{-8mm}
% \includegraphics[width=0.19\textwidth,height=!]{figs/origin_df.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.19\textwidth,height=!]{figs/npo_df.pdf} \\
% \hspace*{-3mm}
% \small{{(a) Unlearning effectiveness (UE) of NPO w/o and w/ smoothness optimization.}}
% &
% % \hspace*{-6mm}
% \small{(b) Origin}
% &
% % \hspace*{-6mm}
% \small{(b) NPO}
% \\
% \end{tabular}

% \vspace*{-1mm} % 调整两行之间的垂直间距

% %============= 第二行：5 幅图 =============
% \begin{tabular}{cccccc}
% \hspace*{-3mm}
% \raisebox{0.1\height}{\rotatebox{90}{\small{Loss landscape on $\mathcal{D}_\mathrm{f}$}}} \hspace*{-5mm} % 提高位置，使其与图片垂直居中
% &
% \hspace*{-3mm}
% \includegraphics[width=0.19\textwidth,height=!]{figs/npo_sam_df.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.19\textwidth,height=!]{figs/npo_rs_df.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.19\textwidth,height=!]{figs/npo_gnr_df.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.19\textwidth,height=!]{figs/npo_cr_df.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.19\textwidth,height=!]{figs/npo_swa_df.pdf}
% \\

% % 在下一行写 (d), (e), (f), (g), (h)

% &
% \hspace*{-6mm}
% \small{(c) NPO + SAM}
% &
% \hspace*{-6mm}
% \small{(d) NPO + RS}
% &
% \hspace*{-6mm}
% \small{(e) NPO + GP}
% &
% \hspace*{-6mm}
% \small{(f) NPO + CR}
% &
% \hspace*{-6mm}
% \small{(g) NPO + WA}
% \\
% \end{tabular}



\begin{myremark}
Although SAM inherently involves second-order derivatives in its optimization analyses, its scalable implementation   for deep models often bypasses this computationally intensive component, calling for a pure first-order optimization approach \citep{foret2021sharpnessaware}. We refer readers to \textbf{Algorithm\,\ref{appendix: algo_sam} of Appendix\,\ref{appendix: algorithm}} for a detailed description of the SAM-enhanced LLM unlearning. This algorithm alternates between the inner maximization step, solved using the closed-form solution in \eqref{eq: inner_max_sol}, and the outer minimization step, addressed via gradient descent but excluding the high-order derivatives described in \eqref{eq: curvature_reg}.
\end{myremark}

\paragraph{Broader smoothness optimization to improve unlearning robustness.}
As analyzed above, the SAM-like optimization in \eqref{eq: prob_LLM_MU_SAM} and \eqref{eq: min-only} indicates smoothness optimization for robust unlearning against relearning attacks. Building on this insight, we extend our investigation to a broader range of smoothness optimization techniques, including randomized smoothing (\textbf{RS}), gradient penalty (\textbf{GP}), curvature regularization (\textbf{CR}), and weight averaging (\textbf{WA}).


First, RS transforms a non-smooth objective function into a smooth one by convolving it with a (smooth) Gaussian distribution function \citep{duchi2012randomized}.  The underlying rationale is that the convolution of two functions produces a new function that is at least as smooth as the smoothest of the original functions. Let $\bdelta$ represent a random perturbation vector sampled from the Gaussian distribution $\mathcal{N}( 0, \sigma^2)$, where the mean is $0$ and the variance is $\sigma^2$ for each independent and identically distributed (i.i.d.) variable component.
Recall that SAM targets the worst-case (maximum) perturbation $\bdelta$ in \eqref{eq: inner_max_sol}. In contrast, RS introduces a random perturbation, smoothing the optimization objective by averaging over random perturbations. This modifies the forget loss  $\ell^{\mathrm{SAM}}_{\mathrm{f}} (\btheta)$ in \eqref{eq: prob_LLM_MU_SAM} to:
\begin{align}
    \ell^{\mathrm{RS}}_{\mathrm{f}} (\btheta) = \mathbb E_{\bdelta \sim \mathcal N(0, \sigma^2)} [ \ell_{\mathrm{f}}(\boldsymbol{\theta} + \boldsymbol{\delta} )].
    \label{eq: SAM_RS}
\end{align}
It is worth noting that in the context of adversarial robustness against input-level adversarial attacks, RS has been widely employed to smooth the model's \textit{input}, offering (certified) robustness against such attacks \citep{cohen2019certified}.


\begin{figure*}[htb]
% \vspace{-1mm}
\centering
\hspace*{-60mm}
\includegraphics[width=0.55\textwidth]{figs/npo_unlearn_legend.pdf}\\
\vspace{-1.5mm}
\begin{tabular}{ccc}
\hspace*{-3mm}
\includegraphics[width=0.55\textwidth,height=!]{figs/npo_unlearn_2.pdf}
&
\hspace*{-8mm}
\includegraphics[width=0.19\textwidth,height=!]{figs/origin_df.pdf}
&
\hspace*{-6mm}
\includegraphics[width=0.215\textwidth,height=!]{figs/npo_df_af.png} \\
% \vspace{-1mm}
\hspace*{-3mm}
\small{{(a) Unlearning effectiveness (UE) of NPO w/o and w/ smoothness optimization.}}
&
\hspace*{-10mm}
\small{(b) Origin}
&
\hspace*{-6mm}
\small{(c) NPO}
\\
\end{tabular}

% \vspace*{1mm} % 调整两行之间的垂直间距

%============= 第二行：5 幅图 =============
\begin{tabular}{cccccc}
\hspace*{-3mm}
\raisebox{0.1\height}{\rotatebox{90}{\small{Loss landscape on $\mathcal{D}_\mathrm{f}$}}} \hspace*{-5mm} % 提高位置，使其与图片垂直居中
&
\hspace*{-3mm}
\includegraphics[width=0.19\textwidth,height=!]{figs/npo_sam_df.pdf}
&
\hspace*{-6mm}
\includegraphics[width=0.19\textwidth,height=!]{figs/npo_rs_df.pdf}
&
\hspace*{-6mm}
\includegraphics[width=0.19\textwidth,height=!]{figs/npo_gnr_df.pdf}
&
\hspace*{-6mm}
\includegraphics[width=0.19\textwidth,height=!]{figs/npo_cr_df.pdf}
&
\hspace*{-6mm}
\includegraphics[width=0.19\textwidth,height=!]{figs/npo_swa_df.pdf}
\\

% 在下一行写 (d), (e), (f), (g), (h)

&
\hspace*{-6mm}
\small{(d) NPO+SAM}
&
\hspace*{-6mm}
\small{(e) NPO+RS}
&
\hspace*{-6mm}
\small{(f) NPO+GP}
&
\hspace*{-6mm}
\small{(g) NPO+CR}
&
\hspace*{-6mm}
\small{(h) NPO+WA}
\\
\end{tabular}

% \vspace*{-2mm}
\caption{\small{Improved unlearning robustness by smoothness optimization-integrated NPO (including NPO+SAM, RS, GP, CR, or WA) compared to vanilla NPO on WMDP following the setup in Fig.\,\ref{fig: NPO_example}. 
(a) Unlearning effectiveness of different models (`Unlearn' and `Relearn$\mathrm{N}$' that undergoes relearning with $\mathrm{N}$ examples) obtained from various NPO variants. 
(b)$\sim$(c) The prediction loss landscape of the original model and NPO-unlearned model on the forget set, where higher values around $x = y = 0$ indicate more effective unlearning. 
 The 3D loss landscape is defined as $z = \ell(\btheta + x \cdot \mathbf{r}_1 + y \cdot \mathbf{r}_2)$, with $\btheta$ representing the unlearned model. 
 %Thus, the loss value evaluated at the unlearned model corresponds to $x = y = 0$. 
 (d)$\sim$(h) Similar loss landscape visualizations to (b), but with the unlearned model obtained using smooth variants of NPO. 
 % {\color{red}[a bit unclear here, why higher the unlearning loss the better? I thought we are minimizing the unlearning loss.]}
}}
% \vspace{-4mm}
\label{fig: loss_lanscape}
\end{figure*}


Second, GP naturally originates from SAM, as demonstrated in \eqref{eq: min-only-linear}. When incorporated as a regularization term in SAM's objective, this variant is referred to as {penalty SAM} \citep{dauphin2024neglected}:
\begin{align}
    \ell^{\mathrm{GP}}_{\mathrm{f}} (\btheta) = \ell_{\mathrm{f}} (\btheta) + \rho \| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2.
    \label{eq: SAM_GP}
\end{align}
In the context of adversarial robustness, applying a gradient norm penalty has also been shown to be beneficial for defending against adversarial attacks \citep{finlay2021scaleable}. However, in this scenario, the gradient is computed with respect to the model's \textit{input} rather than its weights.


Third, CR also naturally emerges as a variant of SAM, given by \eqref{eq: curvature_reg} and \eqref{eq: curvature_reg_finite_diff}. Unlike SAM, which implicitly reduces curvature through its optimization process, CR explicitly penalizes the curvature in the forget loss. This direct penalization on \eqref{eq: curvature_reg_finite_diff} leads to the CR-based variant of SAM:
\begin{align}
\ell^{\mathrm{CR}}_{\mathrm{f}} (\btheta) = \ell_{\mathrm{f}} (\btheta) + \gamma \| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta + \mu \mathbf v ) -\nabla_{\btheta} \ell_{\mathrm{f}} (\btheta )  \|_2,
        \label{eq: SAM_CR}
\end{align}
where $\gamma > 0$ is a regularization parameter, and recall that $\mathbf v = \frac{   \nabla_{\btheta} \ell_{\mathrm{f}}  (\btheta )}{\| \nabla_{\btheta} \ell_{\mathrm{f}} (\btheta ) \|_2}$. Similar to RS and GP, curvature regularization, when applied to the loss surface with respect to \textit{inputs}, is also a known technique for enhancing adversarial robustness  \citep{moosavi2019robustness}.




Fourth, WA is a technique designed to enforce weight smoothness by averaging multiple model checkpoints collected along the training trajectory \citep{izmailov2018averaging}. 
This is given by
%Unlike the SAM-based loss variants in RS, GP, and CR, WA can be seamlessly integrated into existing LLM unlearning approaches by incorporating additional weight averaging steps:
\begin{align}
\boldsymbol{\theta}_{\text{WA},t} = \frac{\boldsymbol{\theta}_{\text{WA},t} \cdot n + \boldsymbol{\theta}_{t}}{n + 1}, \quad 
    \boldsymbol{\theta}_{t} = \boldsymbol{\theta}_{t-1} + \Delta \boldsymbol{\theta}_{t} ,
\end{align}
where $t$ represents the training epoch index, and $\boldsymbol{\theta}_{\text{WA},t}$ denotes the model parameters after applying WA at epoch $t$. The parameter $n$ specifies the number of past checkpoints to be averaged. Additionally, $\boldsymbol{\theta}_{t}$ refers to the optimization variable for solving the SAM-based unlearning problem \eqref{eq: prob_LLM_MU_SAM} at epoch $t$, while $\Delta \boldsymbol{\theta}_{t}$ represents the corresponding descent step used to update $\boldsymbol{\theta}$.
As shown in \citep{chen2020robust}, WA also enhances adversarial robustness against adversarial examples in discriminative models.  %\SL{[talk to me on references issue.]}

\paragraph{Smoothness in unlearning improves robustness: A  loss landscape perspective.}
Furthermore, we investigate the previously discussed smoothness optimization techniques (SAM, RS, GP, CR, and WA) and their role in enhancing unlearning robustness, through the perspective of the \textit{loss landscape}.
%xtend the unlearning robustness example in Fig.\,\ref{fig: NPO_example}, leveraging the previously discussed smooth optimization techniques--SAM, RS, GP, CR, and WA--through the lens of the \textit{loss landscape}. 
The loss landscape represents the geometric surface of a loss function against its model parameter change \citep{li2018visualizing,hao2019visualizing,zan2022complementarity}. 
For ease of visualization, the loss sensitivity can be assessed using a parametric model defined as $f(x, y) = \ell(\btheta + x \cdot \mathbf{r}_1 + y \cdot \mathbf{r}_2)$.
Here, $\ell$ represents the prediction loss function, $\mathbf{r}_1$ and $\mathbf{r}_2$ are two directional vectors given by Gaussian vectors, and  $x$ and $y$ are scalar parameters that define the perturbation strength. The 3D loss landscape visualization is subsequently achieved by plotting the loss sensitivity w.r.t. the perturbation parameters $x$ and $y$.
% The direction vectors $\mathbf{r}_1$ and $\mathbf{r}_2$ are selected as Gaussian noise, forming the basis for exploring the parameter space, with the axes corresponding to the values of $x$ and $y$. 
%The loss landscape allows us to clearly observe how the loss changes with variations in model parameters.
Smoothness is indicated when the loss landscape appears relatively flat in the vicinity of the current model parameters.

%\SL{[Transition and a few sentences about loss landscape visualization techniques and refs.]}

% \SL{\textbf{Fig.\,\ref{fig: loss_lanscape}-(a)$\sim$(c)}} illustrates the unlearning effectiveness of various smooth optimization techniques against relearning attacks, along with visualizations of their corresponding forget loss landscapes in Fig.\,\ref{fig: loss_lanscape}-(d)$\sim$(h). For comparison, we also present the model utility post-unlearning and the corresponding retain loss landscapes in  \textbf{Fig.\,\ref{fig: loss_landscape_dr_diff_smooth} of Appendix\,\ref{appendix: add_exp}}. 

Following the experimental setup in Fig.\,\ref{fig: NPO_example}, \textbf{Fig.\,\ref{fig: loss_lanscape}-(a)} shows UE (unlearning effectiveness) of different models (`Unlearn' and `Relearn$\mathrm{N}$' that undergoes relearning with $\mathrm{N}$ examples) using various unlearning methods. These include NPO and its smooth variants, referred to as NPO+X, where X represents techniques such as SAM, RS, GP, CR, or WA. 
As we can see, when subjected to relearning attacks (\textit{i.e.}, `Relearn$\mathrm{N}$'), the smooth variants of NPO demonstrate improved UE compared to the original NPO. Notably, NPO+SAM  achieves the best unlearning robustness. For instance, under Relearn20, NPO+SAM attains a UE of 0.70, compared to 0.57 for the original NPO.
Moreover, in the absence of relearning attacks (\textit{i.e.}, `Unlearn'), the incorporation of smoothing techniques does not compromise the unlearning performance in the non-adversarial setting, as evidenced by the consistent  UE around 0.74.


% \textbf{Fig.\,\ref{fig: loss_lanscape}-(b)} illustrates the prediction loss landscape of the NPO-resulting unlearned model evaluated on the forget set $\Df$. Here the $z$-axis represents the loss value, where a higher value indicates more effective unlearning on $\Df$. 
\textbf{Figs.\,\ref{fig: loss_lanscape}-(b)$\sim$(c)} illustrate the prediction loss landscape of the original model and the NPO-unlearned model evaluated on the forget set $\mathcal{D}_\mathrm{f}$. The prediction loss is given by the cross-entropy next-token prediction loss. The $z$-axis represents the prediction loss, where higher values indicate more effective unlearning (\textit{i.e.}, worse prediction performance). As observed, NPO increases the prediction loss on $\Df$ at $x = y = 0$, 
% {\red[which is the 'prediction loss'? defined before?]} 
indicating effective unlearning. %transforming the loss landscape from a convex-like shape in (b) to a concave-like shape in (c).
Without the application of smoothness-promoting techniques, the vanilla loss landscape is notably sharp around $x = y = 0$, corresponding to the neighborhood of the unlearned model.
In contrast,  \textbf{Figs.\,\ref{fig: loss_lanscape}-(d)$\sim$(h)} depict the loss landscapes of unlearned models employing the smooth variants of NPO. As we can see, 
%the unlearned model ($x = y = 0$) achieves a higher prediction loss over the forget set, indicating effective unlearning. Moreover, 
the loss landscape becomes significantly smoother than Fig.\,\ref{fig: loss_lanscape}-(c) when using SAM, RS, GP, CR, and WA.
%
Taken together,  Fig.\,\ref{fig: loss_lanscape} shows that the smoothness of the loss landscape is beneficial to unlearning robustness improvement. We also provide the loss landscape on $\mathcal{D}_{\mathrm{r}}$ in \textbf{Figs.\,\ref{fig: loss_lanscape_dr}} of \textbf{Appendix\,\ref{appendix: loss_lanscape_dr}} for comparison.



























% illustrates the unlearning performance and robustness of various smooth optimization techniques against relearning attacks, along with visualizations of their corresponding forget loss landscapes in \textbf{Fig.\,\ref{fig: loss_lanscape}-(d)$\sim$(h)}. For comparison, we also present the corresponding retain loss landscapes in  \textbf{Fig.\,\ref{fig: loss_landscape_dr_diff_smooth} of Appendix\,\ref{appendix: add_exp}}.
% \CF{From Fig.\,\ref{fig: loss_lanscape}-(a)$\sim$(c), we observe that combining unlearning with smooth optimization significantly reduces the change in WMDP Bio Accuracy before and after a relearning attack, demonstrating enhanced robustness against such attacks. Meanwhile, it has almost no impact on unlearning effectiveness or utility retention. Furthermore, we find that among various smooth optimization methods, SAM and GP deliver the strongest robustness. From Fig.\,\ref{fig: loss_lanscape}-(d)$\sim$(h), we observe that the loss landscape of NPO shows a sharp spike at the origin, with rapid variations occurring within a very small region. However, when NPO is combined with the smoothing method, the sharp spike disappears, and the variations at the origin become relatively smooth. This smoothness ensures that the unlearned model's loss does not fluctuate dramatically under a relearning attack, making it more robust to such attacks. . These observations demonstrate how the smoothing method enhances the robustness of the unlearning method.}
% As we can see, \SL{[key insights.]}

% \begin{figure*}[t] % 或者 [htbp], 视排版需求
% \centering
% %============= 第一行：3 幅图 =============
% \begin{tabular}{ccc}
% \hspace*{-3mm}
% \includegraphics[width=0.30\textwidth,height=!]{figs/npo_utility.pdf} 
% &
% \hspace*{-6mm}
% \includegraphics[width=0.30\textwidth,height=!]{figs/npo_unlearn.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.30\textwidth,height=!]{figs/npo_robust.pdf} \\
% \hspace*{-3mm}
% \small{(a) Utility retention}
% &
% \hspace*{-6mm}
% \small{(b) Unlearning effectiveness}
% &
% \hspace*{-6mm}
% \small{(c) Robustness}
% \\
% \\
% \end{tabular}

% \vspace*{-1mm} % 调整两行之间的垂直间距

% %============= 第二行：5 幅图 =============
% \begin{tabular}{ccccc}
% \hspace*{-3mm}
% \includegraphics[width=0.18\textwidth,height=!]{figs/npo_df.pdf} 
% &
% \hspace*{-6mm}
% \includegraphics[width=0.18\textwidth,height=!]{figs/npo_sam_df.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.18\textwidth,height=!]{figs/npo_rs_df.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.18\textwidth,height=!]{figs/npo_gnr_df.pdf}
% &
% \hspace*{-6mm}
% \includegraphics[width=0.18\textwidth,height=!]{figs/npo_swa_df.pdf}
% \\

% % 在下一行写 (d), (e), (f), (g), (h)
% \hspace*{-3mm}
% \small{(d) NPO}
% &
% \hspace*{-6mm}
% \small{(e) NPO + SAM}
% &
% \hspace*{-6mm}
% \small{(f) NPO + RS}
% &
% \hspace*{-6mm}
% \small{(g) NPO + GP}
% &
% \hspace*{-6mm}
% \small{(h) NPO + WA}
% \\

% \end{tabular}

% \vspace*{-2mm}
% \caption{(a)-(c): Utility retention, unlearning effectiveness, and robustness of NPO w/o and w/ smoothing methods on the WMDP Bio benchmark. Utility retention is measured using MMLU Accuracy, and unlearning effectiveness is evaluated using 1 - WMDP Bio Accuracy. For both metrics, higher values indicate better performance. Robustness, on the other hand, assesses the change in WMDP Bio Accuracy before and after relearning 1 epoch using 60 samples from the WMDP Bio forget set. A smaller change in accuracy indicates greater model robustness. (d)-(h): Prediction loss landscape of the unlearned model obtained by NPO w/ or w/o smoothing methods over the WMDP Bio forget data. Z axis denotes the loss value.
% \SL{[talk to me next meeting.]}
% }
% \label{fig: loss_lanscape}
% \end{figure*}

