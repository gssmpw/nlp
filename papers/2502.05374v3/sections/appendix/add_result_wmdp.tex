\section{Additional Results on WMDP}
\label{appendix: add_result_wmdp}
% \textbf{Fig.\,\ref{fig: relearn_wmdp_method}} demonstrates the effectiveness of SAM when incorporated into various unlearning methods, including NPO, GradDiff, and RMU. The experimental setup for unlearning and relearning is consistent with Figure 3. As shown, all SAM-enhanced variants exhibit greater resistance to relearning attacks compared to their vanilla versions.

% \begin{figure}[htb]
% % \vspace*{-5mm}
% \center
% \hspace*{6mm}
% \includegraphics[width=0.45\textwidth]{figs/legend_method_1.pdf}\\
% \vspace{-8mm}

% \begin{tabular}{cc}
% \hspace*{-3mm}
% \includegraphics[width=0.23\textwidth,height=!]{figs/method_epoch_wmdp_var_1.pdf} 
% &
% \hspace*{-6mm}
% \includegraphics[width=0.23\textwidth,height=!]{figs/method_step_wmdp_var_1.pdf}
% \vspace*{-1mm}
% \\
% \hspace*{3mm} \small{(a) UE vs. relearning epoch \#} &  \hspace*{-3mm}  
%  \small{(b) UE vs. relearning data \#}\\
% \end{tabular}
% \vspace{-2mm}
% \caption{\small{Unlearning robustness comparison of different unlearning methods (NPO, GradDiff, and RMU) and their SAM-based variants on WMDP in different relearning attack settings. The figure format follows Fig.\,\ref{fig: relearn_wmdp_npo}.}
% }
% \label{fig: relearn_wmdp_method}
% %\vspace*{-5mm}
% \end{figure}

\begin{table}[htb]
\caption{\small{Comparison of unlearning performance for different methods (NPO, GradDiff, and RMU) with and without SAM on WMDP under various relearning attacks settings. The table format follows Table\,\ref{tab: relearn_wmdp_npo}.
}
}
\label{tab: relearn_wmdp_method}
\begin{center}
\resizebox{0.7\textwidth}{!}{
\begin{tabular}{c|c|c|ccc|ccc}
\toprule[1pt]
\midrule
\multirow{2}{*}{\textbf{Methods}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{UT} (\textuparrow)}} & \multicolumn{6}{c}{\textbf{UE} (\textuparrow)} \\                             
\cline{3-9}
& & W/o atk & $N$ = 20 & $N$ = 40 & $N$ = 60 & $M$ = 1  & $M$ = 2 & $M$ = 3 \\
\midrule
NPO           & 0.44 & 0.74 & 0.57 & 0.39 & 0.37 & 0.57 & 0.40 & 0.37 \\
\rowcolor{Gray}
NPO + SAM     & 0.42 & 0.74 & \cb{mr}{0.70} & \cb{mr}{0.50} & \cb{mr}{0.45} & \cb{mr}{0.70} & \cb{mr}{0.63} & \cb{mr}{0.59} \\
\midrule
GradDiff      & 0.43 & 0.73 & 0.45 & 0.37 & 0.36 & 0.45 & 0.37 & 0.36 \\
\rowcolor{Gray}
GradDiff+ SAM & 0.46 & 0.72 & 0.65 & 0.45 & 0.44 & 0.65 & 0.55 & 0.53 \\
\midrule
RMU           & 0.57 & 0.66 & 0.39 & 0.37 & 0.36 & 0.39 & 0.37 & 0.36 \\
\rowcolor{Gray}
RMU + SAM     & 0.57 & 0.66 & 0.42 & 0.41 & 0.40 & 0.42 & 0.41 & 0.41 \\
\midrule
\bottomrule[1pt]
\end{tabular}
}
\end{center}
\end{table}

\textbf{Robustness comparison for different unlearning methods.} \textbf{Table\,\ref{tab: relearn_wmdp_method}} demonstrates that the effectiveness of SAM generalizes well to various unlearning methods, including NPO, GradDiff, and RMU, under different relearning attack settings, such as varying the number of relearning samples \(N\) and the number of relearning epochs \(M\). It can be observed that incorporating SAM consistently enhances the robustness of all methods compared to their vanilla versions, with NPO+SAM exhibiting the highest robustness among them. Notably, this improvement in robustness does not come at the expense of UT or UE before relearning attacks, as the UT and UE (W/o atk) metrics remain largely unchanged after applying SAM.

\begin{figure*}[htb] % 或者 [htbp], 视排版需求
\center
% % \hspace*{6mm}
% \hspace*{-85mm}
% \includegraphics[width=0.23\textwidth]{figs/rmu_legend.pdf}\\
% \vspace{-4mm}

\begin{tabular}{ccccc}


\hspace*{-3mm}
\raisebox{-0.02\height}{\rotatebox{90}{\small{Loss landscape on $\mathcal{D}_\mathrm{f}$}}} \hspace*{-5mm} % 提高位置，使其与图片垂直居中

&
\hspace*{-3mm}
\includegraphics[width=0.16\textwidth,height=!]{figs/rmu_df.pdf}
&
\hspace*{-3mm}
\includegraphics[width=0.16\textwidth,height=!]{figs/rmu_sam_df.pdf}
&
\hspace*{-3mm}
\includegraphics[width=0.16\textwidth,height=!]{figs/rmu_sam_mismatch_df.pdf}
&
\includegraphics[width=0.18\textwidth,height=!]{figs/rmu_bar.pdf}

\\


&
\hspace*{-3mm}
\small{(a) RMU}
&
\hspace*{-6mm}
\small{(b) RMU+SAM(5$\sim$7)}
&
\hspace*{-3mm}
\small{(c) RMU+SAM(1$\sim$7)}
&
% \hspace*{-3mm}
\small{(d) UE vs. relearning attack}

\\
\end{tabular}

\vspace*{-2mm}
\caption{\small{(a)$\sim$(c) Prediction loss landscape of the RMU-unlearned and SAM-enhanced RMU-unlearned models on the forget set, with numbers in ($\cdot$) indicating the layers using SAM. (d) Unlearning robustness comparison of RMU and SAM-enhanced RMU under a relearning attack with 20 forget samples for 3 epoch on WMDP.
}}
\label{fig: loss_lanscape_rmu}
\end{figure*}


\textbf{The relationship between robustness and parameter count in smoothness optimization.}
In \textbf{Fig.\,\ref{fig: loss_lanscape_rmu}}, we illustrate the impact of parameter count in smoothness optimization on the loss landscape over $\mathcal{D}_\mathrm{f}$ and the unlearning robustness against relearning attacks. RMU is a partial model unlearning method that updates only a subset of layers in the original model, which consists of a total of 32 layers. \textbf{Fig.\,\ref{fig: loss_lanscape_rmu}-(a)} presents the vanilla RMU, which performs unlearning at layers 5$\sim$7. It can be observed that its loss landscape undergoes a sharp change at the origin. In contrast, \textbf{Fig.\,\ref{fig: loss_lanscape_rmu}-(b)} depicts the SAM-enhanced RMU, which unlearns at layers 5$\sim$7 and applies perturbations at layers 5$\sim$7. 
%with the perturbation weights accounting for \textbf{2.43\%} of the total model parameters.
As a result, its loss landscape appears slightly smoother compared to Fig.\,\ref{fig: loss_lanscape_rmu}-(a). In \textbf{Fig.\,\ref{fig: loss_lanscape_rmu}-(c)}, the SAM-enhanced RMU not only unlearns at layers 5$\sim$7 but also applies perturbations across layers 1$\sim$7. 
%with perturbation weights making up \textbf{5.68\%} of the total model parameters. 
This results in a smoother loss landscape. Additionally, In \textbf{Fig.\,\ref{fig: loss_lanscape_rmu}-(d)} illustrates the unlearning robustness against a relearning attack using 20 samples from the WMDP Bio forget set, trained for 3 epochs. It is evident that as the number of perturbed parameters increases, the model demonstrates greater robustness.
