\section{Algorithm for SAM-enhanced Unlearning}
\label{appendix: algorithm}

\begin{algorithm}[htb]
\caption{SAM-enhanced Unlearning}
\label{appendix: algo_sam}
\begin{algorithmic}[1]
\Require Original model $\btheta$, forget set $\mathcal{D}_{\mathrm{f}}$, retain set $\mathcal{D}_{\mathrm{r}}$, unlearning steps $N$, learning rate $\eta$, perturbation radius $\rho$, retain regularization $\lambda$

\State $\btheta_{\mathrm{u}} \gets \btheta$
\For{$i = 1$ to $N$}
    \State Sample $(x_{\mathrm{f}}, y_{\mathrm{f}}) \sim \mathcal{D}_{\mathrm{f}}$
    \State $\bdelta \gets \rho \cdot \dfrac{\nabla_{\btheta} \,\ell_{\mathrm{f}}\bigl(\btheta_{\mathrm{u}}; (x_{\mathrm{f}}, y_{\mathrm{f}})\bigr)}{\bigl\|\nabla_{\btheta} \,\ell_{\mathrm{f}}\bigl(\btheta_{\mathrm{u}}; (x_{\mathrm{f}}, y_{\mathrm{f}})\bigr)\bigr\|_{2}}$
    \State $g_{\mathrm{f}} \gets \nabla_{\btheta} \,\ell_{\mathrm{f}}\bigl(\btheta_{\mathrm{u}} + \bdelta; (x_{\mathrm{f}}, y_{\mathrm{f}})\bigr)$
    \State Sample $(x_{\mathrm{r}}, y_{\mathrm{r}}) \sim \mathcal{D}_{\mathrm{r}}$
    \State $g_{\mathrm{r}} \gets \nabla_{\btheta} \,\ell_{\mathrm{r}}\bigl(\btheta_{\mathrm{u}}; (x_{\mathrm{r}}, y_{\mathrm{r}})\bigr)$
    \State $\btheta_{\mathrm{u}} \gets \btheta_{\mathrm{u}} - \eta \bigl(g_{\mathrm{f}} + \lambda \cdot g_{\mathrm{r}}\bigr)$
\EndFor \\
\Return $\btheta_{\mathrm{u}}$
\end{algorithmic}
\end{algorithm}



% \begin{algorithm}[htb]
% \caption{RS-enhanced unlearning}
% \label{appendix: algo_rs}
% \begin{algorithmic}[1]
% \REQUIRE Original model $\btheta$, forget set $\mathcal{D}_{\mathrm{f}}$, retain set $\mathcal{D}_{\mathrm{r}}$, unlearning steps $N$, learning rate $\eta$, perturbation radius $\sigma$, perturbation sampling iterations $M$, retain regularization $\lambda$.
% \State $\btheta_{\mathrm{u}} \gets \btheta$ 
% \FOR{$i = 1$ to $N$}
%     % \State \COMMENT{a}
%     \State Sample $(x_{\mathrm{f}}, y_{\mathrm{f}}) \sim \mathcal{D}_{\mathrm{f}}$
%     \State $\mathbf{g}_{\mathrm{f}} \gets \mathbf{0}$
%     \FOR{$j = 1$ to $M$}
%         \State $\bdelta \gets \mathcal{N}(0, \sigma^2)$
%         \State $g_{\mathrm{f}, j} \gets \nabla_{\btheta} \,\ell_{\mathrm{f}}\bigl(\btheta_{\mathrm{u}} + \bdelta; (x_{\mathrm{f}}, y_{\mathrm{f}})\bigr)$
%         \State $\mathbf{g}_{\mathrm{f}} \gets \mathbf{g}_{\mathrm{f}} + g_{\mathrm{f}, j}$
%     \ENDFOR
%     \State $\mathbf{g}_{\mathrm{f}} \gets \frac{1}{M} \mathbf{g}_{\mathrm{f}}$
%     % \State \COMMENT{b}
%     \State Sample $(x_{\mathrm{r}}, y_{\mathrm{r}}) \sim \mathcal{D}_{\mathrm{r}}$
%     \State $g_{\mathrm{r}} \gets \nabla_{\btheta} \,\ell_{\mathrm{r}}\bigl(\btheta_{\mathrm{u}}; (x_{\mathrm{r}}, y_{\mathrm{r}})\bigr)$
%     % \State \COMMENT{c}
%     \State $\btheta_{\mathrm{u}} \gets \btheta_{\mathrm{u}} - \eta \bigl(g_{\mathrm{f}} + \lambda \cdot g_{\mathrm{r}}\bigr)$
% \ENDFOR 

% \State \Return $\btheta_{\mathrm{u}}$

% \end{algorithmic}
% \end{algorithm}