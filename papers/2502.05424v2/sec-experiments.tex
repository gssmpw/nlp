\section{Experiments}
In this section, we conduct experiments to assess the performance of \model\ and analyze its empirical results.

\begin{table}[tbp]
\center
\caption{Summary of datasets. 
\label{table.datasets}}
%\vspace{-2mm}
\resizebox{1\linewidth}{!}{%
\begin{tabular}{@{}c|rrrrrrr@{}}
\toprule
	& \makecell[c]{Nodes} & \makecell[c]{Edges} & \makecell[c]{Feature\\dimension} & \makecell[c]{Node\\classes} & \makecell[c]{Avg.\\nd} &\makecell[c]{Avg.\\spl} &\makecell[c]{Avg.\\cc}\\
\midrule
     Cora & 2,708 & 10,556 & 1,433 & 7 & 3.89 & 6.30
 & 0.24 \\
     Citeseer & 3,327 & 9,104 & 3,703 & 6 & 2.73
&9.31 & 0.14 \\ 
     Pubmed & 19,717 & 88,648 & 500 & 3 & 4.49
&6.33   & 0.06\\
     Photo & 7,650 & 238,162 & 745 & 8 & 31.13
&4.05   & 0.40 \\
     Computers & 13,752 & 491,722 & 767 & 10 & 35.75
&3.38   & 0.34\\
     Facebook & 22,470 & 342,004 & 128 & 4 & 15.22
&4.97   &  0.35 \\
     LastFM & 7,624 & 55,612 & 128 & 18 & 7.29
& 5.23 & 0.21

\\
 \bottomrule
\end{tabular}}
   \parbox{1\linewidth}{\footnotesize nd: node degree, spl: shortest path length \cite{borgwardt2005shortest}, cc: clustering coefficient \cite{giatsidis2014corecluster}.}
\end{table}

\begin{table*}[tbp] % [!t]
    \centering
    \small
     \addtolength{\tabcolsep}{0.7mm}
    \caption{Accuracy (\%) of one-shot \emph{node classification} with standard deviations. Each column represents a target domain, using other columns as source domains.  The best method in each column is bolded, and the runner-up is underlined.
    }
   % \vspace{-2mm}
    \label{table.node-classification}%
    %\resizebox{1\linewidth}{!}{%
    \begin{tabular}{c|c|c|c|c|c|c|c}
    \toprule
   {{Method }\textbackslash{ Target domain}}   & Cora & Citeseer & Pubmed & Photo & Computers & Facebook & LastFM
      \\\midrule\midrule
    \method{GCN} 
    & 29.53 $\pm$ \phantom{0}7.56 
    & 26.29 $\pm$ \phantom{0}6.50  
    & 23.32 $\pm$ 11.56  
    & 26.96 $\pm$ 12.94 
    & 24.40 $\pm$ \phantom{0}5.62 
    & 20.45 $\pm$ \phantom{0}5.62 
    & \phantom{0}9.21 $\pm$ \phantom{0}3.11   
\\ 
    \method{GAT} 
    & 24.27 $\pm$ \phantom{0}9.26  
    & 21.56 $\pm$ \phantom{0}8.09    
    & 22.28 $\pm$ \phantom{0}9.76   
    & 17.85 $\pm$ 10.22 
    & 23.03 $\pm$ 12.12 
    & 29.27 $\pm$ \phantom{0}6.47   
    & \phantom{0}9.01 $\pm$ \phantom{0}2.61
 
\\\midrule
    \method{DGI}
    & 33.40 $\pm$ 10.48  
    & 25.80 $\pm$ \phantom{0}8.27
    & 47.22 $\pm$ \phantom{0}9.50  
    & 30.89 $\pm$ 10.54  
    & 25.75 $\pm$ 12.45  
    & 34.36 $\pm$ \phantom{0}9.57 
    & 14.14 $\pm$ \phantom{0}6.31
\\
    \method{GraphCL}
    & 27.72 $\pm$ \phantom{0}9.37   
    & 35.02 $\pm$ \phantom{0}8.46  
    & \underline{48.89} $\pm$ \phantom{0}9.03  
    & 34.78 $\pm$ 11.56  
    & {23.79} $\pm$ 12.28 
    & 34.85 $\pm$  \phantom{0}7.07 
    & 18.93 $\pm$  \phantom{0}7.32 
    
\\%\midrule    
    \method{GPPT}
    & 27.18 $\pm$ \phantom{0}4.88	
    & 25.90 $\pm$ \phantom{0}4.68 
    & 39.82 $\pm$ \phantom{0}8.79 
    & 31.58 $\pm$ 10.27  
    & 19.94 $\pm$ \phantom{0}9.61
    & 34.73 $\pm$ \phantom{0}3.99 
    & 20.98 $\pm$ \phantom{0}3.98
\\
    \method{GraphPrompt}
    & 28.26 $\pm$ 12.68
    & 32.51 $\pm$ \phantom{0}8.73
    & 47.47 $\pm$ \phantom{0}9.15
    & 48.11 $\pm$ \phantom{0}9.89  
    & 42.82 $\pm$ 11.67 
    & 40.44 $\pm$ \phantom{0}9.68
    & 19.84 $\pm$ \phantom{0}7.23 
\\
    \method{GPF}
    & 32.17 $\pm$ \phantom{0}6.56
    & \underline{36.79} $\pm$ \phantom{0}7.70 
    & 41.28 $\pm$ \phantom{0}8.14 
    & 47.47 $\pm$ \phantom{0}8.19  
    & 35.75 $\pm$ \phantom{0}7.12 
    & 40.45 $\pm$ \phantom{0}6.34
    & 27.26 $\pm$ \phantom{0}5.50
\\\midrule
    \method{Hassani}
    & 33.35 $\pm$ \phantom{0}6.93
    & 33.66 $\pm$ \phantom{0}7.24
    & 39.87 $\pm$ \phantom{0}8.16
    & 48.48 $\pm$ \phantom{0}7.07
    & 39.99 $\pm$ \phantom{0}7.91
    & 37.70 $\pm$ \phantom{0}5.79
    & 27.16 $\pm$ \phantom{0}4.94
    
\\\midrule

    \method{GCOPE}
    & \underline{35.62} $\pm$ 11.93	
    & \textbf{38.33} $\pm$ \phantom{0}9.28  
    & 45.38 $\pm$ \phantom{0}9.87  
    & \underline{52.87} $\pm$ \phantom{0}9.19
    & \underline{45.65} $\pm$ 10.69 
    & \underline{40.63} $\pm$ \phantom{0}8.50
    & \underline{28.84} $\pm$ \phantom{0}7.59
 \\
  
      \method{\model}
    & \textbf{47.80} $\pm$ 11.88  
    & 36.38 $\pm$ \phantom{0}9.10
    & \textbf{50.25} $\pm$ 10.43 
    & \textbf{58.71} $\pm$ \phantom{0}8.69 
    & \textbf{48.22} $\pm$ \phantom{0}8.17 
    & \textbf{42.70} $\pm$ \phantom{0}8.73
    & \textbf{33.36} $\pm$ \phantom{0}8.11  
    
\\    \bottomrule
        \end{tabular}%}
        \\
%   \parbox{1\linewidth}{\centering In each column, the best-performing method is highlighted in bold, and the runner-up is underlined. Table~\ref{table.graph-classification} follows the same format.}
\end{table*}

\begin{table*}[tbp] % [!t]
    \centering
    \small
     \addtolength{\tabcolsep}{0.7mm}
    \caption{Accuracy (\%) of one-shot \emph{graph classification} with standard deviations. Each column represents a target domain, using other columns as source domains.  The best method in each column is bolded, and the runner-up is underlined.
    }
    % \vspace{-2mm}
    \label{table.graph-classification}%
    %\resizebox{1\linewidth}{!}{%
    \begin{tabular}{c|c|c|c|c|c|c|c}
    \toprule
   {Method }\textbackslash{ Target domain}   & Cora & Citeseer & Pubmed & Photo & Computers & Facebook & LastFM
      \\\midrule\midrule
     \method{GCN} 
    & 30.64 $\pm$ 10.31 
    & 26.90 $\pm$ \phantom{0}7.15 
    & 38.84 $\pm$ 11.82 
    & 15.60 $\pm$ \phantom{0}8.77   
    & 21.94 $\pm$ 14.51 
    & 31.33 $\pm$ \phantom{0}9.47  
    & 28.83 $\pm$ \phantom{0}9.60
    
\\ 
    \method{GAT} 
    & 27.80 $\pm$ \phantom{0}7.85  
    & 27.50 $\pm$ \phantom{0}7.13    
    & 21.66 $\pm$ \phantom{0}8.70    
    & 15.74 $\pm$ \phantom{0}7.62 
    & 16.02 $\pm$ 13.46 
    & 21.20 $\pm$ \phantom{0}7.31  
    & 27.80 $\pm$ \phantom{0}7.85
 
\\\midrule
    \method{InfoGraph}
    & 34.98 $\pm$ 10.15 
    & 35.87 $\pm$ \phantom{0}9.84
    & 48.67 $\pm$ 12.29  
    & 25.70 $\pm$ 11.73  
    & 19.02 $\pm$ 14.09  
    & 31.26 $\pm$ \phantom{0}9.65 
    & 23.29 $\pm$ \phantom{0}7.99
\\
    \method{GraphCL}
    & \underline{42.70} $\pm$ 10.64
    & 36.66 $\pm$ \phantom{0}8.67
    & 47.53 $\pm$ 11.52  
    & 33.07 $\pm$ 12.31  
    & 16.02 $\pm$ 13.47 
    & 21.99 $\pm$ 13.00
    & 21.30 $\pm$ 10.45
\\%\midrule    
    \method{GraphPrompt}
    & 37.38 $\pm$ 14.03	
    & 36.66 $\pm$ \phantom{0}9.19  
    & \textbf{49.55} $\pm$ 10.25 
    & 50.79 $\pm$ 12.31
    & 43.09 $\pm$ 11.45 
    & \underline{41.71} $\pm$ 10.61
    & 32.62 $\pm$ \phantom{0}8.54
\\
    \method{GPF}
    & 39.62 $\pm$ \phantom{0}8.52	
    & 36.73 $\pm$ \phantom{0}7.66 
    & 45.08 $\pm$ 10.36 
    & 47.57 $\pm$ 10.16 
    & 35.70 $\pm$ \phantom{0}8.71  
    & 34.84 $\pm$ \phantom{0}5.14  
    & 34.31 $\pm$ \phantom{0}7.05

\\\midrule
    \method{Hassani}
    & 36.86 $\pm$ 10.74
    & 35.78 $\pm$ \phantom{0}8.80
    & 43.97 $\pm$ 13.27
    & 41.55 $\pm$ 13.08
    & 29.49 $\pm$ 13.86
    & 35.57 $\pm$ \phantom{0}9.00
    & 25.39 $\pm$ \phantom{0}8.14
\\\midrule


    \method{GCOPE}
    & 38.85 $\pm$ 10.99	
    & \textbf{39.93} $\pm$ \phantom{0}9.82 
    & 47.05 $\pm$ 11.74
    & \underline{53.93} $\pm$ \phantom{0}9.74  
    & \underline{45.60} $\pm$ 10.96 
    & 40.26 $\pm$ \phantom{0}9.53
    & \underline{34.68} $\pm$ \phantom{0}7.70
 \\
  
      \method{\model}
    & \textbf{55.35} $\pm$ 13.62  
    & \underline{38.75} $\pm$ \phantom{0}9.40
    & \underline{48.69} $\pm$ 10.16 
    & \textbf{58.75} $\pm$ 11.67 
    & \textbf{48.72} $\pm$ 11.18 
    & \textbf{43.71} $\pm$ \phantom{0}9.54
    & \textbf{48.28} $\pm$ \phantom{0}9.72 
\\    \bottomrule
        \end{tabular}%}
\end{table*}



\subsection{Experimental Setup}
\stitle{Datasets.}
We conduct experiments on seven benchmark datasets.
(1) \emph{Cora} \cite{mccallum2000automating}, (2) \emph{Citeseer} \cite{sen2008collective} and (3) \emph{Pubmed} \cite{sen2008collective} are scientific paper citation networks from different fields, including computer science and biomedical research. Nodes represent academic publications and edges denote citation relationships.
(4) \emph{Photo} \cite{shchur2018pitfalls} and (5) \emph{Computers} \cite{mcauley2015image} are both e-commerce networks from Amazon in different categories, namely, photography and computer related products. Nodes represent products and edges signify frequent co-purchases between products.
(6) \textit{Facebook} \cite{rozemberczki2021multi} is a Web graph, where nodes represent official Facebook pages while the links are mutual likes between these pages.
(7) \textit{LastFM} \cite{rozemberczki2020characteristic} is a social network, where nodes denote users and edges represent interactions such as follower relationships. Note that each domain comprises a single graph. We summary these datasets in Table~\ref{table.datasets} and present additional details in Appendix~\ref{app.dataset}.

\stitle{Setup of pre-training and downstream tasks.}
Following previous work \cite{zhao2024all,yu2024text}, we treat each dataset as a distinct domain. 
Among the seven datasets (or domains), we use each of them as the target domain while leveraging the remaining six as  source domains for pre-training.

On each target domain, we conduct $m$-shot \textit{node classification} and \textit{graph classification}, where $m$ labeled nodes or graphs per class are randomly selected for downstream prompt tuning. Given that each dataset comprises a single graph, performing graph classification on whole graphs is not feasible. Therefore, following previous works \cite{lu2021learning,yu2023hgprompt,yu2024non}, we generate a series of graphs by constructing ego-networks centered on the labeled nodes within each dataset, and set up graph classification on these ego-networks, with each network labeled according to its central node.
 Note that the graph encoder is pre-trained only once for each set of source domains, and subsequently utilized across all downstream tasks.
We generate 100 $m$-shot tasks for both node classification and graph classification by repeatedly sampling $m$ labeled nodes or graphs per class for 100 times. Each task is executed with five different random seeds, leading to a total of 500 outcomes for each classification type. 
We use accuracy as the evaluation metric, as each task is class-balanced \cite{wang2020graph,liu2021relative,liu2023graphprompt,yu2023generalized}, and report the average accuracy and standard deviation over these 500 outcomes.

\stitle{Baselines.}
We compare the performance of \model\ against state-of-the-art methods in four broad groups, as follows.

(1) \emph{End-to-end graph neural networks}: GCN \cite{kipf2016semi} and GAT \cite{velivckovic2017graph} aggregate information from neighboring nodes to update node representations. For each task, they are trained from scratch in a supervised fashion without pre-training.

(2) \emph{Graph pre-training models}: DGI \cite{velivckovic2018deep}, InfoGraph \cite{sun2019infograph}\footnote{Original DGI only operates at the node level, while InfoGraph extends it to the graph level. We apply DGI to node classification, and InfoGraph to graph classification.} and GraphCL \cite{you2020graph} first pre-train a graph encoder to capture the inherent properties of the graphs, and then fine-tune a classifier on the downstream task while freezing the pre-trained model.  GPPT\footnote{GPPT is tailored for node classification task and is not applicable to graph classification. Thus, in our experiments, we only use GPPT for node classification.} \cite{sun2022gppt}, GPF \cite{fang2022universal} and GraphPrompt \cite{liu2023graphprompt}  employ a universal task template to unify self-supervised pre-training and downstream tasks, and tune a single prompt on downstream tasks. 

(3) \textit{Graph cross-domain models}: Hassani \cite{hassani2022cross} pre-trains a GNN on a single source domain by incorporating both contextual and topological views, which facilitates cross-domain adaptation for downstream tasks.

(4) \emph{Multi-domain pre-training models}: GCOPE \cite{zhao2024all} performs multi-domain pre-training, and subsequently adapts to cross-domain tasks through either fine-tuning a classification head or prompt tuning. We opt for fine-tuning as it yields superior performance. 

Note that the above graph pre-training and cross-domain approaches are originally designed for pre-training on a single source domain. For a fair comparison, we directly merge the multi-domain graphs and apply dimension alignment for them, as in \model.
Further descriptions of the baselines are provided in Appendix~\ref{app.baselines}, with implementation details in Appendix~\ref{app.parameters}.



\subsection{Performance Evaluation}\label{sec.exp.per}
We first compare \model\ and the baseline methods on one-shot node and graph classification tasks, and then investigate the effect of increasing the number of shots.


\stitle{One-shot performance.}\label{exp.main}
Tables~\ref{table.node-classification} and~\ref{table.graph-classification} show the results of one-shot node and graph classification tasks. 
We observe that, first, \model\ achieves outstanding performance in both node and graph classification across various target domains, demonstrating the effectiveness of our proposed structure tokens in multi-domain pre-training and dual prompts in cross-domain adaptation. We defer analysis of the quantitative contributions of these components to the ablation studies in Sect.~\ref{sec.ablation}.
Second, another text-free multi-domain pre-training method, GCOPE, significantly lags behind \model\ because it only performs alignment and adaptation on feature and  homophily patterns, without accounting for structural differences across domains.
This further emphasizes the importance of our structure tokens and dual prompts.
Third, graph pre-training methods generally outperform the end-to-end GCN and GAT, showcasing the benefits of pre-training on unlabeled graphs.


\stitle{Few-shot performance.}
To evaluate the performance of \model\ with more labeled data, we vary the number of shots, $m$, in both node and graph classification tasks. We compare \model\ to two competitive baselines, \method{GraphPrompt} and \method{GCOPE}, with results reported in Fig.~\ref{fig.fewshot}, where error bars represent the standard deviation. We observe that \model\ consistently outperforms the baselines in low-shot settings (\eg, $m\le 5$). When further increasing the number of shots, \model\ still performs best in general, although it may be on par with \method{GCOPE} in some cases when $m$ approaches 10. This is not surprising, since the advantage of \model\ may diminish as more supervision becomes available.

\begin{figure}[tbp]
\centering 
\includegraphics[width=1\linewidth]{figures/fewshot.pdf}%
 \vspace{-3mm}%
\caption{Impact of number of shots on node and graph classification on four target domains.}
\label{fig.fewshot}
\end{figure}

%Its performance is  demonstrating the robustness of \model\ when 


% \begin{figure}[t]
% \centering 
% \includegraphics[width=0.5\linewidth]{figures/data_ablation.pdf}
% \caption{Data ablation study with an increasing number of source domains.}
% \label{fig.data-ablation}
% \end{figure}




\subsection{Ablation Studies}\label{sec.ablation}
To understand the impact of each component in \model, we perform two ablation studies.

\stitle{Data ablation.}
We evaluate the impact of incorporating more source domains by incrementally adding \textit{Citeseer}, \textit{LastFM}, \textit{Photo}, and \textit{Facebook}, in this order, to the pre-training, while fixing \textit{Cora} as the target domain. 
We present one-shot node classification performance of \model\ and two competitive baselines, namely, \method{GraphPrompt} and \method{GCOPE}, in Table~\ref{table.data-ablation}. Across the columns, 1 represents using \textit{Citeseer} as the single source domain, while 2 represents using \textit{Citeseer} and \textit{LastFM} as the source domains, \etc 

\begin{table}[tbp] % [!t]
    \centering
    \small
     \addtolength{\tabcolsep}{-0.5mm}
    \caption{Data ablation study with an increasing number of source domains, while fixing \emph{Cora} as the target domain.
    }
   %  \vspace{-2mm}
    \label{table.data-ablation}%
    \resizebox{1\linewidth}{!}{%
    \begin{tabular}{l|cccc}
    \toprule
   \multirow{2}*{Method} &\multicolumn{4}{c}{Number of source domains}\\   & 1 & 2 & 3 & 4
      \\\midrule%\midrule
    \method{GraphPrompt}
    & 35.53\text{\scriptsize ±12.06}
    & 37.13\text{\scriptsize ±11.79}
    & 36.90\text{\scriptsize ±11.23}
    & 38.54\text{\scriptsize ±11.84}  
\\
    \method{GCOPE}
    & 39.47\text{\scriptsize ±12.14}
    & 36.63\text{\scriptsize ±\phantom{0}9.46}
    & 35.28\text{\scriptsize ±11.99}
    & 38.61\text{\scriptsize ±12.74}
 \\
      \method{\model}
    & \textbf{40.43}\text{\scriptsize ±11.00}
    & \textbf{41.97}\text{\scriptsize ±11.01}
    & \textbf{42.30}\text{\scriptsize ±11.56}
    & \textbf{45.95}\text{\scriptsize ±12.96}
\\    \bottomrule
        \end{tabular}}
\end{table}



\begin{table*}[tbp]
    \centering
    \small
    \addtolength{\tabcolsep}{0.5mm}
    \caption{Model ablation study on key components of \model.}
    % \vspace{-2mm}
    \label{table.ablation}%
    %\resizebox{1\linewidth}{!}{%
    \begin{tabular}{c|ccc|ccc|ccc}
    \toprule
    \multirow{2}*{Methods}
    & Structure & Holistic & Specific &\multicolumn{3}{c|}{Target domain for node classification} &\multicolumn{3}{c}{Target domain for graph classification}\\
    &tokens &prompts &prompts & Cora & Photo & Facebook & Cora & Photo & Facebook\\
    \midrule%\midrule
    \method{Variant 1}
    & $\times$ & $\times$ & $\times$ 
    &36.36 $\pm$ 12.71 & 49.10 $\pm$ \phantom{0}9.94 & 35.36 $\pm$ \phantom{0}9.06
    & 45.44 $\pm$ 13.47 & 52.45 $\pm$ 12.37 & 38.74 $\pm$ 10.26
    \\
    \method{Variant 2}
    & $\times$ & $\times$ & $\checkmark$ 
    &40.62 $\pm$ 11.79  & 56.23 $\pm$ \phantom{0}9.04  & 39.80 $\pm$ 10.39 
    &45.63 $\pm$ 13.52  & 57.78 $\pm$ 11.64  & 42.22 $\pm$ 10.95    \\ 
    \method{Variant 3} 
    & $\checkmark$ & $\times$ & $\times$
    & 44.26 $\pm$ 10.92  & 56.61 $\pm$ 10.14  & 41.11 $\pm$ \phantom{0}8.34 
    & 52.88 $\pm$ 12.25  & 58.14 $\pm$ 12.01  & 43.12 $\pm$ \phantom{0}9.76    \\  
    \method{Variant 4}
    & $\checkmark$ & $\checkmark$ & $\times$ 
    &46.10 $\pm$ 12.02  & 57.76 $\pm$ 10.00  & 40.46 $\pm$ \phantom{0}8.89
    &54.52 $\pm$ 14.32  & 58.12 $\pm$ 12.30  & 43.15 $\pm$ 10.12    \\ 
    \method{\model}
    & $\checkmark$ & $\checkmark$ & $\checkmark$
    &\textbf{47.80} $\pm$ 11.88 &
    \textbf{58.71} $\pm$ \phantom{0}8.69 &
    \textbf{42.70} $\pm$ \phantom{0}8.73 &
    \textbf{55.35} $\pm$ 13.62 & \textbf{58.75} $\pm$ 11.67&
    \textbf{43.71} $\pm$ \phantom{0}9.54 \\
    \bottomrule
    \end{tabular}%}
\end{table*}

We make the following observations. First, \model\ is superior across different numbers of source domains, demonstrating its robustness to varying  configurations of the source domains. Second, both \method{GraphPrompt} and \method{GCOPE} often perform worse as more datasets are added due to the negligence of  structural discrepancies in various domains. In contrast, \model\ exhibits consistent improvement with the addition of more source domains, validating the effectiveness of our structure alignment and adaptation.

\stitle{Model ablation.}
We analyze variants of \model\ by removing structure tokens, \op\ and \cp. We report the results of these variants and \model\ in Table~\ref{table.ablation}. 
Note that Variant 1, which lacks our structural alignment design, is equivalent to the feature alignment method MDGPT \cite{yu2024text}.

The results confirm that each component plays an important role.
First, the use of structure tokens is essential. Notably, Variant 3 consistently outperforms Variant 1 and 2, both of which do not employ structure tokens, demonstrating the effectiveness of structure tokens in aligning multi-domain structural knowledge.
Second, removing \cp\ leads to a drop in performance, evident from the superior accuracy of Variants 2 over Variant 1, and \model\ over Variant 4. This indicates the significance of leveraging source domain-specific structural knowledge for effective cross-domain adaptation. 
Third, \op\ prove to be useful, as Variant 4 often outperforms Variant 3, highlighting the significance of incorporating holistic multi-domain structural information via \op.
These key components together enable \model\ to achieve optimal performance. 


% \begin{table*}[tbp] % [!t]
%     \centering
%     \small
%     \caption{Accuracy (\%) of one-shot node and graph classification on seen domains.}
%     \label{table.seen-node-classification}%
%     \resizebox{0.8\linewidth}{!}{%
%     \begin{tabular}{l|ccc|ccc}
%     \toprule
%    \multirow{2}*{\tiny{Method} \textbackslash\ {\tiny{Target domain}}} &\multicolumn{3}{c|}{Node classification}  &\multicolumn{3}{c}{Graph classification} \\
%    & Cora & Photo & Facebook & Cora & Photo & Facebook
%       \\\midrule\midrule
%     \method{GraphPrompt}
%  & 38.00$\pm$10.47 
%  & 46.60$\pm$\phantom{0}7.99  
%  & 41.00$\pm$\phantom{0}8.86
 
%  & 40.32$\pm$14.07 
%  & 48.60$\pm$11.96
%  & \textbf{45.72}$\pm$11.45

% \\
%     \method{GCOPE}
%  & 37.56$\pm$12.10 
%  & 55.36$\pm$\phantom{0}9.09
%  & 41.98$\pm$\phantom{0}9.25
 
%  & 40.20$\pm$11.25
%  & 56.49$\pm$10.35
%  & 41.72$\pm$10.00
% \\
%     \method{\model}
%  & \textbf{\yu{42.53}}$\pm$11.93
%  & \textbf{61.40}$\pm$\phantom{0}8.93
%  & \textbf{\yu{42.50}}$\pm$\phantom{0}8.38
 
%  & \textbf{\yu{52.05}}$\pm$14.69
%  & \textbf{\yu{57.03}}$\pm$12.15
%  & \yu{43.48}$\pm$10.05
% \\    \bottomrule
%         \end{tabular}}
%         \\
% \end{table*}

% \subsection{\yu{Node Classification on Seen Domains}}\label{app.exp.seen}
% We further conduct one-shot node classification tasks on seen target domains. In this setup, we pre-train the graph encoder on all seven datasets, and evaluate node classification on a seen target domain: \textit{Cora}, \textit{Photo}, or \textit{Facebook}. The results for competitive baselines and \model\ are presented in Table~\ref{table.seen-node-classification}. We observe the same trends as those reported in Sect.~\ref{exp.main}, further demonstrating the robustness of \model\ in adaptation to both seen and unseen domains.

\begin{table}[tb]
    \centering
    \small
    \addtolength{\tabcolsep}{-.1mm}
    \caption{Analysis of one-shot node classification on homophilic and heterophilic graphs.}
   %  \vspace{-2mm}
    \label{table.homo-hetero}%
    %\resizebox{1\linewidth}{!}{%
    \begin{tabular}{@{}c|c|ccc@{}}
    \toprule
    Target & \multirow{2}*{Source domains} & \multicolumn{3}{c}{Accuracy (\%)} \\
    domain &  & \method{GraphPrompt} & GCOPE & \model  \\
    \midrule%\midrule
    Squi.
    & Cham., Corn., Cora &  
    18.98\text{\scriptsize ±4.89} & 18.98\text{\scriptsize ±4.75} & \textbf{20.43}\text{\scriptsize ±4.75} \\
    Corn.
    & Squi., Cham., Cora &
    29.67\text{\scriptsize ±8.36}  & 27.19\text{\scriptsize ±8.51} & \textbf{32.57}\text{\scriptsize ±8.68}\\
    Cham.
    & Squi., Corn., Cora &  
    23.28\text{\scriptsize ±4.63}  & 23.24\text{\scriptsize ±4.50} & \textbf{23.89}\text{\scriptsize ±4.91}\\   
    Facebook
    & Squi., Cora, Photo &  
    32.22\text{\scriptsize ±6.91}  & 35.81\text{\scriptsize ±7.89} & \textbf{41.10}\text{\scriptsize ±9.38}\\
    \bottomrule
    \end{tabular}\\%}
       \parbox{1\linewidth}{\footnotesize \ Squi., Cham., Corn. are short for Squirrel, Chameleon, and Cornell, respectively.}
\end{table}

\subsection{Homophily Sensitivity}\label{sec.hetero}
Apart from feature and structural differences, graphs also exhibit varying homophily and heterophily patterns based on whether linked nodes share the same attribute \cite{ma2021homophily,zhu2020beyond,yu2024non}. To further assess the robustness of \model\ across domains with varying homophily patterns, we conduct one-shot node classification on  homophilic (\textit{Cora}, \textit{Photo}, \textit{Facebook}) and heterophilic (\textit{Chameleon}, \textit{Cornell} and \textit{Squirrel}) graphs. Details about the heterophilic datasets are presented in Appendix~\ref{app.hetero}. 

We report the results in Table~\ref{table.homo-hetero} and observe that \model\ consistently surpasses \method{GraphPrompt} and \method{GCOPE}, regardless of whether the source or target domains are homophilic or heterophilic. 
These results further validate the efficacy of \model, demonstrating its ability to leverage multi-domain knowledge across a wide variety of graph domains. Note that we focus on the node classification task here, as homophily is defined based on node attributes, which directly impacts node-level tasks.





% \begin{figure*}[t]
% \centering
% \begin{minipage}[b]{0.36\textwidth}
% \centering
% \includegraphics[width=0.8\linewidth]{figures/data_ablation.pdf}
% \vspace{-2mm}
% \caption{Data ablation study with an increasing number of source domains.}\vspace{-2mm}
% \label{fig.ablation}
% \end{minipage}%
% \hspace{5.4mm}%
% \begin{minipage}[b]{0.6\textwidth}
% \centering
% \includegraphics[width=0.95\linewidth]{figures/alpha.pdf}
% \vspace{-5mm}
% \caption{Sensitivity study of $\alpha$.}\vspace{-2mm}
% \label{fig.para}
% \end{minipage}
% \end{figure*}


