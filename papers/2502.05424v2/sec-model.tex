\section{Proposed Approach: \model}

In this section, we present \model, beginning with an overview and then delving into the details of multi-domain pre-training and cross-domain adaptation.

\subsection{Overall Framework}
\model\ consists of two phases: multi-domain pre-training, and cross-domain adaptation, as shown in Fig.~\ref{fig.framework}.

In the pre-training phase, as depicted in Fig.~\ref{fig.framework}(a), we first align the feature distributions from multiple source domains following previous work \cite{zhao2024all,yu2024text}. 
Next, we introduce a set of \textit{structure tokens} designed to align the structural distributions across diverse domains. These tokens are domain-specific and are integrated into each layer of the graph encoder, modifying the structure-based aggregation at each layer. 
Finally, the structure token-enhanced graph encoder is pre-trained using a self-supervised loss  \cite{liu2023graphprompt}.
%based on a universal task template \cite{liu2023graphprompt}.

In the adaptation phase, as shown in Fig.~\ref{fig.framework}(b), we first align the feature dimension of the target domain with that of the source domains. Then, we introduce \textit{dual prompts}. The first type, \emph{\op}, are learnable vectors that integrate the target domain with the holistic structural knowledge from all source domains. The second type, \emph{\cp}, comprise learnable mixtures of pre-trained structure tokens that incorporate domain-specific topological information tailored to the target domain. These prompts are applied to each layer of the graph encoder to adjust the structure-based aggregation, while keeping the pre-trained weights of the graph encoder frozen. 
%facilitating cross-domain adaptation with lightweight tuning.

\subsection{Multi-domain Graph Pre-training with Structure Alignment}

As defined in Sect.~\ref{sec.pre.multi-domain}, we are given a set of pre-training graphs from multiple source domains, $\bG_S$. As both the features and structures of these domains can exhibit divergent distributions, effective integration of these multi-domain graphs requires aligning both.
As our work focuses on structure alignment, we follow previous feature alignment methods  \cite{zhao2024all,yu2024text}, as outlined in the preliminaries.  





\stitle{Structure alignment.}
Recall that in the graph encoder, node representations are updated layer-wise through a structure-based aggregation. Each layer captures different levels of structural information. For example, the first layer aggregates one-hop neighborhood information, while the second layer incorporates a broader two-hop neighborhoods. These layer-wise structural patterns may vary significantly across domains. 

Therefore, to unify the structural characteristics in multiple source domains, we introduce learnable \emph{structure tokens}. For each domain $D_{S_i}$, we inject a series of structure tokens $\bT_{S_i}=\{\Vec{t}^l_{S_i}:  l\in \{1,\ldots,L\}\}$ into the graph encoder, where $L$ denotes the number of layers. Specifically, when encoding the graph $G_i=(V_i,E_i,\tilde{\mathbf{X}}_i$) in $D_{S_i}$, we assign structure token $\Vec{t}^l_{S_i}$ to the $l$-th layer, guiding structure-based aggregation:
\begin{align}\label{eq:structure_aggregation}
    \vec{h}^l_{v} = \mathtt{Aggr}(\vec{h}^{l-1}_{v}, \{\Vec{t}^l_{S_i} \odot \vec{h}^{l-1}_{u} : u\in\bN_v\}; \theta^l),~\forall v\in V_i,
\end{align}
%\begin{align}\label{eq:structure_aggregation}
%    \vec{h}^l_{S_i,v} = \mathtt{Aggr}(\vec{h}^{l-1}_{S_i,v}, \{\Vec{t}^l_{S_i} \odot \vec{h}^{l-1}_{S_i,u} : u\in\bN_v\}; \theta^l),
%\end{align}
where $\odot$ represents element-wise multiplication. Note that the graph encoders for feature alignment and structure alignment on all graphs share the same parameters $\Theta$.
Let $\vec{H}^{\mathtt{SAL}}_{i}$ denote the structure-aligned output node embedding matrix for $G_i$ in $D_{S_i}$, following the aggregation in Eq.~\eqref{eq:structure_aggregation}.
In general, each source domain is attached with its own set of structure tokens,
which are applied to modify the aggregation on the graph in the corresponding domain. By stacking the structure-aligned output matrix across graphs in all domains, we obtain the overall structure-aligned embedding matrix,  
$\Vec{H}^\mathtt{SAL}= \mathtt{Stack}(\vec{H}^{\mathtt{SAL}}_{1},\ldots,\vec{H}^{\mathtt{SAL}}_{K})$.
%, defined as $\bT=\{\bT_{S_i}: \forall S_i \text{ s.t. } D_{S_i} \in \bD_{S}\}$. By applying these structure tokens to all source domains, we obtain the structure aligned embedding matrix  $\Vec{H}^\mathtt{SAL}_{S}$. These structure tokens modify the message passing of various domains in a structurally synergistic manner, allowing the pre-trained model to extract both a holistic and domain-specific structural knowledge from a wide range of source domains.

Finally, we fuse $\Vec{H}^\mathtt{SAL}$ with $\Vec{H}^{\mathtt{FAL}}$ in Eq.~\eqref{eq.pre-train.feature-align}  to obtain the multi-domain node embedding matrix $\vec{H}$, incorporating both feature and structure alignment, as shown below.
\begin{align}\label{eq.source-fusion}
    \vec{H}^{\mathtt{AL}} =\Vec{H}^{\mathtt{FAL}}+\alpha\Vec{H}^\mathtt{SAL},
\end{align}
where $\alpha>0$ is a hyperparameter.

\stitle{Pre-training loss.}\label{sec.pre-training}
We leverage a universal task template based on subgraph similarity calculation \cite{liu2023graphprompt,yu2023generalized}, which ensures compatibility across different tasks such as node classification and graph classification. %Note that our framework is flexible with other pre-training methods. 
As demonstrated in GraphPrompt+ \cite{yu2023generalized}, prevailing contrastive pre-training objectives can be unified under this template, making them suitable choices for the pre-training loss in \model. 
%This inherent compatibility of the pre-training task could enhance the model's ability to adapt seamlessly to diverse downstream tasks. 
In general, we can adopt the following form of contrastive loss in pre-training.
\begin{align}\label{eq:generalized_loss}
     \textstyle     \bL_\text{pre}(\bO;\Theta,\bT,\Psi)=-\sum_{o\in \bO}\ln\frac{\sum_{a\in \text{Pos}_o}\exp(\mathtt{sim}(\vec{h}_{a}, \vec{h}_{o})/\tau)}{\sum_{b\in \text{Neg}_o}\exp(\mathtt{sim}(\vec{h}_{b}, \vec{h}_{o})/\tau)},
\end{align}
where $\bO$ denotes the set of observed graph element in pre-training, $a\in\text{pos}_o,b\in\text{neg}_o$ represent the positive or negative instance of $o$, respectively, and $\vec{h}_o,\vec{h}_a,\vec{h}_b$ are their corresponding embeddings. 
Furthermore, $\mathtt{sim}(\cdot,\cdot)$ is a similarity function, such as cosine similarity \cite{rahutomo2012semantic} in our implementation, and $\tau>0$ is a temperature hyperparameter. 
Note that \model\ is flexible in the materialization of $o,a,b$ to realize different contrastive losses \cite{yu2023generalized}. Our experiments adopt GraphCL \cite{you2020graph}, where \( o \) is the original graph \( G \), and \( a,b \) represent two different augmentations of  \( G \).
Hence, $\vec{h}_o,\vec{h}_a,\vec{h}_b$ are the corresponding graph embeddings, which can be obtained through a readout operation \cite{liu2023graphprompt} on the aligned node embeddings in $\mathbf{H}^{\mathtt{AL}}$.
%\( o \) represents an augmented graph \( G' \), \( a \) is the original graph \( G \), and \( b \) is a another augmented graph of \( G'' \).

The pre-training loss is optimized by updating the weights of graph encoder $\Theta$, structure tokens across all source domains %$\bT=\{\bT_{S_i}: \forall S_i \text{ s.t. } D_{S_i} \in \bD_{S}\}$, 
$\bT=\{\bT_{S_1},\ldots,\bT_{S_K}\}$, and feature alignment parameters $\Psi$.
%, namely, $(\Theta_\text{pre},\bT_\text{pre},\Psi_\text{pre})=\arg\min_{\Theta,\bT,\Psi} \mathcal{L}_{\text{pre}}(\Phi_\text{pre};\Theta,\bT,\Psi)$, which are further employed in downstream adaptation.

% Let $\vec{h}_{S,v}$ denote the output embedding of node $v$ from the graph encoder, and $Z_v$ be a subgraph of node $v$ and $Z_G$ be the graph $G$. 
% We define $z_{S,x}$ as the embedding of $Z_x$ by readout $\{\vec{h}_{S,v}:v~\text{in}~Z_x\}$. %Note that a node's smallest subgraph is itself, where $z_{S,x}=\vec{h}_{S,x}$.
% The readout function can be sum pooling, mean pooling and more complex strategies. Then, we define the generalized pre-training loss as follows.
% \begin{align}\label{eq:generalized_loss}
%      \textstyle
%      \bL_\text{pre}(\Phi_\text{pre};\Theta,\bT,\Psi)=-\sum_{o\in \Phi_\text{pre}}\ln\frac{\sum_{a\in Pos_o}\exp(\mathtt{sim}(\vec{z}_{a}, \vec{z}_{o})/\tau)}{\sum_{b\in Neg_o}\exp(\mathtt{sim}(\vec{z}_{b}, \vec{z}_{o})/\tau)},
% \end{align}
% where $\Phi_\text{pre}$ denotes the pre-training datasets. $o$ is the target node/graph, $a,b$ represent the positive or negative samples of $o$. $\mathtt{sim}(\cdot,\cdot)$ is a similarity function, such as cosine similarity \cite{rahutomo2012semantic} in our experiments. $\tau$ is a temperature hyperparameter. In our experiment, we utilize GraphCL \cite{you2020graph} as the pre-training task, where \( o \) represents an augmented graph \( G \), \( a \) is the original graph \( G \), and \( b \) is a another augmented graph of \( G \) by a different augmentation.
% The pre-training loss is optimized by updating the weights of graph encoder $\Theta$, domain tokens $\bT$, and learnable parameters $\Psi$ in feature alignment method, namely, $(\Theta_\text{pre},\bT_\text{pre},\Psi_\text{pre})=\arg\min_{\Theta,\bT,\Psi} \mathcal{L}_{\text{pre}}(\Phi_\text{pre};\Theta,\bT,\Psi)$, which are further employed in downstream adaptation.


\subsection{Cross-domain Structure Adaptation}
Beyond multi-domain pre-training, another challenge lies in cross-domain adaptation. Given a model pre-trained on graphs $\bG_S$ from source domains $\bD_S$, we aim to adapt it to a downstream task on graphs $\bG_T$ from a target domain $D_T \notin \bD_S$. 
As this work focuses on structure adaptation, we directly apply previous work  \cite{yu2024text} for feature adaptation, as outlined in Sect.~\ref{sec:problem_definition}. 

For structure adaptation, we propose \emph{dual prompts}, consisting of \emph{\op} and \emph{\cp}. On one hand, the \op\ are designed to holistically utilize the pre-trained structural knowledge from all source domains. On the other hand, the \cp\ combine multi-domain structure tokens through a learnable mixture, adapting fine-grained, domain-specific structural knowledge to the target domain.


% As both the features and structures of these domains can exhibit divergent distributions, effective integration of these multi-domain graphs requires aligning both.
% As our work focuses on structure alignment, we simply follow previous works \cite{zhao2024all,yu2024few} for feature alignment. 

% , our objective extends to bridge the gap between source and target domains. Previous works solely leverage feature adaptation, failing to narrow the structural gap \cite{zhao2024all}. Therefore, we propose a novel structure adaptation strategy and integrate feature adaptation technique.

% For feature adaptation, we first employ the same dimension alignment method as used in the pre-training phase. Given a downstream graph $G=(V,E,\Vec{X}) \in \bG_T$ from target domain $D_T$, we transform its feature matrix to $\tilde{\Vec{X}}=\mathtt{DA}_T(\Vec{X})$. We then cooperate a feature adaptation technique to align the target domain feature semantics with the source domains as follow.
% \begin{align}\label{eq.feature-emb}
%     \Vec{H}_\text{feat} = \mathtt{GE}(\mathtt{SAG}(\bG,\tilde{\Vec{X}};\Gamma);\Theta_\text{pre}),
% \end{align}
% where $\mathtt{SAG}$ represents the feature adaptation method, and $\Gamma$ denotes the learnable parameters in $\mathtt{SAG}$.


\stitle{Holistic prompts.} 
To transfer the holistic multi-domain structural knowledge to a downstream task, we propose a set of \op\ designed to align the target domain \( D_T \) with the model pre-trained on the source domains \( \bD_S \). %Given a graph \( G_T = (V_T, E_T, \Vec{X}_T) \) from \( D_T \), 
Like any pre-training framework, we encode a downstream graph $G=(V,E,\tilde{\vec{X}})$ using the pre-trained graph encoder with frozen layer-wise weights $\Theta_\text{pre}=\{\theta^1_\text{pre},\ldots,\theta^L_\text{pre}\}$. 
However, the key difference is that we inject a series of learnable vectors \( \bP_\text{hol} = \{ \Vec{p}^1_\text{hol},  \ldots, \Vec{p}^L_\text{hol} \} \) as \op\ into the downstream structure-based aggregation:
\begin{align}\label{eq.open-prompt}
    \vec{h}^l_{v} = \mathtt{Aggr}(\vec{h}^{l-1}_{v}, \{\Vec{p}^l_\text{hol} \odot \vec{h}^{l-1}_{u} : u\in\bN_v\}; \theta^l_\text{pre}),~\forall v\in V.
\end{align}
The final layer outputs a holistic node embedding matrix for the downstream graph $G$, denoted as \( \vec{H}^\text{hol}\).
%\( \vec{H}^\text{hol}=\mathtt{STACK}(\vec{\tilde{h}}_{v}:~\forall v\in G_T) \).

\stitle{Specific prompts.}
In contrast to the \op, \cp\ are designed to adapt structural knowledge specific to each source domain. Since knowledge from related source domains is likely to be more applicable, it is essential to align the target domain with different source domains to varying extents, prioritizing the most relevant ones. Consequently, we define \cp\ as \( \bP_\text{spe} = \{ \Vec{p}^1_\text{spe}, \ldots, \Vec{p}^L_\text{spe} \} \), which will also be injected into different layers of the pre-trained graph encoder. Specifically, in the $l$-th layer, \( \Vec{p}^l_\text{spe} \) is a combination of \( \{ \vec{t}^l_{S_1},\ldots,\vec{t}^l_{S_K}\} \), the pre-trained structure tokens in the corresponding layer 
%\( \bT^l_\text{pre} = \{ t^l_{S_i} \mid \forall S_i, \text{s.t.}~D_{S_i} \in \bD_{S} \} \), 
 across all source domains $D_{S_i} \in \bD_{S}$.
%which are integrated into the \( l \)-th layer of the pre-trained graph encoder. %The \cp\ serve as intermediate prompts, balancing between hard and soft prompts \cite{liu2023pre}, by utilizing pre-trained tokens alongside learnable fusion coefficients in downstream tasks. 
Formally, we define
\begin{align}\label{eq.specific-prompt-generation}\textstyle
\Vec{p}^l_\text{spe} = \sum_{i=1}^K \lambda^l_i \Vec{t}^l_{S_i},
\end{align}
where \( \Lambda^l = \{ \lambda^l_1, \ldots, \lambda^l_K \} \) are learnable coefficients. Thus, the full set of learnable parameters for the \cp\ is \( \Lambda = \{ \Lambda^1, \ldots, \Lambda^L \} \). Subsequently, \cp\ modify the structure-based aggregation in the same way as in Eq.~\eqref{eq.open-prompt}, while freezing the pre-trained weights of the graph encoder. Similarly, we denote the output node embedding matrix based on the specific prompts as \( \vec{H}^\text{spe} \).

\stitle{Prompt tuning.}
To leverage both holistic multi-domain and domain-specific structural knowledge from the pre-trained model, we fuse the output embedding matrices obtained via \op\ and \cp\ as follows.
\begin{align}\label{eq.structure-emb}
    \vec{H}^\mathtt{SAD} =\vec{H}^\text{hol}+\beta\vec{H}^\text{spe},
\end{align}
where $\beta>0$ is a hyperparameter. 
Further incorporating feature adaptation in Eq.~\eqref{eq.feature-emb}, 
we obtain the overall node embedding matrix with both feature and structure adaptations, given by
%and structure-level adapted embeddings $\vec{H}^\text{SAD}$ from Eq.~(\ref{eq.structure-emb}) as follow.
\begin{align}\label{eq.down-fusion}
    \vec{H}^\mathtt{AD} =\vec{H}^\mathtt{FAD}+\alpha\vec{H}^\mathtt{SAD}.
\end{align}
Here, $\alpha$ is the same hyperparameter used in Eq.~\eqref{eq.source-fusion}, as both share the objective of integrating the feature and structure counterparts.

For downstream node and graph classification tasks, the loss function \( \mathcal{L}_\text{down} \) is formulated based on the same task template with subgraph similarity \cite{liu2023graphprompt}, akin to the pre-training loss \( \mathcal{L}_\text{pre} \). Let \( \Omega = \{(x_1, y_1), (x_2, y_2), \ldots\} \) represent the labeled training set, where each \( x_i \) is either a node or graph instance, and \( y_i \in Y \) is its respective class from the set \( Y \). Subsequently, we optimize the following cross-domain adaptation loss:
\begin{align}\label{eq.downstream_loss}\textstyle
    \bL_\text{down}(\Omega;\bP_\text{hol},\Lambda,\Gamma)=-\sum_{(x_i,y_i)\in \Omega}\ln\frac{\exp(\text{sim}(\vec{h}_{x_i},{\vec{h}}_{y_i})/\tau )}{\sum_{y\in Y}\exp(\text{sim}(\vec{h}_{x_i},{\vec{h}}_{y})/\tau )}.
\end{align}
Here, $\vec{h}_{x_i}$ represents the adapted embedding of the node or graph $x_i$ based on $\vec{H}^\mathtt{AD}$, 
where a readout operation on $\vec{H}^\mathtt{AD}$ is required if $x_i$ is a graph. 
Additionally, ${\vec{h}}_y$ denotes the prototype embedding for class $y$, which is calculated as the average embeddings of all training instances of class $y$. %For a node $v$, $\vec{\hat{h}}_{v}$ is a row of $\Vec{\hat{H}}$. 

We outline the key steps for prompt tuning in Algorithm~\ref{alg.prompt}, Appendix~\ref{app.alg} and assess its complexity in Appendix~\ref{complexity}.
