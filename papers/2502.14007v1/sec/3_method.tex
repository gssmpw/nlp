\section{Method}
\label{sec:method}

\subsection{Preliminaries}\label{sec:method_preliminaries}
\textbf{Diffusion models:} A Denoising Diffusion Probabilistic Model (DDPM) defines a Markov chain that learns to generate samples to match the input data distribution over a finite time. The process consists of \emph{forward diffusion} that iteratively perturbs an input by adding noise according to a scheduler, followed by \emph{backward denoising} that learns to reverse the mapping to recover the original input from noise. Given a data distribution $x_0 \sim q(x_0)$, the \emph{forward diffusion} defines an iterative noising process $q$ that adds Gaussian noise over $T$ finite steps, gradually perturbing the input sample $x_0$ to produce latents $\{x_1, ..., x_T\}$ as follows.

\begin{equation}\label{eq:eq1}
  q(x_1, ..., x_T | x_0) := \prod_{t=1}^{T} q(x_t | x_{t-1})
\end{equation}

\begin{equation}\label{eq:eq2}
  q(x_t | x_{t-1}) := \mathcal{N}(x_t; \sqrt{1-\beta_t} ~x_{t-1}, \beta_t \mathbf{I})
\end{equation}

\noindent
where $\beta_t \in (0, 1)$ denotes the variance of the Gaussian noise at time $t \sim [1, T]$. Rewriting Eq. \ref{eq:eq2} with $\alpha_t = 1 - \beta_t$ and $\overline{\alpha}_t = \prod_{i=1}^{t} \alpha_i$, Ho \emph{et al.} \cite{ho2020denoising} deduced a closed-form expression to sample an arbitrary step of the noising process, directly estimating $x_t$ from $x_0$ as the following marginal distribution.

\begin{equation}\label{eq:eq3}
  q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\overline{\alpha}_t} ~x_0, (1-\overline{\alpha}_t) \mathbf{I})
\end{equation}

\noindent
With sufficiently large $T$ and a well-defined schedule of $\beta_t$, the latent $x_T$ closely resembles a Gaussian distribution. If the reverse distribution $q(x_{t-1} | x_t)$ is known, sampling $x_T \sim \mathcal{N}(0, \mathbf{I})$ and iteratively running the process in reverse can yield a sample from $q(x_0)$. However, as $q(x_{t-1} | x_t)$ depends on the entire data distribution, the \emph{backward denoising} process can be approximated by a learnable network, parameterized with $\theta$, as follows.

\begin{equation}\label{eq:eq4}
  p_\theta(x_{t-1} | x_t) := \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
\end{equation}

\noindent
Ho \emph{et al.} \cite{ho2020denoising} also observed that learning to predict the added noise $\epsilon \sim \mathcal{N}(0, \mathbf{I})$ worked best for estimating $x_0$ with the following formulation.

\begin{equation}\label{eq:eq5}
  x_0 = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}} ~\epsilon \right)
\end{equation}

\noindent
Most implementations adopt a U-Net architecture (parameterized with $\theta$) to predict the added noise, minimizing mean squared error as the learning objective.

\begin{equation}\label{eq:eq6}
  \mathcal{L}_{DM} = \mathbb{E}_{t \sim [1, T], ~x_0 \sim q(x_0), ~\epsilon \sim \mathcal{N}(0, \mathbf{I})} \bigg[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \bigg]
\end{equation}

\subsection{Latent Code Translation Network (LCTN)}\label{sec:method_lctn}
We propose a learnable Latent Code Translation Network (LCTN) to shift the input latent space toward the target domain by exploiting the learned feature representations of a pre-trained Latent Diffusion Model (LDM) \cite{rombach2022high}. LCTN is trained with edge maps \cite{su2021pixel} instead of hand-drawn sketches to mitigate the structural ambiguities that arise from freehand sketches. Our experiments show that LCTN trained on edge maps works appreciably well during inference with freehand sketches. Given an image $x$, corresponding edge map $e$, and object class name $c$, we use the pre-trained image encoder $\mathcal{E}$ and text encoder $\mathcal{T}$ of LDM to compute the initial latent codes as, $\overline{x} = \mathcal{E}(x)$, $\overline{e} = \mathcal{E}(e)$, and $\overline{c} = \mathcal{T}(c)$. The input feature space $F$ is computed from the intermediate activation maps of LDM U-Net $\epsilon_\theta$, rescaled to have the same spatial dimensions, with a single denoising pass of $\overline{e}$ at timestep $t = 0$ using $\overline{c}$ as conditioning, $F = f_{\epsilon_\theta}(\overline{e}, \overline{c}, t)$. LCTN learns to project $F$ into the target latent code $z_0$ by minimizing the mean squared error, $\mathcal{L}_{LCTN} = \|z_0 - \overline{x}\|^2$. Architecturally, LCTN consists of a sequence of fully connected (FC) layers with 512, 256, 128, and 64 nodes, with each FC layer followed by ReLU activation and batch normalization. We illustrate the proposed training strategy for LCTN in Fig. \ref{fig:lctn_training}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/2_lctn_training.pdf}
  \caption{Proposed training strategy for the Latent Code Translation Network (LCTN).}
  \label{fig:lctn_training}
\end{figure}

\noindent
Ideally, if the domain translation by LCTN is accurate, we can readily decode $z_0$ into a high-quality photorealistic image using the pre-trained LDM decoder $\mathcal{D}$. However, due to high sparsity in the input edge maps (or sketches), LCTN-projected latent code lacks sufficient subtlety, leading to unrealistic images from direct decoding. We address the issue by first perturbing $z_0$ to $z_k$ over $k \sim [1, T]$ steps, where $1 < k < T$, followed by $T$ denoising iterations to get $\overline{z}_0$ from $z_k$. With a sufficiently large value of $k$, $z_k$ is close to an isotropic Gaussian distribution, $z_k \approx z_T \sim \mathcal{N}(0, \mathbf{I})$. However, strictly enforcing $k < T$ ensures minimal structural elements are retained in $z_k$. We observe that starting the backward denoising from $z_k$ instead of $z_T$ as the initial latent, followed by decoding the final latent $\overline{z}_0$, can produce photorealistic images while retaining the intended structural resemblance with the input edge map (or sketch). In our experiments, $0.7 \leqslant \frac{k}{T} \leqslant 0.9$ works best for most cases. We illustrate the proposed sampling strategy for LCTN in Fig. \ref{fig:lctn_sampling}.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/3_lctn_sampling.pdf}
  \caption{Proposed sampling strategy for the Latent Code Translation Network (LCTN).}
  \label{fig:lctn_sampling}
\end{figure}
