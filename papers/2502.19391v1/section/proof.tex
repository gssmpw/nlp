In this section, we present the proofs of theorems in this paper, beginning with formal definitions of SE(3) equivariance and SE(3) invariance.


\subsubsection{Preliminaries}
\label{appendix-sec:subsec-e3-def}
\begin{definition}[E(3)-equivariance and SE(3)-invariance]
\label{def:e3-equiv-inv}
Let $\varphi : \mathcal{X} \to \mathcal{Y}$ be a mapping function, and let $T \in E(3)$ denote a rigid transformation in three-dimensional space comprising rotation and reflection, $\vect{Q} \in O(3)$ and a translation $\vect{b}\in\mathbb{R}^3$. The transformation acts on coordinates as:
$$
   T(\vect{X}) := \vect{Q}\vect{X} + \vect{b}, 
   \quad \vect{Q} \in O(3), \vect{b} \in \mathbb{R}^3.
$$
Then:
\begin{itemize}[topsep=0.5mm, partopsep=0pt, itemsep=0pt, leftmargin=10pt]
    \item \(\varphi\) is \textbf{E(3)-equivariant}, if for any transformation $\vect{X}\mapsto \vect{X}_{\text{out}} = \varphi(\vect{X})$, we have $T(\vect{X}_{\text{out}}) = \varphi\bigl(T(\vect{X})\bigr)$.
    \item \(\varphi\) is \textbf{E(3)-invariant} if $\varphi \bigl(T ( \vect{X})\bigr) = \varphi(\vect{X})$ for all \(T\in \mathrm{E}(3)\), i.e. $T$ acts as identity transformation in the output space.
\end{itemize}
\end{definition}

In our model architecture, 3D coordinates are E(3)-equivariant, meaning they transform consistently with input transformations, while residue embeddings demonstrate E(3)-invariance, remaining unchanged under rigid transformations. 

{\bf Notations.} Next, we summarize the notations used throughout our analysis.
\begin{itemize}[topsep=0.5mm, partopsep=0pt, itemsep=0pt, leftmargin=10pt]
    \item Let $\{(\vect{H}_i^{(l)}, \vect{X}_i^{(l)})\}_{i=1}^n$ denote the residue embeddings \(\vect{H}_i^{(l)} \in \mathbb{R}^d\) and 3D coordinates $\vect{X}_i^{(l)} \in \mathbb{R}^3$ at layer $l$.  
    \item Let $\vect{H}_{e_{ij}}^{(l)}$ be the edge feature between residues $v_i$ and $v_j$ at layer $l$.  
    \item Let $T(\vect{X}) := \vect{Q}\vect{X} + \vect{b}$ denote a rigid transformation in $E(3)$.
\end{itemize}

Below, we will show that Igformer maintains coordinate equivariance and embedding invariance under these transformations at each layer, following Definition~\ref{def:e3-equiv-inv}.

\subsubsection{E(3)-Equivariance of the Coordinates}

We begin by establishing the E(3)-equivariance property of coordinate predictions in the EMP module.  

\begin{lemma}[Linear Transformation of Coordinate Differences]
\label{lemma:deltaX}
    For coordinates differences \(\Delta \vect{X}_{ij}^{(l)} := \vect{X}_i^{(l)} - \vect{X}_j^{(l)}\), applying \(T\in E(3)\) to coordinates:
    $
       \widetilde{\vect{X}}_i^{(l)} = T(\vect{X}_i^{(l)}) 
       = \vect{Q}\,\vect{X}_i^{(l)} + \vect{b},
    $
    results in  
    $
       \Delta \widetilde{\vect{X}}_{ij}^{(l)} = \vect{Q}\,\Delta \vect{X}_{ij}^{(l)}.
    $
\end{lemma}

\begin{proof}
By direct substitution:
\[
  \widetilde{\vect{X}}_i^{(l)} - \widetilde{\vect{X}}_j^{(l)}
  = (\vect{Q}\vect{X}_i^{(l)} + \vect{b}) - (\vect{Q}\vect{X}_j^{(l)} + \vect{b})
  = \vect{Q}\bigl(\vect{X}_i^{(l)} - \vect{X}_j^{(l)}\bigr) = \vect{Q}\Delta \vect{X}_{ij}^{(l)}.
\]
The translation $\vect{b}$ cancels, leaving only the rotation $\vect{Q}$.
\end{proof}

\begin{lemma}[Geometry-Based Operations]
\label{lemma:geom-invariant}
    Geometric Operations in Igformer, including pairwise distances $\|\vect{X}_i - \vect{X}_j\|$, dot products, and dihedral angles, remain invariant under any $T \in E(3)$.
\end{lemma}

\begin{proof}
   A translation $\vect{b}$ always cancels in $\vect{X}_i - \vect{X}_j$.  A rotation $\vect{Q}\in O(3)$ preserves Euclidean norms and dot products:$ \|\vect{Q}\vect{v}\|^2 = \|\vect{v}\|^2$. Therefore, all geometric operations remain invariant under $T$.
\end{proof}

\begin{theorem}[E(3)-Equivariance of Coordinates in EMP]
\label{thm:coord-equivar}
    At layer \(l\), Igformer updates coordinates through the following sequential operations:
    \begin{align*}
      \vect{S}_{ij}^{(l)} 
       &= \textit{MLP}\bigl(\|\Delta \vect{X}_{ij}^{(l)}\|^2,\,\dots\bigr), \quad \text{(geometry-based score)} \\
      \vect{H}_{e_{ij}}^{(l+1)} 
       &= \textit{EdgeMLP} \left(\vect{H}_i^{(l)} \oplus \vect{H}_j^{(l)} \oplus \vect{S}_{ij}^{(l)} \oplus \vect{H}_{e_{ij}}^{(l)} \right), \\
      \vect{X}_i^{(l+1)}
       &= \vect{X}_i^{(l)} + \sum_{j\in \mathcal{N}(i)}
            \Delta \vect{X}_{ij}^{(l)} \cdot
            \textit{CoordMLP}\bigl(\vect{H}_{e_{ij}}^{(l+1)}\bigr).
    \end{align*}
    This update rule is E(3)-equivariant on coordinates. Concretely, applying $T$ to input coordinates $\{\vect{X}_i^{(l)}\}$ results in the same transformation $T$ being applied to output coordinates $\{\vect{X}_i^{(l+1)}\}$.
\end{theorem}

\begin{proof}
By Lemma~\ref{lemma:geom-invariant}, $\vect{S}_{ij}^{(l)}$ and consequently $\vect{H}_{e_{ij}}^{(l+1)}$ remain unchanged when input coordinates are transformed by $T$. 
%$\vect{X}_i^{(l)}$ is replaced by $Q\,\vect{X}_i^{(l)}+\vect{t}$.  
Let
$
   \vect{w}_{ij}^{(l+1)} := \textit{CoordMLP}\bigl(\vect{H}_{e_{ij}}^{(l+1)}\bigr).
$
Then:
$$
   \vect{X}_i^{(l+1)} = \vect{X}_i^{(l)} + \sum_{j\in \mathcal{N}(i)}
   \Delta \vect{X}_{ij}^{(l)} \cdot \vect{w}_{ij}^{(l+1)}.
$$
Under transformation $T: \vect{X}_i^{(l)}\mapsto \vect{Q}\vect{X}_i^{(l)}+\vect{b}$, we have:
$$
\begin{aligned}
   \widetilde{\vect{X}}_i^{(l+1)}
   &= \widetilde{\vect{X}}_i^{(l)}
      + \sum_{j\in\mathcal{N}(i)}
        \bigl[\widetilde{\vect{X}}_i^{(l)} - \widetilde{\vect{X}}_j^{(l)}\bigr]
        \cdot \vect{w}_{ij}^{(l+1)}
   \quad &\bigl(\text{same } \vect{w}_{ij}^{(l+1)}\bigr) 
   \\[4pt]
   &= (\vect{Q}\vect{X}_i^{(l)}+\vect{b})
      +
      \sum_{j\in\mathcal{N}(i)}
        \Bigl[\vect{Q}(\vect{X}_i^{(l)}-\vect{X}_j^{(l)})\Bigr]
        \cdot \vect{w}_{ij}^{(l+1)}
   &\bigl(\text{Lemma~\ref{lemma:deltaX}}\bigr)
   \\[4pt]
   &= \vect{Q}\,\vect{X}_i^{(l)} + \vect{b}
      + \vect{Q}\sum_{j\in\mathcal{N}(i)}
          (\vect{X}_i^{(l)} - \vect{X}_j^{(l)}) \cdot \vect{w}_{ij}^{(l+1)}
   \\[4pt]
   &= \vect{Q} \Bigl[\vect{X}_i^{(l)}
       + \sum_{j\in\mathcal{N}(i)}
         \Delta \vect{X}_{ij}^{(l)} \cdot \vect{w}_{ij}^{(l+1)}\Bigr]
       + \vect{b}
   \\[2pt]
   &= \vect{Q}\vect{X}_i^{(l+1)} + \vect{b} = T\bigl(\vect{X}_i^{(l+1)}\bigr).
\end{aligned}
$$
Therefore, applying $g$ to input coordinates leads to $T\bigl(\vect{X}_i^{(l+1)}\bigr)$ in output coordinates. By induction over all layers, Igformer maintains E(3)-equivariance through its coordinate computation in the EMP module.
\end{proof}



\subsubsection{E(3)-Invariance of the Residue Embeddings}

We now prove that residue embeddings $\vect{H}_i$ remain numerically invariant under global rigid transformation of the input 3D structure.

\begin{lemma}[Base Case for Embedding Invariance]
\label{lemma:base-embed}
    Residue embeddings \(\vect{H}_i^{(0)}\) are initialized using rigid independent features like residue identity, positional index, etc., making them inherently invariant under any transformation $T\in \mathrm{E}(3)$.
\end{lemma}

\begin{lemma}[Edge Feature Update Invariance]
\label{lemma:edge-MLP}
For edge updates of the form:
$$
   \vect{H}_{e_{ij}}^{(l+1)} =
   \textit{EdgeMLP}\Bigl(
      \vect{H}_i^{(l)} \oplus
      \vect{H}_j^{(l)} \oplus
      S_{ij}^{(l)} \oplus
      \vect{H}_{e_{ij}}^{(l)}
   \Bigr),
$$
where $\vect{S}_{ij}^{(l)}$ represents geometry operations (distance, dot product, etc.). If \(\vect{H}_i^{(l)}, \vect{H}_j^{(l)}\) are invariant and $\vect{S}_{ij}^{(l)}$ is unaffected by $T$ (Lemma~\ref{lemma:geom-invariant}), then \(\vect{H}_{e_{ij}}^{(l+1)}\) maintains invariance.
\end{lemma}

\begin{proof}
    The \textit{EdgeMLP} receives numerically identical inputs regardless of coordinate transformation $\vect{Q}\vect{X}_i^{(l)}+\vect{b}$, ensuring $\vect{H}_{e_{ij}}^{(l+1)}$ remains unchanged.
\end{proof}

\begin{theorem}[E(3)-Invariance of Residue Embeddings]
\label{thm:embed-inv}
    Given Igformer's residue embedding update rule:
    $$
      \vect{H}_i^{(l+1)} = \vect{H}_i^{(l)} + 
      \textit{NodeMLP}\Bigl(
        \vect{H}_i^{(l)} \oplus
        \sum_{j\in \mathcal{N}(i)} \vect{H}_{e_{ij}}^{(l+1)}
      \Bigr),
    $$
    or its self-attention variant, the embeddings $\vect{H}_i^{(l+1)}$ remain invariant under any global transformation $T\in \mathrm{E}(3)$. By extension, Igformer's final embeddings $\vect{H}_i$ maintain E(3)-invariance.
\end{theorem}

\begin{proof}
    We prove this theorem through induction:
    \textbf{Base Case.}  By Lemma~\ref{lemma:base-embed}, initial embeddings $\vect{H}_i^{(0)}$ are independent of 3D coordinates.  
    
    \textbf{Inductive Step.}  Assume $\{\vect{H}_i^{(l)}\}$ is already invariant under $T$. 
    \begin{itemize}[topsep=0.5mm, partopsep=0pt, itemsep=0pt, leftmargin=10pt]
        \item According to Lemma~\ref{lemma:geom-invariant}, any geometry-based scalar $\vect{S}_{ij}^{(l)}$ remain unchanged under $T$. 
        \item According to Lemma~\ref{lemma:edge-MLP}, edge features $\vect{H}_{e_{ij}}^{(l+1)}$ maintain invariance under $T$.
        \item Consequently, all inputs to the residue-level update MLP/attention remain unchanged under $T$. 
    \end{itemize}

    Therefore, $\vect{H}_i^{(l+1)}$ maintains invariance under $T$. By induction across layers, Igformer's residue embeddings are E(3)-invariant.
\end{proof}

{\bf Proof of Theorem~\ref{thm:thm1-emp}.}
Combining Theorems~\ref{thm:coord-equivar} and \ref{thm:embed-inv}, we show that coordinates in the EMP module are E(3)-equivariant and embeddings are E(3)-invariant, which finishes the proof of Theorem~\ref{thm:thm1-emp}.


\begin{lemma}
\label{lemma:igr-tmm}
    The embeddings updated by inter-graph refinement and triangle multiplicative module (TMM) modules are invariant.
\end{lemma}

\begin{proof}
    The APP and SGFormer components update embeddings through weighted aggregation:
    $\vect{H}_{i} = \sum_{j \in V}\vect{H}_j$ with residue connections. These operations are independent of coordinates $\vect{X}_i$. Given that $\vect{H}_i$ is invariant under transformation $T$, the MLP/attention operations preserve E(3)-invariance during embedding updates.

    The Triangle Multiplicative module processes pairwise embeddings $\vect{Z}_{ij} = \textit{MLP}(\vect{H}_i,\vect{H}_j)$ without direct dependence on coordinates $\vect{X}_i$. Since $\vect{H}_i$ maintains invariance under $T$, the pairwise features and subsequent internal operations (row/column gating/attention) on $\vect{Z}$ preserves E(3)-invariance. The merging of $\vect{Z}$ into ${\vect{H}_i}$ through MLP/attention operations maintains this invariance property.
\end{proof}





\subsubsection{Proof of Theorem~\ref{thm:thm-igformer}}

Combining Theorem~\ref{thm:coord-equivar}, Theorem~\ref{thm:embed-inv}, and Lemma~\ref{lemma:igr-tmm}, we conclude:

\begin{theorem}[Igformer is E(3)-Equivariant (Coordinates) and E(3)-Invariant (Embeddings)]
\label{thm:igformer-overall}
Let $\{\vect{H}_i^{(0)},\,\vect{X}_i^{(0)}\}_{i\in V}$ be the initial inputs (node features, coordinates). Suppose Igformer generetes final outputs as follows:
$$
  \bigl\{\vect{H}_i^{(\text{final})},\vect{X}_i^{(\text{final})}\bigr\}
  =
  \textit{Igformer} \Bigl(\bigl\{\vect{H}_i^{(0)},\vect{X}_i^{(0)}\bigr\}\Bigr).
$$
Then, for any $T \in \mathrm{E}(3)$, we have:
$$
  \bigl\{\vect{H}_i^{(\text{final})}, T\bigl(\vect{X}_i^{(\text{final})} \bigr) \bigr\}
  = \textit{Igformer}\Bigl( \bigl \{\vect{H}_i^{(0)}, T\bigl(\vect{X}_i^{(0)} \bigr) \bigr\} \Bigr).
$$
\end{theorem}

\begin{proof}
    The proof follows by chaining layer-wise properties:  
    \begin{itemize}[topsep=0.5mm, partopsep=0pt, itemsep=0pt, leftmargin=10pt]
        \item By Theorem~\ref{thm:coord-equivar}, the coordinate update at each layer maintains E(3)-equivariance. Through induction across layers, this property extends to the entire coordinate transformations.
        \item Similarly, Theorem~\ref{thm:embed-inv} and Lemma~\ref{lemma:igr-tmm} establish that residue feature update at each layer preserves E(3)-invariance. By induction, this invariance property carries through to the final residue embeddings. 
    \end{itemize}
    Therefore, the complete Igformer model satisfies both equivariance and invariance properties as stated in the theorem.
\end{proof}

