\newpage
\section{Related Work}
\label{appendix-sec:related-work}
{\bf Antibody Co-design.}
Antibody co-design methodologies facilitate the simultaneous generation of sequence and structure in an end-to-end manner, thereby enabling the modeling of intricate dependencies between backbone conformation and amino acid composition. Specifically, RefineGNN \cite{jin2022refinegnn} utilized an iterative refinement approach, alternately predicting atom coordinates and residue types in CDRs through auto-regression. DiffAb \cite{luo2022diffab} advanced the field by introducing a diffusion-based framework that explicitly targets specific antigens while considering atomic-level structures, enabling both sequence and structure generation for CDRs based on framework regions and target antigens. MEAN \cite{kong2023mean} and its successor dyMEAN \cite{kong2023dymean} leveraged graph neural networks with E(3)-equivariant architectures for CDR prediction, with dyMEAN extending to full-atom geometry modeling including both backbone and side chains. AbDiffuser \cite{martinkus2023abdiffuser} introduced an efficient SE(3)-equivariant architecture called APMixer for complete antibody structure generation, demonstrating success in wet-lab validation. Most recently, IgGM \cite{wang2024iggm} expanded capabilities to end-to-end antibody design through a hybrid diffusion model that can generate complete antibody sequences and structures simultaneously without requiring template structures.Despite these advances, existing methods have largely simplified or overlooked the complex interactions at antibody-antigen binding interfaces. Our work addresses this limitation through a novel inter-graph refinement strategy that integrates personalized propagation into global attention mechanisms, enabling more accurate modeling of binding interface dynamics. 


{\bf Sequence Design.}
The field of sequence design has evolved from LSTM-based approaches to more advanced language models. LSTM-based antibody design \cite{saka2021antibody} pioneered sequence generation for affinity maturation by employing a long short-term memory network trained on enriched phage display sequences to generate and prioritize antibody variants, 
using likelihood scores from the trained model to identify promising candidates and outperforming traditional frequency-based screening approaches. ProGen \cite{madani2020progen} introduced a controllable protein generation language model trained on 280M sequences, enabling both high-quality sequence generation and fine-grained control through conditioning. The model employed a transformer architecture and demonstrated the ability to generate proteins with native-like structural and functional properties. 
More recently, EvoDiff \cite{alamdari2023protein} introduced an evolutionary-scale diffusion framework operating directly in sequence space. The model combines discrete diffusion with evolutionary-scale sequence data to enable both unconditional generation of diverse, structurally-plausible proteins and flexible conditional generation via sequence inpainting.


{\bf Structure Design. } 
Structure design has progressed from single-step prediction to sophisticated diffusion-based approaches. RFjoint \cite{wang2021RFjoint} initially pioneered functional site scaffolding with structure prediction networks, though limited by its single-step prediction approach. RFdiffusion \cite{watson2022RFdiffusion} advanced this approach by fine-tuning the RoseTTAFold structure prediction network as a denoising network within a diffusion model framework, enabling iteratively protein structure building from random noise.
IgFold \cite{ruffolo2023IgFold} introduced a specialized antibody structure prediction framework combining a pre-trained language model (AntiBERTy) with graph neural networks. This innovation enabled direct prediction of backbone atom coordinates, achieving accuracy comparable to AlphaFold 2 \cite{jumper2021alphafold} while being significantly faster and eliminating the need for multiple sequence alignments or template structures.
Most recently, AlphaFold 3 \cite{abramson2024AlphaFold3} has taken a broader approach by introducing a unified deep-learning framework capable of predicting structures for diverse biomolecular complexes. It achieves this by replacing evoformer in Alphafold2 with a simpler Pairformer and employing a diffusion-based structure module for direct atom coordinates prediction, representing a significant step toward a more generalized solution for biomolecular structure prediction.

