We propose a Partially Observable Gaussian Process Network (POGPN) to model process networks where subprocesses can be stochastic, and the intermediate outputs can be observed using an observation lens, modeled as the observation likelihood. We develop a trainable loss, namely ELBO (Evidence Lower BOund) and Predictive Log Likelihood (PLL), for POGPN that makes inferences on the joint distribution of latent space and not just independent sub-processes. The inference can be made using MC samples, which can be considered analogous to training the child process on many hypothesized parent true/latent outputs. POGPN can incorporate continuous observations and non-Gaussian observations like categorical data. In our experience, we have not found any Gaussian process framework encompassing regression and classification within a single model. This setup makes POGPN very versatile and close to the real-world process networks where subprocesses can have arbitrary likelihood. We propose an ancestor-wise and a node-wise training method for POGPN. Experiments show the superior performance of POGPN-PLL over other existing Gaussian process networks. For further research, one can implement a message-passing algorithm to accommodate for parallel inference or use more complex observation likelihoods like a neural network.

% From a manufacturing point of view, one can also consider the intermediate observations as a target of additional instrumentation using sensors to derive more profound insight into the process. As a next step, actuators should also be used so intermediate observations are not only observable but also influenceable.
\vspace{-1em}
\section*{Acknowledgement}
The research in this paper was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 459291153 (FOR5399).