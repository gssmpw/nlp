Conventionally, a process is considered a single-process black box with input(s) and some output(s) being observed. However, systems are hardly single-process and comprise multiple sub-processes where intermediate outputs from each subprocess can be observed~\cite {Fenner2005Optimal}. The respective sub-processes can be stochastic as well. Figure~\ref{fig:multi_process} shows an example two-process system with root inputs $\cusvector{\params}^{(1)}$, observed intermediate output(s) $\cusvector{\tilde{\obsouts}}^{(1)}$, and observed final output(s) $\cusvector{\tilde{\obsouts}}^{(2)}$.
\begin{figure}[ht]
    \centering
    \input{figures/multi_process_fig}
    \vspace{-1em}
    \caption{Example process network where stochastic subprocesses are coupled by the latent state $\cusvector{\processfunction}^{(\cdot)}$ which is partially observable as $\cusvector{\obsouts}^{(\cdot)}$. Along with the input from the parent, a subprocess can also have adjustable input $\cusvector{\params}^{(\cdot)}.$}
    \vspace{-1em}
    \label{fig:multi_process}
\end{figure}
\begin{figure}[!ht]
    \centering
    % First subfigure
    \begin{subfigure}{\columnwidth}
        \centering
        \input{figures/gp_network_fig_v2}
        \caption{Existing Gaussian Process Network (GPN)}
        \label{fig:toy_process_gpn}
    \end{subfigure}
    % \vspace{1em} % Add some vertical space between figures if desired
    % Second subfigure
    \begin{subfigure}{\columnwidth}
        \centering
        \input{figures/pogpn_fig_v2}
        \caption{Partially Observable Gaussian Process Network (POGPN)}
        \label{fig:toy_process_pogpn}
    \end{subfigure}
    \caption{Comparison of GP network and POGPN. Gray nodes represent observed outputs (likelihood), and white nodes represent latent outputs (GP).}
    \vspace{-1em}
    \label{fig:gpn_pogpn_comaprison}
\end{figure}

Gaussian processes (GP) are a popular probabilistic framework to model nonlinear input-output dependencies. They have been widely used in various applications, such as the monitoring of key performance indicators for processes~\citep{Kontar2017Estimation}, control~\citep{Likar2007Predictive} and Bayesian optimization~\citep{Frazier2015Bayesian}. Work by~\cite{astudillo2021bayesian, aglietti2020causal, sussex2022model, kusakawa2022bayesian, aglietti2020multi, SakshamJPSS} show improved results when intermediate observations are included in modeling and Bayesian optimization. We call the generic class of models used for these results the Gaussian Process Network (GPN).

The GPNs employ a GP network as a Directed Acyclic Graph (DAG), where each node represents a sub-process for which an intermediate observation is recorded. The node GPs are trained to predict the respective node observation(s). The implementation considers GPs to be conditionally independent given the respective input-output pairs using closed-form Marginal Log Likelihood (MLL). However, the existing GPNs have some limitations. In most physical processes, we can observe the output-space only partially with an observation noise. For this reason, the existing GPN training methods can only be used in rare situations where we can make noise-free observations. Also, the models do not scale well to the case of non-Gaussian likelihood observations or large datasets. These limitations underscore the need for a new model.

Section~\ref{sec:multi_process} explains the definition of a DAG process with partial observability, which leads to section~\ref{sec:gp_related_work}, where the existing GPN work and its limitations are discussed. Section~\ref{sec:pogpn} and~\ref{sec:experiments} discusses and shows experiment results of our contributions :
\begin{itemize}
    \item Partially Observable Gaussian Process Network (POPGN): a real-world process-inspired model that overcomes the limitations of the current GPNs.
    \item Doubly stochastic variational inference for POGPN using Evidence Lower BOund (ELBO).
    \item Inference using Predictive Log Likelihood (PLL).
    \item Training methods to condition POGPN on partial observations of nodes/subprocesses.
\end{itemize}