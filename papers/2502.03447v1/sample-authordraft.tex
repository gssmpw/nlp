
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
%%%% Small single column format, used for CIE, CSUR, DTRAP, JACM, JDIQ, JEA, JERIC, JETC, PACMCGIT, TAAS, TACCESS, TACO, TALG, TALLIP (formerly TALIP), TCPS, TDSCI, TEAC, TECS, TELO, THRI, TIIS, TIOT, TISSEC, TIST, TKDD, TMIS, TOCE, TOCHI, TOCL, TOCS, TOCT, TODAES, TODS, TOIS, TOIT, TOMACS, TOMM (formerly TOMCCAP), TOMPECS, TOMS, TOPC, TOPLAS, TOPS, TOS, TOSEM, TOSN, TQC, TRETS, TSAS, TSC, TSLP, TWEB.

\documentclass[sigconf]{acmart}

\copyrightyear{2025}
\acmYear{2025}
\setcopyright{rightsretained}  % æˆ– acmcopyright
\acmConference[IUI '25]{30th International Conference on Intelligent User Interfaces}{March 24--27, 2025}{Cagliari, Italy}
\acmBooktitle{30th International Conference on Intelligent User Interfaces (IUI '25), March 24--27, 2025, Cagliari, Italy}
\acmDOI{10.1145/3708359.3712142}
\acmISBN{979-8-4007-1306-4/25/03}

 % \copyrightyear{2025}
 % \acmYear{2025}
 % \setcopyright{cc}
 % \setcctype{by}
 % \acmConference[IUI '25]{30th International Conference on Intelligent User Interfaces}{March 24--27, 2025}{Cagliari, Italy}
 % \acmBooktitle{30th International Conference on Intelligent User Interfaces (IUI '25), March 24--27, 2025, Cagliari, Italy}\acmDOI{10.1145/3708359.3712142}
 % \acmISBN{979-8-4007-1306-4/25/03}

% \documentclass[acmsmall]{acmart}

%%%% Large single column format, used for IMWUT, JOCCH, PACMPL, POMACS, TAP, PACMHCI
% \documentclass[acmlarge,screen]{acmart}

%%%% Large double column format, used for TOG

% \documentclass[acmtog, authorversion]{acmart}
% \documentclass[manuscript,review,anonymous]{acmart}
% \documentclass[sigconf,review,anonymous]{acmart}
%%%% Generic manuscript mode, required for submission
%%%% and peer review
%\documentclass[manuscript,screen,review]{acmart}
% \documentclass[manuscript,review,anonymous]{acmart}
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.




% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[IUI 2025]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{March 24--27,
%   2025}{Cagliari}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
% \acmBooktitle{IUI 2025} 
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}

%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
% \usepackage{threeparttable}
\usepackage{hyperref}
\usepackage{multirow}
%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title[Designing LLM-simulated Immersive Spaces to Enhance Autistic Children's Social Affordances Understanding]{Designing LLM-simulated Immersive Spaces for Autistic Children to Enhance Understanding of Social Affordances in Traffic Settings}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

 \author{Yancheng Cao}
 \affiliation{%
   \institution{College of Design and Innovation, Tongji University \\ Institute for AI Industry Research, Tsinghua University}
   \city{Shanghai}
   \country{China}}
 \email{yanchengc7@outlook.com}

 \author{Yangyang HE}
 \affiliation{%
   \institution{Institute for AI Industry Research, Tsinghua University}
   \city{Beijing}
   \country{China}}
 \email{yangyang.he@gatech.edu}

  \author{Yonglin Chen}
 \affiliation{%
   \institution{Institute for AI Industry Research, Tsinghua University}
   \city{Beijing}
   \country{China}}
 \email{yonglin0711@gmail.com}

   \author{Menghan Chen}
 \affiliation{%
   \institution{Institute for AI Industry Research, Tsinghua University}
   \city{Beijing}
   \country{China}}
 \email{chenmenghan0815@163.com}

    \author{Shanhe You}
 \affiliation{%
   \institution{Institute for AI Industry Research, Tsinghua University}
   \city{Beijing}
   \country{China}}
 \email{moxdry@outlook.com}

    \author{Yulin Qiu}
 \affiliation{%
   \institution{Institute for AI Industry Research, Tsinghua University}
   \city{Beijing}
   \country{China}}
 \email{brantbaobao@outlook.com}

     \author{Min Liu}
 \affiliation{%
   \institution{Institute for AI Industry Research, Tsinghua University}
   \city{Beijing}
   \country{China}}
 \email{2660991881@qq.com}

     \author{Chuan Luo}
 \affiliation{%
   \institution{Tsinghua University}
   \city{Beijing}
   \country{China}}
 \email{chuanluobj@hotmail.com}

     \author{Chen Zheng}
 \affiliation{%
   \institution{Institute for AI Industry Research, Tsinghua University}
   \city{Beijing}
   \country{China}}
 \email{chen.zheng.psy@outlook.com}

      \author{Xin Tong}
 \affiliation{%
   \institution{Information Hub, HKUST(GZ)}
   \city{Guangzhou}
   \country{China}}
 \email{xint@hkust-gz.edu.cn}

\author{Jing Liang\textsuperscript{*}}
\affiliation{%
  \institution{College of Design and Innovation, Tongji University}
  \city{Shanghai} 
  \country{China}}
\email{12046@tongji.edu.cn}

\author{Jiangtao Gong\textsuperscript{*}}
\affiliation{%
  \institution{Tsinghua university}
  \city{Beijing}
  \country{China}}
\email{gongjiangtao@air.tsinghua.edu.cn}

\thanks{\textsuperscript{*}Mark corresponding authors.}
 
% \author{Ben Trovato}
% \authornote{Both authors contributed equally to this research.}
% \email{trovato@corporation.com}
% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
% \authornotemark[1]
% \email{webmaster@marysville-ohio.com}
% \affiliation{%
%   \institution{Institute for Clarity in Documentation}
%   \streetaddress{P.O. Box 1212}
%   \city{Dublin}
%   \state{Ohio}
%   \country{USA}
%   \postcode{43017-6221}
% }

% \author{Lars Th{\o}rv{\"a}ld}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%   \city{Hekla}
%   \country{Iceland}}
% \email{larst@affiliation.org}

% \author{Valerie B\'eranger}
% \affiliation{%
%   \institution{Inria Paris-Rocquencourt}
%   \city{Rocquencourt}
%   \country{France}
% }

% \author{Aparna Patel}
% \affiliation{%
%  \institution{Rajiv Gandhi University}
%  \streetaddress{Rono-Hills}
%  \city{Doimukh}
%  \state{Arunachal Pradesh}
%  \country{India}}

% \author{Huifen Chan}
% \affiliation{%
%   \institution{Tsinghua University}
%   \streetaddress{30 Shuangqing Rd}
%   \city{Haidian Qu}
%   \state{Beijing Shi}
%   \country{China}}

% \author{Charles Palmer}
% \affiliation{%
%   \institution{Palmer Research Laboratories}
%   \streetaddress{8600 Datapoint Drive}
%   \city{San Antonio}
%   \state{Texas}
%   \country{USA}
%   \postcode{78229}}
% \email{cpalmer@prl.com}

% \author{John Smith}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%   \city{Hekla}
%   \country{Iceland}}
% \email{jsmith@affiliation.org}

% \author{Julius P. Kumquat}
% \affiliation{%
%   \institution{The Kumquat Consortium}
%   \city{New York}
%   \country{USA}}
% \email{jpkumquat@consortium.net}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Cao, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
 One of the key challenges faced by autistic children is understanding social affordances in complex environments, which further impacts their ability to respond appropriately to social signals. 
 In traffic scenarios, this impairment can even lead to safety concerns. In this paper, we introduce an LLM-simulated immersive projection environment designed to improve this ability in autistic children while ensuring their safety. We first propose 17 design considerations across four major categories, derived from a comprehensive review of previous research. Next, we developed a system called AIroad, which leverages LLMs to simulate drivers with varying social intents, expressed through explicit multimodal social signals. AIroad helps autistic children bridge the gap in recognizing the intentions behind behaviors and learning appropriate responses through various stimuli. A user study involving 14 participants demonstrated that this technology effectively engages autistic children and leads to significant improvements in their comprehension of social affordances in traffic scenarios. Additionally, parents reported high perceived usability of the system. These findings highlight the potential of combining LLM technology with immersive environments for the functional rehabilitation of autistic children in the future.
 
 %One of the key challenges for autistic children to live independently in the society is the difficulty of understanding social affordances in complex scenes. Such lack of understanding prevents them from generating appropriate social responses. %In this paper, we focus on complex and unpredictable traffic scenarios involving social cues because misunderstandings in these situations can even pose a life-threatening risk. 
 %In this paper, we introduce an LLM-enabled immersive learning environment designed to enhanced social affordances embedded in a scene and to assist autistic children in comprehending these affordances. To begin with, we propose nineteen design considerations across four major categories based on a comprehensive review of previous research. On this basis, we designed a virtual learning environment for traffic navigation equipped with an LLM-enabled scaffolding system and multimodal feedback. We then demonstrate the effectiveness and applicability of this system with a user experiment where  
 %This study leverages LLMs to construct a complex traffic condition generation system within an immersive space, along with an adjustable scaffold support system. This virtual traffic environment allows for the adjustment of task difficulty and scaffold prompts based on the autistic children's performance, facilitating learning within a multimodal feedback framework. 
%14 autistic children learned to navigate through complex traffic scenarios either with and without it. The children were also tested on their understanding of the social affordances embeded in the scene. The results showed that our system helped improve the children's navigation abilities and enhanced their understanding of social affordances of scenes involving various traffic participants. Our study offers insights in rehabilitation technologies for autistic children.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003121.10011748</concept_id>
       <concept_desc>Human-centered computing~Empirical studies in HCI</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120.10003121.10003129</concept_id>
       <concept_desc>Human-centered computing~Interactive systems and tools</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

% \ccsdesc[500]{Human-centered computing~Empirical studies in HCI}
\ccsdesc[500]{Human-centered computing~Interactive systems}

% \ccsdesc[500]{Human-centered computing~Empirical studies in HCI}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{autistic children, LLM, immersive environment, social affordances, traffic settings}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.


% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Autism Spectrum Disorder (ASD) is one of the most complex and least understood conditions in the field of neurodiversity~\cite{muhle2004genetics}, and it is also among the most prevalent forms of neurodiversity~\cite{lorenz2017different}. Around one in every 36 children worldwide is diagnosed with ASD~\cite{maenner2023prevalence}. 
For these children, achieving social competence is challenging~\cite{hume2009increasing}.
Previous research has revealed that autistic children face difficulties in reading facial expressions~\cite{celani1999understanding, weeks1987salience}, maintaining eye contact~\cite{freeth2013affects,thorsson2024influence}, understanding gestures~\cite{attwood1988understanding, cairney2023interpretations}, and discerning vocal tones~\cite{brooks2013attention, schelinski2019relation}, among other areas. The social opportunities conveyed by these signals are referred to as \textit{social affordances}~\cite{loveland1991social}. % The transmission of emotional signals and the corresponding responses are essential for interpersonal coordination~\cite{schmidt2008dynamics, hale2020you, hobson1991against}, but autistic children's difficulties in understanding social affordances disrupt this process~\cite{loveland1991social, hobson1993emotional, hobson1989sharing, hobson1990acquiring}, leading to difficulties in social adaptation and independent living~\cite{frith1994autism, schreibman1973overselective, kanner1972far, carter2005social}.
The inappropriate understanding of \textit{social affordances} by autistic children further diminishes their opportunities for social integration~\cite{attwood2000strategies, chamberlain2007involvement} and consequently limit their chances to engage in and practice appropriate behaviors~\cite{lynch2009inclusive, smith2012developmental}, which are essential for functional rehabilitation~\cite{helt2008can, wood2019inclusive}.

Current social skills training programs for autistic children face several challenges. Firstly, these interventions often require the presence of other participants, which increases the complexity of the training process~\cite{bellini2007meta}. This is particularly problematic given that autistic children frequently struggle to form friendships in mainstream schools~\cite{rotheram2010social, carter2014promoting}, while the time allocated for group training sessions in special education programs is typically limited~\cite{kasari2011social}.
Moreover, existing programs often focus on specific skills without adequately explaining the underlying reasons for social cues, raising concerns about the generalizability of these interventions~\cite{porayska2012developing, grynszpan2014innovative}. Additionally, the backgrounds and narratives in training scenarios are predefined, which restricts their capacity to capture the complexity of real-life social interactions and to achieve a degree of sophistication for the agent~\cite{bernardini2014echoes}.
Compounding these issues is a notable lack of comprehensive synthesis regarding design considerations for interventions targeting autistic children~\cite{bozgeyikli2017survey}.

In the area of supporting and training social skills for autistic children, HCI community has made significant efforts, such as communication skill support~\cite{cha2021exploring, obiorah2021designing}, social trigger spaces~\cite{zanardi2022hoomie, wu2020squeeze}, emotion recognition and expression~\cite{tsai2021inclusion, lorenzo2016design, tang2024emoeden}, turn-taking and collaborative skills~\cite{bei2024starrescue}, among others~\cite{mosher2022immersive}.
In addition to support for these specific skills, previous research has also focused on particular contexts, such as the medical settings~\cite{guo2024dentar} and traffic scenarios~\cite{josman2008effectiveness}.
Education for autistic children in crossing scenarios primarily employs VR technology~\cite{saiano2015natural, liu2024virtual, goldsmith2008using, peng2019virtual, peng2019virtual}, along with touchable interfaces~\cite{singh2012gaming}. However, due to the complexity of social simulation, current immersive social affordance simulations for autistic children are still very limited, restricting the efficiency of training their social skills. Recently, the development of LLMs and their capabilities for social simulation present promising opportunities to address this issue \cite{paneru2024nexus, lyu2024designing, park2023generative, mishra2024towards}.

In this regard, this study aims to develop an LLM-simulated immersive space for autistic children that could facilitate social affordance understanding. 
In this paper, specifically, we hereby refer to \textbf{social affordance} as the range of \textbf{preferred behaviors opportunities as determined by the combination of explicit and implicit social signals~\cite{zheng2024putting, frith1994autism} and general social norms~\cite{ramstead2016cultural, tomasello2014natural}.}
In certain specific contexts, such as traffic scenarios, where pedestrians are required to understand social signals and make decisions~\cite{pele2017cultural}, this impairment can even pose risks to life and safety~\cite{curry2021comparison, falkmer2004transport}.
To ensure the system is acceptable and effective, we conducted a comprehensive literature review to synthesize design considerations for educational interventions targeting autistic children. 
Then, we use a street-crossing scenario as an example, as the ability to read social signals and understand social affordances becomes crucial for safety when traffic lights are absent~\cite{salamati2013event, vellenga2022driver}.
Towards this end, we leveraged LLMs to empower this space. Through the LLM's social simulation capabilities~\cite{park2023generative, pang2024self}, we generate a rich variety of social intentions based on different driving styles, each embodying distinct social affordances. These are then expressed through social signals in the immersive space using multimodal representations.
The system enables autistic children to interact safely with various car agents, allowing them to repeatedly practice, make mistakes, and receive corrective feedback.

Thus, the contributions of this paper are as follows: 
\begin{enumerate} 
\item Based on the comprehensive literature review, we identified four major categories of design considerations, encompassing a total of 17 of them regarding interactive educational technology for autistic children. 
\item We developed an immersive space with LLM simulation to facilitate autistic children's understanding of social affordances, allowing multimodal perception and output. 
\item The system can generate diverse driving intentions based on four different driving styles, with the underlying social affordances expressed through visual and auditory social signals.
\item A user experiment involving 14 autistic children was conducted to validate the system, demonstrating its usability and appeal to children, and confirming that it effectively helps them better choose the timing for crossing the street, which suggests an improved understanding of social affordances in traffic settings.
\end{enumerate}

%the implications of system design in terms of social affordance understanding and implications for designing future LLM-enabled immersive educational spaces for autistic children.  


% ACM's consolidated article template, introduced in 2017, provides a
% consistent \LaTeX\ style for use across ACM publications, and
% incorporates accessibility and metadata-extraction functionality
% necessary for future Digital Library endeavors. Numerous ACM and
% SIG-specific \LaTeX\ templates have been examined, and their unique
% features incorporated into this single new template.

% If you are new to publishing with ACM, this document is a valuable
% guide to the process of preparing your work for publication. If you
% have published with ACM before, this document provides insight and
% instruction into more recent changes to the article template.

% The ``\verb|acmart|'' document class can be used to prepare articles
% for any ACM publication --- conference or journal, and for any stage
% of publication, from review to final ``camera-ready'' copy, to the
% author's own version, with {\itshape very} few changes to the source.

\section{Related Work}
% As noted in the introduction, the ``\verb|acmart|'' document class can
% be used to prepare many different kinds of documentation --- a
% double-blind initial submission of a full-length technical paper, a
% two-page SIGGRAPH Emerging Technologies abstract, a ``camera-ready''
% journal article, a SIGCHI Extended Abstract, and more --- all by
% selecting the appropriate {\itshape template style} and {\itshape
%   template parameters}.

% This document will explain the major features of the document
% class. For further information, the {\itshape \LaTeX\ User's Guide} is
% available from
% \url{https://www.acm.org/publications/proceedings-template}.

\subsection{Affordance and autistic children}
Affordances refer to the opportunities for perception and action that the environment offers to animals~\cite{gibson1977theory}. The term, coined by Gibson, evolved when Donald Norman introduced it to design, distinguishing between perceived and actual affordances~\cite{norman2013design, norman1988psychology} and highlighting potential everyday inconsistencies between them.
Loveland et al. categorize environmental affordances into three levels: physical transactions, cultural preferences, and social signals reflecting others' meanings. Autistic children often struggle with the latter two types~\cite{loveland1991social}. Difficulties with cultural affordances affect tool usage and may link to neurological issues~\cite{osiurak2017affordance}. Studies have explored interventions like electrical stimulation to enhance this understanding~\cite{lopes2015affordance++}. Understanding social signals involves grasping others' expectations, and research on helping autistic children in this area remains limited~\cite{ramstead2016cultural}.
Perceptual issues with affordances negatively impact social participation of autistic children and contribute to adverse behaviors, reducing learning opportunities~\cite{hellendoorn2014understanding}. While emotional signal transmission is crucial for interpersonal coordination~\cite{schmidt2008dynamics, hale2020you, hobson1991against}, autistic children's difficulties with social affordances~\cite{loveland1991social, hobson1993emotional, hobson1989sharing, hobson1990acquiring} lead to challenges in social adaptation and independent living~\cite{frith1994autism, schreibman1973overselective, kanner1972far, carter2005social}.
% Affordances refer to the opportunities for perception and action that the environment offers to animals~\cite{gibson1977theory}. The term, coined by Gibson, evolved when Donald Norman introduced it to design, distinguishing between perceived and actual affordances~\cite{norman2013design, norman1988psychology} and highlighting potential everyday inconsistencies between them.
% Loveland et al. categorize environmental affordances into three levels: physical transactions, cultural preferences, and social signals reflecting others' meanings. Autistic children often struggle with the latter two types~\cite{loveland1991social}. Difficulties with cultural affordances affect tool usage and may link to neurological issues~\cite{osiurak2017affordance}. Studies have explored interventions like electrical stimulation to enhance this understanding~\cite{lopes2015affordance++}. Understanding social signals involves grasping others' expectations, and research on helping autistic children in this area remains limited~\cite{ramstead2016cultural}.
% Perceptual issues with affordances negatively impact social participation of children with autism spectrum disorder and contribute to adverse behaviors, reducing learning opportunities~\cite{hellendoorn2014understanding}. While emotional signal transmission is crucial for interpersonal coordination~\cite{schmidt2008dynamics, hale2020you, hobson1991against}, autistic children's difficulties with social affordances~\cite{loveland1991social, hobson1993emotional, hobson1989sharing, hobson1990acquiring} lead to challenges in social adaptation and independent living~\cite{frith1994autism, schreibman1973overselective, kanner1972far, carter2005social}.
% Loveland et al. the affordances of human environment affordances into three levels: physical transactions, cultural preferences, and socithat al sign the meanings of otherrs' meanings. Autistic children often struggle with the latte of affordancesr two types~\cite{loveland1991social}. Diin understandingulties with cultural acan ffordances affect tool usabe ge aednd may link to neurological issues~\cite{osiurak2017afPrevious sordance}. Studies have explored in, such asntions like electrical ,stimulation to enhance this understanding~\cite{lopes2015affordance++}.
% Affordances refer to the opportunities for perception and action that the environment offers to animals~\cite{gibson1977theory}. The term, coined has by Gibsoover time.volved when Donald Norman 'affordance' to design, suggesting that affordances indicate how artifacts should be used. He distinguishedtinguishing between perceived and actual affordances~\cite{norman2013design, norman1988,hology} and highlighting potential everyday inconsistencies bet% ween them.


% lopes2015affoThe comprehension ofderstanding social signals involve gring others' e of others, and deficits in this area can hinder social integration. Studying how people understand social and cultural contexts is challenging, with limited research focused on aidrch on helping autistic childrn garains limited~\cite{ramstead2016% cultural}.
% Perceptual issues with affordances negativthe ely impact social participation of children with autism spectrum disorder and contribute to advers in everyday environmentse behaviors, reducing learning opportunities~\cite{hellendoorn2014underThe transmission of emotional signals and corresponding responsesransmission is crucial for interpersonal coordination~\cite{schmidt2008dynamics, hale2020you, hobson19 but91against}, autistic children's difficulties with social  disrupt this processaffordances~\cite{loveland1991social, hobson1993emotional, hobson1989sharing, hobson199,0acquingiring} lead to challenges in social adaptation and independent living~\cite{frith1994autism, schreibman1973overselective, kanner1972far, carter2005social}.

% The primary parameter given to the ``\verb|acmart|'' document class is
% the {\itshape template style} which corresponds to the kind of publication
% or SIG publishing the work. This parameter is enclosed in square
% brackets and is a part of the {\verb|documentclass|} command:
% \begin{verbatim}
%   \documentclass[STYLE]{acmart}
% \end{verbatim}

% Journals use one of three template styles. All but three ACM journals
% use the {\verb|acmsmall|} template style:
% \begin{itemize}
% \item {\verb|acmsmall|}: The default journal template style.
% \item {\verb|acmlarge|}: Used by JOCCH and TAP.
% \item {\verb|acmtog|}: Used by TOG.
% \end{itemize}

% The majority of conference proceedings documentation will use the {\verb|acmconf|} template style.
% \begin{itemize}
% \item {\verb|acmconf|}: The default proceedings template style.
% \item{\verb|sigchi|}: Used for SIGCHI conference articles.
% \item{\verb|sigchi-a|}: Used for SIGCHI ``Extended Abstract'' articles.
% \item{\verb|sigplan|}: Used for SIGPLAN conference articles.
% \end{itemize}

\subsection{Immersive environment for education}
Autistic children often experience significant deficits in social understanding and skills. Immersive systems provide effective learning environments and support mechanisms to help address these challenges ~\cite{cheng2015using}. Studies have shown these technologies successfully improve social behaviors and enhance communication and emotional skills ~\cite{halabi2017immersive,bekele2016multimodal,lorenzo2016design}. Through embodied interactions in virtual environments, children can safely explore new behavioral opportunities independently ~\cite{halabi2017immersive,matsentidou2014immersive}. These immersive settings provide a safe and inclusive space that reduces the hazards and unpredictability of real-life situations.
Immersive environments are typically delivered through VR systems with Head Mounted Displays (HMDs) or projection-based systems like Cave Automatic Virtual Environments (CAVE) ~\cite{bozgeyikli2017survey,burdea2003virtual}. While VR systems face limitations with autistic children often resisting headsets ~\cite{liu2017technology,soltiyeva2023my}, CAVE environments have proven effective for teaching safety skills, such as crossing streets or avoiding vehicles ~\cite{tzanavari2015effectiveness}. The current landscape of immersive environment systems presents significant research opportunities, particularly in integrating LLMs to enhance them with intelligent capabilities for memory, planning, and execution, though research in this area remains limited.
% Autistic children often experience significant deficits in social understanding and skills. Immersive systems have been shown to alleviate these deficits by providing effective learning environments and support mechanisms ~\cite{cheng2015using}. Previous studies have explored the use of immersive technologies as therapeutic tools for autism, confirming their success in improving social behaviors and enhancing communication and emotional skills ~\cite{halabi2017immersive,bekele2016multimodal,lorenzo2016design}. These environments engage and satisfy autistic children, guiding them through a series of social tasks via embodied interactions. In the controlled stimuli of virtual environments, children can explore new behavioral opportunities independently ~\cite{halabi2017immersive,matsentidou2014immersive}. Importantly, these immersive settings provide a safe and inclusive space that reduces the hazards and unpredictability of real-life situations, thereby shielding children from potential harm.


% Immersive environments can primarily be delivered through two types of systems: virtual reality (VR) systems that utilize wearable Head Mounted Displays (HMDs) to create immersive experiences, and projection-based systems, such as Cave Automatic Virtual Environments (CAVE) or desktop systems that project virtual environments into real-world settings ~\cite{bozgeyikli2017survey,burdea2003virtual}. However, VR systems have limitations, as many autistic children may resist wearing head-mounted devices ~\cite{liu2017technology,soltiyeva2023my}. In contrast, projection-based CAVE environments are effective for teaching children skills needed to navigate unsafe situations, such as crossing streets or avoiding vehicles. Tzanavari et al. have demonstrated the effectiveness of immersive virtual environments in teaching autistic children how to safely cross pedestrian crosswalks ~\cite{tzanavari2015effectiveness}. Nonetheless, the current landscape of immersive environment systems presents significant research opportunities that remain largely unexplored. Integrating LLMs into these environments could enhance them into intelligent systems capable of memory, planning, and execution; however, research in this area is still limited.







% In addition to specifying the {\itshape template style} to be used in
% formatting your work, there are a number of {\itshape template parameters}
% which modify some part of the applied template style. A complete list
% of these parameters can be found in the {\itshape \LaTeX\ User's Guide.}

% Frequently-used parameters, or combinations of parameters, include:
% \begin{itemize}
% \item {\verb|anonymous,review|}: Suitable for a ``double-blind''
%   conference submission. Anonymizes the work and includes line
%   numbers. Use with the \verb|\acmSubmissionID| command to print the
%   submission's unique ID on each page of the work.
% \item{\verb|authorversion|}: Produces a version of the work suitable
%   for posting by the author.
% \item{\verb|screen|}: Produces colored hyperlinks.
% \end{itemize}

% This document uses the following string as the first command in the
% source file:
% \begin{verbatim}
% \documentclass[sigconf,authordraft]{acmart}
% \end{verbatim}

\subsection{LLM-simulated social interaction}
Large Language Models like ChatGPT has demonstrated remarkable ability in generating human-like responses \cite{brown2020language}. 
LLMs excel in fundamental tasks like translation \cite{susnjak2022chatgpt}, conversation generation, and code writing, and have made significant advances in more complex domains such as autonomous decision-making and role-playing, as demonstrated by applications such as AutoGPT \cite{yang2023autogpt} and HuggingGPT \cite{shen2023hugginggpt} in task planning and execution.
These advances have enabled practical applications across various domains - from creating character-aligned dialogues and simulating human behaviors in role-playing scenarios \cite{Shanahan2023, 9980408, park2023generative}, to serving specialized functions like educational teaching assistance \cite{Celik2022} and psychological counseling for individuals with high-functioning autism \cite{cho2023evaluating}.
Recent research has developed innovative LLM applications. A project created a simulated job fair environment for training generative agents with enhanced communication capabilities \cite{li2023metaagents}, while another advanced social network simulation by modeling agents with emotional and interactive capabilities \cite{gao2023s3}. Previous research introduced an alignment learning approach that leverages simulated society interactions, providing collective ratings and iterative feedback \cite{liu2023training}. These developments showcase LLMs' potential in mimicking human social interactions, suggesting a future where AI agents can participate in sophisticated social behaviors.
% LLMs have revolutionized NLP, enabling applications far beyond basic text generation. ChatGPT has demonstrated remarkable ability in generating human-like responses \cite{brown2020language}. LLMs excel in tasks like translation \cite{susnjak2022chatgpt}, conversation generation, and code writing, while also advancing into decision-making and role-playing. AutoGPT \cite{yang2023autogpt} and HuggingGPT \cite{shen2023hugginggpt} demonstrate LLMs' capability in task planning and execution. In role-playing, LLMs create character-aligned dialogues \cite{Shanahan2023, 9980408} and simulate human behaviors \cite{park2023generative}. They serve as teaching assistants in classrooms \cite{Celik2022} and provide psychological counseling for individuals with high-functioning autism \cite{cho2023evaluating}.
% Recent research has developed innovative LLM applications. A project created a simulated job fair environment for training generative agents with enhanced communication capabilities \cite{li2023metaagents}, while another advanced social network simulation by modeling agents with emotional and interactive capabilities \cite{gao2023s3}. The SANDBOX project introduced an alignment learning approach using simulated society interactions, providing collective ratings and iterative feedback \cite{liu2023training}. These developments showcase LLMs' potential in mimicking human social interactions, suggesting a future where AI agents can participate in sophisticated social behaviors.


% The advent of LLMs has revolutionized NLP, paving the way for applications that extend far beyond basic text generation. Models such as ChatGPT have demonstrated the capacity to generate human-like responses from the context of the input text \cite{brown2020language}. LLMs have performed excellently in various language tasks, such as translation \cite{susnjak2022chatgpt}, spurring advancements in conversation generation, and even facilitating the writing of code. Beyond text generation, LLMs have stepped into the realms of decision-making and role-playing, where they not only respond to queries but also simulate complex human-like behaviors. AutoGPT \cite{yang2023autogpt} and HuggingGPT \cite{shen2023hugginggpt} use LLMs to plan, select, execute tasks, and generate operations. In role-playing simulations, LLMs can understand character backgrounds and produce dialogues aligned with characters' motivations \cite{Shanahan2023, 9980408}. Some projects proved that ChatGPT can observe, plan, and reflect to simulate human behavior and social interactions, creating computational software agents with believable human actions \cite{park2023generative}. In the educational sector, the versatility of LLMs enables them to serve as teaching assistants or conversational partners, enhancing interactivity in classrooms \cite{Celik2022}. Additionally, research has shown that LLMs can play a valuable role in providing psychological counseling for individuals with high-functioning autism \cite{cho2023evaluating}. 

% Building upon these capabilities, recent research initiatives have developed innovative applications for LLMs. One such project introduced a novel simulated job fair environment to train generative agents with enhanced communication and collaboration capabilities, underpinned by a framework comprising perception, memory, reasoning, and execution modules \cite{li2023metaagents}. Following this innovative approach, another significant advancement in the field is the simulation of social networks. One research advanced social network simulation by modeling agents with nuanced emotional, attitudinal, and interactive capabilities, validated through a two-tiered evaluation using real-world data, indicating a significant stride in LLM-driven agent-based modeling \cite{gao2023s3}. Moreover, a study presented a new alignment learning approach for language models, utilizing a simulated society named SANDBOX with recorded agent interactions, which provides a richer dataset including collective ratings and iterative feedback, shifting supervision to autonomous agents rather than traditional reward modeling \cite{liu2023training}. The groundbreaking research conducted in these studies showcases the impact of LLMs in mimicking human social interactions, suggesting a near future where AI-driven agents may contribute to them with a level of sophistication previously exclusive to human intelligence.

\begin{figure}[http]
  \includegraphics[width=0.4\textwidth]{fig/Review2.png}
  \caption{The literature screening procedure in this study involved two rounds of evaluation. This process resulted in the retention of 74 articles as the basis for design considerations.}
  \Description{This figure illustrates the literature screening process for the study. The literature screening procedure in this study involved two rounds of evaluation. This process resulted in the retention of 74 articles as the basis for design considerations.}
  \label{fig:Fig.1 The publication review procedure}
\end{figure}

\section{Design Consideration}

Design considerations for autism-focused systems remain limited in current literature, particularly regarding interaction-focused system design and LLM-enabled immersive spaces. To establish comprehensive guidelines for LLM-enabled immersive systems for autistic children, we conducted a systematic literature review (Fig. \ref{fig:Fig.1 The publication review procedure}).
Given LLM's nascent status and limited literature on its application for autistic children, our review includes studies involving other emergent technologies for this demographic, particularly focusing on immersive technologies. Our keywords cover three dimensions: (1) target audience - autistic children; (2) application domains - education, intervention, and rehabilitation; (3) associated technologies - virtual reality and similar systems. We used Boolean operators to create search strings like: ("autistic children" OR "Autistic children" OR "Autistic Spectrum Disorder") AND ("Education" OR "Intervention" OR "Rehabilitation") AND ("Artificial Intelligence" OR "LLM" OR "Immersive environment" OR "Virtual reality"). We searched six databases: IEEE Xplore, ACM Digital Library, SpringerLink, Elsevier, ScienceDirect, and Google Scholar.
Our team of five experts in engineering, psychology, and design conducted three screening rounds, reviewing titles, abstracts, and full texts. From 184 initial English articles, we applied two criteria: \textit{Criterion 1} excluded studies of non-childhood ASD cases and those with co-occurring cognitive impairments, while \textit{Criterion 2} identified articles addressing design considerations for technological interventions. 
The final 74 papers were analyzed to synthesize design guidelines across four dimensions: General, Task, Interaction, and Information.

\subsection{General Guidelines}
%\subsubsection{AI Agent}
%In the past, most research endeavors aiming to integrate AI-related technology into the realm of children with ASD have primarily focused on applications in screening and diagnosis ~\cite{jing2019application,song2019use}. 
%However, in recent years, with the emergence of LLMs, attention has shifted toward studies concerning AI-enabled personalized assistive tools ~\cite{barua2022artificial}.
%Cho et al. attempted to employ LLMs within the context of psychological counseling to facilitate interactive language therapy for high-functioning autistic teenagers, demonstrating the pivotal role LLMs could play in future therapeutic environments ~\cite{cho2023evaluating}.
%Furthermore, Mishra et al. endeavored to engage children with ASD in language interactions by introducing a social robot integrated with a LLM, which utilized LLM pipelines with GPT-2 and BART to generate text for the robot's speech ~\cite{mishra2024towards}.
%Based on the aforementioned findings, we have decided to introduce an LLM-based AI agent within an immersive environment, employing it as the core of the system to support interaction. Therefore, the first General guideline is outlined as follows:

%

%\textbullet \textit{General guideline 1: Build an AI agent to support the system.}

% \subsubsection{Personalization}
% Previous studies have emphasized the individual differences among autistic children, highlighting the wide range of symptoms they exhibit~\cite{schadenberg2021predictable,grzadzinski2013dsm,happe2006time}.
% Liu et al. pointed out that each autistic child possesses unique preferences, necessitating a certain degree of personalization in the design of systems intended for them~\cite{liu2017technology}.
% Furthermore, given that each child exhibits distinct strengths and skill deficits, system design prioritize addressing each child's individual abilities and needs. This advocating for personalized adjustments for different children, requiring system that support a high level of personalization~\cite{liu2017technology,cai2023starrypia}.
% Based on the above, we formulated General Guideline 1:

% \textbullet \textit{General guideline 1: Support Personalization.}


\subsubsection{Safe environment}
% Creating a sense of control for autistic children is a crucial design principle, particularly by situating them in a controllable environment ~\cite{grandin200228,davis2010guidelines}. 
Autistic children often struggle to understand their surroundings, especially in terms of processing information, leading them to prefer environments that enhance their sense of control over interactions ~\cite{ke2016virtual,strickland2007evolution}.
Moreover, in the context of immersive environments, virtual reality devices such as head-mounted displays may induce negative experiences (e.g., dizziness or fatigue) for some autistic children ~\cite{liu2017technology,soltiyeva2023my}.
% Based on the above, we formulated General Guideline 2:


\textbullet \textit{General guideline 1: Provide an environment that makes children feel safe and comfortable.}


\subsubsection{Guidance and training}
It is essential to avoid lengthy and complex training sessions as autistic children often encounter difficulties in remembering and processing sequences ~\cite{grandin200228,davis2010guidelines}.
Given the attention comfort zone of autistic children, it is important to appropriately adjust the tone and pace of guidance appropriately and to be prepared to terminate training promptly if any discomfort arises ~\cite{van2008puzzling}.
Furthermore, studies on design considerations for autitic children emphasize the importance of providing instructions and the need for customized content adjustments tailored to the unique characteristics of this population ~\cite{dautenhahn2000design,millen2010development,barry2006interaction}.
% Therefore, we formulated General Guideline 3:


\textbullet \textit{General guideline 2: Provide customized guidance and training in advance.}


\subsection{Task Guidelines}
\subsubsection{Objectives}
To facilitate participation for autistic children in current systems, it is crucial to establish a clear and explicit goal during task execution.~\cite{liu2017technology,whyte2015designing,bartoli2014designing}.
Bartoli et al. mentioned that the task objectives within the system should focus on a single task and a series of clear ,manageable actions (e.g., "swinging arms to hit an object"), to aid cognitive processes related to organizing actions, thereby achieving the set goals~\cite{bartoli2014designing}.
% Therefore, we developed task guideline 1:

\textbullet \textit{Task guideline 1: Provide clear and understandable task objectives.}

\subsubsection{Repeatability and predictability}
Unpredictability may elicit a host of adverse reactions, such as anxiety, in autistic children, necessitating the use of repeatable tasks to facilitate learning and maintain stability ~\cite{liu2017technology,bartoli2014designing}.
System design should ensure that game tasks for autistic children are both repeatable and easily transitioned to higher levels to prevent discouragement. 
Whyte et al. emphasized the significance of repeatability and predictability, suggesting that repeating the same task can not only enhance mastery in autistic children but also provides the predictability they need, along with the anticipate future behaviors ~\cite{whyte2015designing}.
% Consequently, we established task guideline 2:

\textbullet \textit{Task guideline 2: Employ repeatable and predictable tasks, allowing children to attempt and practice repeatedly.}

\subsubsection{Storytelling}
The narrative describes a technique used in the design of systems for autistic children, where some research has utilized this technique alongside multimedia to encourage autistic children to complete tasks and create their own narratives ~\cite{hourcade2012multitouch,chatzara2014digital,kurniawan2018development}.
Certain story scenarios and cues can help improve the communication skills and symbolic functions of autistic children, thereby fostering their autonomy ~\cite{zaffke2015icanlearn}.
Soltiyeva et al. underscored the significance of storylines, noting that if autistic children become frightened by their surroundings, it can disrupt subsequent activities ~\cite{soltiyeva2023my}.
Hence, in spatial experiences, autistic children need to be guided and encouraged by stories from the outset. Moreover, since autistic children often struggle to transition between activities, the introduction of stories can assist them in understanding this transition. 
% Based on the above, we established task guideline 3:

\textbullet \textit{Task guideline 3: Incorporate storylines to contextualize learning and enhance children's motivation.}

\subsubsection{Adjustable difficulty levels}
Given that each child exhibits distinct strengths and skill deficits, system design prioritize addressing each child's individual abilities and needs. This advocating for personalized adjustments for different children, requiring system that support a high level of personalization~\cite{liu2017technology,cai2023starrypia}.
System design should dynamically adjust the difficulty levels in alignment with the user's progression, and the intricacy of game tasks should be progressively increased~\cite{camargo2019designing,liu2017technology}.
Tasks should allowing for the introduction of incrementally more challenging tasks as children with ASD assimilate certain rules within the system. This approach concurrently facilitates the enhancement of both motor and cognitive complexities ~\cite{whyte2015designing,chua2017ict,bartoli2014designing,lee2012effects}.
As autistic children acquire and reinforce appropriate skills, they typically manifest an evolving spectrum of needs, such as escalating requirements for motor, cognitive, and social capabilities ~\cite{bartoli2014designing,lee2012effects}.
Furthermore, research in virtual environments has demonstrated that a gradually increment in task difficulty can yield superior outcomes for autistic children~\cite{strickland2007evolution,neale2002exploring,kee2012universal}.
Pivotal Response Treatment (PRT) further suggests that the emphasis of each task should adapt to individual progress, accommodating more advanced objectives and needs ~\cite{koegel2003empirically,mohammadzaheri2014randomized}.
% In light of the aforementioned, we formulated task guideline 4:


\textbullet \textit{Task guideline 4: Implement adaptable game difficulty levels, judiciously escalating complexity in correspondence with the personal capabilities of each individual child.}


\subsection{Interaction Guidelines}
\subsubsection{Multimodal input}
Multimodal systems that integrate interaction through voice, writing, touch, and other means offer distinct advantages over unimodal systems by leveraging redundancy and complementarity. This facilitates autistic children in conveying their interactive inputs to the system across multiple dimensions ~\cite{vieira2017tell}.
Previous research has also demonstrated the effectiveness of multimodal interventions in enhancing the learning and social communication skills of autistic children~\cite{brady2015investigating,beaumont2013multimodal}.
% Consequently, we developed Interaction Guideline 1:


\textbullet \textit{Interaction Guideline 1: Utilize multimodal perception at the input stage to collect behavioral data from the children.}

\subsubsection{Real-time feedback}
In interfaces designed for autistic children, feedback and signals related to the structure of interactive elements serve a crucial role in reinforcing the expected tasks for these children~\cite{konstantinidis2009using,davis2010guidelines}.
Real-time feedback, in particular, aligns closely with their interaction expectations. Previous research has observed that positive real-time feedback can significantly motivate participants and influence their engagement in subsequent interactions~\cite{konstantinidis2009using,lanyi2004multimedia,parsons2013chooses}.
% Consequently, we established interaction Guideline 2:


\textbullet \textit{Interaction Guideline 2: Provide real-time feedback for each behavior exhibited by the children.}



\subsubsection{Reward mechanisms}
In the domain of system design for autistic children, providing positive reinforcement along with rewards is a strategy known as reward-based intervention ~\cite{liu2017technology,whyte2015designing}.
Bartoli et al. noted that offering reward stimuli to autistic children upon the completing tasks that meet expectations can enhance motivation and engagement and may implicitly augment their skills \cite{bartoli2014designing}. 
Research indicates that some autistic children, particularly those with moderate to low functioning, may not value rewards in the form of quantitative performance outcomes (e.g., scores) to the same extent as they are intrinsically interesting, such as videos or audio effects (e.g., entertaining animations or joyful music) ~\cite{bartoli2014designing,uzuegbunam2017mebook}.
Incorporating reward reinforcement in serious games designed for autistic children is an effective strategy that can enhance a variety of behaviors and skills ~\cite{wong2015evidence,bartoli2014designing,de2014daybyday}.
% Based on the above, we formulated Interaction Guideline 3:

\textbullet \textit{Interaction Guideline 3: Provide positive reinforcement integrated with reward mechanisms.}

\subsubsection{Ease of input}
In system designs tailored for autistic children, simplicity and intuitiveness in control mechanisms are considered as superior design principles ~\cite{bozgeyikli2017survey}.
Complex and cumbersome input methods have been identified as sources of frustration for these children~\cite{davis2010guidelines,strickland2007evolution,kee2012universal,lanyi2004multimedia}. 
Redundant controls can cause confusion among autistic children, who may be more prone to abandonment and disengagement than typical users ~\cite{davis2010guidelines,wickramasinghe2020trustworthy}.
% Thus, we formulated Interaction Guideline 4:

\textbullet \textit{Interaction Guideline 4: Leverage simple and intuitive input methods to facilitate children's ease of use.}

\subsubsection{Devices}
For autistic individuals who may experience motor difficulties, it is advisable to employ a limited number of input devices ~\cite{davis2010guidelines,mei2014usability,bozgeyikli2017survey}.
Previous research has suggested that reducing the number of control buttons within input devices can benefit autistic children
~\cite{davis2010guidelines,strickland2007evolution,kee2012universal}.
Moreover, autistic children may experience panic and resistance when using VR devices, with reports indicating that autistic children with anxiety disorders often fear and refuse to wear VR headsets ~\cite{soltiyeva2023my}.
Additionally, unfriendly methods of device usage can create barriers that hinder the normal progression of research activities. 
% Hence, we established Interaction Guideline 5:

\textbullet \textit{Interaction Guideline 5: Utilize fewer devices that are also child-friendly to facilitate user input.}

% \begin{table*}[http]
%   \caption{Design Guidelines for designing immersive interactive system for autistic children.}
%   \label{tab:design considertion}
%   \begin{threeparttable}
%       \resizebox{\textwidth}{!}{
%       \begin{tabular}{lll}
%         \toprule
%         % \multicolumn{1}{l}{\textbf{Design Guidelines}} \\
%         % \midrule
%         \multicolumn{2}{l}{\textbf{General Guidelines}} \\
%         \midrule
%         % Support Personalization. & ~\cite{schadenberg2021predictable,grzadzinski2013dsm,happe2006time,liu2017technology,cai2023starrypia} \\
%         Provide an environment that makes children feel safe and in control. & ~\cite{grandin200228,davis2010guidelines,ke2016virtual,strickland2007evolution,liu2017technology,soltiyeva2023my} \\
%         Provide customized guidance and training. & ~\cite{grandin200228,davis2010guidelines,van2008puzzling,dautenhahn2000design,millen2010development,barry2006interaction} \\
%         \textit{} &  \\ \hline
%         \multicolumn{2}{l}{\textbf{Task Guidelines}} \\
%         \midrule
%         Provide clear and understandable task objectives. & ~\cite{liu2017technology,whyte2015designing,bartoli2014designing} \\
%         Employ repeatable and predictable tasks, allowing children to attempt and practice repeatedly. & ~\cite{liu2017technology,bartoli2014designing,whyte2015designing} \\
%         Incorporate storylines to contextualize learning and enhance children's motivation. & ~\cite{hourcade2012multitouch,chatzara2014digital,kurniawan2018development,zaffke2015icanlearn,soltiyeva2023my} \\
%         Implement adaptable game difficulty levels, judiciously escalating complexity in correspondence with the personal capabilities of each individual child. & ~\cite{camargo2019designing,liu2017technology,chua2017ict,bartoli2014designing,lee2012effects,whyte2015designing,strickland2007evolution,neale2002exploring,kee2012universal,koegel2003empirically,mohammadzaheri2014randomized,liu2017technology,cai2023starrypia} \\
%         \textit{} &  \\ \hline
        
%         \multicolumn{2}{l}{\textbf{Interaction Guidelines}} \\
%         \midrule
%         Utilize multimodal perception at the input stage to collect behavioral data from the children. & ~\cite{vieira2017tell,brady2015investigating,beaumont2013multimodal} \\
%         Provide real-time feedback for each behavior exhibited by the children. & ~\cite{konstantinidis2009using,davis2010guidelines,lanyi2004multimedia,parsons2013chooses} \\
%         Provide positive reinforcement integrated with reward mechanisms. & ~\cite{liu2017technology,whyte2015designing,bartoli2014designing,uzuegbunam2017mebook,uzuegbunam2017mebook} \\
%         Leverage simple and intuitive input methods to facilitate children's ease of use. & ~\cite{bozgeyikli2017survey,davis2010guidelines,strickland2007evolution,kee2012universal,lanyi2004multimedia,wickramasinghe2020trustworthy} \\
%         Utilize fewer devices that are also child-friendly to facilitate user input. & ~\cite{davis2010guidelines,mei2014usability,bozgeyikli2017survey,strickland2007evolution,kee2012universal} \\
%         &  \\ \hline
        
%         \multicolumn{2}{l}{\textbf{Information Guidelines}} \\
%         \midrule
%         Employ vibrant colors and a consistent style. & ~\cite{grandgeorge2016atypical,adjorlu2020co,quill1997instructional,chua2017ict,grandgeorge2016atypical,quill1997instructional,chua2017ict} \\
%         Implement simplified graphics, sound, and text. & ~\cite{chua2017ict,bozgeyikli2017survey,parsons2005adolescents,parsons2006virtual,fabri2005use,bartoli2014designing} \\
%         Utilize cartoon characters as virtual avatars instead of realistic representations. & ~\cite{cai2023starrypia,rosset2008typical,robain2022measuring,zheng2017toon,liu2017technology,hsu2017investigating,zhao2020virtual} \\
%         Provide appropriate dynamic stimuli in the scenes to capture children's attention. & ~\cite{liu2017technology,whyte2015designing,bartoli2014designing} \\
%         Provide prompts for children using various forms of information presentation, including text, sound, and animation. & ~\cite{liu2017technology,chen2022excessive,hourcade2012multitouch,chatzara2014digital,kurniawan2018development,whyte2015designing,adjorlu2020co} \\
%         Avoid the occurrence of overly unexpected stimuli in the scenes. & ~\cite{soltiyeva2023my,hourcade2012multitouch,bartoli2014designing,grandin200228,davis2010guidelines,van2008puzzling} \\\\
        
%       \bottomrule
%     \end{tabular}}
% \begin{tablenotes}
% 	\footnotesize
% 	\item 
% \end{tablenotes}
% \end{threeparttable}
% \end{table*}

\begin{table*}[htbp]
  \caption{Design Guidelines for designing immersive interactive system for autistic children.}
  \label{tab:design considertion}
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lll}
      \toprule
      \multicolumn{2}{l}{\textbf{General Guidelines}} \\
      \midrule
      Provide an environment that makes children feel safe and in control. & ~\cite{grandin200228,davis2010guidelines,ke2016virtual,strickland2007evolution,liu2017technology,soltiyeva2023my} \\
      Provide customized guidance and training. & ~\cite{grandin200228,davis2010guidelines,van2008puzzling,dautenhahn2000design,millen2010development,barry2006interaction} \\
      \textit{} &  \\ 
      \midrule
      
      \multicolumn{2}{l}{\textbf{Task Guidelines}} \\
      \midrule
      Provide clear and understandable task objectives. & ~\cite{liu2017technology,whyte2015designing,bartoli2014designing} \\
      Employ repeatable and predictable tasks, allowing children to attempt and practice repeatedly. & ~\cite{liu2017technology,bartoli2014designing,whyte2015designing} \\
      Incorporate storylines to contextualize learning and enhance children's motivation. & ~\cite{hourcade2012multitouch,chatzara2014digital,kurniawan2018development,zaffke2015icanlearn,soltiyeva2023my} \\
      Implement adaptable game difficulty levels, judiciously escalating complexity in correspondence with the personal capabilities of each individual child. & ~\cite{camargo2019designing,liu2017technology,chua2017ict,bartoli2014designing,lee2012effects,whyte2015designing,strickland2007evolution,neale2002exploring,kee2012universal,koegel2003empirically,mohammadzaheri2014randomized,liu2017technology,cai2023starrypia} \\
      \textit{} &  \\ 
      \midrule
      
      \multicolumn{2}{l}{\textbf{Interaction Guidelines}} \\
      \midrule
      Utilize multimodal perception at the input stage to collect behavioral data from the children. & ~\cite{vieira2017tell,brady2015investigating,beaumont2013multimodal} \\
      Provide real-time feedback for each behavior exhibited by the children. & ~\cite{konstantinidis2009using,davis2010guidelines,lanyi2004multimedia,parsons2013chooses} \\
      Provide positive reinforcement integrated with reward mechanisms. & ~\cite{liu2017technology,whyte2015designing,bartoli2014designing,uzuegbunam2017mebook,uzuegbunam2017mebook} \\
      Leverage simple and intuitive input methods to facilitate children's ease of use. & ~\cite{bozgeyikli2017survey,davis2010guidelines,strickland2007evolution,kee2012universal,lanyi2004multimedia,wickramasinghe2020trustworthy} \\
      Utilize fewer devices that are also child-friendly to facilitate user input. & ~\cite{davis2010guidelines,mei2014usability,bozgeyikli2017survey,strickland2007evolution,kee2012universal} \\
      \textit{} &  \\ 
      \midrule
      
      \multicolumn{2}{l}{\textbf{Information Guidelines}} \\
      \midrule
      Employ vibrant colors and a consistent style. & ~\cite{grandgeorge2016atypical,adjorlu2020co,quill1997instructional,chua2017ict,grandgeorge2016atypical,quill1997instructional,chua2017ict} \\
      Implement simplified graphics, sound, and text. & ~\cite{chua2017ict,bozgeyikli2017survey,parsons2005adolescents,parsons2006virtual,fabri2005use,bartoli2014designing} \\
      Utilize cartoon characters as virtual avatars instead of realistic representations. & ~\cite{cai2023starrypia,rosset2008typical,robain2022measuring,zheng2017toon,liu2017technology,hsu2017investigating,zhao2020virtual} \\
      Provide appropriate dynamic stimuli in the scenes to capture children's attention. & ~\cite{liu2017technology,whyte2015designing,bartoli2014designing} \\
      Provide prompts for children using various forms of information presentation, including text, sound, and animation. & ~\cite{liu2017technology,chen2022excessive,hourcade2012multitouch,chatzara2014digital,kurniawan2018development,whyte2015designing,adjorlu2020co} \\
      Avoid the occurrence of overly unexpected stimuli in the scenes. & ~\cite{soltiyeva2023my,hourcade2012multitouch,bartoli2014designing,grandin200228,davis2010guidelines,van2008puzzling} \\
      \bottomrule
    \end{tabular}
  }
\end{table*}

\subsection{Information Guidelines}
\subsubsection{Vibrant colors and consistent style}
Autitstic Children often process and remember visual information better than verbal information and are more sensitive to visual sensory stimuli than typically developing children ~\cite{grandgeorge2016atypical,adjorlu2020co,quill1997instructional,chua2017ict}.
Research has suggested that systems designed for autistic children should incorporate more vibrant colors in the visual design to cater to this strength ~\cite{camargo2019designing,zhang2018design,alvarado2017valpodijo,yan2011sunny,siti2011edutism}.
Moreover, a consistent color style can provide comfort and help prevent overstimulation. 
% Based on these insights, we developed Information Guideline 1:

 \textbullet \textit{Information Guideline 1: Employ vibrant colors and a consistent style.}

\subsubsection{Simplified information}
When designing graphics, sound, and text for systems aimed at autistic children, it is advised to avoid complex elements and lengthy compositions, as these may lead to distractions and, in severe cases, sensory overload ~\cite{chua2017ict,bozgeyikli2017survey,parsons2005adolescents,parsons2006virtual,fabri2005use}.
Bartoli et al. noted that excessive visual stimuli can cause anxiety in autisitic children because they may struggle to differentiate and interpret individual elements within a group, while too many auditory stimuli can create additional stress ~\cite{bartoli2014designing}.
Moreover, research has highlighted that simplified graphics can enhance information processing for autistic children~\cite{parsons2005adolescents,parsons2006virtual,fabri2005use}.

% Based on the above insights, we formulated Information Guideline 2:

\textbullet \textit{Information Guideline 2: Implement simplified graphics, sound, and text.}

\subsubsection{Cartoon characters}
Some studies have indicated that autistic children are more visually attentive to and engage in eye contact with cute and stylized cartoon characters than with images of real people ~\cite{cai2023starrypia,rosset2008typical,robain2022measuring,zheng2017toon}.
Furthermore, the use of simple 2D cartoon-like avatars in system has been suggested as a more widely acceptable approach by autistic children compared to realistic human representations or complex characters ~\cite{liu2017technology,hsu2017investigating,zhao2020virtual}.
% Consequently, we established Information Guideline 3:


\textbullet \textit{Information Guideline 3: Utilize cartoon characters as virtual avatars instead of realistic representations.}


\subsubsection{Dynamic stimuli}
Prolonged static scenes in a system can result in a loss of attention in children, and in the case of autistic children, such static scenarios can even trigger motor rigidity ~\cite{liu2017technology,whyte2015designing}.
To counteract this, it is important to provide appropriate dynamic stimulation throughout the interaction to prevent the emergence of repetitive behaviors or motor rigidity in autistic children ~\cite{bartoli2014designing}.
% Consequently, we formulated Information Guideline 4:


\textbullet \textit{Information Guideline 4: Provide appropriate dynamic stimuli in the scenes to capture children's attention.}


\subsubsection{Multimodal Prompts}
Autistic children often have difficulty processing external stimuli, which can affect their awareness of how their actions impact others and the environment. To address this, they may require multiple forms of prompts to guide subsequent actions ~\cite{liu2017technology,chen2022excessive}.
Previous studies have utilized a combination of media in the design of systems for autistic children to encourage interaction and promote autonomy ~\cite{hourcade2012multitouch,chatzara2014digital,kurniawan2018development}.
Additionally, some research has integrated text, auditory, and visual cues to convey game instructions,  with visual aids designed based on expert advice to assist autistic children understand verbal commands ~\cite{liu2017technology,whyte2015designing,adjorlu2020co}.
% Based on these considerations, we have formulated Information Guideline 5:

\textbullet \textit{Information Guideline 5: Provide prompts for children using various forms of information presentation, including text, sound, and visual cues.}


\subsubsection{Avoid overly sudden stimuli}
Some autistic children exhibit atypical fears of loud noises and fast-moving objects, leading to recommendations for excluding such elements from system designs intended for them~\cite{soltiyeva2023my,hourcade2012multitouch,bartoli2014designing}.
Moreover, several studies have advised against incorporating sudden noises and unexpected, abrupt visual changes in the systems or educational content used by autistic children~\cite{grandin200228,davis2010guidelines,van2008puzzling}.
 % Therefore, we have formulated information guideline 6:

 \textbullet \textit{Information Guideline 6: Avoid the occurrence of overly unexpected stimuli in the scenes.}


% Modifying the template --- including but not limited to: adjusting
% margins, typeface sizes, line spacing, paragraph and list definitions,
% and the use of the \verb|\vspace| command to manually adjust the
% vertical spacing between elements of your work --- is not allowed.

% {\bfseries Your document will be returned to you for revision if
%   modifications are discovered.}

% \section{Typefaces}

% The ``\verb|acmart|'' document class requires the use of the
% ``Libertine'' typeface family. Your \TeX\ installation should include
% this set of packages. Please do not substitute other typefaces. The
% ``\verb|lmodern|'' and ``\verb|ltimes|'' packages should not be used,
% as they will override the built-in typeface families.

% \section{Title Information}

% The title of your work should use capital letters appropriately -
% \url{https://capitalizemytitle.com/} has useful rules for
% capitalization. Use the {\verb|title|} command to define the title of
% your work. If your work has a subtitle, define it with the
% {\verb|subtitle|} command.  Do not insert line breaks in your title.

% If your title is lengthy, you must define a short version to be used
% in the page headers, to prevent overlapping text. The \verb|title|
% command has a ``short title'' parameter:
% \begin{verbatim}
%   \title[short title]{full title}
% \end{verbatim}

% \section{Authors and Affiliations}

% Each author must be defined separately for accurate metadata
% identification. Multiple authors may share one affiliation. Authors'
% names should not be abbreviated; use full first names wherever
% possible. Include authors' e-mail addresses whenever possible.

% Grouping authors' names or e-mail addresses, or providing an ``e-mail
% alias,'' as shown below, is not acceptable:
% \begin{verbatim}
%   \author{Brooke Aster, David Mehldau}
%   \email{dave,judy,steve@university.edu}
%   \email{firstname.lastname@phillips.org}
% \end{verbatim}

% The \verb|authornote| and \verb|authornotemark| commands allow a note
% to apply to multiple authors --- for example, if the first two authors
% of an article contributed equally to the work.

% If your author list is lengthy, you must define a shortened version of
% the list of authors to be used in the page headers, to prevent
% overlapping text. The following command should be placed just after
% the last \verb|\author{}| definition:
% \begin{verbatim}
%   \renewcommand{\shortauthors}{McCartney, et al.}
% \end{verbatim}
% Omitting this command will force the use of a concatenated list of all
% of the authors' names, which may result in overlapping text in the
% page headers.

% The article template's documentation, available at
% \url{https://www.acm.org/publications/proceedings-template}, has a
% complete explanation of these commands and tips for their effective
% use.

% Note that authors' addresses are mandatory for journal articles.



\section{System Design of AIRoad}
In traffic scenarios without explicit traffic lights, understanding social affordances becomes crucial \cite{ramstead2016cultural, loveland1991social}. To address this need, we developed AIRoad, a system specifically designed for street-crossing situations. This section first presents AIRoad's conceptual design and demonstrates its application through concrete examples. We then show how these implementations align with our previously established design guidelines, followed by a detailed discussion of the system's software and hardware components.
% Within the virtual scenarios, under various scaffolding cues, AIRoad assists children in understanding the intentions of vehicles with different driving styles.
%, ultimately facilitating the comprehension of social affordances. 
% AIRoad was implemented through projection and HTC trackers. 


% \begin{figure*}
%     \centering
%     \includegraphics[width=0.83\linewidth]{fig/Prompt 2.png}
%     \caption{Prompt design and execution process.}
%     \Description{This figure presents the design of our system's prompt content, which includes three parts: Background, Rules, and Souls; it then exemplifies an input and shows the response, task planning, and execution results after input.}
%     \label{fig:Prompt design and execution process}
% \end{figure*}

\subsection{Concept Design of AIRoad: Bridging Behavior and Intentions to Enhance Understanding of Social Affordance}
While neurotypical children naturally learn social signals through daily exposure~\cite{aboud2003developmental}, autistic children often require structured practice~\cite{helt2008can}. We developed a virtual street-crossing scenario enabling safe, controlled practice~\cite{shahmoradi2022cognitive}, as illustrated in Fig.~\ref{fig:System framework}.
AIRoad presents vehicle behaviors and their intentions through multiple modalities, helping autistic children bridge behavior-intention connections in assessing driver yielding behavior. The system creates an LLM-simulated environment featuring street-crossing scenarios without traffic lights, displaying vehicles with various driving intentions through multi-faceted projections.
Our driving intention generation is based on four styles from O. Taubman-Ben-Ari et al.~\cite{taubman2004multidimensional}: dissociative, anxious, risky, and patient driving. Vehicle intentions are expressed through behavioral cues (speed and gestures) indicating yielding decisions, with LLM-generated narratives conveyed through speech synthesis.
The LLM selects vehicle animations and generates corresponding intentions using literature-based prompts. Participants observe visual cues while hearing drivers' intentions through speech synthesis. During training, participants collect stars across road locations, requiring continuous interpretation of social affordances through multimodal information.
This immersive space provides autistic children with a controlled learning environment~\cite{shahmoradi2022cognitive}. Learning begins with enhanced scaffolding, while the system monitors performance to adjust difficulty and support levels. The LLM-powered adaptive space optimizes difficulty levels and provides multimodal scaffolding to facilitate skill development, ultimately enabling autistic children to comprehend social affordances effectively.

% Neurotypical children could learn the meaning of social signals from daily exposure~\cite{aboud2003developmental}, while autistic children require extensive practice~\cite{helt2008can}. Therefore, this study constructed a virtual street-crossing scenario that allows autistic children to practice in a safe and controlled environment~\cite{shahmoradi2022cognitive}. The overall framework of the system is detailed in Fig.~\ref{fig:System framework}.

% The concept of AIRoad is that the system explicitly presents vehicle driving behaviors and their underlying intentions in a multimodal manner, enabling autistic children to establish a bridge between behaviors and intentions, thereby further assessing social affordancesâ€”in this context, specifically whether a driver will yield to pedestrians. Specifically, AIRoad creates an LLM-simulated immersive space of a street-crossing scenario without traffic lights, featuring multi-faceted projections of vehicles with varying driving intentions on the road.

% To ensure that the generated vehicle behaviors align more closely with the underlying driving intentions, we selected four driving styles from the research by O. Taubman-Ben-Ari et al. as the foundation for simulating driving intention generation~\cite{taubman2004multidimensional}. These styles include dissociative driving, anxious driving, risky driving, and patient driving. 
% The driving intentions of the vehicles are expressed through their behaviors(including speed and gestures), ultimately reflecting whether they wait for passengers. The narrative behind these driving intentions is generated by the LLM and conveyed to the children through speech.
% Based on the descriptions of driving styles in the prompts we designed from the literature, we enable the LLM to select pre-designed vehicle behavior animations while simultaneously generating the corresponding driving intentions.
% These narratives are then converted from text to speech, presenting the information in an auditory modality within the immersive space.
% Participates are able to observe vehicle behaviors represented visually, such as changes in speed and gesture prompts, while simultaneously hearing the underlying driving intentions of the driver.
% The LLM continuously simulates realistic vehicles and their driving intentions throughout the game training. Participants need to collect a sufficient number of stars from different locations on the road, which requires them to repeatedly understand social affordances through multimodal information to complete the star-collecting task safely and efficiently.

% Considering the prohibitively high costs of learning in real-world settings, this study constructed an immersive space that allows autistic children to learn in a safe and controlled environment~\cite{shahmoradi2022cognitive}.
% Autistic children begin their learning journey in virtual traffic scenarios at an initial difficulty level with higher scaffolding. The system monitors their performance and evaluates their understanding of affordances. The LLM adjusts the difficulty level upwards when children perform well and increases the level of scaffolding whedifficulties in understanding. We assume that with sufficient intervention time, children can effectively navigate the highest level of road difficul% ty with minimal scaffolding.
% In this adaptive space, powered by LLM, the system identifies the most suitable difficusupportsach child. It assists them in understanding through multimodal scaffolding whilchallengelly finilitatsing the difficulty to achieve skill breakthroughs. Ultimately, the goal is to enable autistic children children to comprehend social affordances.

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=1.0\linewidth]{fig/framework.png}
    \caption{System framework of AIRoad. The social affordance simulation conducted by the LLM is detailed in the social simulation module. The control of game rules by the LLM is outlined in the control module. Key prompts and outputs related to the LLM are also displayed below.}
    \Description{This figure displays the system framework of AIRoad and the entire training process, including the adaptive adjustment and content generation by the LLM. In our work, we have developed an AI agent system based on LLM, which comprises an social simulation module and a control module.}
    \label{fig:System framework}
\end{figure*}

% larly for acomplex traffictic children. Navigating such conditions often requires individuals to identify both explicit and implicit signals to cooperate with vehicl
% es, thereby ensuring safety.social signals  Neurotypical children learn from daily exposure~\cite{aboud2003developmental}, while autistic children require more repetitive learning opportunitiesâ€”opportunities that real-world scenarios, filled with dangers and uncertaint% ies, do not readily provide.

% To assist these children in understanding affordances, we designed a series of scaffolds that facilitate comprehension through speech, gestures, avariouss, corresponding to different driving styl% es and levels of difficulty.

% Authors of any work published by ACM will need to complete a rights
% form. Depending on the kind of work, and the rights management choice
% made by the author, this may be copyright transfer, permission,
% license, or an OA (open access) agreement.

% Regardless of the rights management choice, the author will receive a
% copy of the completed rights form once it has been submitted. This
% form contains \LaTeX\ commands that must be copied into the source
% document. When the document source is compiled, these commands and
% their parameters add formatted text to several areas of the final
% document:
% \begin{itemize}
% \item the ``ACM Reference Format'' text on the first page.
% \item the ``rights management'' text on the first page.
% \item the conference information in the page header(s).
% \end{itemize}


% Rights information is unique to the work; if you are preparing several
% works for an event, make sure to use the correct set of commands with
% each of the works.

% The ACM Reference Format text is required for all articles over one
% page in length, and is optional for one-page articles (abstracts).
\subsection{Example Scenarios to Illustrate Specific Functions}
The system's core functions are illustrated through two contrasting examples. In the patient driving style, characterized by "Better safe than sorry," the vehicle slows down well in advance, and when participants show high error rates, the system displays a gesture encouraging pedestrians to cross. The LLM generates a matching narrative: "I'm heading to the supermarket to pick up a few things; there's no rush," which is conveyed through audio. Conversely, in the dissociative driving style, where the driver is "lost in thoughts or distracted," the vehicle maintains speed through the crossing without yielding. For participants with low error rates, no additional gesture cues are provided, while the LLM narrates: "I was on the phone and didn't see anyone on the road." These examples demonstrate how the system combines visual behaviors, adaptive gesture cues, and verbal intentions to help participants recognize different social affordances in crossing scenarios.

\subsection{System Development Under Design Guidelines}
% Our system is designed in strict adherence to the 17 design guidelines outlined in the previous section. The following section details the relationship between these design guidelines and the system development process.
The system development followed the aforementioned design considerations, denoted as DG1-DG17 based on their order in the table.

\subsubsection{\textbf{System Development Under General Guidelines}} 
To meet \textbf{DG1}, the system enables users to input a nickname, facilitating personalized addressing in the generated voice prompts. We selected a simple intersection common in everyday environments as the context for our study. To address \textbf{DG2}, an introductory page was developed to facilitate interactions, allowing children to engage in dialogue with various vehicles and trees, thereby familiarizing themselves with the spatial layout before their experience with AIRoad. During the experimental phase, the facilitator provided a comprehensive overview of the game tasks, which is elaborated upon in the subsequent section.

\subsubsection{\textbf{System Development Under Task Guidelines}} 
To align with \textbf{DG3}, we designed a clear and engaging objective: participants must collect stars while safely crossing the road, with emphasis on both speed and safety. In addressing \textbf{DG5}, we leveraged LLM's social simulation capabilities to generate diverse driving intention narratives, presenting them as engaging stories that enhance autistic children's engagement and understanding.
Following \textbf{DG4}, the system implements repeated road-crossing scenarios, allowing participants to progressively improve their ability to interpret vehicle driving intentions while learning from their mistakes. To satisfy For \textbf{DG6}, the system tracks participant errors through short-term and long-term memory, allowing the LLM to adjust difficulty levels dynamically. These adjustments include varying levels of cognitive support (such as gesture cues and voice-over narratives) and environmental challenges (like vehicle speeds and pedestrian interactions).

\subsubsection{\textbf{System Development Under Interaction Guidelines}} 

To meet \textbf{DG7} and \textbf{DG11}, AIRoad utilizes a portable Vive tracker and a lightweight microphone as input devices, facilitating multimodal input while ensuring ease of transport. To address \textbf{DG10}, we minimized the operational tasks required of participants; the tracker functions without intervention, and the microphone can be activated with a single button press. To fulfill \textbf{DG8}, all feedback animations are based on real-time position recognition. In accordance with \textbf{DG9}, the screen provides live updates on the number of stars collected and those yet to be obtained. Additionally, prior to the start of the experiment, participants were informed about the rewards system, which included sticker rewards distributed throughout the process.

\subsubsection{\textbf{System Development Under Information Guidelines}} 
To meet \textbf{DG12} and \textbf{DG14}, the system's visual design incorporates a cartoonish style for vehicles and environments, utilizing vibrant colors that are appealing (as illustrated in Fig. \ref{fig:cave space}). To address \textbf{DG13}, all graphics are designed to avoid excessive detail, and we have specified in the LLM prompts that generated speech should not exceed 25 words. To fulfill \textbf{DG15}, we created dynamic animations for moving vehicles, talking trees, collectible stars, and interfering pedestrians to stimulate engagement among autistic children. To meet \textbf{DG16}, the immersive space conveys prompts through multimodal elements such as vehicle animations, collision sounds, and narrative dialogues. Lastly, to \textbf{address DG17}, the vehicles encountered during training are positioned in fixed locations, and the voice prompts are generated using gentle tones to minimize sudden stimuli for autistic children.


\begin{figure*}[htbp]
\centering
   \includegraphics[width=0.9\textwidth]{fig/Cavespace.png}
   \caption{AIRoad is an AI-enabled immersive educational space tailored for autistic children. It facilitates autistic children's learning about social affordances in complex traffic scenarios through the construction of virtual transportation settings.}
   \Description{This figure shows the physical setup of AIRoad, which is located in a CAVE space consisting of four screens labeled A/B/C/D, with four projectors above. One HTC Vive base station is placed in each corner of the space. Users in the cave are required to wear a cross-body bag equipped with an HTC Vive tracker. Two cameras are set up in front of the CAVE space to record the user experience for analysis.}
   \label{fig:teaserCave}
\end{figure*}

\begin{figure*}[htbp]
  \includegraphics[width=1.0\textwidth]{fig/animationprogress.png}
  \caption{a) Projection on the ground; b) Projection on the wall; c) Overall real-life overview; d) Other cartoon elements; e) Creation of animation effects and vehicle driving style (30 frames per second).}
  \Description{This series of images is a visual presentation of AIRoad, featuring a) Projection on the ground; b) Projection on the wall; c) Overall real-life overview; d) Other cartoon elements; e) Creation of animation effects and vehicle driving style (30 frames per second).}
  \label{fig:cave space}
\end{figure*}


% \subsection{System Core Functional Framework}
% To develop a system that supports autistic children's understanding of social affordances, we conducted two preliminary experiments before finalizing its core functionalities, which are illustrated in the Fig.\ref{fig:System framework}.

% \subsubsection{Pilot study and design iteration}
% Before the formal experiment, we conducted two rounds of pilot studies to ensure the usability of the experiment. In the first pilot study, we invited a typically developing child to experience our system. In the second pilot study, an autistic child experienced our system (abc=107). In the first pilot study, the child primarily pointed out issues with system latency, including asynchronous audio and visual feedback, as well as excessive waiting times, which aligns with the second item in our Interaction Guidelines (see table.\ref{tab:design considertion}). 
% After adjusting for audio-visual synchronization, we conducted the second pilot study. During this experience, the child expressed a preference for the system to include more cars in motion, which aligns with the fourth item in our Information Guidelines (see table.\ref{tab:design considertion}). Ultimately, we developed a virtual traffic scene learning system bustling with cars.


% \subsubsection{Core function of the system}
% We constructed a simulated environment for crossing zebra crossings in complex traffic conditions. On the ground, we projected the image of a zebra crossing. On both sides of the zebra crossing, as well as in the middle, there are graphics representing curbs. We defined that standing on these curbs ensures safety from being hit by cars, while being on the zebra crossing poses a risk. The task of our system is to assist children in navigating the zebra crossing safely, avoiding collision with oncoming vehicles, and to collect a certain number of stars in the process.

%åœ¨å›¾ 4 ä¸­å¯ä»¥çœ‹åˆ°æ•´ä¸ªtrainingçš„è¿›è¡Œä¸Ž LLM åœ¨å…¶ä¸­çš„è‡ªé€‚åº”è°ƒèŠ‚ä¸Žå†…å®¹ç”Ÿæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬åŸºäºŽ LLM æž„å»ºäº† AI agentç³»ç»Ÿï¼ŒåŒ…æ‹¬ educational module å’Œ role play module ä¸¤ä¸ªéƒ¨åˆ†ã€‚
% In Fig\ref{fig:System framework}, we illustrate the entire training process, including the adaptive adjustment and content generation by the LLM. We have developed an AI agent system based on LLM, which comprises two parts: an educational module and a role-play module.

%åœ¨ autistic children å¼€å§‹è®­ç»ƒæ—¶ï¼Œç³»ç»Ÿä¼šè®¾å®šä¸€ä¸ªinitial difficulty å’Œ basic scaffoldï¼Œå¹¶è¿›è¡Œ pre testã€‚è€Œ pretest çš„ æ¸¸æˆæ•°æ®è¢«gameç³»ç»Ÿæ‰€ logï¼Œä½ç½®æ•°æ®ä¼šè¢« trackeré‡‡é›†ã€‚å¹¶å°†è¿™ä¸¤ä¸ªæ•°æ®ä¼ è¾“åˆ° AI agent çš„ education module ä¸­ã€‚é¦–å…ˆæ„ŸçŸ¥æ¨¡æ€ä¼šæ”¶é›† car's feature descriptionï¼Œ è¢«è¯•çš„passing timeï¼Œä»¥åŠä½ç½®æ•°æ®ï¼ŒåŸºäºŽä¸Šè¿°ä¸‰ä¸ªæ•°æ®è®¡ç®—å‡º correct rateã€‚input æ•°æ®ä¼šè¢«è®°å½•ä¸º short-term Memoryï¼Œå¹¶æ›´æ–°åˆ° long-term memory ä¸­ã€‚long-term memory èƒ½å¤Ÿè¯„ä¼°å¯¹å„¿ç«¥æœ¬æ¬¡è®­ç»ƒçš„ overall ability evaluationï¼Œä¸Žshort-term Memoryä¸€èµ·reasoning recent children's performanceã€‚ 
% At the start of training for autistic children, the system sets an initial difficulty level and basic scaffolding, followed by a pre-test. The game data from the pre-test are logged by the game system, while location data are collected by trackers. These two sets of data are then transmitted to the AI agent's educational module. First, the perceptual modality collects the car's feature description, the subject's passing time, and location data. Based on these three data points, the correct rate is calculated. Input data are recorded as short-term memory and updated to long-term memory. Long-term memory can assess the overall ability evaluation of the child for this training session and, together with short-term memory, reason about the child's recent performance.
%åœ¨AI agentæ€è€ƒå¥½åŽŸå› ä¹‹åŽï¼Œå°±ä¼šåŸºäºŽæ­¤è®¡åˆ’é€‚åº”äºŽå„¿ç«¥çš„ training è®¡åˆ’ï¼Œå¹¶é‡‡å– action æŽ§åˆ¶ç³»ç»Ÿçš„è¡¨çŽ°ã€‚action ä¸»è¦æœ‰ä¸¤ç§æ–¹å¼ï¼ŒåŒ…æ‹¬åŸºäºŽ driving styleå’Œ pedestrain characteristic çš„ social affordance simulation toolæŽ§åˆ¶ï¼Œè¿™ä¸Žæ•´ä½“çš„training çš„éš¾åº¦ç›¸å…³ã€‚å¦ä¸€ä¸ªæ–¹å¼æ˜¯åŸºäºŽ speechè°ƒæ•´ã€gesture å±•ç¤ºã€signal æŒ‡å¯¼çš„ scaffold generation toolï¼Œæˆ‘ä»¬å‡è®¾è¿™äº› scaffold èƒ½å¤Ÿå¸®åŠ©å„¿ç«¥ç†è§£ social affordanceã€‚åœ¨ç³»ç»Ÿå¢žåŠ éš¾åº¦æˆ–è°ƒæ•´ scaffold ä¹‹åŽï¼Œå„¿ç«¥å†æ¬¡åœ¨ training åå¤å­¦ä¹ ä¸Žå¾—åˆ°åé¦ˆï¼Œæœ€ç»ˆæœŸæœ›èƒ½å¦å®žçŽ°è®­ç»ƒçš„ç›®æ ‡ã€‚ç†æƒ³æƒ…å†µä¸‹å½“æ—¶é—´è¶³å¤Ÿé•¿æ—¶ï¼Œå„¿ç«¥èƒ½å¤Ÿåœ¨å¾ˆå°‘çš„ scaffold å¸®åŠ©ä¸‹å®Œæˆ è¾ƒé«˜éš¾åº¦çš„è®­ç»ƒä»»åŠ¡ã€‚
% After the AI agent has identified the underlying reasons, it plans a training program tailored for the child and takes action to control the system's behavior. Actions mainly fall into two categories: control via a social affordance simulation tool based on driving style and pedestrian characteristics, which is related to the overall difficulty of the training, and scaffold generation tool control based on speech adjustments, gesture displays, and signal guidance. We hypothesize that these scaffolds can help children understand social affordances. In terms of driving style, we referenced the study conducted by Taubman-Ben-Ari et al., which offers a comprehensive scale for classifying driving behaviors. We selected four types of driving behaviors of the scale: dissociative driving style, anxious driving style, risky driving style, and patient driving style. After the system increases the difficulty or adjusts the scaffolds, the child repeatedly learns from and receives feedback during training, ultimately aiming to achieve the training objectives. Ideally, over a sufficient period, children should be able to complete higher difficulty training tasks with minimal scaffold support. The process can be seen in Fig\ref{fig:Prompt design and execution process}.

%æˆ‘ä»¬å•ç‹¬ä¸º speech è¿™ä¸€ scaffoldæž„å»ºäº† role play moduleï¼Œç”¨äºŽç”Ÿæˆä¸°å¯Œçš„ speechã€‚æˆ‘ä»¬ä»Ž Taubman-Ben-Ariç­‰äººç ”ç©¶çš„é©¾é©¶é£Žæ ¼é‡è¡¨ä¸­é€‰å–äº†å››ç±»é©¾é©¶é©¾é©¶é£Žæ ¼ï¼Œåˆ†åˆ«åŒ…æ‹¬: dissociative driving styleã€anxious driving styleã€risky driving styleã€patient driving style. åŸºäºŽè¿™å››ç§é©¾é©¶é£Žæ ¼åŠå…¶æè¿°ï¼ŒAI agent ä¼šå­¦ä¹ è¿™ç±»é£Žæ ¼çš„é©¾é©¶ intentionï¼Œå¹¶ç”Ÿæˆä¸°å¯Œæœ‰è¶£çš„æ•…äº‹ï¼Œç”Ÿæˆ speech ä»¥è¯­éŸ³æ¨¡æ€ä¼ è¾¾ç»™å„¿ç«¥ï¼Œä½œä¸º scaffold çš„ä¸€éƒ¨åˆ†ã€‚
% We have developed a role-play module specifically for the speech scaffold, aimed at generating rich speech content.  Based on the descriptions of these four driving styles, the AI agent learns the driving intentions associated with each style and generates engaging and informative stories. These stories are then converted into speech and conveyed to the children in an auditory modality, serving as an integral part of the scaffolding. 
% For instance, vehicles equipped with our role-play module can articulate phrases like, â€œIâ€™m in a bit of a rush to get to the hospital, so please wait for me to drive by before you cross the road,â€ and â€œI always prioritize safety, so Iâ€™d like you to go ahead.â€.



\subsection{System implementation}
We developed a Unity-based virtual environment with LLM-controlled assets, featuring safety zones and dual crosswalks. The space is equipped with four VR stations that track users' real-time positions to evaluate their behavior during simulated vehicle crossing scenarios. This immersive environment captures user behaviors and transmits logs to LLMs, which then generate standardized text formats to orchestrate traffic simulations using predefined Unity assets. To enhance acceptance among autistic children, we chose projection as the primary medium, with detailed rationale provided in Table.\ref{tab:design considertion}.


\subsubsection{Hardware and space setting}
As shown in Fig. \ref{fig:teaserCave}, AIRoad creates an immersive experience using a four-projection system with HTC Vive base stations mounted at the four upper corners, and the HTC Vive trackers are used to track the player's real-time position in virtual space. Notably, to avoid children participants feeling uncomfortable with wearing trackers, we strapped the tracker to a backpack and designed with a playful appearance, making them appealing and acceptable to most children so that they are willing to carry a backpack while playing.
Fig. \ref{fig:teaserCave} show that the projections displayed in faces \textit{A} and \textit{D} are of equal size (7.8 m in length and 2.8 m in width), while faces \textit{B} and \textit{C} are also of equal size (2.8 m in length and 2.8 m in width).
Additionally, the experimenter uses a master computer to remotely control the computer connected to the projection system and has set up a \textit{GoPro} and a \textit{HIKVISION E14a 2K} camera to record the experimental process.

\subsubsection{Technical framework}

AIRoad utilizes a prompt-driven decision-making approach for LLMs, leveraging prompts to describe scenarios and requirements, thereby facilitating the decision-making and thought processes of the LLMs. The related source code and associated prompts are available at \url{https://github.com/Minadocyc/AIRoad.git}

\textbf{LLM Model Selection.} GPT-4 Turbo was selected as the underlying model after comparative testing with other models such as GPT-3.5 and ERNIE. At the time of development, it was OpenAI's most capable model. It demonstrated superior performance in instruction compliance, social intention generation, and response time - particularly important given the lengthy prompts used.

\textbf{Prompt Development.} Our system interfaces with GPT-4 Turbo through OpenAI's API, utilizing multiple locally stored prompt files for system configuration. These files include Background (system context); Tool (available tools and output format standards); Social (detailing characteristics of four vehicle types); and History (performance history and recent logs). During operation, these files are consolidated into a comprehensive prompt, sent to the LLM for decision analysis, which then generates simulated traffic scenarios.

\textbf{Memory Module.} The memory module stores log information that encapsulates the entire scenario context, also known as the context of scene changes. Changes in player positions and scene content trigger updates that are logged into the Memory Module. This comprehensive context, provided by the Memory Module, ensures that the LLMs have all the necessary information at their disposal when making decisions. When LLMs are called upon to make decisions, a concatenation of all logs and prompts serves as the input for the LLMs.

\textbf{Spirit.} A spirit is an object that can execute commands, produce animation effects, and generate unique sounds. In our scenario, the setting of it through personified characteristics is defined by adjustable JSON prompts. Each spirit has customizable attributes such as type, personality, position, responsibilities, actions, and voice settings. For example, a pink toy car is characterized as cute and lively, assisting children in crossing the street safely. Its voice is generated using a trained VITS model, employing a gentle female voice to convert text to speech with a distinct tonal quality.

% AIRoad utilizes a prompt-driven decision-making approach for LLMs, leveraging prompts to describe scenarios and requirements, thereby facilitating the decision-making and thought processes of the LLMs. The culmination of these prompts, used as inputs for the LLMs, is referred to as the Memory Module. This module stores log information that encapsulates the entire scenario context, also known as the context of scene changes. Changes in player positions and scene content trigger updates that are logged into the Memory Module. When LLMs are called upon to make decisions, a concatenation of all logs and prompts serves as the input for the LLMs.
% In our scenario, objects provide feedback through personified characteristics defined by adjustable JSON prompts, referred to as "Spirits." Each Spirit has customizable attributes such as type, personality, position, responsibilities, actions, and voice settings. For example, a pink toy car is characterized as cute and lively, assisting children in crossing the street safely when the green light is on, while waving as it does so. Its voice is generated using a trained VITS model, converting text to speech with a distinct tone.
% \textbf{Breathing Life into Objects:} 

% \textbf{Scene Dynamics:} 
\textbf{Real-time feedback.} Scene dynamics include participant positions, traffic light states, and spirit behavior. Due to LLMs' limitations with token, the scene is divided into areas, and each area will have a specific text description for functions. with player movements updated as position changes to the memory model, and these updates are scheduled or triggered by the player or scene change. For decision-making, the LLM input combines memory model data with predefined prompts. LLM will output the content that needs to be executed in a specific format output that dictates Spirit interactions, animations, and vehicle generation based on participant engagement and appropriate difficulty levels. Finally, the output text is disassembled through the script and the corresponding animation or voice playback is executed.

% The scene dynamics encompass participant positions, traffic light changes, and the behavior and dialogue of the Spirits. Due to the limitations of large language models (LLMs) in handling precise numerical data, participant coordinates are not directly provided to the LLM. Instead, the scene is divided into distinct areas, and updates on player movement reflect changes in position. Scripting manages these transitions, while the Memory Module logs updates on Spirit behavior and dialogue.
% When engaging LLMs for decision-making, information from the Memory Module is concatenated with pre-defined prompts to form the input. The output format is predetermined to facilitate parsing and executing the required actions derived from the text output. The LLMs determine which Spirit to engage for dialogue, which to animate, and control the generation of various vehicles within the scene based on the participant's current engagement level and the appropriateness of the difficulty.

\textbf{Synchronization of virtual and real space.} 
Within Unity, four cameras are set and orthographic mode is used to facilitate parallel projection. The views captured by these cameras are then mapped onto the projector's output using Spout, effectively translating the virtual scene into the physical space. Additionally, the positions of tracked participants are linked to a capsule object within Unity, allowing interaction between the players' locations and the colliders in the scene. To ensure accurate positional about the player's position within virtual and real space, the vectors tracked by the Tracker are multiplied by a coefficient \( n \) and adjusted by an offset \( b \). These two coefficient values will be manually calibrated every time the system starts.

\begin{figure*}
  \includegraphics[width=1\textwidth]{fig/procedure.png}
  \caption{The experimental procedure of the study}
  \Description{This figure shows the experimental procedure of our study: Upon arrival, autistic children and their parents signed consent forms and were briefed on the experimental process. Children were randomly assigned to experimental groups and tested on social understanding and emotional responses. They then underwent either AIRoad or video-based learning interventions, followed by retesting with additional measures. Throughout, each child was accompanied by an experimenter.}
  \label{fig:procedure}
\end{figure*}

% \subsubsection{System's elements and animation performance}
% To simulate traffic scenarios, this study employed a cartoonish visual style, as illustrated in Fig. \ref{fig:cave space}. Because the vehicles were designed to approach from the front, the four driving styles were depicted through variations in the speed of changes in the vehicles' sizes(As shown in Fig. \ref{fig:cave space}(e)). Drivers characterized as patient or anxious would wait for participants at the crosswalk, while those exhibiting risky or dissociative driving styles would not wait. The animations were rendered at 30 frames per second.

\begin{figure*}
 \includegraphics[width=0.8\textwidth]{fig/Experiment1.1.jpg}
 \caption{a) Children are participating in a video-based experiment; b) Completing a quiz on social affordance.}
 \Description{This series of images shows children and experimenters during the measurement phase of the experiment; a) Children are participating in a video-based experiment; b) Completing a quiz on social affordance.}
 \label{fig:experiment 1}
\end{figure*}

\begin{figure*}
 \includegraphics[width=0.8\textwidth]{fig/Experiment2.2.jpg}
 \caption{The procedure of immersive space exploring: a) Children observe their surroundings in AIRoad; b) Upon first seeing an approaching vehicle, they nervously run to the other side of the road; c) They observe and learn the different gestures and voice prompts of various vehicles; d) They gradually understand the intentions of different vehicles and begin to cross the road calmly; e) They successfully collect the stars and complete the mission.}
 \Description{This series of images illustrates the procedure of immersive space exploring: a) Children observe their surroundings in AIRoad; b) Upon first seeing an approaching vehicle, they nervously run to the other side of the road; c) They observe and learn the different gestures and voice prompts of various vehicles; d) They gradually understand the intentions of different vehicles and begin to cross the road calmly; e) They successfully collect the stars and complete the mission.}
 \label{fig:experiment 2}
\end{figure*}



\section{User Experiment}
After implementing the system, we conducted user experiments to evaluate its impact on real users. The primary research questions include the following three:

\begin{enumerate}
    \item[RQ1] To what extent does AIRoad demonstrate usability for autistic children? How do these children perform within the training?
    \item[RQ2] What are the engagement behaviors and emotional responses of autistic children when training with the AIRoad ?
    \item[RQ3] Can AIRoad effectively enhance the understanding of social affordances in traffic settings among autistic children?
\end{enumerate}

% How do participants perceive the experience of interacting within the AIRoad?


% \textbullet RQ4: 
% What impact does AIRoad have on the road-crossing behavior of autistic children and the understanding of social affordance?

\subsection{Participants and Ethical Approval}
In our study, we recruited a total of 14 participants aged 6 to 12 years (M = 8.79, SD = 2.01), among whom 5 were recommended by a qualified special education institution, and the remaining 9 were recruited through a combination of online and offline methods. For the 9 participants, the recruitment process was structured and rigorous. Parents were required to provide self-reports on their children's conditions and complete the Autism Behavior Checklist (ABC). Additionally, parents voluntarily provided diagnostic reports from qualified institutions or hospitals, or professional opinions from certified specialists. This recruitment process enabled us to gather a suitable sample of participants while ensuring they met the necessary criteria for the study. This study was approved by the Ethics Committee of Tsinghua University.
%
\subsection{Experimental Design and Experimental Procedure}
We conducted a within-subject study comparing two experimental conditions: AIRoad training and video-based tutorials (Fig. \ref{fig:procedure}). To counterbalance potential order effects, participants were randomly divided into two groups, experiencing either AIRoad or the video-based tutorial first.
In the AIRoad condition, children first familiarized themselves with the virtual environment, then engaged in an immersive road scenario where they collected stars appearing in sequence (Fig. \ref{fig:experiment 2}). The task was complete upon reaching a predetermined number of stars. The interface displayed progress and remaining time to help children track their status. In the video condition, participants watched curated road safety videos~\footnote{https://www.youtube.com/watch?v=yEP3pws5lNQ\&t=1s}.
The experimental procedure consisted of three test sessions (pre-, mid-, and post-test), interspersed with two training processes, and concluded with a semi-structured interview. The procedure was as follows: (1) parent consent and briefing, (2) pre-test, (3) first training intervention (Fig. \ref{fig:experiment 1}), (4) mid-test using the same materials as pre-test, (5) parent completion of System Usability Scale (SUS) \cite{brooke1996sus}, given children's limited compliance in answering such questions, (6) second training condition, (7) post-test using the same materials as mid-test, and (8) concluding interview. Throughout the study, each child was assisted by two experimenters, with parents nearby to address any special circumstances. All sessions were video recorded.

% This study employed a within-subject design (Fig. \ref{fig:procedure}). We established two experimental conditions: training with AIRoad and viewing a video-based tutorial.
% All participants were randomly assigned to two groups: experience either AIRoad or the video-based tutorial first, in order to counterbalance potential order effects.
% The AIRoad training condition involved children first familiarizing themselves with the environment and system. Subsequently, they engaged in an immersive virtual road scenario where they were tasked with safely touching stars that appeared in a sequential order (Fig. \ref{fig:experiment 2}). The task was considered complete upon reaching a predetermined number of stars. The screen will display the task progress and time remaining to help autistic children better understand their task completion status. In contrast, the video-based tutorial condition required children to watch a curated selection of engaging and informative road safety instructional videos~\footnote{https://www.youtube.com/watch?v=yEP3pws5lNQ\&t=1s}. 
% During both experiments, we conducted full video recordings of the entire process.
% In summary, the experimental procedure for each participant consisted of three test sessions (pre-, mid-, and post-test), interspersed with two training processes, and concluded with a semi-structured interview.

% The experimental procedure was as follows:
% Upon arrival, parents signed consent forms and were briefed on the entire experimental process. Participating children were randomly assigned to experimental groups and guided to complete a pre-test. They then experienced a learning intervention, either through AIRoad or video tutotrial (As shown in Fig. \ref{fig:experiment 1}). After a brief rest, participants completed a mid-test using the same materials as the pre-test. At this point, parents completed the System Usability Scale (SUS) test \cite{brooke1996sus}, given the limited compliance of autistic children in answering such questions. Following this, participants engaged in the second training condition. The study concluded with a final post-test and a semi-structured interview with participants. Throughout the process, each child was accompanied and prompted by one experimenter, while another experimenter simultaneously managed the test or intervention system. Parents remained within accessible distance at all times to ensure proper handling of any special circumstances that might arise.

%An experiment of determining the safe moment to cross the road is used, the time difference between the cross-able moment and the decision moment will be recorded as the reaction time, the correctness of their decision will be evaluated. 

%Then, we commenced with the first measurement, including arousal and valence tests, a experiment in terms of whether or not it was safe to cross the road, and a quiz on understanding of social affordance in transportation scenes. Subsequently, participants were randomly assigned to either begin with immersive space exploration or learning through video watching. After the first training session, we conducted a measurement again, this time adding the System Usability Scale (SUS) test\cite{brooke1996sus}. Upon completion of the test, participants were randomly assigned to the other type of intervention. The final measurement included a semi-structured interview in addition to the tests conducted during the second measurement, concluding with a debriefing session. Throughout the entire process, each child is accompanied and prompted by one experimenter, with another operating the test or intervention system.

\subsection{Measurement}
% This study used objective and subjective measures, mainly including quiz on understanding social affordance in transportation scenes, accuracy rate in term of whether or not it was safe to cross the road, response time and level of emotional arousal and valence.
The study measurements consisted of three phases: test scores from pre-, mid-, and post-assessments, behavioral data logged by the AIRoad system, and post-hoc analysis of video recordings. This multi-faceted approach enabled thorough analysis of participants' learning progress and interactions.

\begin{enumerate}

\item \textbf{Video-Based experiments.} We recorded a set of videos depicting real street scenarios and asked autistic children to determine the appropriate moment to cross the street, aiming to evaluate participants' understanding of social affordance. Three authors collaboratively predetermined a safe period for each video, during which it was deemed safe to cross the street based on traffic light signals and passing vehicles. The accuracy and reaction time were computed according to these safe periods. A correct response was recorded if the child selected to cross the street within the predetermined safe period. The reaction time was measured as the duration between the start of the safe period and the participant's selection time.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
\item \textbf{Level of Arousal and Valence.} To assess emotional changes in children before and after the training condition, we employed the Valence Arousal Scale, derived from Russell's circumplex model of affect. This model posits that emotion is composed of two bipolar and orthogonal dimensions~\cite{russell1980circumplex, russell1989affect}. Each scale ranged from -2 to 2, using integer values.

\item \textbf{SUS Scales.} To measure system usability, we employed an adapted version of the System Usability Scale (SUS) \cite{brooke1996sus} (see Appendix). Due to the limited compliance of autistic children in responding to such questionnaires, we asked parents to complete this scale on behalf of their children.

\item \textbf{In-game Log Data.} To evaluate autistic children's performance in the AIRoad training, we recorded road-crossing accuracy based on log data. Accuracy was computed through real-time position detection; a correct result was registered if the child was waiting or had arrived at a safe region when the car-leaving animation initiated. An incorrect result was recorded when the child collided with a vehicle.

\begin{table*}[htbp]
\centering
\caption{Manual coding scheme for Activity Participation and Emotional Activity}
\label{tab:my-table}
\begin{tabular}{ll}
\hline
Codes & Descriptions     \\ \hline
\multirow{2}{*}{Activity Participation} 
& \begin{tabular}[c]{@{}l@{}}Engrossed: Follow instructions, participate in activities according to rules or have a visual\\ gaze for major objects, 3 seconds is counted as 1 time \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}Distracted: Ignore instructions, avert or shift eyes to extraneous objects, and unable to \\ participate in activities according to rules\end{tabular}   \\ \hline
\multirow{2}{*}{Emotional Activity} 
& \begin{tabular}[c]{@{}l@{}}Emotional Expression: Exhibit associated emotions (pleasure, delight, agitation, excitement,\\ nervousness, etc.) \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}Problematic Behavior: Exhibit severe problem behavior (crying, emotional breakdowns, \\ aggressive behavior, etc.)\end{tabular}    \\  \hline
\end{tabular}
\end{table*}
% \begin{table*}[htbp]
% \centering
% \caption{Manual coding scheme for Activity Participation and Emotional Activity}
% \label{tab:my-table}
% \begin{tabular}{lll}
% \hline
% \multicolumn{1}{l}{Codes} & Descriptions     \\ \hline
% \multirow{Activity Participation} & \begin{tabular}[c]{@{}l@{}}Engrossed: Follow instructions, participate in activities according to rules or have a visual\\ gaze for major objects, 3 seconds is counted as 1 time \end{tabular} \\
% & \begin{tabular}[c]{@{}l@{}}Distracted: Ignore instructions, avert or shift eyes to extraneous objects, and unable to \\ participate in activities according to rules\end{tabular}   \\
% \multirow{2}{*}{Emotional Activity} & \begin{tabular}[c]{@{}l@{}}Emotional Expression: Exhibit associated emotions (pleasure, delight, agitation, excitement,\\ nervousness, etc.) \end{tabular} \\
% & \begin{tabular}[c]{@{}l@{}}Problematic Behaviour: Exhibit severe problem behaviour (crying, emotional breakdowns, \\ aggressive behaviour, etc.)\end{tabular}    \\  \hline
% \end{tabular}
% \end{table*}


\item \textbf{Video Data and Analysis.} The entire experiment was recorded using a GoPro and a 2K camera (as shown in Fig. \ref{fig:teaserCave}). These video recordings were primarily utilized for manual coding to analyze children's engagement and emotional expression \cite{1555162}. The coding scheme was developed based on and incorporated elements from Gong et al. \cite{gong2021holoboard} and Wu et al. \cite{wu2023mr}. All children's recordings were coded. Two trained coders independently coded these videos, achieving an inter-rater Pearson correlation greater than 0.99.

% \item \textbf{Interview.}We interviewed all children about their satisfaction and playing experience after they had played in the experiment. Our major questions for satisfaction were, â€œDo you like the game?â€ and â€œWhich item do you favorite?â€ For the gaming experience, we primarily inquired about their game experience and emotions. Interviews were fully recorded and transcribed for further data analysis.
\end{enumerate}


\subsection{Results}
\subsubsection{\textbf{RQ1: System usability and participants' performance}}
The results of the \textbf{\textit{System Usability Scale (SUS)}} are summarized in Table \ref{tab:my-table}. The scores indicate that the usability of AIRoad was excellent (>85.0), acceptable (>70.0), and achieved an A+ level (>84.1) according to Bangor et al.'s empirical evaluation \cite{bangor2008empirical}. As evident from the data presented in Table \ref{tab:my-table}, AIRoad consistently scored higher than the video tutorial condition. Notably, AIRoad's score exceeded 85, placing it in the "Excellent" category.
These findings address RQ1, suggesting that parents of autistic children perceive AIRoad as an acceptable and highly usable tool for this population.

\begin{table}[ht]
\centering
\caption{System Usability Scale}
\label{tab:my-table}
\begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}lcc}
\hline
Experiments & AIRoad   & Video-watching \\ \hline
Mean        & 85.71    & 80.36          \\
SD          & 15.32    & 18.11          \\ \hline
\end{tabular*}
\end{table}


 
\textbf{\textit{Experimental trainingâ€™s in-game performance}}
We conducted a logistic regression analysis to evaluate the behaviors of children in AIRoad, particularly their ability to safely cross the street. As shown in Fig.~\ref{fig:correct result}, the analysis revealed a significant correlation between the training process and the rate of safe crossings (p=0.002). This result addresses RQ1, indicating that through repeated experiences in the game training, autistic children were able to gradually reduce their error rates and demonstrate improved performance.
This finding may also suggest insights related to RQ3, indicating that autistic children may have gained a better understanding of social affordances. However, it is also possible that this improvement stems from their increasing familiarity with the game itself.

\begin{figure}[http]
  \includegraphics[width=0.4\textwidth]{fig/correctresult.png}
  \caption{The relationship between the rate of pantcipants successfully crossing the road and the number of cars used in training.}
  \Description{This figure depicts the results of logging children's behavior in AIRoad, focusing on their rate of safely crossing the street. Logistic regression analysis revealed a significant gradual improvement in participants' ability to safely navigate the game environment (p=.002), demonstrating autistic children's capacity to learn safe strategies within the virtual space.}
  \label{fig:correct result}
\end{figure}

\begin{table*}[ht]
\caption{Children's t-test results of video coding}
\label{tab:CTVC}
\begin{tabular}{llllll}
\hline
Data & Variable & AIRoad & Video-watching & Value & P \\ \hline
\multirow{2}{*}{Activity Participation} & Engrossing & M=55.615(SD=2.980) & M=42.000(SD=18.478) & t=2.281 & 0.046* \\ 
& Distracting & M=4.385(SD=2.980) & M=18.000(SD=18.478) & t=-2.281 & 0.046* \\
\multirow{2}{*}{Emotional Activity} & Emotional Expression & M=1.539(SD=2.015) & M=0.227(SD=0.518) & t=4.719 & 0.001** \\ 
& Problematic Behaviour & M=5.500(SD=3.702) & M=2.546(SD=2.318) & t=-1.330 & 0.213 \\ \hline
\end{tabular}
\end{table*}
% \begin{table*}[ht]
% \caption{Childrenâ€™s t-test results of video coding}
% \label{tab:CTVC}
% \begin{tabular}{llllll}
% \hline
% Data                                    & Variable              & AIRoad            & Video-watching      & Value    & P       \\ \hline
% \multirow{Activity Participation} & Engrossing             & M=55.615(SD=2.980) & M=42.000(SD=18.478) & t=2.281  & 0.046*  \\ 
%                                         & Distracting            & M=4.385(SD=2.980)  & M=18.000(SD=18.478) & t=-2.281 & 0.046*  \\
% \multirow{Emotional Activity}     & Emotional Expression  & M=1.539(SD=2.015)  & M=0.227(SD=0.518)   & t=4.719 & 0.001**   \\ 
%                                         & Problematic Behaviour & M=5.500(SD=3.702)  & M=2.546(SD=2.318)   & t=-1.330  & 0.213 \\\hline

% \end{tabular}
% \end{table*}

\subsubsection{\textbf{RQ2: Engagement and Emotional Responses in AIRoad Training}}
To examine the differences in children's engagement and emotional experiences between AIRoad and Video-watching, we employed a paired-sample T-test for video coding analysis. Analysis of the\textbf{\textit{Video coding}} from the children's tests, as presented in Table \ref{tab:CTVC}, indicates that participants in the AIRoad condition demonstrated higher levels of activity participation and emotional engagement. 

Regarding the Activity Participation Results, the mean of engrossing behavior in AIRoad condition was 55.615 (SD = 2.980) and of engrossing in Video-tutorial condition was 42.000 (SD = 18.478). This difference was statistically significant according to a paired-samples t-test (t(13) = 2.281, p < .05). 
And the mean of distracting behavior in AIRoad condition was 4.385 (SD = 2.980) and of distracting behavior in Video-tutorial condition was 18.000 (SD = 18.478). This difference was statistically significant according to a paired-samples t-test (t(13) = -2.281, p < .05).

In terms of Emotional Activity Results, the mean of emotional expressions in AIRoad condition was 1.539 (SD = 2.015) and of emotional expressions in Video-tutorial condition was 0.227 (SD = 0.518). This difference was statistically significant according to a paired-samples t-test (t(13) = 4.719, p < .001). 
And the mean of problematic behavior in AIRoad condition was 5.500 (SD = 3.702) and of problematic behavior in Video-tutorial condition was 2.546 (SD = 2.318). This difference did not show statistically significant according to a paired-samples t-test (t(13) = -1.330, p > .05).

These findings suggest that children exhibit more positive affective states and increased attentional focus when engaged in AIRoad training than video tutorial.
These results directly address RQ2, providing evidence that the AIRoad system we developed can offer autistic children a more engaged experience and promote positive emotional states.


We conducted a statistical analysis of the results from the\textbf{ Valence and Arousal Scale}.
As shown in Fig. \ref{valence and arousal}, we conducted the Fisher test on the Valence and Arousal Scale. The results reveal a significant improvement in children's valence after undergoing AIRoad training (p<.01). Conversely, following video-watching educational learning, a significant decrease in children's valence was observed (p<.05). In contrast, no significant changes in arousal levels were detected in autistic children before and after the training with either educational technology (p = .353 / .149).

This result addresses RQ2, indicating that AIRoad can bring positive emotions to autistic children, although there are no significant differences in the intensity of these emotions. Meanwhile, traditional video tutorials may lead to negative emotions in autistic children.

\begin{figure}
  \includegraphics[width=0.5\textwidth]{fig/valenceandarousal.png}
  \caption{The result of Valence and Arousal Scale.}
  \Description{This figure shows the results of the Valence and Arousal Scale, indicating a significant improvement in children's valence following AIRoad training (p=.005), while a notable decrease was observed after video-based learning (p=.024). The arousal levels did not show any significant changes.}
  \label{valence and arousal}
\end{figure}

\subsubsection{\textbf{RQ3: Effects on Enhancing the Understanding of Social Affordances}}
\textbf{\textit{Video-based test}}
To assess the impact of training on autistic children's response times to video stimuli, we calculated the difference in reaction times before and after the training intervention. This measure is referred to as the \textit{Delta of Reaction Time}. 
The result of \textit{Delta of Reaction Time} can be seen in Fig. \ref{fig:Reaction}. 
The mean \textit{Delta of Reaction Time} for the AIRoad condition was -2.20 (SD = 6.67), while for the video tutorial condition it was 0.18 (SD = 6.00). The Wilcoxon rank-sum test indicated a statistically significant difference between the two groups (W = 2343, \textit{p} < .05), suggesting that the \textit{Delta of Reaction Time} in the video tutorial condition was significantly higher than in the AIRoad condition.
These findings indicate that after AIRoad training, participants were able to respond more quickly to the appropriate time to cross the street. This also partially addresses RQ3, suggesting that autistic children exhibited a better understanding of social affordance in the context of the street-crossing scenario following their experience with AIRoad. Participant 3 noted, \textit{"But some cars, even though they're far away, they drive so fast and zoom; they're here in no time. So, just because they're far doesn't mean it's safe to go... And if they're close, it's not always okay; I gotta see if they're speeding fast or not."} Participant 7 also mentioned, \textit{"If a car's going fast, it means they're in a hurry for something important, like going to work or to the hospital... And if a car's going slow, it means they don't have anything important going on."} These qualitative results further demonstrate that autistic children gradually connected vehicle behavior with its underlying intentions through repeated practice in AIRoad training, enhancing their understanding of social affordance within traffic settings.

\begin{figure}[htbp]
  \includegraphics[width=0.45\textwidth]{fig/Reaction.png}
  \caption{Reaction Time}
  \Description{This figure shows the changes in response time of autistic children to road videos between AIroad training and video tutorial groups. The AIRoad group demonstrated significantly lower response times, p=0.018.}
  \label{fig:Reaction}
\end{figure}

% \textbf{\textit{Quiz}}
% Analysis of the quiz scores from pre-, mid-, and post-tests reveals no statistically significant differences (p > 0.05). This lack of significance may be attributed to the limited number and increased difficulty of quiz questions, which potentially challenged the ability of autistic children to respond effectively.
% In the initial AIRoad experiment, mid-test scores showed improvement compared to pre-test scores, but interestingly, post-test scores following the video-watching phase decreased. Conversely, in the video-watching experiment, a slight decrease was observed in mid-test scores compared to pre-test scores, while post-test scores demonstrated improvement.
% The inconsistent pattern in test performance might be explained by the extended duration of the experiment. Autistic children may have experienced significant emotional changes by the time they reached the post-test phase, potentially influencing the experimental results. This observation highlights the importance of considering fatigue and emotional factors in experimental design, particularly when working with neurodivergent populations.

% Gestures served as a clear signal for children, and most of them were able to recall a majority of the gestures. The visual channel remained one of the primary means of information intake for autistic children, and in our projection space, gestures were presented to the children in a visual form. In our quizzes and interviews, we observed that children possessed strong gesture recognition abilities (See Fig. \ref{fig:experiment 2}). Such scaffolds can also play a reminding role effectively. The participants said, \textit{"I can recognize this gesture; it's a cross, which means do not cross...I first look for hand gestures before crossing the road; if there are no gestures, then I listen for speech."}

% For autistic children, verbal cues were partly understandable, but two methods left a more lasting impression on them. The first was clear verbal instructions, directly telling the child whether it was safe to walk or not. The second involved more contrasting events, such as a race car driver rushing or someone hurrying to see a doctor; these scenarios more effectively engaged the children and guided their behaviors. In comparison, more common events, like driving to buy groceries or going out for a picnic, lacked distinct speed characteristics and tended to leave a weaker impression on the children. Participant 13 mentioned,\textit{"I'm not really sure if people driving to the grocery store are super rushed... But oh, cars zooming to the hospital? They seem super, super hurried and they just won't wait for us kids to cross the street"}




% \begin{table}[]
% \centering
% \caption{Scores of quiz on understanding social affordance in transportation scenes}
% \label{Quiz}
% \begin{tabular}{llll}
% \hline
% & Pre-Test  & Mid-Test  & Post-Test \\ \hline
% AIRoad & 6.00+1.73 & 8.00+1.41 & 7.75+2.50 \\ \hline
% Video-watching& 7.75+1.71 & 7.25+0.50 & 8.33+1.15\\ \hline
% \end{tabular}
% \end{table}












% \subsection{Quiz on understanding social affordance in transportation scenes}
% Quiz scores based on children's pre-, mid- and post-tests were not significant.
% \begin{table}[]
% \begin{tabular}{llll}
% \caption{Scores on quiz}
% \label{Socres on quiz}
% \hline
%   & Pre-Test  & Mid-Test  & Post-Test \\ \hline
% 0 & 6.00Â±1.73 & 8.00Â±1.41 & 7.75Â±2.50 \\
% 1 & 7.75Â±1.71 & 7.25Â±0.50 & 8.33Â±1.15 \\ \hline
% \end{tabular}
% \end{table}




% \begin{figure}[htbp]
%   \includegraphics[width=0.5\textwidth]{fig/Reaction time.png}
%   \caption{The relationship between the rate of pantcipants successfully crossing the road and the number of cars used in training.}
%   \Description{This figure presents the results of reaction time changes analyzed via the Wilcoxon test following AIRoad and video-based training experiments. Participants exhibited significantly decreased reaction times after AIRoad training (p=.012), suggesting an enhanced ability to respond to road conditions swiftly compared to no significant change after video training (p=.993).}
%   \label{fig:Reaction time}
% \end{figure}

% \section{Findings}
% 17 children participated in the study, each of whom first learned through traffic-related educational videos and then explored learning in the AIRoad space. 

% \subsection{AIRoad scaffolded children's understanding of social affordance}
% \subsubsection{Explicit rules, such as traffic lights, are understandable to autistic children}
% For the majority of participants, rules such as 'stop at red and go at green' were easily recognizable. During training, as long as traffic lights were present, autistic children were able to complete tasks more straightforwardly.





% Two elements of the ``acmart'' document class provide powerful
% taxonomic tools for you to help readers find your work in an online
% search.

% The ACM Computing Classification System ---
% \url{https://www.acm.org/publications/class-2012} --- is a set of
% classifiers and concepts that describe the computing
% discipline. Authors can select entries from this classification
% system, via \url{https://dl.acm.org/ccs/ccs.cfm}, and generate the
% commands to be included in the \LaTeX\ source.

% User-defined keywords are a comma-separated list of words and phrases
% of the authors' choosing, providing a more flexible way of describing
% the research being presented.

% CCS concepts and user-defined keywords are required for for all
% articles over two pages in length, and are optional for one- and
% two-page articles (or abstracts).

% \subsection{AIRoad has the potential to aid children with autism in understanding social affordances.}


% Several mentioned in interviews that
% \begin{quote}
%   "\textit{The fastest cars are racing cars, participating in a race, and they are in a hurry.}"
%  \end{quote}
% indicating that such stimuli made a lasting impression and that children understood to some extent the different driving intentions of various vehicles. Others focused directly on vehicle speed, noting that,

% \begin{quote}
%   "\textit{But some cars, even though they're far away, they drive so fast and zoom, they're here in no time. So, just because they're far doesn't mean it's safe to go ... And if they're close, it's not always okay, I gotta see if they're speeding fast or not.}"
%  \end{quote}

% Thus, children started to read signals beyond simple rules such as traffic lights, including interpreting vehicle speed. 

% Some children were even able to begin inferring the deeper intentions behind car movements.
 % \begin{quote}
  % "\textit{If a car's going fast, it means they're in a hurry for something important...and if a car's going slow, it means they don't have anything important going on.}"
 % \end{quote}
% And other participants even mentioned, 
%  \begin{quote}
%   "\textit{In the future, I will pay more attention when crossing the road, and I will look out for the driver's hand gestures in the cars.}"
%  \end{quote}
% This suggests that children with autism have learned to some extent to use such signals to perceive social affordances.

% \subsubsection{Children's success rate in safely crossing the street significantly improved with training}

% Children indeed felt a sense of crisis towards cars in AIRoad and learned how to avoid risks to ensure safety. Although the screen-based presentation prevented us from making the cars pose a real physical threat, children still exhibited behaviors such as tension, dodging, and retreating in the space. This shows that the children's responses were pronounced. At the same time, nearly all children were able to notice the setup of the safety islands in the middle, indicating that they were actively seeking safe ways to navigate the space.

% We processed and analyzed data on children's experiences during the training process, and it is evident that most children improved their success rates as training progressed (can be seen in Fig.\ref{fig:correct result}, p=0.002). 
% Many autistic children initially paid little attention to the dangers on crosswalks; they would either run quickly across the simulated crosswalks or wait on the crosswalk for cars to arrive. However, as training progressed, children began to recognize the spatial dangers associated with the crosswalk, increasingly staying within the three designated safe areas and observing approaching cars. As shown in Fig. \ref{fig:correct result}, all children gradually improved their success rates over time.



% \subsubsection{LLM achieved adaptive adjustments for different children}

% Autistic children is a highly diverse group, and our system adapted the difficulty of the training process according to each child's online performance. Each autistic child's key symptoms differed, leading to variations in their understanding of social affordance. This resulted in entirely different performances in our system that simulated social affordance. However, based on the success rate of each child in safely crossing the street and the time needed for each crossing, the system was able to adaptively adjust the difficulty. Ultimately, as in Fig.\ref{fig:cave space} we found that for each child, over time, the probability of encountering vehicles of high and low difficulty changes linearly, rather than randomly.

% \begin{figure}[htbp]
%   \includegraphics[width=0.5\textwidth]{fig/adaptive.png}
%   \caption{The literature review procedure in this study.}
%   \Description{The correct result of children in AIRoad}
%   \label{fig:correct result}
% \end{figure}

\section{Discussion}

\subsection{Large Language Models as Special Educational Support Tools for Autistic Children}

LLMs have shown utility beyond common applications, as this study explores their potential in special education for autistic children.
% Special education faces persistent challenges, including the scarcity of specialized educators and the complexity parents face in balancing their roles as both educators and caregivers. 
LLMs have shown utility beyond common applications, as this study explores their potential in special education for autistic children. Leveraging autonomous decision-making and social simulation capabilities, LLMs offer promising solutions through consistent and adaptable learning tools, reducing burdens on educators.
% Similar to systems like SqueeBall, which was designed to facilitate social interaction among autistic children~\cite{andersson2006challenges}, LLMs can be integrated into multimedia platforms to create personalized learning experiences. 
Their adaptability enables customized feedback and guidance based on real-time interactions~\cite{lyu2024designing}. Moreover, their social simulation capabilities create safe, controlled environments for autistic children to practice social skills, generating unlimited possible social scenarios through their generative abilities.
This aligns with previous research demonstrating that virtual environments provide secure spaces for children to rehearse social behaviors without real-world unpredictability~\cite{matsentidou2014immersive}. By generating dynamic, contextually relevant dialogues, LLMs enhance these virtual environments, enabling practice across diverse social scenarios.
While direct real-world experience remains essential, LLMs serve as valuable preparatory tools. The ability to simulate social interactions in virtual settings facilitates repeated practiceâ€”crucial for autistic children who often struggle with skill generalization. Research has shown that children who engage with virtual environments for social skills training successfully transfer these skills to real-world contexts~\cite{matsentidou2014immersive, paneru2024nexus}. 
% Our video-based interaction results further support this potential for real-world skill generalization.
For LLMs, hallucination remains one of their most significant risks.
In our evaluation of 100 simulated LLM responses, we identified 6 hallucination cases (6\%): 2 instances of extraneous text generation and 4 cases of intention-behavior inconsistencies. While Unity's processing system filters extraneous text, intention-behavior contradictions are addressed by introducing the concept of "lying cars" to autistic children during experiments. 
Although the 6 \% hallucination rate is relatively low, future research could employ self-reflection techniques to further reduce these occurrences~\cite{ji2023towards}. Given the rapid advancement of large language models, subsequent work could explore more advanced models to enable more immediate and diverse interactions.
%LLMs address critical challenges by providing consistent and adaptable educational tools, thereby alleviating some of the pressure on parents. Their social simulation capabilities create unique opportunities for autistic children to practice social skills in safe, controlled environments. Although real-world experiences are invaluable for this population, LLMs can function as preparatory aids. The results from video-based interactions suggest potential for generalization and extrapolation to real-world scenarios.

\begin{figure*}[htbp]
  \includegraphics[width=1.0\textwidth]{fig/eyetrack.png}
  \caption{Case on the Changes in Eye Movement Before and After Training with AIRoad. a) Eye movement case before AIRoad training
b) Eye movement case after AIRoad training.}
  \Description{This figure shows a case study on the changes in eye movement before and after training with AIRoad. After AIroad training, autistic children focused their visual attention more on vehicles.}
  \label{eyetrack}
\end{figure*}

\subsection{Benefits and Experiences of Immersive Interfaces for Autistic Children}

Projection-based immersive spaces demonstrate significant advantages in social simulation for autistic children. The medium system proves accessible and acceptable to autistic children. Embodied learning in spatial environments provides children with enhanced immersion and improved emotional engagement, addressing attention deficits and learning challenges common among autistic children~\cite{mcgee2001educating}. Their progressively improving performance demonstrates the effectiveness of learning social affordance in virtual scenarios. Simulation serves as a vital bridge before real traffic exposure for autistic children who typically find direct real-world learning challenging - a proven method in special education~\cite{rao2008social}. Although in virtual spaces, our ultimate goal is to enable autistic children to perform better in the real world through virtual interactions. AIRoad shows promising real-world skill transfer potential, supported by improved response times to real road footage.
Moreover, the decision-making processes of autistic children in the immersive AIRoad environment closely mirrored those observed in video-based tests. For instance, Participant 3 displayed risky behavior, attempting to run across the road during AIRoad training, a behavior echoed in the video-based test. In contrast, Participant 1 consistently waited for vehicles to pass completely before crossing. This suggests that immersive environments can effectively expose the real challenges faced by autistic children in a safe context. Further exploration of rehabilitation effects under simpler equipment conditions is possible~\cite{cosentino2023moves}, as more accessible interactive projection systems have been developed.
% Research indicates that autistic children are more sensitive to visual stimuli in daily life. In AIRoad, gestures served as clear signals, with most children successfully recalling them. Children sought auditory cues only in the absence of gestures. As Participant 2 noted, \textit{"I can recognize this gesture; it's a cross, which means do not cross... I first look for hand gestures before crossing the road; if there are no gestures, then I listen for speech."}


\subsection{Autistic children became more attentive to the characteristics of cars after training in AIRoad}

One possible explanation for the changes in response times lies in the shifts of attention patterns, as revealed by our eye-tracking data during video response tests. 
After the training, autistic children not only pay attention to traffic lights but also begin to observe vehicles and their adherence to traffic rules. Prior to AIRoad training, most children understood only the explicit rules for crossing the streetâ€”such as stopping at a red light, walking on a green light, and waiting for cars to pass before proceeding. However, these rules often fall short in traffic situations that are rich with complex social signals.
The training resulted in a noticeable shift in children's attention patterns towards vehicle signals. This shift is evidenced in eye movement patterns, as shown in Fig.\ref{eyetrack}. The data reveals that post-training, children allocated more time observing vehicles. While participants initially focused primarily on traffic lights and road conditions, after exploring AIRoad, they redistributed their attention to include parked vehicles.
However, this modified attention pattern occasionally led to misjudgments. For example, P11, who previously relied on traffic lights for crossing decisions, began focusing more on vehicle movements post-training, assuming it was safe to cross whenever cars stopped. As P11 noted, \textit{"In the future, I will pay more attention when crossing the road, and I will look out for the driver's hand gestures in the cars."} It is necessary to generate more diverse scenarios to help autistic children integrate multiple cues in their decision-making process.

% However, interviews revealed that after training in AIRoad, children paid more attention to the speed of cars and better understood the intentions of the vehicles, leading to improved social affordance understanding.







% Children's performance in AIRoad differed greatly. Some participants adhered strictly to the rules, having prolonged waiting periods, primarily waiting for cars to pass before choosing to walk. By contrast, some other children calculated the timing of the cars and challenged themselves by running in sync with the vehicles, comparing their speed with the cars.
%   "I'm not scared of cars. Those cars are still far from me. It would take them at least 10 seconds to get here, and I can dash across the crosswalk in 3 seconds. They can't catch up with me."
% while others said that,
% 
% Have I never been hit by a car, even though I'm slower, but safety comes first, right? This way, I won't make any mistakes."
% Children's decision-making behaviors in the virtual space mirrored those in the real world.
% Children's behavioral performance in AIRoad were very similar to their decision-making processe in video-based experiments. For example, participant P11 liked to calculate the speed and timing of cars. In AIRoad, he observed the speed of the cars and decided whether to wait or run. Children who were very cautious in AIRoad displayed attention to and emotional reactions towards violations and infractions in video-based experiments. This indicates that large immersive spaces can, to some extent, simulate children's real-world behaviors, transferring real-scene behavioral expressions into virtual reality spaces.

% \subsection{Beyond rules, there exist ambiguous gray areas of social affordance}
% For autistic children, understanding ambiguous implicit signals in gray areas can be more challenging but is also more deserving of intervention.
% Stereotypical behavior is one of the main symptoms of autism in children \cite{macdonald2007stereotypy}, and because of this, they often have a stronger reverence for rules than typically developing children \cite{Bollard2013-BOLPAA-2}. During our testing process, children would frequently repeat phrases such as "Don't walk on the red light" and "Walk on the green light" to indicate the reasoning and basis for their judgments. In semi-structured interviews, when asked how they ensure their safety and avoid vehicles in the AIRoad space, autistic children would describe some simpler and more direct rules, like "Wait if there's a car" and "Can go if there's no car." However, in our space, we created more grey areas beyond the presence or absence of cars, such as cars that slow down early or brake suddenly. We focus more on scenarios filled with both explicit and implicit signals, enriched with various scaffolds to help autistic children better understand and learn. Our observations and experiments have shown that autistic children are better at grasping clear rules, such as gestural information, and also make better judgments in high-contrast events like race car drivers speeding, but they have difficulty with more neutral, grey-area scenarios. Yet, these rich and subtle signals are essential for healthy social interactions \cite{pezzulo2013human}. 
% Therefore, it is meaningful to simulate more nuanced social affordances that blend explicit and implicit cues, enabling autistic children to read and understand them.

% \subsection{The role-playing module of LLM imbues the system with a soul}
% Most autistic children to some extent perceive the cars in the system as real living entities. Children naturally possess the tendency to animate objects \cite{7881ed3f-5a37-3bdb-a82e-c0da431b7a6c}, and they tend to anthropomorphize cars, considering them as beings with life and thought, and even speculate about the reasons or thoughts behind their driving behaviors. This system incorporates a Role Play module(Mentioned in Fig. \ref{fig:System framework}) that generates a wealth of car speech, revealing a broader range of possible intentions of cars. Consequently, children to some extent regard cars as living beings, paying attention to their behavior. P3 added that,"Some cars really care about other people's safety, but there's this one race car, he's practicing going fast. I kinda think he might be showing off, thinking he's super cool, and then he drives really fast.". 
%  This precisely illustrates that the autistic children are empathizing with the minds behind these cars.

%  The issue of hallucinations in LLMs has been a long-standing topic of discussion and remains challenging to resolve \cite{xu2024hallucination}. In this study, when using GPT-4.0, it was observed that the system identified speeches as related to patiently waiting but dispatched car number 4, which does not wait. However, autistic children were able to discern these hallucination issues. P10 mentioned that,"Some cars tell fibs. When I was crossing the road to pick stars, a car said, "Little buddy, you go first, then I'll follow," but then the car zoomed right towards me.". When children realize that the words spoken by the cars do not match their actions, the children's trust in the speech scaffolds decreases. However, at the same time, this requires children to pay more attention to the speed of the cars, increasing the demand for understanding social affordances.
       
% \subsection{Embodied virtual spaces serve as an educational approach that balances immersive perception with risk}
% Learning in real-world scenarios can be too dangerous, while gaining embodied experiences and feedback in virtual reality can be challenging \cite{fokides2008virtual}. Embodied virtual spaces represent a favorable balance \cite{stolz2015embodied}.
% Except for one child (P10) who experienced excessive fear and resumed exploring the AIRoad space after calming down, all other children successfully completed the entire program. Autistic children indeed feel a sense of crisis towards cars in AIRoad and learn how to avoid risks to ensure safety. Although the limitations of the medium prevent us from making the cars pose a real physical threat, children still exhibit behaviors such as tension, dodging, and retreating in the space. This demonstrates that the children's responses are pronounced. At the same time, nearly all children are able to notice the setup of the safety islands in the middle, indicating that they are actively seeking safe ways to navigate the space.
% By creating a sense of crisis around cars, and ensuring safety, we allowing children to freely and repeatedly explore the space enables them to gradually learn and understand social affordances.
% "One time, I looked and saw no cars on the road, so I bravely ran across, but then a bus came zooming out and whooshed right past me. I got so scared, my whole body got goosebumps. In the game, though I'm scared, I'm safe, and I won't get hit by a car." "I'm scared of cars, but cars won't really hit me, so I'm brave enough to play again."
% Overall, with only one child (P9) mentioning that the sound was too loud, all the autistic children adapted well to experiencing spatial learning within the environment. 

% This indicates that children have a good spatial adaptability of this space. They also exhibited conscious behaviors of observing cars and avoiding risks.

% \subsection{Conversations with Large Language Models (LLMs) can create experiences of social relationships for autistic children}
% \subsection{Waiting times and automotive signals}

% \subsection{The role of personalized capability adaptation}

% \subsection{Children's different coping styles}

\section{Limitation and future work}
Currently, AIRoad still faces numerous limitations. For example, the hallucinations of LLMs mentioned above are difficult to control \cite{xu2024hallucination}, leading to the generation of unexpected content in speech and the simulation of affordances, thereby increasing the system's unpredictability. Additionally, the latency of LLMs to some extent affects the system's response time. Our system currently mitigates the impact of delays by generating multiple vehicles simultaneously, but future upgrades and miniaturization of LLMs may potentially improve this issue \cite{shi2023research}.

Secondly, in the future, it is possible to construct more social scenarios filled with complex signals to simulate the social affordances they comprise, such as richer traffic scenarios including public transportation, among others. Moreover, there could be attempts to simulate a wider range of daily life scenarios. Wherever there is a human environment, the presence of social affordances is inevitable \cite{loveland1991social}.
Currently, the primary input modality for children is positional information. In the future, it's worth considering interactions through additional modalities, such as vocal input or even tactile interaction. With a richer array of interaction modalities in the space, children might experience a stronger sense of immersion and more effective learning outcomes \cite{anastopoulou2004investigating}.

\section{Conclusion}
This study first conducted a comprehensive review of educational technologies for autistic children, resulting in the identification of 17 design guidelines across four major categories, which laid the foundation for our LLM-enabled immersive system. Using a street-crossing scenario, the system simulated diverse driving behaviors through multimodal signals, including visual cues and auditory prompts. This provided autistic children with a safe environment to practice interpreting and responding to social signals. A user study involving 14 autistic children demonstrated significant improvements in their decision-making processes, suggesting an enhanced understanding of social affordances in traffic settings. Our system effectively enhances autistic children's ability to recognize and interpret social affordances by providing a controlled yet dynamic environment where they can safely explore and respond to complex social cues. Promising future research could investigate expanding this system across a broader range of social contexts, such as classroom or public space interactions, and explore the long-term transfer of learned skills to real-world settings through longitudinal studies.
%This study first conducts a comprehensive review of educational technology for autistic children, resulting in 17 design guidelines across four major categories. Based on these guidelines, the research integrates LLMs within a multi-faceted projection virtual space to create adaptive scenarios that simulate social affordances for autistic children. In the process of exploration by the children, continuous adjustment and adaptive scaffolding are employed to aid in understanding social affordances. Ultimately, we invited real autistic individuals to explore and experience this space, uncovering the interaction patterns and experiences of this demographic with new interactive technologies, and sparking discussions for future related research. And we found that such technology holds potential in helping children understand social affordances.
% Your work should use standard \LaTeX\ sectioning commands:
% \verb|section|, \verb|subsection|, \verb|subsubsection|, and
% \verb|paragraph|. They should be numbered; do not remove the numbering
% from the commands.

% Simulating a sectioning command by setting the first word or words of
% a paragraph in boldface or italicized text is {\bfseries not allowed.}

% \section{Tables}

% The ``\verb|acmart|'' document class includes the ``\verb|booktabs|''
% package --- \url{https://ctan.org/pkg/booktabs} --- for preparing
% high-quality tables.

% Table captions are placed {\itshape above} the table.

% Because tables cannot be split across pages, the best placement for
% them is typically the top of the page nearest their initial cite.  To
% ensure this proper ``floating'' placement of tables, use the
% environment \textbf{table} to enclose the table's contents and the
% table caption.  The contents of the table itself must go in the
% \textbf{tabular} environment, to be aligned properly in rows and
% columns, with the desired horizontal and vertical rules.  Again,
% detailed instructions on \textbf{tabular} material are found in the
% \textit{\LaTeX\ User's Guide}.

% Immediately following this sentence is the point at which
% Table~\ref{tab:freq} is included in the input file; compare the
% placement of the table here with the table in the printed output of
% this document.

% \begin{table}
%   \caption{Frequency of Special Characters}
%   \label{tab:freq}
%   \begin{tabular}{ccl}
%     \toprule
%     Non-English or Math&Frequency&Comments\\
%     \midrule
%     \O & 1 in 1,000& For Swedish names\\
%     $\pi$ & 1 in 5& Common in math\\
%     \$ & 4 in 5 & Used in business\\
%     $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%   \bottomrule
% \end{tabular}
% \end{table}

% To set a wider table, which takes up the whole width of the page's
% live area, use the environment \textbf{table*} to enclose the table's
% contents and the table caption.  As with a single-column table, this
% wide table will ``float'' to a location deemed more
% desirable. Immediately following this sentence is the point at which
% Table~\ref{tab:commands} is included in the input file; again, it is
% instructive to compare the placement of the table here with the table
% in the printed output of this document.

% \begin{table*}
%   \caption{Some Typical Commands}
%   \label{tab:commands}
%   \begin{tabular}{ccl}
%     \toprule
%     Command &A Number & Comments\\
%     \midrule
%     \texttt{{\char'134}author} & 100& Author \\
%     \texttt{{\char'134}table}& 300 & For tables\\
%     \texttt{{\char'134}table*}& 400& For wider tables\\
%     \bottomrule
%   \end{tabular}
% \end{table*}

% Always use midrule to separate table header rows from data rows, and
% use it only for this purpose. This enables assistive technologies to
% recognise table headers and support their users in navigating tables
% more easily.

% \section{Math Equations}
% You may want to display math equations in three distinct styles:
% inline, numbered or non-numbered display.  Each of the three are
% discussed in the next sections.

% \subsection{Inline (In-text) Equations}
% A formula that appears in the running text is called an inline or
% in-text formula.  It is produced by the \textbf{math} environment,
% which can be invoked with the usual
% \texttt{{\char'134}begin\,\ldots{\char'134}end} construction or with
% the short form \texttt{\$\,\ldots\$}. You can use any of the symbols
% and structures, from $\alpha$ to $\omega$, available in
% \LaTeX~\cite{Lamport:LaTeX}; this section will simply show a few
% examples of in-text equations in context. Notice how this equation:
% \begin{math}
%   \lim_{n\rightarrow \infty}x=0
% \end{math},
% set here in in-line math style, looks slightly different when
% set in display style.  (See next section).

% \subsection{Display Equations}
% A numbered display equation---one set off by vertical space from the
% text and centered horizontally---is produced by the \textbf{equation}
% environment. An unnumbered display equation is produced by the
% \textbf{displaymath} environment.

% Again, in either environment, you can use any of the symbols and
% structures available in \LaTeX\@; this section will just give a couple
% of examples of display equations in context.  First, consider the
% equation, shown as an inline equation above:
% \begin{equation}
%   \lim_{n\rightarrow \infty}x=0
% \end{equation}
% Notice how it is formatted somewhat differently in
% the \textbf{displaymath}
% environment.  Now, we'll enter an unnumbered equation:
% \begin{displaymath}
%   \sum_{i=0}^{\infty} x + 1
% \end{displaymath}
% and follow it with another numbered equation:
% \begin{equation}
%   \sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f
% \end{equation}
% just to demonstrate \LaTeX's able handling of numbering.

% \section{Figures}

% The ``\verb|figure|'' environment should be used for figures. One or
% more images can be placed within a figure. If your figure contains
% third-party material, you must clearly identify it as such, as shown
% in the example below.
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{fig/sample-franklin.png}
%   \caption{1907 Franklin Model D roadster. Photograph by Harris \&
%     Ewing, Inc. [Public domain], via Wikimedia
%     Commons. (\url{https://goo.gl/VLCRBB}).}
%   \Description{A woman and a girl in white dresses sit in an open car.}
% \end{figure}

% Your figures should contain a caption which describes the figure to
% the reader.

% Figure captions are placed {\itshape below} the figure.

% Every figure should also have a figure description unless it is purely
% decorative. These descriptions convey whatâ€™s in the image to someone
% who cannot see it. They are also used by search engine crawlers for
% indexing images, and when images cannot be loaded.

% A figure description must be unformatted plain text less than 2000
% characters long (including spaces).  {\bfseries Figure descriptions
%   should not repeat the figure caption â€“ their purpose is to capture
%   important information that is not already provided in the caption or
%   the main text of the paper.} For figures that convey important and
% complex new information, a short text description may not be
% adequate. More complex alternative descriptions can be placed in an
% appendix and referenced in a short figure description. For example,
% provide a data table capturing the information in a bar chart, or a
% structured list representing a graph.  For additional information
% regarding how best to write figure descriptions and why doing this is
% so important, please see
% \url{https://www.acm.org/publications/taps/describing-figures/}.

% \subsection{The ``Teaser Figure''}

% A ``teaser figure'' is an image, or set of images in one figure, that
% are placed after all author and affiliation information, and before
% the body of the article, spanning the page. If you wish to have such a
% figure in your article, place the command immediately before the
% \verb|\maketitle| command:
% \begin{verbatim}
%   \begin{teaserfigure}
%     \includegraphics[width=\textwidth]{sampleteaser}
%     \caption{figure caption}
%     \Description{figure description}
%   \end{teaserfigure}
% \end{verbatim}

% \section{Citations and Bibliographies}

% The use of \BibTeX\ for the preparation and formatting of one's
% references is strongly recommended. Authors' names should be complete
% --- use full first names (``Donald E. Knuth'') not initials
% (``D. E. Knuth'') --- and the salient identifying features of a
% reference should be included: title, year, volume, number, pages,
% article DOI, etc.

% The bibliography is included in your source document with these two
% commands, placed just before the \verb|\end{document}| command:
% \begin{verbatim}
%   \bibliographystyle{ACM-Reference-Format}
%   \bibliography{bibfile}
% \end{verbatim}
% where ``\verb|bibfile|'' is the name, without the ``\verb|.bib|''
% suffix, of the \BibTeX\ file.

% Citations and references are numbered by default. A small number of
% ACM publications have citations and references formatted in the
% ``author year'' style; for these exceptions, please include this
% command in the {\bfseries preamble} (before the command
% ``\verb|\begin{document}|'') of your \LaTeX\ source:
% \begin{verbatim}
%   \citestyle{acmauthoryear}
% % \end{verbatim}

%   Some examples.  A paginated journal article \cite{Abril07}, an
%   enumerated journal article \cite{Cohen07}, a reference to an entire
%   issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a
%   monograph/whole book in a series (see 2a in spec. document)
%   \cite{Harel79}, a divisible-book such as an anthology or compilation
%   \cite{Editor00} followed by the same example, however we only output
%   the series if the volume number is given \cite{Editor00a} (so
%   Editor00a's series should NOT be present since it has no vol. no.),
%   a chapter in a divisible book \cite{Spector90}, a chapter in a
%   divisible book in a series \cite{Douglass98}, a multi-volume work as
%   book \cite{Knuth97}, a couple of articles in a proceedings (of a
%   conference, symposium, workshop for example) (paginated proceedings
%   article) \cite{Andler79, Hagerup1993}, a proceedings article with
%   all possible elements \cite{Smith10}, an example of an enumerated
%   proceedings article \cite{VanGundy07}, an informally published work
%   \cite{Harel78}, a couple of preprints \cite{Bornmann2019,
%     AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a
%   master's thesis: \cite{anisi03}, an online document / world wide web
%   resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game
%   (Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05}
%   and (Case 3) a patent \cite{JoeScientist001}, work accepted for
%   publication \cite{rous08}, 'YYYYb'-test for prolific author
%   \cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might
%   contain 'duplicate' DOI and URLs (some SIAM articles)
%   \cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton:
%   multi-volume works as books \cite{MR781536} and \cite{MR781537}. A
%   couple of citations with DOIs:
%   \cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online
%   citations: \cite{TUGInstmem, Thornburg01, CTANacmart}. Artifacts:
%   \cite{R} and \cite{UMassCitations}.

 \section{Acknowledgments}
We would like to thank Shanghai Children's Welfare Institute for their inspiration and assistance in this research. This work was supported by the National Natural Science Foundation of China Youth Fund (No. 62202267).

% Identification of funding sources and other support, and thanks to
% individuals and groups that assisted in the research and the
% preparation of the work should be included in an acknowledgment
% section, which is placed just before the reference section in your
% document.

% This section has a special environment:
% \begin{verbatim}
%   \begin{acks}
%   ...
%   \end{acks}
% \end{verbatim}
% so that the information contained therein can be more easily collected
% during the article metadata extraction phase, and to ensure
% consistency in the spelling of the section heading.

% Authors should not prepare this section as a numbered or unnumbered {\verb|\section|}; please use the ``{\verb|acks|}'' environment.

% \section{Appendices}

% If your work needs an appendix, add it before the
% ``\verb|\end{document}|'' command at the conclusion of your source
% document.

% Start the appendix with the ``\verb|appendix|'' command:
% \begin{verbatim}
%   \appendix
% \end{verbatim}
% and note that in the appendix, sections are lettered, not
% numbered. This document has two appendices, demonstrating the section
% and subsection identification method.

% \section{Multi-language papers}

% Papers may be written in languages other than English or include
% titles, subtitles, keywords and abstracts in different languages (as a
% rule, a paper in a language other than English should include an
% English title and an English abstract).  Use \verb|language=...| for
% every language used in the paper.  The last language indicated is the
% main language of the paper.  For example, a French paper with
% additional titles and abstracts in English and German may start with
% the following command
% \begin{verbatim}
% \documentclass[sigconf, language=english, language=german,
%                language=french]{acmart}
% \end{verbatim}

% The title, subtitle, keywords and abstract will be typeset in the main
% language of the paper.  The commands \verb|\translatedXXX|, \verb|XXX|
% begin title, subtitle and keywords, can be used to set these elements
% in the other languages.  The environment \verb|translatedabstract| is
% used to set the translation of the abstract.  These commands and
% environment have a mandatory first argument: the language of the
% second argument.  See \verb|sample-sigconf-i13n.tex| file for examples
% of their usage.

% \section{SIGCHI Extended Abstracts}

% The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and
% not in Word) produces a landscape-orientation formatted article, with
% a wide left margin. Three environments are available for use with the
% ``\verb|sigchi-a|'' template style, and produce formatted output in
% the margin:
% \begin{itemize}
% \item {\verb|sidebar|}:  Place formatted text in the margin.
% \item {\verb|marginfigure|}: Place a figure in the margin.
% \item {\verb|margintable|}: Place a table in the margin.
% \end{itemize}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
 \bibliographystyle{ACM-Reference-Format}
 \bibliography{sample-base}

\appendix

\section{Experimental Details}

\subsection{Online questionaire}
\textbf{Investigation on ASD children's language and motor skills.}\\
Hello,Parents!Thank you very much for participating in this questionnaire. We have designed a virtual space environment for autistic children to explore, where they can learn and interact.\\
All your answers are for statistical analysis and academic research only. Please fill in the questionnaire carefully according to the actual situation of your child and feel free to answer! If you and your child are interested in participating in our "Little Explorer" virtual space experience and becoming our little explorers, please leave your contact information at the end of the questionnaire.

Your child's name:
What is your child's gender?
\begin{itemize}
    \item male
    \item female
\end{itemize}

Please enter your child's date of birth:

How is your child's motor skills?
\begin{itemize}
\item Very good
\item Good
\item Average
\item Poor
\item Very poor
\end{itemize}

How is your child's language skills?
\begin{itemize}
\item Very good
\item Good
\item Average
\item Poor
\item Very poor
\end{itemize}

Your child's personality:
\begin{itemize}
\item Outgoing and lively
\item Introverted and quiet
\item Curious and exploratory
\item Sensitive and sentimental
\end{itemize}

Does your child enjoy going on trips?
\begin{itemize}
\item Like very much
\item Not so much
\item Neutral
\item Dislike
\item Very Dislike
\end{itemize}

What is your usual mode of trips?
\begin{itemize}
\item Self-drive
\item Public Transport
\item Walking
\item Cycling
\item Other
\end{itemize}

Has your child travelled independently?
\begin{itemize}
\item Yes, he/she can travel fully independently
\item limited independent trips, need some guidance
\item cannot travel independently, always needs to be accompanied
\item never tried to travel independently
\end{itemize}

\section{Adapted SUS scale}
(five-Likert scale,1:It fits perfectly;5:Very inconsistent)
\subsection{AIRoad}
\begin{itemize}
\item I think I would let my child play this game often
\item I think this game is too difficult for children
\item I think this game is too easy for the child to play
\item The child needs help to complete the game
\item I think the system is well integrated with various functions
\item I think other children would learn the game very quickly as well
\item I think there are too many inconsistencies in the system
\item I found the system very cumbersome to use
\item I think the system is well designed and fun for children to play 
\item The child would need to know a lot of other knowledge and information beforehand to play the game
\end{itemize}

\subsection{Video-watching}
\begin{itemize}
\item I think I would let my child watch these videos often
\item I think this video is too difficult for children
\item I think this video is too easy for my child to watch
\item My child needs help to watch this video independently
\item I think this video has a good integration of various elements
\item I think other children would learn the content of this video very quickly as well
\item I think there are too many inconsistencies in the video
\item I found it very cumbersome to watch and use the video
\item I think the video is well designed and interesting for children to watch
\item Children need to know a lot of other knowledge and information before they can watch this video
\end{itemize}

%%
%% If your work has an appendix, this is the place to put it.
% \appendix

% \section{Research Methods}

% \subsection{Part One}

% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
% malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
% sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
% % vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
% lacinia dolor. Integer ultricies commodo sem nec semper.

% \subsection{Part Two}

% Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
% ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
% ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
% eros. Vivamus non purus placerat, scelerisque diam eu, cursus
% ante. Etiam aliquam tortor auctor efficitur mattis.

% \section{Online Resources}

% Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
% pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
% enim maximus. Vestibulum gravida massa ut felis suscipit
% congue. Quisque mattis elit a risus ultrices commodo venenatis eget
% dui. Etiam sagittis eleifend elementum.

% Nam interdum magna at lectus dignissim, ac dignissim lorem
% rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
% massa et mattis lacinia.

\end{document}
\endinput

%% End of file `sample-authordraft.tex'.
