% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}




@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}


@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{yang2023appagent,
  title={AppAgent: Multimodal Agents as Smartphone Users},
  author={Yang, Zhao and Liu, Jiaxuan and Han, Yucheng and Chen, Xin and Huang, Zebiao and Fu, Bin and Yu, Gang},
  journal={arXiv preprint arXiv:2312.13771},
  year={2023}
}

@article{ding2024mobileagent,
  title={MobileAgent: enhancing mobile control via human-machine interaction and SOP integration},
  author={Ding, Tinghe},
  journal={arXiv preprint arXiv:2401.04124},
  year={2024}
}

@article{li2020mapping,
  title={Mapping natural language instructions to mobile UI action sequences},
  author={Li, Yang and He, Jiacong and Zhou, Xin and Zhang, Yuan and Baldridge, Jason},
  journal={arXiv preprint arXiv:2005.03776},
  year={2020}
}

@article{zhang2024android,
  title={Android in the Zoo: Chain-of-Action-Thought for GUI Agents},
  author={Zhang, Jiwen and Wu, Jihao and Teng, Yihua and Liao, Minghui and Xu, Nuo and Xiao, Xiao and Wei, Zhongyu and Tang, Duyu},
  journal={arXiv preprint arXiv:2403.02713},
  year={2024}
}
@article{yan2023gpt,
  title={Gpt-4v in wonderland: Large multimodal models for zero-shot smartphone gui navigation},
  author={Yan, An and Yang, Zhengyuan and Zhu, Wanrong and Lin, Kevin and Li, Linjie and Wang, Jianfeng and Yang, Jianwei and Zhong, Yiwu and McAuley, Julian and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2311.07562},
  year={2023}
}


@article{hong2023cogagent,
  title={CogAgent: A Visual Language Model for GUI Agents},
  author={Hong, Wenyi and Wang, Weihan and Lv, Qingsong and Xu, Jiazheng and Yu, Wenmeng and Ji, Junhui and Wang, Yan and Wang, Zihan and Dong, Yuxiao and Ding, Ming and others},
  journal={arXiv preprint arXiv:2312.08914},
  year={2023}
}

@article{zeng2023agenttuning,
  title={Agenttuning: Enabling generalized agent abilities for llms},
  author={Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2310.12823},
  year={2023}
}

@article{rawles2023android,
  title={Android in the wild: A large-scale dataset for android device control},
  author={Rawles, Christopher and Li, Alice and Rodriguez, Daniel and Riva, Oriana and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2307.10088},
  year={2023}
}

@article{baechler2024screenai,
  title={ScreenAI: A Vision-Language Model for UI and Infographics Understanding},
  author={Baechler, Gilles and Sunkara, Srinivas and Wang, Maria and Zubach, Fedir and Mansoor, Hassan and Etter, Vincent and C{\u{a}}rbune, Victor and Lin, Jason and Chen, Jindong and Sharma, Abhanshu},
  journal={arXiv preprint arXiv:2402.04615},
  year={2024}
}


@article{wu2024mobilevlm,
  title={MobileVLM: A Vision-Language Model for Better Intra-and Inter-UI Understanding},
  author={Wu, Qinzhuo and Xu, Weikai and Liu, Wei and Tan, Tao and Liu, Jianfeng and Li, Ang and Luan, Jian and Wang, Bin and Shang, Shuo},
  journal={arXiv preprint arXiv:2409.14818},
  year={2024}
}



@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhan2023you,
  title={You only look at screens: Multimodal chain-of-action agents},
  author={Zhan, Zhuosheng and Zhang, Aston},
  journal={arXiv preprint arXiv:2309.11436},
  year={2023}
}

@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24185--24198},
  year={2024}
}


@inproceedings{cheng2021boundary,
  title={Boundary IoU: Improving object-centric image segmentation evaluation},
  author={Cheng, Bowen and Girshick, Ross and Doll{\'a}r, Piotr and Berg, Alexander C and Kirillov, Alexander},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={15334--15342},
  year={2021}
}


@article{you2024ferret,
  title={Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs},
  author={You, Keen and Zhang, Haotian and Schoop, Eldon and Weers, Floris and Swearngin, Amanda and Nichols, Jeffrey and Yang, Yinfei and Gan, Zhe},
  journal={arXiv preprint arXiv:2404.05719},
  year={2024}
}

@article{you2023ferret,
  title={Ferret: Refer and ground anything anywhere at any granularity},
  author={You, Haoxuan and Zhang, Haotian and Gan, Zhe and Du, Xianzhi and Zhang, Bowen and Wang, Zirui and Cao, Liangliang and Chang, Shih-Fu and Yang, Yinfei},
  journal={arXiv preprint arXiv:2310.07704},
  year={2023}
}

@article{zhang2024ferret,
  title={Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models},
  author={Zhang, Haotian and You, Haoxuan and Dufter, Philipp and Zhang, Bowen and Chen, Chen and Chen, Hong-You and Fu, Tsu-Jui and Wang, William Yang and Chang, Shih-Fu and Gan, Zhe and others},
  journal={arXiv preprint arXiv:2404.07973},
  year={2024}
}

@inproceedings{deka2017rico,
  title={Rico: A mobile app dataset for building data-driven design applications},
  author={Deka, Biplab and Huang, Zifeng and Franzen, Chad and Hibschman, Joshua and Afergan, Daniel and Li, Yang and Nichols, Jeffrey and Kumar, Ranjitha},
  booktitle={Proceedings of the 30th annual ACM symposium on user interface software and technology},
  pages={845--854},
  year={2017}
}

@article{chai2024amex,
  title={AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents},
  author={Chai, Yuxiang and Huang, Siyuan and Niu, Yazhe and Xiao, Han and Liu, Liang and Zhang, Dingyu and Gao, Peng and Ren, Shuai and Li, Hongsheng},
  journal={arXiv preprint arXiv:2407.17490},
  year={2024}
}

@article{bai2024digirl,
  title={Digirl: Training in-the-wild device-control agents with autonomous reinforcement learning},
  author={Bai, Hao and Zhou, Yifei and Cemri, Mert and Pan, Jiayi and Suhr, Alane and Levine, Sergey and Kumar, Aviral},
  journal={arXiv preprint arXiv:2406.11896},
  year={2024}
}


@inproceedings{yuan2023rrhf,
  title={RRHF: Rank Responses to Align Language Models with Human Feedback},
  author={Yuan, Hongyi and Yuan, Zheng and Tan, Chuanqi and Wang, Wei and Huang, Songfang and Huang, Fei},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{liu2023rltf,
  title={RLTF: Reinforcement Learning from Unit Test Feedback},
  author={Liu, Jiate and Zhu, Yiqin and Xiao, Kaiwen and Fu, Qiang and Han, Xiao and Yang, Wei and Ye, Deheng},
  journal={arXiv preprint arXiv:2307.04349},
  year={2023}
}
@article{shen2023pangu,
  title={Pangu-coder2: Boosting large language models for code with ranking feedback},
  author={Shen, Bo and Zhang, Jiaxin and Chen, Taihong and Zan, Daoguang and Geng, Bing and Fu, An and Zeng, Muhan and Yu, Ailun and Ji, Jichuan and Zhao, Jingyang and others},
  journal={arXiv preprint arXiv:2307.14936},
  year={2023}
}

@inproceedings{ma2024coco,
  title={Coco-agent: A comprehensive cognitive mllm agent for smartphone gui automation},
  author={Ma, Xinbei and Zhang, Zhuosheng and Zhao, Hai},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={9097--9110},
  year={2024}
}
@inproceedings{wang2021screen2words,
  title={Screen2words: Automatic mobile UI summarization with multimodal learning},
  author={Wang, Bryan and Li, Gang and Zhou, Xin and Chen, Zhourong and Grossman, Tovi and Li, Yang},
  booktitle={The 34th Annual ACM Symposium on User Interface Software and Technology},
  pages={498--510},
  year={2021}
}

@inproceedings{li2021screen2vec,
  title={Screen2vec: Semantic embedding of gui screens and gui components},
  author={Li, Toby Jia-Jun and Popowski, Lindsay and Mitchell, Tom and Myers, Brad A},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--15},
  year={2021}
}

@article{hsiao2022screenqa,
  title={Screenqa: Large-scale question-answer pairs over mobile app screenshots},
  author={Hsiao, Yu-Chung and Zubach, Fedir and Baechler, Gilles and Carbune, Victor and Lin, Jason and Wang, Maria and Sunkara, Srinivas and Zhu, Yun and Chen, Jindong},
  journal={arXiv preprint arXiv:2209.08199},
  year={2022}
}
@inproceedings{leiva2020enrico,
  title={Enrico: A dataset for topic modeling of mobile UI designs},
  author={Leiva, Luis A and Hota, Asutosh and Oulasvirta, Antti},
  booktitle={22nd International Conference on Human-Computer Interaction with Mobile Devices and Services},
  pages={1--4},
  year={2020}
}
@article{bai2021uibert,
  title={Uibert: Learning generic multimodal representations for ui understanding},
  author={Bai, Chongyang and Zang, Xiaoxue and Xu, Ying and Sunkara, Srinivas and Rastogi, Abhinav and Chen, Jindong and others},
  journal={arXiv preprint arXiv:2107.13731},
  year={2021}
}
@inproceedings{bunian2021vins,
  title={Vins: Visual search for mobile user interface design},
  author={Bunian, Sara and Li, Kai and Jemmali, Chaima and Harteveld, Casper and Fu, Yun and Seif El-Nasr, Magy Seif},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2021}
}

@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}
@article{wang2024distrl,
  title={Distrl: An asynchronous distributed reinforcement learning framework for on-device control agents},
  author={Wang, Taiyi and Wu, Zhihao and Liu, Jianheng and Hao, Jianye and Wang, Jun and Shao, Kun},
  journal={arXiv preprint arXiv:2410.14803},
  year={2024}
}