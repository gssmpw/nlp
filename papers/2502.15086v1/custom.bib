@INPROCEEDINGS{chatgpt,
  author={Bahrini, Aram and Khamoshifar, Mohammadsadra and Abbasimehr, Hossein and Riggs, Robert J. and Esmaeili, Maryam and Majdabadkohne, Rastin Mastali and Pasehvar, Morteza},
  booktitle={2023 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={ChatGPT: Applications, Opportunities, and Threats}, 
  year={2023},
  volume={},
  number={},
  pages={274-279},
  keywords={Industries;Ethics;Education;Oral communication;Reinforcement learning;Chatbots;Transformers;Artificial Intelligence;ChatGPT;Chatbots;Natural language generation;Education},
  doi={10.1109/SIEDS58326.2023.10137850}}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{qin2023chatgpt,
  title={Is ChatGPT a general-purpose natural language processing task solver?},
  author={Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
  journal={arXiv preprint arXiv:2302.06476},
  year={2023}
}
@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}
@article{lee2024aligning,
  title={Aligning to thousands of preferences via system message generalization},
  author={Lee, Seongyun and Park, Sue Hyun and Kim, Seungone and Seo, Minjoon},
  journal={arXiv preprint arXiv:2405.17977},
  year={2024}
}
@article{xu2024safedecoding,
  title={Safedecoding: Defending against jailbreak attacks via safety-aware decoding},
  author={Xu, Zhangchen and Jiang, Fengqing and Niu, Luyao and Jia, Jinyuan and Lin, Bill Yuchen and Poovendran, Radha},
  journal={arXiv preprint arXiv:2402.08983},
  year={2024}
}
@article{dong2024attacks,
  title={Attacks, defenses and evaluations for llm conversation safety: A survey},
  author={Dong, Zhichen and Zhou, Zhanhui and Yang, Chao and Shao, Jing and Qiao, Yu},
  journal={arXiv preprint arXiv:2402.09283},
  year={2024}
}
@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}
@article{vijjini2024exploring,
  title={Exploring Safety-Utility Trade-Offs in Personalized Language Models},
  author={Vijjini, Anvesh Rao and Chowdhury, Somnath Basu Roy and Chaturvedi, Snigdha},
  journal={arXiv preprint arXiv:2406.11107},
  year={2024}
}
@article{parrish2021bbq,
  title={BBQ: A hand-built bias benchmark for question answering},
  author={Parrish, Alicia and Chen, Angelica and Nangia, Nikita and Padmakumar, Vishakh and Phang, Jason and Thompson, Jana and Htut, Phu Mon and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2110.08193},
  year={2021}
}
@article{zhang2023safetybench,
  title={Safetybench: Evaluating the safety of large language models with multiple choice questions},
  author={Zhang, Zhexin and Lei, Leqi and Wu, Lindong and Sun, Rui and Huang, Yongkang and Long, Chong and Liu, Xiao and Lei, Xuanyu and Tang, Jie and Huang, Minlie},
  journal={arXiv preprint arXiv:2309.07045},
  year={2023}
}
@article{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, N},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}
@article{tedeschi2024alert,
  title={ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming},
  author={Tedeschi, Simone and Friedrich, Felix and Schramowski, Patrick and Kersting, Kristian and Navigli, Roberto and Nguyen, Huu and Li, Bo},
  journal={arXiv preprint arXiv:2404.08676},
  year={2024}
}
@article{sun2023safety,
  title={Safety assessment of chinese large language models},
  author={Sun, Hao and Zhang, Zhexin and Deng, Jiawen and Cheng, Jiale and Huang, Minlie},
  journal={arXiv preprint arXiv:2304.10436},
  year={2023}
}
@article{zhang2024agent,
  title={Agent-SafetyBench: Evaluating the Safety of LLM Agents},
  author={Zhang, Zhexin and Cui, Shiyao and Lu, Yida and Zhou, Jingzhuo and Yang, Junxiao and Wang, Hongning and Huang, Minlie},
  journal={arXiv preprint arXiv:2412.14470},
  year={2024}
}
@article{zhang2024personalization,
  title={Personalization of large language models: A survey},
  author={Zhang, Zhehao and Rossi, Ryan A and Kveton, Branislav and Shao, Yijia and Yang, Diyi and Zamani, Hamed and Dernoncourt, Franck and Barrow, Joe and Yu, Tong and Kim, Sungchul and others},
  journal={arXiv preprint arXiv:2411.00027},
  year={2024}
}
@article{perez2022red,
  title={Red teaming language models with language models},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2202.03286},
  year={2022}
}
@article{zhuo2023red,
  title={Red teaming chatgpt via jailbreaking: Bias, robustness, reliability and toxicity},
  author={Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Xing, Zhenchang},
  journal={arXiv preprint arXiv:2301.12867},
  year={2023}
}
@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}
@article{xie2024sorry,
  title={Sorry-bench: Systematically evaluating large language model safety refusal behaviors},
  author={Xie, Tinghao and Qi, Xiangyu and Zeng, Yi and Huang, Yangsibo and Sehwag, Udari Madhushani and Huang, Kaixuan and He, Luxi and Wei, Boyi and Li, Dacheng and Sheng, Ying and others},
  journal={arXiv preprint arXiv:2406.14598},
  year={2024}
}
@inproceedings{hua2024trustagent,
  title={Trustagent: Towards safe and trustworthy llm-based agents through agent constitution},
  author={Hua, Wenyue and Yang, Xianjun and Jin, Mingyu and Li, Zelong and Cheng, Wei and Tang, Ruixiang and Zhang, Yongfeng},
  booktitle={Trustworthy Multi-modal Foundation Models and AI Agents (TiFA)},
  year={2024}
}
@article{yin2024safeagentbench,
  title={SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents},
  author={Yin, Sheng and Pang, Xianghe and Ding, Yuanzhuo and Chen, Menglan and Bi, Yutong and Xiong, Yichen and Huang, Wenhao and Xiang, Zhen and Shao, Jing and Chen, Siheng},
  journal={arXiv preprint arXiv:2412.13178},
  year={2024}
}
@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{kamalloo2023evaluating,
  title={Evaluating open-domain question answering in the era of large language models},
  author={Kamalloo, Ehsan and Dziri, Nouha and Clarke, Charles LA and Rafiei, Davood},
  journal={arXiv preprint arXiv:2305.06984},
  year={2023}
}
@article{in2024diversify,
  title={Diversify-verify-adapt: Efficient and Robust Retrieval-Augmented Ambiguous Question Answering},
  author={In, Yeonjun and Kim, Sungchul and Rossi, Ryan A and Tanjim, Md Mehrab and Yu, Tong and Sinha, Ritwik and Park, Chanyoung},
  journal={arXiv preprint arXiv:2409.02361},
  year={2024}
}
@article{asai2023self,
  title={Self-rag: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2023}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{qin2023toolllm,
  title={Toolllm: Facilitating large language models to master 16000+ real-world apis},
  author={Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and others},
  journal={arXiv preprint arXiv:2307.16789},
  year={2023}
}
@article{wang2024survey,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={186345},
  year={2024},
  publisher={Springer}
}
@misc{openai-api,
  author = "OpenAI",
  title = "OpenAI API",
  howpublished = "\url{https://openai.com/index/openai-api/}",
}

@misc{claude-api,
  author = "Anthropic",
  title = "Anthropic API",
  howpublished = "\url{https://www.anthropic.com/api/}",
}
@misc{togetherai-api,
  author = "TogetherAI",
  title = "TogetherAI API",
  howpublished = "\url{https://www.together.ai/}",
}

@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}
@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}
@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}
@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}
@article{anthropic2024claude,
  title={Claude 3.5 sonnet model card addendum},
  author={Anthropic, AI},
  journal={Claude-3.5 Model Card},
  volume={3},
  pages={1--8},
  year={2024}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@inproceedings{chakraborty2024maxmin,
  title={Maxmin-rlhf: Towards equitable alignment of large language models with diverse human preferences},
  author={Chakraborty, Souradip and Qiu, Jiahao and Yuan, Hui and Koppel, Alec and Huang, Furong and Manocha, Dinesh and Bedi, Amrit and Wang, Mengdi},
  booktitle={ICML 2024 Workshop on Models of Human Feedback for AI Alignment},
  year={2024}
}
@article{cheng2023everyone,
  title={Everyone deserves a reward: Learning customized human preferences},
  author={Cheng, Pengyu and Xie, Jiawen and Bai, Ke and Dai, Yong and Du, Nan},
  journal={arXiv preprint arXiv:2309.03126},
  year={2023}
}
@article{jang2023personalized,
  title={Personalized soups: Personalized large language model alignment via post-hoc parameter merging},
  author={Jang, Joel and Kim, Seungone and Lin, Bill Yuchen and Wang, Yizhong and Hessel, Jack and Zettlemoyer, Luke and Hajishirzi, Hannaneh and Choi, Yejin and Ammanabrolu, Prithviraj},
  journal={arXiv preprint arXiv:2310.11564},
  year={2023}
}
@article{li2024personalized,
  title={Personalized language modeling from personalized human feedback},
  author={Li, Xinyu and Zhou, Ruiyang and Lipton, Zachary C and Leqi, Liu},
  journal={arXiv preprint arXiv:2402.05133},
  year={2024}
}
@article{wu2023fine,
  title={Fine-grained human feedback gives better rewards for language model training},
  author={Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={59008--59033},
  year={2023}
}
@article{stelmakh2022asqa,
  title={ASQA: Factoid questions meet long-form answers},
  author={Stelmakh, Ivan and Luan, Yi and Dhingra, Bhuwan and Chang, Ming-Wei},
  journal={arXiv preprint arXiv:2204.06092},
  year={2022}
}
@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}