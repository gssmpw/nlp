\section{Ethics Statement}
This project has been classified as exempt by the Institutional Review Board (IRB). All hired experts were at least 18 years old and hold either a master’s or doctoral degree in a mental health-related field, such as psychology or counseling psychology. Each expert received a fixed payment of \$1,500 for all annotations, corresponding to an approximate hourly rate of \$60. The goal of this work is to leverage synthetic data and preference learning algorithms to equip LLMs with the skills needed to generate responses to client speeches in psycho-counseling. However, these responses should not be directly exposed to clients without review by real therapists. Instead, they serve as assistive suggestions to help therapists draft responses, improving the efficiency of psycho-counseling: 


\noindent\textbf{Enhancing Human Expertise, Not Replacing It}. AI tools should function as supportive mechanisms that enhance the capabilities of mental health professionals rather than replacing them. These tools can provide therapists with valuable data-driven insights into client speech, suggest psycho-counseling responses, and assist in structuring interventions. However, their role remains assistive, ensuring human expertise remains central to patient care.

\noindent\textbf{Training and Ethical Integration}. The effective use of AI in psycho-counseling requires mental health professionals to receive specialized training. This ensures they can integrate AI-generated insights into their practice ethically and effectively, maintaining both professional oversight and adherence to best practices.

\noindent\textbf{Safeguards Against Unsupervised AI Interaction}. To uphold safety and ethical integrity, AI-generated insights and psycho-counseling suggestions should always be reviewed by a licensed professional before reaching a patient. Deployment models must include strict access controls, intervention thresholds, and supervision mechanisms to prevent autonomous operation without human oversight.

\noindent\textbf{Transparency and Accountability}
\begin{itemize}
    \item Open Communication: AI deployment in mental health should involve clear and open communication with all stakeholders, including therapists, patients, and regulatory bodies. This fosters trust and ensures transparency in the development and use of AI tools.
    \item Explainability and Justification: AI-generated recommendations should be interpretable, providing clear reasoning behind decisions. This is particularly crucial for psycho-counseling suggestions and mental health assessments, where explainability is essential to professional trust and responsible use.
    \item User Awareness: Patients and therapists interacting with AI must be fully informed about the system’s role, capabilities, and limitations to prevent over-reliance and misapplication.
\end{itemize}


\noindent\textbf{Safety and Privacy Standards}
\begin{itemize}
    \item Error Mitigation: AI models should be rigorously tested to minimize the risk of errors in medical advice or psychological recommendations. Misdiagnoses or inappropriate interventions could have significant negative consequences.
    \item Preventing Misinformation and Hallucinations: AI systems must prioritize accuracy by reducing misinformation and hallucinations, ensuring responses are evidence-based and context-appropriate.
    \item Data Privacy and Confidentiality: AI tools in mental health care must adhere to strict data privacy regulations, ensuring that patient interactions remain secure and confidential. Compliance with legal and ethical data-handling standards is critical to protecting users from breaches or misuse.
\end{itemize}
