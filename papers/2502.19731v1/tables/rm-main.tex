\begingroup
\setlength{\tabcolsep}{4pt}
\begin{table}[th]
    \centering
    \resizebox{0.95\textwidth}{!}{%
        \begin{tabular}{lcc|cc}
            \toprule
            \textbf{Model} & \textbf{Accuracy} & \textbf{AUC} ($\uparrow$) & \textbf{ECE} ($\downarrow$) & \textbf{Brier} ($\downarrow$) \\
            \midrule
            \textbf{State-of-the-art Reward Models} & & &\\
            Skywork-Reward-Llama-3.1-8B-v0.2~\citep{Liu2024-az} & 57.9 & 0.623 & 0.331 & 0.379 \\
            Skywork-Reward-Gemma-2-27B~\citep{Liu2024-az} & 69.2 & 0.740 & 0.123 & 0.229 \\
            Llama-3.1-Nemotron-70B-Reward~\citep{Wang2024-xc} & 87.3 & 0.938 & \textbf{0.040} & 0.102 \\
            \midrule
            \textbf{Generative LLMs} & & & \\
            % Llama3-8B & 80.0 \\
            gemma-2-9b-it~\citep{Gemma-Team2024-jc} & 81.5 & - & - & - \\
            Mistral-Nemo-Instruct-2407\tablefootnote{\url{https://mistral.ai/news/mistral-nemo/}} & 78.0 & - & -  & - \\
            Llama-3.1-70B-Instruct~\citep{Llama-Team2024-vb} & 88.2 & - & - & - \\
            \midrule
            \textbf{Our Reward Models} & &  & \\
            \rewards{} & \textbf{98.1} & 0.997 & 0.050 & \textbf{0.014}  \\
            \rewardl{} & 97.8 & \textbf{0.998} & 0.045 & 0.016 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Performance on the Testing Set of \dataset{}}
    \label{tab:acc}
\end{table}
\endgroup