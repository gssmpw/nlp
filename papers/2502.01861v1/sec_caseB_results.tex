\subsection{Results for Model B}

Across several possible priors for transfer learning, backbone architectures, and datasets, our findings are:

\textbf{The runtime of our DE ELBO is affordable, and avoids the extreme runtime costs of grid search.}
In Tab.~\ref{tab:computational_time_comparison}, we show that an individual SGD run of our DE ELBo has comparable cost to one SGD run of standard MAP estimation. However, the cumulative cost of grid search needed to select $\lambda,\tau$ for the MAP baseline is far higher than our approach: for PTYL the recommended grid search costs over 148 hours; our approach delivers in under 3 hours.

\textbf{Our DE ELBo achieves heldout accuracy comparable to existing approaches with far less compute time.}
In Fig.~\ref{fig:ConvNeXt_Tiny_computational_time_comparison}, we compare test set accuracy on CIFAR-10~\citep{krizhevsky2010cifar}, Oxford-IIIT Pet~\citep{parkhi2012cats}, and Oxford Flower~\citep{nilsback2008automated} images over training time for L2-SP with \baseline\ and our DE ELBo.
Our DE ELBo achieves comparable heldout accuracy with far less compute time.
When training data is limited in size (Pet-37 $N=370$ in Fig.~\ref{fig:ConvNeXt_Tiny_computational_time_comparison}), our approach can perform even better than grid search.
In Tab.~\ref{tab:acc_subset}, we report test-set accuracies for both expensive grid search and our (faster) DE ELBo. See App.~\ref{sec:results} for more results.