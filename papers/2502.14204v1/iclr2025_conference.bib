@incollection{Bengio+chapter2007,
	author = {Bengio, Yoshua and LeCun, Yann},
	booktitle = {Large Scale Kernel Machines},
	publisher = {MIT Press},
	title = {Scaling Learning Algorithms Towards {AI}},
	year = {2007}
}

@article{Hinton06,
	author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
	journal = {Neural Computation},
	pages = {1527--1554},
	title = {A Fast Learning Algorithm for Deep Belief Nets},
	volume = {18},
	year = {2006}
}

@book{goodfellow2016deep,
	title={Deep learning},
	author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
	volume={1},
	year={2016},
	publisher={MIT Press}
}

@article{Yuan2023RRHFRR,
	title={RRHF: Rank Responses to Align Language Models with Human Feedback without tears},
	author={Zheng Yuan and Hongyi Yuan and Chuanqi Tan and Wei Wang and Songfang Huang and Feiran Huang},
	journal={ArXiv},
	year={2023},
	volume={abs/2304.05302},
	url={https://api.semanticscholar.org/CorpusID:258059818}
}

@article{rafailov2023direct,
	title={Direct preference optimization: Your language model is secretly a reward model},
	author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
	journal={arXiv preprint arXiv:2305.18290},
	year={2023}
}

@article{zhu2024lire,
	title={LIRE: listwise reward enhancement for preference alignment},
	author={Zhu, Mingye and Liu, Yi and Zhang, Lei and Guo, Junbo and Mao, Zhendong},
	journal={arXiv preprint arXiv:2405.13516},
	year={2024}
}

@article{stiennon2020learning,
	title={Learning to summarize with human feedback},
	author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	pages={3008--3021},
	year={2020}
}

@article{Gao2024LinearAA,
	title={Linear Alignment: A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback},
	author={Songyang Gao and Qiming Ge and Wei Shen and Shihan Dou and Junjie Ye and Xiao Wang and Rui Zheng and Yicheng Zou and Zhi Chen and Hang Yan and Qi Zhang and Dahua Lin},
	journal={ArXiv},
	year={2024},
	volume={abs/2401.11458},
	url={https://api.semanticscholar.org/CorpusID:267068705}
}

@inproceedings{Pang2024ARMAW,
	title={ARM: Alignment with Residual Energy-Based Model},
	author={Bo Pang and Caiming Xiong and Yingbo Zhou},
	booktitle={North American Chapter of the Association for Computational Linguistics},
	year={2024},
	url={https://api.semanticscholar.org/CorpusID:270514472}
}

@article{Dathathri2019PlugAP,
	title={Plug and Play Language Models: A Simple Approach to Controlled Text Generation},
	author={Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu},
	journal={ArXiv},
	year={2019},
	volume={abs/1912.02164},
	url={https://api.semanticscholar.org/CorpusID:208617790}
}

@article{schulman2017proximal,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}

@article{liu2021dexperts,
	title={DExperts: Decoding-time controlled text generation with experts and anti-experts},
	author={Liu, Alisa and Sap, Maarten and Lu, Ximing and Swayamdipta, Swabha and Bhagavatula, Chandra and Smith, Noah A and Choi, Yejin},
	journal={arXiv preprint arXiv:2105.03023},
	year={2021}
}

@article{qin2022cold,
	title={Cold decoding: Energy-based constrained text generation with langevin dynamics},
	author={Qin, Lianhui and Welleck, Sean and Khashabi, Daniel and Choi, Yejin},
	journal={Advances in Neural Information Processing Systems},
	volume={35},
	pages={9538--9551},
	year={2022}
}

@article{ouyang2022training,
	title={Training language models to follow instructions with human feedback},
	author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
	journal={Advances in Neural Information Processing Systems},
	volume={35},
	pages={27730--27744},
	year={2022}
}

@article{casper2023open,
	title={Open problems and fundamental limitations of reinforcement learning from human feedback},
	author={Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
	journal={arXiv preprint arXiv:2307.15217},
	year={2023}
}

@inproceedings{lin2023unlocking,
	title={The unlocking spell on base llms: Rethinking alignment via in-context learning},
	author={Lin, Bill Yuchen and Ravichander, Abhilasha and Lu, Ximing and Dziri, Nouha and Sclar, Melanie and Chandu, Khyathi and Bhagavatula, Chandra and Choi, Yejin},
	booktitle={The Twelfth International Conference on Learning Representations},
	year={2023}
}

@article{Zhou2023LIMALI,
	title={LIMA: Less Is More for Alignment},
	author={Chunting Zhou and Pengfei Liu and Puxin Xu and Srini Iyer and Jiao Sun and Yuning Mao and Xuezhe Ma and Avia Efrat and Ping Yu and L. Yu and Susan Zhang and Gargi Ghosh and Mike Lewis and Luke Zettlemoyer and Omer Levy},
	journal={ArXiv},
	year={2023},
	volume={abs/2305.11206},
	url={https://api.semanticscholar.org/CorpusID:258822910}
}

@inproceedings{peters2007reinforcement,
	title={Reinforcement learning by reward-weighted regression for operational space control},
	author={Peters, Jan and Schaal, Stefan},
	booktitle={Proceedings of the 24th international conference on Machine learning},
	pages={745--750},
	year={2007}
}

@article{korbak2022reinforcement,
	title={On reinforcement learning and distribution matching for fine-tuning language models with no catastrophic forgetting},
	author={Korbak, Tomasz and Elsahar, Hady and Kruszewski, Germ{\'a}n and Dymetman, Marc},
	journal={Advances in Neural Information Processing Systems},
	volume={35},
	pages={16203--16220},
	year={2022}
}

@article{deng2020residual,
	title={Residual energy-based models for text generation},
	author={Deng, Yuntian and Bakhtin, Anton and Ott, Myle and Szlam, Arthur and Ranzato, Marc'Aurelio},
	journal={arXiv preprint arXiv:2004.11714},
	year={2020}
}

@article{hinton2002training,
	title={Training products of experts by minimizing contrastive divergence},
	author={Hinton, Geoffrey E},
	journal={Neural computation},
	volume={14},
	number={8},
	pages={1771--1800},
	year={2002},
	publisher={MIT Press}
}

@article{lecun2006tutorial,
	title={A tutorial on energy-based learning},
	author={LeCun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, M and Huang, Fujie},
	journal={Predicting structured data},
	volume={1},
	number={0},
	year={2006}
}

@inproceedings{ranzato2007unified,
	title={A unified energy-based framework for unsupervised learning},
	author={Ranzato, Marcâ€™Aurelio and Boureau, Y-Lan and Chopra, Sumit and LeCun, Yann},
	booktitle={Artificial Intelligence and Statistics},
	pages={371--379},
	year={2007},
	organization={PMLR}
}

@article{cheng2023everyone,
	title={Everyone deserves a reward: Learning customized human preferences},
	author={Cheng, Pengyu and Xie, Jiawen and Bai, Ke and Dai, Yong and Du, Nan},
	journal={arXiv preprint arXiv:2309.03126},
	year={2023}
}

@article{li2022contrastive,
	title={Contrastive decoding: Open-ended text generation as optimization},
	author={Li, Xiang Lisa and Holtzman, Ari and Fried, Daniel and Liang, Percy and Eisner, Jason and Hashimoto, Tatsunori and Zettlemoyer, Luke and Lewis, Mike},
	journal={arXiv preprint arXiv:2210.15097},
	year={2022}
}

@article{liang2024controllable,
	title={Controllable Text Generation for Large Language Models: A Survey},
	author={Liang, Xun and Wang, Hanyu and Wang, Yezhaohui and Song, Shichao and Yang, Jiawei and Niu, Simin and Hu, Jie and Liu, Dan and Yao, Shunyu and Xiong, Feiyu and others},
	journal={arXiv preprint arXiv:2408.12599},
	year={2024}
}

@article{khalifa2020distributional,
	title={A distributional approach to controlled text generation},
	author={Khalifa, Muhammad and Elsahar, Hady and Dymetman, Marc},
	journal={arXiv preprint arXiv:2012.11635},
	year={2020}
}

@article{zeldes2020technical,
	title={Technical report: Auxiliary tuning and its application to conditional text generation},
	author={Zeldes, Yoel and Padnos, Dan and Sharir, Or and Peleg, Barak},
	journal={arXiv preprint arXiv:2006.16823},
	year={2020}
}

@article{zhang2022discup,
	title={Discup: Discriminator cooperative unlikelihood prompt-tuning for controllable text generation},
	author={Zhang, Hanqing and Song, Dawei},
	journal={arXiv preprint arXiv:2210.09551},
	year={2022}
}

@article{xu2024safedecoding,
	title={Safedecoding: Defending against jailbreak attacks via safety-aware decoding},
	author={Xu, Zhangchen and Jiang, Fengqing and Niu, Luyao and Jia, Jinyuan and Lin, Bill Yuchen and Poovendran, Radha},
	journal={arXiv preprint arXiv:2402.08983},
	year={2024}
}

@article{shi2024navigating,
	title={Navigating the overkill in large language models},
	author={Shi, Chenyu and Wang, Xiao and Ge, Qiming and Gao, Songyang and Yang, Xianjun and Gui, Tao and Zhang, Qi and Huang, Xuanjing and Zhao, Xun and Lin, Dahua},
	journal={arXiv preprint arXiv:2401.17633},
	year={2024}
}


@article{jang2023personalized,
	title={Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging},
	author={Jang, Joel and Kim, Seungone and Lin, Bill Yuchen and Wang, Yizhong and Hessel, Jack and Zettlemoyer, Luke and Hajishirzi, Hannaneh and Choi, Yejin and Ammanabrolu, Prithviraj},
	journal={arXiv preprint arXiv:2310.11564},
	year={2023}
}

@article{bai2022training,
	title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
	author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
	journal={arXiv preprint arXiv:2204.05862},
	year={2022}
}

@article{pal2024smaug,
	title={Smaug: Fixing failure modes of preference optimisation with dpo-positive},
	author={Pal, Arka and Karkhanis, Deep and Dooley, Samuel and Roberts, Manley and Naidu, Siddartha and White, Colin},
	journal={arXiv preprint arXiv:2402.13228},
	year={2024}
}

@article{li2023rain,
	title={Rain: Your language models can align themselves without finetuning},
	author={Li, Yuhui and Wei, Fangyun and Zhao, Jinjing and Zhang, Chao and Zhang, Hongyang},
	journal={arXiv preprint arXiv:2309.07124},
	year={2023}
}

@article{ji2023language,
	title={Language Model Decoding as Direct Metrics Optimization},
	author={Ji, Haozhe and Ke, Pei and Wang, Hongning and Huang, Minlie},
	journal={arXiv preprint arXiv:2310.01041},
	year={2023}
}

@article{parshakova2019global,
	title={Global autoregressive models for data-efficient sequence learning},
	author={Parshakova, Tetiana and Andreoli, Jean-Marc and Dymetman, Marc},
	journal={arXiv preprint arXiv:1909.07063},
	year={2019}
}

@article{grover2019bias,
	title={Bias correction of learned generative models using likelihood-free importance weighting},
	author={Grover, Aditya and Song, Jiaming and Kapoor, Ashish and Tran, Kenneth and Agarwal, Alekh and Horvitz, Eric J and Ermon, Stefano},
	journal={Advances in neural information processing systems},
	volume={32},
	year={2019}
}

@article{shapiro2003monte,
	title={Monte Carlo sampling methods},
	author={Shapiro, Alexander},
	journal={Handbooks in operations research and management science},
	volume={10},
	pages={353--425},
	year={2003},
	publisher={Elsevier}
}

@article{ranzato2015sequence,
	title={Sequence level training with recurrent neural networks},
	author={Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech},
	journal={arXiv preprint arXiv:1511.06732},
	year={2015}
}

@article{Nakano2021WebGPTBQ,
	title={WebGPT: Browser-assisted question-answering with human feedback},
	author={Reiichiro Nakano and Jacob Hilton and Suchir Balaji and Jeff Wu and Ouyang Long and Christina Kim and Christopher Hesse and Shantanu Jain and Vineet Kosaraju and William Saunders and Xu Jiang and Karl Cobbe and Tyna Eloundou and Gretchen Krueger and Kevin Button and Matthew Knight and Benjamin Chess and John Schulman},
	journal={ArXiv},
	year={2021},
	volume={abs/2112.09332},
	url={https://api.semanticscholar.org/CorpusID:245329531}
}

@article{peng2023does,
	title={When does In-context Learning Fall Short and Why? A Study on Specification-Heavy Tasks},
	author={Peng, Hao and Wang, Xiaozhi and Chen, Jianhui and Li, Weikai and Qi, Yunjia and Wang, Zimu and Wu, Zhili and Zeng, Kaisheng and Xu, Bin and Hou, Lei and others},
	journal={arXiv preprint arXiv:2311.08993},
	year={2023}
}

@inproceedings{kossen2024context,
	title={In-context learning learns label relationships but is not conventional learning},
	author={Kossen, Jannik and Gal, Yarin and Rainforth, Tom},
	booktitle={The Twelfth International Conference on Learning Representations},
	year={2024}
}

@article{webson2021prompt,
	title={Do prompt-based models really understand the meaning of their prompts?},
	author={Webson, Albert and Pavlick, Ellie},
	journal={arXiv preprint arXiv:2109.01247},
	year={2021}
}

@article{Jiang2023Mistral7,
	title={Mistral 7B},
	author={Albert Qiaochu Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de Las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and L'elio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timoth{\'e}e Lacroix and William El Sayed},
	journal={ArXiv},
	year={2023},
	volume={abs/2310.06825},
	url={https://api.semanticscholar.org/CorpusID:263830494}
}

@article{Zheng2023JudgingLW,
	title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
	author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Haotong Zhang and Joseph Gonzalez and Ion Stoica},
	journal={ArXiv},
	year={2023},
	volume={abs/2306.05685},
	url={https://api.semanticscholar.org/CorpusID:259129398}
}
@article{huang2024deal,
	title={Deal: Decoding-time alignment for large language models},
	author={Huang, James Y and Sengupta, Sailik and Bonadiman, Daniele and Lai, Yi-an and Gupta, Arshit and Pappas, Nikolaos and Mansour, Saab and Kirchhoff, Katrin and Roth, Dan},
	journal={arXiv preprint arXiv:2402.06147},
	year={2024}
}

@article{shi2024decoding,
	title={Decoding-time language model alignment with multiple objectives},
	author={Shi, Ruizhe and Chen, Yifang and Hu, Yushi and Liu, Alisa and Hajishirzi, Hannaneh and Smith, Noah A and Du, Simon S},
	journal={arXiv preprint arXiv:2406.18853},
	year={2024}
}

@article{hung2024reward,
	title={Reward Steering with Evolutionary Heuristics for Decoding-time Alignment},
	author={Hung, Chia-Yu and Majumder, Navonil and Mehrish, Ambuj and Poria, Soujanya},
	journal={arXiv preprint arXiv:2406.15193},
	year={2024}
}

@article{zhu2024personality,
	title={Personality alignment of large language models},
	author={Zhu, Minjun and Yang, Linyi and Zhang, Yue},
	journal={arXiv preprint arXiv:2408.11779},
	year={2024}
}

@misc{alpaca_eval,
	author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
	title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
	year = {2023},
	month = {5},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}