@article{wilson2022harnessing,
  title={Harnessing the power of artificial intelligence in otolaryngology and the communication sciences},
  author={Wilson, B. S. and Tucci, D. L. and Moses, D. A. and Chang, E. F. and Young, N. M. and Zeng, F.-G. and Lesica, N. A. and Bur, A. M. and Kavookjian, H. and Mussatto, C. and others},
  journal={Journal of the Association for Research in Otolaryngology},
  volume={23},
  number={3},
  pages={319--349},
  year={2022},
  publisher={Springer}
}
@article{luo2019conv,
  title={Conv-tasnet: Surpassing ideal time--frequency magnitude masking for speech separation},
  author={Luo, Y. and Mesgarani, N.},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={27},
  number={8},
  pages={1256--1266},
  year={2019},
  publisher={IEEE}
}

@inproceedings{akeroyd20232nd,
  title={The 2nd clarity enhancement challenge for hearing aid speech intelligibility enhancement: Overview and outcomes},
  author={Akeroyd, M. A. and Bailey, W. and Barker, J. and Cox, T. J. and Culling, J. F. and Graetzer, S. and Naylor, G. and Podwinska, Z. and Tu, Z.},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{wang2017deep,
  title={Deep learning reinvents the hearing aid},
  author={Wang, D.},
  journal={IEEE spectrum},
  volume={54},
  number={3},
  pages={32--37},
  year={2017},
  publisher={IEEE}
}
@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, A. and Zhou, Y. and Mohamed, A. and Auli, M.},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}
@inproceedings{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, T. and Debut, L. and Sanh, V. and Chaumond, J. and Delangue, C. and Moi, A. and Cistac, P. and Rault, T. and Louf, R. and Funtowicz, M. and others},
  booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations},
  pages={38--45},
  year={2020}
}
@article{hsieh2020wavecrn,
  title={Wavecrn: An efficient convolutional recurrent neural network for end-to-end speech enhancement},
  author={Hsieh, T.-A. and Wang, H.-M. and Lu, X. and Tsao, Y.},
  journal={IEEE Signal Processing Letters},
  volume={27},
  pages={2149--2153},
  year={2020},
  publisher={IEEE}
}
@inproceedings{yang2022don,
  title={Donâ€™t separate, learn to remix: End-to-end neural remixing with joint optimization},
  author={Yang, H. and Firodiya, S. and Bryan, N. J. and Kim, M.},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={116--120},
  year={2022},
  organization={IEEE}
}

@inproceedings{huang2014deep,
  title={Deep learning for monaural speech separation},
  author={Huang, P.-S. and Kim, M. and Hasegawa-Johnson, M. and Smaragdis, P.},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1562--1566},
  year={2014},
  organization={IEEE}
}

@article{wang2008time,
  title={Time-frequency masking for speech separation and its potential for hearing aid design},
  author={Wang, D.},
  journal={Trends in amplification},
  volume={12},
  number={4},
  pages={332--353},
  year={2008},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{nezamdoust2023frequency,
  title={Frequency-Domain Functional Links For Nonlinear Feedback Cancellation In Hearing Aids},
  author={Nezamdoust, A. and Gogate, M. and Dashtipour, K. and Hussain, A. and Comminiello, D.},
  booktitle={2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{gogate2024robust,
  title={Robust Real-time Audio-Visual Speech Enhancement based on DNN and GAN},
  author={Gogate, M. and Dashtipour, K. and Hussain, A.},
  journal={IEEE Transactions on Artificial Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{gajkecki2018deep,
  title={Deep learning models to remix music for cochlear implant users},
  author={Gajecki, T. and Nogueira, W.},
  journal={The Journal of the Acoustical Society of America},
  volume={143},
  number={6},
  pages={3602--3615},
  year={2018},
  publisher={AIP Publishing}
}

@article{OpenMHA,
title = {Open community platform for hearing aid algorithm research: open Master Hearing Aid (openMHA)},
journal = {SoftwareX},
volume = {17},
pages = {100953},
year = {2022},
issn = {2352-7110},
author = {Hendrik Kayser and Tobias Herzke and Paul Maanen and Max Zimmermann and Giso Grimm and Volker Hohmann}
}

@article{halimeh2019neural,
  title={A neural network-based nonlinear acoustic echo canceller},
  author={Halimeh, M. M. and Huemmer, C. and Kellermann, W.},
  journal={IEEE Signal Processing Letters},
  volume={26},
  number={12},
  pages={1827--1831},
  year={2019},
  publisher={IEEE}
}
@article{williamson2015complex,
  title={Complex ratio masking for monaural speech separation},
  author={Williamson, D. S. and Wang, Y. and Wang, D.},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={24},
  number={3},
  pages={483--492},
  year={2015},
  publisher={IEEE}
}
@inproceedings{tan2018convolutional,
  title={A convolutional recurrent neural network for real-time speech enhancement.},
  author={Tan, K. and Wang, D.},
  booktitle={Interspeech},
  volume={2018},
  pages={3229--3233},
  year={2018}
}
@inproceedings{lu2013speech,
  title={Speech enhancement based on deep denoising autoencoder.},
  author={Lu, X. and Tsao, Y. and Matsuda, S. and Hori, C.},
  booktitle={Interspeech},
  volume={2013},
  pages={436--440},
  year={2013}
}
@INPROCEEDINGS{speaker_emb,
  author={Ji, X. and Yu, M. and Zhang, C. and Su, D. and Yu, T. and Liu, X. and Yu, D.},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Speaker-Aware Target Speaker Enhancement by Jointly Learning with Speaker Embedding Extraction}, 
  year={2020},
  volume={},
  number={},
  pages={7294-7298},
  keywords={Training;Deep learning;Speech enhancement;Signal processing;Noise measurement;Time-domain analysis;Gain;speaker-aware;target speech enhancement;speaker embedding;joint learning},
  doi={10.1109/ICASSP40776.2020.9054311}}


@misc{WHO_hearing_loss_2024,
  author = {{World Health Organization}},
  title = {Deafness and Hearing Loss},
  howpublished = {\url{https://www.who.int/news-room/fact-sheets/detail/deafness-and-hearing-loss}},
  year = {2024},
  month = {Feb}
}

@misc{Audiologists_org_2024,
  author = {{Audiologists.org}},
  title = {Deafness and Hearing Loss Statistics 2024},
  year = {2024},
  howpublished = {\url{https://www.audiologists.org/deafness-and-hearing-loss-statistics-2024}}
}

@misc{WorldHearingDay_2024,
  author = {{World Hearing Day}},
  title = {World Hearing Day 2024},
  year = {2024},
  howpublished = {\url{https://worldhearingday.org}}
}

@article{shukla2020hearing,
  author = {Shukla, A. and Harper, M. and Pedersen, E. and Goman, A. and Suen, J. J. and Price, C. and Applebaum, J. and Hoyer, M. and Lin, F. R. and Reed, N. S.},
  title = {Hearing Loss, Loneliness, and Social Isolation: A Systematic Review},
  journal = {Otolaryngology--Head and Neck Surgery: Official Journal of American Academy of Otolaryngology-Head and Neck Surgery},
  volume = {162},
  number = {5},
  pages = {622--633},
  year = {2020},
  doi = {10.1177/0194599820910377}
}


@article{lawrence2020hearing,
  author = {Lawrence, B. J. and Jayakody, D. M. P. and Bennett, R. J. and Eikelboom, R. H. and Gasson, N. and Friedland, P. L.},
  title = {Hearing loss and depression in older adults: a systematic review and meta-analysis},
  journal = {The Gerontologist},
  volume = {60},
  number = {3},
  pages = {137-154},
  year = {2020}
}


@article{ciorba2012impact,
  author = {Ciorba, A. and Bianchini, C. and Pelucchi, S. and Pastore, N.},
  title = {The impact of hearing loss on the quality of life of elderly adults},
  journal = {Clinical Interventions in Aging},
  pages = {159-163},
  year = {2012}
}


@article{lin2013hearing,
  author = {Lin, F. R. and Yaffe, K. and Xia, J. and Xue, Q.-L. and Harris, T. B. and Purchase-Helzner, E. and Satterfield, S. and Ayonayon, H. N. and Ferrucci, L. and Simonsick, E. M.},
  title = {Hearing loss and cognitive decline in older adults},
  journal = {JAMA Internal Medicine},
  volume = {173},
  number = {4},
  pages = {293-299},
  year = {2013}
}

@misc{HA2018use,
  author = {{Centers for Disease Control and Prevention}},
  title = {National Center for Health Statistics. National Health and Nutrition Examination Survey: NHANES 2015--2016 questionnaire data},
  year = {2018},
}

@article{HA2018use2,
    author = {Chien, W. and Lin, F. R.},
    title = "{Prevalence of Hearing Aid Use Among Older Adults in the United States}",
    journal = {Archives of Internal Medicine},
    volume = {172},
    number = {3},
    pages = {292-293},
    year = {2012},
    month = {02},
    doi = {10.1001/archinternmed.2011.1408},
    url = {https://doi.org/10.1001/archinternmed.2011.1408}
}


@article{HA2015use3,
  author = {McCormack, A. and Fortnum, H.},
  title = {Why do people fitted with hearing aids not wear them?},
  journal = {International Journal of Audiology},
  volume = {52},
  number = {5},
  pages = {360-368},
  year = {2013},
  doi = {10.3109/14992027.2013.769066}
}


@article{NAL-R,
  author = {Byrne, D. and Dillon, H.},
  title = {The National Acoustic Laboratories' (NAL) new procedure for selecting the gain and frequency response of a hearing aid},
  journal = {Ear and hearing},
  volume = {7},
  number = {4},
  pages = {257-265},
  year = {1986},
  doi = {10.1097/00003446-198608000-00007}
}

@article{DSL,
  author = {Scollie, S. and Seewald, R. and Cornelisse, L. and Moodie, S. and Bagatto, M. and Laurnagaray, D. and Beaulac, S. and Pumford, J.},
  title = {The Desired Sensation Level multistage input/output algorithm},
  journal = {Trends in amplification},
  volume = {9},
  number = {4},
  pages = {159-197},
  year = {2005}
}

@incollection{NAL-RP,
  author = {Byrne, D. and Parkinson, A. and Newall, P.},
  title = {Modified hearing aid selection procedures for severe/profound hearing losses},
  booktitle = {The Vanderbilt Hearing Aid Report II},
  editor = {Studebaker, G. and Bess, F. and Beck, L.},
  year = {1991},
  publisher = {York Press},
  address = {Parkton, MD}
}

@article{NAL-NL1,
  author = {Byrne, D. and Dillon, H. and Ching, T. and Katsch, R. and Keidser, G.},
  title = {NAL-NL1 procedure for fitting nonlinear hearing aids: characteristics and comparisons with other procedures},
  journal = {Journal of the American Academy of Audiology},
  volume = {12},
  number = {1},
  pages = {37--51},
  year = {2001}
}

@article{NAL-NL2,
  author = {Keidser, G. and Dillon, H. and Flax, M. and Ching, T. and Brewer, S.},
  title = {The NAL-NL2 Prescription Procedure},
  journal = {Audiology Research},
  volume = {1},
  number = {1},
  pages = {e24},
  year = {2011},
  doi = {10.4081/audiores.2011.e24}
}

@article{DSLm,
  author = {Seewald, R. and Moodie, S. and Scollie, S. and Bagatto, M.},
  title = {The DSL method for pediatric hearing instrument fitting: historical perspective and current issues},
  journal = {Trends in Amplification},
  volume = {9},
  number = {4},
  pages = {145--157},
  year = {2005},
  doi = {10.1177/108471380500900402}
}

@article{Compression,
  author = {Souza, P. E.},
  title = {Effects of compression on speech acoustics, intelligibility, and sound quality},
  journal = {Trends in Amplification},
  volume = {6},
  number = {4},
  pages = {131--165},
  year = {2002},
  doi = {10.1177/108471380200600402}
}

@article{nlc1,
  author = {Bohnert, A. and Nyffeler, M. and Keilmann, A.},
  title = {Advantages of a non-linear frequency compression algorithm in noise},
  journal = {European Archives of Oto-Rhino-Laryngology},
  volume = {267},
  number = {7},
  pages = {1045--1053},
  year = {2010},
  doi = {10.1007/s00405-009-1170-x}
}

%%%%%%%%%%%%%%%%%%
@article{nlc2,
title = {Auditory perceptual efficacy of nonlinear frequency compression used in hearing aids: A review},
author = {Y. Mao and J. Yang and E. Hahn and L. Xu},
journal = {Journal of Otology},
volume = {12},
number = {3},
pages = {97-111},
year = {2017},
doi = {https://doi.org/10.1016/j.joto.2017.06.003}
}

@article{WDRCbenefit1,
  author = {Jenstad, L. M. and Seewald, R. C. and Cornelisse, L. E. and Shantz, J.},
  title = {Comparison of linear gain and wide dynamic range compression hearing aid circuits: aided speech perception measures},
  journal = {Ear and Hearing},
  volume = {20},
  number = {2},
  pages = {117--126},
  year = {1999},
  doi = {10.1097/00003446-199904000-00003}
}

@inbook{WDRCblock,
  author = {May, T. and Kowalewski, B. and Dau, T.},
  title = {Scene-Aware Dynamic-Range Compression in Hearing Aids},
  booktitle = {The Technology of Binaural Understanding},
  year = {2020},
  publisher = {Springer International Publishing},
  pages = {763--799},
  doi = {10.1007/978-3-030-00386-9_25}
}


@article{compression1,
  author = {Gatehouse, S. and Naylor, G. and Elberling, C.},
  title = {Linear and nonlinear hearing aid fittings--1. Patterns of benefit},
  journal = {International Journal of Audiology},
  volume = {45},
  number = {3},
  pages = {130--152},
  year = {2006},
  doi = {10.1080/14992020500429518}
}


@article{hadl,
  author = {Zeng, F.-G.},
  title = {A New Landscape for Hearing Aids},
  journal = {The Hearing Journal},
  volume = {70},
  number = {12},
  pages = {6},
  year = {2017}
}

%%%%%%%%%%%%%%
@inproceedings{denoising_ha,
  author = {SchrÃ¶ter, H. and Rosenkranz, T. and Escalante-B, A. N. and Aubreville, M. and Maier, A.},
  title = {CLCNET: Deep Learning-Based Noise Reduction for Hearing Aids using Complex Linear Coding},
  booktitle = {Proc. ICASSP},
  year = {2020},
  pages = {6949--6953}
}

@inproceedings{lstmse,
  author = {Sun, L. and Du, J. and Dai, L.-R. and Lee, C.-H.},
  title = {Multiple-target deep learning for LSTM-RNN based speech enhancement},
  booktitle = {Proc. Hands-free Speech Communications and Microphone Arrays (HSCMA)},
  year = {2017},
  pages = {136--140}
}

@inproceedings{fcnse,
  author = {Fu, S.-W. and Tsao, Y. and Lu, X. and Kawai, H.},
  title = {Raw waveform-based speech enhancement by fully convolutional networks},
  booktitle = {Proc. APSIPA},
  year = {2017},
  address = {Kuala Lumpur, Malaysia}
}


@inproceedings{ddae,
  author = {Zezario, R. E. and Huang, J.-W. and Lu, X. and Tsao, Y. and Hwang, H.-T. and Wang, H.-M.},
  title = {Deep Denoising Autoencoder Based Post Filtering for Speech Enhancement},
  booktitle = {Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  year = {2018},
  address = {Honolulu, HI, USA},
  pages = {373--377}
}


@article{MAWALIM2023109663,
  title={Non-intrusive speech intelligibility prediction using an auditory periphery model with hearing loss},
  author={Mawalim, C. O. and Titalim, B. A. and Okada, S. and Unoki, M.},
  journal={Applied Acoustics},
  volume={214},
  pages={109663},
  year={2023},
  publisher={Elsevier}
}


@inproceedings{edozezario22_interspeech,
  author={R. E. Zezario and F. Chen and C.-S. Fuh and H.-M. Wang and Y. Tsao},
  title={{MBI-Net: A Non-intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids}},
  year=2022,
  booktitle={Proc. INTERSPEECH},
  pages={3944--3948},
  doi={10.21437/Interspeech.2022-10838}
}

@inproceedings{tu22_interspeech,
  author={Z. Tu and N. Ma and J. Barker},
  title={{Exploiting Hidden Representations from a DNN-based Speech Recogniser for Speech Intelligibility Prediction in Hearing-Impaired Listeners}},
  year=2022,
  booktitle={Proc. INTERSPEECH},
  pages={3488--3492},
  doi={10.21437/Interspeech.2022-10399}
}
%%%%%%%%%%%%%%%%%%%%%
@inproceedings{avsednn,
  author = {Hou, J.-C. and others},
  title = {Audio-visual speech enhancement using deep neural networks},
  booktitle = {Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)},
  year = {2016},
  address = {Jeju, Korea (South)},
  pages = {1-6},
  doi = {10.1109/APSIPA.2016.7820732}
}


@article{cnn_general,
  author = {Abdel-Hamid, O. and Mohamed, A. R. and Jiang, H. and Deng, L. and Penn, G. and Yu, D.},
  title = {Convolutional Neural Networks for Speech Recognition},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {22},
  number = {10},
  pages = {1533--1545},
  year = {2014}
}

@inproceedings{cnn_speech,
  author = {Mashiana, H. S. and Salaria, A. and Kaur, K.},
  title = {Speech Enhancement Using Residual Convolutional Neural Network},
  booktitle = {Proc. International Conference on Smart Systems and Inventive Technology (ICSSIT)},
  year = {2019},
  pages = {1193--1196}
}

@article{lstm,
  author = {Hochreiter, S. and Schmidhuber, J.},
  title = {Long Short-Term Memory},
  journal = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  year = {1997},
  doi = {10.1162/neco.1997.9.8.1735}
}

@article{lstm1,
  author = {Mehrish, A. and Majumder, N. and Bharadwaj, R. and Mihalcea, R. and Poria, S.},
  title = {A review of deep learning techniques for speech processing},
  journal = {Information Fusion},
  volume = {99},
  pages = {101869},
  year = {2023},
  issn = {1566-2535}
}

@article{lstm2,
  author = {Wang, J. and Saleem, N. and Gunawan, T. S.},
  title = {Towards Efficient Recurrent Architectures: A Deep LSTM Neural Network Applied to Speech Enhancement and Recognition},
  journal = {Cognitive Computation},
  year = {2024}
}


@inproceedings{crnn,
  author = {Zhao, Y. and Jin, X. and Hu, X.},
  title = {Recurrent Convolutional Neural Network for Speech Processing},
  booktitle = {Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2017},
  address = {New Orleans, LA, USA},
  pages = {5300--5304},
  doi = {10.1109/ICASSP.2017.7953168}
}

@inproceedings{karitaasru,
  author = {Karita, S. and others},
  title = {A Comparative Study on Transformer vs RNN in Speech Applications},
  booktitle = {Proc. IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  year = {2019},
  address = {Singapore},
  pages = {449--456},
  doi = {10.1109/ASRU46091.2019.9003750}
}

@inproceedings{vaswani2017attention,
  author = {Vaswani, A. and Shazeer, N. and Parmar, N. and Uszkoreit, J. and Jones, L. and Gomez, A. N. and Kaiser, {\L}. and Polosukhin, I.},
  title = {Attention is All You Need},
  booktitle = {Proc. Advances in Neural Information Processing Systems},
  pages = {5998--6008},
  year = {2017}
}

@article{transformersurvey,
  author = {Islam, S. and Elmekki, H. and Elsebai, A. and Bentahar, J. and Drawel, N. and Rjoub, G. and Pedrycz, W.},
  title = {A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks},
  journal = {Expert Systems with Applications},
  volume = {241},
  year = {2024}
}

@inproceedings{stransformer,
  author = {Dong, L. and Yang, N. and Wang, W. and Wei, F. and Liu, X.},
  title = {Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition},
  booktitle = {Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2021},
  pages = {5884--5888}
}

@article{timit,
  author = {Garofolo, J. S. and Lamel, L. F. and Fisher, W. M. and Fiscus, J. G. and Pallett, D. S.},
  title = {DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus CD-ROM. NIST Speech Disc 1-1.1},
  journal = {NASA STI/Recon Technical Report N},
  volume = {93},
  pages = {27403},
  year = {1993}
}

@article{timitse,
  author = {Lu, Y.-J. and Chang, C.-Y. and Yu, C. and Liu, C.-F. and Hung, J.-W. and Watanabe, S. and Tsao, Y.},
  title = {Improving Speech Enhancement Performance by Leveraging Contextual Broad Phonetic Class Information},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {31},
  pages = {2738--2750},
  year = {2023}
}

@inproceedings{timitasr,
  author = {Meng, L. and Xu, J. and Tan, X. and Wang, J. and Qin, T. and Xu, B.},
  title = {MixSpeech: Data Augmentation for Low-Resource Automatic Speech Recognition},
  booktitle = {Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2021},
  address = {Toronto, ON, Canada},
  pages = {7008--7012},
  doi = {10.1109/ICASSP39728.2021.9414483}
}

@article{timitse1,
  author = {Fu, S.-W. and Liao, C.-F. and Tsao, Y.},
  title = {Learning With Learned Loss Function: Speech Enhancement With Quality-Net to Improve Perceptual Evaluation of Speech Quality},
  journal = {IEEE Signal Processing Letters},
  volume = {27},
  pages = {26--30},
  year = {2020}
}

%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{timitasr1,
  author = {Ma, C. and Tsao, Y. and Lee, C.-H.},
  title = {A Study on Detection Based Automatic Speech Recognition},
  booktitle = {Proc. Interspeech 2006},
  year = {2006}
}

@techreport{noise,
  author = {Hu, G.},
  title = {100 Nonspeech Environmental Sounds},
  institution = {The Ohio State University, Department of Computer Science and Engineering},
  year = {2004}
}





@inproceedings{tmhint,
  author = {Chen, Y.-W. and Tsao, Y.},
  title = {InQSS: A Speech Intelligibility and Quality Assessment Model Using a Multi-Task Learning Network},
  booktitle = {Proc. Interspeech 2022},
  year = {2022},
  pages = {3088--3092},
  doi = {10.21437/Interspeech.2022-10153}
}


@article{mosa,
  author = {Zezario, R. E. and Fu, S.-W. and Chen, F. and Fuh, C.-S. and Wang, H.-M. and Tsao, Y.},
  title = {Deep Learning-Based Non-Intrusive Multi-Objective Speech Assessment Model With Cross-Domain Features},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {31},
  pages = {54--70},
  year = {2023},
  doi = {10.1109/TASLP.2022.3205757}
}


@article{tmhintse,
  author = {Lu, Y.-J. and others},
  title = {Improving Speech Enhancement Performance by Leveraging Contextual Broad Phonetic Class Information},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {31},
  pages = {2738--2750},
  year = {2023},
  doi = {10.1109/TASLP.2023.3288418}
}


@article{cedenza1,
  author = {Dabike, G. R. and Bannister, S. and Firth, J. and Graetzer, S. and Vos, R. and Akeroyd, M. A. and Whitmer, W.},
  title = {The First Cadenza Signal Processing Challenge: Improving Music for Those with a Hearing Loss},
  journal = {arXiv preprint arXiv:2310.05799},
  year = {2023}
}


@misc{cedenza2,
  author = {{The Cadenza Project}},
  title = {The Cadenza Project},
  note = {[Online]. Available: \url{https://cadenzachallenge.org}}
}

@misc{vctk,
  author = {Valentini-Botinhao, C.},
  title = {Noisy Speech Database for Training Speech Enhancement Algorithms and TTS Models},
  year = {2016},
  note = {[dataset]. University of Edinburgh, School of Informatics, Centre for Speech Technology Research (CSTR).}
}


@inproceedings{matricse,
  author = {Fu, S.-W. and Yu, C. and Hsieh, T. and Plantinga, P. W. and Ravanelli, M. and Lu, X. and Tsao, Y.},
  title = {MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement},
  booktitle = {Proc. Interspeech 2021},
  year = {2021}
}

@inproceedings{vctkse,
  author = {SchrÃ¶ter, H. and Escalante-B., A. N. and Rosenkranz, T. and Maier, A.},
  title = {DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement},
  booktitle = {Proc. Interspeech 2023},
  year = {2023},
  pages = {2008--2009}
}

@misc{vctkasr,
  author = {Ravanelli, M. and others},
  title={{SpeechBrain}: A General-Purpose Speech Toolkit},
  year={2021},
  eprint={2106.04624},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  note={arXiv:2106.04624}
}

@misc{musdb,
  author = {Rafii, Z. and Liutkus, A. and StÃ¶ter, F. and Mimilakis, S. and Bittner, R.},
  title = {MUSDB18-HQ - An Uncompressed Version of MUSDB18},
  year = {2019}
}

@inproceedings{musdb1,
  author = {Rouard, S. and Massa, F. and DÃ©fossez, A.},
  title = {Hybrid Transformers for Music Source Separation},
  booktitle = {Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2023},
  address = {Rhodes Island, Greece},
  pages = {1--5},
  doi = {10.1109/ICASSP49357.2023.10096956}
}


@article{musdb2,
  author = {D'efossez, A.},
  title = {Hybrid Spectrogram and Waveform Source Separation},
  journal = {ArXiv preprint arXiv:2111.03600},
  year = {2021}
}

@article{hlp,
  author = {Alshuaib, W. B. and Al-Kandari, J. M. and Hasan, S. M.},
  title = {Classification of Hearing Loss},
  journal = {Update On Hearing Loss},
  volume = {4},
  pages = {29--37},
  year = {2015}
}

@inproceedings{crnnse,
  author    = {H. Zhao and S. Zarar and I. Tashev and C.-H. Lee},
  title     = {Convolutional-Recurrent Neural Networks for Speech Enhancement},
  booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2018},
  pages     = {2401--2405},
  address   = {Calgary, AB, Canada},
  publisher = {IEEE}
}



@article{msbg,
  author = {Nejime, Y. and Moore, B. C.},
  title = {Simulation of the Effect of Threshold Elevation and Loudness Recruitment Combined with Reduced Frequency Selectivity on the Intelligibility of Speech in Noise},
  journal = {The Journal of the Acoustical Society of America},
  volume = {102},
  number = {1},
  pages = {603--615},
  year = {1997}
}

@inproceedings{fbc,
  author = {Nezamdoust, A. and Gogate, M. and Dashtipour, K. and Hussain, A. and Comminiello, D.},
  title = {Frequency-Domain Functional Links For Nonlinear Feedback Cancellation In Hearing Aids},
  booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)},
  year = {2023}
}
