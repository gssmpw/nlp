@misc{ericsson,
  title = {{IoT connections outlook}},
  author = {{Ericsson}},
  howpublished = {\url{https://www.ericsson.com/en/reports-and-papers/mobility-report/dataforecasts/iot-connections-outlook}},
  note = "[Online]",
  year={2023}
}

@misc{idc,
  title = {{Future of Industry Ecosystems: Shared Data and Insights}},
  author = {{International Data Corporation (IDC)}},
  howpublished = {\url{https://blogs.idc.com/2021/01/06/future-of-industry-ecosystems-shared-data-and-insights/}},
  note = "[Online]",
  year={2021}
}


@misc{iotconnection,
  title = {{State of IoT 2024: Number of connected IoT devices growing 13\% to 18.8 billion globally}},
  author = {{Satyajit Sinha}},
  howpublished = {\url{https://iot-analytics.com/number-connected-iot-devices/}},
  note = "[Online]",
  year={2023}
}

@inproceedings{ouyang2022cosmo,
  title={Cosmo: contrastive fusion learning with small data for multimodal human activity recognition},
  author={Ouyang, Xiaomin and Shuai, Xian and Zhou, Jiayu and Shi, Ivy Wang and Xie, Zhiyuan and Xing, Guoliang and Huang, Jianwei},
  booktitle={Proceedings of the 28th Annual International Conference on Mobile Computing And Networking},
  pages={324--337},
  year={2022}
}

@article{cureau2022new,
  title={A new wearable system for sensing outdoor environmental conditions for monitoring hyper-microclimate},
  author={Cureau, Roberta Jacoby and Pigliautile, Ilaria and Pisello, Anna Laura},
  journal={Sensors},
  volume={22},
  number={2},
  pages={502},
  year={2022},
  publisher={MDPI}
}

@inproceedings{daepp2022eclipse,
  title={Eclipse: an end-to-end platform for low-cost, hyperlocal environmental sensing in cities},
  author={Daepp, Madeleine IG and Cabral, Alex and Ranganathan, Vaishnavi and Iyer, Vikram and Counts, Scott and Johns, Paul and Roseway, Asta and Catlett, Charlie and Jancke, Gavin and Gehring, Darren and others},
  booktitle={2022 21st ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)},
  pages={28--40},
  year={2022},
  organization={IEEE}
}

@inproceedings{xu2023practically,
  title={Practically Adopting Human Activity Recognition},
  author={Xu, Huatao and Zhou, Pengfei and Tan, Rui and Li, Mo},
  booktitle={Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
  pages={1--15},
  year={2023}
}

@article{du2019deep,
  title={Deep air quality forecasting using hybrid deep learning framework},
  author={Du, Shengdong and Li, Tianrui and Yang, Yan and Horng, Shi-Jinn},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={33},
  number={6},
  pages={2412--2424},
  year={2019},
  publisher={IEEE}
}

@inproceedings{xing2021deepsqa,
  title={DeepSQA: Understanding Sensor Data via Question Answering},
  author={Xing, Tianwei and Garcia, Luis and Cerutti, Federico and Kaplan, Lance and Preece, Alun and Srivastava, Mani},
  booktitle={Proceedings of the International Conference on Internet-of-Things Design and Implementation},
  pages={106--118},
  year={2021}
}

@inproceedings{nie2022ai,
  title={Ai therapist for daily functioning assessment and intervention using smart home devices},
  author={Nie, Jingping and Zhao, Minghui and Xia, Stephen and Sun, Xinghua and Shao, Hanya and Fan, Yuang and Preindl, Matthias and Jiang, Xiaofan},
  booktitle={Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
  pages={764--765},
  year={2022}
}

@inproceedings{nie2022conversational,
  title={Conversational ai therapist for daily function screening in home environments},
  author={Nie, Jingping and Shao, Hanya and Zhao, Minghui and Xia, Stephen and Preindl, Matthias and Jiang, Xiaofan},
  booktitle={Proceedings of the 1st ACM International Workshop on Intelligent Acoustic Systems and Applications},
  pages={31--36},
  year={2022}
}

@article{lobry2020rsvqa,
  title={RSVQA: Visual question answering for remote sensing data},
  author={Lobry, Sylvain and Marcos, Diego and Murray, Jesse and Tuia, Devis},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={58},
  number={12},
  pages={8555--8566},
  year={2020},
  publisher={IEEE}
}

@inproceedings{lobry2021rsvqa,
  title={RSVQA meets BigEarthNet: a new, large-scale, visual question answering dataset for remote sensing},
  author={Lobry, Sylvain and Demir, Beg{\"u}m and Tuia, Devis},
  booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS},
  pages={1218--1221},
  year={2021},
  organization={IEEE}
}

@article{zhang2023spatial,
  title={A spatial hierarchical reasoning network for remote sensing visual question answering},
  author={Zhang, Zixiao and Jiao, Licheng and Li, Lingling and Liu, Xu and Chen, Puhua and Liu, Fang and Li, Yuxuan and Guo, Zhicheng},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={61},
  pages={1--15},
  year={2023},
  publisher={IEEE}
}

@article{hu2023rsgpt,
  title={RSGPT: A Remote Sensing Vision Language Model and Benchmark},
  author={Hu, Yuan and Yuan, Jianlong and Wen, Congcong and Lu, Xiaonan and Li, Xiang},
  journal={arXiv preprint arXiv:2307.15266},
  year={2023}
}

@article{liu2023unified,
  title={Unified Transformer with Cross-Modal Mixture Experts for Remote-Sensing Visual Question Answering},
  author={Liu, Gang and He, Jinlong and Li, Pengfei and Zhong, Shenjun and Li, Hongyang and He, Genrong},
  journal={Remote Sensing},
  volume={15},
  number={19},
  pages={4682},
  year={2023},
  publisher={MDPI}
}

@article{chappuis2021find,
  title={How to find a good image-text embedding for remote sensing visual question answering?},
  author={Chappuis, Christel and Lobry, Sylvain and Kellenberger, Benjamin and Saux, Bertrand Le and Tuia, Devis},
  journal={arXiv preprint arXiv:2109.11848},
  year={2021}
}


@article{wang2022sensor,
  title={Sensor data augmentation by resampling in contrastive learning for human activity recognition},
  author={Wang, Jinqiang and Zhu, Tao and Gan, Jingyuan and Chen, Liming Luke and Ning, Huansheng and Wan, Yaping},
  journal={IEEE Sensors Journal},
  volume={22},
  number={23},
  pages={22994--23008},
  year={2022},
  publisher={IEEE}
}

@inproceedings{um2017data,
  title={Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks},
  author={Um, Terry T and Pfister, Franz MJ and Pichler, Daniel and Endo, Satoshi and Lang, Muriel and Hirche, Sandra and Fietzek, Urban and Kuli{\'c}, Dana},
  booktitle={Proceedings of the 19th ACM international conference on multimodal interaction},
  pages={216--220},
  year={2017}
}

@inproceedings{ouyang2023harmony,
  title={Harmony: Heterogeneous Multi-Modal Federated Learning through Disentangled Model Training},
  author={Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei},
  booktitle={Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
  pages={530--543},
  year={2023}
}

@inproceedings{ma2019attnsense,
  title={AttnSense: Multi-level attention mechanism for multimodal human activity recognition.},
  author={Ma, Haojie and Li, Wenzhong and Zhang, Xiao and Gao, Songcheng and Lu, Sanglu},
  booktitle={IJCAI},
  pages={3109--3115},
  year={2019}
}

@article{vaizman2017recognizing,
  title={Recognizing detailed human context in the wild from smartphones and smartwatches},
  author={Vaizman, Yonatan and Ellis, Katherine and Lanckriet, Gert},
  journal={IEEE pervasive computing},
  volume={16},
  number={4},
  pages={62--74},
  year={2017},
  publisher={IEEE}
}

@misc{misc_opportunity_activity_recognition_226,
  author       = {Roggen,Daniel and Calatroni,Alberto and Nguyen-Dinh,Long-Van and Chavarriaga,Ricardo and Sagha,Hesam},
  title        = {{OPPORTUNITY Activity Recognition}},
  year         = {2012},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5M027}
}

@misc{misc_human_activity_recognition_using_smartphones_240,
  author       = {Reyes-Ortiz,Jorge and Anguita,Davide and Ghio,Alessandro and Oneto,Luca and and Parra,Xavier},
  title        = {{Human Activity Recognition Using Smartphones}},
  year         = {2012},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C54S4K}
}

@misc{misc_mhealth_dataset_319,
  author       = {Banos,Oresti and Garcia,Rafael and and Saez,Alejandro},
  title        = {{MHEALTH Dataset}},
  year         = {2014},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5TW22}
}

@article{deldari2022cocoa,
  title={Cocoa: Cross modality contrastive learning for sensor data},
  author={Deldari, Shohreh and Xue, Hao and Saeed, Aaqib and Smith, Daniel V and Salim, Flora D},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={6},
  number={3},
  pages={1--28},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@inproceedings{adib2013see,
  title={See through walls with WiFi!},
  author={Adib, Fadel and Katabi, Dina},
  booktitle={Proceedings of the ACM SIGCOMM 2013 conference on SIGCOMM},
  pages={75--86},
  year={2013}
}

@article{qiu2022multi,
  title={Multi-sensor information fusion based on machine learning for real applications in human activity recognition: State-of-the-art and research challenges},
  author={Qiu, Sen and Zhao, Hongkai and Jiang, Nan and Wang, Zhelong and Liu, Long and An, Yi and Zhao, Hongyu and Miao, Xin and Liu, Ruichen and Fortino, Giancarlo},
  journal={Information Fusion},
  volume={80},
  pages={241--265},
  year={2022},
  publisher={Elsevier}
}

@article{chen2021deep,
  title={Deep learning for sensor-based human activity recognition: Overview, challenges, and opportunities},
  author={Chen, Kaixuan and Zhang, Dalin and Yao, Lina and Guo, Bin and Yu, Zhiwen and Liu, Yunhao},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={4},
  pages={1--40},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{munzner2017cnn,
  title={CNN-based sensor fusion techniques for multimodal human activity recognition},
  author={M{\"u}nzner, Sebastian and Schmidt, Philip and Reiss, Attila and Hanselmann, Michael and Stiefelhagen, Rainer and D{\"u}richen, Robert},
  booktitle={Proceedings of the 2017 ACM international symposium on wearable computers},
  pages={158--165},
  year={2017}
}

@inproceedings{zhang2020pdlens,
  title={PDLens: smartphone knows drug effectiveness among Parkinson's via daily-life activity fusion},
  author={Zhang, Hanbin and Guo, Gabriel and Song, Chen and Xu, Chenhan and Cheung, Kevin and Alexis, Jasleen and Li, Huining and Li, Dongmei and Wang, Kun and Xu, Wenyao},
  booktitle={Proceedings of the 26th annual international conference on mobile computing and networking},
  pages={1--14},
  year={2020}
}

@inproceedings{xu2021limu,
  title={Limu-bert: Unleashing the potential of unlabeled data for imu sensing applications},
  author={Xu, Huatao and Zhou, Pengfei and Tan, Rui and Li, Mo and Shen, Guobin},
  booktitle={Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems},
  pages={220--233},
  year={2021}
}

@inproceedings{jiang2018towards,
  title={Towards environment independent device free human activity recognition},
  author={Jiang, Wenjun and Miao, Chenglin and Ma, Fenglong and Yao, Shuochao and Wang, Yaqing and Yuan, Ye and Xue, Hongfei and Song, Chen and Ma, Xin and Koutsonikolas, Dimitrios and others},
  booktitle={Proceedings of the 24th annual international conference on mobile computing and networking},
  pages={289--304},
  year={2018}
}

@article{radu2019vision2sensor,
  title={Vision2sensor: Knowledge transfer across sensing modalities for human activity recognition},
  author={Radu, Valentin and Henne, Maximilian},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={3},
  number={3},
  pages={1--21},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{li2021two,
  title={Two-stream convolution augmented transformer for human activity recognition},
  author={Li, Bing and Cui, Wei and Wang, Wei and Zhang, Le and Chen, Zhenghua and Wu, Min},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={1},
  pages={286--293},
  year={2021}
}

@inproceedings{chappuis2022prompt,
  title={Prompt-RSVQA: Prompting visual context to a language model for remote sensing visual question answering},
  author={Chappuis, Christel and Zermatten, Val{\'e}rie and Lobry, Sylvain and Le Saux, Bertrand and Tuia, Devis},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1372--1381},
  year={2022}
}

@article{bazi2022bi,
  title={Bi-modal transformer-based approach for visual question answering in remote sensing imagery},
  author={Bazi, Yakoub and Al Rahhal, Mohamad Mahmoud and Mekhalfi, Mohamed Lamine and Al Zuair, Mansour Abdulaziz and Melgani, Farid},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--11},
  year={2022},
  publisher={IEEE}
}


@article{sadhu2023review,
  title={A review of data management and visualization techniques for structural health monitoring using BIM and virtual or augmented reality},
  author={Sadhu, Ayan and Peplinski, Jack E and Mohammadkhorasani, Ali and Moreu, Fernando},
  journal={Journal of Structural Engineering},
  volume={149},
  number={1},
  pages={03122006},
  year={2023},
  publisher={American Society of Civil Engineers}
}

@inproceedings{xu2023mesen,
  title={MESEN: Exploit Multimodal Data to Design Unimodal Human Activity Recognition with Few Labels},
  author={Xu, Lilin and Gu, Chaojie and Tan, Rui and He, Shibo and Chen Jiming},
  booktitle={Proceedings of the 21st ACM Conference on Embedded Networked Sensor Systems},
  year={2023}
}

@article{chung2022real,
  title={Real-world multimodal lifelog dataset for human behavior study},
  author={Chung, Seungeun and Jeong, Chi Yoon and Lim, Jeong Mook and Lim, Jiyoun and Noh, Kyoung Ju and Kim, Gague and Jeong, Hyuntae},
  journal={ETRI Journal},
  volume={44},
  number={3},
  pages={426--437},
  year={2022},
  publisher={Wiley Online Library}
}

@inproceedings{datta2022episodic,
  title={Episodic memory question answering},
  author={Datta, Samyak and Dharur, Sameer and Cartillier, Vincent and Desai, Ruta and Khanna, Mukul and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19119--19128},
  year={2022}
}

@inproceedings{schwenk2022okvqa,
  title={A-okvqa: A benchmark for visual question answering using world knowledge},
  author={Schwenk, Dustin and Khandelwal, Apoorv and Clark, Christopher and Marino, Kenneth and Mottaghi, Roozbeh},
  booktitle={European Conference on Computer Vision},
  pages={146--162},
  year={2022},
  organization={Springer}
}

@article{rogers2023qa,
  title={Qa dataset explosion: A taxonomy of nlp resources for question answering and reading comprehension},
  author={Rogers, Anna and Gardner, Matt and Augenstein, Isabelle},
  journal={ACM Computing Surveys},
  volume={55},
  number={10},
  pages={1--45},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{moon-etal-2023-imu2clip,
    title = "{IMU}2{CLIP}: Language-grounded Motion Sensor Translation with Multimodal Contrastive Learning",
    author = "Moon, Seungwhan  and
      Madotto, Andrea  and
      Lin, Zhaojiang  and
      Saraf, Aparajita  and
      Bearman, Amy  and
      Damavandi, Babak",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    year = "2023",
    pages = "13246--13253",
}

@article{zhou2023tent,
  title={TENT: Connect Language Models with IoT Sensors for Zero-Shot Activity Recognition},
  author={Zhou, Yunjiao and Yang, Jianfei and Zou, Han and Xie, Lihua},
  journal={arXiv preprint arXiv:2311.08245},
  year={2023}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@article{moon2023anymal,
  title={Anymal: An efficient and scalable any-modality augmented language model},
  author={Moon, Seungwhan and Madotto, Andrea and Lin, Zhaojiang and Nagarajan, Tushar and Smith, Matt and Jain, Shashank and Yeh, Chun-Fu and Murugesan, Prakash and Heidari, Peyman and Liu, Yue and others},
  journal={arXiv preprint arXiv:2309.16058},
  year={2023}
}


@inproceedings{girdhar2023imagebind,
  title={Imagebind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}

@inproceedings{han2024onellm,
  title={Onellm: One framework to align all modalities with language},
  author={Han, Jiaming and Gong, Kaixiong and Zhang, Yiyuan and Wang, Jiaqi and Zhang, Kaipeng and Lin, Dahua and Qiao, Yu and Gao, Peng and Yue, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@misc{amt,
  title = {{Amazon Mechanical Turk}},
  howpublished = {\url{https://www.mturk.com/}},
  note = "[Online]",
  year={2024}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{vaizman2018context,
  title={Context recognition in-the-wild: Unified model for multi-modal sensors and multi-label classification},
  author={Vaizman, Yonatan and Weibel, Nadir and Lanckriet, Gert},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={1},
  number={4},
  pages={1--22},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{zhang2023llama,
  title={Llama-adapter: Efficient fine-tuning of language models with zero-init attention},
  author={Zhang, Renrui and Han, Jiaming and Liu, Chris and Gao, Peng and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2303.16199},
  year={2023}
}

@inproceedings{yang2023edgefm,
  title={Edgefm: Leveraging foundation model for open-set learning on the edge},
  author={Yang, Bufang and He, Lixing and Ling, Neiwen and Yan, Zhenyu and Xing, Guoliang and Shuai, Xian and Ren, Xiaozhe and Jiang, Xin},
  booktitle={Proceedings of the 21st ACM Conference on Embedded Networked Sensor Systems},
  pages={111--124},
  year={2023}
}

@article{xu2024survey,
  title={A survey of resource-efficient llm and multimodal foundation models},
  author={Xu, Mengwei and Yin, Wangsong and Cai, Dongqi and Yi, Rongjie and Xu, Daliang and Wang, Qipeng and Wu, Bingyang and Zhao, Yihao and Yang, Chen and Wang, Shihe and others},
  journal={arXiv preprint arXiv:2401.08092},
  year={2024}
}

@article{han2024parameter,
  title={Parameter-efficient fine-tuning for large models: A comprehensive survey},
  author={Han, Zeyu and Gao, Chao and Liu, Jinyang and Zhang, Sai Qian and others},
  journal={arXiv preprint arXiv:2403.14608},
  year={2024}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International conference on machine learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{chen2022vision,
  title={Vision transformer adapter for dense predictions},
  author={Chen, Zhe and Duan, Yuchen and Wang, Wenhai and He, Junjun and Lu, Tong and Dai, Jifeng and Qiao, Yu},
  journal={arXiv preprint arXiv:2205.08534},
  year={2022}
}


@article{han2023onellm,
  title={Onellm: One framework to align all modalities with language},
  author={Han, Jiaming and Gong, Kaixiong and Zhang, Yiyuan and Wang, Jiaqi and Zhang, Kaipeng and Lin, Dahua and Qiao, Yu and Gao, Peng and Yue, Xiangyu},
  journal={arXiv preprint arXiv:2312.03700},
  year={2023}
}

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@article{chavarriaga2013opportunity,
  title={The Opportunity challenge: A benchmark database for on-body sensor-based activity recognition},
  author={Chavarriaga, Ricardo and Sagha, Hesam and Calatroni, Alberto and Digumarti, Sundara Tejaswi and Tr{\"o}ster, Gerhard and Mill{\'a}n, Jos{\'e} del R and Roggen, Daniel},
  journal={Pattern Recognition Letters},
  volume={34},
  number={15},
  pages={2033--2042},
  year={2013},
  publisher={Elsevier}
}

@article{sun2024multimodal,
  title={Multimodal Daily-Life Logging in Free-living Environment Using Non-Visual Egocentric Sensors on a Smartphone},
  author={Sun, Ke and Xia, Chunyu and Zhang, Xinyu and Chen, Hao and Zhang, Charlie Jianzhong},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={8},
  number={1},
  pages={1--32},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@inproceedings{lin2024vila,
  title={Vila: On pre-training for visual language models},
  author={Lin, Ji and Yin, Hongxu and Ping, Wei and Molchanov, Pavlo and Shoeybi, Mohammad and Han, Song},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26689--26699},
  year={2024}
}

@inproceedings{pal2022medmcqa,
  title={Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering},
  author={Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle={Conference on health, inference, and learning},
  pages={248--260},
  year={2022},
  organization={PMLR}
}


@article{yang2024drhouse,
  title={DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge},
  author={Yang, Bufang and Jiang, Siyang and Xu, Lilin and Liu, Kaiwei and Li, Hai and Xing, Guoliang and Chen, Hongkai and Jiang, Xiaofan and Yan, Zhenyu},
  journal={arXiv preprint arXiv:2405.12541},
  year={2024}
}

@article{nie2024llm,
  title={LLM-based Conversational AI Therapist for Daily Functioning Screening and Psychotherapeutic Intervention via Everyday Smart Devices},
  author={Nie, Jingping and Shao, Hanya and Fan, Yuang and Shao, Qijia and You, Haoxuan and Preindl, Matthias and Jiang, Xiaofan},
  journal={arXiv preprint arXiv:2403.10779},
  year={2024}
}

@article{kim2024health,
  title={Health-llm: Large language models for health prediction via wearable sensor data},
  author={Kim, Yubin and Xu, Xuhai and McDuff, Daniel and Breazeal, Cynthia and Park, Hae Won},
  journal={arXiv preprint arXiv:2401.06866},
  year={2024}
}

@article{englhardt2024classification,
  title={From Classification to Clinical Insights: Towards Analyzing and Reasoning About Mobile and Behavioral Health Data With Large Language Models},
  author={Englhardt, Zachary and Ma, Chengqian and Morris, Margaret E and Chang, Chun-Cheng and Xu, Xuhai" Orson" and Qin, Lianhui and McDuff, Daniel and Liu, Xin and Patel, Shwetak and Iyer, Vikram},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={8},
  number={2},
  pages={1--25},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{zhou2024llm,
  title={LLM-Enhanced Data Management},
  author={Zhou, Xuanhe and Zhao, Xinyang and Li, Guoliang},
  journal={arXiv preprint arXiv:2402.02643},
  year={2024}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{song2020multi,
  title={Multi-label contrastive predictive coding},
  author={Song, Jiaming and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={8161--8173},
  year={2020}
}

@inproceedings{reichman2023outside,
  title={Outside knowledge visual question answering version 2.0},
  author={Reichman, Benjamin Z and Sundar, Anirudh and Richardson, Christopher and Zubatiy, Tamara and Chowdhury, Prithwijit and Shah, Aaryan and Truxal, Jack and Grimes, Micah and Shah, Dristi and Chee, Woo Ju and others},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{gpt-4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{gpt-3.5,
  title={A comprehensive capability analysis of gpt-3 and gpt-3.5 series models},
  author={Ye, Junjie and Chen, Xuanting and Xu, Nuo and Zu, Can and Shao, Zekai and Liu, Shichun and Cui, Yuhan and Zhou, Zeyang and Gong, Chao and Shen, Yang and others},
  journal={arXiv preprint arXiv:2303.10420},
  year={2023}
}

@article{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@inproceedings{shao2023prompting,
  title={Prompting large language models with answer heuristics for knowledge-based visual question answering},
  author={Shao, Zhenwei and Yu, Zhou and Wang, Meng and Yu, Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition},
  pages={14974--14983},
  year={2023}
}

@inproceedings{chuCoTReasoningSurvey2024,
    title={Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future},
    author={Zheng Chu and Jingchang Chen and Qianglong Chen and Weijiang Yu and Tao He and Haotian Wang and Weihua Peng and Ming Liu and Bing Qin and Ting Liu},
    booktitle={The 62nd Annual Meeting of the Association for Computational Linguistics: ACL 2024, Bangkok, Thailand, August 11–16, 2024},
    publisher={Association for Computational Linguistics},
    year={2024},
    url={https://arxiv.org/abs/2309.15402}
}

@article{zhao2024retrieval,
  title={Retrieval-augmented generation for ai-generated content: A survey},
  author={Zhao, Penghao and Zhang, Hailin and Yu, Qinhan and Wang, Zhengren and Geng, Yunteng and Fu, Fangcheng and Yang, Ling and Zhang, Wentao and Cui, Bin},
  journal={arXiv preprint arXiv:2402.19473},
  year={2024}
}

@article{li2022infit,
  title={InFit: Combination Movement Recognition for Intensive Fitness Assistant via Wi-Fi},
  author={Li, Huichuwu and Xiao, Jiang and Wang, Wei and Wang, Lu and Zhang, Dian and Jin, Hai},
  journal={IEEE Transactions on Mobile Computing},
  volume={22},
  number={12},
  pages={7188--7202},
  year={2022},
  publisher={IEEE}
}

@article{kwon2021approaching,
  title={Approaching the real-world: Supporting activity recognition training with virtual imu data},
  author={Kwon, Hyeokhyen and Wang, Bingyao and Abowd, Gregory D and Pl{\"o}tz, Thomas},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={5},
  number={3},
  pages={1--32},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@misc{rpi4b,
  title = {{Raspberry Pi 4B}},
  howpublished = {\url{https://www.raspberrypi.com/products/raspberry-pi-4-model-b/}},
  note = "[Online]",
  year={2024}
}

@article{sensorqa,
  title={SensorQA: A Question Answering Benchmark for Daily-Life Monitoring},
  author={Reichman, Benjamin and Yu, Xiaofan and Hu, Lanxiang and Truxal, Jack and Jain, Atishay and Chandrupatla, Rushil and Rosing, Tajana {\v{S}}imuni{\'c} and Heck, Larry},
  journal={arXiv preprint arXiv:2501.04974},
  note="Conditionally accepted by ACM Conference on Embedded Networked Sensor Systems (2025)",
  year={2025}
}

@misc{3080ti,
  title = {{GeForce RTX 3080 Graphical Cards}},
  howpublished = {\url{https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080-3080ti/}},
  note = "[Online]",
  year={2024}
}

@misc{tensorrt,
  title = {{TensorRT SDK}},
  howpublished = {\url{https://developer.nvidia.com/tensorrt}},
  note = "[Online]",
  year={2024}
}

@inproceedings{lin2023awq,
  title={AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration},
  author={Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song},
  booktitle={MLSys},
  year={2024}
}

@inproceedings{zhang2023navigating,
  title={Navigating Alignment for Non-identical Client Class Sets: A Label Name-Anchored Federated Learning Framework},
  author={Zhang, Jiayun and Zhang, Xiyuan and Zhang, Xinyang and Hong, Dezhi and Gupta, Rajesh K and Shang, Jingbo},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={3297--3308},
  year={2023}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@misc{rpi5,
  title = {{Raspberry Pi 5}},
  howpublished = {\url{https://www.raspberrypi.com/products/raspberry-pi-5/}},
  note = "[Online]",
  year={2025}
}

@misc{jetsontx2,
  title = {{Jetson TX2 Module}},
  howpublished = {\url{https://developer.nvidia.com/embedded/jetson-tx2}},
  note = "[Online]",
  year={2025}
}

@misc{jetsonorin,
  title = {{Jetson Orin NX Module}},
  howpublished = {\url{https://developer.nvidia.com/embedded/jetson-modules\#jetson_orin_nx}},
  note = "[Online]",
  year={2025}
}

@misc{openaio3,
  title = {{OpenAI o3-mini}},
  howpublished = {\url{https://openai.com/index/openai-o3-mini/}},
  note = "[Online]",
  year={2025}
}

@misc{deepseek,
  title = {{DeepSeek}},
  howpublished = {\url{https://www.deepseek.com/}},
  note = "[Online]",
  year={2025}
}

@misc{a100,
  title = {{NVIDIA A100 Tensor Core GPU}},
  howpublished = {\url{https://www.nvidia.com/en-us/data-center/a100/}},
  note = "[Online]",
  year={2025}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}


@inproceedings{eyal-etal-2019-question,
    title = "Question Answering as an Automatic Evaluation Metric for News Article Summarization",
    author = "Eyal, Matan  and
      Baumel, Tal  and
      Elhadad, Michael",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    pages = "3938--3948",
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023}
}

@inproceedings{fu2023gpt4aigchip,
  title={Gpt4aigchip: Towards next-generation ai accelerator design automation via large language models},
  author={Fu, Yonggan and Zhang, Yongan and Yu, Zhongzhi and Li, Sixu and Ye, Zhifan and Li, Chaojian and Wan, Cheng and Lin, Yingyan Celine},
  booktitle={2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)},
  pages={1--9},
  year={2023},
  organization={IEEE}
}

@article{kim2023squeezellm,
  title={Squeezellm: Dense-and-sparse quantization},
  author={Kim, Sehoon and Hooper, Coleman and Gholami, Amir and Dong, Zhen and Li, Xiuyu and Shen, Sheng and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2306.07629},
  year={2023}
}

@inproceedings{vaizman2018extrasensory,
  title={Extrasensory app: Data collection in-the-wild with rich user interface to self-report behavior},
  author={Vaizman, Yonatan and Ellis, Katherine and Lanckriet, Gert and Weibel, Nadir},
  booktitle={Proceedings of the 2018 CHI conference on human factors in computing systems},
  pages={1--12},
  year={2018}
}

@article{clinicalai,
  title={Clinical text summarization: Adapting large language models can outperform human experts},
  author={Van Veen, Dave and Van Uden, Cara and Blankemeier, Louis and Delbrouck, Jean-Benoit and Aali, Asad and Bluethgen, Christian and Pareek, Anuj and Polacin, Malgorzata and Reis, Eduardo Pontes and Seehofnerova, Anna and others},
  journal={Research Square},
  year={2023},
  publisher={American Journal Experts}
}

@article{yang2024mm,
  title={Mm-fi: Multi-modal non-intrusive 4d human dataset for versatile wireless sensing},
  author={Yang, Jianfei and Huang, He and Zhou, Yunjiao and Chen, Xinyan and Xu, Yuecong and Yuan, Shenghai and Zou, Han and Lu, Chris Xiaoxuan and Xie, Lihua},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{sun2024multimodal,
  title={Multimodal Daily-Life Logging in Free-living Environment Using Non-Visual Egocentric Sensors on a Smartphone},
  author={Sun, Ke and Xia, Chunyu and Zhang, Xinyu and Chen, Hao and Zhang, Charlie Jianzhong},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={8},
  number={1},
  pages={1--32},
  year={2024},
  publisher={ACM New York, NY, USA}
}


@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}


@techreport{wearablesgrowth,
author = {Tess Skyrme, and Sam Dale},
title = {Wearable Technology Forecasts 2023-2033},
institution = {IDTechEx},
year = {2022},
ISBN = {9781915514578}
}

@article{iotgrowth,
author = {Satyajit Sinha},
title = {State of IoT 2023: Number of connected IoT devices growing 16% to 16.7 billion globally},
institution = {IoT Analytics},
year = {2023}
}

@misc{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{llama2,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gemini,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Gemini Team and Machel Reid and Nikolay Savinov and Denis Teplyashin and Dmitry and Lepikhin and Timothy Lillicrap and Jean-baptiste Alayrac and Radu Soricut and Angeliki Lazaridou and Orhan Firat and Julian Schrittwieser and Ioannis Antonoglou and Rohan Anil and Sebastian Borgeaud and Andrew Dai and Katie Millican and Ethan Dyer and Mia Glaese and Thibault Sottiaux and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and James Molloy and Jilin Chen and Michael Isard and Paul Barham and Tom Hennigan and Ross McIlroy and Melvin Johnson and Johan Schalkwyk and Eli Collins and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Clemens Meyer and Gregory Thornton and Zhen Yang and Henryk Michalewski and Zaheer Abbas and Nathan Schucher and Ankesh Anand and Richard Ives and James Keeling and Karel Lenc and Salem Haykal and Siamak Shakeri and Pranav Shyam and Aakanksha Chowdhery and Roman Ring and Stephen Spencer and Eren Sezener and Luke Vilnis and Oscar Chang and Nobuyuki Morioka and George Tucker and Ce Zheng and Oliver Woodman and Nithya Attaluri and Tomas Kocisky and Evgenii Eltyshev and Xi Chen and Timothy Chung and Vittorio Selo and Siddhartha Brahma and Petko Georgiev and Ambrose Slone and Zhenkai Zhu and James Lottes and Siyuan Qiao and Ben Caine and Sebastian Riedel and Alex Tomala and Martin Chadwick and Juliette Love and Peter Choy and Sid Mittal and Neil Houlsby and Yunhao Tang and Matthew Lamm and Libin Bai and Qiao Zhang and Luheng He and Yong Cheng and Peter Humphreys and Yujia Li and Sergey Brin and Albin Cassirer and Yingjie Miao and Lukas Zilka and Taylor Tobin and Kelvin Xu and Lev Proleev and Daniel Sohn and Alberto Magni and Lisa Anne Hendricks and Isabel Gao and Santiago Ontanon and Oskar Bunyan and Nathan Byrd and Abhanshu Sharma and Biao Zhang and Mario Pinto and Rishika Sinha and Harsh Mehta and Dawei Jia and Sergi Caelles and Albert Webson and Alex Morris and Becca Roelofs and Yifan Ding and Robin Strudel and Xuehan Xiong and Marvin Ritter and Mostafa Dehghani and Rahma Chaabouni and Abhijit Karmarkar and Guangda Lai and Fabian Mentzer and Bibo Xu and YaGuang Li and Yujing Zhang and Tom Le Paine and Alex Goldin and Behnam Neyshabur and Kate Baumli and Anselm Levskaya and Michael Laskin and Wenhao Jia and Jack W. Rae and Kefan Xiao and Antoine He and Skye Giordano and Lakshman Yagati and Jean-Baptiste Lespiau and Paul Natsev and Sanjay Ganapathy and Fangyu Liu and Danilo Martins and Nanxin Chen and Yunhan Xu and Megan Barnes and Rhys May and Arpi Vezer and Junhyuk Oh and Ken Franko and Sophie Bridgers and Ruizhe Zhao and Boxi Wu and Basil Mustafa and Sean Sechrist and Emilio Parisotto and Thanumalayan Sankaranarayana Pillai and Chris Larkin and Chenjie Gu and Christina Sorokin and Maxim Krikun and Alexey Guseynov and Jessica Landon and Romina Datta and Alexander Pritzel and Phoebe Thacker and Fan Yang and Kevin Hui and Anja Hauth and Chih-Kuan Yeh and David Barker and Justin Mao-Jones and Sophia Austin and Hannah Sheahan and Parker Schuh and James Svensson and Rohan Jain and Vinay Ramasesh and Anton Briukhov and Da-Woon Chung and Tamara von Glehn and Christina Butterfield and Priya Jhakra and Matthew Wiethoff and Justin Frye and Jordan Grimstad and Beer Changpinyo and Charline Le Lan and Anna Bortsova and Yonghui Wu and Paul Voigtlaender and Tara Sainath and Shane Gu and Charlotte Smith and Will Hawkins and Kris Cao and James Besley and Srivatsan Srinivasan and Mark Omernick and Colin Gaffney and Gabriela Surita and Ryan Burnell and Bogdan Damoc and Junwhan Ahn and Andrew Brock and Mantas Pajarskas and Anastasia Petrushkina and Seb Noury and Lorenzo Blanco and Kevin Swersky and Arun Ahuja and Thi Avrahami and Vedant Misra and Raoul de Liedekerke and Mariko Iinuma and Alex Polozov and Sarah York and George van den Driessche and Paul Michel and Justin Chiu and Rory Blevins and Zach Gleicher and Adrià Recasens and Alban Rrustemi and Elena Gribovskaya and Aurko Roy and Wiktor Gworek and Sébastien M. R. Arnold and Lisa Lee and James Lee-Thorp and Marcello Maggioni and Enrique Piqueras and Kartikeya Badola and Sharad Vikram and Lucas Gonzalez and Anirudh Baddepudi and Evan Senter and Jacob Devlin and James Qin and Michael Azzam and Maja Trebacz and Martin Polacek and Kashyap Krishnakumar and Shuo-yiin Chang and Matthew Tung and Ivo Penchev and Rishabh Joshi and Kate Olszewska and Carrie Muir and Mateo Wirth and Ale Jakse Hartman and Josh Newlan and Sheleem Kashem and Vijay Bolina and Elahe Dabir and Joost van Amersfoort and Zafarali Ahmed and James Cobon-Kerr and Aishwarya Kamath and Arnar Mar Hrafnkelsson and Le Hou and Ian Mackinnon and Alexandre Frechette and Eric Noland and Xiance Si and Emanuel Taropa and Dong Li and Phil Crone and Anmol Gulati and Sébastien Cevey and Jonas Adler and Ada Ma and David Silver and Simon Tokumine and Richard Powell and Stephan Lee and Kiran Vodrahalli and Samer Hassan and Diana Mincu and Antoine Yang and Nir Levine and Jenny Brennan and Mingqiu Wang and Sarah Hodkinson and Jeffrey Zhao and Josh Lipschultz and Aedan Pope and Michael B. Chang and Cheng Li and Laurent El Shafey and Michela Paganini and Sholto Douglas and Bernd Bohnet and Fabio Pardo and Seth Odoom and Mihaela Rosca and Cicero Nogueira dos Santos and Kedar Soparkar and Arthur Guez and Tom Hudson and Steven Hansen and Chulayuth Asawaroengchai and Ravi Addanki and Tianhe Yu and Wojciech Stokowiec and Mina Khan and Justin Gilmer and Jaehoon Lee and Carrie Grimes Bostock and Keran Rong and Jonathan Caton and Pedram Pejman and Filip Pavetic and Geoff Brown and Vivek Sharma and Mario Lučić and Rajkumar Samuel and Josip Djolonga and Amol Mandhane and Lars Lowe Sjösund and Elena Buchatskaya and Elspeth White and Natalie Clay and Jiepu Jiang and Hyeontaek Lim and Ross Hemsley and Zeyncep Cankara and Jane Labanowski and Nicola De Cao and David Steiner and Sayed Hadi Hashemi and Jacob Austin and Anita Gergely and Tim Blyth and Joe Stanton and Kaushik Shivakumar and Aditya Siddhant and Anders Andreassen and Carlos Araya and Nikhil Sethi and Rakesh Shivanna and Steven Hand and Ankur Bapna and Ali Khodaei and Antoine Miech and Garrett Tanzer and Andy Swing and Shantanu Thakoor and Lora Aroyo and Zhufeng Pan and Zachary Nado and Jakub Sygnowski and Stephanie Winkler and Dian Yu and Mohammad Saleh and Loren Maggiore and Yamini Bansal and Xavier Garcia and Mehran Kazemi and Piyush Patil and Ishita Dasgupta and Iain Barr and Minh Giang and Thais Kagohara and Ivo Danihelka and Amit Marathe and Vladimir Feinberg and Mohamed Elhawaty and Nimesh Ghelani and Dan Horgan and Helen Miller and Lexi Walker and Richard Tanburn and Mukarram Tariq and Disha Shrivastava and Fei Xia and Qingze Wang and Chung-Cheng Chiu and Zoe Ashwood and Khuslen Baatarsukh and Sina Samangooei and Raphaël Lopez Kaufman and Fred Alcober and Axel Stjerngren and Paul Komarek and Katerina Tsihlas and Anudhyan Boral and Ramona Comanescu and Jeremy Chen and Ruibo Liu and Chris Welty and Dawn Bloxwich and Charlie Chen and Yanhua Sun and Fangxiaoyu Feng and Matthew Mauger and Xerxes Dotiwalla and Vincent Hellendoorn and Michael Sharman and Ivy Zheng and Krishna Haridasan and Gabe Barth-Maron and Craig Swanson and Dominika Rogozińska and Alek Andreev and Paul Kishan Rubenstein and Ruoxin Sang and Dan Hurt and Gamaleldin Elsayed and Renshen Wang and Dave Lacey and Anastasija Ilić and Yao Zhao and Adam Iwanicki and Alejandro Lince and Alexander Chen and Christina Lyu and Carl Lebsack and Jordan Griffith and Meenu Gaba and Paramjit Sandhu and Phil Chen and Anna Koop and Ravi Rajwar and Soheil Hassas Yeganeh and Solomon Chang and Rui Zhu and Soroush Radpour and Elnaz Davoodi and Ving Ian Lei and Yang Xu and Daniel Toyama and Constant Segal and Martin Wicke and Hanzhao Lin and Anna Bulanova and Adrià Puigdomènech Badia and Nemanja Rakićević and Pablo Sprechmann and Angelos Filos and Shaobo Hou and Víctor Campos and Nora Kassner and Devendra Sachan and Meire Fortunato and Chimezie Iwuanyanwu and Vitaly Nikolaev and Balaji Lakshminarayanan and Sadegh Jazayeri and Mani Varadarajan and Chetan Tekur and Doug Fritz and Misha Khalman and David Reitter and Kingshuk Dasgupta and Shourya Sarcar and Tina Ornduff and Javier Snaider and Fantine Huot and Johnson Jia and Rupert Kemp and Nejc Trdin and Anitha Vijayakumar and Lucy Kim and Christof Angermueller and Li Lao and Tianqi Liu and Haibin Zhang and David Engel and Somer Greene and Anaïs White and Jessica Austin and Lilly Taylor and Shereen Ashraf and Dangyi Liu and Maria Georgaki and Irene Cai and Yana Kulizhskaya and Sonam Goenka and Brennan Saeta and Ying Xu and Christian Frank and Dario de Cesare and Brona Robenek and Harry Richardson and Mahmoud Alnahlawi and Christopher Yew and Priya Ponnapalli and Marco Tagliasacchi and Alex Korchemniy and Yelin Kim and Dinghua Li and Bill Rosgen and Kyle Levin and Jeremy Wiesner and Praseem Banzal and Praveen Srinivasan and Hongkun Yu and Çağlar Ünlü and David Reid and Zora Tung and Daniel Finchelstein and Ravin Kumar and Andre Elisseeff and Jin Huang and Ming Zhang and Ricardo Aguilar and Mai Giménez and Jiawei Xia and Olivier Dousse and Willi Gierke and Damion Yates and Komal Jalan and Lu Li and Eri Latorre-Chimoto and Duc Dung Nguyen and Ken Durden and Praveen Kallakuri and Yaxin Liu and Matthew Johnson and Tomy Tsai and Alice Talbert and Jasmine Liu and Alexander Neitz and Chen Elkind and Marco Selvi and Mimi Jasarevic and Livio Baldini Soares and Albert Cui and Pidong Wang and Alek Wenjiao Wang and Xinyu Ye and Krystal Kallarackal and Lucia Loher and Hoi Lam and Josef Broder and Dan Holtmann-Rice and Nina Martin and Bramandia Ramadhana and Mrinal Shukla and Sujoy Basu and Abhi Mohan and Nick Fernando and Noah Fiedel and Kim Paterson and Hui Li and Ankush Garg and Jane Park and DongHyun Choi and Diane Wu and Sankalp Singh and Zhishuai Zhang and Amir Globerson and Lily Yu and John Carpenter and Félix de Chaumont Quitry and Carey Radebaugh and Chu-Cheng Lin and Alex Tudor and Prakash Shroff and Drew Garmon and Dayou Du and Neera Vats and Han Lu and Shariq Iqbal and Alex Yakubovich and Nilesh Tripuraneni and James Manyika and Haroon Qureshi and Nan Hua and Christel Ngani and Maria Abi Raad and Hannah Forbes and Jeff Stanway and Mukund Sundararajan and Victor Ungureanu and Colton Bishop and Yunjie Li and Balaji Venkatraman and Bo Li and Chloe Thornton and Salvatore Scellato and Nishesh Gupta and Yicheng Wang and Ian Tenney and Xihui Wu and Ashish Shenoy and Gabriel Carvajal and Diana Gage Wright and Ben Bariach and Zhuyun Xiao and Peter Hawkins and Sid Dalmia and Clement Farabet and Pedro Valenzuela and Quan Yuan and Ananth Agarwal and Mia Chen and Wooyeol Kim and Brice Hulse and Nandita Dukkipati and Adam Paszke and Andrew Bolt and Kiam Choo and Jennifer Beattie and Jennifer Prendki and Harsha Vashisht and Rebeca Santamaria-Fernandez and Luis C. Cobo and Jarek Wilkiewicz and David Madras and Ali Elqursh and Grant Uy and Kevin Ramirez and Matt Harvey and Tyler Liechty and Heiga Zen and Jeff Seibert and Clara Huiyi Hu and Andrey Khorlin and Maigo Le and Asaf Aharoni and Megan Li and Lily Wang and Sandeep Kumar and Norman Casagrande and Jay Hoover and Dalia El Badawy and David Soergel and Denis Vnukov and Matt Miecnikowski and Jiri Simsa and Praveen Kumar and Thibault Sellam and Daniel Vlasic and Samira Daruki and Nir Shabat and John Zhang and Guolong Su and Jiageng Zhang and Jeremiah Liu and Yi Sun and Evan Palmer and Alireza Ghaffarkhah and Xi Xiong and Victor Cotruta and Michael Fink and Lucas Dixon and Ashwin Sreevatsa and Adrian Goedeckemeyer and Alek Dimitriev and Mohsen Jafari and Remi Crocker and Nicholas FitzGerald and Aviral Kumar and Sanjay Ghemawat and Ivan Philips and Frederick Liu and Yannie Liang and Rachel Sterneck and Alena Repina and Marcus Wu and Laura Knight and Marin Georgiev and Hyo Lee and Harry Askham and Abhishek Chakladar and Annie Louis and Carl Crous and Hardie Cate and Dessie Petrova and Michael Quinn and Denese Owusu-Afriyie and Achintya Singhal and Nan Wei and Solomon Kim and Damien Vincent and Milad Nasr and Christopher A. Choquette-Choo and Reiko Tojo and Shawn Lu and Diego de Las Casas and Yuchung Cheng and Tolga Bolukbasi and Katherine Lee and Saaber Fatehi and Rajagopal Ananthanarayanan and Miteyan Patel and Charbel Kaed and Jing Li and Shreyas Rammohan Belle and Zhe Chen and Jaclyn Konzelmann and Siim Põder and Roopal Garg and Vinod Koverkathu and Adam Brown and Chris Dyer and Rosanne Liu and Azade Nova and Jun Xu and Alanna Walton and Alicia Parrish and Mark Epstein and Sara McCarthy and Slav Petrov and Demis Hassabis and Koray Kavukcuoglu and Jeffrey Dean and Oriol Vinyals},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{llamaadapter,
  title = {LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention},
  author={Zhang, Renrui and Han, Jiaming and Liu, Chris and Gao, Peng and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2303.16199},
  year={2023}
}

@article{llamaadapterv2,
  title = {LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model},
  author={Gao, Peng and Han, Jiaming and Zhang, Renrui and Lin, Ziyi and Geng, Shijie and Zhou, Aojun and Zhang, Wei and Lu, Pan and He, Conghui and Yue, Xiangyu and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2304.15010},
  year={2023}
}

@inproceedings{ctbls,
    title = "c{TBLS}: Augmenting Large Language Models with Conversational Tables",
    author = "Sundar, Anirudh S.  and
      Heck, Larry",
    editor = "Chen, Yun-Nung  and
      Rastogi, Abhinav",
    booktitle = "Proceedings of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.nlp4convai-1.6",
    doi = "10.18653/v1/2023.nlp4convai-1.6",
    pages = "59--70",
}

@misc{gtbls,
      title={gTBLS: Generating Tables from Text by Conditional Question Answering}, 
      author={Anirudh Sundar and Christopher Richardson and Larry Heck},
      year={2024},
      eprint={2403.14457},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{itbls,
      title={iTBLS: A Dataset of Interactive Conversations Over Tabular Information}, 
      author={Anirudh Sundar and Christopher Richardson and William Gay and Larry Heck},
      year={2024},
      eprint={2404.12580},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{jecqa,
      title={JEC-QA: A Legal-Domain Question Answering Dataset}, 
      author={Haoxi Zhong and Chaojun Xiao and Cunchao Tu and Tianyang Zhang and Zhiyuan Liu and Maosong Sun},
      year={2019},
      eprint={1911.12011},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{medquad,    
      author    = {Asma {Ben Abacha} and Dina Demner{-}Fushman},
      title     = {A Question-Entailment Approach to Question Answering},
      journal = {{BMC} Bioinform.}, 
      volume    = {20},
      number    = {1},
          pages     = {511:1--511:23},
      year      = {2019},
url       = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3119-4}
}     

@inproceedings{finqa,
    title = "{F}in{QA}: A Dataset of Numerical Reasoning over Financial Data",
    author = "Chen, Zhiyu  and
      Chen, Wenhu  and
      Smiley, Charese  and
      Shah, Sameena  and
      Borova, Iana  and
      Langdon, Dylan  and
      Moussa, Reema  and
      Beane, Matt  and
      Huang, Ting-Hao  and
      Routledge, Bryan  and
      Wang, William Yang",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.300",
    doi = "10.18653/v1/2021.emnlp-main.300",
    pages = "3697--3711",
}

@inproceedings{squad,
    title = "Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}",
    author = "Rajpurkar, Pranav  and
      Jia, Robin  and
      Liang, Percy",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-2124",
    doi = "10.18653/v1/P18-2124",
    pages = "784--789",
}

@inproceedings{boolq,
    title = "{B}ool{Q}: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    author = "Clark, Christopher  and
      Lee, Kenton  and
      Chang, Ming-Wei  and
      Kwiatkowski, Tom  and
      Collins, Michael  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1300",
    doi = "10.18653/v1/N19-1300",
    pages = "2924--2936",
}

@inproceedings{triviaqa,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1147",
    doi = "10.18653/v1/P17-1147",
    pages = "1601--1611",
}

@article{naturalquestions,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.",
}

@inproceedings{hotpotqa,
    title = "{H}otpot{QA}: A Dataset for Diverse, Explainable Multi-hop Question Answering",
    author = "Yang, Zhilin  and
      Qi, Peng  and
      Zhang, Saizheng  and
      Bengio, Yoshua  and
      Cohen, William  and
      Salakhutdinov, Ruslan  and
      Manning, Christopher D.",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1259",
    doi = "10.18653/v1/D18-1259",
    pages = "2369--2380",
    abstract = "Existing question answering (QA) datasets fail to train QA systems to perform complex reasoning and provide explanations for answers. We introduce HotpotQA, a new dataset with 113k Wikipedia-based question-answer pairs with four key features: (1) the questions require finding and reasoning over multiple supporting documents to answer; (2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas; (3) we provide sentence-level supporting facts required for reasoning, allowing QA systems to reason with strong supervision and explain the predictions; (4) we offer a new type of factoid comparison questions to test QA systems{'} ability to extract relevant facts and perform necessary comparison. We show that HotpotQA is challenging for the latest QA systems, and the supporting facts enable models to improve performance and make explainable predictions.",
}

@InProceedings{vqav2,
author = {Yash Goyal and Tejas Khot and Douglas Summers{-}Stay and Dhruv Batra and Devi Parikh},
title = {Making the {V} in {VQA} Matter: Elevating the Role of Image Understanding in {V}isual {Q}uestion {A}nswering},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2017},
}

@article{cocoqa,
  title={Exploring models and data for image question answering},
  author={Ren, Mengye and Kiros, Ryan and Zemel, Richard},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{visualgenome,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@inproceedings{scienceqa,
    title={Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering},
    author={Lu, Pan and Mishra, Swaroop and Xia, Tony and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Ashwin Kalyan},
    booktitle={The 36th Conference on Neural Information Processing Systems (NeurIPS)},
    year={2022}
}

@article{pathvqa,
  title={PathVQA: 30000+ Questions for Medical Visual Question Answering},
  author={Xuehai He and Yichen Zhang and Luntian Mou and Eric P. Xing and Pengtao Xie},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.10286},
  url={https://api.semanticscholar.org/CorpusID:214612106}
}

@inproceedings{okvqav2,
  author={Reichman, Benjamin Z. and Sundar, Anirudh and Richardson, Christopher and Zubatiy, Tamara and Chowdhury, Prithwijit and Shah, Aaryan and Truxal, Jack and Grimes, Micah and Shah, Dristi and Chee, Woo Ju and Punjwani, Saif and Jain, Atishay and Heck, Larry},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Outside Knowledge Visual Question Answering Version 2.0}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Visualization;Lead;Signal processing;Transformers;Question answering (information retrieval);Acoustics;Task analysis;Visual Question Answering;Outside Knowledge VQA;Datasets},
  doi={10.1109/ICASSP49357.2023.10096074}
}

@article{aokvqa,
  title={A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge},
  author={Dustin Schwenk and Apoorv Khandelwal and Christopher Clark and Kenneth Marino and Roozbeh Mottaghi},
  journal={arXiv},
  year={2022},
}

@inproceedings{kvqa,
  author    = "Sanket Shah, Anand Mishra, Naganand Yadati and Partha Pratim Talukdar",
  title     = "KVQA: Knowledge-Aware Visual Question Answering",
  booktitle = "AAAI",
  year      = "2019",
}

@inproceedings{how2qahow2r,
    title = "{HERO}: Hierarchical Encoder for {V}ideo+{L}anguage Omni-representation Pre-training",
    author = "Li, Linjie  and
      Chen, Yen-Chun  and
      Cheng, Yu  and
      Gan, Zhe  and
      Yu, Licheng  and
      Liu, Jingjing",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.161",
    doi = "10.18653/v1/2020.emnlp-main.161",
    pages = "2046--2065",
}

@inproceedings{tvqa+,
    title = "{TVQA}+: Spatio-Temporal Grounding for Video Question Answering",
    author = "Lei, Jie  and
      Yu, Licheng  and
      Berg, Tamara  and
      Bansal, Mohit",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.730",
    doi = "10.18653/v1/2020.acl-main.730",
    pages = "8211--8225",
}

@inproceedings{knowitvqa,
   author    = {Noa Garcia and Mayu Otani and Chenhui Chu and Yuta Nakashima},
   title     = {KnowIT VQA: Answering Knowledge-Based Questions about Videos},
   booktitle = {Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence},
   year      = {2020},
}

@inproceedings{knowitxvqa,
   author    = {Tianran Wu and Noa Garcia and Mayu Otani and Chenhui Chu and Yuta Nakashima and Haruo Takemura},
   title     = {Transferring Domain-Agnostic Knowledge in Video Question Answering},
   booktitle = {Proceedings of the British Machine Vision Conference (BMVC)},
   year      = {2021},
}

@inproceedings{dramaqa,
  title={Dramaqa: Character-centered video story understanding with hierarchical qa},
  author={Choi, Seongho and On, Kyoung-Woon and Heo, Yu-Jung and Seo, Ahjeong and Jang, Youwon and Lee, Minsu and Zhang, Byoung-Tak},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={2},
  pages={1166--1174},
  year={2021}
}

@inproceedings{satbird,
title={SatBird: a Dataset for Bird Species Distribution Modeling using Remote Sensing and Citizen Science Data},
author={M{\'e}lisande Teng and Amna Elmustafa and Benjamin Akera and Yoshua Bengio and Hager Radi and Hugo Larochelle and David Rolnick},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
url={https://openreview.net/forum?id=Vn5qZGxGj3}}

@article{rsvqa,
  title={RSVQA: Visual question answering for remote sensing data},
  author={Lobry, Sylvain and Marcos, Diego and Murray, Jesse and Tuia, Devis},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={58},
  number={12},
  pages={8555--8566},
  year={2020},
  publisher={IEEE}
}

@article{samvqa,
  title={Sam-vqa: Supervised attention-based visual question answering model for post-disaster damage assessment on remote sensing imagery},
  author={Sarkar, Argho and Chowdhury, Tashnim and Murphy, Robin and Gangopadhyay, Aryya and Rahnemoonfar, Maryam},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2023},
  publisher={IEEE}
}

@inproceedings{earthvqa,
  title={EarthVQA: Towards Queryable Earth via Relational Reasoning-Based Remote Sensing Visual Question Answering},
  author={Wang, Junjue and Zheng, Zhuo and Chen, Zihang and Ma, Ailong and Zhong, Yanfei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={5481--5489},
  year={2024}
}

@article{lidcidri,
  title={The lung image database consortium (LIDC) and image database resource initiative (IDRI): a completed reference database of lung nodules on CT scans},
  author={Armato III, Samuel G and McLennan, Geoffrey and Bidaut, Luc and McNitt-Gray, Michael F and Meyer, Charles R and Reeves, Anthony P and Zhao, Binsheng and Aberle, Denise R and Henschke, Claudia I and Hoffman, Eric A and others},
  journal={Medical physics},
  volume={38},
  number={2},
  pages={915--931},
  year={2011},
  publisher={Wiley Online Library}
}

@inproceedings{lunotimct,
  title={Medical image tampering detection: A new dataset and baseline},
  author={Reichman, Benjamin and Jing, Longlong and Akin, Oguz and Tian, Yingli},
  booktitle={Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10--15, 2021, Proceedings, Part I},
  pages={266--277},
  year={2021},
  organization={Springer}
}

@article{echonet,
  title={Video-based AI for beat-to-beat assessment of cardiac function},
  author={Ouyang, David and He, Bryan and Ghorbani, Amirata and Yuan, Neal and Ebinger, Joseph and Langlotz, Curtis P and Heidenreich, Paul A and Harrington, Robert A and Liang, David H and Ashley, Euan A and others},
  journal={Nature},
  volume={580},
  number={7802},
  pages={252--256},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{brainmetshare,
  title={Deep learning enables automatic detection and segmentation of brain metastases on multisequence MRI},
  author={Gr{\o}vik, Endre and Yi, Darvin and Iv, Michael and Tong, Elizabeth and Rubin, Daniel and Zaharchuk, Greg},
  journal={Journal of Magnetic Resonance Imaging},
  volume={51},
  number={1},
  pages={175--182},
  year={2020},
  publisher={Wiley Online Library}
}

@article{sinoct,
  title={Impact of upstream medical image processing on downstream performance of a head CT triage neural network},
  author={Hooper, Sarah M and Dunnmon, Jared A and Lungren, Matthew P and Mastrodicasa, Domenico and Rubin, Daniel L and R{\'e}, Christopher and Wang, Adam and Patel, Bhavik N},
  journal={Radiology: Artificial Intelligence},
  volume={3},
  number={4},
  pages={e200229},
  year={2021},
  publisher={Radiological Society of North America}
}



@article{lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}


@article{rag,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{raganalysis,
  title={Retrieval-Augmented Generation: Is Dense Passage Retrieval Retrieving?},
  author={Reichman, Benjamin and Heck, Larry},
  journal={arXiv preprint arXiv:2402.11035},
  year={2024}
}

@inproceedings{cao2024mmclip,
  title={mmCLIP: Boosting mmWave-based Zero-shot HAR via Signal-Text Alignment},
  author={Cao, Qiming and Xue, Hongfei and Liu, Tianci and Wang, Xingchen and Wang, Haoyu and Zhang, Xincheng and Su, Lu},
  booktitle={Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems},
  pages={184--197},
  year={2024}
}

@inproceedings{weng2024large,
  title={Large Model for Small Data: Foundation Model for Cross-Modal RF Human Activity Recognition},
  author={Weng, Yuxuan and Wu, Guoquan and Zheng, Tianyue and Yang, Yanbing and Luo, Jun},
  booktitle={Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems},
  pages={436--449},
  year={2024}
}

@article{oh2024ecg,
  title={Ecg-qa: A comprehensive question answering dataset combined with electrocardiogram},
  author={Oh, Jungwoo and Lee, Gyubok and Bae, Seongsu and Kwon, Joon-myoung and Choi, Edward},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liu2024benchmarking,
  title={Benchmarking large language models on cmexam-a comprehensive chinese medical exam dataset},
  author={Liu, Junling and Zhou, Peilin and Hua, Yining and Chong, Dading and Tian, Zhongyu and Liu, Andrew and Wang, Helin and You, Chenyu and Guo, Zhenhua and Zhu, Lei and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{hu2024ket,
  title={KET-QA: A Dataset for Knowledge Enhanced Table Question Answering},
  author={Hu, Mengkang and Dong, Haoyu and Luo, Ping and Han, Shi and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2405.08099},
  year={2024}
}

@inproceedings{qian2024nuscenes,
  title={Nuscenes-qa: A multi-modal visual question answering benchmark for autonomous driving scenario},
  author={Qian, Tianwen and Chen, Jingjing and Zhuo, Linhai and Jiao, Yang and Jiang, Yu-Gang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4542--4550},
  year={2024}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@article{choi2021smart,
  title={Smart home and internet of things: A bibliometric study},
  author={Choi, Wonyoung and Kim, Jisu and Lee, SangEun and Park, Eunil},
  journal={Journal of Cleaner Production},
  volume={301},
  pages={126908},
  year={2021},
  publisher={Elsevier}
}

@book{khang2023smart,
  title={Smart Cities: IoT Technologies, big data solutions, cloud platforms, and cybersecurity techniques},
  author={Khang, Alex and Gupta, Shashi Kant and Rani, Sita and Karras, Dimitrios A},
  year={2023},
  publisher={CRC Press}
}

@article{lumbreras2022data,
  title={Data driven model for heat load prediction in buildings connected to District Heating by using smart heat meters},
  author={Lumbreras, Mikel and Garay-Martinez, Roberto and Arregi, Benat and Martin-Escudero, Koldobika and Diarce, Gonzalo and Raud, Margus and Hagu, Indrek},
  journal={Energy},
  volume={239},
  pages={122318},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{moreno2024kalmanhd,
  title={KalmanHD: Robust On-Device Time Series Forecasting with Hyperdimensional Computing},
  author={Moreno, Ivannia Gomez and Yu, Xiaofan and Rosing, Tajana},
  booktitle={2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC)},
  pages={710--715},
  year={2024},
  organization={IEEE}
}

@article{chen2024sensor2text,
  title={Sensor2Text: Enabling Natural Language Interactions for Daily Activity Tracking Using Wearable Sensors},
  author={Chen, Wenqiang and Cheng, Jiaxuan and Wang, Leyao and Zhao, Wei and Matusik, Wojciech},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={8},
  number={4},
  pages={1--26},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@article{arakawa2024prism,
  title={PrISM-Q\&A: Step-Aware Voice Assistant on a Smartwatch Enabled by Multimodal Procedure Tracking and Large Language Models},
  author={Arakawa, Riku and Lehman, Jill Fain and Goel, Mayank},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={8},
  number={4},
  pages={1--26},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@article{ji2024mindguard,
  title={MindGuard: Towards Accessible and Sitgma-free Mental Health First Aid via Edge LLM},
  author={Ji, Sijie and Zheng, Xinzhe and Sun, Jiawei and Chen, Renqi and Gao, Wei and Srivastava, Mani},
  journal={arXiv preprint arXiv:2409.10064},
  year={2024}
}

@misc{us2021increase,
  title={Increase the proportion of adults who do enough aerobic physical activity for substantial health benefits—PA-02},
  author={US Department of Health and Human Services and others},
  year={2021}
}

@article{li2024long,
  title={Long-context llms struggle with long in-context learning},
  author={Li, Tianle and Zhang, Ge and Do, Quy Duc and Yue, Xiang and Chen, Wenhu},
  journal={arXiv preprint arXiv:2404.02060},
  year={2024}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@article{khosla2020supervised,
  title={Supervised contrastive learning},
  author={Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={18661--18673},
  year={2020}
}

@article{liu2024mobilellm,
  title={Mobilellm: Optimizing sub-billion parameter language models for on-device use cases},
  author={Liu, Zechun and Zhao, Changsheng and Iandola, Forrest and Lai, Chen and Tian, Yuandong and Fedorov, Igor and Xiong, Yunyang and Chang, Ernie and Shi, Yangyang and Krishnamoorthi, Raghuraman and others},
  journal={arXiv preprint arXiv:2402.14905},
  year={2024}
}

@inproceedings{zhuang2024litemoe,
  title={LiteMoE: Customizing On-device LLM Serving via Proxy Submodel Tuning},
  author={Zhuang, Yan and Zheng, Zhenzhe and Wu, Fan and Chen, Guihai},
  booktitle={Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems},
  pages={521--534},
  year={2024}
}