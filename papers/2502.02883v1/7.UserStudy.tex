%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Evaluation on real deployment
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Real User Study}
\label{sec:deployment}


We conduct a user study to evaluate \Method's real-world applicability. 
In addition to dataset-based evaluations in Sec.~\ref{sec:evaluation} which focus on quantitative questions, this study places \Method into the ``wilderness''. Participants will interact with \Method immediately after data collection and may pose arbitrary questions, especially the qualitative and open-ended ones.
Our study is approved by the Institutional Review Board Committee.

\textbf{User Study Setup} We recruited eight volunteers (five males and three females) who were instructed to follow their normal daily routines while carrying a smartphone with the ExtraSensoryApp~\cite{vaizman2018extrasensory}. The smartphone models include Huawei Mate 10 Pro, LG G7 ThinQ and Google Pixel 2. The app automatically collected multimodal sensor data and transmitted it to \Method whenever a network connection was available. Reporting activity labels was optional for the participants. The data collection phase lasted one to three days, with valid samples ranging from 52 to 1366 minutes. Sensor data availability varied due to factors such as phone model and usage patterns. After the data collection phase, volunteers were invited to interact with \MethodC in-person through a chat-based graphical interface. They were encouraged to ask any questions about their lives during the data collection phase and observe \MethodC's response generation in real time. Finally, we gathered feedback from the participants including ratings on answer content, latency, and practical value of \Method on a scale from 1 to 5. %, with 1 being the least favorable and 5 being the most favorable. 
%
We specifically select \MethodC for the user study to evaluate \Method's full functionality in real-world conditions. We leave user evaluation and optimization of \MethodE in a purely edge scenario for future work.


\textbf{User Feedback Results}
Fig.~\ref{fig:user_study} displays the quantitative feedback ratings gathered from the eight participants. \textbf{\Method received an average score of 3.12 for answer content, 4.50 for latency, and 4.00 for practical utility}, supporting \Method's applicability in real life scenarios.
Participant comments praised \Method's natural responses, e.g., ``\textit{The answers were formatted in an easy to understand way}''.
However, concerns were also raised about quantitative accuracy, such as ``\textit{some numbers were a little off}'' and ``\textit{it mentioned activities I never did}''.
We attribute these issues to the limited performance of the sensor encoder when generalizing from a dataset to real-world users, as we observed noisy outputs from the sensor query stage, occasionally detecting activities that never occurred.
Fortunately, generalizing models trained on one dataset to different settings is a well-studied problem~\cite{xu2023practically}. Integrating these techniques into \Method could enhance its practical performance, which we leave for future investigation.
%If the sensor encoder does not transfer well to a new user, the resulting queried data and answers can be inaccurate. 

%More data and few-shot transfer learning could help, which we plan to explore in future work. 
In terms of latency, all participants give positive feedbacks regarding the end-to-end answer generation latency, with comments such as "\textit{I do not feel as if I had to wait a long time for the answers}" and "\textit{I think it is faster than I thought previously}".
Most participants are positive in terms of the practical utility of \Method in their daily lives, e.g., ``\textit{I believe it can help with my wellness management significantly.}'' The less positive comments mentioned the challenge of adapting \Method to individual users for generating more personalized and useful responses, an issue that we leave for future exploration.

%i.e., adapting both sensor encoder and the LLM components to better fit specific users' lifestyle and needs, 
%can be attributed to two potential reasons on the model's performance: (1) the sensor encoder may not predict accurately, and (2) the LLM components may not perform optimally for specific participants' requests.

%Based on the detailed comments from participants, \Method gives more convincing answers in qualitative questions such as ``''The quality of \Method's answers can be potentially improved from...

\textbf{Generalization to Qualitative and Open-Ended Questions}
Participants have asked creative and open-ended questions to \Method that do not exist in \Dataset, providing a more comprehensive assessment of \Method's practical utility.
%For example, one participant asked, ``Was I in a crowded area yesterday?''. While it is not instantly obvious which labels or sensors are relevant, \Method is able to reason by decomposing the question into an activity query, and infers that the participant likely visited crowded places based on labels such as "in school," "talking," and "with friends."
For example, one participant asked, ``\textit{How would you rate my lifestyle and what improvements do you suggest?}'' \Method responded with, ``\textit{I would rate this lifestyle as 2 out of 5 stars and would suggest you improve on your exercise and talking,}'' based on the duration of each activity where exercise and talking were lacking.
The three-stage pipeline, especially the explicit sensor data query stage, enables \Method to analyze users' overall lifestyle and fitness, in addition to answering quantitative questions in \Dataset~\citesensorqa. 
Specifically, \Method achieves this through comprehensively querying a list of activity schedule in the sensor data query stage and then analyzing them with LLM during the answer assembly stage.
Participants appreciated \Method's ability to effectively handle both quantitative and qualitative questions, e.g., "\textit{I think it could be very useful to be able to answer these qualitative and quantitative questions about my lifestyle,}" highlighting its broad applicability to diverse real-life scenarios.

%With its LLM-powered backbone, \Method shows notable expertise in answering these kinds of creative questions. %, which clearly advances the capabilities of existing systems.

\begin{figure*}[t]
  \centering
  \includegraphics[width=0.98\textwidth]{figs/user_study.png}
  \vspace{-4mm}
  \caption{Satisfactory ratings from eight participants on three questions.}
  \vspace{-6mm}
  \label{fig:user_study}
\end{figure*}
