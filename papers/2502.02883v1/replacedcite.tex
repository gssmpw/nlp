\section{Related Work}
\label{sec:related-work}




%\subsection{Question Answering using Sensor Data}
\textbf{Question Answering using Sensor Data}
The QA problem has been extensively studied across various domains, including text____, visual____, medical____, and remote sensing____. In the sensor domain, early works \textit{AI Therapist}____ and its successor CaiTI____ utilized smart home devices, such as Amazon Echo, to engage in conversations with users and assess mental well-being. 
DeepSQA____ was the first to benchmark time-series sensor-based QA for human activity recognition. It introduced SQA-GEN, an automated QA generation tool that gathers 1-minute sensor readings and generates valid Q\&A pairs by exhaustively searching six pre-defined question templates. They mainly focused on quantitative questions including time query, counting and action compare.
The authors also evaluated traditional neural network models, including CNNs and LSTMs, finding that the ConvLSTM network with Compositional Attention achieved the highest QA accuracy.
%However, DeepSQA is limited by a restricted variety of questions and answers, formulating the problem as a classification task. In contrast, \Method supports natural question types and varied time lengths.

Recent contributions have pioneered the integration of LLMs for generating more intuitive answers and better interpreting sensor data. Englhardt \textit{et al.}____, Health-LLM____, and DrHouse____ converted physiological data from wearable devices, such as heart rates and daily step counts, into text prompts for LLMs, enabling more sophisticated medical and healthcare diagnoses.
The latest Sensor2Text____ and PrISM-Q\&A____ explored natural language interactions between users and wearable devices to understand and support daily activities using sensor data, such as advising on "What should I do next with this?" Both approaches utilized LLMs as their backbone and fed sensor embeddings into the models.

While promising, existing systems exhibit significant limitations in handling long duration and complex sensor data required for accurate answers. Table~\ref{tbl:related_works} highlights the key differences between \Method and existing QA systems. In summary, \Method greatly enhances capabilities of existing systems by (1) answering questions based on long-duration sensor data spanning weeks or months, compared to the short windows of seconds or minutes in previous systems____, and (2) encoding high-dimensional time-series data to extract fine-grained activity details for reasoning, unlike prior systems that are limited to low-dimensional sensor data____.
%However, these works use coarse-grained sensor data which cannot be easily adapted to timeseries and detailed quantitative questions.
%\Method instead focuses on analyzing rich timeseries data.
%However, these works have two drawbacks: (1) they merely input text-formatted sensor data into LLM which may not work well for timeseries; (2) their usage of closed-source LLMs such as GPT-4 and external knowledge databases are challenging for edge devices. \Method addresses both drawbacks. 
%However, all above works focused on health-related aspects and used lower dimensional of data compared to raw sensor time series. Their approaches cannot be directly transferred to daily-life activity monitoring with raw time series sensors.

%fused low-dimensional sensors data such as from smart home sensors or wristband with LLMs to infer health status.
%infer mental health and assess the user's daily functioning using GPT-3. %Their approach integrated a GPT-3-based natural language processing core to interact with users as well as detect abnormal mental status, based on 37 dimensions suggested by the therapists.

%considering only the top 27 answers and 

%A major constraint lies in their language models, which predict outputs as a classification problem - such as a 0-2 mental health core in \textit{AI therapist} and only the top 27 answers considered as the ground-truth labels in DeepSQA. This design restricts their models to a highly constrained QA scenario that may not be applicable in real life.
%In contrast, the distinctiveness of \Method lies in its capacity to accommodate "arbitrary" and "unpredictable" questions, namely open-ended question answering.

%\subsection{LLMs for Multimodal Reasoning}
%\vspace{1mm}
\textbf{LLMs for Multimodal Reasoning}
%The surge of LLM has triggered a wave of innovations in text understanding and reasoning applications.
Recent works investigated multimodal LLMs that transform other data modalities into a sequence of tokens for LLM integration____.
IMU2CLIP____ and TENT____ employed contrastive pretraining to align text with various timeseries sensor signals.
%To enable this transformation, IMU2CLIP____ utilized contrastive pretraining to align IMU signals with text narration____. Similarly, TENT____ employed contrastive pretraining to align text with a broader set of IoT sensor signals, including camera video, LiDAR, and mmWave data. Both approaches have limited sensor-specific reasoning capabilities as they used a frozen LLM without further tuning or did not utilize an LLM at all. 
Recent designs like AnyMAL____ and OneLLM____ proposed fine-tuning multimodal LLMs to process up to eight different modalities, including IMU time series, for reasoning tasks.
However, direct integration of time series sensor data to LLMs is constrained by LLM's inherent weakness in handling long-context inputs____, making them unsuitable for processing long-duration sensor signals. In contrast, \Method overcomes this limitation by incorporating a dedicated sensor data query stage, enabling it to handle long-term queries effectively.
%requires a large instruction dataset with well-aligned multimodal data, which is lacking in multimodal sensor-based QA. 
%that accept IMU signal inputs using carefully prepared instruction datasets.

%\begin{wraptable}{r}{0.55\textwidth}
%\vspace{-4mm}
\begin{table}
\small
\caption{Comparing {\Method} and existing QA systems.}
\label{tbl:related_works}
\vspace{-4mm}
\begin{center}
\begin{tabular}{ccc} % note: no vertical bars at all
\toprule
\textbf{Existing QA systems for sensor data} & \textbf{Long-duration} & \textbf{High-dimensional} \\
& \textbf{sensor data} & \textbf{time series sensors} \\
\midrule
DeepSQA____, Sensor2Text____, PrISM-Q\&A____ & \X & \Ch \\
Englhardt \textit{et al.}____, Health-LLM____, DrHouse____& \Ch & \X \\ \midrule
 \textbf{\Method (this work)} & \textbf{\Ch} & \textbf{\Ch} \\
\bottomrule
\end{tabular}
\end{center}
\vspace{-4mm}
\end{table}
%\end{wraptable}


\iffalse
\begin{figure*}[htbp]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/frequency_query.png}
        \vspace{-6mm}
        \caption{Example question of frequency query.}
        \label{fig:daily-freq}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/time_query.png}
        \vspace{-6mm}
        \caption{Example question of time query.}
        \label{fig:daily-time}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/day_query.png}
        \vspace{-6mm}
        \caption{Example question of day query.}
        \label{fig:weekly-day}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/activity_query.png}
        \vspace{-6mm}
        \caption{Example question of activity query.}
        \label{fig:weekly-activity}
    \end{subfigure}
    \vspace{-4mm}
    \caption{Example QA pairs that we collect from AMT. (a) and (b) are generated from daily graph, while (c) and (d) are generated from weekly graph.}
    \label{fig:example_qas}
    \vspace{-4mm}
\end{figure*}
\fi





\iffalse
Limited prior research has studied finetuning LLMs for specific reasoning tasks. Based on IMU2CLIP, AnyMAL____ further finetuned the LLM by training projection layers or applying Low-Rank Adaptation (LoRA).
Nevertheless, the general fine-tuning approach of AnyMAL struggles to accurately address sensor-specific queries, such as those pertaining to specific times and locations. These challenges are effectively tackled in \Method through the introduction of two novel fine-tuning techniques, setting \Method apart from existing methodologies.
\fi

%\subsection{Human Activity Monitoring}
%\vspace{1mm}
\textbf{Mobile Systems for Daily Life Monitoring}
Researchers have explored a variety of sensing technologies for monitoring human lives, including built-in sensors on smart phones____, cameras____, Wi-Fi signals____ and mmWave radar____.
Although these efforts have resulted in numerous open-source datasets____ and powerful machine learning models____, they fail to handle queries in natural language, which are more creative and open-ended.
%the vast majority of the existing work has focused on human activity recognition. %, a \textit{passive} way of processing information where the user has no control. 
%How to further interpret the data beyond activity classification has remained less explored.
In this paper, we design \Method to facilitate long-term QA interactions based on time series sensor data.
The methodology of \Method can be further integrated with other sensing modalities and applications.