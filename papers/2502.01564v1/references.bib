@inproceedings{dabbish2012social,
  title={Social coding in GitHub: transparency and collaboration in an open software repository},
  author={Dabbish, Laura and Stuart, Colleen and Tsay, Jason and Herbsleb, Jim},
  booktitle={Proceedings of the ACM 2012 conference on computer supported cooperative work},
  pages={1277--1286},
  year={2012}
}

@inproceedings{tankelevitch2024metacognitive,
  title={The metacognitive demands and opportunities of generative AI},
  author={Tankelevitch, Lev and Kewenig, Viktor and Simkute, Auste and Scott, Ava Elizabeth and Sarkar, Advait and Sellen, Abigail and Rintel, Sean},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--24},
  year={2024}
}

@article{do2023err,
  title={To Err is AI: Imperfect Interventions and Repair in a Conversational Agent Facilitating Group Chat Discussions},
  author={Do, Hyo Jin and Kong, Ha-Kyung and Tetali, Pooja and Lee, Jaewook and Bailey, Brian P},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={7},
  number={CSCW1},
  pages={1--23},
  year={2023},
  publisher={ACM New York, NY, USA}
}
@inproceedings{park2024coexplorer,
  title={The CoExplorer Technology Probe: A Generative AI-Powered Adaptive Interface to Support Intentionality in Planning and Running Video Meetings},
  author={Park, Gun Woo and Panda, Payod and Tankelevitch, Lev and Rintel, Sean},
  booktitle={Proceedings of the 2024 ACM Designing Interactive Systems Conference},
  pages={1638--1657},
  year={2024}
}

@inproceedings{yang2020re,
  title={Re-examining whether, why, and how human-AI interaction is uniquely difficult to design},
  author={Yang, Qian and Steinfeld, Aaron and Ros{\'e}, Carolyn and Zimmerman, John},
  booktitle={Proceedings of the 2020 chi conference on human factors in computing systems},
  pages={1--13},
  year={2020}
}

@inproceedings{dhillon2024shaping,
  title={Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models},
  author={Dhillon, Paramveer S and Molaei, Somayeh and Li, Jiaqi and Golub, Maximilian and Zheng, Shaochun and Robert, Lionel Peter},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  year={2024}
}


@inproceedings{lu2023readingquizmaker,
  title={ReadingQuizMaker: A Human-NLP Collaborative System that Supports Instructors to Design High-Quality Reading Quiz Questions},
  author={Lu, Xinyi and Fan, Simin and Houghton, Jessica and Wang, Lu and Wang, Xu},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  year={2023}
}


@article{fang2022understanding,
  title={Understanding the Effects of Structured Note-taking Systems for Video-based Learners in Individual and Social Learning Contexts},
  author={Fang, Jingchao and Wang, Yanhao and Yang, Chi-Lan and Liu, Ching and Wang, Hao-Chuan},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={6},
  number={GROUP},
  pages={1--21},
  year={2022},
  publisher={ACM New York, NY, USA}
}


@article{koedinger2007exploring,
  title={Exploring the assistance dilemma in experiments with cognitive tutors},
  author={Koedinger, Kenneth R and Aleven, Vincent},
  journal={Educational Psychology Review},
  volume={19},
  pages={239--264},
  year={2007},
  publisher={Springer}
}



@article{sun2022students,
  title={How do students generate ideas together in scientific creativity tasks through computer-based mind mapping?},
  author={Sun, Meng and Wang, Minhong and Wegerif, Rupert and Peng, Jun},
  journal={Computers \& Education},
  volume={176},
  pages={104359},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{shih2009groupmind,
  title={GroupMind: supporting idea generation through a collaborative mind-mapping tool},
  author={Shih, Patrick C and Nguyen, David H and Hirano, Sen H and Redmiles, David F and Hayes, Gillian R},
  booktitle={Proceedings of the 2009 ACM International Conference on Supporting Group Work},
  pages={139--148},
  year={2009}
}


@inproceedings{liao2023deepthinkingmap,
  title={DeepThinkingMap: Collaborative Video Reflection System with Graph-based Summarizing and Commenting},
  author={Liao, Jingxian and Singh, Mrinalini and Wang, Hao-Chuan},
  booktitle={Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
  pages={369--371},
  year={2023}
}

@inproceedings{liu2018conceptscape,
  title={ConceptScape: Collaborative concept mapping for video learning},
  author={Liu, Ching and Kim, Juho and Wang, Hao-Chuan},
  booktitle={Proceedings of the 2018 CHI conference on human factors in computing systems},
  pages={1--12},
  year={2018}
}

@inproceedings{liu2023visual,
  title={Visual Captions: Augmenting Verbal Communication With On-the-Fly Visuals},
  author={Liu, Xingyu" Bruce" and Kirilyuk, Vladimir and Yuan, Xiuxiu and Olwal, Alex and Chi, Peggy and Chen, Xiang" Anthony" and Du, Ruofei},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--20},
  year={2023}
}
 @article{tornberg2023chatgpt,
  title={Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning},
  author={T{\"o}rnberg, Petter},
  journal={arXiv preprint arXiv:2304.06588},
  year={2023}
}

@article{Barnett1981WhatIL,
  title={What Is Learned in Note Taking},
  author={Jerrold E. Barnett and Francis J. di Vesta and James T. Rogozinski},
  journal={Journal of Educational Psychology},
  year={1981},
  volume={73},
  pages={181-192},
  url={https://api.semanticscholar.org/CorpusID:143614892}
}

@article{Courtney2022IndividualVC,
  title={Individual versus collaborative note-taking: Results of a quasi-experimental study on student note completeness, test performance, and academic writing},
  author={Matthew Courtney and Jamie Costley and Matthew Baldwin and Kyungmee Lee and Mik Fanguy},
  journal={Internet High. Educ.},
  year={2022},
  volume={55},
  pages={100873},
  url={https://api.semanticscholar.org/CorpusID:250229395}
}

@inproceedings{Bain2007UsingSR,
  title={Using Speech Recognition and Intelligent Search Tools to Enhance Information Accessibility},
  author={Keith Bain and Jason Hines and Pawan Lingras and Yumei Qin},
  booktitle={Interacci{\'o}n},
  year={2007},
  url={https://api.semanticscholar.org/CorpusID:475582}
}

@book{schwartz2016abcs,
  title={The ABCs of how we learn: 26 scientifically proven approaches, how they work, and when to use them},
  author={Schwartz, Daniel L and Tsang, Jessica M and Blair, Kristen P},
  year={2016},
  publisher={WW Norton \& Company}
}

@book{braun2012thematic,
  title={Thematic analysis.},
  author={Braun, Virginia and Clarke, Victoria},
  year={2012},
  publisher={American Psychological Association}
}

@article{zhang2021ideal,
  title={" An ideal human" expectations of AI teammates in human-AI teaming},
  author={Zhang, Rui and McNeese, Nathan J and Freeman, Guo and Musick, Geoff},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW3},
  pages={1--25},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{schutmaat2023take,
  title={Take a Break, But Make It Different! Moderating Effects of Incubation Task Specificity on Advertising Idea Generation},
  author={Sch{\"u}tmaat, Sarah and Kopka, Julian Felix and Ang, Lawrence and Langner, Tobias},
  journal={Journal of Advertising},
  volume={52},
  number={4},
  pages={578--593},
  year={2023},
  publisher={Taylor \& Francis}
}
@inproceedings{richter2001integrating,
  title={Integrating meeting capture within a collaborative team environment},
  author={Richter, Heather and Abowd, Gregory D and Geyer, Werner and Fuchs, Ludwin and Daijavad, Shahrokh and Poltrock, Steven},
  booktitle={Ubicomp 2001: Ubiquitous Computing: International Conference Atlanta Georgia, USA, September 30--October 2, 2001 Proceedings 3},
  pages={123--138},
  year={2001},
  organization={Springer}
}

@article{davis1998notepals,
  title={NotePals: Lightweight Note Taking by the Group, for the Group},
  author={Davis, Richard C and Brotherton, Jason A and Landay, James A and Price, Morgan N and Schilit, Bill N},
  journal={University of California, Berkeley, Computer Science Division},
  volume={8},
  year={1998},
  publisher={Citeseer}
}

@article{a.allenUnderstandingWorkplaceMeetings2014,
  title = {Understanding Workplace Meetings: {{A}} Qualitative Taxonomy of Meeting Purposes},
  shorttitle = {Understanding Workplace Meetings},
  author = {A. Allen, Joseph and Beck, Tammy and W. Scott, Cliff and G. Rogelberg, Steven},
  date = {2014-01-01},
  journaltitle = {Management Research Review},
  volume = {37},
  number = {9},
  pages = {791--814},
  publisher = {{Emerald Group Publishing Limited}},
  issn = {2040-8269},
  doi = {10.1108/MRR-03-2013-0067},
  url = {https://doi.org/10.1108/MRR-03-2013-0067},
  urldate = {2023-06-05},
  abstract = {Purpose The purpose of this study is to propose a taxonomy of meeting purpose. Meetings are a workplace activity that deserves increased attention from researchers and practitioners. Previous researchers attempted to develop typologies of meeting purpose with limited success. Through a comparison of classification methodologies, the authors consider a taxonomy as the appropriate classification scheme for meeting purpose. The authors then utilize the developed taxonomy to investigate the frequency with which a representative sample of working adults engaged in meetings of these varying purposes. Their proposed taxonomy provides relevant classifications for future research on meetings as well and serves as a useful tool for managers seeking to use and evaluate the effectiveness of meetings within their organizations. Design/methodology/approach This study employs an inductive methodology using discourse analysis of qualitative meeting descriptions to develop a taxonomy of meeting purpose. The authors discourse analysis utilizes open-ended survey responses from a sample of working adults (n = 491). Findings The authors categorical analysis of open-ended questions resulted in a 16-category taxonomy of meeting purpose. The two most prevalent meeting purpose categories in this sample were “to discuss ongoing projects” at 11.6 per cent and “to routinely discuss the state of the business” at 10.8 per cent. The two least common meeting purpose categories in this sample were “to brainstorm for ideas or solutions” at 3.3 per cent and “to discuss productivity and efficiencies” at 3.7 per cent. The taxonomy was analyzed across organizational type and employee job level to identify differences between those important organizational and employee characteristics. Research limitations/implications The data suggested that meetings were institutionalized in organizations, making them useful at identifying differences between organizations as well as differences in employees in terms of scope of responsibility. Researchers and managers should consider the purposes for which they call meetings and how that manifests their overarching organizational focus, structure and goals. Originality/value This is the first study to overtly attempt to categorize the various purposes for which meetings are held. Further, this study develops a taxonomy of meeting purposes that will prove useful for investigating the different types of meeting purposes in a broad range of organizational types and structures.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/WYU4XVBR/A. Allen et al. - 2014 - Understanding workplace meetings A qualitative ta.pdf}
}

@article{mik2019effects,
  title={The effects of collaborative note-taking in flipped learning contexts},
  author={Mik, Fanguy and others},
  journal={Journal of Language and Education},
  volume={5},
  number={4 (20)},
  pages={25--35},
  year={2019},
  publisher={Федеральное государственное автономное образовательное учреждение высшего~…}
}

@article{Kiewra1991NotetakingFA,
  title={Note-taking functions and techniques.},
  author={Kenneth A. Kiewra and Nelson F. Dubois and David Christian and Anne McShane and Michelle Meyerhoffer and David Roskelley},
  journal={Journal of Educational Psychology},
  year={1991},
  volume={83},
  pages={240-245},
  url={https://api.semanticscholar.org/CorpusID:144626647}
}

@article{zubizarreta2013co,
  title={Co-creative dialogue for meeting practical challenges},
  author={Zubizarreta, Rosa},
  journal={OD Practitioner},
  volume={45},
  number={1},
  pages={47--53},
  year={2013}
}

@article{kiewra1989review,
  title={A review of note-taking: The encoding-storage paradigm and beyond},
  author={Kiewra, Kenneth A},
  journal={Educational Psychology Review},
  volume={1},
  pages={147--172},
  year={1989},
  publisher={Springer}
}

@online{AccessibilityBarriersConflicts,
  title = {Accessibility {{Barriers}}, {{Conflicts}} and {{Repairs}}: {{Understanding}} the {{Experience}} of {{Professionals}} with {{Disabilities}} in {{Hybrid Meetings}} - {{CHI}} '23},
  shorttitle = {Accessibility {{Barriers}}, {{Conflicts}} and {{Repairs}}},
  url = {https://programs.sigchi.org/chi/2023/program/content/95906},
  urldate = {2023-04-27},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4JIKSRW7/95906.html}
}

@online{AccessibilityBarriersConflictsa,
  title = {Accessibility {{Barriers}}, {{Conflicts}}, and {{Repairs}}: {{Understanding}} the {{Experience}} of {{Professionals}} with {{Disabilities}} in {{Hybrid Meetings}} | {{Proceedings}} of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581541},
  urldate = {2023-04-27},
  keywords = {notion}
}

@incollection{ackermannGroupSupportSystems2021,
  title = {Group {{Support Systems}}: {{Past}}, {{Present}}, and {{Future}}},
  shorttitle = {Group {{Support Systems}}},
  booktitle = {Handbook of {{Group Decision}} and {{Negotiation}}},
  author = {Ackermann, Fran},
  editor = {Kilgour, D. Marc and Eden, Colin},
  date = {2021},
  pages = {627--654},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-49629-6_47},
  url = {https://link.springer.com/10.1007/978-3-030-49629-6_47},
  urldate = {2023-08-21},
  isbn = {978-3-030-49628-9 978-3-030-49629-6},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/5WBHHMC6/Ackermann - 2021 - Group Support Systems Past, Present, and Future.pdf}
}

@article{adamsPeopleSystematicallyOverlook2021,
  title = {People Systematically Overlook Subtractive Changes},
  author = {Adams, Gabrielle S. and Converse, Benjamin A. and Hales, Andrew H. and Klotz, Leidy E.},
  date = {2021-04},
  journaltitle = {Nature},
  volume = {592},
  number = {7853},
  pages = {258--261},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03380-y},
  url = {https://www.nature.com/articles/s41586-021-03380-y},
  urldate = {2023-03-15},
  abstract = {Improving objects, ideas or situations—whether a designer seeks to advance technology, a writer seeks to strengthen an argument or a manager seeks to encourage desired behaviour—requires a mental search for possible changes1–3. We investigated whether people are as likely to consider changes that subtract components from an object, idea or situation as they are to consider changes that add new components. People typically consider a limited number of promising ideas in order to manage the cognitive burden of searching through all possible ideas, but this can lead them to accept adequate solutions without considering potentially superior alternatives4–10. Here we show that people systematically default to searching for additive transformations, and consequently overlook subtractive transformations. Across eight experiments, participants were less likely to identify advantageous subtractive changes when the task did not (versus did) cue them to consider subtraction, when they had only one opportunity (versus several) to recognize the shortcomings of an additive search strategy or when they were under a higher (versus lower) cognitive load. Defaulting to searches for additive changes may be one reason that people struggle to mitigate overburdened schedules11, institutional red tape12 and damaging effects on the planet13,14.},
  issue = {7853},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/KPEH2IWK/Adams et al. - 2021 - People systematically overlook subtractive changes.pdf}
}

@article{ahmadAutomaticContentAnalysis2022,
  title = {Automatic Content Analysis of Asynchronous Discussion Forum Transcripts: {{A}} Systematic Literature Review},
  shorttitle = {Automatic Content Analysis of Asynchronous Discussion Forum Transcripts},
  author = {Ahmad, Mubarik and Junus, Kasiyah and Santoso, Harry Budi},
  date = {2022-09-01},
  journaltitle = {Education and Information Technologies},
  shortjournal = {Educ Inf Technol},
  volume = {27},
  number = {8},
  pages = {11355--11410},
  issn = {1573-7608},
  doi = {10.1007/s10639-022-11065-w},
  url = {https://doi.org/10.1007/s10639-022-11065-w},
  urldate = {2023-05-08},
  abstract = {In recent years, the use of asynchronous discussion forums in online learning has increased rapidly. In earlier studies, content analysis is the most-used research method in exploring the discussion transcripts. However, conventional content analysis is a time-consuming task and requires experienced coders. There is a need for an automated approach to analyse the online discussion transcripts to help instructors optimise the learners' learning experiences. This article presents a systematic literature review of the automated content analysis approach in online discussion transcripts. Fifty-four relevant peer-reviewed conference and journal papers were found between January 2016 and October 2021, using the PRISMA and snowball methods. Eight measurement dimensions were studied from online learning transcripts: cognitive, social, relevance/importance, summary, pattern, behaviour, topic, and learning resources. Six theoretical frameworks were used in the selected studies, namely the Community of Inquiry, Stump's Post Classification, Arguello's Speech Acts, ICAP, Wise's Speaking Behaviour, and Bloom's Taxonomy. All selected studies are experimental, with 93\% using machine learning to analyse discussion transcripts. English is the most-used language dataset, used in 78\% of studies. These studies reported promising results in accuracy and precision. However, this research area still has room for improvement, especially in the reliability and generalisability of cross-domain context.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/EBLBTEZM/Ahmad et al. - 2022 - Automatic content analysis of asynchronous discuss.pdf}
}

@article{AnalysisNegotiationCommon2007,
  title = {The analysis of negotiation of common ground in CSCL},
  date = {2007-08-01},
  journaltitle = {Learning and Instruction},
  volume = {17},
  number = {4},
  pages = {427--435},
  publisher = {{Pergamon}},
  issn = {0959-4752},
  doi = {10.1016/j.learninstruc.2007.04.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0959475207000576},
  urldate = {2023-03-15},
  abstract = {CSCL research has given rise to a plethora of analysis methods, all with specific analysis goals, units of analysis, and for specific types of data (c…},
  langid = {chinese},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CQ52F9FT/Beers et al. - 2007 - The analysis of negotiation of common ground in CS.pdf;/Users/xinyuech/Zotero/storage/DPPDQBTE/2007 - The analysis of negotiation of common ground in CS.pdf;/Users/xinyuech/Zotero/storage/U4DG7NZ2/S0959475207000576.html}
}

@online{AnalysisVerbalInteractions,
  title = {Analysis of Verbal Interactions in Tutorial Groups: A Process Study - {{Visschers}}‐{{Pleijers}} - 2006 - {{Medical Education}} - {{Wiley Online Library}}},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2929.2005.02368.x?casa_token=Df7gPJ9miKIAAAAA:a3uZIFW8HUlJFecwWlo7mHeF5pz3QxxVuzPmFJSYBjzn1bj8vP80G10zdNz4ON9cJI6pKeAzb3MjtgADgA},
  urldate = {2023-06-04},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/FUFPTANH/j.1365-2929.2005.02368.html}
}

@article{telenius2016sensemaking,
  title={Sensemaking in Meetings-Collaborative Construction of Meaning and Decisions through Epistemic Authority},
  author={Telenius, Johanna and others},
  year={2016},
  publisher={Aalto University}
}

@inproceedings{anastasiouMakingSenseOnline2021,
  title = {Making {{Sense}} of {{Online Discussions}}: {{Can Automated Reports}} Help?},
  shorttitle = {Making {{Sense}} of {{Online Discussions}}},
  booktitle = {Extended {{Abstracts}} of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Anastasiou, Lucas and De Liddo, Anna},
  date = {2021-05-08},
  pages = {1--7},
  publisher = {{ACM}},
  location = {{Yokohama Japan}},
  doi = {10.1145/3411763.3451815},
  url = {https://dl.acm.org/doi/10.1145/3411763.3451815},
  urldate = {2022-11-02},
  abstract = {Enabling healthier online deliberation around issues of public concerns is an increasingly vital challenge in nowadays society. Two fundamental components of a healthier deliberation are: i. the capability of people to make sense of what they read, so that their contribution can be relevant; and ii. the improvement of the overall quality of the debate, so that noise can be reduced and useful signals can inform collective decision making. Platform designers often resort to computational aids to improve these two processes. In this paper, we examine automated reporting as promising mean of improving sensemaking in discussion platforms. We compared three approaches to automated reporting: an abstractive summariser, a template report and an argumentation highlighting system. We then evaluated improvements in sensemaking of participants and the perception on overall quality of the debate. The study suggests that argument mining technologies are particularly promising computational aids to improve sense making and perceived quality of online discussion, thanks to their capability to combine computational models for automated reasoning with users’ cognitive needs and expectation of automated reporting.},
  eventtitle = {{{CHI}} '21: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-8095-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/9WLF5S65/Anastasiou and De Liddo - 2021 - Making Sense of Online Discussions Can Automated .pdf}
}

@inproceedings{andolinaCrowdboardAugmentingInPerson2017,
  title = {Crowdboard: {{Augmenting In-Person Idea Generation}} with {{Real-Time Crowds}}},
  shorttitle = {Crowdboard},
  booktitle = {Proceedings of the 2017 {{ACM SIGCHI Conference}} on {{Creativity}} and {{Cognition}}},
  author = {Andolina, Salvatore and Schneider, Hendrik and Chan, Joel and Klouche, Khalil and Jacucci, Giulio and Dow, Steven},
  date = {2017-06-22},
  pages = {106--118},
  publisher = {{ACM}},
  location = {{Singapore Singapore}},
  doi = {10.1145/3059454.3059477},
  url = {https://dl.acm.org/doi/10.1145/3059454.3059477},
  urldate = {2023-03-21},
  eventtitle = {C\&{{C}} '17: {{Creativity}} and {{Cognition}}},
  isbn = {978-1-4503-4403-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/WKRI85J2/Andolina et al. - 2017 - Crowdboard Augmenting In-Person Idea Generation w.pdf}
}

@inproceedings{ansahNeedRespondThis2022,
  title = {”{{I}} Need to Respond to This” – {{Contributions}} to Group Creativity in Remote Meetings with Distractions},
  booktitle = {2022 {{Symposium}} on {{Human-Computer Interaction}} for {{Work}}},
  author = {Ansah, Alberta A. and Xing, Yilun and Kamaraj, Amudha Varshini and Tosca, Diana and Boyle, Linda and Iqbal, Shamsi and Kun, Andrew L. and Lee, John D. and Pahud, Michel and Shaer, Orit},
  date = {2022-06-08},
  pages = {1--12},
  publisher = {{ACM}},
  location = {{Durham NH USA}},
  doi = {10.1145/3533406.3533411},
  url = {https://dl.acm.org/doi/10.1145/3533406.3533411},
  urldate = {2023-08-16},
  eventtitle = {{{CHIWORK}} 2022: 2022 {{Symposium}} on {{Human-Computer Interaction}} for {{Work}}},
  isbn = {978-1-4503-9655-4},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️},
  file = {/Users/xinyuech/Zotero/storage/KNWEB5W7/Ansah et al. - 2022 - ”I need to respond to this” – Contributions to gro.pdf}
}

@article{aragonThreadNotThread2017,
  title = {To {{Thread}} or {{Not}} to {{Thread}}: {{The Impact}} of {{Conversation Threading}} on {{Online Discussion}}},
  shorttitle = {To {{Thread}} or {{Not}} to {{Thread}}},
  author = {Aragón, Pablo and Gómez, Vicenç and Kaltenbrunner, Andreaks},
  date = {2017-05-03},
  journaltitle = {Proceedings of the International AAAI Conference on Web and Social Media},
  volume = {11},
  number = {1},
  pages = {12--21},
  issn = {2334-0770},
  doi = {10.1609/icwsm.v11i1.14880},
  url = {https://ojs.aaai.org/index.php/ICWSM/article/view/14880},
  urldate = {2023-03-22},
  abstract = {Online discussion is essential for the communication and collaboration of online communities. The reciprocal exchange of messages between users that characterizes online discussion can be represented in many different ways. While some platforms display messages chronologically using a simple linear interface, others use a hierarchical (threaded) interface to represent more explicitly the structure of the discussion. Although the type of representation has been shown to affect communication, to the best of our knowledge, the impact of using either one or the other has not yet been investigated in a large and mature online community. In this work we analyze Meneame, a popular Spanish social news platform which recently transitioned from a linear to a hierarchical interface, becoming an ideal research opportunity for this purpose. Using interrupted time series analysis and regression discontinuity design, we observe an abrupt and significant increase in social reciprocity after the adoption of a threaded interface. We furthermore extend state-of-the-art generative models of discussion threads by including reciprocity, a fundamental feature to explain better the structure of the discussions, both before and after the change in the interface.},
  issue = {1},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/T93HKA5K/Aragón et al. - 2017 - To Thread or Not to Thread The Impact of Conversa.pdf}
}

@inproceedings{arakawaCatAlystDomainExtensibleIntervention2023,
  title = {{{CatAlyst}}: {{Domain-Extensible Intervention}} for {{Preventing Task Procrastination Using Large Generative Models}}},
  shorttitle = {{{CatAlyst}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Arakawa, Riku and Yakura, Hiromu and Goto, Masataka},
  date = {2023-04-19},
  pages = {1--19},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581133},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581133},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4TQJ5FGL/Arakawa et al. - 2023 - CatAlyst Domain-Extensible Intervention for Preve.pdf}
}

@inproceedings{ashbyPersonalizedQuestDialogue2023,
  title = {Personalized {{Quest}} and {{Dialogue Generation}} in {{Role-Playing Games}}: {{A Knowledge Graph-}} and {{Language Model-based Approach}}},
  shorttitle = {Personalized {{Quest}} and {{Dialogue Generation}} in {{Role-Playing Games}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Ashby, Trevor and Webb, Braden K and Knapp, Gregory and Searle, Jackson and Fulda, Nancy},
  date = {2023-04-19},
  pages = {1--20},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581441},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581441},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/H6JGHLXQ/Ashby et al. - 2023 - Personalized Quest and Dialogue Generation in Role.pdf}
}

@inproceedings{ashktorabResilientChatbotsRepair2019,
  title = {Resilient {{Chatbots}}: {{Repair Strategy Preferences}} for {{Conversational Breakdowns}}},
  shorttitle = {Resilient {{Chatbots}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Ashktorab, Zahra and Jain, Mohit and Liao, Q. Vera and Weisz, Justin D.},
  date = {2019-05-02},
  series = {{{CHI}} '19},
  pages = {1--12},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3290605.3300484},
  url = {https://doi.org/10.1145/3290605.3300484},
  urldate = {2023-03-14},
  abstract = {Text-based conversational systems, also referred to as chatbots, have grown widely popular. Current natural language understanding technologies are not yet ready to tackle the complexities in conversational interactions. Breakdowns are common, leading to negative user experiences. Guided by communication theories, we explore user preferences for eight repair strategies, including ones that are common in commercially-deployed chatbots (e.g., confirmation, providing options), as well as novel strategies that explain characteristics of the underlying machine learning algorithms. We conducted a scenario-based study to compare repair strategies with Mechanical Turk workers (N=203). We found that providing options and explanations were generally favored, as they manifest initiative from the chatbot and are actionable to recover from breakdowns. Through detailed analysis of participants' responses, we provide a nuanced understanding on the strengths and weaknesses of each repair strategy.},
  isbn = {978-1-4503-5970-2},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/76C5H2X2/Ashktorab et al. - 2019 - Resilient Chatbots Repair Strategy Preferences fo.pdf}
}

@inproceedings{baeSpinneretAidingCreative2020,
  title = {Spinneret: {{Aiding Creative Ideation}} through {{Non-Obvious Concept Associations}}},
  shorttitle = {Spinneret},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Bae, Suyun Sandra and Kwon, Oh-Hyun and Chandrasegaran, Senthil and Ma, Kwan-Liu},
  date = {2020-04-23},
  series = {{{CHI}} '20},
  pages = {1--13},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3313831.3376746},
  url = {https://doi.org/10.1145/3313831.3376746},
  urldate = {2023-03-15},
  abstract = {思维导图是一种在创造性思维练习中探索设计空间的流行方式，允许用户在概念之间形成关联。然而，大多数现有的思维导图数字工具都侧重于创作和组织，很少支持解决思维导图的挑战，例如停滞和设计固定。我们介绍了 Spinneret，这是一种通过基于知识图提供建议来帮助思维导图的功能方法。Spinneret 使用有偏随机游走在思维导图中现有概念节点的邻域内探索知识图谱，并为用户提供添加到思维导图中的“建议”。与基线思维导图工具的比较研究表明，参与者使用 Spinneret 创建了更加多样化和独特的概念，},
  isbn = {978-1-4503-6708-0},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DG95K3EK/Bae et al. - 2020 - Spinneret Aiding Creative Ideation through Non-Ob.pdf}
}

@article{fanguy2023analyzing,
  title={Analyzing collaborative note-taking behaviors and their relationship with student learning through the collaborative encoding-storage paradigm},
  author={Fanguy, Mik and Costley, Jamie and Courtney, Matthew and Lee, Kyungmee},
  journal={Interactive Learning Environments},
  pages={1--15},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{makany2009optimising,
  title={Optimising the use of note-taking as an external cognitive aid for increasing learning},
  author={Makany, Tamas and Kemp, Jonathan and Dror, Itiel E},
  journal={British Journal of Educational Technology},
  volume={40},
  number={4},
  pages={619--635},
  year={2009},
  publisher={Wiley Online Library}
}

@article{bailensonNonverbalOverloadTheoretical2021,
  title = {Nonverbal Overload: {{A}} Theoretical Argument for the Causes of {{Zoom}} Fatigue.},
  shorttitle = {Nonverbal Overload},
  author = {Bailenson, Jeremy N.},
  date = {2021-02-23},
  journaltitle = {Technology, Mind, and Behavior},
  shortjournal = {Technology, Mind, and Behavior},
  volume = {2},
  number = {1},
  issn = {2689-0208},
  doi = {10.1037/tmb0000030},
  url = {https://tmb.apaopen.org/pub/nonverbal-overload},
  urldate = {2023-03-22},
  abstract = {For decades, scholars have predicted that videoconference technology will disrupt the practice of commuting daily to and from work and will change the way people socialize. In 2020, the Covid-19 pandemic forced a drastic increase in the number of videoconference meetings, and Zoom became the leading software package because it was free, robust, and easy to use. While the software has been an essential tool for productivity, learning, and social interaction, something about being on videoconference all day seems particularly exhausting, and the term “Zoom Fatigue” caught on quickly. In this article, I focus on nonverbal overload as a potential cause for fatigue and provide four arguments outlining how various aspects of the current Zoom interface likely lead to psychological consequences. The arguments are based on academic theory and research, but also have yet to be directly tested in the context of Zoom, and require future experimentation to confirm. Instead of indicting the medium, my goal is to point out these design flaws to isolate research areas for social scientists and to suggest design improvements for technologists.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/FPDH5E3D/Bailenson - 2021 - Nonverbal overload A theoretical argument for the.pdf}
}

@article{bakerROLEGROUNDINGCOLLABORATIVE,
  title = {{{THE ROLE OF GROUNDING IN COLLABORATIVE LEARNING TASKS}}},
  author = {Baker, Michael and Hansen, Tia and Joiner, Richard},
  abstract = {Collaborative learning tasks involve interaction between multiple participants, who thus need to maintain some degree of mutual understanding. The process by which this is accomplished is termed grounding. The way in which collaboration, grounding and learning take place is largely determined by the task, the situation and the tools available. This paper discusses relations between grounding, collaboration and learning, drawing on research from two main areas: the Language Sciences and Cultural-Historical Activity Theory ("CHAT"). We build a unifying perspective of mutual understanding mediated by material and semiotic tools that can be used for analysis as well as for design of collaborative learning tasks, especially those that are carried out via computer-mediated communication. We illustrate the perspective with reference to a particular computermediated collaborative learning situation in the domain of physics.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4KQMBNFB/Baker et al. - THE ROLE OF GROUNDING IN COLLABORATIVE LEARNING TA.pdf}
}

@inproceedings{banerjeeNecessityMeetingRecording2005,
  title = {The {{Necessity}} of a {{Meeting Recording}} and {{Playback System}}, and the {{Benefit}} of {{Topic}}–{{Level Annotations}} to {{Meeting Browsing}}},
  booktitle = {Human-{{Computer Interaction}} - {{INTERACT}} 2005},
  author = {Banerjee, Satanjeev and Rose, Carolyn and Rudnicky, Alexander I.},
  editor = {Costabile, Maria Francesca and Paternò, Fabio},
  date = {2005},
  pages = {643--656},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11555261_52},
  abstract = {Much work in the area of Computer Supported Cooperative Work (CSCW) has targeted the problem of supporting meetings between collaborators who are non-collocated, enabling meetings to transcend boundaries of space. In this paper, we explore the beginnings of a proposed solution for allowing meetings to transcend time as well. The need for such a solution is motivated by a user survey in which busy professionals are questioned about meetings they have either missed or forgotten the important details about after the fact. Our proposed solution allows these professionals to transcend time in a sense by revisiting a recorded meeting that has been structured for quick retrieval of sought information. Such a solution supports complete recovery of prior discussions, allowing needed information to be retrieved quickly, and thus potentially facilitating the effective continuation of discussions from the past. We evaluate the proposed solution with a formal user study in which we measure the impact of the proposed structural annotations on retrieval of information. The results of the study show that participants took significantly less time to retrieve the answers when they had access to discourse structure based annotation than in a control condition in which they had access only to unannotated video recordings (p {$<$} 0.01, effect size 0.94 standard deviations).},
  isbn = {978-3-540-31722-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/MM54KABY/Banerjee et al. - 2005 - The Necessity of a Meeting Recording and Playback .pdf}
}

@inproceedings{banerjeeSmartNotesImplicitLabeling2006,
  title = {{{SmartNotes}}: {{Implicit Labeling}} of {{Meeting Data}} through {{User Note-Taking}} and {{Browsing}}},
  shorttitle = {{{SmartNotes}}},
  booktitle = {Proceedings of the {{Human Language Technology Conference}} of the {{NAACL}}, {{Companion Volume}}: {{Demonstrations}}},
  author = {Banerjee, Satanjeev and Rudnicky, Alexander I.},
  date = {2006-06},
  pages = {261--264},
  publisher = {{Association for Computational Linguistics}},
  location = {{New York City, USA}},
  url = {https://aclanthology.org/N06-4003},
  urldate = {2023-06-05},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/MD5JF59Z/Banerjee and Rudnicky - 2006 - SmartNotes Implicit Labeling of Meeting Data thro.pdf}
}

@article{beersCommonGroundComplex2006,
  title = {Common {{Ground}}, {{Complex Problems}} and {{Decision Making}}},
  author = {Beers, Pieter J. and Boshuizen, Henny P. A. and Kirschner, Paul A. and Gijselaers, Wim H.},
  date = {2006-10-27},
  journaltitle = {Group Decision and Negotiation},
  shortjournal = {Group Decis Negot},
  volume = {15},
  number = {6},
  pages = {529--556},
  issn = {0926-2644, 1572-9907},
  doi = {10.1007/s10726-006-9030-1},
  url = {http://link.springer.com/10.1007/s10726-006-9030-1},
  urldate = {2022-08-07},
  abstract = {Organisations increasingly have to deal with complex problems. They often use multidisciplinary teams to cope with such problems where different team members have different perspectives on the problem, different individual knowledge and skills, and different approaches on how to solve the problem. In order to solve those problems, team members have to share their existing knowledge and construct new knowledge. Theory suggests that negotiation of common ground can positively affect team decision making on the solution of complex problems, by facilitating knowledge sharing across perspectives. In a small scale study with student groups, external representations supported by a specific negotiation ontology were used to facilitate negotiation by encouraging participants to make their beliefs and values explicit. Results showed that the external representations supported clarifying contributions to group members and increased group participation in discussions.},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/BLQ5PHL4/Beers et al. - 2006 - Common Ground, Complex Problems and Decision Makin.pdf}
}

@article{benkeTeamSpiritousRetrospectiveEmotional2022,
  title = {{{TeamSpiritous}} - {{A Retrospective Emotional Competence Development System}} for {{Video-Meetings}}},
  author = {Benke, Ivo and Schneider, Maren and Liu, Xuanhui and Maedche, Alexander},
  date = {2022-11-11},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {392:1--392:28},
  doi = {10.1145/3555117},
  url = {https://dl.acm.org/doi/10.1145/3555117},
  urldate = {2023-03-24},
  abstract = {Video-meetings essentially determine remote work life. However, video-meetings experience challenges originating from human emotions. Therefore, emotional competence, the ability to perceive, understand, and regulate emotions, is of the highest relevance. With limited transfer capacity of emotional information and various communication challenges, developing emotional competence, however, is complex. To overcome this complexity, we present TeamSpiritous, an individual, retrospective emotional competence development system for video-meetings. TeamSpiritous allows to upload and analyze recorded video-meetings on emotional processes and provides support for individual development of emotional competence. We evaluated TeamSpiritous quantitatively and qualitatively in a six-week, longitudinal field study with 47 participants from China and Germany. Results of our study show that intra- and interpersonal emotional competence significantly increased over time for the whole sample. In particular, intrapersonal emotion regulation and interpersonal emotion perception and understanding improved. Since remote work video-meetings are often multicultural, we also investigated cultural differences and observed in our results that the effects of TeamSpiritous exist beyond cultural backgrounds (China, Germany). With our work, we contribute with the design of TeamSpiritous and understanding of its effects on emotional competence development.},
  issue = {CSCW2},
  keywords = {����},
  file = {/Users/xinyuech/Zotero/storage/TZL4QNCB/Benke et al. - 2022 - TeamSpiritous - A Retrospective Emotional Competen.pdf}
}

@inproceedings{bergstromConversationClustersGrouping2009,
  title = {Conversation Clusters: Grouping Conversation Topics through Human-Computer Dialog},
  shorttitle = {Conversation Clusters},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Bergstrom, Tony and Karahalios, Karrie},
  date = {2009-04-04},
  pages = {2349--2352},
  publisher = {{ACM}},
  location = {{Boston MA USA}},
  doi = {10.1145/1518701.1519060},
  url = {https://dl.acm.org/doi/10.1145/1518701.1519060},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '09: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-246-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CDE7ZTHS/Bergstrom and Karahalios - 2009 - Conversation clusters grouping conversation topic.pdf}
}

@article{bilottaRemoteCommunicationCoronavirus2021,
  title = {Remote Communication amid the Coronavirus Pandemic: {{Optimizing}} Interpersonal Dynamics and Team Performance},
  shorttitle = {Remote Communication amid the Coronavirus Pandemic},
  author = {Bilotta, Isabel and Cheng, Shannon K. and Ng, Linnea C. and Corrington, Abby R. and Watson, Ivy and Paoletti, Jensine and Hebl, Mikki R. and King, Eden B.},
  date = {2021-06},
  journaltitle = {Industrial and Organizational Psychology},
  volume = {14},
  number = {1-2},
  pages = {36--40},
  publisher = {{Cambridge University Press}},
  issn = {1754-9426, 1754-9434},
  doi = {10.1017/iop.2021.10},
  url = {https://www.cambridge.org/core/journals/industrial-and-organizational-psychology/article/remote-communication-amid-the-coronavirus-pandemic-optimizing-interpersonal-dynamics-and-team-performance/0B7A1FF7BD2E5ED9028075573F643D0C},
  urldate = {2023-03-21},
  abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS1754942621000109/resource/name/firstPage-S1754942621000109a.jpg},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/QDGCCRL9/Bilotta et al. - 2021 - Remote communication amid the coronavirus pandemic.pdf}
}

@article{borgeLearningMonitorRegulate2018,
  title = {Learning to Monitor and Regulate Collective Thinking Processes},
  author = {Borge, Marcela and Ong, Yann Shiou and Rosé, Carolyn Penstein},
  date = {2018-03-01},
  journaltitle = {International Journal of Computer-Supported Collaborative Learning},
  shortjournal = {Intern. J. Comput.-Support. Collab. Learn},
  volume = {13},
  number = {1},
  pages = {61--92},
  issn = {1556-1615},
  doi = {10.1007/s11412-018-9270-5},
  url = {https://doi.org/10.1007/s11412-018-9270-5},
  urldate = {2023-05-08},
  abstract = {In this paper, we propose a conceptual framework to guide the design of a computer-supported collaborative learning intervention to help students learn how to improve collaborative knowledge building discourse at the level of the small group. The framework focuses on scripting individual and collective regulatory processes following collaboration. Individuals are required to evaluate their team’s chat transcripts against rubrics to score discussion quality. These theoretically supported rubrics provide individuals with~concrete examples of desired communication processes. After this individual assessment, the team is prompted to discuss their individual scores, identify strengths and weaknesses of their collaborative discourse processes, and select strategies to improve the quality of their collaborative discussion in a future discussion session. To evaluate our framework, we created a prototype of an online system and asked students to use it over ten weeks as part of five discussion sessions. Participants included 37 students, divided into 13 teams, from an undergraduate online course in information sciences. We used quantitative and qualitative analysis techniques to examine students’ collaborative processes over time, with teams as the main unit of analysis. All teams followed the same general activities, but there were two different conditions for scripting individual reflections that preceded the collective sense-making activity: one (Future-thinking) focused on pushing individuals to pay attention to advice on how to improve existing processes in future sessions and another (Evidence-Based) pushed individuals to pay closer attention to the chat transcripts to provide evidence for their group process scores. Our results suggest (1) use of the framework can help students’ monitor and regulate collaborative processes and improve collaborative discourse over time and (2) the Evidence-Based condition can help students engage in higher quality reflective analysis.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/JHU7VFEP/Borge et al. - 2018 - Learning to monitor and regulate collective thinki.pdf}
}

@article{bothinParticipantsPersonalNotetaking2012,
  title = {Participants’ Personal Note-Taking in Meetings and Its Value for Automatic Meeting Summarisation},
  author = {Bothin, Antje and Clough, Paul},
  date = {2012-03-01},
  journaltitle = {Information Technology and Management},
  shortjournal = {Inf Technol Manag},
  volume = {13},
  number = {1},
  pages = {39--57},
  issn = {1573-7667},
  doi = {10.1007/s10799-011-0112-7},
  url = {https://doi.org/10.1007/s10799-011-0112-7},
  urldate = {2023-04-21},
  abstract = {This paper reports the results of novel quantitative research on multiple people’s personal note-taking in meetings with the long-term aim of aiding the creation of innovative meeting understanding applications. We present three experiments using a large number of group meetings taken from the Augmented Multi-party Interaction meeting corpus. Statistical techniques were employed for this work. Our findings suggest that temporal note-taking overlap information and the semantic content of the written private notes taken by many meeting participants both point to the majority of the most informative meeting events. Thus, the characteristics of note-taking can be seen as a contributing feature for new automatic meeting summarisation approaches and for the development of future meeting browser environments that better support the needs of individuals and organisations.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/K2A9E6XW/Bothin and Clough - 2012 - Participants’ personal note-taking in meetings and.pdf}
}

@article{bothinUserEvaluationStudy2014,
  title = {A {{User Evaluation Study}}: {{Do Participants}}' {{Personal Notes Help Us}} to {{Summarise Meetings}}?},
  shorttitle = {A {{User Evaluation Study}}},
  author = {Bothin, Antje and Clough, Paul},
  date = {2014},
  journaltitle = {Knowledge and Process Management},
  volume = {21},
  number = {2},
  pages = {122--133},
  issn = {1099-1441},
  doi = {10.1002/kpm.1439},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/kpm.1439},
  urldate = {2023-06-05},
  abstract = {We describe a novel user evaluation study on the value of people's personal meeting notes for a question-answering task involving meeting data taken from the Augmented Multiparty Interaction (AMI) corpus. A survey on task perceptions and note-taking strategies in meetings was also conducted. The results suggest that written notes taken by multiple meeting participants contain the majority of the most informative meeting information and are thus likely to support information systems that employ automatic meeting understanding and summarisation. The users were able to achieve 79\% and 76\% accuracy in the task with handwritten and typed notes respectively as information source. Contrary to that, they scored 36\% accuracy only using short extracts from the meeting speech and 98\% correctness using abstractive human model summaries. The survey showed that people are generally very experienced with attending meetings and note-taking and usually record the most important meeting events in a concise way. This provides evidence for the fact that personal notes are suitable as keywords and indices into a meeting recording. In general, task results correlated positively with perceived success. Users liked well-structured abstractive human reference summaries but found meeting speech extracts difficult to work with. However, they also disliked the appearance of the notes, in particular the fact that the handwritten ones were hard to read. This emphasises the need for the development of innovative handwriting recognition methods and user interfaces that employ new presentation techniques, for example, key area highlighting. Meeting participants would also benefit from corporate training for better communication and note-taking skills. Copyright © 2014 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {notion}
}

@article{brown-schmidtMemoryCommonGround2016,
  title = {Memory and {{Common Ground Processes}} in {{Language Use}}},
  author = {Brown-Schmidt, Sarah and Duff, Melissa C.},
  date = {2016},
  journaltitle = {Topics in Cognitive Science},
  volume = {8},
  number = {4},
  pages = {722--736},
  issn = {1756-8765},
  doi = {10.1111/tops.12224},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12224},
  urldate = {2023-05-07},
  abstract = {During communication, we form assumptions about what our communication partners know and believe. Information that is mutually known between the discourse partners—their common ground—serves as a backdrop for successful communication. Here we present an introduction to the focus of this topic, which is the role of memory in common ground and language use. Two types of questions emerge as central to understanding the relationship between memory and common ground, specifically questions having to do with the representation of common ground in memory, and the use of common ground during language processing.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/WP8K7BRT/Brown-Schmidt and Duff - 2016 - Memory and Common Ground Processes in Language Use.pdf;/Users/xinyuech/Zotero/storage/NNB76HI2/tops.html}
}

@article{burlutskiyHowVisualiseConversation,
  title = {How to {{Visualise}} a {{Conversation}}: {{Case-Based Reasoning Approach}}},
  author = {Burlutskiy, Nikolay and Petridis, Miltos and Fish, Andrew and Ali, Nour},
  abstract = {At present, the complexity and scale of modern digital conversations between people is at its highest level but there is a gap in how to represent these conversations to a user. As a result, it is often hard for a user to understand the flow of a conversation and make an informed decision over it. However, an aesthetic and efficient visualisation can mitigate this drawback of data representation. In this paper, a case-based approach was proposed for choosing an appropriate visualisation for user’s conversations. A case was formulated as a visualisation of a conversation which a user decided to use for his analysis of the conversation. When a user decides to visualise a new conversation, the most similar visualisation type from previous users’ experiences is selected for the visualisation of the new conversation. In this paper, the cases of visualisations of conversations from the IBM Many Eyes platform were collected and a case-based reasoning approach for choosing a visualisation of user’s conversation was designed. Finally, the work of the proposed approach was tested on a sample email conversation, and then four participants evaluated the appropriateness of the chosen visualisation types in comparison with other eight possible visualisations for the email conversation.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/JV5W23BD/Burlutskiy et al. - How to Visualise a Conversation Case-Based Reason.pdf}
}

@article{caiUsingSemanticDiagram2016,
  title = {Using a Semantic Diagram to Structure a Collaborative Problem Solving Process in the Classroom},
  author = {Cai, Huiying and Lin, Lin and Gu, Xiaoqing},
  date = {2016-12-01},
  journaltitle = {Educational Technology Research and Development},
  shortjournal = {Education Tech Research Dev},
  volume = {64},
  number = {6},
  pages = {1207--1225},
  issn = {1556-6501},
  doi = {10.1007/s11423-016-9445-6},
  url = {https://doi.org/10.1007/s11423-016-9445-6},
  urldate = {2023-05-08},
  abstract = {This study provides an in-depth look into the implementation process of visualization-based tools for structuring collaborative problem solving (CPS) in the classroom. A visualization-based learning platform—the semantic diagram for structuring CPS in a real classroom was designed and implemented. Metafora, the preliminary vehicle of the semantic diagram, was integrated into the Food and Nutrition CPS curriculum in a fifth-grade science classroom in east China. Data of a teacher’s and her students’ activities from the CPS classroom were analyzed to understand how Metafora could be integrated into the CPS instructional process, what roles Metafora and the teacher played in the CPS project, and to what extent Metafora might have affected the teacher’s instruction and the students’ learning activities in the CPS classroom. Results showed that the semantic diagram could be integrated into the CPS classroom adaptively and flexibly, and that it was important to keep a balance between the role of the semantic diagram and the role of the teacher. Implications for semantic diagram design and implementation for structuring CPS in the classroom, as well as future work about the semantic diagram will be discussed.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/ZFARIE9L/Cai et al. - 2016 - Using a semantic diagram to structure a collaborat.pdf}
}

@article{callis-duehlMissedOpportunitiesScience2018,
  title = {Missed {{Opportunities}} for {{Science Learning}}: {{Unacknowledged Unscientific Arguments}} in {{Asynchronous Online}} and {{Face-to-Face Discussions}}},
  shorttitle = {Missed {{Opportunities}} for {{Science Learning}}},
  author = {Callis-Duehl, Kristine and Idsardi, Robert and Humphrey, Eve A. and Gougis, Rebekka Darner},
  date = {2018-02-01},
  journaltitle = {Journal of Science Education and Technology},
  shortjournal = {J Sci Educ Technol},
  volume = {27},
  number = {1},
  pages = {86--98},
  issn = {1573-1839},
  doi = {10.1007/s10956-017-9710-4},
  url = {https://doi.org/10.1007/s10956-017-9710-4},
  urldate = {2023-03-15},
  abstract = {We explored the scientific argumentation that occurs among university biology students during an argumentation task implemented in two environments: face-to-face in a classroom and online in an asynchronous discussion. We observed 10 student groups, each composed of three students. Our analysis focused on how students respond to their peers’ unscientific arguments, which we define as assertions, hypotheses, propositions, or explanations that are inaccurate or incomplete from a scientific perspective. Unscientific arguments provide opportunities for productive dissent, scientific argumentation, and conceptual development of scientifically desirable conceptions. We found that students did not respond to the majority of unscientific arguments in both environments. Challenges to unscientific arguments were expressed as a question or through explanation, although the latter was more common online than face-to-face. Students demonstrated significantly more epistemic distancing in the face-to-face environment than the online environment. We discuss the differences in discourse observed in both environments and teaching implications. We also provide direction for future research seeking to address the challenges of engaging students in productive scientific argumentation in both face-to-face and online environments.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/KRY9YKW8/Callis-Duehl et al. - 2018 - Missed Opportunities for Science Learning Unackno.pdf}
}

@online{CanGraphicalInteraction,
  title = {Can {{Graphical Interaction Increase Feelings}} of {{Conveying}} and {{Understanding}} in {{On-Line Group Discussion}}?},
  doi = {10.9746/jcmsi.11.55},
  url = {https://www.tandfonline.com/doi/epdf/10.9746/jcmsi.11.55?needAccess=true&role=button},
  urldate = {2023-06-02},
  langid = {english},
  keywords = {notion}
}

@inproceedings{caoDataParticlesBlockbasedLanguageoriented2023,
  title = {{{DataParticles}}: {{Block-based}} and {{Language-oriented Authoring}} of {{Animated Unit Visualizations}}},
  shorttitle = {{{DataParticles}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Cao, Yining and E, Jane L and Chen, Zhutian and Xia, Haijun},
  date = {2023-04-19},
  pages = {1--15},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581472},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581472},
  urldate = {2023-05-03},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion,������},
  file = {/Users/xinyuech/Zotero/storage/QRHR5NUW/Cao et al. - 2023 - DataParticles Block-based and Language-oriented A.pdf}
}

@book{carrollHCIModelsTheories2003,
  title = {{{HCI Models}}, {{Theories}}, and {{Frameworks}}: {{Toward}} a {{Multidisciplinary Science}}},
  shorttitle = {{{HCI Models}}, {{Theories}}, and {{Frameworks}}},
  author = {Carroll, John M.},
  date = {2003-05-21},
  eprint = {gGyEOjkdpbYC},
  eprinttype = {googlebooks},
  publisher = {{Elsevier}},
  abstract = {HCI Models, Theories, and Frameworks provides a thorough pedagological survey of the science of Human-Computer Interaction (HCI). HCI spans many disciplines and professions, including anthropology, cognitive psychology, computer graphics, graphical design, human factors engineering, interaction design, sociology, and software engineering. While many books and courses now address HCI technology and application areas, none has addressed HCI’s multidisciplinary foundations with much scope or depth. This text fills a huge void in the university education and training of HCI students as well as in the lifelong learning and professional development of HCI practitioners. Contributors are leading researchers in the field of HCI. If you teach a second course in HCI, you should consider this book. This book provides a comprehensive understanding of the HCI concepts and methods in use today, presenting enough comparative detail to make primary sources more accessible. Chapters are formatted to facilitate comparisons among the various HCI models. Each chapter focuses on a different level of scientific analysis or approach, but all in an identical format, facilitating comparison and contrast of the various HCI models. Each approach is described in terms of its roots, motivation, and type of HCI problems it typically addresses. The approach is then compared with its nearest neighbors, illustrated in a paradigmatic application, and analyzed in terms of its future. This book is essential reading for professionals, educators, and students in HCI who want to gain a better understanding of the theoretical bases of HCI, and who will make use of a good background, refresher, reference to the field and/or index to the literature. Contributors are leading researchers in the field of Human-Comptuter Interaction  Fills a major gap in current literature about the rich scientific foundations of HCI  Provides a thorough pedogological survey of the science of HCI},
  isbn = {978-0-08-049141-7},
  langid = {english},
  pagetotal = {579},
  keywords = {notion}
}

@inproceedings{chanComparingDifferentSensemaking2016,
  title = {Comparing {{Different Sensemaking Approaches}} for {{Large-Scale Ideation}}},
  booktitle = {Proceedings of the 2016 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chan, Joel and Dang, Steven and Dow, Steven P.},
  date = {2016-05-07},
  series = {{{CHI}} '16},
  pages = {2717--2728},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2858036.2858178},
  url = {https://dl.acm.org/doi/10.1145/2858036.2858178},
  urldate = {2023-03-20},
  abstract = {大型创意生成平台经常让思想家接触到以前的想法。然而，研究表明，如果人们看到抽象的解决方案路径（例如，通过人类意义构建生成的解决方案方法的描述），而不是被所有先前的想法所淹没，他们就会产生更好的想法。自动化和半自动化方法也可以提供对早期想法的解释。为了在资源有限的情况下从实践中的意义构建中受益，构思平台开发人员需要权衡不同方法的成本质量权衡，以呈现解决方案路径。为了探索这一点，我们进行了一项在线研究，其中245名参与者在以下五个条件之一中为两个问题产生了想法：1）没有刺激，2）接触所有先前的想法，或使用3）全自动工作流程从先前的想法中提取的解决方案路径，4）混合人机方法，以及5）完全手动的方法。与预期相反，人类生成的路径并没有通过简单地展示所有想法来改善构思（正如构思的流畅性和广度所衡量的那样）。机器生成的路径有时会显着提高构思的流畅性和广度，而不是没有想法（尽管以一些想法质量为代价）。这些发现表明，自动意义构建可以改善想法的产生，但我们需要更多的研究来了解人类意义构建对群体构思的价值。},
  isbn = {978-1-4503-3362-7},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/5GV3IJ7F/Chan et al. - 2016 - Comparing Different Sensemaking Approaches for Lar.pdf}
}

@inproceedings{chanConceptualDistanceMatters2014,
  title = {Conceptual Distance Matters When Building on Others' Ideas in Crowd-Collaborative Innovation Platforms},
  booktitle = {Proceedings of the Companion Publication of the 17th {{ACM}} Conference on {{Computer}} Supported Cooperative Work \& Social Computing},
  author = {Chan, Joel and Dow, Steven and Schunn, Christian},
  date = {2014-02-15},
  series = {{{CSCW Companion}} '14},
  pages = {141--144},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2556420.2556500},
  url = {https://doi.org/10.1145/2556420.2556500},
  urldate = {2023-03-14},
  abstract = {在人群协同创新平台中，其他贡献者的想法可以作为创意的灵感来源，但与他人的想法互动的哪些模式最有帮助？我们调查了这样一个假设，即建立在概念上远离目标领域的灵感来源是最有帮助的，这是一个具有混合经验支持的流行假设。我们根据引用源与目标域的概念距离（使用想法的概率主题建模来衡量），预测基于 Web 的协作创新平台中 12 种不同设计挑战的 2,344 个想法的成功率。令人惊讶的是，我们发现在概念上引用近源灵感的创新者比那些喜欢远源的创新者获得更高的成功率。},
  isbn = {978-1-4503-2541-7},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/7SBSET34/Chan et al. - 2014 - Conceptual distance matters when building on other.pdf}
}

@thesis{chenAssociationReflectionStimulation2021,
  type = {Thesis},
  title = {Association, {{Reflection}}, {{Stimulation}}: {{Problem Exploration}} in {{Early Design}} through {{AI-Augmented Mind-Mapping}}},
  shorttitle = {Association, {{Reflection}}, {{Stimulation}}},
  author = {Chen, Ting-Ju},
  date = {2021-07-26},
  url = {https://oaktrust.library.tamu.edu/handle/1969.1/195385},
  urldate = {2023-03-16},
  abstract = {The formulation of a problem is often more essential than its solution, which may be merely a matter of mathematical or experimental skill. To raise new questions, new possibilities, to regard old problems from a new angle requires creative imagination and marks real advances in science. - Albert Einstein This dissertation aims at developing a computational framework to support the process of problem exploration in early design. To do so, we investigate digital mind-mapping as a tool for problem exploration and develop new algorithms and interaction workflows by leveraging large knowledge databases. The central premise of this work is that channeling the designer's thinking process through intelligent stimulation using such databases can augment designers' ability to reason about the problem at hand and creatively synthesize new ideas to address the problem. Design problems are typically ambiguous, ill-defined, unstructured, and open-ended. Therefore, learning about the problem and exploration of the problem domain is critical in early design to build a well-developed understanding of the context toward fruitful solution exploration in design. Despite the importance of problem understanding in design, little research has been devoted to investigating problem exploration activities in-depth and drawing a clear connection on the effects of such activities on the resulting design outcomes. Most current efforts focus exclusively on implementing methods for ideation, conceptualization, and concept evaluation wherein the solution space takes prominence. In this regard, this dissertation aims to complement this with a study of problem exploration techniques (mind-mapping and free writing) and evaluation in early design. We highlight the importance of problem-based exploration and learning, and share insights on how the structure and associative capability afforded by mind-maps affect ideation on the problem statement, product opportunity gap, and the needs around a given design context. It is common for designers to tend to commit to solutions too early and limit the potential of discovering creative and novel ideas in early design. This tendency is further pronounced with the advent of several digital design tools that are feature-rich and focus on design conceptualization and solution formulation, rather than design problem exploration. Additionally, much of the research in design theory and methodology has also mostly focused on conceptualization techniques such as C-Sketch and morphological matrix, that aim to support the formation of new solution concepts through modification and re-interpretation of rough initial ones. To complement these, in this dissertation, we emphasize the importance of problem exploration and brainstorming tasks towards design opportunity identification during early design. This is studied with the use of mind-maps, a technique that helps designers express their thoughts by making connections or associations between ideas around a given context. Further, we propose novel human-computer collaborative mind-mapping workflows for enhancing design experiences through novel textual, verbal and visual computer supports. Specifically, we designed and implemented two cognitive support mechanisms to help designers in inspecting design problems and generating ideas. Human-subject studies were conducted to examine how these systems perform and user perception. Based on the extensive investigation, this dissertation further shares insights on how to promote reflection in problem exploration by stimulating association across ideas, and develops design implications for intelligent AI-augmented workflows during early design exploratory tasks.},
  langid = {english},
  keywords = {！！！,notion},
  annotation = {Accepted: 2022-01-27T22:18:02Z},
  file = {/Users/xinyuech/Zotero/storage/SD9LXK7W/Chen - 2021 - Association, Reflection, Stimulation Problem Expl.pdf}
}

@inproceedings{chenCognitionorientedFacilitationGuidelines2023,
  title = {Cognition-Oriented {{Facilitation}} and {{Guidelines}} for {{Collaborative Problem-solving Online}} and {{Face-to-face}}: {{An}} in-Depth Examination of Format and Facilitation Influence on Problem-Solving Performance},
  shorttitle = {Cognition-Oriented {{Facilitation}} and {{Guidelines}} for {{Collaborative Problem-solving Online}} and {{Face-to-face}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chen, Yingting and Kanno, Taro and Furuta, Kazuo},
  date = {2023-04-19},
  pages = {1--15},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581112},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581112},
  urldate = {2023-04-24},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/THPQEF6N/Chen et al. - 2023 - Cognition-oriented Facilitation and Guidelines for.pdf}
}

@inproceedings{chenCollaborativeMindMappingStudy2019,
  title = {Collaborative Mind-Mapping: A Study of Patterns, Strategies, and Evolution of Maps Created by Peer-Pairs},
  shorttitle = {Collaborative Mind-Mapping},
  author = {Chen, Ting-Ju and Mohanty, Ronak R. and Hoffmann Rodriguez, Miguel A. and Krishnamurthy, Vinayak R.},
  date = {2019-11-25},
  publisher = {{American Society of Mechanical Engineers Digital Collection}},
  doi = {10.1115/DETC2019-98125},
  url = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-abstract/IDETC-CIE2019/59278/1070194},
  urldate = {2023-03-16},
  abstract = {Abstract. We present a study on collaborative mind-mapping to understand how peers collaborate in pairs to create mind-maps, how the maps evolve over time, and how collaboration changes between the peer-pair across multiple maps. Mind-mapping is an important tool that is studied and taught in design practice and research respectively. While widely used as a brainstorming technique, the collaborative aspects of mind-mapping are little understood in comparison to other ideation methods such as concept sketching etc. In addition to presenting creativity ratings on the outcome (i.e. the mind-map), we extensively report on the patterns of collaborative exploration, strategies that emerge from the collaborators, inhibition, and the overall process of map creation. We discuss the implications of these observations on the development of computer-support for mind-mapping.},
  eventtitle = {ASME 2019 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  langid = {chinese},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/TM4TYPRU/Chen et al. - 2019 - Collaborative Mind-Mapping A Study of Patterns, S.pdf}
}

@inproceedings{chenQCueQueriesCues2022,
  title = {QCue: Queries and Cues for Computer-Facilitated Mind-Mapping},
  shorttitle = {QCue},
  author = {Chen, Ting-Ju and Subramanian, Sai Ganesh and Krishnamurthy, Vinayak R.},
  date = {2022-07-08},
  url = {https://openreview.net/forum?id=r5vnRRwrgX},
  urldate = {2023-03-16},
  abstract = {We introduce a novel workflow, QCue, for providing textual stimulation during mind-mapping. Mind-mapping is a powerful tool whose intent is to allow one to externalize ideas and their relationships surrounding a central problem. The key challenge in mind-mapping is the difficulty in balancing the exploration of different aspects of the problem (breadth) with a detailed exploration of each of those aspects (depth). Our idea behind QCue is based on two mechanisms: (1) computer-generated automatic cues to stimulate the user to explore the breadth of topics based on the temporal and topological evolution of a mind-map and (2) user-elicited queries for helping the user explore the depth for a given topic. We present a two-phase study wherein the first phase provided insights that led to the development of our work-flow for stimulating the user through cues and queries. In the second phase, we present a between-subjects evaluation comparing QCue with a digital mind-mapping work-flow without computer intervention. Finally, we present an expert rater evaluation of the mind-maps created by users in conjunction with user feedback.},
  eventtitle = {Graphics Interface 2020},
  langid = {chinese},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/RW7UAPXU/Chen et al. - 2022 - QCue Queries and Cues for Computer-Facilitated Mi.pdf}
}
@article{mahyar2012note,
  title={Note-taking in co-located collaborative visual analytics: Analysis of an observational study},
  author={Mahyar, Narges and Sarvghad, Ali and Tory, Melanie},
  journal={Information Visualization},
  volume={11},
  number={3},
  pages={190--204},
  year={2012},
  publisher={Sage Publications Sage UK: London, England}
}
@article{bostrom1993group,
  title={Group facilitation and group support systems},
  author={Bostrom, Robert P and Anson, Robert and Clawson, Vikki K},
  journal={Group support systems: New perspectives},
  volume={8},
  pages={146--168},
  year={1993},
  publisher={Macmillan New York}
}

@article{choEffectsCommunicationOrientedOverload2019,
  title = {Effects of {{Communication-Oriented Overload}} in {{Mobile Instant Messaging}} on {{Role Stressors}}, {{Burnout}}, and {{Turnover Intention}} in the {{Workplace}}},
  author = {Cho, Jaehee and Lee, H. Erin and Kim, Haeyeon},
  date = {2019-04-14},
  journaltitle = {International Journal of Communication},
  volume = {13},
  number = {0},
  pages = {21},
  issn = {1932-8036},
  url = {https://ijoc.org/index.php/ijoc/article/view/9290},
  urldate = {2023-03-21},
  abstract = {This study aimed at developing and testing a model that can explain how overload perceived in relation to organizational use of mobile instant messaging services (MIMs) leads to burnout and turnover intention in employees through the mediating effect of role-oriented stressors such as role ambiguity and role conflict. To empirically test the model, an online survey was conducted with 434 office workers in South Korea who used KakaoTalk for organizational purposes. Overload in KakaoTalk use was measured in three dimensions: information, communication, and system feature overload. Path analysis results showed that information overload and system feature overload significantly increased role ambiguity and role conflict, which ultimately led to significant increases in burnout (in the form of emotional exhaustion and reduced personal achievement) and turnover intention.},
  issue = {0},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XKTDE2JT/Cho et al. - 2019 - Effects of Communication-Oriented Overload in Mobi.pdf}
}

@article{comanCommunicationGroupCognitive2019,
  title = {Communication and {{Group Cognitive Complexity}}},
  author = {Coman, Andra Diana and Curșeu, Petru Lucian and Fodor, Oana Cătălina and Oțoiu, Cătălina and Rațiu, Lucia and Fleștea, Alina Maria and Bria, Mara},
  date = {2019-08-01},
  journaltitle = {Small Group Research},
  volume = {50},
  number = {4},
  pages = {539--568},
  publisher = {{SAGE Publications Inc}},
  issn = {1046-4964},
  doi = {10.1177/1046496419853624},
  url = {https://doi.org/10.1177/1046496419853624},
  urldate = {2023-03-21},
  abstract = {This study explores the effects of group size, group composition, and group argument frequency on group cognitive complexity (GCC). We evaluated a sample of 509 students organized into 106 groups who participated in a group cognitive mapping activity. As hypothesized, we found that group argumentation has an inverted U-shaped association with GCC. Group member familiarity did not moderate this relationship. We also found that task-related arguments mediate the relationships between group size and gender diversity on one hand, and GCC, on the other. Moreover, we found that optimal group-level cognitive benefits were observed in group discussions in which the ratio between task-related and nontask-related group arguments was 3 to 1. The discussion focuses on the practical and theoretical implications of these findings.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CC43A9AR/Coman et al. - 2019 - Communication and Group Cognitive Complexity.pdf}
}

@incollection{conklinDialogMappingReflections2003,
  title = {Dialog {{Mapping}}: {{Reflections}} on an {{Industrial Strength Case Study}}},
  shorttitle = {Dialog {{Mapping}}},
  booktitle = {Visualizing {{Argumentation}}: {{Software Tools}} for {{Collaborative}} and {{Educational Sense-Making}}},
  author = {Conklin, Jeff},
  editor = {Kirschner, Paul A. and Buckingham Shum, Simon J. and Carr, Chad S.},
  date = {2003},
  series = {CSCW},
  pages = {117--136},
  publisher = {{Springer}},
  location = {{London}},
  doi = {10.1007/978-1-4471-0037-9_6},
  url = {https://doi.org/10.1007/978-1-4471-0037-9_6},
  urldate = {2023-08-21},
  abstract = {Earlier chapters have introduced the notion of “wicked problems” and the Issue Based Information System (IBIS) framework (Buckingham Shum, Chapter 1, van Bruggen Chapter 2), both of which derive from the work of Horst Rittel. Selvin (Chapter 7) proposes a generic framework for facilitated Computer Supported Argument Visualization (CSAV), and reports on case studies using the IBIS-based Compendium approach. Compendium itself is based on a facilitated CSAV approach called Dialog Mapping, the focus of this chapter. We begin by elaborating on the art and process of Dialog Mapping, before reporting on a particular business application, probably the longest-term case study available of CSAV adoption in an organization},
  isbn = {978-1-4471-0037-9},
  langid = {english},
  keywords = {/unread,notion,共享显示,参考节点,异步模式,论证知识,邪恶的问题},
  file = {/Users/xinyuech/Zotero/storage/IX9PWYEF/Conklin - 2003 - Dialog Mapping Reflections on an Industrial Stren.pdf}
}

@inproceedings{convertinoArticulatingCommonGround2008,
  title = {Articulating Common Ground in Cooperative Work: Content and Process},
  shorttitle = {Articulating Common Ground in Cooperative Work},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Convertino, Gregorio and Mentis, Helena M. and Rosson, Mary Beth and Carroll, John M. and Slavkovic, Aleksandra and Ganoe, Craig H.},
  date = {2008-04-06},
  pages = {1637--1646},
  publisher = {{ACM}},
  location = {{Florence Italy}},
  doi = {10.1145/1357054.1357310},
  url = {https://dl.acm.org/doi/10.1145/1357054.1357310},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '08: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-011-1},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/HANR3RW8/Convertino et al. - 2008 - Articulating common ground in cooperative work co.pdf}
}

@article{cookeInteractiveTeamCognition2013,
  title = {Interactive {{Team Cognition}}},
  author = {Cooke, Nancy J. and Gorman, Jamie C. and Myers, Christopher W. and Duran, Jasmine L.},
  date = {2013},
  journaltitle = {Cognitive Science},
  volume = {37},
  number = {2},
  pages = {255--285},
  issn = {1551-6709},
  doi = {10.1111/cogs.12009},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12009},
  urldate = {2023-03-15},
  abstract = {Cognition in work teams has been predominantly understood and explained in terms of shared cognition with a focus on the similarity of static knowledge structures across individual team members. Inspired by the current zeitgeist in cognitive science, as well as by empirical data and pragmatic concerns, we offer an alternative theory of team cognition. Interactive Team Cognition (ITC) theory posits that (1) team cognition is an activity, not a property or a product; (2) team cognition should be measured and studied at the team level; and (3) team cognition is inextricably tied to context. There are implications of ITC for theory building, modeling, measurement, and applications that make teams more effective performers.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/N4YDSHJ4/Cooke et al. - 2013 - Interactive Team Cognition.pdf}
}

@article{deweverContentAnalysisSchemes2006,
  title = {Content Analysis Schemes to Analyze Transcripts of Online Asynchronous Discussion Groups: {{A}} Review},
  shorttitle = {Content Analysis Schemes to Analyze Transcripts of Online Asynchronous Discussion Groups},
  author = {De Wever, B. and Schellens, T. and Valcke, M. and Van Keer, H.},
  date = {2006-01-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  series = {Methodological {{Issues}} in {{Researching CSCL}}},
  volume = {46},
  number = {1},
  pages = {6--28},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2005.04.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131505000552},
  urldate = {2023-05-10},
  abstract = {Research in the field of Computer Supported Collaborative Learning (CSCL) is based on a wide variety of methodologies. In this paper, we focus upon content analysis, which is a technique often used to analyze transcripts of asynchronous, computer mediated discussion groups in formal educational settings. Although this research technique is often used, standards are not yet established. The applied instruments reflect a wide variety of approaches and differ in their level of detail and the type of analysis categories used. Further differences are related to a diversity in their theoretical base, the amount of information about validity and reliability, and the choice for the unit of analysis. This article presents an overview of different content analysis instruments, building on a sample of models commonly used in the CSCL-literature. The discussion of 15 instruments results in a number of critical conclusions. There are questions about the coherence between the theoretical base and the operational translation of the theory in the instruments. Instruments are hardly compared or contrasted with one another. As a consequence the empirical base of the validity of the instruments is limited. The analysis is rather critical when it comes to the issue of reliability. The authors put forward the need to improve the theoretical and empirical base of the existing instruments in order to promote the overall quality of CSCL-research.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4ALEEBHQ/S0360131505000552.html}
}

@inproceedings{difedeIdeaMachineLLMbased2022,
  title = {The {{Idea Machine}}: {{LLM-based Expansion}}, {{Rewriting}}, {{Combination}}, and {{Suggestion}} of {{Ideas}}},
  shorttitle = {The {{Idea Machine}}},
  booktitle = {Creativity and {{Cognition}}},
  author = {Di Fede, Giulia and Rocchesso, Davide and Dow, Steven P. and Andolina, Salvatore},
  date = {2022-06-20},
  series = {C\&amp;{{C}} '22},
  pages = {623--627},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3527927.3535197},
  url = {https://doi.org/10.1145/3527927.3535197},
  urldate = {2023-03-14},
  abstract = {我们介绍了 Idea Machine，这是一种创造力支持工具，它利用大型语言模型 (LLM) 为从事创意生成任务的人们提供支持。该工具包括许多可用于实现各种级别的自动化和智能支持的功能。输入系统的每个想法都可以扩展、重写或与其他想法或概念相结合。还可以开启点子建议模式，让系统主动提出点子。},
  isbn = {978-1-4503-9327-0},
  keywords = {notion}
}

@article{doErrAIImperfect2023a,
  title = {To {{Err}} Is {{AI}}: {{Imperfect Interventions}} and {{Repair}} in a {{Conversational Agent Facilitating Group Chat Discussions}}},
  shorttitle = {To {{Err}} Is {{AI}}},
  author = {Do, Hyo Jin and Kong, Ha-Kyung and Tetali, Pooja and Lee, Jaewook and Bailey, Brian P.},
  date = {2023-04-16},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {7},
  pages = {99:1--99:23},
  doi = {10.1145/3579532},
  url = {https://dl.acm.org/doi/10.1145/3579532},
  urldate = {2023-08-16},
  abstract = {Conversational agents (CAs) can analyze online conversations using natural language techniques and effectively facilitate group discussions by sending supervisory messages. However, if a CA makes imperfect interventions, users may stop trusting the CA and discontinue using it. In this study, we demonstrate how inaccurate interventions of a CA and a conversational repair strategy can influence user acceptance of the CA, members' participation in the discussion, perceived discussion experience between the members, and group performance. We built a CA that encourages the participation of members with low contributions in an online chat discussion in which a small group (3-6 members) performs a decision-making task. Two types of errors can occur when detecting under-contributing members: 1) false-positive (FP) errors happen when the CA falsely identifies a member as under-contributing and 2) false-negative (FN) errors occur when the CA misses detecting an under-contributing member. We designed a conversational repair strategy that gives users a chance to contest the detection results and the agent sends a correctional message if an error is detected. Through an online study with 175 participants, we found that participants who received FN error messages reported higher acceptance of the CA and better discussion experience, but participated less compared to those who received FP error messages. The conversational repair strategy moderated the effect of errors such as improving the perceived discussion experience of participants who received FP error messages. Based on our findings, we offer design implications for which model should be selected by practitioners between high precision (i.e., fewer FP errors) and high recall (i.e., fewer FN errors) models depending on the desired effects. When frequent FP errors are expected, we suggest using the conversational repair strategy to improve the perceived discussion experience.},
  issue = {CSCW1},
  keywords = {/unread,collaborative task,conversational agent,group discussion,participation,user acceptance},
  file = {/Users/xinyuech/Zotero/storage/VKX5PNZW/Do et al. - 2023 - To Err is AI Imperfect Interventions and Repair i.pdf}
}

@inproceedings{dongOnePieceTime2012,
  title = {One Piece at a Time: Why Video-Based Communication Is Better for Negotiation and Conflict Resolution},
  shorttitle = {One Piece at a Time},
  booktitle = {Proceedings of the {{ACM}} 2012 Conference on {{Computer Supported Cooperative Work}}},
  author = {Dong, Wei and Fu, Wai-Tat},
  date = {2012-02-11},
  series = {{{CSCW}} '12},
  pages = {167--176},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2145204.2145232},
  url = {https://dl.acm.org/doi/10.1145/2145204.2145232},
  urldate = {2023-03-22},
  isbn = {978-1-4503-1086-4},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CFCD7A7M/Dong and Fu - 2012 - One piece at a time why video-based communication.pdf}
}

@article{duboviEmpiricalAnalysisKnowledge2020,
  title = {An Empirical Analysis of Knowledge Co-Construction in {{YouTube}} Comments},
  author = {Dubovi, Ilana and Tabak, Iris},
  date = {2020-10-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {156},
  pages = {103939},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2020.103939},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131520301378},
  urldate = {2023-05-08},
  abstract = {Internet and social media platforms such as YouTube are an emblem of information on demand, but, their educative value, especially for conceptually rich domains, such as science, remains unclear. Many people perceive YouTube as a good resource for learning about science, yet viewing many of the available videos can be akin to learning through transmission models, which are considered inferior when they are the sole form of instruction. The goal of this study was to examine whether YouTube's embedded feature of posting (post-video) comments could mitigate these limitations, and offer a potential educative added-value by opening opportunities for discussion and deliberation, which have been associated with deeper learning. Focusing on Science as a target domain, we examined 1530 post-video public comments from a corpus of leading science channels. We coded the comments for argumentative and knowledge construction moves, and tested whether particular moves led to higher-level knowledge construction. Our findings reveal that this informal setting reflected comments that went beyond information sharing to argumentative negotiation, reaching a higher level of knowledge construction, and yielding a greater proportion of such comments that have been found in previous studies within formal settings. This study demonstrates that YouTube can offer an informal space for science deliberation and a forum for collaborative interactions that have a potential to support life-long learning. Implications for future research are discussed.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/3WAUG52T/Dubovi and Tabak - 2020 - An empirical analysis of knowledge co-construction.pdf;/Users/xinyuech/Zotero/storage/KNZSBMVQ/S0360131520301378.html}
}

@inproceedings{duRapsaiAcceleratingMachine2023,
  title = {Rapsai: {{Accelerating Machine Learning Prototyping}} of {{Multimedia Applications}} through {{Visual Programming}}},
  shorttitle = {Rapsai},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Du, Ruofei and Li, Na and Jin, Jing and Carney, Michelle and Miles, Scott and Kleiner, Maria and Yuan, Xiuxiu and Zhang, Yinda and Kulkarni, Anuva and Liu, Xingyu and Sabie, Ahmed and Orts-Escolano, Sergio and Kar, Abhishek and Yu, Ping and Iyengar, Ram and Kowdle, Adarsh and Olwal, Alex},
  date = {2023-04-19},
  pages = {1--23},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581338},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581338},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/HWC2JAT9/Du et al. - 2023 - Rapsai Accelerating Machine Learning Prototyping .pdf}
}

@inproceedings{ehlenMeetingAdjournedOffline2008,
  title = {Meeting Adjourned: Off-Line Learning Interfaces for Automatic Meeting Understanding},
  shorttitle = {Meeting Adjourned},
  booktitle = {Proceedings of the 13th International Conference on {{Intelligent}} User Interfaces},
  author = {Ehlen, Patrick and Purver, Matthew and Niekrasz, John and Lee, Kari and Peters, Stanley},
  date = {2008-01-13},
  pages = {276--284},
  publisher = {{ACM}},
  location = {{Gran Canaria Spain}},
  doi = {10.1145/1378773.1378810},
  url = {https://dl.acm.org/doi/10.1145/1378773.1378810},
  urldate = {2023-04-21},
  eventtitle = {{{IUI08}}: 13th {{International Conference}} on {{Intelligent User Interfaces}}},
  isbn = {978-1-59593-987-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/V9REX7RJ/Ehlen et al. - 2008 - Meeting adjourned off-line learning interfaces fo.pdf}
}

@article{el-assadyDiscourseMapsFeature,
  title = {Discourse {{Maps}} — {{Feature Encoding}} for the {{Analysis}} of {{Verbatim Conversation Transcripts}}},
  author = {El-Assady, Mennatallah},
  pages = {31},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/GYFMP5LW/El-Assady - Discourse Maps — Feature Encoding for the Analysis.pdf}
}

@article{el-assadyThreadReconstructorModelingReplyChains2018,
  title = {{{ThreadReconstructor}}: {{Modeling Reply-Chains}} to {{Untangle Conversational Text}} through {{Visual Analytics}}},
  shorttitle = {{{ThreadReconstructor}}},
  author = {El-Assady, Mennatallah and Sevastjanova, Rita and Keim, Daniel and Collins, Christopher},
  date = {2018},
  journaltitle = {Computer Graphics Forum},
  volume = {37},
  number = {3},
  pages = {351--365},
  issn = {1467-8659},
  doi = {10.1111/cgf.13425},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13425},
  urldate = {2023-03-22},
  abstract = {We present ThreadReconstructor, a visual analytics approach for detecting and analyzing the implicit conversational structure of discussions, e.g., in political debates and forums. Our work is motivated by the need to reveal and understand single threads in massive online conversations and verbatim text transcripts. We combine supervised and unsupervised machine learning models to generate a basic structure that is enriched by user-defined queries and rule-based heuristics. Depending on the data and tasks, users can modify and create various reconstruction models that are presented and compared in the visualization interface. Our tool enables the exploration of the generated threaded structures and the analysis of the untangled reply-chains, comparing different models and their agreement. To understand the inner-workings of the models, we visualize their decision spaces, including all considered candidate relations. In addition to a quantitative evaluation, we report qualitative feedback from an expert user study with four forum moderators and one machine learning expert, showing the effectiveness of our approach.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/PV4AMY9D/El-Assady et al. - 2018 - ThreadReconstructor Modeling Reply-Chains to Unta.pdf;/Users/xinyuech/Zotero/storage/DDU87IDQ/cgf.html}
}

@inproceedings{ezen-canClassifyingStudentDialogue2015,
  title = {Classifying Student Dialogue Acts with Multimodal Learning Analytics},
  booktitle = {Proceedings of the {{Fifth International Conference}} on {{Learning Analytics And Knowledge}}},
  author = {Ezen-Can, Aysu and Grafsgaard, Joseph F. and Lester, James C. and Boyer, Kristy Elizabeth},
  date = {2015-03-16},
  series = {{{LAK}} '15},
  pages = {280--289},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2723576.2723588},
  url = {https://dl.acm.org/doi/10.1145/2723576.2723588},
  urldate = {2023-04-24},
  abstract = {Supporting learning with rich natural language dialogue has been the focus of increasing attention in recent years. Many adaptive learning environments model students' natural language input, and there is growing recognition that these systems can be improved by leveraging multimodal cues to understand learners better. This paper investigates multimodal features related to posture and gesture for the task of classifying students' dialogue acts within tutorial dialogue. In order to accelerate the modeling process by eliminating the manual annotation bottleneck, a fully unsupervised machine learning approach is utilized for this task. The results indicate that these unsupervised models are significantly improved with the addition of automatically extracted posture and gesture information. Further, even in the absence of any linguistic features, a model that utilizes posture and gesture features alone performed significantly better than a majority class baseline. This work represents a step toward achieving better understanding of student utterances by incorporating multimodal features within adaptive learning environments. Additionally, the technique presented here is scalable to very large student datasets.},
  isbn = {978-1-4503-3417-4},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/24YFXLAQ/Ezen-Can et al. - 2015 - Classifying student dialogue acts with multimodal .pdf}
}

@inproceedings{faridaniOpinionSpaceScalable2010,
  title = {Opinion Space: A Scalable Tool for Browsing Online Comments},
  shorttitle = {Opinion Space},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Faridani, Siamak and Bitton, Ephrat and Ryokai, Kimiko and Goldberg, Ken},
  date = {2010-04-10},
  pages = {1175--1184},
  publisher = {{ACM}},
  location = {{Atlanta Georgia USA}},
  doi = {10.1145/1753326.1753502},
  url = {https://dl.acm.org/doi/10.1145/1753326.1753502},
  urldate = {2023-05-08},
  eventtitle = {{{CHI}} '10: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-929-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/MPNWCDAG/Faridani et al. - 2010 - Opinion space a scalable tool for browsing online.pdf}
}

@article{francaSystematizingImpactsProjection2020,
  title = {Systematizing the Impacts Projection of Complex Decisions in Work Groups},
  author = {França, Juliana B. S. and Borges, Marcos R. S.},
  date = {2020-06-25},
  journaltitle = {SN Applied Sciences},
  shortjournal = {SN Appl. Sci.},
  volume = {2},
  number = {7},
  pages = {1287},
  issn = {2523-3971},
  doi = {10.1007/s42452-020-3086-4},
  url = {https://doi.org/10.1007/s42452-020-3086-4},
  urldate = {2023-03-21},
  abstract = {Complex decisions can give rise to unexpected consequences from implemented actions. The main problem discussed by this research is the difficulty suffered by decision-makers in projecting impacts of a complex decision before the decision occurrence. Unexpected impacts of complex decisions demand mitigating action so that it is possible to intensify the positive aspects and neutralize the negatives. Dealing with unexpected impacts generates a cognitive overload on decision-makers and on the availability of material resources. To solve these problems, this research proposes the impact projection of complex decisions in a collaborative way, to be applied before the decision occurrence. The proposed solution considers a systematizing project impact of complex decisions inside work groups and delivers a framework and artefacts to support decision-makers in their decision impact tasks before the occurrence of a real decision scenario. This solution was evaluated by decision-making specialists and their goal was to investigate the applicability of this proposal to different teams. This is a qualitative research, and the method applied was the case study because we would like to deeply understand the behaviour of this approach in decision-makers team. The evaluation generated evidence on the feasibility of this approach, showing that the artefacts provide a systematic structure to orient what decision-makers must do to know and understand the impacts of decisions before their execution. This evidence is contribution for decision support field.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/JXV9VSA3/França and Borges - 2020 - Systematizing the impacts projection of complex de.pdf}
}

@inproceedings{fussellCoordinationOverloadTeam1998,
  title = {Coordination, Overload and Team Performance: Effects of Team Communication Strategies},
  shorttitle = {Coordination, Overload and Team Performance},
  booktitle = {Proceedings of the 1998 {{ACM}} Conference on {{Computer}} Supported Cooperative Work},
  author = {Fussell, Susan R. and Kraut, Robert E. and Lerch, F. Javier and Scherlis, William L. and McNally, Matthew M. and Cadiz, Jonathan J.},
  date = {1998-11},
  pages = {275--284},
  publisher = {{ACM}},
  location = {{Seattle Washington USA}},
  doi = {10.1145/289444.289502},
  url = {https://dl.acm.org/doi/10.1145/289444.289502},
  urldate = {2023-03-15},
  eventtitle = {{{CSCW98}}: {{Computer Supported Cooperative Work}}},
  isbn = {978-1-58113-009-6},
  langid = {english},
  keywords = {notion}
}

@inproceedings{fuTCalUnderstandingTeam2018,
  title = {T-{{Cal}}: {{Understanding Team Conversational Data}} with {{Calendar-based Visualization}}},
  shorttitle = {T-{{Cal}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Fu, Siwei and Zhao, Jian and Cheng, Hao Fei and Zhu, Haiyi and Marlow, Jennifer},
  date = {2018-04-21},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Montreal QC Canada}},
  doi = {10.1145/3173574.3174074},
  url = {https://dl.acm.org/doi/10.1145/3173574.3174074},
  urldate = {2023-04-10},
  abstract = {Understanding team communication and collaboration patterns is critical for improving work efficiency in organizations. This paper presents an interactive visualization system, T-Cal, that supports the analysis of conversation data from modern team messaging platforms (e.g., Slack). T-Cal employs a user-familiar visual interface, a calendar, to enable seamless multi-scale browsing of data from different perspectives. T-Cal also incorporates a number of analytical techniques for disentangling interleaving conversations, extracting keywords, and estimating sentiment. The design of T-Cal is based on an iterative user-centered design process including interview studies, requirements gathering, initial prototypes demonstration, and evaluation with domain users. The resulting two case studies indicate the effectiveness and usefulness of T-Cal in real-world applications, including daily conversations within an industry research lab and student group chats in a MOOC.},
  eventtitle = {{{CHI}} '18: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  file = {/Users/xinyuech/Zotero/storage/4KCXGRMH/Fu et al. - 2018 - T-Cal Understanding Team Conversational Data with.pdf}
}

@inproceedings{gebreegziabherPaTATHumanAICollaborative2023,
  title = {{{PaTAT}}: {{Human-AI Collaborative Qualitative Coding}} with {{Explainable Interactive Rule Synthesis}}},
  shorttitle = {{{PaTAT}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Gebreegziabher, Simret Araya and Zhang, Zheng and Tang, Xiaohang and Meng, Yihao and Glassman, Elena L. and Li, Toby Jia-Jun},
  date = {2023-04-19},
  pages = {1--19},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581352},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581352},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/L4IBU5NZ/Gebreegziabher et al. - 2023 - PaTAT Human-AI Collaborative Qualitative Coding w.pdf}
}

@inproceedings{geyerTeamCollaborationSpace2001,
  title = {A Team Collaboration Space Supporting Capture and Access of Virtual Meetings},
  booktitle = {Proceedings of the 2001 {{International ACM SIGGROUP Conference}} on {{Supporting Group Work}}  - {{GROUP}} '01},
  author = {Geyer, Werner and Richter, Heather and Fuchs, Ludwin and Frauenhofer, Tom and Daijavad, Shahrokh and Poltrock, Steven},
  date = {2001},
  pages = {188},
  publisher = {{ACM Press}},
  location = {{Boulder, Colorado, USA}},
  doi = {10.1145/500286.500315},
  url = {http://portal.acm.org/citation.cfm?doid=500286.500315},
  urldate = {2023-05-07},
  eventtitle = {The 2001 {{International ACM SIGGROUP Conference}}},
  isbn = {978-1-58113-294-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/WRGHHSII/Geyer et al. - 2001 - A team collaboration space supporting capture and .pdf}
}

@article{gongVIRTUALBRAINSTORMINGCREATIVITY2021,
  title = {VIRTUAL BRAINSTORMING AND CREATIVITY: AN ANALYSIS OF MEASURES, AVATARS, ENVIRONMENTS, INTERFACES, AND APPLICATIONS},
  shorttitle = {VIRTUAL BRAINSTORMING AND CREATIVITY},
  author = {Gong, Zhengya and Nanjappan, Vijayakumar and Soomro, Sohail Ahmed and Georgiev, Georgi V.},
  date = {2021-08},
  journaltitle = {Proceedings of the Design Society},
  volume = {1},
  pages = {3399--3408},
  publisher = {{Cambridge University Press}},
  issn = {2732-527X},
  doi = {10.1017/pds.2021.601},
  url = {https://www.cambridge.org/core/journals/proceedings-of-the-design-society/article/virtual-brainstorming-and-creativity-an-analysis-of-measures-avatars-environments-interfaces-and-applications/6D0C767DF1C9FBE3DDBB7EDE1901B68A},
  urldate = {2023-03-15},
  abstract = {如何提升创造力，尤其是将新技术应用到创造力方法中，是研究者不断提出的问题。原因之一是创造力是人们日常生活的重要组成部分，也是社会的重要组成部分。因此，许多提高创造力的方法应运而生，尤其是头脑风暴法，它是最流行和最有效的工具之一，可以激发个人产生想法，从而提高创造力。此外，虚拟现实 (VR) 等技术为个人和团体提供了发挥创造力的机会。作为回应，最近的研究在头脑风暴中采用 VR 来增强创造力。然而，缺乏对在这种情况下采用的实验方法和创造性措施的系统分析。针对这个问题，这项研究对与化身、环境、界面或应用程序类别相关的主题的现有文章进行了分类。调查结果详细说明了趋势、用于评估创造力和创意产生的措施、确定的类别以及这些研究的结果。},
  langid = {chinese},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/2WA444BS/Gong et al. - 2021 - VIRTUAL BRAINSTORMING AND CREATIVITY AN ANALYSIS .pdf}
}

@inproceedings{gonzalezAutomaticallyGeneratedSummaries2023,
  title = {Automatically {{Generated Summaries}} of {{Video Lectures May Enhance Students}}' {{Learning Experience}}},
  booktitle = {Proceedings of the 18th {{Workshop}} on {{Innovative Use}} of {{NLP}} for {{Building Educational Applications}} ({{BEA}} 2023)},
  author = {Gonzalez, Hannah and Li, Jiening and Jin, Helen and Ren, Jiaxuan and Zhang, Hongyu and Akinyele, Ayotomiwa and Wang, Adrian and Miltsakaki, Eleni and Baker, Ryan and Callison-Burch, Chris},
  date = {2023-07},
  pages = {382--393},
  publisher = {{Association for Computational Linguistics}},
  location = {{Toronto, Canada}},
  doi = {10.18653/v1/2023.bea-1.31},
  url = {https://aclanthology.org/2023.bea-1.31},
  urldate = {2023-08-15},
  abstract = {We introduce a novel technique for automatically summarizing lecture videos using large language models such as GPT-3 and we present a user study investigating the effects on the studying experience when automatic summaries are added to lecture videos. We test students under different conditions and find that the students who are shown a summary next to a lecture video perform better on quizzes designed to test the course materials than the students who have access only to the video or the summary. Our findings suggest that adding automatic summaries to lecture videos enhances the learning experience. Qualitatively, students preferred summaries when studying under time constraints.},
  eventtitle = {{{BEA}} 2023},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/2W9MWFJG/Gonzalez et al. - 2023 - Automatically Generated Summaries of Video Lecture.pdf}
}

@inproceedings{gumiennySupportingSynthesisInformation2014,
  title = {Supporting the Synthesis of Information in Design Teams},
  booktitle = {Proceedings of the 2014 Conference on {{Designing}} Interactive Systems},
  author = {Gumienny, Raja and Dow, Steven P. and Meinel, Christoph},
  date = {2014-06-21},
  pages = {463--472},
  publisher = {{ACM}},
  location = {{Vancouver BC Canada}},
  doi = {10.1145/2598510.2598545},
  url = {https://dl.acm.org/doi/10.1145/2598510.2598545},
  urldate = {2023-03-21},
  eventtitle = {{{DIS}} '14: {{Designing Interactive Systems Conference}} 2014},
  isbn = {978-1-4503-2902-6},
  langid = {english},
  keywords = {notion}
}

@article{habernalArgumentationMiningUserGenerated2017,
  title = {Argumentation {{Mining}} in {{User-Generated Web Discourse}}},
  author = {Habernal, Ivan and Gurevych, Iryna},
  date = {2017-04-01},
  journaltitle = {Computational Linguistics},
  shortjournal = {Computational Linguistics},
  volume = {43},
  number = {1},
  pages = {125--179},
  issn = {0891-2017},
  doi = {10.1162/COLI_a_00276},
  url = {https://doi.org/10.1162/COLI_a_00276},
  urldate = {2022-11-07},
  abstract = {The goal of argumentation mining, an evolving research field in computational linguistics, is to design methods capable of analyzing people's argumentation. In this article, we go beyond the state of the art in several ways. (i) We deal with actual Web data and take up the challenges given by the variety of registers, multiple domains, and unrestricted noisy user-generated Web discourse. (ii) We bridge the gap between normative argumentation theories and argumentation phenomena encountered in actual data by adapting an argumentation model tested in an extensive annotation study. (iii) We create a new gold standard corpus (90k tokens in 340 documents) and experiment with several machine learning methods to identify argument components. We offer the data, source codes, and annotation guidelines to the community under free licenses. Our findings show that argumentation mining in user-generated Web discourse is a feasible but challenging task.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XFLJ286D/Habernal and Gurevych - 2017 - Argumentation Mining in User-Generated Web Discour.pdf;/Users/xinyuech/Zotero/storage/ZAIGEHG2/Habernal and Gurevych - 2017 - Argumentation Mining in User-Generated Web Discour.pdf;/Users/xinyuech/Zotero/storage/WUJJ9G9T/Argumentation-Mining-in-User-Generated-Web.html}
}

@article{hindalongAbstractionsVisualizingPreferences2022,
  title = {Abstractions for {{Visualizing Preferences}} in {{Group Decisions}}},
  author = {Hindalong, Emily and Johnson, Jordon and Carenini, Giuseppe and Munzner, Tamara},
  date = {2022-03-30},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {1--44},
  issn = {2573-0142},
  doi = {10.1145/3512896},
  url = {https://dl.acm.org/doi/10.1145/3512896},
  urldate = {2023-03-21},
  abstract = {Group decision making occurs when individuals collectively choose from a set of alternatives based on individual preferences. In these ubiquitous situations, it can be helpful for decision makers to visually model and compare stakeholder preferences in order to better understand others' points of view and reach consensus. Although a number of collaboration support tools allow preference inspection in some form, they are rarely based on a comprehensive understanding of the needs of group decision makers. The goal of our work is to study these demands, develop abstractions to model them, and create a framework to inform the design and assessment of existing and future tools. First, guided by decision analysis theory, we examine a diverse set of group decision making scenarios, characterizing variations in problem formulation, analysis goals, and situational features. Second, we amalgamate these findings into data and task abstractions that can be used to relate specific scenarios to the language of visualization. Finally, we use this framework to assess existing preference visualization tools in order to shed light on areas for future work in supporting group decision making.},
  issue = {CSCW1},
  langid = {english},
  keywords = {notion}
}

@inproceedings{hongCollaborativeDynamicQueries2018,
  title = {Collaborative {{Dynamic Queries}}: {{Supporting Distributed Small Group Decision-making}}},
  shorttitle = {Collaborative {{Dynamic Queries}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hong, Sungsoo (Ray) and Suh, Minhyang (Mia) and Henry Riche, Nathalie and Lee, Jooyoung and Kim, Juho and Zachry, Mark},
  date = {2018-04-19},
  pages = {1--12},
  publisher = {{ACM}},
  location = {{Montreal QC Canada}},
  doi = {10.1145/3173574.3173640},
  url = {https://dl.acm.org/doi/10.1145/3173574.3173640},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '18: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/99PS8KBH/Hong et al. - 2018 - Collaborative Dynamic Queries Supporting Distribu.pdf}
}

@article{houAnalyzingSocialKnowledge2011,
  title = {Analyzing the Social Knowledge Construction Behavioral Patterns of an Online Synchronous Collaborative Discussion Instructional Activity Using an Instant Messaging Tool: {{A}} Case Study},
  shorttitle = {Analyzing the Social Knowledge Construction Behavioral Patterns of an Online Synchronous Collaborative Discussion Instructional Activity Using an Instant Messaging Tool},
  author = {Hou, Huei-Tse and Wu, Sheng-Yi},
  date = {2011-09-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {57},
  number = {2},
  pages = {1459--1468},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2011.02.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131511000509},
  urldate = {2023-05-07},
  abstract = {Online discussions have been widely utilized as an educational activity, and much research has been conducted on the process and behaviors involved in asynchronous discussions. However, research on behavioral patterns in learners’ synchronous discussions, including the process of social knowledge construction and project coordination is limited. Through the examination of the behavioral patterns and differences between students with high- and low-quality discussions, it may be possible to understand the limitations of knowledge construction in synchronous discussions. Furthermore, these findings may help teachers design and guide synchronous discussions activities. This study is an empirical case study in which college students conducted synchronous discussions based on topics specified by the teacher. The students used a text-based instant messaging (IM) tool in a period of 98 days. Two analytical methods were employed. The coding of the discussion messages was followed by a quantitative content analysis and a lag sequential analysis of behaviors. The social knowledge construction, project coordination, and social interactions in the group discussion were explored. Furthermore, the differences between the behavioral patterns of the high- and low-quality discussion groups were also examined. The findings indicate that although more than half of the discussion messages were off-topic, there were also some knowledge construction behavioral sequences. Furthermore, there were several limitations on the diversity and depth of the knowledge construction in the students’ discussions. The high-quality discussion teams performed better than the low-quality discussion teams in terms of participation, diversity in knowledge construction, and coordination. However, they also had more off-topic discussions. In this paper, we discuss these behavioral patterns and provide specific suggestions for teachers regarding how to implement synchronous discussions that are targeted to students’ knowledge construction processes.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/JUHKUYIM/Hou and Wu - 2011 - Analyzing the social knowledge construction behavi.pdf}
}

@online{HowDisplayGroup,
  title = {How to {{Display Group Information}} on {{Node-Link Diagrams}}: {{An Evaluation}} | {{IEEE Journals}} \& {{Magazine}} | {{IEEE Xplore}}},
  url = {https://ieeexplore.ieee.org/document/6787045},
  urldate = {2023-06-02},
  keywords = {notion}
}

@article{hoxhaDREAMClassificationScheme2016,
  title = {{{DREAM}}: {{Classification}} Scheme for Dialog Acts in Clinical Research Query Mediation},
  shorttitle = {{{DREAM}}},
  author = {Hoxha, Julia and Chandar, Praveen and He, Zhe and Cimino, James and Hanauer, David and Weng, Chunhua},
  date = {2016-02-01},
  journaltitle = {Journal of Biomedical Informatics},
  shortjournal = {Journal of Biomedical Informatics},
  volume = {59},
  pages = {89--101},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2015.11.011},
  url = {https://www.sciencedirect.com/science/article/pii/S1532046415002798},
  urldate = {2023-04-24},
  abstract = {Clinical data access involves complex but opaque communication between medical researchers and query analysts. Understanding such communication is indispensable for designing intelligent human–machine dialog systems that automate query formulation. This study investigates email communication and proposes a novel scheme for classifying dialog acts in clinical research query mediation. We analyzed 315 email messages exchanged in the communication for 20 data requests obtained from three institutions. The messages were segmented into 1333 utterance units. Through a rigorous process, we developed a classification scheme and applied it for dialog act annotation of the extracted utterances. Evaluation results with high inter-annotator agreement demonstrate the reliability of this scheme. This dataset is used to contribute preliminary understanding of dialog acts distribution and conversation flow in this dialog space.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/923I9UQR/Hoxha et al. - 2016 - DREAM Classification scheme for dialog acts in cl.pdf;/Users/xinyuech/Zotero/storage/VN3AJILG/S1532046415002798.html}
}

@article{hrastinskiPotentialSynchronousCommunication2008,
  title = {The Potential of Synchronous Communication to Enhance Participation in Online Discussions: {{A}} Case Study of Two e-Learning Courses},
  shorttitle = {The Potential of Synchronous Communication to Enhance Participation in Online Discussions},
  author = {Hrastinski, Stefan},
  date = {2008-11-01},
  journaltitle = {Information \& Management},
  shortjournal = {Information \& Management},
  volume = {45},
  number = {7},
  pages = {499--506},
  issn = {0378-7206},
  doi = {10.1016/j.im.2008.07.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0378720608000931},
  urldate = {2023-03-15},
  abstract = {Computer-mediated communication (CMC) has been adopted in most e-learning settings. However, few research studies have considered the effect of different CMC. This study examined how and why synchronous communication affected participation in online discussions. Two online classes that participated in two asynchronous and two synchronous online discussions were examined. Actual and perceived measures of participation indicated that synchronous communication induced personal participation, which could be regarded as a complement to cognitive participation. Personal participation involves more intense interaction better supported by synchronous communication while cognitive participation is a more reflective type of participation supported by asynchronous communication. In synchronous discussions, the e-learners felt that they worked together and were not restricted to only discuss course content. This was likely to induce arousal and motivation and increased convergence on meaning, especially in small groups.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/X78KRQ2Q/Hrastinski - 2008 - The potential of synchronous communication to enha.pdf;/Users/xinyuech/Zotero/storage/CE75Y4WR/S0378720608000931.html}
}

@inproceedings{andolina2017crowdboard,
  title={Crowdboard: augmenting in-person idea generation with real-time crowds},
  author={Andolina, Salvatore and Schneider, Hendrik and Chan, Joel and Klouche, Khalil and Jacucci, Giulio and Dow, Steven},
  booktitle={Proceedings of the 2017 ACM SIGCHI Conference on Creativity and Cognition},
  pages={106--118},
  year={2017}
}

@inproceedings{yu2010capture,
  title={Capture, recognition, and visualization of human semantic interactions in meetings},
  author={Yu, Zhiwen and Yu, Zhiyong and Aoyama, Hideki and Ozeki, Motoyuki and Nakamura, Yuichi},
  booktitle={2010 IEEE International Conference on Pervasive Computing and Communications (PerCom)},
  pages={107--115},
  year={2010},
  organization={IEEE}
}


@inproceedings{hsuehImprovingMeetingSummarization2009,
  title = {Improving Meeting Summarization by Focusing on User Needs: A Task-Oriented Evaluation},
  shorttitle = {Improving Meeting Summarization by Focusing on User Needs},
  booktitle = {Proceedings of the 14th International Conference on {{Intelligent}} User Interfaces},
  author = {Hsueh, Pei-Yun and Moore, Johanna D.},
  date = {2009-02-08},
  series = {{{IUI}} '09},
  pages = {17--26},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/1502650.1502657},
  url = {https://doi.org/10.1145/1502650.1502657},
  urldate = {2023-06-04},
  abstract = {Advances in multimedia technologies have enabled the creation of huge archives of audio-video recordings of meetings, and there is burgeoning interest in developing meeting browsers to help users better leverage these archives. A recent study has shown that extractive summaries provide a more efficient way of navigating meeting content than simply reading through the transcript and using the audio-video record, or navigating via keyword search (Murray, 2007). The extractive summary technique identifies informative dialogue acts to generate general purpose summaries. These summaries can still be lengthy. Recently, we have developed a decision-focused summarization system that presents only 1-2\% of the recordings related to decision making. In this paper, we describe a task-based evaluation in which we compare the decision-focused summaries to the general purpose summaries. Our results indicate that the more focused summaries help users perform the decision debriefing task more effectively and improve perceived efficiency. In addition, this study also investigates the effect of automatic summaries and transcription on task effectiveness, report quality, and users' perceptions of task success.},
  isbn = {978-1-60558-168-2},
  keywords = {��,notion},
  file = {/Users/xinyuech/Zotero/storage/U8HRRU58/Hsueh and Moore - 2009 - Improving meeting summarization by focusing on use.pdf}
}

@inproceedings{hughesKeeperSynchronousOnline2021,
  title = {Keeper: {{A Synchronous Online Conversation Environment Informed}} by {{In-Person Facilitation Practices}}},
  shorttitle = {Keeper},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hughes, Margaret A. and Roy, Deb},
  date = {2021-05-06},
  pages = {1--14},
  publisher = {{ACM}},
  location = {{Yokohama Japan}},
  doi = {10.1145/3411764.3445316},
  url = {https://dl.acm.org/doi/10.1145/3411764.3445316},
  urldate = {2023-06-26},
  eventtitle = {{{CHI}} '21: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-8096-6},
  langid = {english},
  file = {/Users/xinyuech/Zotero/storage/BLVZMV5K/Hughes and Roy - 2021 - Keeper A Synchronous Online Conversation Environm.pdf}
}

@inproceedings{huhAVscriptAccessibleVideo2023,
  title = {{{AVscript}}: {{Accessible Video Editing}} with {{Audio-Visual Scripts}}},
  shorttitle = {{{AVscript}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Huh, Mina and Yang, Saelyne and Peng, Yi-Hao and Chen, Xiang 'Anthony' and Kim, Young-Ho and Pavel, Amy},
  date = {2023-04-19},
  pages = {1--17},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581494},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581494},
  urldate = {2023-05-03},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/LCRIEXQW/Huh et al. - 2023 - AVscript Accessible Video Editing with Audio-Visu.pdf}
}

@online{ImprovingTeamworkUsing,
  title = {Improving Teamwork Using Real-Time Language Feedback | {{Proceedings}} of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  url = {https://dl.acm.org/doi/abs/10.1145/2470654.2470720?casa_token=KjvCEmNA31sAAAAA%3AB-O2o73feDgj-AVKRiJMaKn1QJpXRwHITYubJfQquDoMQSo9hL8lzWZ7JLjtykbYzjstz_tSEd_4T3k},
  urldate = {2023-06-02},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/62FIFFT9/2470654.html}
}

@inproceedings{ishizukaPrototypingAgentsResolving2022,
  title = {Prototyping {{Agents}} for {{Resolving Opinion Biases Toward Facilitating Sublation}} of {{Conflict}} in {{Web-based Discussions}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Agents}} ({{ICA}})},
  author = {Ishizuka, Hikaru and Shiramatsu, Shun and Ono, Keiko},
  date = {2022-11},
  pages = {18--23},
  doi = {10.1109/ICA55837.2022.00010},
  abstract = {The term “sublation” (or “aufheben”) refers to the process of arriving at an agreed upon answer to two opposing arguments without denying either of them. In this study, we conducted a discussion experiment in which we quantified the degree of sublation and analyzed the results to determine the factors that contribute to the cessation of conflicting opinions in discussions. Our findings revealed a weak positive correlation between the number of URLs posted as evidence for one's opinion and the degree of sublation of the consensus proposal. In actual discussions and debates, however, there are times when everyone makes the same argument, with little or no opposing views, resulting in biased opinions. To address this problem, we developed a method to eliminate bias in opinions, in which an agent posts information that reinforces the opinion of a minority in a discussion. The experimental results demonstrate that GPT-3, a natural language processing model, can be applied to summarization of relevant information for information provision and the resolution of opinion bias.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Agents}} ({{ICA}})},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XZRPUVFG/Ishizuka et al. - 2022 - Prototyping Agents for Resolving Opinion Biases To.pdf;/Users/xinyuech/Zotero/storage/SFPNEPBG/9999104.html}
}

@article{isterdaelDialogueMappingGuideaMaps,
  title = {Dialogue {{Mapping}} for {{GuideaMaps}}},
  author = {Isterdael, Nick Van},
  abstract = {In any software development process, one of the  rst phases includes collecting and formulating the requirements that the software should meet. This is important because starting from the right requirements will allow developing software that satis es the users as well as the customer. This is why collecting requirements is so vital in the whole software development process. In addition, maintaining or modifying existing software can also be a di cult task, especially when it is not clear what the original requirements and rationale were behind software design decisions. Therefore, requirement collection and analysis is an important phase in the development of software. Both tasks, developing and maintaining software, can be made easier by providing the developers with the design rationale of the original software in an explicit way. Design rationale documentation can provide an insight into why design decisions, such as requirements, have been made, what other alternatives have been considered and why these alternatives have been accepted or declined. Therefore it is important to provide developers with tools to document the requirements collection and analysis process.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/PAMXBWB2/Isterdael - Dialogue Mapping for GuideaMaps.pdf}
}

@article{janssenVisualizationAgreementDiscussion2007,
  title = {Visualization of Agreement and Discussion Processes during Computer-Supported Collaborative Learning},
  author = {Janssen, Jeroen and Erkens, Gijsbert and Kanselaar, Gellof},
  date = {2007-05-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  series = {Including the {{Special Issue}}: {{Avoiding Simplicity}}, {{Confronting Complexity}}: {{Advances}} in {{Designing Powerful Electronic Learning Environments}}},
  volume = {23},
  number = {3},
  pages = {1105--1125},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2006.10.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563206001282},
  urldate = {2023-06-02},
  abstract = {This study examined the effects of the shared space (SS) on students’ behaviors in a computer-supported collaborative learning (CSCL) environment. The SS visualizes discussion and agreement during online discussions. It was hypothesized the SS would increase the media richness of the CSCL-environment, would stimulate critical and exploratory group-norms, would lead to more positive perceptions of online collaboration, and would have an impact on students’ collaborative activities. In total, 59 students working in 20 groups had access to the SS visualization, while 58 students working in 20 groups did not. The results show that students with access to the SS visualization: (a) perceived higher media richness; (b) had a more exploratory group-norm perception; (b) perceived more positive group behavior; (c) perceived their group’s task strategies to be more effective; (d) engaged in different collaborative activities and (e) performed better on one part of the group task. These results demonstrate the potential benefits of visualizing agreement and discussion during CSCL.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XPIRYGWZ/S0747563206001282.html}
}

@online{jiangGraphologueExploringLarge2023,
  title = {Graphologue: {{Exploring Large Language Model Responses}} with {{Interactive Diagrams}}},
  shorttitle = {Graphologue},
  author = {Jiang, Peiling and Rayan, Jude and Dow, Steven P. and Xia, Haijun},
  date = {2023-05-19},
  eprint = {2305.11473},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.11473},
  urldate = {2023-05-23},
  abstract = {Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented intelligence exhibited on diverse applications. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can interact with the diagrams to flexibly adjust the graphical presentation and to submit context-specific prompts to obtain more information. Utilizing diagrams, Graphologue enables graphical, non-linear dialogues between humans and LLMs, facilitating information exploration, organization, and comprehension.},
  pubstate = {preprint},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/2EM3W56R/Jiang et al. - 2023 - Graphologue Exploring Large Language Model Respon.pdf;/Users/xinyuech/Zotero/storage/WJU3F3R5/2305.html}
}

@article{jotyTopicSegmentationLabeling2013,
  title = {Topic {{Segmentation}} and {{Labeling}} in {{Asynchronous Conversations}}},
  author = {Joty, Shafiq Rayhan and Carenini, Giuseppe and Ng, Raymond T.},
  date = {2013-07-22},
  journaltitle = {Journal of Artificial Intelligence Research},
  shortjournal = {jair},
  volume = {47},
  eprint = {1402.0586},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {521--573},
  issn = {1076-9757},
  doi = {10.1613/jair.3940},
  url = {http://arxiv.org/abs/1402.0586},
  urldate = {2023-06-04},
  abstract = {Topic segmentation and labeling is often considered a prerequisite for higher-level conversation analysis and has been shown to be useful in many Natural Language Processing (NLP) applications. We present two new corpora of email and blog conversations annotated with topics, and evaluate annotator reliability for the segmentation and labeling tasks in these asynchronous conversations. We propose a complete computational framework for topic segmentation and labeling in asynchronous conversations. Our approach extends state-of-the-art methods by considering a fine-grained structure of an asynchronous conversation, along with other conversational features by applying recent graph-based methods for NLP. For topic segmentation, we propose two novel unsupervised models that exploit the fine-grained conversational structure, and a novel graph-theoretic supervised model that combines lexical, conversational and topic features. For topic labeling, we propose two novel (unsupervised) random walk models that respectively capture conversation specific clues from two different sources: the leading sentences and the fine-grained conversational structure. Empirical evaluation shows that the segmentation and the labeling performed by our best models beat the state-of-the-art, and are highly correlated with human annotations.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DESNBLS2/Joty et al. - 2013 - Topic Segmentation and Labeling in Asynchronous Co.pdf;/Users/xinyuech/Zotero/storage/WBD227AP/1402.html}
}

@article{kangSynergiMixedInitiativeSystem2023,
  title = {Synergi: {{A Mixed-Initiative System}} for {{Scholarly Synthesis}} and {{Sensemaking}}},
  author = {Kang, Hyeonsu B and Wu, Sherry Tongshuang and Chang, Joseph Chee and Kittur, Aniket},
  date = {2023},
  abstract = {Efficiently reviewing scholarly literature and synthesizing prior art are crucial for scientific progress. Yet, the growing scale of publications and the burden of knowledge make synthesis of research threads more challenging than ever. While significant research has been devoted to helping scholars interact with individual papers, building research threads scattered across multiple papers remains a challenge. Most top-down synthesis (and LLMs) make it difficult to personalize and iterate on the output, while bottom-up synthesis is costly in time and effort. Here, we explore a new design space of mixed-initiative workflows. In doing so we develop a novel computational pipeline, Synergi, that ties together user input of relevant seed threads with citation graphs and LLMs, to expand and structure them, respectively. Synergi allows scholars to start with an entire threads-and-subthreads structure generated from papers relevant to their interests, and to iterate and customize on it as they wish. In our evaluation, we find that Synergi helps scholars efficiently make sense of relevant threads, broaden their perspectives, and increases their curiosity. We discuss future design implications for thread-based, mixed-initiative scholarly synthesis support tools.},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/XMUD9G22/Kang et al. - 2023 - Synergi A Mixed-Initiative System for Scholarly S.pdf}
}

@article{karlVirtualWorkMeetings2022,
  title = {Virtual {{Work Meetings During}} the {{COVID-19 Pandemic}}: {{The Good}}, {{Bad}}, and {{Ugly}}},
  shorttitle = {Virtual {{Work Meetings During}} the {{COVID-19 Pandemic}}},
  author = {Karl, Katherine A. and Peluchette, Joy V. and Aghakhani, Navid},
  date = {2022-06-01},
  journaltitle = {Small Group Research},
  volume = {53},
  number = {3},
  pages = {343--365},
  publisher = {{SAGE Publications Inc}},
  issn = {1046-4964},
  doi = {10.1177/10464964211015286},
  url = {https://doi.org/10.1177/10464964211015286},
  urldate = {2023-03-21},
  abstract = {This study focuses on the good, the bad and the ugly of using videoconferencing for work-related meetings during the COVID-19 pandemic. Using a text mining process and qualitative content analysis of 549 comments posted to a LinkedIn online discussion board, we identified six key themes; three were tied to camera and microphone issues, two involved eating and meeting management issues, and one dealt with work-from-home issues. These themes are discussed in relationship to media naturalness theory and meeting science. Because widespread use of videoconferencing will likely continue, we provide guidance for workplace policies/practices and suggest directions for future research.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/HW8SWFRC/Karl et al. - 2022 - Virtual Work Meetings During the COVID-19 Pandemic.pdf}
}

@article{katukaMyPartnerWas,
  title = {My {{Partner}} Was a {{Good Partner}}: {{Investigating}} the {{Relationship}} between {{Dialogue Acts}} and {{Satisfaction}} among {{Middle School Computer Science Learners}}},
  author = {Katuka, Gloria Ashiya and Bex, Richard T and Celepkolu, Mehmet and Boyer, Kristy Elizabeth and Wiebe, Eric and Mott, Bradford and Lester, James},
  abstract = {Collaborative dialogue provides a rich information source for understanding the effectiveness of student interactions. While many studies emphasize the importance of productive dialogue behaviors, the impact of those behaviors on learners’ perceptions of their partners is not yet understood. This paper examines a dialogue corpus of 18 pairs of middle school students as they engage in block-based coding activities. We tagged the corpus with a collaborative dialogue act taxonomy and identified sequences of one to two dialogue acts (ngrams) that are significantly associated with partner satisfaction during collaborative learning. Six n-grams were found to be significant predictors: n-grams that were positively associated with satisfaction included some questions and clarifications. In contrast, n-grams that were negatively associated with satisfaction included off-task utterances, pairs of consecutive questions, and unexpectedly, positive feedback. These findings contribute to our understanding of how learners prefer to interact with their partners and how that interaction impacts collaborative experiences.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/RZ4I75Q3/Katuka et al. - My Partner was a Good Partner Investigating the R.pdf}
}

@article{kecskesActivatingSeekingCreating2009,
  title = {Activating, Seeking, and Creating Common Ground: {{A}} Socio-Cognitive Approach},
  shorttitle = {Activating, Seeking, and Creating Common Ground},
  author = {Kecskes, Istvan and Zhang, Fenghui},
  date = {2009-08-31},
  journaltitle = {Pragmatics \& Cognition},
  shortjournal = {P\&C},
  volume = {17},
  number = {2},
  pages = {331--355},
  issn = {0929-0907, 1569-9943},
  doi = {10.1075/pc.17.2.06kec},
  url = {http://www.jbe-platform.com/content/journals/10.1075/pc.17.2.06kec},
  urldate = {2023-05-07},
  abstract = {This paper argues that current pragmatic theories fail to describe common ground in its complexity because they usually retain a communication-as-transfer-between-minds view of language, and disregard the fact that disagreement and egocentrism of speaker-hearers are as fundamental parts of communication as agreement and cooperation. On the other hand, current cognitive research has overestimated the egocentric behavior of the dyads and argued for the dynamic emergent property of common ground while devaluing the overall significance of cooperation in the process of verbal communication. The paper attempts to eliminate this conflict and proposes to combine the two views into an integrated concept of common ground, in which both core common ground (assumed shared knowledge, a priori mental representation) and emergent common ground (emergent participant resource, a post facto emergence through use) converge to construct a dialectical socio-cultural background for communication. Both cognitive and pragmatic considerations are central to this issue. While attention (through salience, which is the cause for interlocutors’ egocentrism) explains why emergent property unfolds, intention (through relevance, which is expressed in cooperation) explains why presumed shared knowledge is needed. Based on this, common ground is perceived as an effort to converge the mental representation of shared knowledge present as memory that we can activate, shared knowledge that we can seek, and rapport, as well as knowledge that we can create in the communicative process. The socio-cognitive approach emphasizes that common ground is a dynamic construct that is mutually constructed by interlocutors throughout the communicative process. The core and emergent components join in the construction of common ground in all stages, although they may contribute to the construction process in different ways, to different extents, and in different phases of the communicative process.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DFY26N4W/Kecskes and Zhang - 2009 - Activating, seeking, and creating common ground A.pdf}
}

@article{khadpeEmpathospherePromotingConstructive2022,
  title = {Empathosphere: {{Promoting Constructive Communication}} in {{Ad-hoc Virtual Teams}} through {{Perspective-taking Spaces}}},
  shorttitle = {Empathosphere},
  author = {Khadpe, Pranav and Kulkarni, Chinmay and Kaufman, Geoff},
  date = {2022-03-30},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {1--26},
  issn = {2573-0142},
  doi = {10.1145/3512902},
  url = {https://dl.acm.org/doi/10.1145/3512902},
  urldate = {2023-06-02},
  abstract = {When members of ad-hoc virtual teams need to collectively ideate or deliberate, they often fail to engage with each others' perspectives in a constructive manner. At best, this leads to sub-optimal outcomes, and, at worst, it can cause conflicts that lead to teams not wanting to continue working together. Prior work has attempted to facilitate constructive communication by highlighting problematic communication patterns and nudging teams to alter their interaction norms. However, these approaches achieve limited success because they fail to acknowledge two social barriers: (1) it is hard to reset team norms mid-interaction, and (2) corrective nudges have limited utility unless team members believe it is safe to voice their opinion and that their opinion will be heard. This paper introduces Empathosphere, a chat-embedded intervention to mitigate these barriers and foster constructive communication in teams. To mitigate the first barrier, Empathosphere leverages the known benefits of "experimental spaces" in dampening existing norms and creating a climate conducive to change. Empathosphere instantiates this "space'' as a separate communication channel in a team's workspace. To mitigate the second barrier, Empathosphere harnesses the benefits of perspective-taking to cultivate a group climate that promotes a norm of members speaking up and engaging with each other. Empathosphere achieves this by orchestrating authentic socio-emotional exchanges designed to induce perspective-taking. A controlled study (\$N=110\$) compared Empathosphere to an alternate intervention strategy of prompting teams to reflect on their team experience. We found that Empathosphere led to higher work satisfaction, encouraged more open communication and feedback within teams, and boosted teams' desire to continue working together. This work demonstrates that "experimental spaces," particularly those that integrate methods of encouraging perspective-taking, can be a powerful means of improving communication in virtual teams.},
  issue = {CSCW1},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/6H6K666V/Khadpe et al. - 2022 - Empathosphere Promoting Constructive Communicatio.pdf}
}

@article{kimCellsGeneratorsLenses2023,
  title = {Cells, {{Generators}}, and {{Lenses}}: {{Design Framework}} for {{Object-Oriented Interaction}} with {{Large Language Models}}},
  author = {Kim, Tae Soo and Chang, Minsuk and Lee, Yoonjoo and Kim, Juho},
  date = {2023},
  langid = {english},
  keywords = {��������},
  file = {/Users/xinyuech/Zotero/storage/B6K7WP6G/Kim et al. - 2023 - Cells, Generators, and Lenses Design Framework fo.pdf}
}

@article{kimModeratorChatbotDeliberative2021,
  title = {Moderator {{Chatbot}} for {{Deliberative Discussion}}: {{Effects}} of {{Discussion Structure}} and {{Discussant Facilitation}}},
  shorttitle = {Moderator {{Chatbot}} for {{Deliberative Discussion}}},
  author = {Kim, Soomin and Eun, Jinsu and Seering, Joseph and Lee, Joonhwan},
  date = {2021-04-13},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  pages = {1--26},
  issn = {2573-0142},
  doi = {10.1145/3449161},
  url = {https://dl.acm.org/doi/10.1145/3449161},
  urldate = {2023-05-08},
  abstract = {Online chat functions as a discussion channel for diverse social issues. However, deliberative discussion and consensus-reaching can be difficult in online chats in part because of the lack of structure. To explore the feasibility of a conversational agent that enables deliberative discussion, we designed and developed DebateBot, a chatbot that structures discussion and encourages reticent participants to contribute. We conducted a 2 (discussion structure: unstructured vs. structured) × 2 (discussant facilitation: unfacilitated vs. facilitated) between-subjects experiment (N = 64, 12 groups). Our findings are as follows: (1) Structured discussion positively affects discussion quality by generating diverse opinions within a group and resulting in a high level of perceived deliberative quality. (2) Facilitation drives a high level of opinion alignment between group consensus and independent individual opinions, resulting in authentic consensus reaching. Facilitation also drives more even contribution and a higher level of task cohesion and communication fairness. Our results suggest that a chatbot agent could partially substitute for a human moderator in deliberative discussions.},
  issue = {CSCW1},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/F6PPSDRG/Kim et al. - 2021 - Moderator Chatbot for Deliberative Discussion Eff.pdf}
}

@inproceedings{kimSurchEnablingStructural2023,
  title = {Surch: {{Enabling Structural Search}} and {{Comparison}} for {{Surgical Videos}}},
  shorttitle = {Surch},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kim, Jeongyeon and Choi, Daeun and Lee, Nicole and Beane, Matt and Kim, Juho},
  date = {2023-04-19},
  pages = {1--17},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580772},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580772},
  urldate = {2023-08-15},
  abstract = {Video is an effective medium for learning procedural knowledge, such as surgical techniques. However, learning procedural knowledge through videos remains difficult due to limited access to procedural structures of knowledge (e.g., compositions and ordering of steps) in a large-scale video dataset. We present Surch, a system that enables structural search and comparison of surgical procedures. Surch supports video search based on procedural graphs generated by our clustering workflow capturing latent patterns within surgical procedures. We used vectorization and weighting schemes that characterize the features of procedures, such as recursive structures and unique paths. Surch enhances cross-video comparison by providing video navigation synchronized by surgical steps. Evaluation of the workflow demonstrates the effectiveness and interpretability (Silhouette score = 0.82) of our clustering for surgical learning. A user study with 11 residents shows that our system significantly improves the learning experience and task efficiency of video search and comparison, especially benefiting junior residents.},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/RTNENUAJ/Kim et al. - 2023 - Surch Enabling Structural Search and Comparison f.pdf}
}

@inproceedings{kimSystematicReviewDyadic2021,
  title = {A {{Systematic Review}} on {{Dyadic Conversation Visualizations}}},
  booktitle = {Companion {{Publication}} of the 2021 {{International Conference}} on {{Multimodal Interaction}}},
  author = {Kim, Joshua Y. and Calvo, Rafael A. and Enfield, N. J. and Yacef, Kalina},
  date = {2021-10-18},
  pages = {137--147},
  publisher = {{ACM}},
  location = {{Montreal QC Canada}},
  doi = {10.1145/3461615.3485396},
  url = {https://dl.acm.org/doi/10.1145/3461615.3485396},
  urldate = {2023-05-08},
  eventtitle = {{{ICMI}} '21: {{INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION}}},
  isbn = {978-1-4503-8471-1},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/5G6LXJTH/Kim et al. - 2021 - A Systematic Review on Dyadic Conversation Visuali.pdf}
}

@article{kirshenbaumTracesTimeSpace2021c,
  title = {Traces of {{Time}} through {{Space}}: {{Advantages}} of {{Creating Complex Canvases}} in {{Collaborative Meetings}}},
  shorttitle = {Traces of {{Time}} through {{Space}}},
  author = {Kirshenbaum, Nurit and Davidson, Kylie and Harden, Jesse and North, Chris and Kobayashi, Dylan and Theriot, Ryan and Tabalba, Roderick S. and Rogers, Michael L. and Belcaid, Mahdi and Burks, Andrew T. and Bharadwaj, Krishna N. and Renambot, Luc and Johnson, Andrew E. and Long, Lance and Leigh, Jason},
  date = {2021-11-03},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  pages = {1--20},
  issn = {2573-0142},
  doi = {10.1145/3488552},
  url = {https://dl.acm.org/doi/10.1145/3488552},
  urldate = {2023-03-24},
  abstract = {Technology have long been a partner of workplace meeting facilitation. The recent outbreak of COVID-19 and the cautionary measures to reduce its spread have made it more prevalent than ever before in the form of online-meetings. In this paper, we recount our experiences during weekly meetings in three modalities: using SAGE2 - a collaborative sharing software designed for large displays - for co-located meetings, using a conventional projector for co-located meetings, and using the Zoom video-conferencing tool for distributed meetings. We view these meetings through the lens of effective meeting attributes and share ethnographic observations and attitudinal survey conducted in our research lab. We discuss patterns of content sharing, either sequential, parallel, or semi-parallel, and the potential advantages of creating complex canvases of content. We see how the SAGE2 tool affords parallel content sharing to create complex canvases, which represent queues of ideas and contributions (past, present, and future) using the space on a large display to suggest the progression of time through the meeting.},
  issue = {ISS},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/UGDEZ2TH/Kirshenbaum et al. - 2021 - Traces of Time through Space Advantages of Creati.pdf}
}

@incollection{kleinCommonGroundCoordination2005,
  title = {Common {{Ground}} and {{Coordination}} in {{Joint Activity}}},
  booktitle = {Organizational {{Simulation}}},
  author = {Klein, Gary and Feltovich, Paul J. and Bradshaw, Jeffrey M. and Woods, David D.},
  editor = {Rouse, William B. and Boff, Kenneth R.},
  date = {2005-06-27},
  pages = {139--184},
  publisher = {{John Wiley \& Sons, Inc.}},
  location = {{Hoboken, NJ, USA}},
  doi = {10.1002/0471739448.ch6},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/0471739448.ch6},
  urldate = {2023-03-15},
  abstract = {Generalizing the concepts of joint activity developed by Clark (1996), we describe key aspects of team coordination. Joint activity depends on interpredictability of the participants’ attitudes and actions. Such interpredictability is based on common ground—pertinent knowledge, beliefs and assumptions that are shared among the involved parties. Joint activity assumes a basic compact, which is an agreement (often tacit) to facilitate coordination and prevent its breakdown. One aspect of the Basic Compact is the commitment to some degree of aligning multiple goals. A second aspect is that all parties are expected to bear their portion of the responsibility to establish and sustain common ground and to repair it as needed.},
  isbn = {978-0-471-73944-9 978-0-471-68163-2},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CVQWKTGM/Klein et al. - 2005 - Common Ground and Coordination in Joint Activity.pdf}
}

@article{kohnBuildingIdeasOthers2011,
  title = {Building on the Ideas of Others: {{An}} Examination of the Idea Combination Process},
  shorttitle = {Building on the Ideas of Others},
  author = {Kohn, Nicholas W. and Paulus, Paul B. and Choi, YunHee},
  date = {2011-05-01},
  journaltitle = {Journal of Experimental Social Psychology},
  shortjournal = {Journal of Experimental Social Psychology},
  volume = {47},
  number = {3},
  pages = {554--561},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2011.01.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0022103111000059},
  urldate = {2023-03-14},
  abstract = {Two experiments were conducted to explore the process of building on ideas in brainstorming. Although this is presumed to be an important role of brainstorming, this has never been explored experimentally. In one experiment individual and group brainstormers generated ideas which were subsequently presented to these same individuals and groups to combine and build on for additional ideas, either as groups or individuals. The combination process was influenced by whether the participants had previously brainstormed alone or in groups and the phase of the combination period (early vs. late). In a second study participants were presented lists of rare or common ideas to combine and build on either as individuals or groups. Although groups generated fewer combinations than nominal groups, they generated more novel and feasible combinations when combining rare ideas. These findings indicate that groups are able to benefit from the exchange process in building on each other's ideas and are interpreted in the context of past research on idea generation and evaluation in groups.},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/GH6XPI5P/Kohn et al. - 2011 - Building on the ideas of others An examination of.pdf;/Users/xinyuech/Zotero/storage/AYD4TT8Q/S0022103111000059.html}
}

@article{kontogiorgosGroundingBehavioursConversational2021,
  title = {Grounding Behaviours with Conversational Interfaces: Effects of Embodiment and Failures},
  shorttitle = {Grounding Behaviours with Conversational Interfaces},
  author = {Kontogiorgos, Dimosthenis and Pereira, Andre and Gustafson, Joakim},
  date = {2021-06-01},
  journaltitle = {Journal on Multimodal User Interfaces},
  shortjournal = {J Multimodal User Interfaces},
  volume = {15},
  number = {2},
  pages = {239--254},
  issn = {1783-8738},
  doi = {10.1007/s12193-021-00366-y},
  url = {https://doi.org/10.1007/s12193-021-00366-y},
  urldate = {2023-03-15},
  abstract = {Conversational interfaces that interact with humans need to continuously establish, maintain and repair common ground in task-oriented dialogues. Uncertainty, repairs and acknowledgements are expressed in user behaviour in the continuous efforts of the conversational partners to maintain mutual understanding. Users change their behaviour when interacting with systems in different forms of embodiment, which affects the abilities of these interfaces to observe users’ recurrent social signals. Additionally, humans are intellectually biased towards social activity when facing anthropomorphic agents or when presented with subtle social cues. Two studies are presented in this paper examining how humans interact in a referential communication task with wizarded interfaces in different forms of embodiment. In study 1 (N = 30), we test whether humans respond the same way to agents, in different forms of embodiment and social behaviour. In study 2 (N = 44), we replicate the same task and agents but introduce conversational failures disrupting the process of grounding. Findings indicate that it is not always favourable for agents to be anthropomorphised or to communicate with non-verbal cues, as human grounding behaviours change when embodiment and failures are manipulated.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/3ZH6IR4L/Kontogiorgos et al. - 2021 - Grounding behaviours with conversational interface.pdf}
}

@article{kuoEffectsApplyingSTR2012,
  title = {Effects of Applying {{STR}} for Group Learning Activities on Learning Performance in a Synchronous Cyber Classroom},
  author = {Kuo, Tony C. T. and Shadiev, Rustam and Hwang, Wu-Yuin and Chen, Nian-Shing},
  date = {2012-01-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {58},
  number = {1},
  pages = {600--608},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2011.07.018},
  url = {https://www.sciencedirect.com/science/article/pii/S036013151100176X},
  urldate = {2023-03-15},
  abstract = {This study aimed to apply Speech to Text Recognition (STR) for individual oral presentations and group discussions of students in a synchronous cyber classroom. An experiment was conducted to analyze the effectiveness of applying STR on learning performance. Students’ perceptions and behavioral intentions toward using STR were also investigated. The results revealed students of the experimental group performed significantly better compared to the control group students in two sessions of writing essays, intermediate test and post-test. Most of students perceived that STR was useful for individual presentations and for essays writing. Students also expressed they are willing to use the STR for learning in the future. However, the students who obtained transcripts with low accuracy rate and experienced delay in STR-text generation did not perceive the STR as easy to use and useful for group discussions. Meanwhile, the results of this study showed that the STR is beneficial to students’ oral presentations and group discussions in a synchronous cyber classroom so as to improve their overall learning performance.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/ZSBS223B/Kuo et al. - 2012 - Effects of applying STR for group learning activit.pdf;/Users/xinyuech/Zotero/storage/S5HE2SI6/S036013151100176X.html}
}

@inproceedings{leeDAPIEInteractiveStepbyStep2023,
  title = {{{DAPIE}}: {{Interactive Step-by-Step Explanatory Dialogues}} to {{Answer Children}}’s {{Why}} and {{How Questions}}},
  shorttitle = {{{DAPIE}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lee, Yoonjoo and Kim, Tae Soo and Kim, Sungdong and Yun, Yohan and Kim, Juho},
  date = {2023-04-19},
  pages = {1--22},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581369},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581369},
  urldate = {2023-08-15},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/PIJTKWZV/Lee et al. - 2023 - DAPIE Interactive Step-by-Step Explanatory Dialog.pdf}
}

@inproceedings{leePromptiverseScalableGeneration2022,
  title = {Promptiverse: {{Scalable Generation}} of {{Scaffolding Prompts Through Human-AI Hybrid Knowledge Graph Annotation}}},
  shorttitle = {Promptiverse},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lee, Yoonjoo and Chung, John Joon Young and Kim, Tae Soo and Song, Jean Y and Kim, Juho},
  date = {2022-04-27},
  pages = {1--18},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3491102.3502087},
  url = {https://dl.acm.org/doi/10.1145/3491102.3502087},
  urldate = {2023-08-16},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9157-3},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️},
  file = {/Users/xinyuech/Zotero/storage/F9L8EUIF/Lee et al. - 2022 - Promptiverse Scalable Generation of Scaffolding P.pdf}
}

@inproceedings{leshedVisualizingLanguageUse2010,
  title = {Visualizing Language Use in Team Conversations: Designing through Theory, Experiments, and Iterations},
  shorttitle = {Visualizing Language Use in Team Conversations},
  booktitle = {{{CHI}} '10 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Leshed, Gilly and Cosley, Dan and Hancock, Jeffrey T. and Gay, Geri},
  date = {2010-04-10},
  pages = {4567--4582},
  publisher = {{ACM}},
  location = {{Atlanta Georgia USA}},
  doi = {10.1145/1753846.1754195},
  url = {https://dl.acm.org/doi/10.1145/1753846.1754195},
  urldate = {2023-05-08},
  eventtitle = {{{CHI}} '10: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-930-5},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/AP6B9X9B/Leshed et al. - 2010 - Visualizing language use in team conversations de.pdf}
}

@inproceedings{leshedVisualizingRealtimeLanguagebased2009,
  title = {Visualizing Real-Time Language-Based Feedback on Teamwork Behavior in Computer-Mediated Groups},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Leshed, Gilly and Perez, Diego and Hancock, Jeffrey T. and Cosley, Dan and Birnholtz, Jeremy and Lee, Soyoung and McLeod, Poppy L. and Gay, Geri},
  date = {2009-04-04},
  pages = {537--546},
  publisher = {{ACM}},
  location = {{Boston MA USA}},
  doi = {10.1145/1518701.1518784},
  url = {https://dl.acm.org/doi/10.1145/1518701.1518784},
  urldate = {2023-05-08},
  eventtitle = {{{CHI}} '09: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-246-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/HYHPTMBI/Leshed et al. - 2009 - Visualizing real-time language-based feedback on t.pdf}
}

@inproceedings{liangImplicitCommunicationActionable2019,
  title = {Implicit {{Communication}} of {{Actionable Information}} in {{Human-AI}} Teams},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liang, Claire and Proft, Julia and Andersen, Erik and Knepper, Ross A.},
  date = {2019-05-02},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Glasgow Scotland Uk}},
  doi = {10.1145/3290605.3300325},
  url = {https://dl.acm.org/doi/10.1145/3290605.3300325},
  urldate = {2023-08-15},
  eventtitle = {{{CHI}} '19: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5970-2},
  langid = {english},
  file = {/Users/xinyuech/Zotero/storage/TRACZL8B/Liang et al. - 2019 - Implicit Communication of Actionable Information i.pdf}
}

@online{liaoRethinkingModelEvaluation2023,
  title = {Rethinking {{Model Evaluation}} as {{Narrowing}} the {{Socio-Technical Gap}}},
  author = {Liao, Q. Vera and Xiao, Ziang},
  date = {2023-06-28},
  eprint = {2306.03100},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.03100},
  urldate = {2023-07-31},
  abstract = {The recent development of generative and large language models (LLMs) poses new challenges for model evaluation that the research community and industry are grappling with. While the versatile capabilities of these models ignite excitement, they also inevitably make a leap toward homogenization: powering a wide range of applications with a single, often referred to as ``general-purpose'', model. In this position paper, we argue that model evaluation practices must take on a critical task to cope with the challenges and responsibilities brought by this homogenization: providing valid assessments for whether and how much human needs in downstream use cases can be satisfied by the given model (socio-technical gap). By drawing on lessons from the social sciences, human-computer interaction (HCI), and the interdisciplinary field of explainable AI (XAI), we urge the community to develop evaluation methods based on real-world socio-requirements and embrace diverse evaluation methods with an acknowledgment of trade-offs between realism to socio-requirements and pragmatic costs to conduct the evaluation. By mapping HCI and current NLG evaluation methods, we identify opportunities for evaluation methods for LLMs to narrow the socio-technical gap and pose open questions.},
  pubstate = {preprint},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/33Z3I4A3/Liao and Xiao - 2023 - Rethinking Model Evaluation as Narrowing the Socio.pdf;/Users/xinyuech/Zotero/storage/5MGQ9PE2/2306.html}
}

@inproceedings{liImprovingAutomaticSummarization2023,
  title = {Improving {{Automatic Summarization}} for {{Browsing Longform Spoken Dialog}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Li, Daniel and Chen, Thomas and Zadikian, Alec and Tung, Albert and Chilton, Lydia B},
  date = {2023-04-19},
  pages = {1--20},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581339},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581339},
  urldate = {2023-04-27},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/AGDAF5FA/Li et al. - 2023 - Improving Automatic Summarization for Browsing Lon.pdf}
}

@thesis{limDesigningSupportSensemaking2021,
  type = {phdthesis},
  title = {Designing to Support Sensemaking in Cross-Lingual Computer-Mediated Communication Using NLP Techniques},
  author = {Lim, Hajin},
  date = {2021},
  url = {https://www.proquest.com/docview/2550610767/abstract/5CFA5E0A7FDA45E3PQ/1},
  urldate = {2023-03-16},
  abstract = {Advances in machine translation (MT) and computer-mediated communication (CMC) tools now allow people to collaborate on common problems and interact with others across linguistic and cultural boundaries. However, communicating with linguistically different others, specifically, making sense of the meanings in foreign language messages, is still challenging. Because of the imperfect quality of MT and a lack of cultural and contextual knowledge regarding other cultures, people experience difficulties in extracting informative cues and interpreting the meanings of foreign language messages. Such challenges can diminish the capability of CMC platforms to facilitate communication and information exchange between linguistically and/or culturally diverse communities. The main goal of this dissertation is to explore design solutions that can improve people’s sensemaking processes when they encounter foreign language messages. I investigate how people make sense of foreign language messages and identify their challenges and needs in their sensemaking process. Based on my findings, I design and develop sensemaking support tools and evaluate them in the context of social media sites and email communication. Specifically, I use natural language processing (NLP) techniques to generate useful cues for users’ sensemaking of foreign language messages. First, I design and develop SenseTrans–a browser extension that provides NLP-generated information about cultural referents, sentiments, and emotions using emotion/sentiment detection algorithms and entity extraction techniques. Second, I design the Politeness estimator, an email extension that provides politeness assessments of foreign language messages using language-specific classification algorithms in addition to MT outputs. The results from experimental evaluations of these tools provide initial evidence for the value of NLP techniques to improve cross-lingual sensemaking by increasing users’ confidence and accuracy in interpreting foreign language messages. Future, the deployment study of the tools in a real-world setting points to the need for further investigation of how users understand and utilize the NLP-generated information from the tools in their sensemaking process. The dissertation contributes to our understanding of current challenges in making sense of foreign language messages and the design of future tools for cross-lingual CMC and sensemaking.},
  isbn = {9798516921889},
  langid = {英语},
  pagetotal = {219},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/LM638B9E/Lim - 2021 - Designing to Support Sensemaking in Cross-Lingual .pdf}
}

@article{limHowEmotionalContextual2019,
  title = {How {{Emotional}} and {{Contextual Annotations Involve}} in {{Sensemaking Processes}} of {{Foreign Language Social Media Posts}}},
  author = {Lim, Hajin and Cosley, Dan and Fussell, Susan R.},
  date = {2019-11-07},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  pages = {1--18},
  issn = {2573-0142},
  doi = {10.1145/3359171},
  url = {https://dl.acm.org/doi/10.1145/3359171},
  urldate = {2023-06-02},
  abstract = {The goal of this paper is to investigate how computational tools to annotate communication can support multilingual sense-making on social media. We conducted a field study of SenseTrans, a browser extension that uses sentiment analysis and named entity extraction techniques to annotate Facebook posts with emotional and contextual information. Interviews with 18 participants who used SenseTrans in their Facebook newsfeed for two weeks suggest that the annotations often supported sensemaking by providing additional information they could use to get a quick gist of the posts or to supplement their own interpretations. Participants varied in the extent to which they were motivated to evaluate the credibility of and form mental models of how the annotations were generated, which shaped how they utilized the annotations for sensemaking. Our findings demonstrate the value of designing to support cross-lingual communication and inform design implications for intelligent tools that support communication and sensemaking.},
  issue = {CSCW},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XZM4WN2X/Lim et al. - 2019 - How Emotional and Contextual Annotations Involve i.pdf}
}

@inproceedings{liMultiModalRepairsConversational2020,
  title = {Multi-{{Modal Repairs}} of {{Conversational Breakdowns}} in {{Task-Oriented Dialogs}}},
  booktitle = {Proceedings of the 33rd {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Li, Toby Jia-Jun and Chen, Jingya and Xia, Haijun and Mitchell, Tom M. and Myers, Brad A.},
  date = {2020-10-20},
  series = {{{UIST}} '20},
  pages = {1094--1107},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3379337.3415820},
  url = {https://doi.org/10.1145/3379337.3415820},
  urldate = {2023-03-14},
  abstract = {A major problem in task-oriented conversational agents is the lack of support for the repair of conversational breakdowns. Prior studies have shown that current repair strategies for these kinds of errors are often ineffective due to: (1) the lack of transparency about the state of the system's understanding of the user's utterance; and (2) the system's limited capabilities to understand the user's verbal attempts to repair natural language understanding errors. This paper introduces SOVITE, a new multi-modal speech plus direct manipulation interface that helps users discover, identify the causes of, and recover from conversational breakdowns using the resources of existing mobile app GUIs for grounding. SOVITE displays the system's understanding of user intents using GUI screenshots, allows users to refer to third-party apps and their GUI screens in conversations as inputs for intent disambiguation, and enables users to repair breakdowns using direct manipulation on these screenshots. The results from a remote user study with 10 users using SOVITE in 7 scenarios suggested that SOVITE's approach is usable and effective.},
  isbn = {978-1-4503-7514-6},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/KY5IDJKR/Li et al. - 2020 - Multi-Modal Repairs of Conversational Breakdowns i.pdf}
}

@inproceedings{liSupportingDynamicSituation2013,
  title = {Supporting {{Dynamic Situation Awareness}} in {{Online Group Discussion}}: {{A Visualization Approach}}},
  shorttitle = {Supporting {{Dynamic Situation Awareness}} in {{Online Group Discussion}}},
  booktitle = {2013 46th {{Hawaii International Conference}} on {{System Sciences}}},
  author = {Li, Jia and Zhang, Dongsong and Zhang, Pengzhu},
  date = {2013-01},
  pages = {470--479},
  issn = {1530-1605},
  doi = {10.1109/HICSS.2013.504},
  abstract = {Situation awareness (SA) has been well recognized as a critical yet often elusive foundation for effective group decision-making. The task of identifying and understanding dynamic, evolving discussion situation can be quite challenging, especially when coping with information overload and time pressure. With the wide adoption of collaborative software in support of group collaboration, there has been exponential growth of online group discussion. As a result, the traditional thread-based hierarchical structure and presentation of group messages become ineffective in support of real-time SA, which may affect the process and outcome of group collaboration. To address this important problem, in this study, we propose a novel visualization-based approach to supporting users' SA in online group discussion and decision making. We have also developed a set of new variables to measure SA in online group discussion from three key aspects: discussion snapshot, discussion evolution, and people. The proposed approach was empirically evaluated by using a prototype system and discussion data collected from an online group discussion session. The results show that the proposed approach significantly improves user performance and perception of SA in group discussion. The findings of this study provide significant research contributions and practical implications for the design and use of situation-aware collaborative software.},
  eventtitle = {2013 46th {{Hawaii International Conference}} on {{System Sciences}}},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DRHC42IP/Li et al. - 2013 - Supporting Dynamic Situation Awareness in Online G.pdf;/Users/xinyuech/Zotero/storage/4TA5MHF5/6479890.html}
}

@inproceedings{liuCoArgueFosteringLurkers2023,
  title = {{{CoArgue}} : {{Fostering Lurkers}}’ {{Contribution}} to {{Collective Arguments}} in {{Community-based QA Platforms}}},
  shorttitle = {{{CoArgue}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liu, Chengzhong and Zhou, Shixu and Liu, Dingdong and Li, Junze and Huang, Zeyu and Ma, Xiaojuan},
  date = {2023-04-19},
  pages = {1--17},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580932},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580932},
  urldate = {2023-08-16},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {��������},
  file = {/Users/xinyuech/Zotero/storage/7KD9XIBF/Liu et al. - 2023 - CoArgue  Fostering Lurkers’ Contribution to Colle.pdf}
}

@article{liuConsensUsSupportingMultiCriteria2018,
  title = {{{ConsensUs}}: {{Supporting Multi-Criteria Group Decisions}} by {{Visualizing Points}} of {{Disagreement}}},
  shorttitle = {{{ConsensUs}}},
  author = {Liu, Weichen and Xiao, Sijia and Browne, Jacob T. and Yang, Ming and Dow, Steven P.},
  date = {2018-03-31},
  journaltitle = {ACM Transactions on Social Computing},
  shortjournal = {Trans. Soc. Comput.},
  volume = {1},
  number = {1},
  pages = {1--26},
  issn = {2469-7818, 2469-7826},
  doi = {10.1145/3159649},
  url = {https://dl.acm.org/doi/10.1145/3159649},
  urldate = {2023-03-20},
  abstract = {Groups often face difficulty reaching consensus. For complex decisions with multiple criteria, verbal and written discourse alone may impede groups from pinpointing and moving past fundamental disagreements. To help support consensus building, we introduce ConsensUs, a novel visualization tool that highlights disagreement by asking group members to quantify their subjective opinions across multiple criteria. To evaluate this approach, we conducted a between-subjects experiment with 87 participants on a comparative hiring task. The study compared three modes of sensemaking on a group decision: written discourse only, visualization only, and written discourse plus visualization. We confirmed that the visualization helped participants identify disagreements within the group and then measured subsequent changes to their individual opinions. The results show that disagreement highlighting led participants to align their ratings more with the opinions of other group members. While disagreement highlighting led to better score alignment, participants reported a number of reasons for shifting their score, from genuine consensus to appeasement. We discuss further research angles to understand how disagreement highlighting affects social processes and whether it produces objectively better decisions.},
  langid = {english},
  keywords = {notion}
}

@inproceedings{liuWhatItWants2023,
  title = {“{{What It Wants Me To Say}}”: {{Bridging}} the {{Abstraction Gap Between End-User Programmers}} and {{Code-Generating Large Language Models}}},
  shorttitle = {“{{What It Wants Me To Say}}”},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
  date = {2023-04-19},
  pages = {1--31},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580817},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580817},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/J29Y9SLH/Liu et al. - 2023 - “What It Wants Me To Say” Bridging the Abstractio.pdf}
}

@inproceedings{luReadingQuizMakerHumanNLPCollaborative2023,
  title = {{{ReadingQuizMaker}}: {{A Human-NLP Collaborative System}} That {{Supports Instructors}} to {{Design High-Quality Reading Quiz Questions}}},
  shorttitle = {{{ReadingQuizMaker}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lu, Xinyi and Fan, Simin and Houghton, Jessica and Wang, Lu and Wang, Xu},
  date = {2023-04-19},
  pages = {1--18},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580957},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580957},
  urldate = {2023-08-20},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {������},
  file = {/Users/xinyuech/Zotero/storage/8IIGTE79/Lu et al. - 2023 - ReadingQuizMaker A Human-NLP Collaborative System.pdf}
}

@article{mackenzieWisdomDecisionSupport2006,
  title = {Wisdom, Decision Support and Paradigms of Decision Making},
  author = {Mackenzie, Adrian and Pidd, Michael and Rooksby, John and Sommerville, Ian and Warren, Ian and Westcombe, Mark},
  date = {2006-04-01},
  journaltitle = {European Journal of Operational Research},
  shortjournal = {European Journal of Operational Research},
  volume = {170},
  number = {1},
  pages = {156--171},
  issn = {0377-2217},
  doi = {10.1016/j.ejor.2004.07.041},
  url = {https://www.sciencedirect.com/science/article/pii/S0377221704005107},
  urldate = {2023-08-21},
  abstract = {Many decision support tools have been developed over the last 20 years and, in general, they support what Simon termed substantive rationality. However, such tools are rarely suited to helping people tackle wicked problems, for which a form of procedural rationality is better suited. Procedurally rational approaches have appeared in both management science and computer science, examples being the soft OR approach of cognitive mapping and the design rationale based on IBIS. These approaches are reviewed and the development of Wisdom, a procedurally rational decision support process and accompanying tool, is discussed and evaluated.},
  keywords = {/unread,Cognitive mapping,Decision support,notion,Wicked problems},
  file = {/Users/xinyuech/Zotero/storage/4KER6GVK/Mackenzie et al. - 2006 - Wisdom, decision support and paradigms of decision.pdf;/Users/xinyuech/Zotero/storage/W5AZ4PWB/S0377221704005107.html}
}

@inproceedings{majumderInterviewLargescaleModeling2020,
  title = {Interview: {{Large-scale Modeling}} of {{Media Dialog}} with {{Discourse Patterns}} and {{Knowledge Grounding}}},
  shorttitle = {Interview},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Majumder, Bodhisattwa Prasad and Li, Shuyang and Ni, Jianmo and McAuley, Julian},
  date = {2020-11},
  pages = {8129--8141},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.emnlp-main.653},
  url = {https://aclanthology.org/2020.emnlp-main.653},
  urldate = {2023-06-02},
  abstract = {In this work, we perform the first large-scale analysis of discourse in media dialog and its impact on generative modeling of dialog turns, with a focus on interrogative patterns and use of external knowledge. Discourse analysis can help us understand modes of persuasion, entertainment, and information elicitation in such settings, but has been limited to manual review of small corpora. We introduce **Interview**—a large-scale (105K conversations) media dialog dataset collected from news interview transcripts—which allows us to investigate such patterns at scale. We present a dialog model that leverages external knowledge as well as dialog acts via auxiliary losses and demonstrate that our model quantitatively and qualitatively outperforms strong discourse-agnostic baselines for dialog modeling—generating more specific and topical responses in interview-style conversations.},
  eventtitle = {{{EMNLP}} 2020},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/J3S6ZEX7/Majumder et al. - 2020 - Interview Large-scale Modeling of Media Dialog wi.pdf}
}

@article{menneckeEffectsMediaTask2000,
  title = {The {{Effects}} of {{Media}} and {{Task}} on {{User Performance}}: {{A Test}} of the {{Task-Media Fit Hypothesis}}},
  shorttitle = {The {{Effects}} of {{Media}} and {{Task}} on {{User Performance}}},
  author = {Mennecke, Brian E. and Valacich, Joseph S. and Wheeler, Bradley C.},
  date = {2000-11-01},
  journaltitle = {Group Decision and Negotiation},
  shortjournal = {Group Decision and Negotiation},
  volume = {9},
  number = {6},
  pages = {507--529},
  issn = {1572-9907},
  doi = {10.1023/A:1008770106779},
  url = {https://doi.org/10.1023/A:1008770106779},
  urldate = {2023-08-21},
  abstract = {This research was designed to examine the task-media fit hypothesis, an extension to media richness theory that predicts the objective performance of various media for a number of task types. To examine this model, dyads communicating through face-to-face, videophone, telephone (i.e., audio-only communication), or synchronous computer-mediated communication worked in a laboratory experiment to address an intellective or negotiation task. The intellective task required that each dyad member effectively share factual information that each individual independently held. The negotiation task required that each dyad member effectively share preferences based on personal values and reach an agreement. The results of the study provide mixed support for the task-media fit hypothesis. In general, the results for the negotiation task largely supported the theory while the results for the intellective task did not support the theory. These results help to clarify limitations and provide extensions to the theory by demonstrating how variations in task processes and communication media act to mediate task performance. The implications of these results for future research and practice are discussed.},
  langid = {english},
  keywords = {/unread,data and information sharing,dyads,experimental research,group decision making,media richness theory,media selection,task manipulation},
  file = {/Users/xinyuech/Zotero/storage/BFXEVXEI/Mennecke et al. - 2000 - The Effects of Media and Task on User Performance.pdf}
}

@inproceedings{mentisDevelopmentDecisionRationale2009,
  title = {Development of Decision Rationale in Complex Group Decision Making},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Mentis, Helena M. and Bach, Paula M. and Hoffman, Blaine and Rosson, Mary Beth and Carroll, John M.},
  date = {2009-04-04},
  pages = {1341--1350},
  publisher = {{ACM}},
  location = {{Boston MA USA}},
  doi = {10.1145/1518701.1518904},
  url = {https://dl.acm.org/doi/10.1145/1518701.1518904},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '09: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-246-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/TAU75W2D/Mentis et al. - 2009 - Development of decision rationale in complex group.pdf}
}

@inproceedings{mirowskiCoWritingScreenplaysTheatre2023,
  title = {Co-{{Writing Screenplays}} and {{Theatre Scripts}} with {{Language Models}}: {{Evaluation}} by {{Industry Professionals}}},
  shorttitle = {Co-{{Writing Screenplays}} and {{Theatre Scripts}} with {{Language Models}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Mirowski, Piotr and Mathewson, Kory W. and Pittman, Jaylen and Evans, Richard},
  date = {2023-04-19},
  pages = {1--34},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581225},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581225},
  urldate = {2023-04-27},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/T7MTVQQL/Mirowski et al. - 2023 - Co-Writing Screenplays and Theatre Scripts with La.pdf}
}

@online{mishraPromptAidPromptExploration2023,
  title = {{{PromptAid}}: {{Prompt Exploration}}, {{Perturbation}}, {{Testing}} and {{Iteration}} Using {{Visual Analytics}} for {{Large Language Models}}},
  shorttitle = {{{PromptAid}}},
  author = {Mishra, Aditi and Soni, Utkarsh and Arunkumar, Anjana and Huang, Jinbin and Kwon, Bum Chul and Bryan, Chris},
  date = {2023-04-08},
  eprint = {2304.01964},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.01964},
  urldate = {2023-07-31},
  abstract = {Large Language Models (LLMs) have gained widespread popularity due to their ability to perform ad-hoc Natural Language Processing (NLP) tasks with a simple natural language prompt. Part of the appeal for LLMs is their approachability to the general public, including individuals with no prior technical experience in NLP techniques. However, natural language prompts can vary significantly in terms of their linguistic structure, context, and other semantics. Modifying one or more of these aspects can result in significant differences in task performance. Non-expert users may find it challenging to identify the changes needed to improve a prompt, especially when they lack domain-specific knowledge and lack appropriate feedback. To address this challenge, we present PromptAid, a visual analytics system designed to interactively create, refine, and test prompts through exploration, perturbation, testing, and iteration. PromptAid uses multiple, coordinated visualizations which allow users to improve prompts by using the three strategies: keyword perturbations, paraphrasing perturbations, and obtaining the best set of in-context few-shot examples. PromptAid was designed through an iterative prototyping process involving NLP experts and was evaluated through quantitative and qualitative assessments for LLMs. Our findings indicate that PromptAid helps users to iterate over prompt template alterations with less cognitive overhead, generate diverse prompts with help of recommendations, and analyze the performance of the generated prompts while surpassing existing state-of-the-art prompting interfaces in performance.},
  pubstate = {preprint},
  keywords = {/unread,notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/UHTM6TRT/Mishra et al. - 2023 - PromptAid Prompt Exploration, Perturbation, Testi.pdf;/Users/xinyuech/Zotero/storage/XB4PZ9L8/2304.html}
}

@article{montenegroDialogueActTaxonomyVirtual2019,
  title = {A {{Dialogue-Act Taxonomy}} for a {{Virtual Coach Designed}} to {{Improve}} the {{Life}} of {{Elderly}}},
  author = {Montenegro, César and López Zorrilla, Asier and Mikel Olaso, Javier and Santana, Roberto and Justo, Raquel and Lozano, Jose A. and Torres, María Inés},
  date = {2019-09},
  journaltitle = {Multimodal Technologies and Interaction},
  volume = {3},
  number = {3},
  pages = {52},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2414-4088},
  doi = {10.3390/mti3030052},
  url = {https://www.mdpi.com/2414-4088/3/3/52},
  urldate = {2023-04-24},
  abstract = {This paper presents a dialogue act taxonomy designed for the development of a conversational agent for elderly. The main goal of this conversational agent is to improve life quality of the user by means of coaching sessions in different topics. In contrast to other approaches such as task-oriented dialogue systems and chit-chat implementations, the agent should display a pro-active attitude, driving the conversation to reach a number of diverse coaching goals. Therefore, the main characteristic of the introduced dialogue act taxonomy is its capacity for supporting a communication based on the GROW model for coaching. In addition, the taxonomy has a hierarchical structure between the tags and it is multimodal. We use the taxonomy to annotate a Spanish dialogue corpus collected from a group of elder people. We also present a preliminary examination of the annotated corpus and discuss on the multiple possibilities it presents for further research.},
  issue = {3},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/ERBT5QP8/Montenegro et al. - 2019 - A Dialogue-Act Taxonomy for a Virtual Coach Design.pdf}
}

@article{mullerIndividualPerceptionsShared2020,
  title = {Individual Perceptions of Shared Mental Models of Information and Communication Technology ({{ICT}}) and Virtual Team Coordination and Performance—{{The}} Moderating Role of Flexibility in {{ICT}} Use},
  author = {Müller, Rebecca and Antoni, Conny Herbert},
  date = {2020},
  journaltitle = {Group Dynamics: Theory, Research, and Practice},
  volume = {24},
  pages = {186--200},
  publisher = {{Educational Publishing Foundation}},
  location = {{US}},
  issn = {1930-7802},
  doi = {10.1037/gdn0000130},
  abstract = {Coordination and performance of virtual teams depend on the use of information and communication technology (ICT). Team members use many ICTs to collaborate with each other. Research has shown that shared mental models (SMM) improve team coordination and performance. Based on these results, we expect that for virtual teams, ICT SMM are positively related to team coordination and performance. Specifically, the relationship between ICT SMM and coordination is stronger if virtual team members have less flexibility in ICT use. We expect that ICT SMM explain incremental variance of team coordination and performance beyond teamwork and taskwork SMM. One hundred forty-one employees of two IT companies working in 31 virtual teams participated. Results of multilevel model analyses supported the positive relation between individual perceptions of ICT SMM and team coordination and performance, but not for objective ICT SMM. Results of analyses with aggregated team data indicate the same direction. Results showed that individual perceptions of ICT SMM explained incremental variance of team coordination beyond individual perceptions of teamwork and taskwork SMM. The relation between individual perceptions of ICT SMM and team coordination was moderated by flexibility in ICT use. Individual perceptions of ICT SMM seem to be relevant for virtual teamwork. Longitudinal and experimental studies exploring the differential causal effects of SMM subtypes on team coordination and performance seem to be promising. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {notion}
}

@article{murrayInformationProcessingOverload2019,
  title = {Information {{Processing}} and {{Overload}} in {{Group Conversation}}: {{A Graph-Based Prediction Model}}},
  shorttitle = {Information {{Processing}} and {{Overload}} in {{Group Conversation}}},
  author = {Murray, Gabriel},
  date = {2019-09},
  journaltitle = {Multimodal Technologies and Interaction},
  volume = {3},
  number = {3},
  pages = {46},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2414-4088},
  doi = {10.3390/mti3030046},
  url = {https://www.mdpi.com/2414-4088/3/3/46},
  urldate = {2023-03-21},
  abstract = {Based on analyzing verbal and nonverbal features of small group conversations in a task-based scenario, this work focuses on automatic detection of group member perceptions about how well they are making use of available information, and whether they are experiencing information overload. Both the verbal and nonverbal features are derived from graph-based social network representations of the group interaction. For the task of predicting the information use ratings, a predictive model using random forests with verbal and nonverbal features significantly outperforms baselines in which the mean or median values of the training data are predicted, as well as significantly outperforming a linear regression baseline. For the task of predicting information overload ratings, the multimodal random forests model again outperforms all other models, including significant improvement over linear regression and gradient boosting models. However, on that task the best model is not significantly better than the mean and median baselines. For both tasks, we analyze performance using the full multimodal feature set versus using only linguistic features or only turn-taking features. While utilizing the full feature set yields the best performance in terms of mean squared error (MSE), there are no statistically significant differences, and using only linguistic features gives comparable performance. We provide a detailed analysis of the individual features that are most useful for each task. Beyond the immediate prediction tasks, our more general goal is to represent conversational interaction in such a way that yields a small number of features capturing the group interaction in an easily interpretable manner. The proposed approach is relevant to many other group prediction tasks as well, and is distinct from both classical natural language processing (NLP) as well as more current deep learning/artificial neural network approaches.},
  issue = {3},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/G6PG7KUM/Murray - 2019 - Information Processing and Overload in Group Conve.pdf}
}

@inproceedings{nguyenArgvizInteractiveVisualization2013,
  title = {Argviz: {{Interactive Visualization}} of {{Topic Dynamics}} in {{Multi-party Conversations}}},
  shorttitle = {Argviz},
  booktitle = {Proceedings of the 2013 {{NAACL HLT Demonstration Session}}},
  author = {Nguyen, Viet-An and Hu, Yuening and Boyd-Graber, Jordan and Resnik, Philip},
  date = {2013-06},
  pages = {36--39},
  publisher = {{Association for Computational Linguistics}},
  location = {{Atlanta, Georgia}},
  url = {https://aclanthology.org/N13-3009},
  urldate = {2023-03-22},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/7WI752QP/Nguyen et al. - 2013 - Argviz Interactive Visualization of Topic Dynamic.pdf}
}

@article{nussbaumPuttingPiecesTogether2007,
  title = {Putting the Pieces Together: {{Online}} Argumentation Vee Diagrams Enhance Thinking during Discussions},
  shorttitle = {Putting the Pieces Together},
  author = {Nussbaum, E. Michael and Winsor, Denise L. and Aqui, Yvette M. and Poliquin, Anne M.},
  date = {2007-12-01},
  journaltitle = {International Journal of Computer-Supported Collaborative Learning},
  shortjournal = {Computer Supported Learning},
  volume = {2},
  number = {4},
  pages = {479--500},
  issn = {1556-1615},
  doi = {10.1007/s11412-007-9025-1},
  url = {https://doi.org/10.1007/s11412-007-9025-1},
  urldate = {2023-06-02},
  abstract = {We examine the effect of online Argumentation Vee Diagrams (AVDs) on the quality of students’ argumentation during asynchronous, online discussions. With AVDs, students develop arguments on both sides of a controversial issue and then develop an integrated, overall final conclusion. In this study, students used AVDs individually before composing discussion notes, and then—at the end of the discussion—jointly created a group AVD using Wiki technology. Compared to a control group, the experimental intervention was found to significantly enhance the integration of arguments and counterarguments (specifically, compromises) and fostered opinion change. For AVDs to be effective, however, it was found to be necessary to include specific scaffolds on how to evaluate argument strength and/or to provide practice and feedback in using the AVDs.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DSACAW68/Nussbaum et al. - 2007 - Putting the pieces together Online argumentation .pdf}
}

@inproceedings{oehlModelingGroundingProcesses2010,
  title = {Modeling Grounding Processes in Chat-based CSCL},
  author = {Oehl, Michael and Berwe, Theodor and Wahl, Mathias and Pfister, Hans-Ruediger},
  date = {2010-06-29},
  pages = {3774--3779},
  publisher = {{Association for the Advancement of Computing in Education (AACE)}},
  url = {https://www.learntechlib.org/primary/p/35187/},
  urldate = {2023-03-15},
  abstract = {In the field of computer-supported collaborative learning (CSCL), the grounding theory according to Clark (1996) is widely used to explain how co-construction of knowledge is achieved in learning groups. Communication problems such as incoherence or inadequate coordination are common in simultaneous, text-based chat tools resulting in impaired grounding processes, which again may affect the learning outcomes. Thus collaboration scripts like learning protocols are implemented, increasing the structure of chat discourses in order to reduce communication problems and support grounding...},
  eventtitle = {EdMedia + Innovate Learning},
  isbn = {978-1-880094-81-5},
  langid = {chinese},
  keywords = {notion}
}

@article{okadaEvidenceBasedDialogue2008,
  title = {Evidence‐based {{Dialogue Maps}} as a Research Tool to Investigate the Quality of School Pupils’ Scientific Argumentation},
  author = {Okada, Alexandra and Buckingham Shum, Simon},
  date = {2008-11-01},
  journaltitle = {International Journal of Research \& Method in Education},
  volume = {31},
  number = {3},
  pages = {291--315},
  publisher = {{Routledge}},
  issn = {1743-727X},
  doi = {10.1080/17437270802417184},
  url = {https://doi.org/10.1080/17437270802417184},
  urldate = {2023-08-21},
  abstract = {This pilot study focuses on the potential of Evidence‐based Dialogue Mapping as a participatory action research tool to investigate young teenagers’ scientific argumentation. Evidence‐based Dialogue Mapping is a technique for representing graphically an argumentative dialogue through Questions, Ideas, Pros, Cons and Data. Our research objective is to better understand the usage of Compendium, a Dialogue Mapping software tool, as both (1) a learning strategy to scaffold school pupils’ argumentation, and (2) as a method to investigate the quality of their argumentative essays. The participants were a science teacher‐researcher, a knowledge mapping researcher and 20 pupils, 12–13 years old, in a summer science course for ‘gifted and talented’ children in the UK. This study draws on multiple data sources: discussion forum, science teacher‐researchers’ and pupils’ Dialogue Maps, pupil essays and reflective comments about the uses of mapping for writing. Through qualitative analysis of two case studies, we examine the role of Evidence‐based Dialogue Maps as a mediating tool in scientific reasoning: as conceptual bridges for linking and making knowledge intelligible; as support for the linearization task of generating a coherent document outline; as a reflective aid to rethinking reasoning in response to teacher feedback; and as a visual language for making arguments tangible via cartographic conventions.},
  keywords = {/unread,notion,参与性行动研究,基于证据的对话图,青少年的科学论证},
  file = {/Users/xinyuech/Zotero/storage/ZEZ59AC4/Okada and Buckingham Shum - 2008 - Evidence‐based Dialogue Maps as a research tool to.pdf}
}

@article{osinskiSuccessfulKnowledgeIntegration2019,
  title = {Towards {{Successful Knowledge Integration}} in {{Online Collaboration}}: {{An Experiment}} on the {{Role}} of {{Meta-Knowledge}}},
  shorttitle = {Towards {{Successful Knowledge Integration}} in {{Online Collaboration}}},
  author = {Osinski, Meike and Rummel, Nikol},
  date = {2019-11-07},
  journaltitle = {ACM 人机交互论文集},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  pages = {31:1--31:17},
  doi = {10.1145/3359133},
  url = {https://doi.org/10.1145/3359133},
  urldate = {2023-03-15},
  abstract = {成功的知识整合，即未共享信息的系统综合，是成功的关键，但同时对于具有分布式知识的在线协作团队来说也是一项具有挑战性的冒险。例如，具有异质知识的团队通常对谁知道什么只有模糊甚至错误的想法。如果协作伙伴彼此不认识并且仅在线交流，则情况会更加复杂。先前的研究发现元知识，即关于自己和合作伙伴知识领域的知识，是一种很有前途但尚未得到充分研究的促进知识整合的方法。通过我们的实验研究，我们旨在解决关于元知识在基于网络的协作中的作用的研究的迫切需要。我们“模拟” 通过将特定信息分配给在隐藏配置文件任务中进行双人协作的学生，具有异质知识的合作伙伴之间基于聊天的协作。为了为这项任务找到正确的联合解决方案，合作伙伴必须汇集他们共享的，但更重要的是他们未共享的信息。我们比较了两种情况：在实验条件下，通过向合作伙伴提供彼此角色的自我介绍来促进元知识，这指向他们独特的知识领域，而控制条件下的参与者没有收到此信息。结果表明元知识操作对协作的两个关键因素有积极影响：知识整合和交互记忆系统 (TMS) 的构建。},
  issue = {CSCW},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XIFJ3WDB/Osinski and Rummel - 2019 - Towards Successful Knowledge Integration in Online.pdf}
}

@book{paulusOxfordHandbookGroup2019,
  title = {The {{Oxford Handbook}} of {{Group Creativity}} and {{Innovation}}},
  author = {Paulus, Paul B. and Nijstad, Bernard A.},
  date = {2019-04-30},
  eprint = {BNqUDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Oxford University Press}},
  abstract = {Although creativity is often considered an individual ability or activity, innovation in teams and organizations involves collaboration of people with diverse perspectives, knowledge, and skills. The effective development of collaborative innovations and solutions to problems is critical to the success of teams and organizations, but research has also demonstrated many factors which tend to limit the effectiveness of collaborative innovation of groups and teams. This volume highlights recent theoretical, empirical, and practical developments that provide a solid basis for the practice of collaborative innovation and future research. It draws from a broad range of research perspectives including cognition, social influence, groups, teams, creativity, communication, networks, information systems, organizational psychology, engineering, computer science, and the arts. This volume is an important source of information for students, scholars, practitioners, and others interested in understanding the complexity of the group creative process and tapping the creative potential of groups and teams.},
  isbn = {978-0-19-094253-3},
  langid = {english},
  pagetotal = {401},
  keywords = {notion}
}

@inproceedings{pavelVideoDigestsBrowsable2014,
  title = {Video Digests: A Browsable, Skimmable Format for Informational Lecture Videos},
  shorttitle = {Video Digests},
  booktitle = {Proceedings of the 27th Annual {{ACM}} Symposium on {{User}} Interface Software and Technology},
  author = {Pavel, Amy and Reed, Colorado and Hartmann, Björn and Agrawala, Maneesh},
  date = {2014-10-05},
  pages = {573--582},
  publisher = {{ACM}},
  location = {{Honolulu Hawaii USA}},
  doi = {10.1145/2642918.2647400},
  url = {https://dl.acm.org/doi/10.1145/2642918.2647400},
  urldate = {2023-08-16},
  abstract = {Increasingly, authors are publishing long informational talks, lectures, and distance-learning videos online. However, it is difficult to browse and skim the content of such videos using current timeline-based video players. Video digests are a new format for informational videos that afford browsing and skimming by segmenting videos into a chapter/section structure and providing short text summaries and thumbnails for each section. Viewers can navigate by reading the summaries and clicking on sections to access the corresponding point in the video. We present a set of tools to help authors create such digests using transcript-based interactions. With our tools, authors can manually create a video digest from scratch, or they can automatically generate a digest by applying a combination of algorithmic and crowdsourcing techniques and then manually refine it as needed. Feedback from first-time users suggests that our transcript-based authoring tools and automated techniques greatly facilitate video digest creation. In an evaluative crowdsourced study we find that given a short viewing time, video digests support browsing and skimming better than timeline-based or transcript-based video players.},
  eventtitle = {{{UIST}} '14: {{The}} 27th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-3069-5},
  langid = {english},
  keywords = {����},
  file = {/Users/xinyuech/Zotero/storage/GQQCEX5Z/Pavel et al. - 2014 - Video digests a browsable, skimmable format for i.pdf}
}

@inproceedings{pengSlideGestaltAutomatic2023,
  title = {Slide {{Gestalt}}: {{Automatic Structure Extraction}} in {{Slide Decks}} for {{Non-Visual Access}}},
  shorttitle = {Slide {{Gestalt}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Peng, Yi-Hao and Chi, Peggy and Kannan, Anjuli and Morris, Meredith Ringel and Essa, Irfan},
  date = {2023-04-19},
  pages = {1--14},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580921},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580921},
  urldate = {2023-05-03},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/SKSKMFL4/Peng et al. - 2023 - Slide Gestalt Automatic Structure Extraction in S.pdf}
}

@article{piRelationOpennessCreativity2022,
  title = {The Relation between Openness and Creativity Is Moderated by Attention to Peers’ Ideas in Electronic Brainstorming},
  author = {Pi, Zhongling and Yang, Jiumin and Hu, Weiping and Hong, Jianzhong},
  date = {2022-02-04},
  journaltitle = {Interactive Learning Environments},
  volume = {30},
  number = {2},
  pages = {344--352},
  publisher = {{Routledge}},
  issn = {1049-4820},
  doi = {10.1080/10494820.2019.1655458},
  url = {https://doi.org/10.1080/10494820.2019.1655458},
  urldate = {2023-03-15},
  abstract = {An emerging body of research has focused on students’ creativity in group contexts, with the assumption that students could be inspired by peers’ ideas. Although students’ openness and attention to peers’ ideas are claimed to play important roles in their creativity in group settings, there is little empirical research that tests this assumption. This study examined the moderating effect of attention to peers’ ideas in the relation between openness and creativity in electronic brainstorming. Participants were 91 undergraduate students who took about 10 min to complete a creative idea generation task during electronic brainstorming. Regression analyses found that students who were characterized by high openness were more creative, but only when they showed more attention to peers’ ideas. This suggests that electronic brainstorming can be useful for enhancing the creativity of some students.},
  keywords = {notion}
}

@inproceedings{reitmaierSituatingAutomaticSpeech2023,
  title = {Situating {{Automatic Speech Recognition Development}} within {{Communities}} of {{Under-heard Language Speakers}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Reitmaier, Thomas and Wallington, Electra and Klejch, Ondřej and Markl, Nina and Lam-Yee-Mui, Léa-Marie and Pearson, Jennifer and Jones, Matt and Bell, Peter and Robinson, Simon},
  date = {2023-04-19},
  pages = {1--17},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581385},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581385},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/LJA7Q8KR/Reitmaier et al. - 2023 - Situating Automatic Speech Recognition Development.pdf}
}

@inproceedings{rongUnderstandingPersonalData2023,
  title = {Understanding {{Personal Data Tracking}} and {{Sensemaking Practices}} for {{Self-Directed Learning}} in {{Non-classroom}} and {{Non-computer-based Contexts}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Rong, Ethan Z. and Zhou, Mo Morgana and Gao, Ge and Lu, Zhicong},
  date = {2023-04-19},
  pages = {1--16},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581364},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581364},
  urldate = {2023-05-03},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/YKUJ9ADT/Rong et al. - 2023 - Understanding Personal Data Tracking and Sensemaki.pdf}
}

@inproceedings{sarkarKGCRuSERecurrentWalks2022,
  title = {{{KG-CRuSE}}: {{Recurrent Walks}} over {{Knowledge Graph}} for {{Explainable Conversation Reasoning}} Using {{Semantic Embeddings}}},
  shorttitle = {{{KG-CRuSE}}},
  booktitle = {Proceedings of the 4th {{Workshop}} on {{NLP}} for {{Conversational AI}}},
  author = {Sarkar, Rajdeep and Arcan, Mihael and McCrae, John},
  date = {2022},
  pages = {98--107},
  publisher = {{Association for Computational Linguistics}},
  location = {{Dublin, Ireland}},
  doi = {10.18653/v1/2022.nlp4convai-1.9},
  url = {https://aclanthology.org/2022.nlp4convai-1.9},
  urldate = {2023-05-11},
  abstract = {Knowledge-grounded dialogue systems utilise external knowledge such as knowledge graphs to generate informative and appropriate responses. A crucial challenge of such systems is to select facts from a knowledge graph pertinent to the dialogue context for response generation. This fact selection can be formulated as path traversal over a knowledge graph conditioned on the dialogue context. Such paths can originate from facts mentioned in the dialogue history and terminate at the facts to be mentioned in the response. These walks, in turn, provide an explanation of the flow of the conversation. This work proposes KG-CRUSE, a simple, yet effective LSTM based decoder that utilises the semantic information in the dialogue history and the knowledge graph elements to generate such paths for effective conversation explanation. Extensive evaluations showed that our model outperforms the stateof-the-art models on the OpenDialKG dataset on multiple metrics.},
  eventtitle = {Proceedings of the 4th {{Workshop}} on {{NLP}} for {{Conversational AI}}},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4AV7WHWJ/Sarkar et al. - 2022 - KG-CRuSE Recurrent Walks over Knowledge Graph for.pdf}
}

@inproceedings{sasakiReachingFinalConsensus2020,
  title = {Reaching a {{Final Consensus}} in a {{Discussion}}: The {{Impact}} of {{Real-time Intention Expression Related}} to {{Categories}}},
  shorttitle = {Reaching a {{Final Consensus}} in a {{Discussion}}},
  booktitle = {2020 13th {{International Conference}} on {{Human System Interaction}} ({{HSI}})},
  author = {Sasaki, Chihiro and Oshima, Chika and Kajihara, Shin and Nakayama, Koichi},
  date = {2020-06},
  pages = {106--111},
  issn = {2158-2254},
  doi = {10.1109/HSI49210.2020.9142630},
  abstract = {A facilitator is effective for ensuring smooth and appropriate decision-making in group discussions. In this study, we developed the “Discussion Board System” for the purpose of reproducing a part of the facilitator's function and grasping the intentions of discussion participants in real time. Each discussion participant had their own terminal on which the application was installed. The participants could show the agreement or disagreement with each keyword extracted from the other participants' utterances by moving the keywords to item boxes on their individual screens. The movements of the keywords were not visible to other participants before the discussion was over, thus each participant's screen could be considered a “semi-personal space.” In an experiment using the system, the progress and decisions of all participants were compared with each individual participant's intentions, as shown by their moving of keywords. A final decision could include the intentions of a “silent denier,” which is difficult to elicit in consideration of human relationships during typical discussions. Moreover, even though the screens were not shared among participants, the moving of each keyword to the item box could be regarded as a simple approval action of the participant's opinion. Thus, one of the positive effects of a facilitator, “fostering a sense of satisfaction” among participants, may be realized by the system.},
  eventtitle = {2020 13th {{International Conference}} on {{Human System Interaction}} ({{HSI}})},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/URDKI9DM/Sasaki et al. - 2020 - Reaching a Final Consensus in a Discussion the Im.pdf}
}

@inproceedings{satoGroupnamicsDesigningInterface2023,
  title = {Groupnamics: {{Designing}} an {{Interface}} for {{Overviewing}} and {{Managing Parallel Group Discussions}} in an {{Online Classroom}}},
  shorttitle = {Groupnamics},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Sato, Arissa J. and Sramek, Zefan and Yatani, Koji},
  date = {2023-04-19},
  pages = {1--18},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581322},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581322},
  urldate = {2023-08-16},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {��������},
  file = {/Users/xinyuech/Zotero/storage/GGHVPNHS/Sato et al. - 2023 - Groupnamics Designing an Interface for Overviewin.pdf}
}

@article{schelbleLetThinkTogether2022,
  title = {Let's {{Think Together}}! {{Assessing Shared Mental Models}}, {{Performance}}, and {{Trust}} in {{Human-Agent Teams}}},
  author = {Schelble, Beau G. and Flathmann, Christopher and McNeese, Nathan J. and Freeman, Guo and Mallick, Rohit},
  date = {2022-01-14},
  journaltitle = {Proc. ACM Hum.-Comput. Interact.},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {13:1--13:29},
  doi = {10.1145/3492832},
  url = {https://doi.org/10.1145/3492832},
  urldate = {2023-03-15},
  issue = {GROUP},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/U7V84X7U/Schelble et al. - 2022 - Let's Think Together! Assessing Shared Mental Mode.pdf}
}

@article{schmittCognitiveOverloadDigital2021,
  title = {From Cognitive Overload to Digital Detox: {{Psychological}} Implications of Telework during the {{COVID-19}} Pandemic},
  shorttitle = {From Cognitive Overload to Digital Detox},
  author = {Schmitt, Josephine B. and Breuer, Johannes and Wulf, Tim},
  date = {2021-11-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {124},
  pages = {106899},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106899},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563221002223},
  urldate = {2023-03-21},
  abstract = {For most people, telework during the COVID-19 pandemic necessitates the increased use of digital tools. Although working from home can enhance flexibility, it comes with various psychological challenges, all of which can be substantially exacerbated for people during the COVID-19 pandemic. The increased need to use digital tools can create cognitive overload that may negatively impact work productivity and well-being. The idea of digital detox has received increasing attention in the last few years as a means for recovering from stress caused by the use of digital media. This paper presents an analysis of the relationships between the use of digital work tools, the feeling of cognitive overload, digital detox measures, perceived work performance, and well-being. Results from an online survey (N~=~403) conducted during the period of strict lockdown measures in Germany in April and May 2020 indicate that the relationship between the use of text-based tools and well-being, but not perceived job performance, is mediated by cognitive overload. These relationships were not found for the use of videoconferencing tools. However, for users of these tools, the number of digital detox measures moderates the relationship between cognitive overload and the perception of work demands.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/3MD2P6GU/Schmitt et al. - 2021 - From cognitive overload to digital detox Psycholo.pdf;/Users/xinyuech/Zotero/storage/Z9HBHB3I/S0747563221002223.html}
}

@article{schnaubertGroupAwarenessRegulation2022,
  title = {Group Awareness and Regulation in Computer-Supported Collaborative Learning},
  author = {Schnaubert, Lenka and Bodemer, Daniel},
  date = {2022-03-01},
  journaltitle = {International Journal of Computer-Supported Collaborative Learning},
  shortjournal = {Intern. J. Comput.-Support. Collab. Learn},
  volume = {17},
  number = {1},
  pages = {11--38},
  issn = {1556-1615},
  doi = {10.1007/s11412-022-09361-1},
  url = {https://doi.org/10.1007/s11412-022-09361-1},
  urldate = {2022-11-02},
  abstract = {Group awareness is of critical relevance for collaborative learning and interaction and is thus often referred to in CSCL research. However, the concept is only vaguely defined as some kind of understanding or perception of characteristics of learning partners or the collaborating group. Most CSCL research activities concerned with group awareness aim at modifying learners' awareness using so-called group awareness tools. However, there are much less attempts to measure group awareness and to conceptualize its formation. Thus, building on existing group awareness research, this article derives a conceptualization with six defining aspects of group awareness: (1) group awareness is cognitive, (2) group awareness is conscious, (3) group awareness is current, (4) group awareness is individual, (5) group awareness is social, and (6) group awareness is perceived as valid. Additionally, while it is often assumed that group awareness builds on self-regulatory skills, its role in regulating behavior and cognition within a social context is seldom explored. Thus, this article aims at defining and analyzing the concept of group awareness, specifying its relation to regulatory processes, and sketching possible research paths whilst building on, complementing, and informing tool-driven research.},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/LKHMB67E/Schnaubert and Bodemer - 2022 - Group awareness and regulation in computer-support.pdf}
}

@inproceedings{schumannSupportingInitialTrust2012,
  title = {Supporting Initial Trust in Distributed Idea Generation and Idea Evaluation},
  booktitle = {Proceedings of the 2012 {{ACM International Conference}} on {{Supporting Group Work}}},
  author = {Schumann, Jana and Shih, Patrick C. and Redmiles, David F. and Horton, Graham},
  date = {2012-10-27},
  series = {{{GROUP}} '12},
  pages = {199--208},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2389176.2389207},
  url = {https://doi.org/10.1145/2389176.2389207},
  urldate = {2023-03-14},
  abstract = {先前的研究表明，分布式协作团队内部的多样性可以带来创新，但必须存在信任才能公开表达创新思想并建立思想可信度。最初的信任对于团队成员从未面对面并且只有非常有限的时间来完成任务的分布式团队至关重要。我们的目标是确定了解其他团队成员的具体信息是否可以增强最初的信任并提高创意生成和创意评估会议的生产力和满意度。在一项实验中，我们表明通过呈现相关信息元素（例如领域专业知识和个人爱好）可以成功增强认知和情感信任，并且可以对想法生成会议中想法的质量和数量以及参与者对想法评估会议中的评级结果的满意度产生积极影响。然而，接收个人信息的参与者常常将其误解为专业能力。我们还描述了在想法生成会议中观察到的性别差异，并讨论如何更好地设计未来系统以支持想法生成和想法评估活动。},
  isbn = {978-1-4503-1486-2},
  keywords = {notion}
}

@inproceedings{shinChatbotsFacilitatingConsensusBuilding2022,
  title = {Chatbots {{Facilitating Consensus-Building}} in {{Asynchronous Co-Design}}},
  booktitle = {The 35th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Shin, Joongi and Hedderich, Michael A. and Lucero, AndréS and Oulasvirta, Antti},
  date = {2022-10-29},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Bend OR USA}},
  doi = {10.1145/3526113.3545671},
  url = {https://dl.acm.org/doi/10.1145/3526113.3545671},
  urldate = {2023-03-21},
  eventtitle = {{{UIST}} '22: {{The}} 35th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-9320-1},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/RKLGG7CJ/Shin et al. - 2022 - Chatbots Facilitating Consensus-Building in Asynch.pdf}
}

@article{shinIntegratingAIHumanHuman2023,
  title = {Integrating {{AI}} in {{Human-Human Collaborative Ideation}}},
  author = {Shin, Joongi and Koch, Janin and Lucero, Andrés and Dalsgaard, Peter and Mackay, Wendy E},
  date = {2023},
  abstract = {People can generate more innovative ideas when they collaborate with one another, collectively exploring ideas and exchanging viewpoints. Advancements in artificial intelligence have opened up new opportunities in people’s creative activities where individual users ideate with diverse forms of AI. For instance, AI agents and intelligent tools have been designed as ideation partners that provide inspiration, suggest ideation methods, or generate alternative ideas. However, what AI can bring to collaborative ideation among a group of users has not been fully understood. Compared to ideating with individuals, ideating with multiple users would require understanding users’ social interaction, transforming individual efforts into a group effort, and—in the end—making users satisfied that they collaborated with other group members. This workshop aims to bring together a community of researchers and practitioners to explore the integration of AI in human-human collaborative ideation. The exploration will center around identifying the potential roles of AI as well as the process and form of collaborative ideation, considering what users want to do with AI or humans.},
  langid = {english},
  keywords = {����,notion},
  file = {/Users/xinyuech/Zotero/storage/DEEL9547/Shin et al. - 2023 - Integrating AI in Human-Human Collaborative Ideati.pdf}
}

@inproceedings{shinIntroBotExploringUse2023,
  title = {{{IntroBot}}: {{Exploring}} the {{Use}} of {{Chatbot-assisted Familiarization}} in {{Online Collaborative Groups}}},
  shorttitle = {{{IntroBot}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Shin, Donghoon and Kim, Soomin and Shang, Ruoxi and Lee, Joonhwan and Hsieh, Gary},
  date = {2023-04-19},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580930},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580930},
  urldate = {2023-08-16},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,��������},
  file = {/Users/xinyuech/Zotero/storage/9HK9M8BT/Shin et al. - 2023 - IntroBot Exploring the Use of Chatbot-assisted Fa.pdf}
}

@article{shumHypermediaSupportArgumentation,
  title = {5 {{Hypermedia Support}} for {{Argumentation-}}},
  author = {Shum, S J Buckingham and Selvin, A M and Sierhuis, M and Conklin, J and Haley, C B and Nuseibeh, B},
  abstract = {Having developed, used and evaluated some of the early IBISbased approaches to design rationale (DR) such as gIBIS and QOC in the late 1980s/mid-1990s, we describe the subsequent evolution of the argumentation-based paradigm through software support, and perspectives drawn from modeling and meeting facilitation. Particular attention is given to the challenge of negotiating the overheads of capturing this form of rationale. Our approach has maintained a strong emphasis on keeping the representational scheme as simple as possible to enable real time meeting mediation and capture, attending explicitly to the skills required to use the approach well, particularly for the sort of participatory, multistakeholder requirements analysis demanded by many design problems. However, we can then specialize the notation and the way in which the tool is used in the service of specific methodologies, supported by a customizable hypermedia environment, and interoperable with other software tools. After presenting this approach, called Compendium, we present examples to illustrate the capabilities for support security argumentation in requirements engineering, template driven modeling for document generation, and IBIS-based indexing of and navigation around video records of meetings.},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/CCI8XHIW/Shum et al. - 5 Hypermedia Support for Argumentation-.pdf}
}

@inproceedings{siangliulueCollaborativeIdeationScale2015,
  title = {Toward {{Collaborative Ideation}} at {{Scale}}: {{Leveraging Ideas}} from {{Others}} to {{Generate More Creative}} and {{Diverse Ideas}}},
  shorttitle = {Toward {{Collaborative Ideation}} at {{Scale}}},
  booktitle = {Proceedings of the 18th {{ACM Conference}} on {{Computer Supported Cooperative Work}} \& {{Social Computing}}},
  author = {Siangliulue, Pao and Arnold, Kenneth C. and Gajos, Krzysztof Z. and Dow, Steven P.},
  date = {2015-02-28},
  pages = {937--945},
  publisher = {{ACM}},
  location = {{Vancouver BC Canada}},
  doi = {10.1145/2675133.2675239},
  url = {https://dl.acm.org/doi/10.1145/2675133.2675239},
  urldate = {2023-03-16},
  abstract = {A growing number of large collaborative idea generation platforms promise that by generating ideas together, people can create better ideas than any would have alone. But how might these platforms best leverage the number and diversity of contributors to help each contributor generate even better ideas? Prior research suggests that seeing particularly creative or diverse ideas from others can inspire you, but few scalable mechanisms exist to assess diversity. We contribute a new scalable crowd-powered method for evaluating the diversity of sets of ideas. The method relies on similarity comparisons (is idea A more similar to B or C?) generated by non-experts to create an abstract spatial idea map. Our validation study reveals that human raters agree with the estimates of dissimilarity derived from our idea map as much or more than they agree with each other. People seeing the diverse sets of examples from our idea map generate more diverse ideas than those seeing randomly selected examples. Our results also corroborate findings from prior research showing that people presented with creative examples generated more creative ideas than those who saw a set of random examples. We see this work as a step toward building more effective online systems for supporting large scale collective ideation.},
  eventtitle = {{{CSCW}} '15: {{Computer Supported Cooperative Work}} and {{Social Computing}}},
  isbn = {978-1-4503-2922-4},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/LCR8S4UE/Siangliulue et al. - 2015 - Toward Collaborative Ideation at Scale Leveraging.pdf}
}

@inproceedings{siangliulueIdeaHoundImprovingLargescale2016,
  title = {{{IdeaHound}}: {{Improving Large-scale Collaborative Ideation}} with {{Crowd-Powered Real-time Semantic Modeling}}},
  shorttitle = {{{IdeaHound}}},
  booktitle = {Proceedings of the 29th {{Annual Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Siangliulue, Pao and Chan, Joel and Dow, Steven P. and Gajos, Krzysztof Z.},
  date = {2016-10-16},
  pages = {609--624},
  publisher = {{ACM}},
  location = {{Tokyo Japan}},
  doi = {10.1145/2984511.2984578},
  url = {https://dl.acm.org/doi/10.1145/2984511.2984578},
  urldate = {2023-03-21},
  eventtitle = {{{UIST}} '16: {{The}} 29th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-4189-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/B4YRSKWW/Siangliulue et al. - 2016 - IdeaHound Improving Large-scale Collaborative Ide.pdf}
}

@inproceedings{siangliulueProvidingTimelyExamples2015,
  title = {Providing {{Timely Examples Improves}} the {{Quantity}} and {{Quality}} of {{Generated Ideas}}},
  booktitle = {Proceedings of the 2015 {{ACM SIGCHI Conference}} on {{Creativity}} and {{Cognition}}},
  author = {Siangliulue, Pao and Chan, Joel and Gajos, Krzysztof Z. and Dow, Steven P.},
  date = {2015-06-22},
  pages = {83--92},
  publisher = {{ACM}},
  location = {{Glasgow United Kingdom}},
  doi = {10.1145/2757226.2757230},
  url = {https://dl.acm.org/doi/10.1145/2757226.2757230},
  urldate = {2023-05-08},
  eventtitle = {C\&{{C}} '15: {{Creativity}} and {{Cognition}}},
  isbn = {978-1-4503-3598-0},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/FK68P7GC/Siangliulue et al. - 2015 - Providing Timely Examples Improves the Quantity an.pdf}
}

@inproceedings{smithVisualizationComponentsPersistent2001,
  title = {Visualization Components for Persistent Conversations},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Smith, Marc A. and Fiore, Andrew T.},
  date = {2001-03},
  pages = {136--143},
  publisher = {{ACM}},
  location = {{Seattle Washington USA}},
  doi = {10.1145/365024.365073},
  url = {https://dl.acm.org/doi/10.1145/365024.365073},
  urldate = {2023-05-08},
  eventtitle = {{{CHI01}}: {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-58113-327-1},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/72TPW58F/Smith and Fiore - 2001 - Visualization components for persistent conversati.pdf}
}

@online{songUnderstandingPeopleNeeds2023,
  title = {Understanding People's Needs in Viewing Diverse Social Opinions about Controversial Topics},
  author = {Song, Hayeong and Qi, Zhengyang and Stasko, John and Yang, Diyi},
  date = {2023-04-23},
  eprint = {2304.11561},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.1109/PacificVis56936.2023.00008},
  url = {http://arxiv.org/abs/2304.11561},
  urldate = {2023-04-27},
  abstract = {Social media (i.e., Reddit) users are overloaded with people's opinions when viewing discourses about divisive topics. Traditional user interfaces in such media present those opinions in a linear structure, which can limit users in viewing diverse social opinions at scale. Prior work has recognized this limitation, that the linear structure can reinforce biases, where a certain point of view becomes widespread simply because many viewers seem to believe it. This limitation can make it difficult for users to have a truly conversational mode of mediated discussion. Thus, when designing a user interface for viewing people's opinions, we should consider ways to mitigate selective exposure to information and polarization of opinions. We conducted a needs-finding study with 11 Reddit users, who follow climate change threads and make posts and comments regularly. In the study, we aimed to understand key limitations in people viewing online controversial discourses and to extract design implications to address these problems. Our findings discuss potential future directions to address these problems.},
  pubstate = {preprint},
  keywords = {��,notion},
  file = {/Users/xinyuech/Zotero/storage/HPPHYWI8/Song et al. - 2023 - Understanding people's needs in viewing diverse so.pdf;/Users/xinyuech/Zotero/storage/LEPLV6KJ/2304.html}
}

@inproceedings{amershi2019guidelines,
  title={Guidelines for human-AI interaction},
  author={Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N and Inkpen, Kori and others},
  booktitle={Proceedings of the 2019 chi conference on human factors in computing systems},
  pages={1--13},
  year={2019}
}

@inproceedings{sonItOkayBe2023,
  title = {It Is {{Okay}} to Be {{Distracted}}: {{How Real-time Transcriptions Facilitate Online Meeting}} with {{Distraction}}},
  shorttitle = {It Is {{Okay}} to Be {{Distracted}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Son, Seoyun and Choi, Junyoug and Lee, Sunjae and Song, Jean Y and Shin, Insik},
  date = {2023-04-19},
  pages = {1--19},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580742},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580742},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/2TIHKV9H/Son et al. - 2023 - It is Okay to be Distracted How Real-time Transcr.pdf}
}

@article{stewartSayYouSay2019,
  title = {I {{Say}}, {{You Say}}, {{We Say}}: {{Using Spoken Language}} to {{Model Socio-Cognitive Processes}} during {{Computer-Supported Collaborative Problem Solving}}},
  shorttitle = {I {{Say}}, {{You Say}}, {{We Say}}},
  author = {Stewart, Angela E.B. and Vrzakova, Hana and Sun, Chen and Yonehiro, Jade and Stone, Cathlyn Adele and Duran, Nicholas D. and Shute, Valerie and D'Mello, Sidney K.},
  date = {2019-11-07},
  journaltitle = {ACM 人机交互论文集},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  pages = {194:1--194:19},
  doi = {10.1145/3359296},
  url = {https://dl.acm.org/doi/10.1145/3359296},
  urldate = {2023-03-24},
  issue = {CSCW},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/UJPYJ73A/Stewart et al. - 2019 - I Say, You Say, We Say Using Spoken Language to M.pdf}
}

@article{stolckeDialogueActModeling,
  title = {Dialogue {{Act Modeling}} for {{Automatic Tagging}} and {{Recognition}} of {{Conversational Speech}}},
  author = {Stolcke, Andreas and Coccaro, Noah and Bates, Rebecca and Taylor, Paul},
  journaltitle = {Computational Linguistics},
  volume = {26},
  number = {3},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/TE2S7N43/Stolcke et al. - Dialogue Act Modeling for Automatic Tagging and Re.pdf}
}

@online{suhSensecapeEnablingMultilevel2023,
  title = {Sensecape: {{Enabling Multilevel Exploration}} and {{Sensemaking}} with {{Large Language Models}}},
  shorttitle = {Sensecape},
  author = {Suh, Sangho and Min, Bryan and Palani, Srishti and Xia, Haijun},
  date = {2023-05-19},
  eprint = {2305.11483},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.11483},
  urldate = {2023-08-16},
  abstract = {People are increasingly turning to large language models (LLMs) for complex information tasks like academic research or planning a move to another city. However, while they often require working in a nonlinear manner - e.g., to arrange information spatially to organize and make sense of it, current interfaces for interacting with LLMs are generally linear to support conversational interaction. To address this limitation and explore how we can support LLM-powered exploration and sensemaking, we developed Sensecape, an interactive system designed to support complex information tasks with an LLM by enabling users to (1) manage the complexity of information through multilevel abstraction and (2) seamlessly switch between foraging and sensemaking. Our within-subject user study reveals that Sensecape empowers users to explore more topics and structure their knowledge hierarchically. We contribute implications for LLM-based workflows and interfaces for information tasks.},
  pubstate = {preprint},
  keywords = {❤️❤️❤️❤️❤️,Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction},
  file = {/Users/xinyuech/Zotero/storage/PZ9ZN7NV/Suh et al. - 2023 - Sensecape Enabling Multilevel Exploration and Sen.pdf;/Users/xinyuech/Zotero/storage/X3M756S6/2305.html}
}

@article{sunHowStudentsGenerate2022,
  title = {How Do Students Generate Ideas Together in Scientific Creativity Tasks through Computer-Based Mind Mapping?},
  author = {Sun, Meng and Wang, Minhong and Wegerif, Rupert and Peng, Jun},
  date = {2022-01-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {176},
  pages = {104359},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2021.104359},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131521002360},
  urldate = {2023-03-15},
  abstract = {Creativity is widely described as a key ‘21st Century skill’. Science education in schools has emphasized the development of science inquiry and problem-solving skills with the support of technology, and paid insufficient attention to creative thinking skills for producing innovative ideas or solutions. This paper presents an exploratory study aiming to investigate how secondary school students engage in scientific creativity tasks with the support of technology, in particular how they generate ideas in small groups via applying relevant thinking strategies, engaging in social communication, and constructing a computer-based mind map to facilitate group thinking. The participants were 24 Grade 11 students from a high school, who worked on a set of scientific creativity tasks in 6 groups. Epistemic network analysis of group conversations reveals that constructing a mind map helped students to retain ideas for elaboration and evaluation, stimulate new threads of discussion, and regulate task progression. Compared to low-performing groups, high-performing groups engaged more in divergent thinking, mind mapping, and regulative discussions, in addition to making these activities more closely connected with idea generation. These findings have implications for the design of technology-supported educational interventions intended to promote and improve group creativity in science education.},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/8PI9EVJ8/Sun et al. - 2022 - How do students generate ideas together in scienti.pdf;/Users/xinyuech/Zotero/storage/N6IRNPNW/S0360131521002360.html}
}

@inproceedings{tangConceptGuideSupportingOnline2021,
  title = {{{ConceptGuide}}: {{Supporting Online Video Learning}} with {{Concept Map-based Recommendation}} of {{Learning Path}}},
  shorttitle = {{{ConceptGuide}}},
  booktitle = {Proceedings of the {{Web Conference}} 2021},
  author = {Tang, Chien-Lin and Liao, Jingxian and Wang, Hao-Chuan and Sung, Ching-Ying and Lin, Wen-Chieh},
  date = {2021-04-19},
  pages = {2757--2768},
  publisher = {{ACM}},
  location = {{Ljubljana Slovenia}},
  doi = {10.1145/3442381.3449808},
  url = {https://dl.acm.org/doi/10.1145/3442381.3449808},
  urldate = {2023-05-23},
  eventtitle = {{{WWW}} '21: {{The Web Conference}} 2021},
  isbn = {978-1-4503-8312-7},
  langid = {english},
  file = {/Users/xinyuech/Zotero/storage/8A7W2BGB/Tang et al. - 2021 - ConceptGuide Supporting Online Video Learning wit.pdf}
}

@article{thomasVisualizingConversationsGroup2020,
  title = {Visualizing Conversations {{In}} Group Therapy: Developing a Tool to Visualize Conversations and Improve Therapist Skills.},
  shorttitle = {Visualizing Conversations {{In}} Group Therapy},
  author = {Thomas, Libby},
  date = {2020},
  url = {https://repository.library.northeastern.edu/files/neu:bz60mb52t},
  urldate = {2023-04-24},
  abstract = {Society has a growing need for trained, insightful therapists. Group therapy is a popular and effective form of psychiatric treatment but documenting and reviewing large amounts of information from long group sessions is time-consuming, both for therapists and their supervisors. The increased availability and accuracy of automatically generated session transcripts gives designers an opportunity to design tools that smooth the way to clearer insight for therapists and improved care for patients. This thesis introduces prototypes for a visualization tool to help therapists and their supervisors explore patterns, conversation topics, dynamics in group therapy. The tool will allow users to search session transcripts, view outcome trends for individuals and groups, and visualize group dynamics over time. It is my hope that the work presented in this thesis will not only be considered in the context of mental healthcare, but will serve as a springboard for designers to experiment and visualize group conversations in a variety of contexts. Funding for the preparation of this thesis was provided by the National Institute of Mental Health under award 1-R56-MH-118550-01.--Author's abstract},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/N6QKX5AH/Thomas - 2020 - Visualizing conversations In group therapy develo.pdf}
}
@inproceedings{bexheti2016measuring,
  title={Measuring the effect of cued recall on work meetings},
  author={Bexheti, Agon and Niforatos, Evangelos and Bahrainian, Seyed Ali and Langheinrich, Marc and Crestani, Fabio},
  booktitle={Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
  pages={1020--1026},
  year={2016}
}

@article{bostrom1993group,
  title={Group facilitation and group support systems},
  author={Bostrom, Robert P and Anson, Robert and Clawson, Vikki K},
  journal={Group support systems: New perspectives},
  volume={8},
  pages={146--168},
  year={1993},
  publisher={Macmillan New York}
}

@article{reilly2011groupnotes,
  title={GroupNotes: encouraging proactive student engagement in lectures through collaborative note-taking on smartphones},
  author={Reilly, Mark and Shen, Haifeng},
  year={2011},
  publisher={International Society of the Learning Sciences}
}

@inproceedings{macaulay2005facilitation,
  title={Facilitation of e-meetings: State-of-the-art review},
  author={Macaulay, Linda A and Alabdulkarim, Aref},
  booktitle={2005 IEEE International Conference on e-Technology, e-Commerce and e-Service},
  pages={728--735},
  year={2005},
  organization={IEEE}
}

@inproceedings{conklin2001facilitated,
  title={Facilitated hypertext for collective sensemaking: 15 years on from gIBIS},
  author={Conklin, Jeff and Selvin, Albert and Buckingham Shum, Simon and Sierhuis, Maarten},
  booktitle={Proceedings of the 12th ACM conference on Hypertext and Hypermedia},
  pages={123--124},
  year={2001}
}

@incollection{dillenbourg2007designing,
  title={Designing integrative scripts},
  author={Dillenbourg, Pierre and Jermann, Patrick},
  booktitle={Scripting computer-supported collaborative learning: Cognitive, computational and educational perspectives},
  pages={275--301},
  year={2007},
  publisher={Springer}
}

@article{kobbe2007specifying,
  title={Specifying computer-supported collaboration scripts},
  author={Kobbe, Lars and Weinberger, Armin and Dillenbourg, Pierre and Harrer, Andreas and H{\"a}m{\"a}l{\"a}inen, Raija and H{\"a}kkinen, P{\"a}ivi and Fischer, Frank},
  journal={International Journal of Computer-Supported Collaborative Learning},
  volume={2},
  pages={211--224},
  year={2007},
  publisher={Springer}
}
@article{xu2022semantic,
  title={Semantic Navigation of PowerPoint-Based Lecture Video for AutoNote Generation},
  author={Xu, Chengpei and Jia, Wenjing and Wang, Ruomei and He, Xiangjian and Zhao, Baoquan and Zhang, Yuanfang},
  journal={IEEE Transactions on Learning Technologies},
  volume={16},
  number={1},
  pages={1--17},
  year={2022},
  publisher={IEEE}
}

@article{valkIdeationCompassSupporting2022,
  title = {The {{Ideation Compass}}: Supporting Interdisciplinary Creative Dialogues with Real Time Visualization},
  shorttitle = {The {{Ideation Compass}}},
  author = {Välk, Sander and Thabsuwan, Chitipat and Mougenot, Céline},
  date = {2022-11-21},
  journaltitle = {International Journal of Design Creativity and Innovation},
  volume = {0},
  number = {0},
  pages = {1--18},
  publisher = {{Taylor \& Francis}},
  issn = {2165-0349},
  doi = {10.1080/21650349.2022.2142674},
  url = {https://doi.org/10.1080/21650349.2022.2142674},
  urldate = {2023-03-16},
  abstract = {This study presents the potential of live topic visualization in supporting creative dialogs during remote idea generation. We developed a novel Creativity Support Tool (CST) to explore the effects of the live topic visualization. The tool emphasizes the interdisciplinary knowledge background of participants. Using Natural Language Processing (NLP) and topic modeling, the tool provides users with a live visual mapping of the domains and topics being orally discussed. To understand the tool’s user perceived effects, we conducted evaluation sessions and interviews with participants (N = 10) from two different disciplinary backgrounds: design and bioscience. The findings show that live visualization of domains and topics supported self-reflection during individual and collaborative creativity and encouraged a balanced discussion, which can mitigate discipline-based fixation in ideation.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/TGFDG8N7/Välk et al. - 2022 - The Ideation Compass supporting interdisciplinary.pdf}
}

@inproceedings{viegasStudyingCooperationConflict2004,
  title = {Studying Cooperation and Conflict between Authors with {\emph{History Flow}} Visualizations},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Viégas, Fernanda B. and Wattenberg, Martin and Dave, Kushal},
  date = {2004-04-25},
  pages = {575--582},
  publisher = {{ACM}},
  location = {{Vienna Austria}},
  doi = {10.1145/985692.985765},
  url = {https://dl.acm.org/doi/10.1145/985692.985765},
  urldate = {2023-04-06},
  eventtitle = {{{CHI04}}: {{CHI}} 2004 {{Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-58113-702-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/EZCNK3J2/Viégas et al. - 2004 - Studying cooperation and conflict between authors .pdf}
}

@inproceedings{wangCallistoCapturingWhy2020,
  title = {Callisto: {{Capturing}} the "{{Why}}" by {{Connecting Conversations}} with {{Computational Narratives}}},
  shorttitle = {Callisto},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wang, April Yi and Wu, Zihan and Brooks, Christopher and Oney, Steve},
  date = {2020-04-21},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Honolulu HI USA}},
  doi = {10.1145/3313831.3376740},
  url = {https://dl.acm.org/doi/10.1145/3313831.3376740},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '20: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-6708-0},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/GXSQSBW3/Wang et al. - 2020 - Callisto Capturing the Why by Connecting Conver.pdf}
}

@inproceedings{wangIdeaExpanderSupporting2010,
  title = {Idea Expander: Supporting Group Brainstorming with Conversationally Triggered Visual Thinking Stimuli},
  shorttitle = {Idea Expander},
  booktitle = {Proceedings of the 2010 {{ACM}} Conference on {{Computer}} Supported Cooperative Work},
  author = {Wang, Hao-Chuan and Cosley, Dan and Fussell, Susan R.},
  date = {2010-02-06},
  series = {{{CSCW}} '10},
  pages = {103--106},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/1718918.1718938},
  url = {https://doi.org/10.1145/1718918.1718938},
  urldate = {2023-03-15},
  abstract = {创造力是许多人类解决问题和创新的核心。头脑风暴过程试图利用团队创造力，但团队动力有时会限制其效用。我们推出了 IdeaExpander，这是一种通过根据小组对话智能选择图片刺激来支持小组头脑风暴的工具。设计基于感知、思维和沟通如何相互作用的理论；一项试点研究 (N=16) 表明，它增加了个人的想法产生，并且人们重视它。},
  isbn = {978-1-60558-795-0},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/AE64YDGK/Wang et al. - 2010 - Idea expander supporting group brainstorming with.pdf}
}

@article{wangLearningPerformanceBehavioral2020,
  title = {Learning Performance and Behavioral Patterns of Online Collaborative Learning: {{Impact}} of Cognitive Load and Affordances of Different Multimedia},
  shorttitle = {Learning Performance and Behavioral Patterns of Online Collaborative Learning},
  author = {Wang, Cixiao and Fang, Ting and Gu, Yinxuan},
  date = {2020-01-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {143},
  pages = {103683},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2019.103683},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131519302362},
  urldate = {2023-03-22},
  abstract = {In online collaborative learning, discussions have been widely utilized as an educational activity, and much research has been conducted on the process and behaviors involved in synchronous or asynchronous discussions. However, research on behavioral patterns in collaborative learning environments with different formats of learning materials has not been addressed in detailed yet. In this study, we designed three versions of media to present the same learning contents: interactive version, video version, and text version. The differences among the above three versions are the form of information organization and the interaction mode between students and the given version. There were 131 eighth graders from three classes participated in this study. They were asked to complete a group worksheet through online discussion while engaging with the given learning materials. In order to explore students' online collaborative behavioral patterns while engaging with different multimedia, this study proposed a verb-dominated coding scheme for synchronous online collaborative learning and conducted a lag sequential analysis. The findings indicate that Class A (interactive version) formed an active learning atmosphere, while Class B (video version) spent more time on showing disagreement due to overloaded working memory caused by improper information presentation. In contrast, Class C (text version) had high efficiency in information exchanges because of the convenience of information acquisition. Besides, Class A gained the highest scores in group worksheet and invested moderate cognitive load. Class B had unsatisfactory learning performance on group worksheet along with the highest cognitive load. Class C invested the lowest cognitive load and had better knowledge retention than Class A, as shown in the results of the post-test a week later.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/Q63RUCYA/S0360131519302362.html}
}

@online{wangPopBlendsStrategiesConceptual2023,
  title = {{{PopBlends}}: {{Strategies}} for {{Conceptual Blending}} with {{Large Language Models}}},
  shorttitle = {{{PopBlends}}},
  author = {Wang, Sitong and Petridis, Savvas and Kwon, Taeahn and Ma, Xiaojuan and Chilton, Lydia B.},
  date = {2023-02-19},
  eprint = {2111.04920},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2111.04920},
  urldate = {2023-04-19},
  abstract = {Pop culture is an important aspect of communication. On social media people often post pop culture reference images that connect an event, product or other entity to a pop culture domain. Creating these images is a creative challenge that requires finding a conceptual connection between the users' topic and a pop culture domain. In cognitive theory, this task is called conceptual blending. We present a system called PopBlends that automatically suggests conceptual blends. The system explores three approaches that involve both traditional knowledge extraction methods and large language models. Our annotation study shows that all three methods provide connections with similar accuracy, but with very different characteristics. Our user study shows that people found twice as many blend suggestions as they did without the system, and with half the mental demand. We discuss the advantages of combining large language models with knowledge bases for supporting divergent and convergent thinking.},
  pubstate = {preprint},
  keywords = {��������,notion},
  file = {/Users/xinyuech/Zotero/storage/G3PSMFYZ/Wang et al. - 2023 - PopBlends Strategies for Conceptual Blending with.pdf;/Users/xinyuech/Zotero/storage/5G3L6Z37/2111.html}
}

@inproceedings{wangSlide4NCreatingPresentation2023,
  title = {{{Slide4N}}: {{Creating Presentation Slides}} from {{Computational Notebooks}} with {{Human-AI Collaboration}}},
  shorttitle = {{{Slide4N}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wang, Fengjie and Liu, Xuye and Liu, Oujing and Neshati, Ali and Ma, Tengfei and Zhu, Min and Zhao, Jian},
  date = {2023-04-19},
  pages = {1--18},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580753},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580753},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {��������,notion},
  file = {/Users/xinyuech/Zotero/storage/ZR22UERN/Wang et al. - 2023 - Slide4N Creating Presentation Slides from Computa.pdf}
}

@inproceedings{xu2024jamplate,
  title={Jamplate: Exploring LLM-Enhanced Templates for Idea Reflection},
  author={Xu, Xiaotong and Yin, Jiayu and Gu, Catherine and Mar, Jenny and Zhang, Sydney and E, Jane L and Dow, Steven P},
  booktitle={Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages={907--921},
  year={2024}
}

@inproceedings{kadoma2024role,
  title={The Role of Inclusion, Control, and Ownership in Workplace AI-Mediated Communication},
  author={Kadoma, Kowe and Aubin Le Quere, Marianne and Fu, Xiyu Jenny and Munsch, Christin and Metaxa, Dana{\"e} and Naaman, Mor},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--10},
  year={2024}
}

@article{wegerifExploringCreativeThinking2010,
  title = {Exploring Creative Thinking in Graphically Mediated Synchronous Dialogues},
  author = {Wegerif, Rupert and McLaren, Bruce M. and Chamrada, Marian and Scheuer, Oliver and Mansour, Nasser and Mikšátko, Jan and Williams, Mriga},
  date = {2010-04-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  series = {Learning in {{Digital Worlds}}: {{Selected Contributions}} from the {{CAL}} 09 {{Conference}}},
  volume = {54},
  number = {3},
  pages = {613--621},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2009.10.015},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131509003054},
  urldate = {2023-05-24},
  abstract = {This paper reports on an aspect of the EC funded Argunaut project which researched and developed awareness tools for moderators of online dialogues. In this study we report on an investigation into the nature of creative thinking in online dialogues and whether or not this creative thinking can be coded for and recognized automatically such that moderators can be alerted when creative thinking is occurring or when it has not occurred after a period of time. We outline a dialogic theory of creativity, as the emergence of new perspectives from the interplay of voices, and the testing of this theory using a range of methods including a coding scheme which combined coding for creative thinking with more established codes for critical thinking, artificial intelligence pattern-matching techniques to see if our codes could be read automatically from maps and ‘key event recall’ interviews to explore the experience of participants. Our findings are that: (1) the emergence of new perspectives in a graphical dialogue map can be recognized by our coding scheme supported by a machine pattern-matching algorithm in a way that can be used to provide awareness indicators for moderators; (2) that the trigger events leading to the emergence of new perspectives in the online dialogues studied were most commonly disagreements and (3) the spatial representation of messages in a graphically mediated synchronous dialogue environment such as Digalo may offer more affordance for creativity than the much more common scrolling text chat environments. All these findings support the usefulness of our new account of creativity in online dialogues based on dialogic theory and demonstrate that this account can be operationalised through machine coding in a way that can be turned into alerts for moderators.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/5WWZ8WIW/Wegerif et al. - 2010 - Exploring creative thinking in graphically mediate.pdf;/Users/xinyuech/Zotero/storage/P9F2VQHY/S0360131509003054.html}
}

@report{wenTransactivityPredictorFuture2016,
  title = {Transactivity as a {{Predictor}} of {{Future Collaborative Knowledge Integration}} in {{Team-Based Learning}} in {{Online Courses}}},
  author = {Wen, Miaomiao and Maki, Keith and Wang, Xu and Dow, Steven P. and Herbsleb, James and Rose, Carolyn},
  date = {2016},
  journaltitle = {International Educational Data Mining Society},
  institution = {{International Educational Data Mining Society}},
  url = {https://eric.ed.gov/?id=ED592733},
  urldate = {2023-03-21},
  abstract = {To create a satisfying social learning experience, an emerging challenge in educational data mining is to automatically assign students into effective learning teams. In this paper, we utilize discourse data mining as the foundation for an online team-formation procedure. The procedure features a deliberation process prior to team assignment, where participants hold discussions both to prepare for the collaboration task and provide indicators that are then used during automated team assignment. We automatically assign teams in a way that maximizes average observed pairwise transactivity exchange within teams, whereas in a control condition, teams are assigned randomly. We validate our team-formation procedure in a crowdsourced online environment that enables effective isolation of variables, namely Amazon's Mechanical Turk. We compare group knowledge integration outcomes between the two team assignment conditions. Our results demonstrate that transactivity-based team assignment is associated with significantly greater knowledge integration (p {$<$} 0.05, effect size 3 standard deviations). [For the full proceedings, see ED592609.]},
  langid = {english},
  keywords = {notion},
  annotation = {ERIC Number: ED592733},
  file = {/Users/xinyuech/Zotero/storage/QM7PTZLY/Wen et al. - 2016 - Transactivity as a Predictor of Future Collaborati.pdf}
}

@article{cao2009nasa,
  title={NASA TLX: Software for assessing subjective mental workload},
  author={Cao, Alex and Chintamani, Keshav K and Pandya, Abhilash K and Ellis, R Darin},
  journal={Behavior research methods},
  volume={41},
  pages={113--117},
  year={2009},
  publisher={Springer}
}

@inproceedings{wuPromptChainerChainingLarge2022,
  title = {{{PromptChainer}}: {{Chaining Large Language Model Prompts}} through {{Visual Programming}}},
  shorttitle = {{{PromptChainer}}},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems Extended Abstracts}}},
  author = {Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J},
  date = {2022-04-27},
  pages = {1--10},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3491101.3519729},
  url = {https://dl.acm.org/doi/10.1145/3491101.3519729},
  urldate = {2023-04-27},
  abstract = {While LLMs have made it possible to rapidly prototype new ML functionalities, many real-world applications involve complex tasks that cannot be easily handled via a single run of an LLM. Recent work has found that chaining multiple LLM runs together (with the output of one step being the input to the next) can help users accomplish these more complex tasks, and in a way that is perceived to be more transparent and controllable. However, it remains unknown what users need when authoring their own LLM chains – a key step to lowering the barriers for non-AI-experts to prototype AI-infused applications. In this work, we explore the LLM chain authoring process. We find from pilot studies that users need support transforming data between steps of a chain, as well as debugging the chain at multiple granularities. To address these needs, we designed PromptChainer, an interactive interface for visually programming chains. Through case studies with four designers and developers, we show that PromptChainer supports building prototypes for a range of applications, and conclude with open questions on scaling chains to even more complex tasks, as well as supporting low-fi chain prototyping.},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9156-6},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/VL8IQYZJ/Wu et al. - 2022 - PromptChainer Chaining Large Language Model Promp.pdf}
}

@article{xiaCrossTalkIntelligentSubstrates2023,
  title = {{{CrossTalk}}: {{Intelligent Substrates}} for {{Language-Oriented Interaction}} in {{Video-Based Communication}} and {{Collaboration}}},
  author = {Xia, Haijun and Wang, Tony and Gunturu, Aditya and Jiang, Peiling and Duan, William and Yao, Xiaoshuo},
  date = {2023},
  langid = {english},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/UNUYLY7K/Xia et al. - 2023 - CrossTalk Intelligent Substrates for Language-Ori.pdf}
}

@article{xiaPersuaVisualInteractive2022,
  title = {Persua: {{A Visual Interactive System}} to {{Enhance}} the {{Persuasiveness}} of {{Arguments}} in {{Online Discussion}}},
  shorttitle = {Persua},
  author = {Xia, Meng and Zhu, Qian and Wang, Xingbo and Nie, Fei and Qu, Huamin and Ma, Xiaojuan},
  date = {2022-11-07},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  eprint = {2204.07741},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {1--30},
  issn = {2573-0142},
  doi = {10.1145/3555210},
  url = {http://arxiv.org/abs/2204.07741},
  urldate = {2023-04-19},
  abstract = {Persuading people to change their opinions is a common practice in online discussion forums on topics ranging from political campaigns to relationship consultation. Enhancing people's ability to write persuasive arguments could not only practice their critical thinking and reasoning but also contribute to the effectiveness and civility in online communication. It is, however, not an easy task in online discussion settings where written words are the primary communication channel. In this paper, we derived four design goals for a tool that helps users improve the persuasiveness of arguments in online discussions through a survey with 123 online forum users and interviews with five debating experts. To satisfy these design goals, we analyzed and built a labeled dataset of fine-grained persuasive strategies (i.e., logos, pathos, ethos, and evidence) in 164 arguments with high ratings on persuasiveness from ChangeMyView, a popular online discussion forum. We then designed an interactive visual system, Persua, which provides example-based guidance on persuasive strategies to enhance the persuasiveness of arguments. In particular, the system constructs portfolios of arguments based on different persuasive strategies applied to a given discussion topic. It then presents concrete examples based on the difference between the portfolios of user input and high-quality arguments in the dataset. A between-subjects study shows suggestive evidence that Persua encourages users to submit more times for feedback and helps users improve more on the persuasiveness of their arguments than a baseline system. Finally, a set of design considerations was summarized to guide future intelligent systems that improve the persuasiveness in text.},
  issue = {CSCW2},
  keywords = {notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/I62NK3R3/Xia et al. - 2022 - Persua A Visual Interactive System to Enhance the.pdf;/Users/xinyuech/Zotero/storage/VJBHDQVW/2204.html}
}

@inproceedings{xingImprovingUnsupervisedDialogue2021,
  title = {Improving {{Unsupervised Dialogue Topic Segmentation}} with {{Utterance-Pair Coherence Scoring}}},
  booktitle = {Proceedings of the 22nd {{Annual Meeting}} of the {{Special Interest Group}} on {{Discourse}} and {{Dialogue}}},
  author = {Xing, Linzi and Carenini, Giuseppe},
  date = {2021-07},
  pages = {167--177},
  publisher = {{Association for Computational Linguistics}},
  location = {{Singapore and Online}},
  url = {https://aclanthology.org/2021.sigdial-1.18},
  urldate = {2023-06-05},
  abstract = {Dialogue topic segmentation is critical in several dialogue modeling problems. However, popular unsupervised approaches only exploit surface features in assessing topical coherence among utterances. In this work, we address this limitation by leveraging supervisory signals from the utterance-pair coherence scoring task. First, we present a simple yet effective strategy to generate a training corpus for utterance-pair coherence scoring. Then, we train a BERT-based neural utterance-pair coherence model with the obtained training corpus. Finally, such model is used to measure the topical relevance between utterances, acting as the basis of the segmentation inference. Experiments on three public datasets in English and Chinese demonstrate that our proposal outperforms the state-of-the-art baselines.},
  eventtitle = {{{SIGDIAL}} 2021},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/6ZRGMUFF/Xing and Carenini - 2021 - Improving Unsupervised Dialogue Topic Segmentation.pdf}
}

@article{xuIdeateRelateExamplesGallery2021,
  title = {{{IdeateRelate}}: {{An Examples Gallery That Helps Creators Explore Ideas}} in {{Relation}} to {{Their Own}}},
  shorttitle = {{{IdeateRelate}}},
  author = {Xu, Xiaotong (Tone) and Xiong, Rosaleen and Wang, Boyang and Min, David and Dow, Steven P.},
  date = {2021-10-13},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  pages = {1--18},
  issn = {2573-0142},
  doi = {10.1145/3479496},
  url = {https://dl.acm.org/doi/10.1145/3479496},
  urldate = {2023-03-20},
  abstract = {Creating truly original ideas requires extensive knowledge of existing ideas. Navigating prior examples can help people to understand what has already been done and to assess the quality of their own ideas through comparison. The creativity literature has suggested that the conceptual distance between a proposed solution and a potential inspiration can influence one's thinking. However, less is known about how creators might use data about conceptual distance when exploring a large repository of ideas. To investigate this, we created a novel tool for exploring examples called IdeateRelate that visualizes 600+ COVID-related ideas, organized by their similarity to a new idea. In an experiment that compared the IdeateRelate visualization to a simple list of examples, we found that users in the Viz condition leveraged both semantic and categorical similarity, curated a more similar set of examples, and adopted more language from examples into their iterated ideas (without negatively affecting the overall novelty). We discuss implications for creating adaptive interfaces that provide creative inspiration in response to designers' ideas throughout an iterative design process.},
  issue = {CSCW2},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/88SRGQFU/Xu et al. - 2021 - IdeateRelate An Examples Gallery That Helps Creat.pdf}
}

@inproceedings{yangCatchLiveRealtimeSummarization2022,
  title = {{{CatchLive}}: {{Real-time Summarization}} of {{Live Streams}} with {{Stream Content}} and {{Interaction Data}}},
  shorttitle = {{{CatchLive}}},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Yang, Saelyne and Yim, Jisu and Kim, Juho and Shin, Hijung Valentina},
  date = {2022-04-29},
  pages = {1--20},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3491102.3517461},
  url = {https://dl.acm.org/doi/10.1145/3491102.3517461},
  urldate = {2023-08-16},
  abstract = {Live streams usually last several hours with many viewers joining in the middle. Viewers who join in the middle often want to understand what has happened in the stream. However, catching up with the earlier parts is challenging because it is difcult to know which parts are important in the long, unedited stream while also ∗This work was done while the author was an intern at Adobe Research.},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9157-3},
  langid = {english},
  keywords = {/unread,❤️❤️❤️❤️❤️,��},
  file = {/Users/xinyuech/Zotero/storage/F8TTUCKW/Yang et al. - 2022 - CatchLive Real-time Summarization of Live Streams.pdf}
}

@inproceedings{yangSoftVideoImprovingLearning2022,
  title = {{{SoftVideo}}: {{Improving}} the {{Learning Experience}} of {{Software Tutorial Videos}} with {{Collective Interaction Data}}},
  shorttitle = {{{SoftVideo}}},
  booktitle = {27th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Yang, Saelyne and Yim, Jisu and Baigutanova, Aitolkyn and Kim, Seoyoung and Chang, Minsuk and Kim, Juho},
  date = {2022-03-22},
  pages = {646--660},
  publisher = {{ACM}},
  location = {{Helsinki Finland}},
  doi = {10.1145/3490099.3511106},
  url = {https://dl.acm.org/doi/10.1145/3490099.3511106},
  urldate = {2023-08-15},
  abstract = {Many people rely on tutorial videos when learning to perform tasks using complex software. Watching the video for instructions and applying them to target software requires frequent going backand-forth between the two, which incurs cognitive overhead. Furthermore, users need to constantly compare the two to see if they are following correctly, as they are prone to missing out on subtle differences. We propose SoftVideo, a prototype system that helps users plan ahead before watching each step in tutorial videos and provides feedback and help to users on their progress. SoftVideo is powered by collective interaction data, as experiences of previous learners with the same goal can provide insights into how they learned from the tutorial. By identifying the difficulty and relatedness of each step from the interaction logs, SoftVideo provides information on each step such as its estimated difficulty, lets users know if they completed or missed a step, and suggests tips such as relevant steps when it detects users struggling. To enable such a data-driven system, we collected and analyzed video interaction logs and the associated Photoshop usage logs for two tutorial videos from 120 users. We then defined six metrics that portray the difficulty of each step, including the time taken to complete a step and the number of pauses in a step, which were also used to detect users’ struggling moments by comparing their progress to the collected data. To investigate the feasibility and usefulness of SoftVideo, we ran a user study with 30 participants where they performed a Photoshop task by following along a tutorial video with SoftVideo. Results show that participants could proactively and effectively plan their pauses and playback speed, and adjust their concentration level. They were also able to identify and recover from errors with the help SoftVideo provides.},
  eventtitle = {{{IUI}} '22: 27th {{International Conference}} on {{Intelligent User Interfaces}}},
  isbn = {978-1-4503-9144-3},
  langid = {english},
  keywords = {notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/ZY7P48DC/Yang et al. - 2022 - SoftVideo Improving the Learning Experience of So.pdf}
}

@article{yuExploringHowWorkspace2022,
  title = {Exploring {{How Workspace Awareness Cues Affect Distributed Meeting Outcome}}},
  author = {Yu, Fangyu and Zhang, Peng and Ding, Xianghua and Lu, Tun and Gu, Ning},
  date = {2022-04-24},
  journaltitle = {International Journal of Human–Computer Interaction},
  volume = {0},
  number = {0},
  pages = {1--20},
  publisher = {{Taylor \& Francis}},
  issn = {1044-7318},
  doi = {10.1080/10447318.2022.2064063},
  url = {https://doi.org/10.1080/10447318.2022.2064063},
  urldate = {2022-08-05},
  abstract = {Nowadays, using the online whiteboard to share knowledge in distributed meetings has become a common practice. Existing studies and practices have attempted to visualize attendees’ interactive activities in whiteboard tools to support the virtual team’s workspace awareness (WA). However, the impact of such visual cues on meeting success remains unclear. For this purpose, we primarily explore whether and to what extent WA cues are conducive to meeting outcome. This study applies activity theory to guide our prototype design and research analysis. A customized web-based whiteboard interface is implemented under two conditions. We conduct a study with 42 subjects in a distributed meeting scenario via a controlled experiment. Also, we analyze the system affordance via user experience. The results demonstrate that the benefits of WA cues to meeting outcome are especially embodied in goal attainment and quality of contributions, but not effectively supported in productivity and user satisfaction. Moreover, subjects report that they do not feel distracted by the system’s visual cues because they do not notice those cues most of the time and use them only when needed. Drawing upon findings from our trial work, we provide several implications for designing a collaborative knowledge-sharing environment to assist the visual support of WA in distributed meetings.},
  keywords = {/unread,notion}
}

@article{zhangFacilitatingGlobalTeam2022,
  title = {Facilitating {{Global Team Meetings Between Language-Based Subgroups}}: {{When}} and {{How Can Machine Translation Help}}?},
  shorttitle = {Facilitating {{Global Team Meetings Between Language-Based Subgroups}}},
  author = {Zhang, Yongle and Asamoah Owusu, Dennis and Carpuat, Marine and Gao, Ge},
  date = {2022-04-07},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {90:1--90:26},
  doi = {10.1145/3512937},
  url = {https://dl.acm.org/doi/10.1145/3512937},
  urldate = {2023-03-24},
  abstract = {Global teams frequently consist of language-based subgroups who put together complementary information to achieve common goals. Previous research outlines a two-step work communication flow in these teams. There are team meetings using a required common language (i.e., English); in preparation for those meetings, people have subgroup conversations in their native languages. Work communication at team meetings is often less effective than in subgroup conversations. In the current study, we investigate the idea of leveraging machine translation (MT) to facilitate global team meetings. We hypothesize that exchanging subgroup conversation logs before a team meeting offers contextual information that benefits teamwork at the meeting. MT can translate these logs, which enables comprehension at a low cost. To test our hypothesis, we conducted a between-subjects experiment where twenty quartets of participants performed a personnel selection task. Each quartet included two English native speakers (NS) and two non-native speakers (NNS) whose native language was Mandarin. All participants began the task with subgroup conversations in their native languages, then proceeded to team meetings in English. We manipulated the exchange of subgroup conversation logs prior to team meetings: with MT-mediated exchanges versus without. Analysis of participants' subjective experience, task performance, and depth of discussions as reflected through their conversational moves jointly indicates that team meeting quality improved when there were MT-mediated exchanges of subgroup conversation logs as opposed to no exchanges. We conclude with reflections on when and how MT could be applied to enhance global teamwork across a language barrier.},
  issue = {CSCW1},
  keywords = {❤️❤️❤️❤️❤️},
  file = {/Users/xinyuech/Zotero/storage/4PKNSFHL/Zhang et al. - 2022 - Facilitating Global Team Meetings Between Language.pdf}
}

@article{asthana2023summaries,
  title={Summaries, Highlights, and Action items: Design, implementation and evaluation of an LLM-powered meeting recap system},
  author={Asthana, Sumit and Hilleli, Sagih and He, Pengcheng and Halfaker, Aaron},
  journal={arXiv preprint arXiv:2307.15793},
  year={2023}
}

@inproceedings{zhangIceBreakingTechnologyRobots2023,
  title = {Ice-{{Breaking Technology}}: {{Robots}} and {{Computers Can Foster Meaningful Connections}} between {{Strangers}} through {{In-Person Conversations}}},
  shorttitle = {Ice-{{Breaking Technology}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zhang, Alex Wuqi and Lin, Ting-Han and Zhao, Xuan and Sebo, Sarah},
  date = {2023-04-19},
  pages = {1--14},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581135},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581135},
  urldate = {2023-06-26},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion,������},
  file = {/Users/xinyuech/Zotero/storage/W9FHG52W/Zhang et al. - 2023 - Ice-Breaking Technology Robots and Computers Can .pdf}
}

@inproceedings{paul2009cosense,
  title={CoSense: enhancing sensemaking for collaborative web search},
  author={Paul, Sharoda A and Morris, Meredith Ringel},
  booktitle={Proceedings of the SIGCHI conference on human factors in computing systems},
  pages={1771--1780},
  year={2009}
}

@inproceedings{paul2010understanding,
  title={Understanding together: sensemaking in collaborative information seeking},
  author={Paul, Sharoda A and Reddy, Madhu C},
  booktitle={Proceedings of the 2010 ACM conference on Computer supported cooperative work},
  pages={321--330},
  year={2010}
}

@inproceedings{paul2010understanding,
  title={Understanding together: sensemaking in collaborative information seeking},
  author={Paul, Sharoda A and Reddy, Madhu C},
  booktitle={Proceedings of the 2010 ACM conference on Computer supported cooperative work},
  pages={321--330},
  year={2010}
}
@online{zhangVISARHumanAIArgumentative2023,
  title = {{{VISAR}}: {{A Human-AI Argumentative Writing Assistant}} with {{Visual Programming}} and {{Rapid Draft Prototyping}}},
  shorttitle = {{{VISAR}}},
  author = {Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun},
  date = {2023-04-16},
  eprint = {2304.07810},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.07810},
  urldate = {2023-04-19},
  abstract = {In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confirmed the usability and effectiveness of VISAR in facilitating the argumentative writing planning process.},
  pubstate = {preprint},
  keywords = {❤️❤️❤️❤️❤️,notion},
  file = {/Users/xinyuech/Zotero/storage/DVD7MEXE/Zhang et al. - 2023 - VISAR A Human-AI Argumentative Writing Assistant .pdf;/Users/xinyuech/Zotero/storage/V2LV7VAR/2304.html}
}




@inproceedings{yang2022catchlive,
  title={CatchLive: Real-time Summarization of Live Streams with Stream Content and Interaction Data},
  author={Yang, Saelyne and Yim, Jisu and Kim, Juho and Shin, Hijung Valentina},
  booktitle={CHI Conference on Human Factors in Computing Systems},
  pages={1--20},
  year={2022}
}


 @article{bifulco1994childhood,
  title={Childhood Experience of Care and Abuse (CECA): a retrospective interview measure},
  author={Bifulco, Antonia and Brown, George W and Harris, Tirrill O},
  journal={Journal of Child Psychology and Psychiatry},
  volume={35},
  number={8},
  pages={1419--1435},
  year={1994},
  publisher={Wiley Online Library}
}

@article{cote2005tracing,
  title={Tracing the development of athletes using retrospective interview methods: A proposed interview and validation procedure for reported information},
  author={C{\^o}t{\'e}, Jean and Ericsson, K Anders and Law, Madelyn P},
  journal={Journal of applied sport psychology},
  volume={17},
  number={1},
  pages={1--19},
  year={2005},
  publisher={Taylor \& Francis}
}


   @article{jong2012effects,
  title={Effects of anonymity in group discussion on peer interaction and learning achievement},
  author={Jong, Bin-Shyan and Lai, Chien-Hung and Hsia, Yen-Teh and Lin, Tsong-Wuu},
  journal={IEEE Transactions on Education},
  volume={56},
  number={3},
  pages={292--299},
  year={2012},
  publisher={IEEE}
}


   @article{strauss2021promoting,
  title={Promoting regulation of equal participation in online collaboration by combining a group awareness tool and adaptive prompts. But does it even matter?},
  author={Strau{\ss}, Sebastian and Rummel, Nikol},
  journal={International Journal of Computer-Supported Collaborative Learning},
  volume={16},
  number={1},
  pages={67--104},
  year={2021},
  publisher={Springer}
}


   @misc{digitalocean, title={The developer cloud}, url={https://www.digitalocean.com/}, journal={DigitalOcean}} 
   
  @misc{jitsi_2021, title={Jitsi API: How to ADD video meetings to your site &amp; app}, url={https://jitsi.org/api/}, journal={Jitsi}, year={2021}, month={Feb}} 
  
 @article{xu2021benchmarking,
  title={A benchmarking on cloud based speech-to-text services for french speech and background noise effect},
  author={Xu, Binbin and Tao, Chongyang and Feng, Zidu and Raqui, Youssef and Ranwez, Sylvie},
  journal={arXiv preprint arXiv:2105.03409},
  year={2021}
}


 @article{zimmerman2017speed,
  title={Speed dating: providing a menu of possible futures},
  author={Zimmerman, John and Forlizzi, Jodi},
  journal={She Ji: The Journal of Design, Economics, and Innovation},
  volume={3},
  number={1},
  pages={30--50},
  year={2017},
  publisher={Elsevier}
}

 
 @article{gagne2016cooperative,
  title={Cooperative learning tasks in a Grade 6 intensive English as a second language class: turn-taking and degree of participation},
  author={Gagn{\'e}, Nathalie and Parks, Susan},
  journal={The Language Learning Journal},
  volume={44},
  number={2},
  pages={169--180},
  year={2016},
  publisher={Taylor \& Francis}
}


 @misc{speech, title={Speech to text – audio to text translation: Microsoft azure}, url={https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/}, journal={Speech to Text – Audio to Text Translation | Microsoft Azure}} 

@inproceedings{seita2021deaf,
  title={Deaf and hard-of-hearing users' preferences for hearing speakers' behavior during technology-mediated in-person and remote conversations},
  author={Seita, Matthew and Andrew, Sarah and Huenerfauth, Matt},
  booktitle={Proceedings of the 18th International Web for All Conference},
  pages={1--12},
  year={2021}
}


@article{kafle2021deaf,
  title={Deaf and Hard-of-hearing Users Evaluating Designs for Highlighting Key Words in Educational Lecture Videos},
  author={Kafle, Sushant and Dingman, Becca and Huenerfauth, Matt},
  journal={ACM Transactions on Accessible Computing (TACCESS)},
  volume={14},
  number={4},
  pages={1--24},
  year={2021},
  publisher={ACM New York, NY}
}


@inproceedings{gao2015improving,
  title={Improving multilingual collaboration by displaying how non-native speakers use automated transcripts and bilingual dictionaries},
  author={Gao, Ge and Yamashita, Naomi and Hautasaari, Ari MJ and Fussell, Susan R},
  booktitle={Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
  pages={3463--3472},
  year={2015}
}


@inproceedings{duan2018let,
  title={" Let Me Ask Them to Clarify If You Don't Want To"-A Clarification Agent for Nonnative Speakers},
  author={Duan, Wen and Yamashita, Naomi and Hwang, Sun Young and Fussell, Susan},
  booktitle={Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--6},
  year={2018}
}


@article{duan2021bridging,
  title={Bridging Fluency Disparity between Native and Nonnative Speakers in Multilingual Multiparty Collaboration Using a Clarification Agent},
  author={Duan, Wen and Yamashita, Naomi and Shirai, Yoshinari and Fussell, Susan R},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={5},
  number={CSCW2},
  pages={1--31},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{gronbaek2021mirrorblender,
  title={MirrorBlender: Supporting Hybrid Meetings with a Malleable Video-Conferencing System},
  author={Gr{\o}nb{\ae}k, Jens Emil and Saat{\c{c}}i, Banu and Griggio, Carla F and Klokmose, Clemens Nylandsted},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2021}
}


@article{cheng2022mapping,
  title={Mapping the Design Space of Human-AI Interaction in Text Summarization},
  author={Cheng, Ruijia and Smith-Renner, Alison and Zhang, Ke and Tetreault, Joel R and Jaimes, Alejandro},
  journal={arXiv preprint arXiv:2206.14863},
  year={2022}
}


@inproceedings{lins2019cnn,
  title={The cnn-corpus: A large textual corpus for single-document extractive summarization},
  author={Lins, Rafael Dueire and Oliveira, Hilario and Cabral, Luciano and Batista, Jamilson and Tenorio, Bruno and Ferreira, Rafael and Lima, Rinaldo and de Fran{\c{c}}a Pereira e Silva, Gabriel and Simske, Steven J},
  booktitle={Proceedings of the ACM Symposium on Document Engineering 2019},
  pages={1--10},
  year={2019}
}


@inproceedings{hong2014repository,
  title={A repository of state of the art and competitive baseline summaries for generic news summarization},
  author={Hong, Kai and Conroy, John and Favre, Benoit and Kulesza, Alex and Lin, Hui and Nenkova, Ani},
  booktitle={Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14)},
  pages={1608--1616},
  year={2014}
}

@article{mueller2014pen,
  title={The pen is mightier than the keyboard: Advantages of longhand over laptop note taking},
  author={Mueller, Pam A and Oppenheimer, Daniel M},
  journal={Psychological science},
  volume={25},
  number={6},
  pages={1159--1168},
  year={2014},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}



@inproceedings{sarkar2021promise,
  title={The promise and peril of parallel chat in video meetings for work},
  author={Sarkar, Advait and Rintel, Sean and Borowiec, Damian and Bergmann, Rachel and Gillett, Sharon and Bragg, Danielle and Baym, Nancy and Sellen, Abigail},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--8},
  year={2021}
}

@article{weintrop2019block,
  title={Block-based programming in computer science education},
  author={Weintrop, David},
  journal={Communications of the ACM},
  volume={62},
  number={8},
  pages={22--25},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{stefanou2008note,
  title={Note-taking in the college classroom as evidence of generative learning},
  author={Stefanou, Candice and Hoffman, Lynn and Vielee, Nicolette},
  journal={Learning Environments Research},
  volume={11},
  pages={1--17},
  year={2008},
  publisher={Springer}
}

@article{katayama1997getting,
  title={Getting Students Involved in Note Taking: Why Partial Notes Benefit Learners More Than Complete Notes.},
  author={Katayama, Andrew D},
  year={1997},
  publisher={ERIC}
}


@article{piolat2005cognitive,
  title={Cognitive effort during note taking},
  author={Piolat, Annie and Olive, Thierry and Kellogg, Ronald T},
  journal={Applied cognitive psychology},
  volume={19},
  number={3},
  pages={291--312},
  year={2005},
  publisher={Wiley Online Library}
}

@article{gallagher1993nominal,
  title={The nominal group technique: a research tool for general practice?},
  author={Gallagher, Morris and Hares, TIM and Spencer, John and Bradshaw, Colin and Webb, IAN},
  journal={Family practice},
  volume={10},
  number={1},
  pages={76--81},
  year={1993},
  publisher={Oxford University Press}
}

@article{feldman1984development,
  title={The development and enforcement of group norms},
  author={Feldman, Daniel C},
  journal={Academy of management review},
  volume={9},
  number={1},
  pages={47--53},
  year={1984},
  publisher={Academy of Management Briarcliff Manor, NY 10510}
}

@article{hartley1983note,
  title={Note-taking research: Resetting the scoreboard.},
  author={Hartley, James},
  journal={Bulletin of the British Psychological Society},
  year={1983},
  publisher={British Psychological Society}
}


@inproceedings{kam2005livenotes,
  title={Livenotes: a system for cooperative and augmented note-taking in lectures},
  author={Kam, Matthew and Wang, Jingtao and Iles, Alastair and Tse, Eric and Chiu, Jane and Glaser, Daniel and Tarshish, Orna and Canny, John},
  booktitle={Proceedings of the SIGCHI conference on Human factors in computing systems},
  pages={531--540},
  year={2005}
}

@article{robertson2005active,
  title={Active listening: more than just paying attention},
  author={Robertson, Kathryn},
  journal={Australian family physician},
  volume={34},
  number={12},
  year={2005}
}

@article{dhawan2021videoconferencing,
  title={Videoconferencing etiquette: promoting gender equity during virtual meetings},
  author={Dhawan, Natasha and Carnes, Molly and Byars-Winston, Angela and Duma, Narjust},
  journal={Journal of Women's Health},
  volume={30},
  number={4},
  pages={460--465},
  year={2021},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~…}
}

@inproceedings{meng2016hynote,
  title={HyNote: integrated concept mapping and notetaking},
  author={Meng, Xiaojun and Zhao, Shengdong and Edge, Darren},
  booktitle={Proceedings of the International Working Conference on Advanced Visual Interfaces},
  pages={236--239},
  year={2016}
}


@incollection{ng2008dialogue,
  title={Dialogue Mapping and Collaborative Learning},
  author={Ng, Fung Fai},
  booktitle={Handbook of Conversation Design for Instructional Applications},
  pages={403--418},
  year={2008},
  publisher={IGI Global}
}


@inproceedings{cao2022videosticker,
  title={VideoSticker: A Tool for Active Viewing and Visual Note-taking from Videos},
  author={Cao, Yining and Subramonyam, Hariharan and Adar, Eytan},
  booktitle={27th International Conference on Intelligent User Interfaces},
  pages={672--690},
  year={2022}
}

@incollection{lansiquot2015concept,
  title={Concept Mapping Narratives to Promote CSCL and Interdisciplinary Studies},
  author={Lansiquot, Reneta D and Cabo, Candido},
  year={2015},
  publisher={International Society of the Learning Sciences, Inc.[ISLS].}
}


@article{dyke2013student,
  title={Student Strategies for Collaborative Note-Taking and the Influence of FloorControl},
  author={Dyke, Gregory and Lund, Kristine},
  year={2013},
  publisher={International Society of the Learning Sciences}
}

@article{piolat2005cognitive,
  title={Cognitive effort during note taking},
  author={Piolat, Annie and Olive, Thierry and Kellogg, Ronald T},
  journal={Applied cognitive psychology},
  volume={19},
  number={3},
  pages={291--312},
  year={2005},
  publisher={Wiley Online Library}
}

@article{makany2009optimising,
  title={Optimising the use of note-taking as an external cognitive aid for increasing learning},
  author={Makany, Tamas and Kemp, Jonathan and Dror, Itiel E},
  journal={British Journal of Educational Technology},
  volume={40},
  number={4},
  pages={619--635},
  year={2009},
  publisher={Wiley Online Library}
}

@book{sibbet2010visual,
  title={Visual meetings: How graphics, sticky notes and idea mapping can transform group productivity},
  author={Sibbet, David},
  year={2010},
  publisher={John Wiley \& Sons}
}

@inproceedings{qu2008building,
  title={Building shared understanding in collaborative sensemaking},
  author={Qu, Yan and Hansen, Derek L},
  booktitle={Proceedings of CHI 2008 Sensemaking Workshop},
  year={2008}
}

@article{sadita2020collaborative,
  title={Collaborative concept mapping with reciprocal kit-build: a practical use in linear algebra course},
  author={Sadita, Lia and Hirashima, Tsukasa and Hayashi, Yusuke and Wunnasri, Warunya and Pailai, Jaruwat and Junus, Kasiyah and Santoso, Harry Budi},
  journal={Research and Practice in Technology Enhanced Learning},
  volume={15},
  number={1},
  pages={1--22},
  year={2020},
  publisher={SpringerOpen}
}

@inproceedings{haliburton2023walking,
  title={The Walking Talking Stick: Understanding Automated Note-Taking in Walking Meetings},
  author={Haliburton, Luke and Bart{\l}omiejczyk, Natalia and Schmidt, Albrecht and Wo{\'z}niak, Pawe{\l} W and Niess, Jasmin},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2023}
}

@article{kirshenbaum2021traces,
  title={Traces of Time through Space: Advantages of Creating Complex Canvases in Collaborative Meetings},
  author={Kirshenbaum, Nurit and Davidson, Kylie and Harden, Jesse and North, Chris and Kobayashi, Dylan and Theriot, Ryan and Tabalba Jr, Roderick S and Rogers, Michael L and Belcaid, Mahdi and Burks, Andrew T and others},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={5},
  number={ISS},
  pages={1--20},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@book{cook2009building,
  title={Building a High Performance Team: Proven techniques for effective team working},
  author={Cook, Sarah},
  year={2009},
  publisher={IT Governance Ltd}
}
@inproceedings{fowler2014talking,
  title={Talking teams: Increased equity in participation in online compared to face-to-face team discussions},
  author={Fowler, Robin},
  booktitle={2014 ASEE Annual Conference \& Exposition},
  pages={24--1154},
  year={2014}
}

@article{bonito1997participation,
  title={Participation in small groups},
  author={Bonito, Joseph A and Hollingshead, Andrea B},
  journal={Annals of the International Communication Association},
  volume={20},
  number={1},
  pages={227--261},
  year={1997},
  publisher={Taylor \& Francis}
}

@article{straus1996getting,
  title={Getting a clue: The effects of communication media and information distribution on participation and performance in computer-mediated and face-to-face groups},
  author={Straus, Susan G},
  journal={Small group research},
  volume={27},
  number={1},
  pages={115--142},
  year={1996},
  publisher={SAGE PUBLICATIONS, INC. 2455 Teller Road, Thousand Oaks, CA 91320}
}

@misc{marginnote, url={https://www.marginnote.com/}, journal={Marginnote}}
@article{he2021you,
  title={Are You Looking at Me? Eye Gazing in Web Video Conferences},
  author={He, Muchen and Xiong, Beibei and Xia, Kaseya},
  journal={methods},
  volume={27},
  pages={28},
  year={2021}
}

@article{convertino2011supporting,
  title={Supporting common ground and awareness in emergency management planning: A design research project},
  author={Convertino, Gregorio and Mentis, Helena M and Slavkovic, Aleksandra and Rosson, Mary Beth and Carroll, John M},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={18},
  number={4},
  pages={1--34},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{mahyar2014supporting,
  title={Supporting communication and coordination in collaborative sensemaking},
  author={Mahyar, Narges and Tory, Melanie},
  journal={IEEE transactions on visualization and computer graphics},
  volume={20},
  number={12},
  pages={1633--1642},
  year={2014},
  publisher={IEEE}
}

@article{telenius2016sensemaking,
  title={Sensemaking in Meetings-Collaborative Construction of Meaning and Decisions through Epistemic Authority},
  author={Telenius, Johanna and others},
  year={2016},
  publisher={Aalto University}
}

@article{yang2022towards,
  title={Towards immersive collaborative sensemaking},
  author={Yang, Ying and Dwyer, Tim and Wybrow, Michael and Lee, Benjamin and Cordeil, Maxime and Billinghurst, Mark and Thomas, Bruce H},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={6},
  number={ISS},
  pages={722--746},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{hancock2020ai,
  title={AI-mediated communication: Definition, research agenda, and ethical considerations},
  author={Hancock, Jeffrey T and Naaman, Mor and Levy, Karen},
  journal={Journal of Computer-Mediated Communication},
  volume={25},
  number={1},
  pages={89--100},
  year={2020},
  publisher={Oxford University Press}
}

@inproceedings{kalnikaite2012markup,
  title={Markup as you talk: establishing effective memory cues while still contributing to a meeting},
  author={Kalnikait{\.e}, Vaiva and Ehlen, Patrick and Whittaker, Steve},
  booktitle={Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work},
  pages={349--358},
  year={2012}
}

@inproceedings{fang2021notecostruct,
  title={NoteCoStruct: Powering Online Learners with Socially Scaffolded Note Taking and Sharing},
  author={Fang, Jingchao and Wang, Yanhao and Yang, Chi-Lan and Wang, Hao-Chuan},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--5},
  year={2021}
}
@book{conklin2005dialogue,
  title={Dialogue mapping: Building shared understanding of wicked problems},
  author={Conklin, Jeff},
  year={2005},
  publisher={John Wiley \& Sons, Inc.}
}

@inproceedings{chiu2001liteminutes,
  title={LiteMinutes: an Internet-based system for multimedia meeting minutes},
  author={Chiu, Patrick and Boreczky, John and Girgensohn, Andreas and Kimber, Don},
  booktitle={Proceedings of the 10th international conference on World Wide Web},
  pages={140--149},
  year={2001}
}

@article{tian2021system,
  title={A System for Interleaving Discussion and Summarization in Online Collaboration},
  author={Tian, Sunny and Zhang, Amy X and Karger, David},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW3},
  pages={1--27},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@inproceedings{geller2020confused,
  title={Confused and beyond: detecting confusion in course forums using students' hashtags},
  author={Geller, Shay A and Hoernle, Nicholas and Gal, Kobi and Segal, Avi and Zhang, Amy X and Karger, David and Facciotti, Marc T and Igo, Michele},
  booktitle={Proceedings of the Tenth International Conference on Learning Analytics \& Knowledge},
  pages={589--594},
  year={2020}
}

@inproceedings{zhang2017wikum,
  title={Wikum: Bridging discussion forums and wikis using recursive summarization},
  author={Zhang, Amy X and Verou, Lea and Karger, David},
  booktitle={Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
  pages={2082--2096},
  year={2017}
}
@inproceedings{zheng2023competent,
  title={Competent but Rigid: Identifying the Gap in Empowering AI to Participate Equally in Group Decision-Making},
  author={Zheng, Chengbo and Wu, Yuheng and Shi, Chuhan and Ma, Shuai and Luo, Jiehui and Ma, Xiaojuan},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2023}
}

@article{kim2021moderator,
  title={Moderator Chatbot for Deliberative Discussion: Effects of Discussion Structure and Discussant Facilitation},
  author={Kim, Soomin and Eun, Jinsu and Seering, Joseph and Lee, Joonhwan},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={5},
  number={CSCW1},
  pages={1--26},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{shi2018meetingvis,
  title={Meetingvis: Visual narratives to assist in recalling meeting context and content},
  author={Shi, Yang and Bryan, Chris and Bhamidipati, Sridatt and Zhao, Ying and Zhang, Yaoxue and Ma, Kwan-Liu},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={24},
  number={6},
  pages={1918--1929},
  year={2018},
  publisher={IEEE}
}
@misc{miro, title = {Run Interactive Meetings & Workshops with Miro | Miro}, url={https://miro.com/meetings-and-workshops/}, abstractNote={Miro gives you the power to bring the in-person experience online, whether you’re running a brainstorm or facilitating a workshop. Start your online meeting or virtual workshop with one of our 230+ ready-made templates.}, journal={https://miro.com/} }
@misc{otter,
	title = {Otter {Voice} {Meeting} {Notes}},
	url = {https://otter.ai},
	abstract = {Otter.ai uses artificial intelligence to empower users with real-time transcription meeting notes that are shareable, searchable, accessible and secure.},
	language = {en},
	urldate = {2021-09-08},
}

@article{chiaonline,
  title={Online Interview Tools for Qualitative Data Collection During COVID-19 Pandemic: Review of Web Conferencing Platforms' Functionality},
  author={CHIA, CHI-KUAN and GHAVIFEKR, SIMIN and RAZAK, AHMAD ZABIDI BIN ABDUL}
}

@article{karl2021virtual,
  title={Virtual Work Meetings During the COVID-19 Pandemic: The Good, Bad, and Ugly},
  author={Karl, Katherine A and Peluchette, Joy V and Aghakhani, Navid},
  journal={Small Group Research},
  pages={10464964211015286},
  year={2021},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}
@misc{wiederhold2020connecting,
  title={Connecting through technology during the coronavirus disease 2019 pandemic: Avoiding “Zoom Fatigue”},
  author={Wiederhold, Brenda K},
  year={2020},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~…}
}
@article{kohnke2020facilitating,
  title={Facilitating synchronous online language learning through Zoom},
  author={Kohnke, Lucas and Moorhouse, Benjamin Luke},
  journal={RELC Journal},
  pages={0033688220937235},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{adamson2014towards,
  title={Towards an agile approach to adapting dynamic collaboration support to student needs},
  author={Adamson, David and Dyke, Gregory and Jang, Hyeju and Ros{\'e}, Carolyn Penstein},
  journal={International Journal of Artificial Intelligence in Education},
  volume={24},
  number={1},
  pages={92--124},
  year={2014},
  publisher={Springer}
}

@incollection{wang2017contrasting,
  title={Contrasting explicit and implicit support for transactive exchange in team oriented project based learning},
  author={Wang, Xu and Wen, Miaomiao and Rose, Carolyn},
  year={2017},
  publisher={Philadelphia, PA: International Society of the Learning Sciences.}
}

@article{chen2023MeetScript,
  title={MeetScript: Designing Transcript-based Interactions to
Support Active Participation in Group Video Meetings},
  author={Chen, Xinyue and Li, Shuo and Liu, Shipeng and Fowler, Robin,  and Wang, Xu},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={7},
  number={CSCW2},
  pages={1-32},
  doi = {https://doi.org/10.1145/3610196},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@misc{dillenbourg2002over,
  title={Over-scripting CSCL: The risks of blending collaborative learning with instructional design.},
  author={Dillenbourg, Pierre},
  year={2002},
  publisher={Citeseer}
}

@book{howlearningworks2010,
  title={How learning works: Seven research-based principles for smart teaching},
  author={Ambrose, Susan A and Bridges, Michael W and DiPietro, Michele and Lovett, Marsha C and Norman, Marie K},
  year={2010},
  publisher={John Wiley \& Sons}
}
@article{crouch2001peer,
  title={Peer instruction: Ten years of experience and results},
  author={Crouch, Catherine H and Mazur, Eric},
  journal={American journal of physics},
  volume={69},
  number={9},
  pages={970--977},
  year={2001},
  publisher={American Association of Physics Teachers}
}

@inproceedings{zheng2021sketchnote,
  title={Sketchnote Components, Design Space Dimensions, and Strategies for Effective Visual Note Taking},
  author={Zheng, Rebecca and Fern{\'a}ndez Camporro, Marina and Romat, Hugo and Henry Riche, Nathalie and Bach, Benjamin and Chevalier, Fanny and Hinckley, Ken and Marquardt, Nicolai},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--15},
  year={2021}
}
@article{hacker2020virtually,
  title={Virtually in this together--how web-conferencing systems enabled a new virtual togetherness during the COVID-19 crisis},
  author={Hacker, Janine and vom Brocke, Jan and Handali, Joshua and Otto, Markus and Schneider, Johannes},
  journal={European Journal of Information Systems},
  volume={29},
  number={5},
  pages={563--584},
  year={2020},
  publisher={Taylor \& Francis}
}
@misc{zoomusers,
  author =       "{Backlinko}",
  year =         "2021",
  title =        "Zoom User Stats",
  url =          "https://backlinko.com/zoom-users",
}

@article{seuren2021whose,
  title={Whose turn is it anyway? Latency and the organization of turn-taking in video-mediated interaction},
  author={Seuren, Lucas M and Wherton, Joseph and Greenhalgh, Trisha and Shaw, Sara E},
  journal={Journal of pragmatics},
  volume={172},
  pages={63--78},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{al2021preferences,
  title={Preferences of Deaf or Hard of Hearing Users for Live-TV Caption Appearance},
  author={Al Amin, Akhter and Glasser, Abraham and Kushalnagar, Raja and Vogler, Christian and Huenerfauth, Matt},
  booktitle={International Conference on Human-Computer Interaction},
  pages={189--201},
  year={2021},
  organization={Springer}
}
@inproceedings{bodi2021automated,
  title={Automated Video Description for Blind and Low Vision Users},
  author={Bodi, Aditya and Fazli, Pooyan and Ihorn, Shasta and Siu, Yue-Ting and Scott, Andrew T and Narins, Lothar and Kant, Yash and Das, Abhishek and Yoon, Ilmi},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021}
}
@article{standaert2021shall,
  title={How shall we meet? Understanding the importance of meeting mode capabilities for different meeting objectives},
  author={Standaert, Willem and Muylle, Steve and Basu, Amit},
  journal={Information \& Management},
  volume={58},
  number={1},
  pages={103393},
  year={2021},
  publisher={Elsevier}
}
@misc{class_2021, title={The Virtual Classroom Built On Zoom. 50 Online Teaching Tools for Remote Learning on Zoom}, url={https://www.class.com/}, journal={Class}, year={2021}, month={Aug}}

@inproceedings{murali2021affectivespotlight,
  title={Affectivespotlight: Facilitating the communication of affective responses from audience members during online presentations},
  author={Murali, Prasanth and Hernandez, Javier and McDuff, Daniel and Rowan, Kael and Suh, Jina and Czerwinski, Mary},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2021}
}


@inproceedings{cho2021want,
  title={“I want more than” User-generated Icons for Better Video-mediated Communications on the Collaborative Design Process},
  author={Cho, Haena and Im, Hyeonjeong and Lee, Sunok and Lee, Sangsu},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--6},
  year={2021}
}

@inproceedings{zhang2023peanut,
  title={PEANUT: A Human-AI Collaborative Tool for Annotating Audio-Visual Data},
  author={Zhang, Zheng and Ning, Zheng and Xu, Chenliang and Tian, Yapeng and Li, Toby Jia-Jun},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--18},
  year={2023}
}

@inproceedings{gao2014effects,
  title={Effects of public vs. private automated transcripts on multiparty communication between native and non-native English speakers},
  author={Gao, Ge and Yamashita, Naomi and Hautasaari, Ari MJ and Echenique, Andy and Fussell, Susan R},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={843--852},
  year={2014}
}

@inproceedings{junuzovic2011did,
  title={What did I miss? In-meeting review using multimodal accelerated instant replay (AIR) conferencing},
  author={Junuzovic, Sasa and Inkpen, Kori and Hegde, Rajesh and Zhang, Zhengyou and Tang, John and Brooks, Christopher},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={513--522},
  year={2011}
}

@article{morrison2020challenges,
  title={Challenges and barriers in virtual teams: a literature review},
  author={Morrison-Smith, Sarah and Ruiz, Jaime},
  journal={SN Applied Sciences},
  volume={2},
  pages={1--33},
  year={2020},
  publisher={Springer}
}
@article{chi2014icap,
  title={The ICAP framework: Linking cognitive engagement to active learning outcomes},
  author={Chi, Michelene TH and Wylie, Ruth},
  journal={Educational psychologist},
  volume={49},
  number={4},
  pages={219--243},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{gruenfeld1996group,
  title={Group composition and decision making: How member familiarity and information distribution affect process and performance},
  author={Gruenfeld, Deborah H and Mannix, Elizabeth A and Williams, Katherine Y and Neale, Margaret A},
  journal={Organizational behavior and human decision processes},
  volume={67},
  number={1},
  pages={1--15},
  year={1996},
  publisher={Elsevier}
}
@inproceedings{stewart2020beyond,
  title={Beyond team makeup: Diversity in teams predicts valued outcomes in Computer-Mediated collaborations},
  author={Stewart, Angela EB and Amon, Mary Jean and Duran, Nicholas D and D'Mello, Sidney K},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2020}
}
@inproceedings{he2017did,
  title={Why did they do that? Exploring attribution mismatches between native and non-native speakers using videoconferencing},
  author={He, Helen Ai and Yamashita, Naomi and Hautasaari, Ari and Cao, Xun and Huang, Elaine M},
  booktitle={Proceedings of The 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
  pages={297--309},
  year={2017}
}
@article{xu2009makes,
  title={“What makes you shy?”: Understanding situational elicitors of shyness in Chinese children},
  author={Xu, Yiyuan and Farver, Jo Ann M},
  journal={International Journal of Behavioral Development},
  volume={33},
  number={2},
  pages={97--104},
  year={2009},
  publisher={Sage Publications Sage UK: London, England}
}
@book{jones2013communication,
  title={Communication in the real world: An introduction to communication studies},
  author={Jones, Richard},
  year={2013},
  publisher={The Saylor Foundation}
}
@article{ullmann2019visualisation,
  title={A Visualisation Dashboard for Contested Collective Intelligence. Learning Analytics to Improve Sensemaking of Group Discussion},
  author={Ullmann, Thomas Daniel and De Liddo, Anna and Bachler, Michelle},
  journal={RIED: Revista Iboeroamericana de Educaci{\'o}n a Distancia (The Ibero-American Journal of Digital Education)},
  volume={22},
  number={1},
  pages={41--80},
  year={2019}
}
@inproceedings{echenique2014effects,
  title={Effects of video and text support on grounding in multilingual multiparty audio conferencing},
  author={Echenique, Andy and Yamashita, Naomi and Kuzuoka, Hideaki and Hautasaari, Ari},
  booktitle={Proceedings of the 5th ACM international conference on Collaboration across boundaries: culture, distance \& technology},
  pages={73--81},
  year={2014}
}
@incollection{pier2017videoconferencing,
  title={Videoconferencing in Peer Review: Exploring Differences in Efficiency and Outcomes},
  author={Pier, Elizabeth L and Raclaw, Joshua and Ford, Cecilia E and Kaatz, Anna and Carnes, Molly and Nathan, Mitchell J},
  year={2017},
  publisher={Philadelphia, PA: International Society of the Learning Sciences.}
}
@inproceedings{goyal2014effects,
  title={Effects of implicit sharing in collaborative analysis},
  author={Goyal, Nitesh and Leshed, Gilly and Cosley, Dan and Fussell, Susan R},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={129--138},
  year={2014}
}
@article{lee2001mutual,
  title={Mutual knowledge, background knowledge and shared beliefs: Their roles in establishing common ground},
  author={Lee, Benny PH},
  journal={Journal of pragmatics},
  volume={33},
  number={1},
  pages={21--44},
  year={2001},
  publisher={Elsevier}
}
@article{remedios2012learning,
  title={Learning to listen and listening to learn: one student’s experience of small group collaborative learning},
  author={Remedios, Louisa and Clarke, David and Hawthorne, Lesleyanne},
  journal={The Australian Educational Researcher},
  volume={39},
  number={3},
  pages={333--348},
  year={2012},
  publisher={Springer}
}
@article{keysar1998definite,
  title={Definite reference and mutual knowledge: Process models of common ground in comprehension},
  author={Keysar, Boaz and Barr, Dale J and Balin, Jennifer A and Paek, Timothy S},
  journal={Journal of Memory and Language},
  volume={39},
  number={1},
  pages={1--20},
  year={1998},
  publisher={Elsevier}
}
@misc{review_2021, title={How to Combat Zoom Fatigue}, url={https://hbr.org/2020/04/how-to-combat-zoom-fatigue}, journal={Harvard Business Review}, year={2021}, month={Feb}}

 @misc{ko_2021, title={Zoom is a vile teaching tool}, url={https://medium.com/bits-and-behavior/zoom-is-a-vile-teaching-tool-cd19851a4cf9}, journal={Medium}, publisher={Bits and Behavior}, author={Ko, Amy J.}, year={2021}, month={Mar}} 
 
@misc{depositphotos_2021, title={Stanford study into "Zoom Fatigue" explains why video chats are so tiring}, url={https://newatlas.com/telecommunications/zoom-fatigue-video-exhaustion-tips-help-stanford/}, journal={New Atlas}, author={golubovy/Depositphotos and AndreyPopov/Depositphotos and VadymPastukh/Depsoitphotos and ArturVerkhovetskiy/Depositphotos}, year={2021}, month={Feb}}
@misc{morgan_2018, 
title={5 Fatal Flaws With Virtual Meetings}, url={https://www.forbes.com/sites/nickmorgan/2012/10/02/5-fatal-flaws-with-virtual-meetings/?sh=6c8d8230704f}, journal={Forbes}, publisher={Forbes Magazine}, author={Morgan, Nick}, year={2018}, month={May}}

@inproceedings{miller2017through,
  title={Through the looking glass: The effects of feedback on self-awareness and conversational behaviour during video chat},
  author={Miller, Matthew K and Mandryk, Regan L and Birk, Max V and Depping, Ansgar E and Patel, Tushita},
  booktitle={Proceedings of the 2017 CHI conference on human factors in computing systems},
  pages={5271--5283},
  year={2017}
}
@inproceedings{benford2012uncomfortable,
  title={Uncomfortable interactions},
  author={Benford, Steve and Greenhalgh, Chris and Giannachi, Gabriella and Walker, Brendan and Marshall, Joe and Rodden, Tom},
  booktitle={Proceedings of the sigchi conference on human factors in computing systems},
  pages={2005--2014},
  year={2012}
}

@article{zhang2024ladica,
  title={LADICA: A Large Shared Display Interface for Generative AI Cognitive Assistance in Co-Located Team Collaboration},
  author={Zhang, Zheng and Peng, Weirui and Chen, Xinyue and Cao, Luke and Li, Toby Jia-Jun},
  journal={arXiv preprint arXiv:2409.13968},
  year={2024}
}

@article{chen2021afraid,
  title={" I was afraid, but now I enjoy being a streamer!" Understanding the Challenges and Prospects of Using Live Streaming for Online Education},
  author={Chen, Xinyue and Chen, Si and Wang, Xu and Huang, Yun},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW3},
  pages={1--32},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@inproceedings{chen2019integrating,
  title={Integrating Multimedia Tools to Enrich Interactions in Live Streaming for Language Learning},
  author={Chen, Di and Freeman, Dustin and Balakrishnan, Ravin},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2019}
}
@article{wang2019data,
  title={How data scientists use computational notebooks for real-time collaboration},
  author={Wang, April Yi and Mittal, Anant and Brooks, Christopher and Oney, Steve},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={3},
  number={CSCW},
  pages={1--30},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@article{hallnas2001slow,
  title={Slow technology--designing for reflection},
  author={Halln{\"a}s, Lars and Redstr{\"o}m, Johan},
  journal={Personal and ubiquitous computing},
  volume={5},
  number={3},
  pages={201--212},
  year={2001},
  publisher={Springer}
}
@inproceedings{an2020ta,
  title={The TA Framework: Designing real-time teaching augmentation for K-12 classrooms},
  author={An, Pengcheng and Holstein, Kenneth and d'Anjou, Bernice and Eggen, Berry and Bakker, Saskia},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2020}
}
@article{bailey2006need,
  title={On the need for attention-aware systems: Measuring effects of interruption on task performance, error rate, and affective state},
  author={Bailey, Brian P and Konstan, Joseph A},
  journal={Computers in human behavior},
  volume={22},
  number={4},
  pages={685--708},
  year={2006},
  publisher={Elsevier}
}

@article{martinez2019handheld,
  title={A handheld classroom dashboard: Teachers’ perspectives on the use of real-time collaborative learning analytics},
  author={Martinez-Maldonado, Roberto},
  journal={International Journal of Computer-Supported Collaborative Learning},
  volume={14},
  number={3},
  pages={383--411},
  year={2019},
  publisher={Springer}
}
@inproceedings{macneil2019ineqdetect,
  title={Ineqdetect: A visual analytics system to detect conversational inequality and support reflection during active learning},
  author={MacNeil, Stephen and Kiefer, Kyle and Thompson, Brian and Takle, Dev and Latulipe, Celine},
  booktitle={Proceedings of the ACM Conference on Global Computing Education},
  pages={85--91},
  year={2019}
}
@inproceedings{gibson2017dashboard,
  title={That dashboard looks nice, but what does it mean? Towards making meaning explicit in learning analytics design},
  author={Gibson, Andrew and Martinez-Maldonado, Roberto},
  booktitle={Proceedings of the 29th Australian Conference on Computer-Human Interaction},
  pages={528--532},
  year={2017}
}

@article{cornide2020multimodal,
  title={A Multimodal Real-Time Feedback Platform Based on Spoken Interactions for Remote Active Learning Support},
  author={Cornide-Reyes, Hector and Riquelme, Fabi{\'a}n and Monsalves, Diego and Noel, Rene and Cechinel, Cristian and Villarroel, Rodolfo and Ponce, Francisco and Munoz, Roberto},
  journal={Sensors},
  volume={20},
  number={21},
  pages={6337},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{odom2014designing,
  title={Designing for slowness, anticipation and re-visitation: a long term field study of the photobox},
  author={Odom, William T and Sellen, Abigail J and Banks, Richard and Kirk, David S and Regan, Tim and Selby, Mark and Forlizzi, Jodi L and Zimmerman, John},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={1961--1970},
  year={2014}
}

@inproceedings{odom2015understanding,
  title={Understanding long-term interactions with a slow technology: an investigation of experiences with FutureMe},
  author={Odom, William},
  booktitle={Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
  pages={575--584},
  year={2015}
}

@inproceedings{odom2018attending,
  title={Attending to slowness and temporality with olly and slow game: A design inquiry into supporting longer-term relations with everyday computational objects},
  author={Odom, William and Wakkary, Ron and Bertran, Ishac and Harkness, Matthew and Hertz, Garnet and Hol, Jeroen and Lin, Henry and Naus, Bram and Tan, Perry and Verburg, Pepijn},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2018}
}
@inproceedings{halbert2015designing,
  title={Designing for discomfort: Supporting critical reflection through interactive tools},
  author={Halbert, Helen and Nathan, Lisa P},
  booktitle={Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
  pages={349--360},
  year={2015}
}
@article{aseniero2020meetcues,
  title={MeetCues: Supporting Online Meetings Experience},
  author={Aseniero, Bon Adriel and Constantinides, Marios and Joglekar, Sagar and Zhou, Ke and Quercia, Daniele},
  journal={arXiv preprint arXiv:2010.06259},
  year={2020}
}
@article{benke2020chatbot,
  title={Chatbot-based emotion management for distributed teams: A participatory design study},
  author={Benke, Ivo and Knierim, Michael Thomas and Maedche, Alexander},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW2},
  pages={1--30},
  year={2020},
  publisher={ACM New York, NY, USA}
}
@inproceedings{geller2020confused,
  title={Confused and beyond: detecting confusion in course forums using students' hashtags},
  author={Geller, Shay A and Hoernle, Nicholas and Gal, Kobi and Segal, Avi and Zhang, Amy X and Karger, David and Facciotti, Marc T and Igo, Michele},
  booktitle={Proceedings of the Tenth International Conference on Learning Analytics and Knowledge},
  pages={589--594},
  year={2020}
}
@article{tian2021system,
  title={A System for Interleaving Discussion and Summarization in Online Collaboration},
  author={Tian, Sunny and Zhang, Amy X and Karger, David},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW3},
  pages={1--27},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{suh2018s,
  title={" It's Kind of Boring Looking at Just the Face" How Teens Multitask During Mobile Videochat},
  author={Suh, Minhyang and Bentley, Frank and Lottridge, Danielle},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={2},
  number={CSCW},
  pages={1--23},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@article{jarboe1996intragroup,
  title={Intragroup conflict management in task-oriented groups: The influence of problem sources and problem analyses},
  author={Jarboe, Susan C and Witteman, Hal R},
  journal={Small group research},
  volume={27},
  number={2},
  pages={316--338},
  year={1996},
  publisher={SAGE PUBLICATIONS, INC. 2455 Teller Road, Thousand Oaks, CA 91320}
}
@article{wall1987small,
  title={Small, task-oriented groups: Conflict, conflict management, satisfaction, and decision quality},
  author={Wall Jr, Victor D and Galanes, Gloria J and Love, SueBeth},
  journal={Small Group Behavior},
  volume={18},
  number={1},
  pages={31--55},
  year={1987},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}
@article{brennan1998grounding,
  title={The grounding problem in conversations with and through computers},
  author={Brennan, Susan E},
  journal={Social and cognitive approaches to interpersonal communication},
  pages={201--225},
  year={1998}
}
@incollection{dyke2013towards,
  title={Towards academically productive talk supported by conversational agents},
  author={Dyke, Gregory and Howley, Iris and Adamson, David and Kumar, Rohit and Ros{\'e}, Carolyn Penstein},
  booktitle={Productive multivocality in the analysis of group interactions},
  pages={459--476},
  year={2013},
  publisher={Springer}
}

@article{duncan1985superiority,
  title={The superiority theory of humor at work: Joking relationships as indicators of formal and informal status patterns in small, task-oriented groups},
  author={Duncan, W Jack},
  journal={Small Group Behavior},
  volume={16},
  number={4},
  pages={556--564},
  year={1985},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{sanford2004audio,
  title={Audio channel constraints in video-mediated communication},
  author={Sanford, Alison and H. Anderson, Anne and Mullin, Jim},
  journal={Interacting with Computers},
  volume={16},
  number={6},
  pages={1069--1094},
  year={2004},
  publisher={Oxford University Press Oxford, UK}
}
@inproceedings{veinott1999video,
  title={Video helps remote work: Speakers who need to negotiate common ground benefit from seeing each other},
  author={Veinott, Elizabeth S and Olson, Judith and Olson, Gary M and Fu, Xiaolan},
  booktitle={Proceedings of the SIGCHI conference on Human Factors in Computing Systems},
  pages={302--309},
  year={1999}
}
@inproceedings{lucero2015using,
  title={Using affinity diagrams to evaluate interactive prototypes},
  author={Lucero, Andr{\'e}s},
  booktitle={IFIP Conference on Human-Computer Interaction},
  pages={231--248},
  year={2015},
  organization={Springer}
}
@inproceedings{davidoff2007rapidly,
  title={Rapidly exploring application design through speed dating},
  author={Davidoff, Scott and Lee, Min Kyung and Dey, Anind K and Zimmerman, John},
  booktitle={International Conference on Ubiquitous Computing},
  pages={429--446},
  year={2007},
  organization={Springer}
}
@inproceedings{chiang2020exploring,
  title={Exploring the design space of user-system communication for smart-home routine assistants},
  author={Chiang, Yi-Shyuan and Chang, Ruei-Che and Chuang, Yi-Lin and Chou, Shih-Ya and Lee, Hao-Ping and Lin, I-Ju and Jiang Chen, Jian-Hua and Chang, Yung-Ju},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2020}
}

@inproceedings{tenorio2020raising,
  title={Raising teachers empowerment in gamification design of adaptive learning systems: a qualitative research},
  author={Ten{\'o}rio, Kamilla and Dermeval, Diego and Monteiro, Mateus and Peixoto, Aristoteles and Pedro, Alan},
  booktitle={International Conference on Artificial Intelligence in Education},
  pages={524--536},
  year={2020},
  organization={Springer}
}

@inproceedings{dillahunt2018designing,
  title={Designing future employment applications for underserved job seekers: a speed dating study},
  author={Dillahunt, Tawanna R and Lam, Jason and Lu, Alex and Wheeler, Earnest},
  booktitle={Proceedings of the 2018 Designing Interactive Systems Conference},
  pages={33--44},
  year={2018}
}
@inproceedings{holstein2017intelligent,
  title={Intelligent tutors as teachers' aides: exploring teacher needs for real-time analytics in blended classrooms},
  author={Holstein, Kenneth and McLaren, Bruce M and Aleven, Vincent},
  booktitle={Proceedings of the seventh international learning analytics and knowledge conference},
  pages={257--266},
  year={2017}
}
@inproceedings{davidoff2007rapidly,
  title={Rapidly exploring application design through speed dating},
  author={Davidoff, Scott and Lee, Min Kyung and Dey, Anind K and Zimmerman, John},
  booktitle={International Conference on Ubiquitous Computing},
  pages={429--446},
  year={2007},
  organization={Springer}
}

@article{zimmerman2017speed,
  title={Speed dating: providing a menu of possible futures},
  author={Zimmerman, John and Forlizzi, Jodi},
  journal={She Ji: The Journal of Design, Economics, and Innovation},
  volume={3},
  number={1},
  pages={30--50},
  year={2017},
  publisher={Elsevier}
}
@inproceedings{laschke2020meaningful,
  title={Meaningful Technology at Work-A Reflective Design Case of Improving Radiologists' Wellbeing Through Medical Technology},
  author={Laschke, Matthias and Braun, Christoph and Neuhaus, Robin and Hassenzahl, Marc},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2020}
}

@inproceedings{luria2020social,
  title={Social Boundaries for Personal Agents in the Interpersonal Space of the Home},
  author={Luria, Michal and Zheng, Rebecca and Huffman, Bennett and Huang, Shuangni and Zimmerman, John and Forlizzi, Jodi},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2020}
}

@inproceedings{chandra2012designing,
  title={Designing to support prescribed home exercises: understanding the needs of physiotherapy patients},
  author={Chandra, Hitee and Oakley, Ian and Silva, Hugo},
  booktitle={Proceedings of the 7th Nordic Conference on Human-Computer Interaction: Making Sense Through Design},
  pages={607--616},
  year={2012}
}

@inproceedings{park2010investigating,
  title={Investigating the opportunity for a smart activity bag},
  author={Park, Sun Young and Zimmerman, John},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={2543--2552},
  year={2010}
}

@article{samrose2018coco,
  title={Coco: Collaboration coach for understanding team dynamics during video conferencing},
  author={Samrose, Samiha and Zhao, Ru and White, Jeffery and Li, Vivian and Nova, Luis and Lu, Yichen and Ali, Mohammad Rafayet and Hoque, Mohammed Ehsan},
  journal={Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies},
  volume={1},
  number={4},
  pages={1--24},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@article{dimicco2007impact,
  title={The impact of increased awareness while face-to-face},
  author={DiMicco, Joan Morris and Hollenbach, Katherine J and Pandolfo, Anna and Bender, Walter},
  journal={Human--Computer Interaction},
  volume={22},
  number={1-2},
  pages={47--96},
  year={2007},
  publisher={Taylor \& Francis}
}

@InProceedings{samrose2021meetingcoach,
author = {Samrose, Samiha and McDuff, Daniel and Sim, Robert and Suh, Jina and Rowan, Kael and Hernandez, Javier and Rintel, Sean and Moynihan, Kevin and Czerwinski, Mary},
title = {MeetingCoach: An Intelligent Dashboard for Supporting Effective and Inclusive Meetings},
booktitle = {CHI 2021},
year = {2021},
month = {May},url = {https://www.microsoft.com/en-us/research/publication/meetingcoach-an-intelligent-dashboard-for-supporting-effective-inclusive-meetings/},
}
@misc{cao2021large,
    title={Large Scale Analysis of Multitasking Behavior During Remote Meetings},
    author={Hancheng Cao and Chia-Jung Lee and Shamsi Iqbal and Mary Czerwinski and Priscilla Wong and Sean Rintel and Brent Hecht and Jaime Teevan and Longqi Yang},
    year={2021},
    eprint={2101.11865},
    archivePrefix={arXiv},
    primaryClass={cs.CY}
}
@misc{koschmann2003reconsidering,
  title={Reconsidering Common Ground: Examining Clark's Contribution Theory in the OR. ECSCW 2003: the Eighth European Conference on Computer-Supported Cooperative Work},
  author={Koschmann, T},
  year={2003},
  publisher={Kluwer Academic Publishing}
}

@article{bjork2020desirable,
  title={Desirable difficulties in theory and practice.},
  author={Bjork, Robert A and Bjork, Elizabeth L},
  journal={Journal of Applied research in Memory and Cognition},
  volume={9},
  number={4},
  pages={475},
  year={2020},
  publisher={Elsevier Science}
}

@inproceedings{birnholtz2005grounding,
  title={Grounding needs: achieving common ground via lightweight chat in large, distributed, ad-hoc groups},
  author={Birnholtz, Jeremy P and Finholt, Thomas A and Horn, Daniel B and Bae, Sung Joo},
  booktitle={Proceedings of the SIGCHI conference on Human factors in computing systems},
  pages={21--30},
  year={2005}
}
@misc{Microsoft, url={https://www.microsoft.com/en-us/worklab/work-trend-index/brain-research}, journal={Microsoft}, author = {Microsoft}, year = {2023}} 
@misc{Otter.ai_2023, url={https://help.otter.ai/hc/en-us/articles/5093383818263-Automated-Live-Summary-Overview}, journal={Automated live summary overview – otter.ai help center}, author={Otter.ai}, year={2023}} 
@inproceedings{convertino2008articulating,
  title={Articulating common ground in cooperative work: content and process},
  author={Convertino, Gregorio and Mentis, Helena M and Rosson, Mary Beth and Carroll, John M and Slavkovic, Aleksandra and Ganoe, Craig H},
  booktitle={Proceedings of the SIGCHI conference on human factors in computing systems},
  pages={1637--1646},
  year={2008}
}
@inproceedings{nakano2003towards,
  title={Towards a model of face-to-face grounding},
  author={Nakano, Yukiko I and Reinstein, Gabe and Stocky, Tom and Cassell, Justine},
  booktitle={Proceedings of the 41st annual meeting of the Association for Computational Linguistics},
  pages={553--561},
  year={2003}
}

@inproceedings{jung2017affective,
  title={Affective grounding in human-robot interaction},
  author={Jung, Malte F},
  booktitle={2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI},
  pages={263--273},
  year={2017},
  organization={IEEE}
}
@inproceedings{pustejovsky2017creating,
  title={Creating common ground through multimodal simulations},
  author={Pustejovsky, James and Krishnaswamy, Nikhil and Draper, Bruce and Narayana, Pradyumna and Bangar, Rahul},
  booktitle={Proceedings of the IWCS workshop on Foundations of Situated and Multimodal Communication},
  year={2017}
}

@article{paus2012common,
  title={Common ground? How the encoding of specialist vocabulary affects peer-to-peer online discourse},
  author={Paus, Elisabeth and Jucks, Regina},
  journal={Discourse Processes},
  volume={49},
  number={7},
  pages={565--598},
  year={2012},
  publisher={Taylor \& Francis}
}
@inproceedings{rae2012one,
  title={One of the gang: supporting in-group behavior for embodied mediated communication},
  author={Rae, Irene and Takayama, Leila and Mutlu, Bilge},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={3091--3100},
  year={2012}
}
@inproceedings{kuzminykh2020low,
  title={Low Engagement As a Deliberate Practice of Remote Participants in Video Meetings},
  author={Kuzminykh, Anastasia and Rintel, Sean},
  booktitle={Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--9},
  year={2020}
}
@inproceedings{shamekhi2018face,
  title={Face Value? Exploring the effects of embodiment for a group facilitation agent},
  author={Shamekhi, Ameneh and Liao, Q Vera and Wang, Dakuo and Bellamy, Rachel KE and Erickson, Thomas},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2018}
}
@article{fruchter2011building,
  title={Building common ground in global teamwork through re-representation},
  author={Fruchter, Renate and Courtier, Rodolphe},
  journal={AI \& society},
  volume={26},
  number={3},
  pages={233--245},
  year={2011},
  publisher={Springer}
}
@article{anderson2007virtual,
  title={Virtual team meetings: An analysis of communication and context},
  author={Anderson, Anne H and McEwan, Rachel and Bal, Jay and Carletta, Jean},
  journal={Computers in Human Behavior},
  volume={23},
  number={5},
  pages={2558--2580},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{dong2012one,
  title={One piece at a time: why video-based communication is better for negotiation and conflict resolution},
  author={Dong, Wei and Fu, Wai-Tat},
  booktitle={Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work},
  pages={167--176},
  year={2012}
}
@book{clark1996using,
  title={Using language},
  author={Clark, Herbert H},
  year={1996},
  publisher={Cambridge university press}
}
@article{clark1982hearers,
  title={Hearers and speech acts},
  author={Clark, Herbert H and Carlson, Thomas B},
  journal={Language},
  pages={332--373},
  year={1982},
  publisher={JSTOR}
}

@article{clark1986referring,
  title={Referring as a collaborative process},
  author={Clark, Herbert H and Wilkes-Gibbs, Deanna},
  journal={Cognition},
  volume={22},
  number={1},
  pages={1--39},
  year={1986},
  publisher={Elsevier}
}

@article{clark2004speaking,
  title={Speaking while monitoring addressees for understanding},
  author={Clark, Herbert H and Krych, Meredyth A},
  journal={Journal of memory and language},
  volume={50},
  number={1},
  pages={62--81},
  year={2004},
  publisher={Elsevier}
}

@inproceedings{lee2012micro,
  title={Micro-coordination: because we did not already learn everything we need to know about working with others in kindergarten},
  author={Lee, Joon Suk and Tatar, Deborah and Harrison, Steve},
  booktitle={Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work},
  pages={1135--1144},
  year={2012}
}

@inproceedings{lee2014sounds,
  title={Sounds of silence: exploring contributions to conversations, non-responses and the impact of mediating technologies in triple space},
  author={Lee, Joon Suk and Tatar, Deborah},
  booktitle={Proceedings of the 17th ACM conference on Computer supported cooperative work \& social computing},
  pages={1561--1572},
  year={2014}
}
@inproceedings{wang2010groups,
  title={Groups in groups: conversational similarity in online multicultural multiparty brainstorming},
  author={Wang, Hao-Chuan and Fussell, Susan},
  booktitle={Proceedings of the 2010 ACM conference on Computer supported cooperative work},
  pages={351--360},
  year={2010}
}
@article{anderson2006achieving,
  title={Achieving understanding in face-to-face and video-mediated multiparty interactions},
  author={Anderson, Anne H},
  journal={Discourse processes},
  volume={41},
  number={3},
  pages={251--287},
  year={2006},
  publisher={Taylor \& Francis}
}
@article{beers2006common,
  title={Common ground, complex problems and decision making},
  author={Beers, Pieter J and Boshuizen, Henny PA and Kirschner, Paul A and Gijselaers, Wim H},
  journal={Group decision and negotiation},
  volume={15},
  number={6},
  pages={529--556},
  year={2006},
  publisher={Springer}
}

@inproceedings{convertino2009supporting,
  title={Supporting content and process common ground in computer-supported teamwork},
  author={Convertino, Gregorio and Mentis, Helena M and Rosson, Mary Beth and Slavkovic, Aleksandra and Carroll, John M},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={2339--2348},
  year={2009}
}

@book{mcgrath1984groups,
  title={Groups: Interaction and performance},
  author={McGrath, Joseph Edward},
  volume={14},
  year={1984},
  publisher={Prentice-Hall Englewood Cliffs, NJ}
}

@inproceedings{Audiotool,
author = {Hughes, Maggie and Roy, Deb},
title = {Keeper: An Online Synchronous Conversation Environment Informed by In-Person Facilitation Practices},
year = {2020},
isbn = {9781450380591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406865.3418344},
doi = {10.1145/3406865.3418344},
booktitle = {Conference Companion Publication of the 2020 on Computer Supported Cooperative Work and Social Computing},
pages = {275–279},
numpages = {5},
keywords = {facilitation, design, computer-mediated communication},
location = {Virtual Event, USA},
series = {CSCW '20 Companion}
}

@incollection{wang2017contrasting,
  title={Contrasting explicit and implicit support for transactive exchange in team oriented project based learning},
  author={Wang, Xu and Wen, Miaomiao and Rose, Carolyn},
  year={2017},
  publisher={Philadelphia, PA: International Society of the Learning Sciences.}
}

@inproceedings{chen2019integrating,
  title={Integrating Multimedia Tools to Enrich Interactions in Live Streaming for Language Learning},
  author={Chen, Di and Freeman, Dustin and Balakrishnan, Ravin},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2019}
}
@article{dillenbourg2006sharing,
  title={Sharing solutions: Persistence and grounding in multimodal collaborative problem solving},
  author={Dillenbourg, Pierre and Traum, David},
  journal={The Journal of the Learning Sciences},
  volume={15},
  number={1},
  pages={121--151},
  year={2006},
  publisher={Taylor \& Francis}
}
@article{liu2018consensus,
  title={ConsensUs: Supporting multi-criteria group decisions by visualizing points of disagreement},
  author={Liu, Weichen and Xiao, Sijia and Browne, Jacob T and Yang, Ming and Dow, Steven P},
  journal={ACM Transactions on Social Computing},
  volume={1},
  number={1},
  pages={1--26},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@article{lunenburg2010communication,
  title={Communication: The process, barriers, and improving effectiveness},
  author={Lunenburg, Fred C},
  journal={Schooling},
  volume={1},
  number={1},
  pages={1--10},
  year={2010}
}
@inproceedings{clark2019makes,
  title={What makes a good conversation? challenges in designing truly conversational agents},
  author={Clark, Leigh and Pantidi, Nadia and Cooney, Orla and Doyle, Philip and Garaialde, Diego and Edwards, Justin and Spillane, Brendan and Gilmartin, Emer and Murad, Christine and Munteanu, Cosmin and others},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2019}
}
@inproceedings{kriplean2012you,
  title={Is this what you meant? Promoting listening on the web with reflect},
  author={Kriplean, Travis and Toomim, Michael and Morgan, Jonathan and Borning, Alan and Ko, Andrew},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={1559--1568},
  year={2012}
}
@inproceedings{kim2020bot,
  title={Bot in the Bunch: Facilitating Group Chat Discussion by Improving Efficiency and Participation with a Chatbot},
  author={Kim, Soomin and Eun, Jinsu and Oh, Changhoon and Suh, Bongwon and Lee, Joonhwan},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2020}
}
@inproceedings{chandrasegaran2019talktraces,
  title={TalkTraces: real-time capture and visualization of verbal content in meetings},
  author={Chandrasegaran, Senthil and Bryan, Chris and Shidara, Hidekazu and Chuang, Tung-Yen and Ma, Kwan-Liu},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2019}
}
@inproceedings{schiavo2014overt,
  title={Overt or subtle? Supporting group conversations with automatically targeted directives},
  author={Schiavo, Gianluca and Cappelletti, Alessandro and Mencarini, Eleonora and Stock, Oliviero and Zancanaro, Massimo},
  booktitle={Proceedings of the 19th international conference on Intelligent User Interfaces},
  pages={225--234},
  year={2014}
}
@inproceedings{kittur2007he,
  title={He says, she says: conflict and coordination in Wikipedia},
  author={Kittur, Aniket and Suh, Bongwon and Pendleton, Bryan A and Chi, Ed H},
  booktitle={Proceedings of the SIGCHI conference on Human factors in computing systems},
  pages={453--462},
  year={2007}
}
@inproceedings{gergle2004action,
  title={Action as language in a shared visual space},
  author={Gergle, Darren and Kraut, Robert E and Fussell, Susan R},
  booktitle={Proceedings of the 2004 ACM conference on Computer supported cooperative work},
  pages={487--496},
  year={2004}
}
@inproceedings{smith2018communication,
  title={Communication behavior in embodied virtual reality},
  author={Smith, Harrison Jesse and Neff, Michael},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2018}
}
@inproceedings{tu2018you,
  title={Do you think what I think: Perceptions of delayed instant messages in computer-mediated communication of romantic relations},
  author={Tu, Pei-Yun and Yuan, Chien Wen and Wang, Hao-Chuan},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--11},
  year={2018}
}
@article{fahy2006online,
  title={Online and face-to-face group interaction processes compared using Bales' interaction process analysis (IPA)},
  author={Fahy, Patrick J},
  journal={European Journal of open, distance and e-learning},
  volume={9},
  number={1},
  year={2006}
}
@article{mustajoki2012speaker,
  title={A speaker-oriented multidimensional approach to risks and causes of miscommunication},
  author={Mustajoki, Arto},
  journal={Language and dialogue},
  volume={2},
  number={2},
  pages={216--243},
  year={2012},
  publisher={John Benjamins}
}
@article{clark1989contributing,
  title={Contributing to discourse},
  author={Clark, Herbert H and Schaefer, Edward F},
  journal={Cognitive science},
  volume={13},
  number={2},
  pages={259--294},
  year={1989},
  publisher={Elsevier}
}
@inproceedings{koschmann2003reconsidering,
  title={Reconsidering common ground},
  author={Koschmann, Timothy and LeBaron, Curtis D},
  booktitle={ECSCW 2003},
  pages={81--98},
  year={2003},
  organization={Springer}
}
@book{ellis1999crafting,
  title={Crafting society: Ethnicity, class, and communication theory},
  author={Ellis, Donald G},
  year={1999},
  publisher={Routledge}
}
@book{heath2013human,
  title={Human communication theory and research: Concepts, contexts, and challenges},
  author={Heath, Robert L and Bryant, Jennings},
  year={2013},
  publisher={Routledge}
}
@book{mcquail1987mass,
  title={Mass communication theory: An introduction},
  author={McQuail, Denis},
  year={1987},
  publisher={Sage Publications, Inc}
}
@article{grover2005shaping,
  title={Shaping effective communication skills and therapeutic relationships at work: The foundation of collaboration},
  author={Grover, Susan M},
  journal={Aaohn journal},
  volume={53},
  number={4},
  pages={177--182},
  year={2005},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}
@article{isohatala2018striking,
  title={Striking a balance: Socio-emotional processes during argumentation in collaborative learning interaction},
  author={Isoh{\"a}t{\"a}l{\"a}, Jaana and N{\"a}ykki, Piia and J{\"a}rvel{\"a}, Sanna and Baker, Michael J},
  journal={Learning, Culture and Social Interaction},
  volume={16},
  pages={1--19},
  year={2018},
  publisher={Elsevier}
}
@article{o1996shifting,
  title={Shifting participant frameworks: Orchestrating thinking practices in group discussion},
  author={O’Connor, Mary Catherine and Michaels, Sarah},
  journal={Discourse, learning, and schooling},
  volume={63},
  pages={103},
  year={1996}
}
@article{clark1991grounding,
  title={Grounding in communication.},
  author={Clark, Herbert H and Brennan, Susan E},
  year={1991},
  publisher={American Psychological Association}
}
@article{clark1987collaborating,
  title={Collaborating on contributions to conversations},
  author={Clark, Herbert H and Schaefer, Edward F},
  journal={Language and cognitive processes},
  volume={2},
  number={1},
  pages={19--41},
  year={1987},
  publisher={Taylor \& Francis}
}
@article{jonassen2001communication,
  title={Communication patterns in computer mediated versus face-to-face group problem solving},
  author={Jonassen, David H and Kwon, Hyug},
  journal={Educational technology research and development},
  volume={49},
  number={1},
  pages={35},
  year={2001},
  publisher={Springer}
}
@article{jenks2012doing,
  title={Doing being reprehensive: Some interactional features of English as a lingua franca in a chat room},
  author={Jenks, Christopher Joseph},
  journal={Applied Linguistics},
  volume={33},
  number={4},
  pages={386--405},
  year={2012},
  publisher={Oxford University Press}
}
@article{fonteijn2019group,
  title={Group work and group dynamics in PBL},
  author={Fonteijn, Herco TH and Dolmans, Diana HJM},
  journal={The Wiley handbook of problem-based learning},
  pages={199--220},
  year={2019},
  publisher={Wiley Online Library}
}
@article{toomaneejinda2018disagreement,
  title={Disagreement practices in ELF academic group discussion: verbal, nonverbal and interactional strategies},
  author={Toomaneejinda, Anuchit and Harding, Luke},
  journal={Journal of English as a Lingua Franca},
  volume={7},
  number={2},
  pages={307--332},
  year={2018},
  publisher={De Gruyter Mouton}
}
@article{macdonald2003assessing,
  title={Assessing online collaborative learning: process and product},
  author={Macdonald, Janet},
  journal={Computers \& Education},
  volume={40},
  number={4},
  pages={377--391},
  year={2003},
  publisher={Elsevier}
}
@article{kumar2011conversational,
  title={Conversational strategies that support idea generation productivity in groups},
  author={Kumar, Rohit and Beuth, Jack and Rose, Carolyn},
  year={2011},
  publisher={International Society of the Learning Sciences}
}
@book{myers2008fundamentals,
  title={The fundamentals of small group communication},
  author={Myers, Scott A and Anderson, Carolyn M},
  year={2008},
  publisher={Sage Publications}
}

@inproceedings{nowak2023hear,
  title={Hear We Are: Spatial Audio Benefits Perceptions of Turn-Taking and Social Presence in Video Meetings},
  author={Nowak, Kate and Tankelevitch, Lev and Tang, John and Rintel, Sean},
  booktitle={Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
  pages={1--10},
  year={2023}
}

@article{hou2011analyzing,
  title={Analyzing the social knowledge construction behavioral patterns of an online synchronous collaborative discussion instructional activity using an instant messaging tool: A case study},
  author={Hou, Huei-Tse and Wu, Sheng-Yi},
  journal={Computers \& Education},
  volume={57},
  number={2},
  pages={1459--1468},
  year={2011},
  publisher={Elsevier}
}
@inproceedings{xiao2020if,
  title={If I Hear You Correctly: Building and Evaluating Interview Chatbots with Active Listening Skills},
  author={Xiao, Ziang and Zhou, Michelle X and Chen, Wenxi and Yang, Huahai and Chi, Changyan},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2020}
}
@inproceedings{lee2020solutionchat,
  title={SolutionChat: Real-time Moderator Support for Chat-based Structured Discussion},
  author={Lee, Sung-Chul and Song, Jaeyoon and Ko, Eun-Young and Park, Seongho and Kim, Jihee and Kim, Juho},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2020}
}
@inproceedings{maddock2017talking,
  title={Talking about talk: coordination in large online communities},
  author={Maddock, Jim and Shaw, Aaron and Gergle, Darren},
  booktitle={Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
  pages={1869--1876},
  year={2017}
}
@inproceedings{MyriadHub,
author = {Kokkalis, Nicolas and Fan, Chengdiao and Roith, Johannes and Bernstein, Michael S. and Klemmer, Scott},
title = {MyriadHub: Efficiently Scaling Personalized Email Conversations with Valet Crowdsourcing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025954},
doi = {10.1145/3025453.3025954},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {73–84},
numpages = {12},
keywords = {mail merge, valet crowdsourcing, email overload},
location = {Denver, Colorado, USA},
series = {CHI '17}
}
@inproceedings{kriplean2012you,
  title={Is this what you meant? Promoting listening on the web with reflect},
  author={Kriplean, Travis and Toomim, Michael and Morgan, Jonathan and Borning, Alan and Ko, Andrew},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={1559--1568},
  year={2012}
}
@inproceedings{teevan2016supporting,
  title={Supporting collaborative writing with microtasks},
  author={Teevan, Jaime and Iqbal, Shamsi T and Von Veh, Curtis},
  booktitle={Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
  pages={2657--2668},
  year={2016}
}
@article{rice2007improving,
  title={Improving the effectiveness of virtual teams by adapting team processes},
  author={Rice, Daniel J and Davidson, Barry D and Dannenhoffer, John F and Gay, Geri K},
  journal={Computer Supported Cooperative Work (CSCW)},
  volume={16},
  number={6},
  pages={567--594},
  year={2007},
  publisher={Springer}
}
@article{zhang2018mobile,
  title={Mobile social media in inter-organizational projects: Aligning tool, task and team for virtual collaboration effectiveness},
  author={Zhang, Yali and Sun, Jun and Yang, Zhaojun and Wang, Ying},
  journal={International Journal of Project Management},
  volume={36},
  number={8},
  pages={1096--1108},
  year={2018},
  publisher={Elsevier}
}
@article{yanguas2018focus,
  title={Focus on form in task-based L2 oral computer-mediated communication},
  author={Yanguas, Inigo and Bergin, Tyler},
  journal={Language Learning \& Technology},
  volume={22},
  number={3},
  pages={65--81},
  year={2018},
  publisher={University of Hawaii National Foreign Language Resource Center}
}
@inproceedings{masyagin2020understanding,
  title={Understanding Interaction and Communication Challenges Present in Software Engineering.},
  author={Masyagin, Sergey and Succi, Giancarlo and Yermolaieva, Sofiia and Zagvozkina, Nadezhda},
  booktitle={ENASE},
  pages={572--578},
  year={2020}
}
@article{chang2016challenges,
  title={Challenges facing group work online},
  author={Chang, Bo and Kang, Haijun},
  journal={Distance Education},
  volume={37},
  number={1},
  pages={73--88},
  year={2016},
  publisher={Taylor \& Francis}
}
@book{wainfan2004challenges,
  title={Challenges in virtual collaboration: Videoconferencing, audioconferencing, and computer-mediated communications},
  author={Wainfan, Lynne and Davis, Paul K},
  year={2004},
  publisher={Rand Corporation}
}
@article{mccroskey1977oral,
  title={Oral communication apprehension: A summary of recent theory and research},
  author={McCroskey, James C},
  journal={Human communication research},
  volume={4},
  number={1},
  pages={78--96},
  year={1977},
  publisher={Oxford University Press}
}
@article{zhang2018making,
  title={Making sense of group chat through collaborative tagging and summarization},
  author={Zhang, Amy X and Cranshaw, Justin},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={2},
  number={CSCW},
  pages={1--27},
  year={2018},
  publisher={ACM New York, NY, USA}
}


@article{cameron2005unintended,
  title={Unintended consequences of emerging communication technologies: Instant messaging in the workplace},
  author={Cameron, Ann Frances and Webster, Jane},
  journal={Computers in Human behavior},
  volume={21},
  number={1},
  pages={85--103},
  year={2005},
  publisher={Elsevier}
}


@misc{larsson2020communication,
  title={Communication challenges perceived by leaders of different sized virtual teams, and how they are managed: Experiences from leaders within Swedish organizations},
  author={Larsson, Daniella and Wahlgren, Matilda},
  year={2020}
}
@inproceedings{zhang2017toward,
  title={Toward a supporting system of communication skill: the influence of functional roles of participants in group discussion},
  author={Zhang, Qi and Huang, Hung-Hsuan and Kimura, Seiya and Okada, Shogo and Hayashi, Yuki and Takase, Yutaka and Nakano, Yukiko and Ohta, Naoki and Kuwabara, Kazuhiro},
  booktitle={International Conference on Social Computing and Social Media},
  pages={178--188},
  year={2017},
  organization={Springer}
}


@article{content,
author = {Krippendorff, Klaus},
title = {{Reliability in Content Analysis: Some Common Misconceptions and Recommendations}},
journal = {Human Communication Research},
year = {2006},
volume = {30},
number = {3},
pages = {411--433},
month = jan
}
@article{braun2006using,
  title={Using thematic analysis in psychology},
  author={Braun, Virginia and Clarke, Victoria},
  journal={Qualitative research in psychology},
  volume={3},
  number={2},
  pages={77--101},
  year={2006},
  publisher={Taylor \& Francis}
}
@book{charmaz2006constructing,
  title={Constructing grounded theory: A practical guide through qualitative analysis},
  author={Charmaz, Kathy},
  year={2006},
  publisher={sage}
}
@inproceedings{seering2020takes,
  title={It Takes a Village: Integrating an Adaptive Chatbot into an Online Gaming Community},
  author={Seering, Joseph and Luria, Michal and Ye, Connie and Kaufman, Geoff and Hammer, Jessica},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2020}
}

@inproceedings{wohn2017face,
  title={Face to face matters: communication modality, perceived social support, and psychological wellbeing},
  author={Wohn, Donghee Yvette and Peng, Wei and Zytko, Doug},
  booktitle={Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
  pages={3019--3026},
  year={2017}
}
@article{mayer2016small,
  title={Small group work and whole group discussion mediated through web conferencing software},
  author={Mayer, Greg},
  journal={International Journal for the Scholarship of Technology Enhanced Learning},
  volume={1},
  number={1},
  pages={43--64},
  year={2016}
}
@article{pietikainen2018misunderstandings,
  title={Misunderstandings and ensuring understanding in private ELF talk},
  author={Pietik{\"a}inen, Kaisa S},
  journal={Applied Linguistics},
  volume={39},
  number={2},
  pages={188--212},
  year={2018},
  publisher={Oxford University Press}
}


%%%% NLP STUFF %%%%

@article{chen2020dirichlet,
  title={A Dirichlet process biterm-based mixture model for short text stream clustering},
  author={Chen, Junyang and Gong, Zhiguo and Liu, Weiwen},
  journal={Applied Intelligence},
  volume={50},
  pages={1609--1619},
  year={2020},
  publisher={Springer}
}

@inproceedings{kumar2020online,
  title={An online semantic-enhanced Dirichlet model for short text stream clustering},
  author={Kumar, Jay and Shao, Junming and Uddin, Salah and Ali, Wazir},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={766--776},
  year={2020}
}


%%% Related Work %%%

@article{Jiang2023GraphologueEL,
  title={Graphologue: Exploring Large Language Model Responses with Interactive Diagrams},
  author={Peiling Jiang and Jude Rayan and Steven W. Dow and Haijun Xia},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.11473},
  url={https://api.semanticscholar.org/CorpusID:258823121}
}


@article{Suh2023SensecapeEM,
  title={Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models},
  author={Sangho Suh and Bryan Min and Srishti Palani and Haijun Xia},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.11483},
  url={https://api.semanticscholar.org/CorpusID:258822925}
}

@article{Pedersen1997AROMAAR,
  title={AROMA: abstract representation of presence supporting mutual awareness},
  author={Elin R{\o}nby Pedersen and Tomas Sokoler},
  journal={Proceedings of the ACM SIGCHI Conference on Human factors in computing systems},
  year={1997},
  url={https://api.semanticscholar.org/CorpusID:15186183}
}
@book{aronson1978jigsaw,
  title={The jigsaw classroom.},
  author={Aronson, Elliot and others},
  year={1978},
  publisher={Sage}
}

@article{Schaekermann2018ResolvableVI,
  title={Resolvable vs. Irresolvable Disagreement},
  author={Mike Schaekermann and Joslin Goh and K. Larson and Edith Law},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  year={2018},
  volume={2},
  pages={1 - 19},
  url={https://api.semanticscholar.org/CorpusID:53223672}
}

@article{Jansen2017AnIR,
  title={An integrative review of the cognitive costs and benefits of note-taking},
  author={Rs Ren{\'e}e Jansen and Daniel Lakens and Wa Wijnand IJsselsteijn},
  journal={Educational Research Review},
  year={2017},
  volume={22},
  pages={223-233},
  url={https://api.semanticscholar.org/CorpusID:148791987}
}

@article{costley2021collaborative,
  title={Collaborative note-taking affects cognitive load: the interplay of completeness and interaction},
  author={Costley, Jamie and Fanguy, Mik},
  journal={Educational Technology Research and Development},
  volume={69},
  pages={655--671},
  year={2021},
  publisher={Springer}
}

@inproceedings{xu-etal-2022-narrate,
    title = "Narrate Dialogues for Better Summarization",
    author = "Xu, Ruochen  and
      Zhu, Chenguang  and
      Zeng, Michael",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.261",
    doi = "10.18653/v1/2022.findings-emnlp.261",
    pages = "3565--3575",
    abstract = "Dialogue summarization models aim to generate a concise and accurate summary for multi-party dialogue. The complexity of dialogue, including coreference, dialogue acts, and inter-speaker interactions bring unique challenges to dialogue summarization. Most recent neural models achieve state-of-art performance following the pretrain-then-finetune recipe, where the large-scale language model (LLM) is pretrained on large-scale single-speaker written text, but later finetuned on multi-speaker dialogue text. To mitigate the gap between pretraining and finetuning, we propose several approaches to convert the dialogue into a third-person narrative style and show that the narration serves as a valuable annotation for LLMs. Empirical results on three benchmark datasets show our simple approach achieves higher scores on the ROUGE and a factual correctness metric.",
}

@inproceedings{li-etal-2022-controllable,
    title = "Controllable Dialogue Simulation with In-context Learning",
    author = "Li, Zekun  and
      Chen, Wenhu  and
      Li, Shiyang  and
      Wang, Hong  and
      Qian, Jing  and
      Yan, Xifeng",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.318",
    doi = "10.18653/v1/2022.findings-emnlp.318",
    pages = "4330--4347",
    abstract = "Building dialogue systems requires a large corpus of annotated dialogues. Such datasets are usually created via crowdsourcing, which is expensive and time-consuming. In this paper, we propose Dialogic, a novel dialogue simulation method based on large language model in-context learning to automate dataset creation. Seeded with a few annotated dialogues, Dialogic automatically selects in-context examples for demonstration and prompts GPT-3 to generate new dialogues and annotations in a controllable way. Our method can rapidly expand a small set of dialogue data with minimum or zero \textit{human involvement} and \textit{parameter update} and is thus much more cost-efficient and time-saving than crowdsourcing. Experimental results on the MultiWOZ dataset demonstrate that training a model on the simulated dialogues leads to even better performance than using the same amount of human-generated dialogues under the challenging low-resource settings, with as few as 85 dialogues as a seed. When the full training set is given, our method can still serve as an effective data augmentation method to further improve performance. Human evaluation results also show that our simulated dialogues have near-human fluency and annotation accuracy. The code and data are available at \textbf{ \url{https://github.com/Leezekun/dialogic} }.",
}

@misc{zhang2021exploratory,
      title={An Exploratory Study on Long Dialogue Summarization: What Works and What's Next}, 
      author={Yusen Zhang and Ansong Ni and Tao Yu and Rui Zhang and Chenguang Zhu and Budhaditya Deb and Asli Celikyilmaz and Ahmed Hassan Awadallah and Dragomir Radev},
      year={2021},
      eprint={2109.04609},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}