@article{a.allenUnderstandingWorkplaceMeetings2014,
  title = {Understanding Workplace Meetings: {{A}} Qualitative Taxonomy of Meeting Purposes},
  shorttitle = {Understanding Workplace Meetings},
  author = {A. Allen, Joseph and Beck, Tammy and W. Scott, Cliff and G. Rogelberg, Steven},
  date = {2014-01-01},
  journaltitle = {Management Research Review},
  volume = {37},
  number = {9},
  pages = {791--814},
  publisher = {{Emerald Group Publishing Limited}},
  issn = {2040-8269},
  doi = {10.1108/MRR-03-2013-0067},
  url = {https://doi.org/10.1108/MRR-03-2013-0067},
  urldate = {2023-06-05},
  abstract = {Purpose The purpose of this study is to propose a taxonomy of meeting purpose. Meetings are a workplace activity that deserves increased attention from researchers and practitioners. Previous researchers attempted to develop typologies of meeting purpose with limited success. Through a comparison of classification methodologies, the authors consider a taxonomy as the appropriate classification scheme for meeting purpose. The authors then utilize the developed taxonomy to investigate the frequency with which a representative sample of working adults engaged in meetings of these varying purposes. Their proposed taxonomy provides relevant classifications for future research on meetings as well and serves as a useful tool for managers seeking to use and evaluate the effectiveness of meetings within their organizations. Design/methodology/approach This study employs an inductive methodology using discourse analysis of qualitative meeting descriptions to develop a taxonomy of meeting purpose. The authors discourse analysis utilizes open-ended survey responses from a sample of working adults (n = 491). Findings The authors categorical analysis of open-ended questions resulted in a 16-category taxonomy of meeting purpose. The two most prevalent meeting purpose categories in this sample were â€œto discuss ongoing projectsâ€ at 11.6 per cent and â€œto routinely discuss the state of the businessâ€ at 10.8 per cent. The two least common meeting purpose categories in this sample were â€œto brainstorm for ideas or solutionsâ€ at 3.3 per cent and â€œto discuss productivity and efficienciesâ€ at 3.7 per cent. The taxonomy was analyzed across organizational type and employee job level to identify differences between those important organizational and employee characteristics. Research limitations/implications The data suggested that meetings were institutionalized in organizations, making them useful at identifying differences between organizations as well as differences in employees in terms of scope of responsibility. Researchers and managers should consider the purposes for which they call meetings and how that manifests their overarching organizational focus, structure and goals. Originality/value This is the first study to overtly attempt to categorize the various purposes for which meetings are held. Further, this study develops a taxonomy of meeting purposes that will prove useful for investigating the different types of meeting purposes in a broad range of organizational types and structures.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/WYU4XVBR/A. Allen et al. - 2014 - Understanding workplace meetings A qualitative ta.pdf}
}

@online{AccessibilityBarriersConflicts,
  title = {Accessibility {{Barriers}}, {{Conflicts}} and {{Repairs}}: {{Understanding}} the {{Experience}} of {{Professionals}} with {{Disabilities}} in {{Hybrid Meetings}} - {{CHI}} '23},
  shorttitle = {Accessibility {{Barriers}}, {{Conflicts}} and {{Repairs}}},
  url = {https://programs.sigchi.org/chi/2023/program/content/95906},
  urldate = {2023-04-27},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4JIKSRW7/95906.html}
}

@online{AccessibilityBarriersConflictsa,
  title = {Accessibility {{Barriers}}, {{Conflicts}}, and {{Repairs}}: {{Understanding}} the {{Experience}} of {{Professionals}} with {{Disabilities}} in {{Hybrid Meetings}} | {{Proceedings}} of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581541},
  urldate = {2023-04-27},
  keywords = {notion}
}

@incollection{ackermannGroupSupportSystems2021,
  title = {Group {{Support Systems}}: {{Past}}, {{Present}}, and {{Future}}},
  shorttitle = {Group {{Support Systems}}},
  booktitle = {Handbook of {{Group Decision}} and {{Negotiation}}},
  author = {Ackermann, Fran},
  editor = {Kilgour, D. Marc and Eden, Colin},
  date = {2021},
  pages = {627--654},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-49629-6_47},
  url = {https://link.springer.com/10.1007/978-3-030-49629-6_47},
  urldate = {2023-08-21},
  isbn = {978-3-030-49628-9 978-3-030-49629-6},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/5WBHHMC6/Ackermann - 2021 - Group Support Systems Past, Present, and Future.pdf}
}

@article{adamsPeopleSystematicallyOverlook2021,
  title = {People Systematically Overlook Subtractive Changes},
  author = {Adams, Gabrielle S. and Converse, Benjamin A. and Hales, Andrew H. and Klotz, Leidy E.},
  date = {2021-04},
  journaltitle = {Nature},
  volume = {592},
  number = {7853},
  pages = {258--261},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03380-y},
  url = {https://www.nature.com/articles/s41586-021-03380-y},
  urldate = {2023-03-15},
  abstract = {Improving objects, ideas or situationsâ€”whether a designer seeks to advance technology, a writer seeks to strengthen an argument or a manager seeks to encourage desired behaviourâ€”requires a mental search for possible changes1â€“3. We investigated whether people are as likely to consider changes that subtract components from an object, idea or situation as they are to consider changes that add new components. People typically consider a limited number of promising ideas in order to manage the cognitive burden of searching through all possible ideas, but this can lead them to accept adequate solutions without considering potentially superior alternatives4â€“10. Here we show that people systematically default to searching for additive transformations, and consequently overlook subtractive transformations. Across eight experiments, participants were less likely to identify advantageous subtractive changes when the task did not (versus did) cue them to consider subtraction, when they had only one opportunity (versus several) to recognize the shortcomings of an additive search strategy or when they were under a higher (versus lower) cognitive load. Defaulting to searches for additive changes may be one reason that people struggle to mitigate overburdened schedules11, institutional red tape12 and damaging effects on the planet13,14.},
  issue = {7853},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/KPEH2IWK/Adams et al. - 2021 - People systematically overlook subtractive changes.pdf}
}

@article{ahmadAutomaticContentAnalysis2022,
  title = {Automatic Content Analysis of Asynchronous Discussion Forum Transcripts: {{A}} Systematic Literature Review},
  shorttitle = {Automatic Content Analysis of Asynchronous Discussion Forum Transcripts},
  author = {Ahmad, Mubarik and Junus, Kasiyah and Santoso, Harry Budi},
  date = {2022-09-01},
  journaltitle = {Education and Information Technologies},
  shortjournal = {Educ Inf Technol},
  volume = {27},
  number = {8},
  pages = {11355--11410},
  issn = {1573-7608},
  doi = {10.1007/s10639-022-11065-w},
  url = {https://doi.org/10.1007/s10639-022-11065-w},
  urldate = {2023-05-08},
  abstract = {In recent years, the use of asynchronous discussion forums in online learning has increased rapidly. In earlier studies, content analysis is the most-used research method in exploring the discussion transcripts. However, conventional content analysis is a time-consuming task and requires experienced coders. There is a need for an automated approach to analyse the online discussion transcripts to help instructors optimise the learners' learning experiences. This article presents a systematic literature review of the automated content analysis approach in online discussion transcripts. Fifty-four relevant peer-reviewed conference and journal papers were found between January 2016 and October 2021, using the PRISMA and snowball methods. Eight measurement dimensions were studied from online learning transcripts: cognitive, social, relevance/importance, summary, pattern, behaviour, topic, and learning resources. Six theoretical frameworks were used in the selected studies, namely the Community of Inquiry, Stump's Post Classification, Arguello's Speech Acts, ICAP, Wise's Speaking Behaviour, and Bloom's Taxonomy. All selected studies are experimental, with 93\% using machine learning to analyse discussion transcripts. English is the most-used language dataset, used in 78\% of studies. These studies reported promising results in accuracy and precision. However, this research area still has room for improvement, especially in the reliability and generalisability of cross-domain context.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/EBLBTEZM/Ahmad et al. - 2022 - Automatic content analysis of asynchronous discuss.pdf}
}

@article{AnalysisNegotiationCommon2007,
  title = {The analysis of negotiation of common ground in CSCL},
  date = {2007-08-01},
  journaltitle = {Learning and Instruction},
  volume = {17},
  number = {4},
  pages = {427--435},
  publisher = {{Pergamon}},
  issn = {0959-4752},
  doi = {10.1016/j.learninstruc.2007.04.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0959475207000576},
  urldate = {2023-03-15},
  abstract = {CSCL research has given rise to a plethora of analysis methods, all with specific analysis goals, units of analysis, and for specific types of data (câ€¦},
  langid = {chinese},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CQ52F9FT/Beers et al. - 2007 - The analysis of negotiation of common ground in CS.pdf;/Users/xinyuech/Zotero/storage/DPPDQBTE/2007 - The analysis of negotiation of common ground in CS.pdf;/Users/xinyuech/Zotero/storage/U4DG7NZ2/S0959475207000576.html}
}

@online{AnalysisVerbalInteractions,
  title = {Analysis of Verbal Interactions in Tutorial Groups: A Process Study - {{Visschers}}â€{{Pleijers}} - 2006 - {{Medical Education}} - {{Wiley Online Library}}},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2929.2005.02368.x?casa_token=Df7gPJ9miKIAAAAA:a3uZIFW8HUlJFecwWlo7mHeF5pz3QxxVuzPmFJSYBjzn1bj8vP80G10zdNz4ON9cJI6pKeAzb3MjtgADgA},
  urldate = {2023-06-04},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/FUFPTANH/j.1365-2929.2005.02368.html}
}

@inproceedings{anastasiouMakingSenseOnline2021,
  title = {Making {{Sense}} of {{Online Discussions}}: {{Can Automated Reports}} Help?},
  shorttitle = {Making {{Sense}} of {{Online Discussions}}},
  booktitle = {Extended {{Abstracts}} of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Anastasiou, Lucas and De Liddo, Anna},
  date = {2021-05-08},
  pages = {1--7},
  publisher = {{ACM}},
  location = {{Yokohama Japan}},
  doi = {10.1145/3411763.3451815},
  url = {https://dl.acm.org/doi/10.1145/3411763.3451815},
  urldate = {2022-11-02},
  abstract = {Enabling healthier online deliberation around issues of public concerns is an increasingly vital challenge in nowadays society. Two fundamental components of a healthier deliberation are: i. the capability of people to make sense of what they read, so that their contribution can be relevant; and ii. the improvement of the overall quality of the debate, so that noise can be reduced and useful signals can inform collective decision making. Platform designers often resort to computational aids to improve these two processes. In this paper, we examine automated reporting as promising mean of improving sensemaking in discussion platforms. We compared three approaches to automated reporting: an abstractive summariser, a template report and an argumentation highlighting system. We then evaluated improvements in sensemaking of participants and the perception on overall quality of the debate. The study suggests that argument mining technologies are particularly promising computational aids to improve sense making and perceived quality of online discussion, thanks to their capability to combine computational models for automated reasoning with usersâ€™ cognitive needs and expectation of automated reporting.},
  eventtitle = {{{CHI}} '21: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-8095-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/9WLF5S65/Anastasiou and De Liddo - 2021 - Making Sense of Online Discussions Can Automated .pdf}
}

@inproceedings{andolinaCrowdboardAugmentingInPerson2017,
  title = {Crowdboard: {{Augmenting In-Person Idea Generation}} with {{Real-Time Crowds}}},
  shorttitle = {Crowdboard},
  booktitle = {Proceedings of the 2017 {{ACM SIGCHI Conference}} on {{Creativity}} and {{Cognition}}},
  author = {Andolina, Salvatore and Schneider, Hendrik and Chan, Joel and Klouche, Khalil and Jacucci, Giulio and Dow, Steven},
  date = {2017-06-22},
  pages = {106--118},
  publisher = {{ACM}},
  location = {{Singapore Singapore}},
  doi = {10.1145/3059454.3059477},
  url = {https://dl.acm.org/doi/10.1145/3059454.3059477},
  urldate = {2023-03-21},
  eventtitle = {C\&{{C}} '17: {{Creativity}} and {{Cognition}}},
  isbn = {978-1-4503-4403-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/WKRI85J2/Andolina et al. - 2017 - Crowdboard Augmenting In-Person Idea Generation w.pdf}
}

@inproceedings{ansahNeedRespondThis2022,
  title = {â€{{I}} Need to Respond to Thisâ€ â€“ {{Contributions}} to Group Creativity in Remote Meetings with Distractions},
  booktitle = {2022 {{Symposium}} on {{Human-Computer Interaction}} for {{Work}}},
  author = {Ansah, Alberta A. and Xing, Yilun and Kamaraj, Amudha Varshini and Tosca, Diana and Boyle, Linda and Iqbal, Shamsi and Kun, Andrew L. and Lee, John D. and Pahud, Michel and Shaer, Orit},
  date = {2022-06-08},
  pages = {1--12},
  publisher = {{ACM}},
  location = {{Durham NH USA}},
  doi = {10.1145/3533406.3533411},
  url = {https://dl.acm.org/doi/10.1145/3533406.3533411},
  urldate = {2023-08-16},
  eventtitle = {{{CHIWORK}} 2022: 2022 {{Symposium}} on {{Human-Computer Interaction}} for {{Work}}},
  isbn = {978-1-4503-9655-4},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸},
  file = {/Users/xinyuech/Zotero/storage/KNWEB5W7/Ansah et al. - 2022 - â€I need to respond to thisâ€ â€“ Contributions to gro.pdf}
}

@article{aragonThreadNotThread2017,
  title = {To {{Thread}} or {{Not}} to {{Thread}}: {{The Impact}} of {{Conversation Threading}} on {{Online Discussion}}},
  shorttitle = {To {{Thread}} or {{Not}} to {{Thread}}},
  author = {AragÃ³n, Pablo and GÃ³mez, VicenÃ§ and Kaltenbrunner, Andreaks},
  date = {2017-05-03},
  journaltitle = {Proceedings of the International AAAI Conference on Web and Social Media},
  volume = {11},
  number = {1},
  pages = {12--21},
  issn = {2334-0770},
  doi = {10.1609/icwsm.v11i1.14880},
  url = {https://ojs.aaai.org/index.php/ICWSM/article/view/14880},
  urldate = {2023-03-22},
  abstract = {Online discussion is essential for the communication and collaboration of online communities. The reciprocal exchange of messages between users that characterizes online discussion can be represented in many different ways. While some platforms display messages chronologically using a simple linear interface, others use a hierarchical (threaded) interface to represent more explicitly the structure of the discussion. Although the type of representation has been shown to affect communication, to the best of our knowledge, the impact of using either one or the other has not yet been investigated in a large and mature online community. In this work we analyze Meneame, a popular Spanish social news platform which recently transitioned from a linear to a hierarchical interface, becoming an ideal research opportunity for this purpose. Using interrupted time series analysis and regression discontinuity design, we observe an abrupt and significant increase in social reciprocity after the adoption of a threaded interface. We furthermore extend state-of-the-art generative models of discussion threads by including reciprocity, a fundamental feature to explain better the structure of the discussions, both before and after the change in the interface.},
  issue = {1},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/T93HKA5K/AragÃ³n et al. - 2017 - To Thread or Not to Thread The Impact of Conversa.pdf}
}

@inproceedings{arakawaCatAlystDomainExtensibleIntervention2023,
  title = {{{CatAlyst}}: {{Domain-Extensible Intervention}} for {{Preventing Task Procrastination Using Large Generative Models}}},
  shorttitle = {{{CatAlyst}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Arakawa, Riku and Yakura, Hiromu and Goto, Masataka},
  date = {2023-04-19},
  pages = {1--19},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581133},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581133},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4TQJ5FGL/Arakawa et al. - 2023 - CatAlyst Domain-Extensible Intervention for Preve.pdf}
}

@inproceedings{ashbyPersonalizedQuestDialogue2023,
  title = {Personalized {{Quest}} and {{Dialogue Generation}} in {{Role-Playing Games}}: {{A Knowledge Graph-}} and {{Language Model-based Approach}}},
  shorttitle = {Personalized {{Quest}} and {{Dialogue Generation}} in {{Role-Playing Games}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Ashby, Trevor and Webb, Braden K and Knapp, Gregory and Searle, Jackson and Fulda, Nancy},
  date = {2023-04-19},
  pages = {1--20},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581441},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581441},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/H6JGHLXQ/Ashby et al. - 2023 - Personalized Quest and Dialogue Generation in Role.pdf}
}

@inproceedings{ashktorabResilientChatbotsRepair2019,
  title = {Resilient {{Chatbots}}: {{Repair Strategy Preferences}} for {{Conversational Breakdowns}}},
  shorttitle = {Resilient {{Chatbots}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Ashktorab, Zahra and Jain, Mohit and Liao, Q. Vera and Weisz, Justin D.},
  date = {2019-05-02},
  series = {{{CHI}} '19},
  pages = {1--12},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3290605.3300484},
  url = {https://doi.org/10.1145/3290605.3300484},
  urldate = {2023-03-14},
  abstract = {Text-based conversational systems, also referred to as chatbots, have grown widely popular. Current natural language understanding technologies are not yet ready to tackle the complexities in conversational interactions. Breakdowns are common, leading to negative user experiences. Guided by communication theories, we explore user preferences for eight repair strategies, including ones that are common in commercially-deployed chatbots (e.g., confirmation, providing options), as well as novel strategies that explain characteristics of the underlying machine learning algorithms. We conducted a scenario-based study to compare repair strategies with Mechanical Turk workers (N=203). We found that providing options and explanations were generally favored, as they manifest initiative from the chatbot and are actionable to recover from breakdowns. Through detailed analysis of participants' responses, we provide a nuanced understanding on the strengths and weaknesses of each repair strategy.},
  isbn = {978-1-4503-5970-2},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/76C5H2X2/Ashktorab et al. - 2019 - Resilient Chatbots Repair Strategy Preferences fo.pdf}
}

@inproceedings{baeSpinneretAidingCreative2020,
  title = {Spinneret: {{Aiding Creative Ideation}} through {{Non-Obvious Concept Associations}}},
  shorttitle = {Spinneret},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Bae, Suyun Sandra and Kwon, Oh-Hyun and Chandrasegaran, Senthil and Ma, Kwan-Liu},
  date = {2020-04-23},
  series = {{{CHI}} '20},
  pages = {1--13},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3313831.3376746},
  url = {https://doi.org/10.1145/3313831.3376746},
  urldate = {2023-03-15},
  abstract = {æ€ç»´å¯¼å›¾æ˜¯ä¸€ç§åœ¨åˆ›é€ æ€§æ€ç»´ç»ƒä¹ ä¸­æ¢ç´¢è®¾è®¡ç©ºé—´çš„æµè¡Œæ–¹å¼ï¼Œå…è®¸ç”¨æˆ·åœ¨æ¦‚å¿µä¹‹é—´å½¢æˆå…³è”ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„æ€ç»´å¯¼å›¾æ•°å­—å·¥å…·éƒ½ä¾§é‡äºåˆ›ä½œå’Œç»„ç»‡ï¼Œå¾ˆå°‘æ”¯æŒè§£å†³æ€ç»´å¯¼å›¾çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚åœæ»å’Œè®¾è®¡å›ºå®šã€‚æˆ‘ä»¬ä»‹ç»äº† Spinneretï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡åŸºäºçŸ¥è¯†å›¾æä¾›å»ºè®®æ¥å¸®åŠ©æ€ç»´å¯¼å›¾çš„åŠŸèƒ½æ–¹æ³•ã€‚Spinneret ä½¿ç”¨æœ‰åéšæœºæ¸¸èµ°åœ¨æ€ç»´å¯¼å›¾ä¸­ç°æœ‰æ¦‚å¿µèŠ‚ç‚¹çš„é‚»åŸŸå†…æ¢ç´¢çŸ¥è¯†å›¾è°±ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ·»åŠ åˆ°æ€ç»´å¯¼å›¾ä¸­çš„â€œå»ºè®®â€ã€‚ä¸åŸºçº¿æ€ç»´å¯¼å›¾å·¥å…·çš„æ¯”è¾ƒç ”ç©¶è¡¨æ˜ï¼Œå‚ä¸è€…ä½¿ç”¨ Spinneret åˆ›å»ºäº†æ›´åŠ å¤šæ ·åŒ–å’Œç‹¬ç‰¹çš„æ¦‚å¿µï¼Œ},
  isbn = {978-1-4503-6708-0},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DG95K3EK/Bae et al. - 2020 - Spinneret Aiding Creative Ideation through Non-Ob.pdf}
}

@article{bailensonNonverbalOverloadTheoretical2021,
  title = {Nonverbal Overload: {{A}} Theoretical Argument for the Causes of {{Zoom}} Fatigue.},
  shorttitle = {Nonverbal Overload},
  author = {Bailenson, Jeremy N.},
  date = {2021-02-23},
  journaltitle = {Technology, Mind, and Behavior},
  shortjournal = {Technology, Mind, and Behavior},
  volume = {2},
  number = {1},
  issn = {2689-0208},
  doi = {10.1037/tmb0000030},
  url = {https://tmb.apaopen.org/pub/nonverbal-overload},
  urldate = {2023-03-22},
  abstract = {For decades, scholars have predicted that videoconference technology will disrupt the practice of commuting daily to and from work and will change the way people socialize. In 2020, the Covid-19 pandemic forced a drastic increase in the number of videoconference meetings, and Zoom became the leading software package because it was free, robust, and easy to use. While the software has been an essential tool for productivity, learning, and social interaction, something about being on videoconference all day seems particularly exhausting, and the term â€œZoom Fatigueâ€ caught on quickly. In this article, I focus on nonverbal overload as a potential cause for fatigue and provide four arguments outlining how various aspects of the current Zoom interface likely lead to psychological consequences. The arguments are based on academic theory and research, but also have yet to be directly tested in the context of Zoom, and require future experimentation to confirm. Instead of indicting the medium, my goal is to point out these design flaws to isolate research areas for social scientists and to suggest design improvements for technologists.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/FPDH5E3D/Bailenson - 2021 - Nonverbal overload A theoretical argument for the.pdf}
}

@article{bakerROLEGROUNDINGCOLLABORATIVE,
  title = {{{THE ROLE OF GROUNDING IN COLLABORATIVE LEARNING TASKS}}},
  author = {Baker, Michael and Hansen, Tia and Joiner, Richard},
  abstract = {Collaborative learning tasks involve interaction between multiple participants, who thus need to maintain some degree of mutual understanding. The process by which this is accomplished is termed grounding. The way in which collaboration, grounding and learning take place is largely determined by the task, the situation and the tools available. This paper discusses relations between grounding, collaboration and learning, drawing on research from two main areas: the Language Sciences and Cultural-Historical Activity Theory ("CHAT"). We build a unifying perspective of mutual understanding mediated by material and semiotic tools that can be used for analysis as well as for design of collaborative learning tasks, especially those that are carried out via computer-mediated communication. We illustrate the perspective with reference to a particular computermediated collaborative learning situation in the domain of physics.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4KQMBNFB/Baker et al. - THE ROLE OF GROUNDING IN COLLABORATIVE LEARNING TA.pdf}
}

@inproceedings{banerjeeNecessityMeetingRecording2005,
  title = {The {{Necessity}} of a {{Meeting Recording}} and {{Playback System}}, and the {{Benefit}} of {{Topic}}â€“{{Level Annotations}} to {{Meeting Browsing}}},
  booktitle = {Human-{{Computer Interaction}} - {{INTERACT}} 2005},
  author = {Banerjee, Satanjeev and Rose, Carolyn and Rudnicky, Alexander I.},
  editor = {Costabile, Maria Francesca and PaternÃ², Fabio},
  date = {2005},
  series = {è®¡ç®—æœºç§‘å­¦ç³»åˆ—è®²ä¹‰},
  pages = {643--656},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11555261_52},
  abstract = {Much work in the area of Computer Supported Cooperative Work (CSCW) has targeted the problem of supporting meetings between collaborators who are non-collocated, enabling meetings to transcend boundaries of space. In this paper, we explore the beginnings of a proposed solution for allowing meetings to transcend time as well. The need for such a solution is motivated by a user survey in which busy professionals are questioned about meetings they have either missed or forgotten the important details about after the fact. Our proposed solution allows these professionals to transcend time in a sense by revisiting a recorded meeting that has been structured for quick retrieval of sought information. Such a solution supports complete recovery of prior discussions, allowing needed information to be retrieved quickly, and thus potentially facilitating the effective continuation of discussions from the past. We evaluate the proposed solution with a formal user study in which we measure the impact of the proposed structural annotations on retrieval of information. The results of the study show that participants took significantly less time to retrieve the answers when they had access to discourse structure based annotation than in a control condition in which they had access only to unannotated video recordings (p {$<$} 0.01, effect size 0.94 standard deviations).},
  isbn = {978-3-540-31722-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/MM54KABY/Banerjee et al. - 2005 - The Necessity of a Meeting Recording and Playback .pdf}
}

@inproceedings{banerjeeSmartNotesImplicitLabeling2006,
  title = {{{SmartNotes}}: {{Implicit Labeling}} of {{Meeting Data}} through {{User Note-Taking}} and {{Browsing}}},
  shorttitle = {{{SmartNotes}}},
  booktitle = {Proceedings of the {{Human Language Technology Conference}} of the {{NAACL}}, {{Companion Volume}}: {{Demonstrations}}},
  author = {Banerjee, Satanjeev and Rudnicky, Alexander I.},
  date = {2006-06},
  pages = {261--264},
  publisher = {{Association for Computational Linguistics}},
  location = {{New York City, USA}},
  url = {https://aclanthology.org/N06-4003},
  urldate = {2023-06-05},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/MD5JF59Z/Banerjee and Rudnicky - 2006 - SmartNotes Implicit Labeling of Meeting Data thro.pdf}
}

@article{beersCommonGroundComplex2006,
  title = {Common {{Ground}}, {{Complex Problems}} and {{Decision Making}}},
  author = {Beers, Pieter J. and Boshuizen, Henny P. A. and Kirschner, Paul A. and Gijselaers, Wim H.},
  date = {2006-10-27},
  journaltitle = {Group Decision and Negotiation},
  shortjournal = {Group Decis Negot},
  volume = {15},
  number = {6},
  pages = {529--556},
  issn = {0926-2644, 1572-9907},
  doi = {10.1007/s10726-006-9030-1},
  url = {http://link.springer.com/10.1007/s10726-006-9030-1},
  urldate = {2022-08-07},
  abstract = {Organisations increasingly have to deal with complex problems. They often use multidisciplinary teams to cope with such problems where different team members have different perspectives on the problem, different individual knowledge and skills, and different approaches on how to solve the problem. In order to solve those problems, team members have to share their existing knowledge and construct new knowledge. Theory suggests that negotiation of common ground can positively affect team decision making on the solution of complex problems, by facilitating knowledge sharing across perspectives. In a small scale study with student groups, external representations supported by a specific negotiation ontology were used to facilitate negotiation by encouraging participants to make their beliefs and values explicit. Results showed that the external representations supported clarifying contributions to group members and increased group participation in discussions.},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/BLQ5PHL4/Beers et al. - 2006 - Common Ground, Complex Problems and Decision Makin.pdf}
}

@article{benkeTeamSpiritousRetrospectiveEmotional2022,
  title = {{{TeamSpiritous}} - {{A Retrospective Emotional Competence Development System}} for {{Video-Meetings}}},
  author = {Benke, Ivo and Schneider, Maren and Liu, Xuanhui and Maedche, Alexander},
  date = {2022-11-11},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {392:1--392:28},
  doi = {10.1145/3555117},
  url = {https://dl.acm.org/doi/10.1145/3555117},
  urldate = {2023-03-24},
  abstract = {Video-meetings essentially determine remote work life. However, video-meetings experience challenges originating from human emotions. Therefore, emotional competence, the ability to perceive, understand, and regulate emotions, is of the highest relevance. With limited transfer capacity of emotional information and various communication challenges, developing emotional competence, however, is complex. To overcome this complexity, we present TeamSpiritous, an individual, retrospective emotional competence development system for video-meetings. TeamSpiritous allows to upload and analyze recorded video-meetings on emotional processes and provides support for individual development of emotional competence. We evaluated TeamSpiritous quantitatively and qualitatively in a six-week, longitudinal field study with 47 participants from China and Germany. Results of our study show that intra- and interpersonal emotional competence significantly increased over time for the whole sample. In particular, intrapersonal emotion regulation and interpersonal emotion perception and understanding improved. Since remote work video-meetings are often multicultural, we also investigated cultural differences and observed in our results that the effects of TeamSpiritous exist beyond cultural backgrounds (China, Germany). With our work, we contribute with the design of TeamSpiritous and understanding of its effects on emotional competence development.},
  issue = {CSCW2},
  keywords = {ğŸ’›ğŸ’›},
  file = {/Users/xinyuech/Zotero/storage/TZL4QNCB/Benke et al. - 2022 - TeamSpiritous - A Retrospective Emotional Competen.pdf}
}

@inproceedings{bergstromConversationClustersGrouping2009,
  title = {Conversation Clusters: Grouping Conversation Topics through Human-Computer Dialog},
  shorttitle = {Conversation Clusters},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Bergstrom, Tony and Karahalios, Karrie},
  date = {2009-04-04},
  pages = {2349--2352},
  publisher = {{ACM}},
  location = {{Boston MA USA}},
  doi = {10.1145/1518701.1519060},
  url = {https://dl.acm.org/doi/10.1145/1518701.1519060},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '09: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-246-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CDE7ZTHS/Bergstrom and Karahalios - 2009 - Conversation clusters grouping conversation topic.pdf}
}

@article{bilottaRemoteCommunicationCoronavirus2021,
  title = {Remote Communication amid the Coronavirus Pandemic: {{Optimizing}} Interpersonal Dynamics and Team Performance},
  shorttitle = {Remote Communication amid the Coronavirus Pandemic},
  author = {Bilotta, Isabel and Cheng, Shannon K. and Ng, Linnea C. and Corrington, Abby R. and Watson, Ivy and Paoletti, Jensine and Hebl, Mikki R. and King, Eden B.},
  date = {2021-06},
  journaltitle = {Industrial and Organizational Psychology},
  volume = {14},
  number = {1-2},
  pages = {36--40},
  publisher = {{Cambridge University Press}},
  issn = {1754-9426, 1754-9434},
  doi = {10.1017/iop.2021.10},
  url = {https://www.cambridge.org/core/journals/industrial-and-organizational-psychology/article/remote-communication-amid-the-coronavirus-pandemic-optimizing-interpersonal-dynamics-and-team-performance/0B7A1FF7BD2E5ED9028075573F643D0C},
  urldate = {2023-03-21},
  abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS1754942621000109/resource/name/firstPage-S1754942621000109a.jpg},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/QDGCCRL9/Bilotta et al. - 2021 - Remote communication amid the coronavirus pandemic.pdf}
}

@article{borgeLearningMonitorRegulate2018,
  title = {Learning to Monitor and Regulate Collective Thinking Processes},
  author = {Borge, Marcela and Ong, Yann Shiou and RosÃ©, Carolyn Penstein},
  date = {2018-03-01},
  journaltitle = {International Journal of Computer-Supported Collaborative Learning},
  shortjournal = {Intern. J. Comput.-Support. Collab. Learn},
  volume = {13},
  number = {1},
  pages = {61--92},
  issn = {1556-1615},
  doi = {10.1007/s11412-018-9270-5},
  url = {https://doi.org/10.1007/s11412-018-9270-5},
  urldate = {2023-05-08},
  abstract = {In this paper, we propose a conceptual framework to guide the design of a computer-supported collaborative learning intervention to help students learn how to improve collaborative knowledge building discourse at the level of the small group. The framework focuses on scripting individual and collective regulatory processes following collaboration. Individuals are required to evaluate their teamâ€™s chat transcripts against rubrics to score discussion quality. These theoretically supported rubrics provide individuals with~concrete examples of desired communication processes. After this individual assessment, the team is prompted to discuss their individual scores, identify strengths and weaknesses of their collaborative discourse processes, and select strategies to improve the quality of their collaborative discussion in a future discussion session. To evaluate our framework, we created a prototype of an online system and asked students to use it over ten weeks as part of five discussion sessions. Participants included 37 students, divided into 13 teams, from an undergraduate online course in information sciences. We used quantitative and qualitative analysis techniques to examine studentsâ€™ collaborative processes over time, with teams as the main unit of analysis. All teams followed the same general activities, but there were two different conditions for scripting individual reflections that preceded the collective sense-making activity: one (Future-thinking) focused on pushing individuals to pay attention to advice on how to improve existing processes in future sessions and another (Evidence-Based) pushed individuals to pay closer attention to the chat transcripts to provide evidence for their group process scores. Our results suggest (1) use of the framework can help studentsâ€™ monitor and regulate collaborative processes and improve collaborative discourse over time and (2) the Evidence-Based condition can help students engage in higher quality reflective analysis.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/JHU7VFEP/Borge et al. - 2018 - Learning to monitor and regulate collective thinki.pdf}
}

@article{bothinParticipantsPersonalNotetaking2012,
  title = {Participantsâ€™ Personal Note-Taking in Meetings and Its Value for Automatic Meeting Summarisation},
  author = {Bothin, Antje and Clough, Paul},
  date = {2012-03-01},
  journaltitle = {Information Technology and Management},
  shortjournal = {Inf Technol Manag},
  volume = {13},
  number = {1},
  pages = {39--57},
  issn = {1573-7667},
  doi = {10.1007/s10799-011-0112-7},
  url = {https://doi.org/10.1007/s10799-011-0112-7},
  urldate = {2023-04-21},
  abstract = {This paper reports the results of novel quantitative research on multiple peopleâ€™s personal note-taking in meetings with the long-term aim of aiding the creation of innovative meeting understanding applications. We present three experiments using a large number of group meetings taken from the Augmented Multi-party Interaction meeting corpus. Statistical techniques were employed for this work. Our findings suggest that temporal note-taking overlap information and the semantic content of the written private notes taken by many meeting participants both point to the majority of the most informative meeting events. Thus, the characteristics of note-taking can be seen as a contributing feature for new automatic meeting summarisation approaches and for the development of future meeting browser environments that better support the needs of individuals and organisations.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/K2A9E6XW/Bothin and Clough - 2012 - Participantsâ€™ personal note-taking in meetings and.pdf}
}

@article{bothinUserEvaluationStudy2014,
  title = {A {{User Evaluation Study}}: {{Do Participants}}' {{Personal Notes Help Us}} to {{Summarise Meetings}}?},
  shorttitle = {A {{User Evaluation Study}}},
  author = {Bothin, Antje and Clough, Paul},
  date = {2014},
  journaltitle = {Knowledge and Process Management},
  volume = {21},
  number = {2},
  pages = {122--133},
  issn = {1099-1441},
  doi = {10.1002/kpm.1439},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/kpm.1439},
  urldate = {2023-06-05},
  abstract = {We describe a novel user evaluation study on the value of people's personal meeting notes for a question-answering task involving meeting data taken from the Augmented Multiparty Interaction (AMI) corpus. A survey on task perceptions and note-taking strategies in meetings was also conducted. The results suggest that written notes taken by multiple meeting participants contain the majority of the most informative meeting information and are thus likely to support information systems that employ automatic meeting understanding and summarisation. The users were able to achieve 79\% and 76\% accuracy in the task with handwritten and typed notes respectively as information source. Contrary to that, they scored 36\% accuracy only using short extracts from the meeting speech and 98\% correctness using abstractive human model summaries. The survey showed that people are generally very experienced with attending meetings and note-taking and usually record the most important meeting events in a concise way. This provides evidence for the fact that personal notes are suitable as keywords and indices into a meeting recording. In general, task results correlated positively with perceived success. Users liked well-structured abstractive human reference summaries but found meeting speech extracts difficult to work with. However, they also disliked the appearance of the notes, in particular the fact that the handwritten ones were hard to read. This emphasises the need for the development of innovative handwriting recognition methods and user interfaces that employ new presentation techniques, for example, key area highlighting. Meeting participants would also benefit from corporate training for better communication and note-taking skills. Copyright Â© 2014 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {notion}
}

@article{brown-schmidtMemoryCommonGround2016,
  title = {Memory and {{Common Ground Processes}} in {{Language Use}}},
  author = {Brown-Schmidt, Sarah and Duff, Melissa C.},
  date = {2016},
  journaltitle = {Topics in Cognitive Science},
  volume = {8},
  number = {4},
  pages = {722--736},
  issn = {1756-8765},
  doi = {10.1111/tops.12224},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12224},
  urldate = {2023-05-07},
  abstract = {During communication, we form assumptions about what our communication partners know and believe. Information that is mutually known between the discourse partnersâ€”their common groundâ€”serves as a backdrop for successful communication. Here we present an introduction to the focus of this topic, which is the role of memory in common ground and language use. Two types of questions emerge as central to understanding the relationship between memory and common ground, specifically questions having to do with the representation of common ground in memory, and the use of common ground during language processing.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/WP8K7BRT/Brown-Schmidt and Duff - 2016 - Memory and Common Ground Processes in Language Use.pdf;/Users/xinyuech/Zotero/storage/NNB76HI2/tops.html}
}

@article{burlutskiyHowVisualiseConversation,
  title = {How to {{Visualise}} a {{Conversation}}: {{Case-Based Reasoning Approach}}},
  author = {Burlutskiy, Nikolay and Petridis, Miltos and Fish, Andrew and Ali, Nour},
  abstract = {At present, the complexity and scale of modern digital conversations between people is at its highest level but there is a gap in how to represent these conversations to a user. As a result, it is often hard for a user to understand the flow of a conversation and make an informed decision over it. However, an aesthetic and efficient visualisation can mitigate this drawback of data representation. In this paper, a case-based approach was proposed for choosing an appropriate visualisation for userâ€™s conversations. A case was formulated as a visualisation of a conversation which a user decided to use for his analysis of the conversation. When a user decides to visualise a new conversation, the most similar visualisation type from previous usersâ€™ experiences is selected for the visualisation of the new conversation. In this paper, the cases of visualisations of conversations from the IBM Many Eyes platform were collected and a case-based reasoning approach for choosing a visualisation of userâ€™s conversation was designed. Finally, the work of the proposed approach was tested on a sample email conversation, and then four participants evaluated the appropriateness of the chosen visualisation types in comparison with other eight possible visualisations for the email conversation.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/JV5W23BD/Burlutskiy et al. - How to Visualise a Conversation Case-Based Reason.pdf}
}

@article{caiUsingSemanticDiagram2016,
  title = {Using a Semantic Diagram to Structure a Collaborative Problem Solving Process in the Classroom},
  author = {Cai, Huiying and Lin, Lin and Gu, Xiaoqing},
  date = {2016-12-01},
  journaltitle = {Educational Technology Research and Development},
  shortjournal = {Education Tech Research Dev},
  volume = {64},
  number = {6},
  pages = {1207--1225},
  issn = {1556-6501},
  doi = {10.1007/s11423-016-9445-6},
  url = {https://doi.org/10.1007/s11423-016-9445-6},
  urldate = {2023-05-08},
  abstract = {This study provides an in-depth look into the implementation process of visualization-based tools for structuring collaborative problem solving (CPS) in the classroom. A visualization-based learning platformâ€”the semantic diagram for structuring CPS in a real classroom was designed and implemented. Metafora, the preliminary vehicle of the semantic diagram, was integrated into the Food and Nutrition CPS curriculum in a fifth-grade science classroom in east China. Data of a teacherâ€™s and her studentsâ€™ activities from the CPS classroom were analyzed to understand how Metafora could be integrated into the CPS instructional process, what roles Metafora and the teacher played in the CPS project, and to what extent Metafora might have affected the teacherâ€™s instruction and the studentsâ€™ learning activities in the CPS classroom. Results showed that the semantic diagram could be integrated into the CPS classroom adaptively and flexibly, and that it was important to keep a balance between the role of the semantic diagram and the role of the teacher. Implications for semantic diagram design and implementation for structuring CPS in the classroom, as well as future work about the semantic diagram will be discussed.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/ZFARIE9L/Cai et al. - 2016 - Using a semantic diagram to structure a collaborat.pdf}
}

@article{callis-duehlMissedOpportunitiesScience2018,
  title = {Missed {{Opportunities}} for {{Science Learning}}: {{Unacknowledged Unscientific Arguments}} in {{Asynchronous Online}} and {{Face-to-Face Discussions}}},
  shorttitle = {Missed {{Opportunities}} for {{Science Learning}}},
  author = {Callis-Duehl, Kristine and Idsardi, Robert and Humphrey, Eve A. and Gougis, Rebekka Darner},
  date = {2018-02-01},
  journaltitle = {Journal of Science Education and Technology},
  shortjournal = {J Sci Educ Technol},
  volume = {27},
  number = {1},
  pages = {86--98},
  issn = {1573-1839},
  doi = {10.1007/s10956-017-9710-4},
  url = {https://doi.org/10.1007/s10956-017-9710-4},
  urldate = {2023-03-15},
  abstract = {We explored the scientific argumentation that occurs among university biology students during an argumentation task implemented in two environments: face-to-face in a classroom and online in an asynchronous discussion. We observed 10 student groups, each composed of three students. Our analysis focused on how students respond to their peersâ€™ unscientific arguments, which we define as assertions, hypotheses, propositions, or explanations that are inaccurate or incomplete from a scientific perspective. Unscientific arguments provide opportunities for productive dissent, scientific argumentation, and conceptual development of scientifically desirable conceptions. We found that students did not respond to the majority of unscientific arguments in both environments. Challenges to unscientific arguments were expressed as a question or through explanation, although the latter was more common online than face-to-face. Students demonstrated significantly more epistemic distancing in the face-to-face environment than the online environment. We discuss the differences in discourse observed in both environments and teaching implications. We also provide direction for future research seeking to address the challenges of engaging students in productive scientific argumentation in both face-to-face and online environments.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/KRY9YKW8/Callis-Duehl et al. - 2018 - Missed Opportunities for Science Learning Unackno.pdf}
}

@online{CanGraphicalInteraction,
  title = {Can {{Graphical Interaction Increase Feelings}} of {{Conveying}} and {{Understanding}} in {{On-Line Group Discussion}}?},
  doi = {10.9746/jcmsi.11.55},
  url = {https://www.tandfonline.com/doi/epdf/10.9746/jcmsi.11.55?needAccess=true&role=button},
  urldate = {2023-06-02},
  langid = {english},
  keywords = {notion}
}

@inproceedings{caoDataParticlesBlockbasedLanguageoriented2023,
  title = {{{DataParticles}}: {{Block-based}} and {{Language-oriented Authoring}} of {{Animated Unit Visualizations}}},
  shorttitle = {{{DataParticles}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Cao, Yining and E, Jane L and Chen, Zhutian and Xia, Haijun},
  date = {2023-04-19},
  pages = {1--15},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581472},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581472},
  urldate = {2023-05-03},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion,ğŸ©·ğŸ©·ğŸ©·},
  file = {/Users/xinyuech/Zotero/storage/QRHR5NUW/Cao et al. - 2023 - DataParticles Block-based and Language-oriented A.pdf}
}

@book{carrollHCIModelsTheories2003,
  title = {{{HCI Models}}, {{Theories}}, and {{Frameworks}}: {{Toward}} a {{Multidisciplinary Science}}},
  shorttitle = {{{HCI Models}}, {{Theories}}, and {{Frameworks}}},
  author = {Carroll, John M.},
  date = {2003-05-21},
  eprint = {gGyEOjkdpbYC},
  eprinttype = {googlebooks},
  publisher = {{Elsevier}},
  abstract = {HCI Models, Theories, and Frameworks provides a thorough pedagological survey of the science of Human-Computer Interaction (HCI). HCI spans many disciplines and professions, including anthropology, cognitive psychology, computer graphics, graphical design, human factors engineering, interaction design, sociology, and software engineering. While many books and courses now address HCI technology and application areas, none has addressed HCIâ€™s multidisciplinary foundations with much scope or depth. This text fills a huge void in the university education and training of HCI students as well as in the lifelong learning and professional development of HCI practitioners. Contributors are leading researchers in the field of HCI. If you teach a second course in HCI, you should consider this book. This book provides a comprehensive understanding of the HCI concepts and methods in use today, presenting enough comparative detail to make primary sources more accessible. Chapters are formatted to facilitate comparisons among the various HCI models. Each chapter focuses on a different level of scientific analysis or approach, but all in an identical format, facilitating comparison and contrast of the various HCI models. Each approach is described in terms of its roots, motivation, and type of HCI problems it typically addresses. The approach is then compared with its nearest neighbors, illustrated in a paradigmatic application, and analyzed in terms of its future. This book is essential reading for professionals, educators, and students in HCI who want to gain a better understanding of the theoretical bases of HCI, and who will make use of a good background, refresher, reference to the field and/or index to the literature. Contributors are leading researchers in the field of Human-Comptuter Interaction  Fills a major gap in current literature about the rich scientific foundations of HCI  Provides a thorough pedogological survey of the science of HCI},
  isbn = {978-0-08-049141-7},
  langid = {english},
  pagetotal = {579},
  keywords = {notion}
}

@inproceedings{chanComparingDifferentSensemaking2016,
  title = {Comparing {{Different Sensemaking Approaches}} for {{Large-Scale Ideation}}},
  booktitle = {Proceedings of the 2016 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chan, Joel and Dang, Steven and Dow, Steven P.},
  date = {2016-05-07},
  series = {{{CHI}} '16},
  pages = {2717--2728},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2858036.2858178},
  url = {https://dl.acm.org/doi/10.1145/2858036.2858178},
  urldate = {2023-03-20},
  abstract = {å¤§å‹åˆ›æ„ç”Ÿæˆå¹³å°ç»å¸¸è®©æ€æƒ³å®¶æ¥è§¦åˆ°ä»¥å‰çš„æƒ³æ³•ã€‚ç„¶è€Œï¼Œç ”ç©¶è¡¨æ˜ï¼Œå¦‚æœäººä»¬çœ‹åˆ°æŠ½è±¡çš„è§£å†³æ–¹æ¡ˆè·¯å¾„ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡äººç±»æ„ä¹‰æ„å»ºç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆæ–¹æ³•çš„æè¿°ï¼‰ï¼Œè€Œä¸æ˜¯è¢«æ‰€æœ‰å…ˆå‰çš„æƒ³æ³•æ‰€æ·¹æ²¡ï¼Œä»–ä»¬å°±ä¼šäº§ç”Ÿæ›´å¥½çš„æƒ³æ³•ã€‚è‡ªåŠ¨åŒ–å’ŒåŠè‡ªåŠ¨åŒ–æ–¹æ³•ä¹Ÿå¯ä»¥æä¾›å¯¹æ—©æœŸæƒ³æ³•çš„è§£é‡Šã€‚ä¸ºäº†åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ä»å®è·µä¸­çš„æ„ä¹‰æ„å»ºä¸­å—ç›Šï¼Œæ„æ€å¹³å°å¼€å‘äººå‘˜éœ€è¦æƒè¡¡ä¸åŒæ–¹æ³•çš„æˆæœ¬è´¨é‡æƒè¡¡ï¼Œä»¥å‘ˆç°è§£å†³æ–¹æ¡ˆè·¯å¾„ã€‚ä¸ºäº†æ¢ç´¢è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹åœ¨çº¿ç ”ç©¶ï¼Œå…¶ä¸­245åå‚ä¸è€…åœ¨ä»¥ä¸‹äº”ä¸ªæ¡ä»¶ä¹‹ä¸€ä¸­ä¸ºä¸¤ä¸ªé—®é¢˜äº§ç”Ÿäº†æƒ³æ³•ï¼š1ï¼‰æ²¡æœ‰åˆºæ¿€ï¼Œ2ï¼‰æ¥è§¦æ‰€æœ‰å…ˆå‰çš„æƒ³æ³•ï¼Œæˆ–ä½¿ç”¨3ï¼‰å…¨è‡ªåŠ¨å·¥ä½œæµç¨‹ä»å…ˆå‰çš„æƒ³æ³•ä¸­æå–çš„è§£å†³æ–¹æ¡ˆè·¯å¾„ï¼Œ4ï¼‰æ··åˆäººæœºæ–¹æ³•ï¼Œä»¥åŠ5ï¼‰å®Œå…¨æ‰‹åŠ¨çš„æ–¹æ³•ã€‚ä¸é¢„æœŸç›¸åï¼Œäººç±»ç”Ÿæˆçš„è·¯å¾„å¹¶æ²¡æœ‰é€šè¿‡ç®€å•åœ°å±•ç¤ºæ‰€æœ‰æƒ³æ³•æ¥æ”¹å–„æ„æ€ï¼ˆæ­£å¦‚æ„æ€çš„æµç•…æ€§å’Œå¹¿åº¦æ‰€è¡¡é‡çš„é‚£æ ·ï¼‰ã€‚æœºå™¨ç”Ÿæˆçš„è·¯å¾„æœ‰æ—¶ä¼šæ˜¾ç€æé«˜æ„æ€çš„æµç•…æ€§å’Œå¹¿åº¦ï¼Œè€Œä¸æ˜¯æ²¡æœ‰æƒ³æ³•ï¼ˆå°½ç®¡ä»¥ä¸€äº›æƒ³æ³•è´¨é‡ä¸ºä»£ä»·ï¼‰ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œè‡ªåŠ¨æ„ä¹‰æ„å»ºå¯ä»¥æ”¹å–„æƒ³æ³•çš„äº§ç”Ÿï¼Œä½†æˆ‘ä»¬éœ€è¦æ›´å¤šçš„ç ”ç©¶æ¥äº†è§£äººç±»æ„ä¹‰æ„å»ºå¯¹ç¾¤ä½“æ„æ€çš„ä»·å€¼ã€‚},
  isbn = {978-1-4503-3362-7},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/5GV3IJ7F/Chan et al. - 2016 - Comparing Different Sensemaking Approaches for Lar.pdf}
}

@inproceedings{chanConceptualDistanceMatters2014,
  title = {Conceptual Distance Matters When Building on Others' Ideas in Crowd-Collaborative Innovation Platforms},
  booktitle = {Proceedings of the Companion Publication of the 17th {{ACM}} Conference on {{Computer}} Supported Cooperative Work \& Social Computing},
  author = {Chan, Joel and Dow, Steven and Schunn, Christian},
  date = {2014-02-15},
  series = {{{CSCW Companion}} '14},
  pages = {141--144},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2556420.2556500},
  url = {https://doi.org/10.1145/2556420.2556500},
  urldate = {2023-03-14},
  abstract = {åœ¨äººç¾¤ååŒåˆ›æ–°å¹³å°ä¸­ï¼Œå…¶ä»–è´¡çŒ®è€…çš„æƒ³æ³•å¯ä»¥ä½œä¸ºåˆ›æ„çš„çµæ„Ÿæ¥æºï¼Œä½†ä¸ä»–äººçš„æƒ³æ³•äº’åŠ¨çš„å“ªäº›æ¨¡å¼æœ€æœ‰å¸®åŠ©ï¼Ÿæˆ‘ä»¬è°ƒæŸ¥äº†è¿™æ ·ä¸€ä¸ªå‡è®¾ï¼Œå³å»ºç«‹åœ¨æ¦‚å¿µä¸Šè¿œç¦»ç›®æ ‡é¢†åŸŸçš„çµæ„Ÿæ¥æºæ˜¯æœ€æœ‰å¸®åŠ©çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰æ··åˆç»éªŒæ”¯æŒçš„æµè¡Œå‡è®¾ã€‚æˆ‘ä»¬æ ¹æ®å¼•ç”¨æºä¸ç›®æ ‡åŸŸçš„æ¦‚å¿µè·ç¦»ï¼ˆä½¿ç”¨æƒ³æ³•çš„æ¦‚ç‡ä¸»é¢˜å»ºæ¨¡æ¥è¡¡é‡ï¼‰ï¼Œé¢„æµ‹åŸºäº Web çš„åä½œåˆ›æ–°å¹³å°ä¸­ 12 ç§ä¸åŒè®¾è®¡æŒ‘æˆ˜çš„ 2,344 ä¸ªæƒ³æ³•çš„æˆåŠŸç‡ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°åœ¨æ¦‚å¿µä¸Šå¼•ç”¨è¿‘æºçµæ„Ÿçš„åˆ›æ–°è€…æ¯”é‚£äº›å–œæ¬¢è¿œæºçš„åˆ›æ–°è€…è·å¾—æ›´é«˜çš„æˆåŠŸç‡ã€‚},
  isbn = {978-1-4503-2541-7},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/7SBSET34/Chan et al. - 2014 - Conceptual distance matters when building on other.pdf}
}

@thesis{chenAssociationReflectionStimulation2021,
  type = {Thesis},
  title = {Association, {{Reflection}}, {{Stimulation}}: {{Problem Exploration}} in {{Early Design}} through {{AI-Augmented Mind-Mapping}}},
  shorttitle = {Association, {{Reflection}}, {{Stimulation}}},
  author = {Chen, Ting-Ju},
  date = {2021-07-26},
  url = {https://oaktrust.library.tamu.edu/handle/1969.1/195385},
  urldate = {2023-03-16},
  abstract = {The formulation of a problem is often more essential than its solution, which may be merely a matter of mathematical or experimental skill. To raise new questions, new possibilities, to regard old problems from a new angle requires creative imagination and marks real advances in science. - Albert Einstein This dissertation aims at developing a computational framework to support the process of problem exploration in early design. To do so, we investigate digital mind-mapping as a tool for problem exploration and develop new algorithms and interaction workflows by leveraging large knowledge databases. The central premise of this work is that channeling the designer's thinking process through intelligent stimulation using such databases can augment designers' ability to reason about the problem at hand and creatively synthesize new ideas to address the problem. Design problems are typically ambiguous, ill-defined, unstructured, and open-ended. Therefore, learning about the problem and exploration of the problem domain is critical in early design to build a well-developed understanding of the context toward fruitful solution exploration in design. Despite the importance of problem understanding in design, little research has been devoted to investigating problem exploration activities in-depth and drawing a clear connection on the effects of such activities on the resulting design outcomes. Most current efforts focus exclusively on implementing methods for ideation, conceptualization, and concept evaluation wherein the solution space takes prominence. In this regard, this dissertation aims to complement this with a study of problem exploration techniques (mind-mapping and free writing) and evaluation in early design. We highlight the importance of problem-based exploration and learning, and share insights on how the structure and associative capability afforded by mind-maps affect ideation on the problem statement, product opportunity gap, and the needs around a given design context. It is common for designers to tend to commit to solutions too early and limit the potential of discovering creative and novel ideas in early design. This tendency is further pronounced with the advent of several digital design tools that are feature-rich and focus on design conceptualization and solution formulation, rather than design problem exploration. Additionally, much of the research in design theory and methodology has also mostly focused on conceptualization techniques such as C-Sketch and morphological matrix, that aim to support the formation of new solution concepts through modification and re-interpretation of rough initial ones. To complement these, in this dissertation, we emphasize the importance of problem exploration and brainstorming tasks towards design opportunity identification during early design. This is studied with the use of mind-maps, a technique that helps designers express their thoughts by making connections or associations between ideas around a given context. Further, we propose novel human-computer collaborative mind-mapping workflows for enhancing design experiences through novel textual, verbal and visual computer supports. Specifically, we designed and implemented two cognitive support mechanisms to help designers in inspecting design problems and generating ideas. Human-subject studies were conducted to examine how these systems perform and user perception. Based on the extensive investigation, this dissertation further shares insights on how to promote reflection in problem exploration by stimulating association across ideas, and develops design implications for intelligent AI-augmented workflows during early design exploratory tasks.},
  langid = {english},
  keywords = {ï¼ï¼ï¼,notion},
  annotation = {Accepted: 2022-01-27T22:18:02Z},
  file = {/Users/xinyuech/Zotero/storage/SD9LXK7W/Chen - 2021 - Association, Reflection, Stimulation Problem Expl.pdf}
}

@inproceedings{chenCognitionorientedFacilitationGuidelines2023,
  title = {Cognition-Oriented {{Facilitation}} and {{Guidelines}} for {{Collaborative Problem-solving Online}} and {{Face-to-face}}: {{An}} in-Depth Examination of Format and Facilitation Influence on Problem-Solving Performance},
  shorttitle = {Cognition-Oriented {{Facilitation}} and {{Guidelines}} for {{Collaborative Problem-solving Online}} and {{Face-to-face}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chen, Yingting and Kanno, Taro and Furuta, Kazuo},
  date = {2023-04-19},
  pages = {1--15},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581112},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581112},
  urldate = {2023-04-24},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/THPQEF6N/Chen et al. - 2023 - Cognition-oriented Facilitation and Guidelines for.pdf}
}

@inproceedings{chenCollaborativeMindMappingStudy2019,
  title = {Collaborative Mind-Mapping: A Study of Patterns, Strategies, and Evolution of Maps Created by Peer-Pairs},
  shorttitle = {Collaborative Mind-Mapping},
  author = {Chen, Ting-Ju and Mohanty, Ronak R. and Hoffmann Rodriguez, Miguel A. and Krishnamurthy, Vinayak R.},
  date = {2019-11-25},
  publisher = {{American Society of Mechanical Engineers Digital Collection}},
  doi = {10.1115/DETC2019-98125},
  url = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-abstract/IDETC-CIE2019/59278/1070194},
  urldate = {2023-03-16},
  abstract = {Abstract. We present a study on collaborative mind-mapping to understand how peers collaborate in pairs to create mind-maps, how the maps evolve over time, and how collaboration changes between the peer-pair across multiple maps. Mind-mapping is an important tool that is studied and taught in design practice and research respectively. While widely used as a brainstorming technique, the collaborative aspects of mind-mapping are little understood in comparison to other ideation methods such as concept sketching etc. In addition to presenting creativity ratings on the outcome (i.e. the mind-map), we extensively report on the patterns of collaborative exploration, strategies that emerge from the collaborators, inhibition, and the overall process of map creation. We discuss the implications of these observations on the development of computer-support for mind-mapping.},
  eventtitle = {ASME 2019 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  langid = {chinese},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/TM4TYPRU/Chen et al. - 2019 - Collaborative Mind-Mapping A Study of Patterns, S.pdf}
}

@inproceedings{chenQCueQueriesCues2022,
  title = {QCue: Queries and Cues for Computer-Facilitated Mind-Mapping},
  shorttitle = {QCue},
  author = {Chen, Ting-Ju and Subramanian, Sai Ganesh and Krishnamurthy, Vinayak R.},
  date = {2022-07-08},
  url = {https://openreview.net/forum?id=r5vnRRwrgX},
  urldate = {2023-03-16},
  abstract = {We introduce a novel workflow, QCue, for providing textual stimulation during mind-mapping. Mind-mapping is a powerful tool whose intent is to allow one to externalize ideas and their relationships surrounding a central problem. The key challenge in mind-mapping is the difficulty in balancing the exploration of different aspects of the problem (breadth) with a detailed exploration of each of those aspects (depth). Our idea behind QCue is based on two mechanisms: (1) computer-generated automatic cues to stimulate the user to explore the breadth of topics based on the temporal and topological evolution of a mind-map and (2) user-elicited queries for helping the user explore the depth for a given topic. We present a two-phase study wherein the first phase provided insights that led to the development of our work-flow for stimulating the user through cues and queries. In the second phase, we present a between-subjects evaluation comparing QCue with a digital mind-mapping work-flow without computer intervention. Finally, we present an expert rater evaluation of the mind-maps created by users in conjunction with user feedback.},
  eventtitle = {Graphics Interface 2020},
  langid = {chinese},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/RW7UAPXU/Chen et al. - 2022 - QCue Queries and Cues for Computer-Facilitated Mi.pdf}
}

@article{choEffectsCommunicationOrientedOverload2019,
  title = {Effects of {{Communication-Oriented Overload}} in {{Mobile Instant Messaging}} on {{Role Stressors}}, {{Burnout}}, and {{Turnover Intention}} in the {{Workplace}}},
  author = {Cho, Jaehee and Lee, H. Erin and Kim, Haeyeon},
  date = {2019-04-14},
  journaltitle = {International Journal of Communication},
  volume = {13},
  number = {0},
  pages = {21},
  issn = {1932-8036},
  url = {https://ijoc.org/index.php/ijoc/article/view/9290},
  urldate = {2023-03-21},
  abstract = {This study aimed at developing and testing a model that can explain how overload perceived in relation to organizational use of mobile instant messaging services (MIMs) leads to burnout and turnover intention in employees through the mediating effect of role-oriented stressors such as role ambiguity and role conflict. To empirically test the model, an online survey was conducted with 434 office workers in South Korea who used KakaoTalk for organizational purposes. Overload in KakaoTalk use was measured in three dimensions: information, communication, and system feature overload. Path analysis results showed that information overload and system feature overload significantly increased role ambiguity and role conflict, which ultimately led to significant increases in burnout (in the form of emotional exhaustion and reduced personal achievement) and turnover intention.},
  issue = {0},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XKTDE2JT/Cho et al. - 2019 - Effects of Communication-Oriented Overload in Mobi.pdf}
}

@article{comanCommunicationGroupCognitive2019,
  title = {Communication and {{Group Cognitive Complexity}}},
  author = {Coman, Andra Diana and CurÈ™eu, Petru Lucian and Fodor, Oana CÄƒtÄƒlina and OÈ›oiu, CÄƒtÄƒlina and RaÈ›iu, Lucia and FleÈ™tea, Alina Maria and Bria, Mara},
  date = {2019-08-01},
  journaltitle = {Small Group Research},
  volume = {50},
  number = {4},
  pages = {539--568},
  publisher = {{SAGE Publications Inc}},
  issn = {1046-4964},
  doi = {10.1177/1046496419853624},
  url = {https://doi.org/10.1177/1046496419853624},
  urldate = {2023-03-21},
  abstract = {This study explores the effects of group size, group composition, and group argument frequency on group cognitive complexity (GCC). We evaluated a sample of 509 students organized into 106 groups who participated in a group cognitive mapping activity. As hypothesized, we found that group argumentation has an inverted U-shaped association with GCC. Group member familiarity did not moderate this relationship. We also found that task-related arguments mediate the relationships between group size and gender diversity on one hand, and GCC, on the other. Moreover, we found that optimal group-level cognitive benefits were observed in group discussions in which the ratio between task-related and nontask-related group arguments was 3 to 1. The discussion focuses on the practical and theoretical implications of these findings.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CC43A9AR/Coman et al. - 2019 - Communication and Group Cognitive Complexity.pdf}
}

@incollection{conklinDialogMappingReflections2003,
  title = {Dialog {{Mapping}}: {{Reflections}} on an {{Industrial Strength Case Study}}},
  shorttitle = {Dialog {{Mapping}}},
  booktitle = {Visualizing {{Argumentation}}: {{Software Tools}} for {{Collaborative}} and {{Educational Sense-Making}}},
  author = {Conklin, Jeff},
  editor = {Kirschner, Paul A. and Buckingham Shum, Simon J. and Carr, Chad S.},
  date = {2003},
  series = {è®¡ç®—æœºæ”¯æŒçš„åä½œå·¥ä½œ},
  pages = {117--136},
  publisher = {{Springer}},
  location = {{London}},
  doi = {10.1007/978-1-4471-0037-9_6},
  url = {https://doi.org/10.1007/978-1-4471-0037-9_6},
  urldate = {2023-08-21},
  abstract = {Earlier chapters have introduced the notion of â€œwicked problemsâ€ and the Issue Based Information System (IBIS) framework (Buckingham Shum, Chapter 1, van Bruggen Chapter 2), both of which derive from the work of Horst Rittel. Selvin (Chapter 7) proposes a generic framework for facilitated Computer Supported Argument Visualization (CSAV), and reports on case studies using the IBIS-based Compendium approach. Compendium itself is based on a facilitated CSAV approach called Dialog Mapping, the focus of this chapter. We begin by elaborating on the art and process of Dialog Mapping, before reporting on a particular business application, probably the longest-term case study available of CSAV adoption in an organization},
  isbn = {978-1-4471-0037-9},
  langid = {english},
  keywords = {/unread,notion,å…±äº«æ˜¾ç¤º,å‚è€ƒèŠ‚ç‚¹,å¼‚æ­¥æ¨¡å¼,è®ºè¯çŸ¥è¯†,é‚ªæ¶çš„é—®é¢˜},
  file = {/Users/xinyuech/Zotero/storage/IX9PWYEF/Conklin - 2003 - Dialog Mapping Reflections on an Industrial Stren.pdf}
}

@inproceedings{convertinoArticulatingCommonGround2008,
  title = {Articulating Common Ground in Cooperative Work: Content and Process},
  shorttitle = {Articulating Common Ground in Cooperative Work},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Convertino, Gregorio and Mentis, Helena M. and Rosson, Mary Beth and Carroll, John M. and Slavkovic, Aleksandra and Ganoe, Craig H.},
  date = {2008-04-06},
  pages = {1637--1646},
  publisher = {{ACM}},
  location = {{Florence Italy}},
  doi = {10.1145/1357054.1357310},
  url = {https://dl.acm.org/doi/10.1145/1357054.1357310},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '08: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-011-1},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/HANR3RW8/Convertino et al. - 2008 - Articulating common ground in cooperative work co.pdf}
}

@article{cookeInteractiveTeamCognition2013,
  title = {Interactive {{Team Cognition}}},
  author = {Cooke, Nancy J. and Gorman, Jamie C. and Myers, Christopher W. and Duran, Jasmine L.},
  date = {2013},
  journaltitle = {Cognitive Science},
  volume = {37},
  number = {2},
  pages = {255--285},
  issn = {1551-6709},
  doi = {10.1111/cogs.12009},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12009},
  urldate = {2023-03-15},
  abstract = {Cognition in work teams has been predominantly understood and explained in terms of shared cognition with a focus on the similarity of static knowledge structures across individual team members. Inspired by the current zeitgeist in cognitive science, as well as by empirical data and pragmatic concerns, we offer an alternative theory of team cognition. Interactive Team Cognition (ITC) theory posits that (1) team cognition is an activity, not a property or a product; (2) team cognition should be measured and studied at the team level; and (3) team cognition is inextricably tied to context. There are implications of ITC for theory building, modeling, measurement, and applications that make teams more effective performers.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/N4YDSHJ4/Cooke et al. - 2013 - Interactive Team Cognition.pdf}
}

@article{deweverContentAnalysisSchemes2006,
  title = {Content Analysis Schemes to Analyze Transcripts of Online Asynchronous Discussion Groups: {{A}} Review},
  shorttitle = {Content Analysis Schemes to Analyze Transcripts of Online Asynchronous Discussion Groups},
  author = {De Wever, B. and Schellens, T. and Valcke, M. and Van Keer, H.},
  date = {2006-01-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  series = {Methodological {{Issues}} in {{Researching CSCL}}},
  volume = {46},
  number = {1},
  pages = {6--28},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2005.04.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131505000552},
  urldate = {2023-05-10},
  abstract = {Research in the field of Computer Supported Collaborative Learning (CSCL) is based on a wide variety of methodologies. In this paper, we focus upon content analysis, which is a technique often used to analyze transcripts of asynchronous, computer mediated discussion groups in formal educational settings. Although this research technique is often used, standards are not yet established. The applied instruments reflect a wide variety of approaches and differ in their level of detail and the type of analysis categories used. Further differences are related to a diversity in their theoretical base, the amount of information about validity and reliability, and the choice for the unit of analysis. This article presents an overview of different content analysis instruments, building on a sample of models commonly used in the CSCL-literature. The discussion of 15 instruments results in a number of critical conclusions. There are questions about the coherence between the theoretical base and the operational translation of the theory in the instruments. Instruments are hardly compared or contrasted with one another. As a consequence the empirical base of the validity of the instruments is limited. The analysis is rather critical when it comes to the issue of reliability. The authors put forward the need to improve the theoretical and empirical base of the existing instruments in order to promote the overall quality of CSCL-research.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4ALEEBHQ/S0360131505000552.html}
}

@inproceedings{difedeIdeaMachineLLMbased2022,
  title = {The {{Idea Machine}}: {{LLM-based Expansion}}, {{Rewriting}}, {{Combination}}, and {{Suggestion}} of {{Ideas}}},
  shorttitle = {The {{Idea Machine}}},
  booktitle = {Creativity and {{Cognition}}},
  author = {Di Fede, Giulia and Rocchesso, Davide and Dow, Steven P. and Andolina, Salvatore},
  date = {2022-06-20},
  series = {C\&amp;{{C}} '22},
  pages = {623--627},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3527927.3535197},
  url = {https://doi.org/10.1145/3527927.3535197},
  urldate = {2023-03-14},
  abstract = {æˆ‘ä»¬ä»‹ç»äº† Idea Machineï¼Œè¿™æ˜¯ä¸€ç§åˆ›é€ åŠ›æ”¯æŒå·¥å…·ï¼Œå®ƒåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) ä¸ºä»äº‹åˆ›æ„ç”Ÿæˆä»»åŠ¡çš„äººä»¬æä¾›æ”¯æŒã€‚è¯¥å·¥å…·åŒ…æ‹¬è®¸å¤šå¯ç”¨äºå®ç°å„ç§çº§åˆ«çš„è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½æ”¯æŒçš„åŠŸèƒ½ã€‚è¾“å…¥ç³»ç»Ÿçš„æ¯ä¸ªæƒ³æ³•éƒ½å¯ä»¥æ‰©å±•ã€é‡å†™æˆ–ä¸å…¶ä»–æƒ³æ³•æˆ–æ¦‚å¿µç›¸ç»“åˆã€‚è¿˜å¯ä»¥å¼€å¯ç‚¹å­å»ºè®®æ¨¡å¼ï¼Œè®©ç³»ç»Ÿä¸»åŠ¨æå‡ºç‚¹å­ã€‚},
  isbn = {978-1-4503-9327-0},
  keywords = {notion}
}

@article{doErrAIImperfect2023a,
  title = {To {{Err}} Is {{AI}}: {{Imperfect Interventions}} and {{Repair}} in a {{Conversational Agent Facilitating Group Chat Discussions}}},
  shorttitle = {To {{Err}} Is {{AI}}},
  author = {Do, Hyo Jin and Kong, Ha-Kyung and Tetali, Pooja and Lee, Jaewook and Bailey, Brian P.},
  date = {2023-04-16},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {7},
  pages = {99:1--99:23},
  doi = {10.1145/3579532},
  url = {https://dl.acm.org/doi/10.1145/3579532},
  urldate = {2023-08-16},
  abstract = {Conversational agents (CAs) can analyze online conversations using natural language techniques and effectively facilitate group discussions by sending supervisory messages. However, if a CA makes imperfect interventions, users may stop trusting the CA and discontinue using it. In this study, we demonstrate how inaccurate interventions of a CA and a conversational repair strategy can influence user acceptance of the CA, members' participation in the discussion, perceived discussion experience between the members, and group performance. We built a CA that encourages the participation of members with low contributions in an online chat discussion in which a small group (3-6 members) performs a decision-making task. Two types of errors can occur when detecting under-contributing members: 1) false-positive (FP) errors happen when the CA falsely identifies a member as under-contributing and 2) false-negative (FN) errors occur when the CA misses detecting an under-contributing member. We designed a conversational repair strategy that gives users a chance to contest the detection results and the agent sends a correctional message if an error is detected. Through an online study with 175 participants, we found that participants who received FN error messages reported higher acceptance of the CA and better discussion experience, but participated less compared to those who received FP error messages. The conversational repair strategy moderated the effect of errors such as improving the perceived discussion experience of participants who received FP error messages. Based on our findings, we offer design implications for which model should be selected by practitioners between high precision (i.e., fewer FP errors) and high recall (i.e., fewer FN errors) models depending on the desired effects. When frequent FP errors are expected, we suggest using the conversational repair strategy to improve the perceived discussion experience.},
  issue = {CSCW1},
  keywords = {/unread,collaborative task,conversational agent,group discussion,participation,user acceptance},
  file = {/Users/xinyuech/Zotero/storage/VKX5PNZW/Do et al. - 2023 - To Err is AI Imperfect Interventions and Repair i.pdf}
}

@inproceedings{dongOnePieceTime2012,
  title = {One Piece at a Time: Why Video-Based Communication Is Better for Negotiation and Conflict Resolution},
  shorttitle = {One Piece at a Time},
  booktitle = {Proceedings of the {{ACM}} 2012 Conference on {{Computer Supported Cooperative Work}}},
  author = {Dong, Wei and Fu, Wai-Tat},
  date = {2012-02-11},
  series = {{{CSCW}} '12},
  pages = {167--176},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2145204.2145232},
  url = {https://dl.acm.org/doi/10.1145/2145204.2145232},
  urldate = {2023-03-22},
  abstract = {æˆ‘ä»¬æ¯”è¾ƒäº†ä¸‰ç§è®¡ç®—æœºä¸­ä»‹é€šä¿¡ (CMC) æ¸ é“ï¼ˆæ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘ï¼‰å¯¹äººä»¬å¦‚ä½•æ‰§è¡Œé¢„çº¦å®‰æ’ä»»åŠ¡çš„å½±å“ã€‚è¯¥ä»»åŠ¡æ¶‰åŠæ¥åœ°å’Œå†²çªè§£å†³ç»„ä»¶ã€‚ç»“æœè¡¨æ˜ï¼Œåªæœ‰å½“ä»»åŠ¡éš¾åº¦é«˜ä¸”ä»»åŠ¡ä¸­å­˜åœ¨æ›´å¤šå†…åœ¨å†²çªæ—¶ï¼Œè§†é¢‘ä¼šè®®æ‰æ”¯æŒå‚ä¸è€…äºŒäººç»„è¾¾æˆå…±è¯†ï¼Œå³äºŒäººç»„ä¹‹é—´çš„è¡¨ç°æ›´å¥½ã€‚ä¸‰ç§ CMC æ¡ä»¶ä¸‹çš„å‚ä¸è€…åœ¨ä¿¡æ¯äº¤æ¢å’Œåå•†è¿‡ç¨‹ä¸­ä¹Ÿå±•ç¤ºäº†ä¸åŒçš„å¯¹è¯åŠ¨æ€æ¨¡å¼ã€‚è°ƒè§£åˆ†æè¡¨æ˜ï¼Œåœ¨åŸºäºè§†é¢‘çš„é€šä¿¡ä¸­ï¼Œä¸€æ¬¡äº¤æ¢è¾ƒå°‘ä¿¡æ¯çš„ç­–ç•¥é¢„ç¤ºç€æ›´é«˜æ°´å¹³çš„è°ˆåˆ¤ï¼Œè¿™åè¿‡æ¥é¢„ç¤ºç€åœ¨é«˜å†²çªæ¡ä»¶ä¸‹è¡¨ç°å·®å¼‚è¾ƒå°ã€‚},
  isbn = {978-1-4503-1086-4},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CFCD7A7M/Dong and Fu - 2012 - One piece at a time why video-based communication.pdf}
}

@article{duboviEmpiricalAnalysisKnowledge2020,
  title = {An Empirical Analysis of Knowledge Co-Construction in {{YouTube}} Comments},
  author = {Dubovi, Ilana and Tabak, Iris},
  date = {2020-10-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {156},
  pages = {103939},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2020.103939},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131520301378},
  urldate = {2023-05-08},
  abstract = {Internet and social media platforms such as YouTube are an emblem of information on demand, but, their educative value, especially for conceptually rich domains, such as science, remains unclear. Many people perceive YouTube as a good resource for learning about science, yet viewing many of the available videos can be akin to learning through transmission models, which are considered inferior when they are the sole form of instruction. The goal of this study was to examine whether YouTube's embedded feature of posting (post-video) comments could mitigate these limitations, and offer a potential educative added-value by opening opportunities for discussion and deliberation, which have been associated with deeper learning. Focusing on Science as a target domain, we examined 1530 post-video public comments from a corpus of leading science channels. We coded the comments for argumentative and knowledge construction moves, and tested whether particular moves led to higher-level knowledge construction. Our findings reveal that this informal setting reflected comments that went beyond information sharing to argumentative negotiation, reaching a higher level of knowledge construction, and yielding a greater proportion of such comments that have been found in previous studies within formal settings. This study demonstrates that YouTube can offer an informal space for science deliberation and a forum for collaborative interactions that have a potential to support life-long learning. Implications for future research are discussed.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/3WAUG52T/Dubovi and Tabak - 2020 - An empirical analysis of knowledge co-construction.pdf;/Users/xinyuech/Zotero/storage/KNZSBMVQ/S0360131520301378.html}
}

@inproceedings{duRapsaiAcceleratingMachine2023,
  title = {Rapsai: {{Accelerating Machine Learning Prototyping}} of {{Multimedia Applications}} through {{Visual Programming}}},
  shorttitle = {Rapsai},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Du, Ruofei and Li, Na and Jin, Jing and Carney, Michelle and Miles, Scott and Kleiner, Maria and Yuan, Xiuxiu and Zhang, Yinda and Kulkarni, Anuva and Liu, Xingyu and Sabie, Ahmed and Orts-Escolano, Sergio and Kar, Abhishek and Yu, Ping and Iyengar, Ram and Kowdle, Adarsh and Olwal, Alex},
  date = {2023-04-19},
  pages = {1--23},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581338},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581338},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/HWC2JAT9/Du et al. - 2023 - Rapsai Accelerating Machine Learning Prototyping .pdf}
}

@inproceedings{ehlenMeetingAdjournedOffline2008,
  title = {Meeting Adjourned: Off-Line Learning Interfaces for Automatic Meeting Understanding},
  shorttitle = {Meeting Adjourned},
  booktitle = {Proceedings of the 13th International Conference on {{Intelligent}} User Interfaces},
  author = {Ehlen, Patrick and Purver, Matthew and Niekrasz, John and Lee, Kari and Peters, Stanley},
  date = {2008-01-13},
  pages = {276--284},
  publisher = {{ACM}},
  location = {{Gran Canaria Spain}},
  doi = {10.1145/1378773.1378810},
  url = {https://dl.acm.org/doi/10.1145/1378773.1378810},
  urldate = {2023-04-21},
  eventtitle = {{{IUI08}}: 13th {{International Conference}} on {{Intelligent User Interfaces}}},
  isbn = {978-1-59593-987-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/V9REX7RJ/Ehlen et al. - 2008 - Meeting adjourned off-line learning interfaces fo.pdf}
}

@article{el-assadyDiscourseMapsFeature,
  title = {Discourse {{Maps}} â€” {{Feature Encoding}} for the {{Analysis}} of {{Verbatim Conversation Transcripts}}},
  author = {El-Assady, Mennatallah},
  pages = {31},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/GYFMP5LW/El-Assady - Discourse Maps â€” Feature Encoding for the Analysis.pdf}
}

@article{el-assadyThreadReconstructorModelingReplyChains2018,
  title = {{{ThreadReconstructor}}: {{Modeling Reply-Chains}} to {{Untangle Conversational Text}} through {{Visual Analytics}}},
  shorttitle = {{{ThreadReconstructor}}},
  author = {El-Assady, Mennatallah and Sevastjanova, Rita and Keim, Daniel and Collins, Christopher},
  date = {2018},
  journaltitle = {Computer Graphics Forum},
  volume = {37},
  number = {3},
  pages = {351--365},
  issn = {1467-8659},
  doi = {10.1111/cgf.13425},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13425},
  urldate = {2023-03-22},
  abstract = {We present ThreadReconstructor, a visual analytics approach for detecting and analyzing the implicit conversational structure of discussions, e.g., in political debates and forums. Our work is motivated by the need to reveal and understand single threads in massive online conversations and verbatim text transcripts. We combine supervised and unsupervised machine learning models to generate a basic structure that is enriched by user-defined queries and rule-based heuristics. Depending on the data and tasks, users can modify and create various reconstruction models that are presented and compared in the visualization interface. Our tool enables the exploration of the generated threaded structures and the analysis of the untangled reply-chains, comparing different models and their agreement. To understand the inner-workings of the models, we visualize their decision spaces, including all considered candidate relations. In addition to a quantitative evaluation, we report qualitative feedback from an expert user study with four forum moderators and one machine learning expert, showing the effectiveness of our approach.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/PV4AMY9D/El-Assady et al. - 2018 - ThreadReconstructor Modeling Reply-Chains to Unta.pdf;/Users/xinyuech/Zotero/storage/DDU87IDQ/cgf.html}
}

@inproceedings{ezen-canClassifyingStudentDialogue2015,
  title = {Classifying Student Dialogue Acts with Multimodal Learning Analytics},
  booktitle = {Proceedings of the {{Fifth International Conference}} on {{Learning Analytics And Knowledge}}},
  author = {Ezen-Can, Aysu and Grafsgaard, Joseph F. and Lester, James C. and Boyer, Kristy Elizabeth},
  date = {2015-03-16},
  series = {{{LAK}} '15},
  pages = {280--289},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2723576.2723588},
  url = {https://dl.acm.org/doi/10.1145/2723576.2723588},
  urldate = {2023-04-24},
  abstract = {Supporting learning with rich natural language dialogue has been the focus of increasing attention in recent years. Many adaptive learning environments model students' natural language input, and there is growing recognition that these systems can be improved by leveraging multimodal cues to understand learners better. This paper investigates multimodal features related to posture and gesture for the task of classifying students' dialogue acts within tutorial dialogue. In order to accelerate the modeling process by eliminating the manual annotation bottleneck, a fully unsupervised machine learning approach is utilized for this task. The results indicate that these unsupervised models are significantly improved with the addition of automatically extracted posture and gesture information. Further, even in the absence of any linguistic features, a model that utilizes posture and gesture features alone performed significantly better than a majority class baseline. This work represents a step toward achieving better understanding of student utterances by incorporating multimodal features within adaptive learning environments. Additionally, the technique presented here is scalable to very large student datasets.},
  isbn = {978-1-4503-3417-4},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/24YFXLAQ/Ezen-Can et al. - 2015 - Classifying student dialogue acts with multimodal .pdf}
}

@inproceedings{faridaniOpinionSpaceScalable2010,
  title = {Opinion Space: A Scalable Tool for Browsing Online Comments},
  shorttitle = {Opinion Space},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Faridani, Siamak and Bitton, Ephrat and Ryokai, Kimiko and Goldberg, Ken},
  date = {2010-04-10},
  pages = {1175--1184},
  publisher = {{ACM}},
  location = {{Atlanta Georgia USA}},
  doi = {10.1145/1753326.1753502},
  url = {https://dl.acm.org/doi/10.1145/1753326.1753502},
  urldate = {2023-05-08},
  eventtitle = {{{CHI}} '10: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-929-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/MPNWCDAG/Faridani et al. - 2010 - Opinion space a scalable tool for browsing online.pdf}
}

@article{francaSystematizingImpactsProjection2020,
  title = {Systematizing the Impacts Projection of Complex Decisions in Work Groups},
  author = {FranÃ§a, Juliana B. S. and Borges, Marcos R. S.},
  date = {2020-06-25},
  journaltitle = {SN Applied Sciences},
  shortjournal = {SN Appl. Sci.},
  volume = {2},
  number = {7},
  pages = {1287},
  issn = {2523-3971},
  doi = {10.1007/s42452-020-3086-4},
  url = {https://doi.org/10.1007/s42452-020-3086-4},
  urldate = {2023-03-21},
  abstract = {Complex decisions can give rise to unexpected consequences from implemented actions. The main problem discussed by this research is the difficulty suffered by decision-makers in projecting impacts of a complex decision before the decision occurrence. Unexpected impacts of complex decisions demand mitigating action so that it is possible to intensify the positive aspects and neutralize the negatives. Dealing with unexpected impacts generates a cognitive overload on decision-makers and on the availability of material resources. To solve these problems, this research proposes the impact projection of complex decisions in a collaborative way, to be applied before the decision occurrence. The proposed solution considers a systematizing project impact of complex decisions inside work groups and delivers a framework and artefacts to support decision-makers in their decision impact tasks before the occurrence of a real decision scenario. This solution was evaluated by decision-making specialists and their goal was to investigate the applicability of this proposal to different teams. This is a qualitative research, and the method applied was the case study because we would like to deeply understand the behaviour of this approach in decision-makers team. The evaluation generated evidence on the feasibility of this approach, showing that the artefacts provide a systematic structure to orient what decision-makers must do to know and understand the impacts of decisions before their execution. This evidence is contribution for decision support field.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/JXV9VSA3/FranÃ§a and Borges - 2020 - Systematizing the impacts projection of complex de.pdf}
}

@inproceedings{fussellCoordinationOverloadTeam1998,
  title = {Coordination, Overload and Team Performance: Effects of Team Communication Strategies},
  shorttitle = {Coordination, Overload and Team Performance},
  booktitle = {Proceedings of the 1998 {{ACM}} Conference on {{Computer}} Supported Cooperative Work},
  author = {Fussell, Susan R. and Kraut, Robert E. and Lerch, F. Javier and Scherlis, William L. and McNally, Matthew M. and Cadiz, Jonathan J.},
  date = {1998-11},
  pages = {275--284},
  publisher = {{ACM}},
  location = {{Seattle Washington USA}},
  doi = {10.1145/289444.289502},
  url = {https://dl.acm.org/doi/10.1145/289444.289502},
  urldate = {2023-03-15},
  eventtitle = {{{CSCW98}}: {{Computer Supported Cooperative Work}}},
  isbn = {978-1-58113-009-6},
  langid = {english},
  keywords = {notion}
}

@inproceedings{fuTCalUnderstandingTeam2018,
  title = {T-{{Cal}}: {{Understanding Team Conversational Data}} with {{Calendar-based Visualization}}},
  shorttitle = {T-{{Cal}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Fu, Siwei and Zhao, Jian and Cheng, Hao Fei and Zhu, Haiyi and Marlow, Jennifer},
  date = {2018-04-21},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Montreal QC Canada}},
  doi = {10.1145/3173574.3174074},
  url = {https://dl.acm.org/doi/10.1145/3173574.3174074},
  urldate = {2023-04-10},
  abstract = {Understanding team communication and collaboration patterns is critical for improving work efficiency in organizations. This paper presents an interactive visualization system, T-Cal, that supports the analysis of conversation data from modern team messaging platforms (e.g., Slack). T-Cal employs a user-familiar visual interface, a calendar, to enable seamless multi-scale browsing of data from different perspectives. T-Cal also incorporates a number of analytical techniques for disentangling interleaving conversations, extracting keywords, and estimating sentiment. The design of T-Cal is based on an iterative user-centered design process including interview studies, requirements gathering, initial prototypes demonstration, and evaluation with domain users. The resulting two case studies indicate the effectiveness and usefulness of T-Cal in real-world applications, including daily conversations within an industry research lab and student group chats in a MOOC.},
  eventtitle = {{{CHI}} '18: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  file = {/Users/xinyuech/Zotero/storage/4KCXGRMH/Fu et al. - 2018 - T-Cal Understanding Team Conversational Data with.pdf}
}

@inproceedings{gebreegziabherPaTATHumanAICollaborative2023,
  title = {{{PaTAT}}: {{Human-AI Collaborative Qualitative Coding}} with {{Explainable Interactive Rule Synthesis}}},
  shorttitle = {{{PaTAT}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Gebreegziabher, Simret Araya and Zhang, Zheng and Tang, Xiaohang and Meng, Yihao and Glassman, Elena L. and Li, Toby Jia-Jun},
  date = {2023-04-19},
  pages = {1--19},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581352},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581352},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/L4IBU5NZ/Gebreegziabher et al. - 2023 - PaTAT Human-AI Collaborative Qualitative Coding w.pdf}
}

@inproceedings{geyerTeamCollaborationSpace2001,
  title = {A Team Collaboration Space Supporting Capture and Access of Virtual Meetings},
  booktitle = {Proceedings of the 2001 {{International ACM SIGGROUP Conference}} on {{Supporting Group Work}}  - {{GROUP}} '01},
  author = {Geyer, Werner and Richter, Heather and Fuchs, Ludwin and Frauenhofer, Tom and Daijavad, Shahrokh and Poltrock, Steven},
  date = {2001},
  pages = {188},
  publisher = {{ACM Press}},
  location = {{Boulder, Colorado, USA}},
  doi = {10.1145/500286.500315},
  url = {http://portal.acm.org/citation.cfm?doid=500286.500315},
  urldate = {2023-05-07},
  eventtitle = {The 2001 {{International ACM SIGGROUP Conference}}},
  isbn = {978-1-58113-294-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/WRGHHSII/Geyer et al. - 2001 - A team collaboration space supporting capture and .pdf}
}

@article{gongVIRTUALBRAINSTORMINGCREATIVITY2021,
  title = {VIRTUAL BRAINSTORMING AND CREATIVITY: AN ANALYSIS OF MEASURES, AVATARS, ENVIRONMENTS, INTERFACES, AND APPLICATIONS},
  shorttitle = {VIRTUAL BRAINSTORMING AND CREATIVITY},
  author = {Gong, Zhengya and Nanjappan, Vijayakumar and Soomro, Sohail Ahmed and Georgiev, Georgi V.},
  date = {2021-08},
  journaltitle = {Proceedings of the Design Society},
  volume = {1},
  pages = {3399--3408},
  publisher = {{Cambridge University Press}},
  issn = {2732-527X},
  doi = {10.1017/pds.2021.601},
  url = {https://www.cambridge.org/core/journals/proceedings-of-the-design-society/article/virtual-brainstorming-and-creativity-an-analysis-of-measures-avatars-environments-interfaces-and-applications/6D0C767DF1C9FBE3DDBB7EDE1901B68A},
  urldate = {2023-03-15},
  abstract = {å¦‚ä½•æå‡åˆ›é€ åŠ›ï¼Œå°¤å…¶æ˜¯å°†æ–°æŠ€æœ¯åº”ç”¨åˆ°åˆ›é€ åŠ›æ–¹æ³•ä¸­ï¼Œæ˜¯ç ”ç©¶è€…ä¸æ–­æå‡ºçš„é—®é¢˜ã€‚åŸå› ä¹‹ä¸€æ˜¯åˆ›é€ åŠ›æ˜¯äººä»¬æ—¥å¸¸ç”Ÿæ´»çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä¹Ÿæ˜¯ç¤¾ä¼šçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚å› æ­¤ï¼Œè®¸å¤šæé«˜åˆ›é€ åŠ›çš„æ–¹æ³•åº”è¿è€Œç”Ÿï¼Œå°¤å…¶æ˜¯å¤´è„‘é£æš´æ³•ï¼Œå®ƒæ˜¯æœ€æµè¡Œå’Œæœ€æœ‰æ•ˆçš„å·¥å…·ä¹‹ä¸€ï¼Œå¯ä»¥æ¿€å‘ä¸ªäººäº§ç”Ÿæƒ³æ³•ï¼Œä»è€Œæé«˜åˆ›é€ åŠ›ã€‚æ­¤å¤–ï¼Œè™šæ‹Ÿç°å® (VR) ç­‰æŠ€æœ¯ä¸ºä¸ªäººå’Œå›¢ä½“æä¾›äº†å‘æŒ¥åˆ›é€ åŠ›çš„æœºä¼šã€‚ä½œä¸ºå›åº”ï¼Œæœ€è¿‘çš„ç ”ç©¶åœ¨å¤´è„‘é£æš´ä¸­é‡‡ç”¨ VR æ¥å¢å¼ºåˆ›é€ åŠ›ã€‚ç„¶è€Œï¼Œç¼ºä¹å¯¹åœ¨è¿™ç§æƒ…å†µä¸‹é‡‡ç”¨çš„å®éªŒæ–¹æ³•å’Œåˆ›é€ æ€§æªæ–½çš„ç³»ç»Ÿåˆ†æã€‚é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œè¿™é¡¹ç ”ç©¶å¯¹ä¸åŒ–èº«ã€ç¯å¢ƒã€ç•Œé¢æˆ–åº”ç”¨ç¨‹åºç±»åˆ«ç›¸å…³çš„ä¸»é¢˜çš„ç°æœ‰æ–‡ç« è¿›è¡Œäº†åˆ†ç±»ã€‚è°ƒæŸ¥ç»“æœè¯¦ç»†è¯´æ˜äº†è¶‹åŠ¿ã€ç”¨äºè¯„ä¼°åˆ›é€ åŠ›å’Œåˆ›æ„äº§ç”Ÿçš„æªæ–½ã€ç¡®å®šçš„ç±»åˆ«ä»¥åŠè¿™äº›ç ”ç©¶çš„ç»“æœã€‚},
  langid = {chinese},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/2WA444BS/Gong et al. - 2021 - VIRTUAL BRAINSTORMING AND CREATIVITY AN ANALYSIS .pdf}
}

@inproceedings{gonzalezAutomaticallyGeneratedSummaries2023,
  title = {Automatically {{Generated Summaries}} of {{Video Lectures May Enhance Students}}' {{Learning Experience}}},
  booktitle = {Proceedings of the 18th {{Workshop}} on {{Innovative Use}} of {{NLP}} for {{Building Educational Applications}} ({{BEA}} 2023)},
  author = {Gonzalez, Hannah and Li, Jiening and Jin, Helen and Ren, Jiaxuan and Zhang, Hongyu and Akinyele, Ayotomiwa and Wang, Adrian and Miltsakaki, Eleni and Baker, Ryan and Callison-Burch, Chris},
  date = {2023-07},
  pages = {382--393},
  publisher = {{Association for Computational Linguistics}},
  location = {{Toronto, Canada}},
  doi = {10.18653/v1/2023.bea-1.31},
  url = {https://aclanthology.org/2023.bea-1.31},
  urldate = {2023-08-15},
  abstract = {We introduce a novel technique for automatically summarizing lecture videos using large language models such as GPT-3 and we present a user study investigating the effects on the studying experience when automatic summaries are added to lecture videos. We test students under different conditions and find that the students who are shown a summary next to a lecture video perform better on quizzes designed to test the course materials than the students who have access only to the video or the summary. Our findings suggest that adding automatic summaries to lecture videos enhances the learning experience. Qualitatively, students preferred summaries when studying under time constraints.},
  eventtitle = {{{BEA}} 2023},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/2W9MWFJG/Gonzalez et al. - 2023 - Automatically Generated Summaries of Video Lecture.pdf}
}

@inproceedings{gumiennySupportingSynthesisInformation2014,
  title = {Supporting the Synthesis of Information in Design Teams},
  booktitle = {Proceedings of the 2014 Conference on {{Designing}} Interactive Systems},
  author = {Gumienny, Raja and Dow, Steven P. and Meinel, Christoph},
  date = {2014-06-21},
  pages = {463--472},
  publisher = {{ACM}},
  location = {{Vancouver BC Canada}},
  doi = {10.1145/2598510.2598545},
  url = {https://dl.acm.org/doi/10.1145/2598510.2598545},
  urldate = {2023-03-21},
  eventtitle = {{{DIS}} '14: {{Designing Interactive Systems Conference}} 2014},
  isbn = {978-1-4503-2902-6},
  langid = {english},
  keywords = {notion}
}

@article{habernalArgumentationMiningUserGenerated2017,
  title = {Argumentation {{Mining}} in {{User-Generated Web Discourse}}},
  author = {Habernal, Ivan and Gurevych, Iryna},
  date = {2017-04-01},
  journaltitle = {Computational Linguistics},
  shortjournal = {Computational Linguistics},
  volume = {43},
  number = {1},
  pages = {125--179},
  issn = {0891-2017},
  doi = {10.1162/COLI_a_00276},
  url = {https://doi.org/10.1162/COLI_a_00276},
  urldate = {2022-11-07},
  abstract = {The goal of argumentation mining, an evolving research field in computational linguistics, is to design methods capable of analyzing people's argumentation. In this article, we go beyond the state of the art in several ways. (i) We deal with actual Web data and take up the challenges given by the variety of registers, multiple domains, and unrestricted noisy user-generated Web discourse. (ii) We bridge the gap between normative argumentation theories and argumentation phenomena encountered in actual data by adapting an argumentation model tested in an extensive annotation study. (iii) We create a new gold standard corpus (90k tokens in 340 documents) and experiment with several machine learning methods to identify argument components. We offer the data, source codes, and annotation guidelines to the community under free licenses. Our findings show that argumentation mining in user-generated Web discourse is a feasible but challenging task.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XFLJ286D/Habernal and Gurevych - 2017 - Argumentation Mining in User-Generated Web Discour.pdf;/Users/xinyuech/Zotero/storage/ZAIGEHG2/Habernal and Gurevych - 2017 - Argumentation Mining in User-Generated Web Discour.pdf;/Users/xinyuech/Zotero/storage/WUJJ9G9T/Argumentation-Mining-in-User-Generated-Web.html}
}

@article{hindalongAbstractionsVisualizingPreferences2022,
  title = {Abstractions for {{Visualizing Preferences}} in {{Group Decisions}}},
  author = {Hindalong, Emily and Johnson, Jordon and Carenini, Giuseppe and Munzner, Tamara},
  date = {2022-03-30},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {1--44},
  issn = {2573-0142},
  doi = {10.1145/3512896},
  url = {https://dl.acm.org/doi/10.1145/3512896},
  urldate = {2023-03-21},
  abstract = {Group decision making occurs when individuals collectively choose from a set of alternatives based on individual preferences. In these ubiquitous situations, it can be helpful for decision makers to visually model and compare stakeholder preferences in order to better understand others' points of view and reach consensus. Although a number of collaboration support tools allow preference inspection in some form, they are rarely based on a comprehensive understanding of the needs of group decision makers. The goal of our work is to study these demands, develop abstractions to model them, and create a framework to inform the design and assessment of existing and future tools. First, guided by decision analysis theory, we examine a diverse set of group decision making scenarios, characterizing variations in problem formulation, analysis goals, and situational features. Second, we amalgamate these findings into data and task abstractions that can be used to relate specific scenarios to the language of visualization. Finally, we use this framework to assess existing preference visualization tools in order to shed light on areas for future work in supporting group decision making.},
  issue = {CSCW1},
  langid = {english},
  keywords = {notion}
}

@inproceedings{hongCollaborativeDynamicQueries2018,
  title = {Collaborative {{Dynamic Queries}}: {{Supporting Distributed Small Group Decision-making}}},
  shorttitle = {Collaborative {{Dynamic Queries}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hong, Sungsoo (Ray) and Suh, Minhyang (Mia) and Henry Riche, Nathalie and Lee, Jooyoung and Kim, Juho and Zachry, Mark},
  date = {2018-04-19},
  pages = {1--12},
  publisher = {{ACM}},
  location = {{Montreal QC Canada}},
  doi = {10.1145/3173574.3173640},
  url = {https://dl.acm.org/doi/10.1145/3173574.3173640},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '18: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/99PS8KBH/Hong et al. - 2018 - Collaborative Dynamic Queries Supporting Distribu.pdf}
}

@article{houAnalyzingSocialKnowledge2011,
  title = {Analyzing the Social Knowledge Construction Behavioral Patterns of an Online Synchronous Collaborative Discussion Instructional Activity Using an Instant Messaging Tool: {{A}} Case Study},
  shorttitle = {Analyzing the Social Knowledge Construction Behavioral Patterns of an Online Synchronous Collaborative Discussion Instructional Activity Using an Instant Messaging Tool},
  author = {Hou, Huei-Tse and Wu, Sheng-Yi},
  date = {2011-09-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {57},
  number = {2},
  pages = {1459--1468},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2011.02.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131511000509},
  urldate = {2023-05-07},
  abstract = {Online discussions have been widely utilized as an educational activity, and much research has been conducted on the process and behaviors involved in asynchronous discussions. However, research on behavioral patterns in learnersâ€™ synchronous discussions, including the process of social knowledge construction and project coordination is limited. Through the examination of the behavioral patterns and differences between students with high- and low-quality discussions, it may be possible to understand the limitations of knowledge construction in synchronous discussions. Furthermore, these findings may help teachers design and guide synchronous discussions activities. This study is an empirical case study in which college students conducted synchronous discussions based on topics specified by the teacher. The students used a text-based instant messaging (IM) tool in a period of 98 days. Two analytical methods were employed. The coding of the discussion messages was followed by a quantitative content analysis and a lag sequential analysis of behaviors. The social knowledge construction, project coordination, and social interactions in the group discussion were explored. Furthermore, the differences between the behavioral patterns of the high- and low-quality discussion groups were also examined. The findings indicate that although more than half of the discussion messages were off-topic, there were also some knowledge construction behavioral sequences. Furthermore, there were several limitations on the diversity and depth of the knowledge construction in the studentsâ€™ discussions. The high-quality discussion teams performed better than the low-quality discussion teams in terms of participation, diversity in knowledge construction, and coordination. However, they also had more off-topic discussions. In this paper, we discuss these behavioral patterns and provide specific suggestions for teachers regarding how to implement synchronous discussions that are targeted to studentsâ€™ knowledge construction processes.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/JUHKUYIM/Hou and Wu - 2011 - Analyzing the social knowledge construction behavi.pdf}
}

@online{HowDisplayGroup,
  title = {How to {{Display Group Information}} on {{Node-Link Diagrams}}: {{An Evaluation}} | {{IEEE Journals}} \& {{Magazine}} | {{IEEE Xplore}}},
  url = {https://ieeexplore.ieee.org/document/6787045},
  urldate = {2023-06-02},
  keywords = {notion}
}

@article{hoxhaDREAMClassificationScheme2016,
  title = {{{DREAM}}: {{Classification}} Scheme for Dialog Acts in Clinical Research Query Mediation},
  shorttitle = {{{DREAM}}},
  author = {Hoxha, Julia and Chandar, Praveen and He, Zhe and Cimino, James and Hanauer, David and Weng, Chunhua},
  date = {2016-02-01},
  journaltitle = {Journal of Biomedical Informatics},
  shortjournal = {Journal of Biomedical Informatics},
  volume = {59},
  pages = {89--101},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2015.11.011},
  url = {https://www.sciencedirect.com/science/article/pii/S1532046415002798},
  urldate = {2023-04-24},
  abstract = {Clinical data access involves complex but opaque communication between medical researchers and query analysts. Understanding such communication is indispensable for designing intelligent humanâ€“machine dialog systems that automate query formulation. This study investigates email communication and proposes a novel scheme for classifying dialog acts in clinical research query mediation. We analyzed 315 email messages exchanged in the communication for 20 data requests obtained from three institutions. The messages were segmented into 1333 utterance units. Through a rigorous process, we developed a classification scheme and applied it for dialog act annotation of the extracted utterances. Evaluation results with high inter-annotator agreement demonstrate the reliability of this scheme. This dataset is used to contribute preliminary understanding of dialog acts distribution and conversation flow in this dialog space.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/923I9UQR/Hoxha et al. - 2016 - DREAM Classification scheme for dialog acts in cl.pdf;/Users/xinyuech/Zotero/storage/VN3AJILG/S1532046415002798.html}
}

@article{hrastinskiPotentialSynchronousCommunication2008,
  title = {The Potential of Synchronous Communication to Enhance Participation in Online Discussions: {{A}} Case Study of Two e-Learning Courses},
  shorttitle = {The Potential of Synchronous Communication to Enhance Participation in Online Discussions},
  author = {Hrastinski, Stefan},
  date = {2008-11-01},
  journaltitle = {Information \& Management},
  shortjournal = {Information \& Management},
  volume = {45},
  number = {7},
  pages = {499--506},
  issn = {0378-7206},
  doi = {10.1016/j.im.2008.07.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0378720608000931},
  urldate = {2023-03-15},
  abstract = {Computer-mediated communication (CMC) has been adopted in most e-learning settings. However, few research studies have considered the effect of different CMC. This study examined how and why synchronous communication affected participation in online discussions. Two online classes that participated in two asynchronous and two synchronous online discussions were examined. Actual and perceived measures of participation indicated that synchronous communication induced personal participation, which could be regarded as a complement to cognitive participation. Personal participation involves more intense interaction better supported by synchronous communication while cognitive participation is a more reflective type of participation supported by asynchronous communication. In synchronous discussions, the e-learners felt that they worked together and were not restricted to only discuss course content. This was likely to induce arousal and motivation and increased convergence on meaning, especially in small groups.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/X78KRQ2Q/Hrastinski - 2008 - The potential of synchronous communication to enha.pdf;/Users/xinyuech/Zotero/storage/CE75Y4WR/S0378720608000931.html}
}

@inproceedings{hsuehImprovingMeetingSummarization2009,
  title = {Improving Meeting Summarization by Focusing on User Needs: A Task-Oriented Evaluation},
  shorttitle = {Improving Meeting Summarization by Focusing on User Needs},
  booktitle = {Proceedings of the 14th International Conference on {{Intelligent}} User Interfaces},
  author = {Hsueh, Pei-Yun and Moore, Johanna D.},
  date = {2009-02-08},
  series = {{{IUI}} '09},
  pages = {17--26},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/1502650.1502657},
  url = {https://doi.org/10.1145/1502650.1502657},
  urldate = {2023-06-04},
  abstract = {Advances in multimedia technologies have enabled the creation of huge archives of audio-video recordings of meetings, and there is burgeoning interest in developing meeting browsers to help users better leverage these archives. A recent study has shown that extractive summaries provide a more efficient way of navigating meeting content than simply reading through the transcript and using the audio-video record, or navigating via keyword search (Murray, 2007). The extractive summary technique identifies informative dialogue acts to generate general purpose summaries. These summaries can still be lengthy. Recently, we have developed a decision-focused summarization system that presents only 1-2\% of the recordings related to decision making. In this paper, we describe a task-based evaluation in which we compare the decision-focused summaries to the general purpose summaries. Our results indicate that the more focused summaries help users perform the decision debriefing task more effectively and improve perceived efficiency. In addition, this study also investigates the effect of automatic summaries and transcription on task effectiveness, report quality, and users' perceptions of task success.},
  isbn = {978-1-60558-168-2},
  keywords = {ğŸ’™,notion},
  file = {/Users/xinyuech/Zotero/storage/U8HRRU58/Hsueh and Moore - 2009 - Improving meeting summarization by focusing on use.pdf}
}

@inproceedings{hughesKeeperSynchronousOnline2021,
  title = {Keeper: {{A Synchronous Online Conversation Environment Informed}} by {{In-Person Facilitation Practices}}},
  shorttitle = {Keeper},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hughes, Margaret A. and Roy, Deb},
  date = {2021-05-06},
  pages = {1--14},
  publisher = {{ACM}},
  location = {{Yokohama Japan}},
  doi = {10.1145/3411764.3445316},
  url = {https://dl.acm.org/doi/10.1145/3411764.3445316},
  urldate = {2023-06-26},
  eventtitle = {{{CHI}} '21: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-8096-6},
  langid = {english},
  file = {/Users/xinyuech/Zotero/storage/BLVZMV5K/Hughes and Roy - 2021 - Keeper A Synchronous Online Conversation Environm.pdf}
}

@inproceedings{huhAVscriptAccessibleVideo2023,
  title = {{{AVscript}}: {{Accessible Video Editing}} with {{Audio-Visual Scripts}}},
  shorttitle = {{{AVscript}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Huh, Mina and Yang, Saelyne and Peng, Yi-Hao and Chen, Xiang 'Anthony' and Kim, Young-Ho and Pavel, Amy},
  date = {2023-04-19},
  pages = {1--17},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581494},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581494},
  urldate = {2023-05-03},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/LCRIEXQW/Huh et al. - 2023 - AVscript Accessible Video Editing with Audio-Visu.pdf}
}

@online{ImprovingTeamworkUsing,
  title = {Improving Teamwork Using Real-Time Language Feedback | {{Proceedings}} of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  url = {https://dl.acm.org/doi/abs/10.1145/2470654.2470720?casa_token=KjvCEmNA31sAAAAA%3AB-O2o73feDgj-AVKRiJMaKn1QJpXRwHITYubJfQquDoMQSo9hL8lzWZ7JLjtykbYzjstz_tSEd_4T3k},
  urldate = {2023-06-02},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/62FIFFT9/2470654.html}
}

@inproceedings{ishizukaPrototypingAgentsResolving2022,
  title = {Prototyping {{Agents}} for {{Resolving Opinion Biases Toward Facilitating Sublation}} of {{Conflict}} in {{Web-based Discussions}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Agents}} ({{ICA}})},
  author = {Ishizuka, Hikaru and Shiramatsu, Shun and Ono, Keiko},
  date = {2022-11},
  pages = {18--23},
  doi = {10.1109/ICA55837.2022.00010},
  abstract = {The term â€œsublationâ€ (or â€œaufhebenâ€) refers to the process of arriving at an agreed upon answer to two opposing arguments without denying either of them. In this study, we conducted a discussion experiment in which we quantified the degree of sublation and analyzed the results to determine the factors that contribute to the cessation of conflicting opinions in discussions. Our findings revealed a weak positive correlation between the number of URLs posted as evidence for one's opinion and the degree of sublation of the consensus proposal. In actual discussions and debates, however, there are times when everyone makes the same argument, with little or no opposing views, resulting in biased opinions. To address this problem, we developed a method to eliminate bias in opinions, in which an agent posts information that reinforces the opinion of a minority in a discussion. The experimental results demonstrate that GPT-3, a natural language processing model, can be applied to summarization of relevant information for information provision and the resolution of opinion bias.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Agents}} ({{ICA}})},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XZRPUVFG/Ishizuka et al. - 2022 - Prototyping Agents for Resolving Opinion Biases To.pdf;/Users/xinyuech/Zotero/storage/SFPNEPBG/9999104.html}
}

@article{isterdaelDialogueMappingGuideaMaps,
  title = {Dialogue {{Mapping}} for {{GuideaMaps}}},
  author = {Isterdael, Nick Van},
  abstract = {In any software development process, one of the  rst phases includes collecting and formulating the requirements that the software should meet. This is important because starting from the right requirements will allow developing software that satis es the users as well as the customer. This is why collecting requirements is so vital in the whole software development process. In addition, maintaining or modifying existing software can also be a di cult task, especially when it is not clear what the original requirements and rationale were behind software design decisions. Therefore, requirement collection and analysis is an important phase in the development of software. Both tasks, developing and maintaining software, can be made easier by providing the developers with the design rationale of the original software in an explicit way. Design rationale documentation can provide an insight into why design decisions, such as requirements, have been made, what other alternatives have been considered and why these alternatives have been accepted or declined. Therefore it is important to provide developers with tools to document the requirements collection and analysis process.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/PAMXBWB2/Isterdael - Dialogue Mapping for GuideaMaps.pdf}
}

@article{janssenVisualizationAgreementDiscussion2007,
  title = {Visualization of Agreement and Discussion Processes during Computer-Supported Collaborative Learning},
  author = {Janssen, Jeroen and Erkens, Gijsbert and Kanselaar, Gellof},
  date = {2007-05-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  series = {Including the {{Special Issue}}: {{Avoiding Simplicity}}, {{Confronting Complexity}}: {{Advances}} in {{Designing Powerful Electronic Learning Environments}}},
  volume = {23},
  number = {3},
  pages = {1105--1125},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2006.10.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563206001282},
  urldate = {2023-06-02},
  abstract = {This study examined the effects of the shared space (SS) on studentsâ€™ behaviors in a computer-supported collaborative learning (CSCL) environment. The SS visualizes discussion and agreement during online discussions. It was hypothesized the SS would increase the media richness of the CSCL-environment, would stimulate critical and exploratory group-norms, would lead to more positive perceptions of online collaboration, and would have an impact on studentsâ€™ collaborative activities. In total, 59 students working in 20 groups had access to the SS visualization, while 58 students working in 20 groups did not. The results show that students with access to the SS visualization: (a) perceived higher media richness; (b) had a more exploratory group-norm perception; (b) perceived more positive group behavior; (c) perceived their groupâ€™s task strategies to be more effective; (d) engaged in different collaborative activities and (e) performed better on one part of the group task. These results demonstrate the potential benefits of visualizing agreement and discussion during CSCL.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XPIRYGWZ/S0747563206001282.html}
}

@online{jiangGraphologueExploringLarge2023,
  title = {Graphologue: {{Exploring Large Language Model Responses}} with {{Interactive Diagrams}}},
  shorttitle = {Graphologue},
  author = {Jiang, Peiling and Rayan, Jude and Dow, Steven P. and Xia, Haijun},
  date = {2023-05-19},
  eprint = {2305.11473},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.11473},
  urldate = {2023-05-23},
  abstract = {Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented intelligence exhibited on diverse applications. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can interact with the diagrams to flexibly adjust the graphical presentation and to submit context-specific prompts to obtain more information. Utilizing diagrams, Graphologue enables graphical, non-linear dialogues between humans and LLMs, facilitating information exploration, organization, and comprehension.},
  pubstate = {preprint},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/2EM3W56R/Jiang et al. - 2023 - Graphologue Exploring Large Language Model Respon.pdf;/Users/xinyuech/Zotero/storage/WJU3F3R5/2305.html}
}

@article{jotyTopicSegmentationLabeling2013,
  title = {Topic {{Segmentation}} and {{Labeling}} in {{Asynchronous Conversations}}},
  author = {Joty, Shafiq Rayhan and Carenini, Giuseppe and Ng, Raymond T.},
  date = {2013-07-22},
  journaltitle = {Journal of Artificial Intelligence Research},
  shortjournal = {jair},
  volume = {47},
  eprint = {1402.0586},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {521--573},
  issn = {1076-9757},
  doi = {10.1613/jair.3940},
  url = {http://arxiv.org/abs/1402.0586},
  urldate = {2023-06-04},
  abstract = {Topic segmentation and labeling is often considered a prerequisite for higher-level conversation analysis and has been shown to be useful in many Natural Language Processing (NLP) applications. We present two new corpora of email and blog conversations annotated with topics, and evaluate annotator reliability for the segmentation and labeling tasks in these asynchronous conversations. We propose a complete computational framework for topic segmentation and labeling in asynchronous conversations. Our approach extends state-of-the-art methods by considering a fine-grained structure of an asynchronous conversation, along with other conversational features by applying recent graph-based methods for NLP. For topic segmentation, we propose two novel unsupervised models that exploit the fine-grained conversational structure, and a novel graph-theoretic supervised model that combines lexical, conversational and topic features. For topic labeling, we propose two novel (unsupervised) random walk models that respectively capture conversation specific clues from two different sources: the leading sentences and the fine-grained conversational structure. Empirical evaluation shows that the segmentation and the labeling performed by our best models beat the state-of-the-art, and are highly correlated with human annotations.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DESNBLS2/Joty et al. - 2013 - Topic Segmentation and Labeling in Asynchronous Co.pdf;/Users/xinyuech/Zotero/storage/WBD227AP/1402.html}
}

@article{kangSynergiMixedInitiativeSystem2023,
  title = {Synergi: {{A Mixed-Initiative System}} for {{Scholarly Synthesis}} and {{Sensemaking}}},
  author = {Kang, Hyeonsu B and Wu, Sherry Tongshuang and Chang, Joseph Chee and Kittur, Aniket},
  date = {2023},
  abstract = {Efficiently reviewing scholarly literature and synthesizing prior art are crucial for scientific progress. Yet, the growing scale of publications and the burden of knowledge make synthesis of research threads more challenging than ever. While significant research has been devoted to helping scholars interact with individual papers, building research threads scattered across multiple papers remains a challenge. Most top-down synthesis (and LLMs) make it difficult to personalize and iterate on the output, while bottom-up synthesis is costly in time and effort. Here, we explore a new design space of mixed-initiative workflows. In doing so we develop a novel computational pipeline, Synergi, that ties together user input of relevant seed threads with citation graphs and LLMs, to expand and structure them, respectively. Synergi allows scholars to start with an entire threads-and-subthreads structure generated from papers relevant to their interests, and to iterate and customize on it as they wish. In our evaluation, we find that Synergi helps scholars efficiently make sense of relevant threads, broaden their perspectives, and increases their curiosity. We discuss future design implications for thread-based, mixed-initiative scholarly synthesis support tools.},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/XMUD9G22/Kang et al. - 2023 - Synergi A Mixed-Initiative System for Scholarly S.pdf}
}

@article{karlVirtualWorkMeetings2022,
  title = {Virtual {{Work Meetings During}} the {{COVID-19 Pandemic}}: {{The Good}}, {{Bad}}, and {{Ugly}}},
  shorttitle = {Virtual {{Work Meetings During}} the {{COVID-19 Pandemic}}},
  author = {Karl, Katherine A. and Peluchette, Joy V. and Aghakhani, Navid},
  date = {2022-06-01},
  journaltitle = {Small Group Research},
  volume = {53},
  number = {3},
  pages = {343--365},
  publisher = {{SAGE Publications Inc}},
  issn = {1046-4964},
  doi = {10.1177/10464964211015286},
  url = {https://doi.org/10.1177/10464964211015286},
  urldate = {2023-03-21},
  abstract = {This study focuses on the good, the bad and the ugly of using videoconferencing for work-related meetings during the COVID-19 pandemic. Using a text mining process and qualitative content analysis of 549 comments posted to a LinkedIn online discussion board, we identified six key themes; three were tied to camera and microphone issues, two involved eating and meeting management issues, and one dealt with work-from-home issues. These themes are discussed in relationship to media naturalness theory and meeting science. Because widespread use of videoconferencing will likely continue, we provide guidance for workplace policies/practices and suggest directions for future research.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/HW8SWFRC/Karl et al. - 2022 - Virtual Work Meetings During the COVID-19 Pandemic.pdf}
}

@article{katukaMyPartnerWas,
  title = {My {{Partner}} Was a {{Good Partner}}: {{Investigating}} the {{Relationship}} between {{Dialogue Acts}} and {{Satisfaction}} among {{Middle School Computer Science Learners}}},
  author = {Katuka, Gloria Ashiya and Bex, Richard T and Celepkolu, Mehmet and Boyer, Kristy Elizabeth and Wiebe, Eric and Mott, Bradford and Lester, James},
  abstract = {Collaborative dialogue provides a rich information source for understanding the effectiveness of student interactions. While many studies emphasize the importance of productive dialogue behaviors, the impact of those behaviors on learnersâ€™ perceptions of their partners is not yet understood. This paper examines a dialogue corpus of 18 pairs of middle school students as they engage in block-based coding activities. We tagged the corpus with a collaborative dialogue act taxonomy and identified sequences of one to two dialogue acts (ngrams) that are significantly associated with partner satisfaction during collaborative learning. Six n-grams were found to be significant predictors: n-grams that were positively associated with satisfaction included some questions and clarifications. In contrast, n-grams that were negatively associated with satisfaction included off-task utterances, pairs of consecutive questions, and unexpectedly, positive feedback. These findings contribute to our understanding of how learners prefer to interact with their partners and how that interaction impacts collaborative experiences.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/RZ4I75Q3/Katuka et al. - My Partner was a Good Partner Investigating the R.pdf}
}

@article{kecskesActivatingSeekingCreating2009,
  title = {Activating, Seeking, and Creating Common Ground: {{A}} Socio-Cognitive Approach},
  shorttitle = {Activating, Seeking, and Creating Common Ground},
  author = {Kecskes, Istvan and Zhang, Fenghui},
  date = {2009-08-31},
  journaltitle = {Pragmatics \& Cognition},
  shortjournal = {P\&C},
  volume = {17},
  number = {2},
  pages = {331--355},
  issn = {0929-0907, 1569-9943},
  doi = {10.1075/pc.17.2.06kec},
  url = {http://www.jbe-platform.com/content/journals/10.1075/pc.17.2.06kec},
  urldate = {2023-05-07},
  abstract = {This paper argues that current pragmatic theories fail to describe common ground in its complexity because they usually retain a communication-as-transfer-between-minds view of language, and disregard the fact that disagreement and egocentrism of speaker-hearers are as fundamental parts of communication as agreement and cooperation. On the other hand, current cognitive research has overestimated the egocentric behavior of the dyads and argued for the dynamic emergent property of common ground while devaluing the overall significance of cooperation in the process of verbal communication. The paper attempts to eliminate this conflict and proposes to combine the two views into an integrated concept of common ground, in which both core common ground (assumed shared knowledge, a priori mental representation) and emergent common ground (emergent participant resource, a post facto emergence through use) converge to construct a dialectical socio-cultural background for communication. Both cognitive and pragmatic considerations are central to this issue. While attention (through salience, which is the cause for interlocutorsâ€™ egocentrism) explains why emergent property unfolds, intention (through relevance, which is expressed in cooperation) explains why presumed shared knowledge is needed. Based on this, common ground is perceived as an effort to converge the mental representation of shared knowledge present as memory that we can activate, shared knowledge that we can seek, and rapport, as well as knowledge that we can create in the communicative process. The socio-cognitive approach emphasizes that common ground is a dynamic construct that is mutually constructed by interlocutors throughout the communicative process. The core and emergent components join in the construction of common ground in all stages, although they may contribute to the construction process in different ways, to different extents, and in different phases of the communicative process.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DFY26N4W/Kecskes and Zhang - 2009 - Activating, seeking, and creating common ground A.pdf}
}

@article{khadpeEmpathospherePromotingConstructive2022,
  title = {Empathosphere: {{Promoting Constructive Communication}} in {{Ad-hoc Virtual Teams}} through {{Perspective-taking Spaces}}},
  shorttitle = {Empathosphere},
  author = {Khadpe, Pranav and Kulkarni, Chinmay and Kaufman, Geoff},
  date = {2022-03-30},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {1--26},
  issn = {2573-0142},
  doi = {10.1145/3512902},
  url = {https://dl.acm.org/doi/10.1145/3512902},
  urldate = {2023-06-02},
  abstract = {When members of ad-hoc virtual teams need to collectively ideate or deliberate, they often fail to engage with each others' perspectives in a constructive manner. At best, this leads to sub-optimal outcomes, and, at worst, it can cause conflicts that lead to teams not wanting to continue working together. Prior work has attempted to facilitate constructive communication by highlighting problematic communication patterns and nudging teams to alter their interaction norms. However, these approaches achieve limited success because they fail to acknowledge two social barriers: (1) it is hard to reset team norms mid-interaction, and (2) corrective nudges have limited utility unless team members believe it is safe to voice their opinion and that their opinion will be heard. This paper introduces Empathosphere, a chat-embedded intervention to mitigate these barriers and foster constructive communication in teams. To mitigate the first barrier, Empathosphere leverages the known benefits of "experimental spaces" in dampening existing norms and creating a climate conducive to change. Empathosphere instantiates this "space'' as a separate communication channel in a team's workspace. To mitigate the second barrier, Empathosphere harnesses the benefits of perspective-taking to cultivate a group climate that promotes a norm of members speaking up and engaging with each other. Empathosphere achieves this by orchestrating authentic socio-emotional exchanges designed to induce perspective-taking. A controlled study (\$N=110\$) compared Empathosphere to an alternate intervention strategy of prompting teams to reflect on their team experience. We found that Empathosphere led to higher work satisfaction, encouraged more open communication and feedback within teams, and boosted teams' desire to continue working together. This work demonstrates that "experimental spaces," particularly those that integrate methods of encouraging perspective-taking, can be a powerful means of improving communication in virtual teams.},
  issue = {CSCW1},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/6H6K666V/Khadpe et al. - 2022 - Empathosphere Promoting Constructive Communicatio.pdf}
}

@article{kimCellsGeneratorsLenses2023,
  title = {Cells, {{Generators}}, and {{Lenses}}: {{Design Framework}} for {{Object-Oriented Interaction}} with {{Large Language Models}}},
  author = {Kim, Tae Soo and Chang, Minsuk and Lee, Yoonjoo and Kim, Juho},
  date = {2023},
  langid = {english},
  keywords = {ğŸ§¡ğŸ§¡ğŸ§¡ğŸ§¡},
  file = {/Users/xinyuech/Zotero/storage/B6K7WP6G/Kim et al. - 2023 - Cells, Generators, and Lenses Design Framework fo.pdf}
}

@article{kimModeratorChatbotDeliberative2021,
  title = {Moderator {{Chatbot}} for {{Deliberative Discussion}}: {{Effects}} of {{Discussion Structure}} and {{Discussant Facilitation}}},
  shorttitle = {Moderator {{Chatbot}} for {{Deliberative Discussion}}},
  author = {Kim, Soomin and Eun, Jinsu and Seering, Joseph and Lee, Joonhwan},
  date = {2021-04-13},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  pages = {1--26},
  issn = {2573-0142},
  doi = {10.1145/3449161},
  url = {https://dl.acm.org/doi/10.1145/3449161},
  urldate = {2023-05-08},
  abstract = {Online chat functions as a discussion channel for diverse social issues. However, deliberative discussion and consensus-reaching can be difficult in online chats in part because of the lack of structure. To explore the feasibility of a conversational agent that enables deliberative discussion, we designed and developed DebateBot, a chatbot that structures discussion and encourages reticent participants to contribute. We conducted a 2 (discussion structure: unstructured vs. structured) Ã— 2 (discussant facilitation: unfacilitated vs. facilitated) between-subjects experiment (N = 64, 12 groups). Our findings are as follows: (1) Structured discussion positively affects discussion quality by generating diverse opinions within a group and resulting in a high level of perceived deliberative quality. (2) Facilitation drives a high level of opinion alignment between group consensus and independent individual opinions, resulting in authentic consensus reaching. Facilitation also drives more even contribution and a higher level of task cohesion and communication fairness. Our results suggest that a chatbot agent could partially substitute for a human moderator in deliberative discussions.},
  issue = {CSCW1},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/F6PPSDRG/Kim et al. - 2021 - Moderator Chatbot for Deliberative Discussion Eff.pdf}
}

@inproceedings{kimSurchEnablingStructural2023,
  title = {Surch: {{Enabling Structural Search}} and {{Comparison}} for {{Surgical Videos}}},
  shorttitle = {Surch},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kim, Jeongyeon and Choi, Daeun and Lee, Nicole and Beane, Matt and Kim, Juho},
  date = {2023-04-19},
  pages = {1--17},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580772},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580772},
  urldate = {2023-08-15},
  abstract = {Video is an effective medium for learning procedural knowledge, such as surgical techniques. However, learning procedural knowledge through videos remains difficult due to limited access to procedural structures of knowledge (e.g., compositions and ordering of steps) in a large-scale video dataset. We present Surch, a system that enables structural search and comparison of surgical procedures. Surch supports video search based on procedural graphs generated by our clustering workflow capturing latent patterns within surgical procedures. We used vectorization and weighting schemes that characterize the features of procedures, such as recursive structures and unique paths. Surch enhances cross-video comparison by providing video navigation synchronized by surgical steps. Evaluation of the workflow demonstrates the effectiveness and interpretability (Silhouette score = 0.82) of our clustering for surgical learning. A user study with 11 residents shows that our system significantly improves the learning experience and task efficiency of video search and comparison, especially benefiting junior residents.},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/RTNENUAJ/Kim et al. - 2023 - Surch Enabling Structural Search and Comparison f.pdf}
}

@inproceedings{kimSystematicReviewDyadic2021,
  title = {A {{Systematic Review}} on {{Dyadic Conversation Visualizations}}},
  booktitle = {Companion {{Publication}} of the 2021 {{International Conference}} on {{Multimodal Interaction}}},
  author = {Kim, Joshua Y. and Calvo, Rafael A. and Enfield, N. J. and Yacef, Kalina},
  date = {2021-10-18},
  pages = {137--147},
  publisher = {{ACM}},
  location = {{Montreal QC Canada}},
  doi = {10.1145/3461615.3485396},
  url = {https://dl.acm.org/doi/10.1145/3461615.3485396},
  urldate = {2023-05-08},
  eventtitle = {{{ICMI}} '21: {{INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION}}},
  isbn = {978-1-4503-8471-1},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/5G6LXJTH/Kim et al. - 2021 - A Systematic Review on Dyadic Conversation Visuali.pdf}
}

@article{kirshenbaumTracesTimeSpace2021c,
  title = {Traces of {{Time}} through {{Space}}: {{Advantages}} of {{Creating Complex Canvases}} in {{Collaborative Meetings}}},
  shorttitle = {Traces of {{Time}} through {{Space}}},
  author = {Kirshenbaum, Nurit and Davidson, Kylie and Harden, Jesse and North, Chris and Kobayashi, Dylan and Theriot, Ryan and Tabalba, Roderick S. and Rogers, Michael L. and Belcaid, Mahdi and Burks, Andrew T. and Bharadwaj, Krishna N. and Renambot, Luc and Johnson, Andrew E. and Long, Lance and Leigh, Jason},
  date = {2021-11-03},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  pages = {1--20},
  issn = {2573-0142},
  doi = {10.1145/3488552},
  url = {https://dl.acm.org/doi/10.1145/3488552},
  urldate = {2023-03-24},
  abstract = {Technology have long been a partner of workplace meeting facilitation. The recent outbreak of COVID-19 and the cautionary measures to reduce its spread have made it more prevalent than ever before in the form of online-meetings. In this paper, we recount our experiences during weekly meetings in three modalities: using SAGE2 - a collaborative sharing software designed for large displays - for co-located meetings, using a conventional projector for co-located meetings, and using the Zoom video-conferencing tool for distributed meetings. We view these meetings through the lens of effective meeting attributes and share ethnographic observations and attitudinal survey conducted in our research lab. We discuss patterns of content sharing, either sequential, parallel, or semi-parallel, and the potential advantages of creating complex canvases of content. We see how the SAGE2 tool affords parallel content sharing to create complex canvases, which represent queues of ideas and contributions (past, present, and future) using the space on a large display to suggest the progression of time through the meeting.},
  issue = {ISS},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/UGDEZ2TH/Kirshenbaum et al. - 2021 - Traces of Time through Space Advantages of Creati.pdf}
}

@incollection{kleinCommonGroundCoordination2005,
  title = {Common {{Ground}} and {{Coordination}} in {{Joint Activity}}},
  booktitle = {Organizational {{Simulation}}},
  author = {Klein, Gary and Feltovich, Paul J. and Bradshaw, Jeffrey M. and Woods, David D.},
  editor = {Rouse, William B. and Boff, Kenneth R.},
  date = {2005-06-27},
  pages = {139--184},
  publisher = {{John Wiley \& Sons, Inc.}},
  location = {{Hoboken, NJ, USA}},
  doi = {10.1002/0471739448.ch6},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/0471739448.ch6},
  urldate = {2023-03-15},
  abstract = {Generalizing the concepts of joint activity developed by Clark (1996), we describe key aspects of team coordination. Joint activity depends on interpredictability of the participantsâ€™ attitudes and actions. Such interpredictability is based on common groundâ€”pertinent knowledge, beliefs and assumptions that are shared among the involved parties. Joint activity assumes a basic compact, which is an agreement (often tacit) to facilitate coordination and prevent its breakdown. One aspect of the Basic Compact is the commitment to some degree of aligning multiple goals. A second aspect is that all parties are expected to bear their portion of the responsibility to establish and sustain common ground and to repair it as needed.},
  isbn = {978-0-471-73944-9 978-0-471-68163-2},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/CVQWKTGM/Klein et al. - 2005 - Common Ground and Coordination in Joint Activity.pdf}
}

@article{kohnBuildingIdeasOthers2011,
  title = {Building on the Ideas of Others: {{An}} Examination of the Idea Combination Process},
  shorttitle = {Building on the Ideas of Others},
  author = {Kohn, Nicholas W. and Paulus, Paul B. and Choi, YunHee},
  date = {2011-05-01},
  journaltitle = {Journal of Experimental Social Psychology},
  shortjournal = {Journal of Experimental Social Psychology},
  volume = {47},
  number = {3},
  pages = {554--561},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2011.01.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0022103111000059},
  urldate = {2023-03-14},
  abstract = {Two experiments were conducted to explore the process of building on ideas in brainstorming. Although this is presumed to be an important role of brainstorming, this has never been explored experimentally. In one experiment individual and group brainstormers generated ideas which were subsequently presented to these same individuals and groups to combine and build on for additional ideas, either as groups or individuals. The combination process was influenced by whether the participants had previously brainstormed alone or in groups and the phase of the combination period (early vs. late). In a second study participants were presented lists of rare or common ideas to combine and build on either as individuals or groups. Although groups generated fewer combinations than nominal groups, they generated more novel and feasible combinations when combining rare ideas. These findings indicate that groups are able to benefit from the exchange process in building on each other's ideas and are interpreted in the context of past research on idea generation and evaluation in groups.},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/GH6XPI5P/Kohn et al. - 2011 - Building on the ideas of others An examination of.pdf;/Users/xinyuech/Zotero/storage/AYD4TT8Q/S0022103111000059.html}
}

@article{kontogiorgosGroundingBehavioursConversational2021,
  title = {Grounding Behaviours with Conversational Interfaces: Effects of Embodiment and Failures},
  shorttitle = {Grounding Behaviours with Conversational Interfaces},
  author = {Kontogiorgos, Dimosthenis and Pereira, Andre and Gustafson, Joakim},
  date = {2021-06-01},
  journaltitle = {Journal on Multimodal User Interfaces},
  shortjournal = {J Multimodal User Interfaces},
  volume = {15},
  number = {2},
  pages = {239--254},
  issn = {1783-8738},
  doi = {10.1007/s12193-021-00366-y},
  url = {https://doi.org/10.1007/s12193-021-00366-y},
  urldate = {2023-03-15},
  abstract = {Conversational interfaces that interact with humans need to continuously establish, maintain and repair common ground in task-oriented dialogues. Uncertainty, repairs and acknowledgements are expressed in user behaviour in the continuous efforts of the conversational partners to maintain mutual understanding. Users change their behaviour when interacting with systems in different forms of embodiment, which affects the abilities of these interfaces to observe usersâ€™ recurrent social signals. Additionally, humans are intellectually biased towards social activity when facing anthropomorphic agents or when presented with subtle social cues. Two studies are presented in this paper examining how humans interact in a referential communication task with wizarded interfaces in different forms of embodiment. In study 1 (N = 30), we test whether humans respond the same way to agents, in different forms of embodiment and social behaviour. In study 2 (N = 44), we replicate the same task and agents but introduce conversational failures disrupting the process of grounding. Findings indicate that it is not always favourable for agents to be anthropomorphised or to communicate with non-verbal cues, as human grounding behaviours change when embodiment and failures are manipulated.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/3ZH6IR4L/Kontogiorgos et al. - 2021 - Grounding behaviours with conversational interface.pdf}
}

@article{kuoEffectsApplyingSTR2012,
  title = {Effects of Applying {{STR}} for Group Learning Activities on Learning Performance in a Synchronous Cyber Classroom},
  author = {Kuo, Tony C. T. and Shadiev, Rustam and Hwang, Wu-Yuin and Chen, Nian-Shing},
  date = {2012-01-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {58},
  number = {1},
  pages = {600--608},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2011.07.018},
  url = {https://www.sciencedirect.com/science/article/pii/S036013151100176X},
  urldate = {2023-03-15},
  abstract = {This study aimed to apply Speech to Text Recognition (STR) for individual oral presentations and group discussions of students in a synchronous cyber classroom. An experiment was conducted to analyze the effectiveness of applying STR on learning performance. Studentsâ€™ perceptions and behavioral intentions toward using STR were also investigated. The results revealed students of the experimental group performed significantly better compared to the control group students in two sessions of writing essays, intermediate test and post-test. Most of students perceived that STR was useful for individual presentations and for essays writing. Students also expressed they are willing to use the STR for learning in the future. However, the students who obtained transcripts with low accuracy rate and experienced delay in STR-text generation did not perceive the STR as easy to use and useful for group discussions. Meanwhile, the results of this study showed that the STR is beneficial to studentsâ€™ oral presentations and group discussions in a synchronous cyber classroom so as to improve their overall learning performance.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/ZSBS223B/Kuo et al. - 2012 - Effects of applying STR for group learning activit.pdf;/Users/xinyuech/Zotero/storage/S5HE2SI6/S036013151100176X.html}
}

@inproceedings{leeDAPIEInteractiveStepbyStep2023,
  title = {{{DAPIE}}: {{Interactive Step-by-Step Explanatory Dialogues}} to {{Answer Children}}â€™s {{Why}} and {{How Questions}}},
  shorttitle = {{{DAPIE}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lee, Yoonjoo and Kim, Tae Soo and Kim, Sungdong and Yun, Yohan and Kim, Juho},
  date = {2023-04-19},
  pages = {1--22},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581369},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581369},
  urldate = {2023-08-15},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/PIJTKWZV/Lee et al. - 2023 - DAPIE Interactive Step-by-Step Explanatory Dialog.pdf}
}

@inproceedings{leePromptiverseScalableGeneration2022,
  title = {Promptiverse: {{Scalable Generation}} of {{Scaffolding Prompts Through Human-AI Hybrid Knowledge Graph Annotation}}},
  shorttitle = {Promptiverse},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lee, Yoonjoo and Chung, John Joon Young and Kim, Tae Soo and Song, Jean Y and Kim, Juho},
  date = {2022-04-27},
  pages = {1--18},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3491102.3502087},
  url = {https://dl.acm.org/doi/10.1145/3491102.3502087},
  urldate = {2023-08-16},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9157-3},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸},
  file = {/Users/xinyuech/Zotero/storage/F9L8EUIF/Lee et al. - 2022 - Promptiverse Scalable Generation of Scaffolding P.pdf}
}

@inproceedings{leshedVisualizingLanguageUse2010,
  title = {Visualizing Language Use in Team Conversations: Designing through Theory, Experiments, and Iterations},
  shorttitle = {Visualizing Language Use in Team Conversations},
  booktitle = {{{CHI}} '10 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Leshed, Gilly and Cosley, Dan and Hancock, Jeffrey T. and Gay, Geri},
  date = {2010-04-10},
  pages = {4567--4582},
  publisher = {{ACM}},
  location = {{Atlanta Georgia USA}},
  doi = {10.1145/1753846.1754195},
  url = {https://dl.acm.org/doi/10.1145/1753846.1754195},
  urldate = {2023-05-08},
  eventtitle = {{{CHI}} '10: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-930-5},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/AP6B9X9B/Leshed et al. - 2010 - Visualizing language use in team conversations de.pdf}
}

@inproceedings{leshedVisualizingRealtimeLanguagebased2009,
  title = {Visualizing Real-Time Language-Based Feedback on Teamwork Behavior in Computer-Mediated Groups},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Leshed, Gilly and Perez, Diego and Hancock, Jeffrey T. and Cosley, Dan and Birnholtz, Jeremy and Lee, Soyoung and McLeod, Poppy L. and Gay, Geri},
  date = {2009-04-04},
  pages = {537--546},
  publisher = {{ACM}},
  location = {{Boston MA USA}},
  doi = {10.1145/1518701.1518784},
  url = {https://dl.acm.org/doi/10.1145/1518701.1518784},
  urldate = {2023-05-08},
  eventtitle = {{{CHI}} '09: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-246-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/HYHPTMBI/Leshed et al. - 2009 - Visualizing real-time language-based feedback on t.pdf}
}

@inproceedings{liangImplicitCommunicationActionable2019,
  title = {Implicit {{Communication}} of {{Actionable Information}} in {{Human-AI}} Teams},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liang, Claire and Proft, Julia and Andersen, Erik and Knepper, Ross A.},
  date = {2019-05-02},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Glasgow Scotland Uk}},
  doi = {10.1145/3290605.3300325},
  url = {https://dl.acm.org/doi/10.1145/3290605.3300325},
  urldate = {2023-08-15},
  eventtitle = {{{CHI}} '19: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5970-2},
  langid = {english},
  file = {/Users/xinyuech/Zotero/storage/TRACZL8B/Liang et al. - 2019 - Implicit Communication of Actionable Information i.pdf}
}

@online{liaoRethinkingModelEvaluation2023,
  title = {Rethinking {{Model Evaluation}} as {{Narrowing}} the {{Socio-Technical Gap}}},
  author = {Liao, Q. Vera and Xiao, Ziang},
  date = {2023-06-28},
  eprint = {2306.03100},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.03100},
  urldate = {2023-07-31},
  abstract = {The recent development of generative and large language models (LLMs) poses new challenges for model evaluation that the research community and industry are grappling with. While the versatile capabilities of these models ignite excitement, they also inevitably make a leap toward homogenization: powering a wide range of applications with a single, often referred to as ``general-purpose'', model. In this position paper, we argue that model evaluation practices must take on a critical task to cope with the challenges and responsibilities brought by this homogenization: providing valid assessments for whether and how much human needs in downstream use cases can be satisfied by the given model (socio-technical gap). By drawing on lessons from the social sciences, human-computer interaction (HCI), and the interdisciplinary field of explainable AI (XAI), we urge the community to develop evaluation methods based on real-world socio-requirements and embrace diverse evaluation methods with an acknowledgment of trade-offs between realism to socio-requirements and pragmatic costs to conduct the evaluation. By mapping HCI and current NLG evaluation methods, we identify opportunities for evaluation methods for LLMs to narrow the socio-technical gap and pose open questions.},
  pubstate = {preprint},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/33Z3I4A3/Liao and Xiao - 2023 - Rethinking Model Evaluation as Narrowing the Socio.pdf;/Users/xinyuech/Zotero/storage/5MGQ9PE2/2306.html}
}

@inproceedings{liImprovingAutomaticSummarization2023,
  title = {Improving {{Automatic Summarization}} for {{Browsing Longform Spoken Dialog}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Li, Daniel and Chen, Thomas and Zadikian, Alec and Tung, Albert and Chilton, Lydia B},
  date = {2023-04-19},
  pages = {1--20},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581339},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581339},
  urldate = {2023-04-27},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/AGDAF5FA/Li et al. - 2023 - Improving Automatic Summarization for Browsing Lon.pdf}
}

@thesis{limDesigningSupportSensemaking2021,
  type = {phdthesis},
  title = {Designing to Support Sensemaking in Cross-Lingual Computer-Mediated Communication Using NLP Techniques},
  author = {Lim, Hajin},
  date = {2021},
  url = {https://www.proquest.com/docview/2550610767/abstract/5CFA5E0A7FDA45E3PQ/1},
  urldate = {2023-03-16},
  abstract = {Advances in machine translation (MT) and computer-mediated communication (CMC) tools now allow people to collaborate on common problems and interact with others across linguistic and cultural boundaries. However, communicating with linguistically different others, specifically, making sense of the meanings in foreign language messages, is still challenging. Because of the imperfect quality of MT and a lack of cultural and contextual knowledge regarding other cultures, people experience difficulties in extracting informative cues and interpreting the meanings of foreign language messages. Such challenges can diminish the capability of CMC platforms to facilitate communication and information exchange between linguistically and/or culturally diverse communities. The main goal of this dissertation is to explore design solutions that can improve peopleâ€™s sensemaking processes when they encounter foreign language messages. I investigate how people make sense of foreign language messages and identify their challenges and needs in their sensemaking process. Based on my findings, I design and develop sensemaking support tools and evaluate them in the context of social media sites and email communication. Specifically, I use natural language processing (NLP) techniques to generate useful cues for usersâ€™ sensemaking of foreign language messages. First, I design and develop SenseTransâ€“a browser extension that provides NLP-generated information about cultural referents, sentiments, and emotions using emotion/sentiment detection algorithms and entity extraction techniques. Second, I design the Politeness estimator, an email extension that provides politeness assessments of foreign language messages using language-specific classification algorithms in addition to MT outputs. The results from experimental evaluations of these tools provide initial evidence for the value of NLP techniques to improve cross-lingual sensemaking by increasing usersâ€™ confidence and accuracy in interpreting foreign language messages. Future, the deployment study of the tools in a real-world setting points to the need for further investigation of how users understand and utilize the NLP-generated information from the tools in their sensemaking process. The dissertation contributes to our understanding of current challenges in making sense of foreign language messages and the design of future tools for cross-lingual CMC and sensemaking.},
  isbn = {9798516921889},
  langid = {è‹±è¯­},
  pagetotal = {219},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/LM638B9E/Lim - 2021 - Designing to Support Sensemaking in Cross-Lingual .pdf}
}

@article{limHowEmotionalContextual2019,
  title = {How {{Emotional}} and {{Contextual Annotations Involve}} in {{Sensemaking Processes}} of {{Foreign Language Social Media Posts}}},
  author = {Lim, Hajin and Cosley, Dan and Fussell, Susan R.},
  date = {2019-11-07},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  pages = {1--18},
  issn = {2573-0142},
  doi = {10.1145/3359171},
  url = {https://dl.acm.org/doi/10.1145/3359171},
  urldate = {2023-06-02},
  abstract = {The goal of this paper is to investigate how computational tools to annotate communication can support multilingual sense-making on social media. We conducted a field study of SenseTrans, a browser extension that uses sentiment analysis and named entity extraction techniques to annotate Facebook posts with emotional and contextual information. Interviews with 18 participants who used SenseTrans in their Facebook newsfeed for two weeks suggest that the annotations often supported sensemaking by providing additional information they could use to get a quick gist of the posts or to supplement their own interpretations. Participants varied in the extent to which they were motivated to evaluate the credibility of and form mental models of how the annotations were generated, which shaped how they utilized the annotations for sensemaking. Our findings demonstrate the value of designing to support cross-lingual communication and inform design implications for intelligent tools that support communication and sensemaking.},
  issue = {CSCW},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XZM4WN2X/Lim et al. - 2019 - How Emotional and Contextual Annotations Involve i.pdf}
}

@inproceedings{liMultiModalRepairsConversational2020,
  title = {Multi-{{Modal Repairs}} of {{Conversational Breakdowns}} in {{Task-Oriented Dialogs}}},
  booktitle = {Proceedings of the 33rd {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Li, Toby Jia-Jun and Chen, Jingya and Xia, Haijun and Mitchell, Tom M. and Myers, Brad A.},
  date = {2020-10-20},
  series = {{{UIST}} '20},
  pages = {1094--1107},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3379337.3415820},
  url = {https://doi.org/10.1145/3379337.3415820},
  urldate = {2023-03-14},
  abstract = {A major problem in task-oriented conversational agents is the lack of support for the repair of conversational breakdowns. Prior studies have shown that current repair strategies for these kinds of errors are often ineffective due to: (1) the lack of transparency about the state of the system's understanding of the user's utterance; and (2) the system's limited capabilities to understand the user's verbal attempts to repair natural language understanding errors. This paper introduces SOVITE, a new multi-modal speech plus direct manipulation interface that helps users discover, identify the causes of, and recover from conversational breakdowns using the resources of existing mobile app GUIs for grounding. SOVITE displays the system's understanding of user intents using GUI screenshots, allows users to refer to third-party apps and their GUI screens in conversations as inputs for intent disambiguation, and enables users to repair breakdowns using direct manipulation on these screenshots. The results from a remote user study with 10 users using SOVITE in 7 scenarios suggested that SOVITE's approach is usable and effective.},
  isbn = {978-1-4503-7514-6},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/KY5IDJKR/Li et al. - 2020 - Multi-Modal Repairs of Conversational Breakdowns i.pdf}
}

@inproceedings{liSupportingDynamicSituation2013,
  title = {Supporting {{Dynamic Situation Awareness}} in {{Online Group Discussion}}: {{A Visualization Approach}}},
  shorttitle = {Supporting {{Dynamic Situation Awareness}} in {{Online Group Discussion}}},
  booktitle = {2013 46th {{Hawaii International Conference}} on {{System Sciences}}},
  author = {Li, Jia and Zhang, Dongsong and Zhang, Pengzhu},
  date = {2013-01},
  pages = {470--479},
  issn = {1530-1605},
  doi = {10.1109/HICSS.2013.504},
  abstract = {Situation awareness (SA) has been well recognized as a critical yet often elusive foundation for effective group decision-making. The task of identifying and understanding dynamic, evolving discussion situation can be quite challenging, especially when coping with information overload and time pressure. With the wide adoption of collaborative software in support of group collaboration, there has been exponential growth of online group discussion. As a result, the traditional thread-based hierarchical structure and presentation of group messages become ineffective in support of real-time SA, which may affect the process and outcome of group collaboration. To address this important problem, in this study, we propose a novel visualization-based approach to supporting users' SA in online group discussion and decision making. We have also developed a set of new variables to measure SA in online group discussion from three key aspects: discussion snapshot, discussion evolution, and people. The proposed approach was empirically evaluated by using a prototype system and discussion data collected from an online group discussion session. The results show that the proposed approach significantly improves user performance and perception of SA in group discussion. The findings of this study provide significant research contributions and practical implications for the design and use of situation-aware collaborative software.},
  eventtitle = {2013 46th {{Hawaii International Conference}} on {{System Sciences}}},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DRHC42IP/Li et al. - 2013 - Supporting Dynamic Situation Awareness in Online G.pdf;/Users/xinyuech/Zotero/storage/4TA5MHF5/6479890.html}
}

@inproceedings{liuCoArgueFosteringLurkers2023,
  title = {{{CoArgue}} : {{Fostering Lurkers}}â€™ {{Contribution}} to {{Collective Arguments}} in {{Community-based QA Platforms}}},
  shorttitle = {{{CoArgue}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liu, Chengzhong and Zhou, Shixu and Liu, Dingdong and Li, Junze and Huang, Zeyu and Ma, Xiaojuan},
  date = {2023-04-19},
  pages = {1--17},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580932},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580932},
  urldate = {2023-08-16},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {ğŸ§¡ğŸ§¡ğŸ§¡ğŸ§¡},
  file = {/Users/xinyuech/Zotero/storage/7KD9XIBF/Liu et al. - 2023 - CoArgue  Fostering Lurkersâ€™ Contribution to Colle.pdf}
}

@article{liuConsensUsSupportingMultiCriteria2018,
  title = {{{ConsensUs}}: {{Supporting Multi-Criteria Group Decisions}} by {{Visualizing Points}} of {{Disagreement}}},
  shorttitle = {{{ConsensUs}}},
  author = {Liu, Weichen and Xiao, Sijia and Browne, Jacob T. and Yang, Ming and Dow, Steven P.},
  date = {2018-03-31},
  journaltitle = {ACM Transactions on Social Computing},
  shortjournal = {Trans. Soc. Comput.},
  volume = {1},
  number = {1},
  pages = {1--26},
  issn = {2469-7818, 2469-7826},
  doi = {10.1145/3159649},
  url = {https://dl.acm.org/doi/10.1145/3159649},
  urldate = {2023-03-20},
  abstract = {Groups often face difficulty reaching consensus. For complex decisions with multiple criteria, verbal and written discourse alone may impede groups from pinpointing and moving past fundamental disagreements. To help support consensus building, we introduce ConsensUs, a novel visualization tool that highlights disagreement by asking group members to quantify their subjective opinions across multiple criteria. To evaluate this approach, we conducted a between-subjects experiment with 87 participants on a comparative hiring task. The study compared three modes of sensemaking on a group decision: written discourse only, visualization only, and written discourse plus visualization. We confirmed that the visualization helped participants identify disagreements within the group and then measured subsequent changes to their individual opinions. The results show that disagreement highlighting led participants to align their ratings more with the opinions of other group members. While disagreement highlighting led to better score alignment, participants reported a number of reasons for shifting their score, from genuine consensus to appeasement. We discuss further research angles to understand how disagreement highlighting affects social processes and whether it produces objectively better decisions.},
  langid = {english},
  keywords = {notion}
}

@inproceedings{liuWhatItWants2023,
  title = {â€œ{{What It Wants Me To Say}}â€: {{Bridging}} the {{Abstraction Gap Between End-User Programmers}} and {{Code-Generating Large Language Models}}},
  shorttitle = {â€œ{{What It Wants Me To Say}}â€},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
  date = {2023-04-19},
  pages = {1--31},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580817},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580817},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/J29Y9SLH/Liu et al. - 2023 - â€œWhat It Wants Me To Sayâ€ Bridging the Abstractio.pdf}
}

@inproceedings{luReadingQuizMakerHumanNLPCollaborative2023,
  title = {{{ReadingQuizMaker}}: {{A Human-NLP Collaborative System}} That {{Supports Instructors}} to {{Design High-Quality Reading Quiz Questions}}},
  shorttitle = {{{ReadingQuizMaker}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lu, Xinyi and Fan, Simin and Houghton, Jessica and Wang, Lu and Wang, Xu},
  date = {2023-04-19},
  pages = {1--18},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580957},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580957},
  urldate = {2023-08-20},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {ğŸ©·ğŸ©·ğŸ©·},
  file = {/Users/xinyuech/Zotero/storage/8IIGTE79/Lu et al. - 2023 - ReadingQuizMaker A Human-NLP Collaborative System.pdf}
}

@article{mackenzieWisdomDecisionSupport2006,
  title = {Wisdom, Decision Support and Paradigms of Decision Making},
  author = {Mackenzie, Adrian and Pidd, Michael and Rooksby, John and Sommerville, Ian and Warren, Ian and Westcombe, Mark},
  date = {2006-04-01},
  journaltitle = {European Journal of Operational Research},
  shortjournal = {European Journal of Operational Research},
  volume = {170},
  number = {1},
  pages = {156--171},
  issn = {0377-2217},
  doi = {10.1016/j.ejor.2004.07.041},
  url = {https://www.sciencedirect.com/science/article/pii/S0377221704005107},
  urldate = {2023-08-21},
  abstract = {Many decision support tools have been developed over the last 20 years and, in general, they support what Simon termed substantive rationality. However, such tools are rarely suited to helping people tackle wicked problems, for which a form of procedural rationality is better suited. Procedurally rational approaches have appeared in both management science and computer science, examples being the soft OR approach of cognitive mapping and the design rationale based on IBIS. These approaches are reviewed and the development of Wisdom, a procedurally rational decision support process and accompanying tool, is discussed and evaluated.},
  keywords = {/unread,Cognitive mapping,Decision support,notion,Wicked problems},
  file = {/Users/xinyuech/Zotero/storage/4KER6GVK/Mackenzie et al. - 2006 - Wisdom, decision support and paradigms of decision.pdf;/Users/xinyuech/Zotero/storage/W5AZ4PWB/S0377221704005107.html}
}

@inproceedings{majumderInterviewLargescaleModeling2020,
  title = {Interview: {{Large-scale Modeling}} of {{Media Dialog}} with {{Discourse Patterns}} and {{Knowledge Grounding}}},
  shorttitle = {Interview},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Majumder, Bodhisattwa Prasad and Li, Shuyang and Ni, Jianmo and McAuley, Julian},
  date = {2020-11},
  pages = {8129--8141},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.emnlp-main.653},
  url = {https://aclanthology.org/2020.emnlp-main.653},
  urldate = {2023-06-02},
  abstract = {In this work, we perform the first large-scale analysis of discourse in media dialog and its impact on generative modeling of dialog turns, with a focus on interrogative patterns and use of external knowledge. Discourse analysis can help us understand modes of persuasion, entertainment, and information elicitation in such settings, but has been limited to manual review of small corpora. We introduce **Interview**â€”a large-scale (105K conversations) media dialog dataset collected from news interview transcriptsâ€”which allows us to investigate such patterns at scale. We present a dialog model that leverages external knowledge as well as dialog acts via auxiliary losses and demonstrate that our model quantitatively and qualitatively outperforms strong discourse-agnostic baselines for dialog modelingâ€”generating more specific and topical responses in interview-style conversations.},
  eventtitle = {{{EMNLP}} 2020},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/J3S6ZEX7/Majumder et al. - 2020 - Interview Large-scale Modeling of Media Dialog wi.pdf}
}

@article{menneckeEffectsMediaTask2000,
  title = {The {{Effects}} of {{Media}} and {{Task}} on {{User Performance}}: {{A Test}} of the {{Task-Media Fit Hypothesis}}},
  shorttitle = {The {{Effects}} of {{Media}} and {{Task}} on {{User Performance}}},
  author = {Mennecke, Brian E. and Valacich, Joseph S. and Wheeler, Bradley C.},
  date = {2000-11-01},
  journaltitle = {Group Decision and Negotiation},
  shortjournal = {Group Decision and Negotiation},
  volume = {9},
  number = {6},
  pages = {507--529},
  issn = {1572-9907},
  doi = {10.1023/A:1008770106779},
  url = {https://doi.org/10.1023/A:1008770106779},
  urldate = {2023-08-21},
  abstract = {This research was designed to examine the task-media fit hypothesis, an extension to media richness theory that predicts the objective performance of various media for a number of task types. To examine this model, dyads communicating through face-to-face, videophone, telephone (i.e., audio-only communication), or synchronous computer-mediated communication worked in a laboratory experiment to address an intellective or negotiation task. The intellective task required that each dyad member effectively share factual information that each individual independently held. The negotiation task required that each dyad member effectively share preferences based on personal values and reach an agreement. The results of the study provide mixed support for the task-media fit hypothesis. In general, the results for the negotiation task largely supported the theory while the results for the intellective task did not support the theory. These results help to clarify limitations and provide extensions to the theory by demonstrating how variations in task processes and communication media act to mediate task performance. The implications of these results for future research and practice are discussed.},
  langid = {english},
  keywords = {/unread,data and information sharing,dyads,experimental research,group decision making,media richness theory,media selection,task manipulation},
  file = {/Users/xinyuech/Zotero/storage/BFXEVXEI/Mennecke et al. - 2000 - The Effects of Media and Task on User Performance.pdf}
}

@inproceedings{mentisDevelopmentDecisionRationale2009,
  title = {Development of Decision Rationale in Complex Group Decision Making},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Mentis, Helena M. and Bach, Paula M. and Hoffman, Blaine and Rosson, Mary Beth and Carroll, John M.},
  date = {2009-04-04},
  pages = {1341--1350},
  publisher = {{ACM}},
  location = {{Boston MA USA}},
  doi = {10.1145/1518701.1518904},
  url = {https://dl.acm.org/doi/10.1145/1518701.1518904},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '09: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-60558-246-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/TAU75W2D/Mentis et al. - 2009 - Development of decision rationale in complex group.pdf}
}

@inproceedings{mirowskiCoWritingScreenplaysTheatre2023,
  title = {Co-{{Writing Screenplays}} and {{Theatre Scripts}} with {{Language Models}}: {{Evaluation}} by {{Industry Professionals}}},
  shorttitle = {Co-{{Writing Screenplays}} and {{Theatre Scripts}} with {{Language Models}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Mirowski, Piotr and Mathewson, Kory W. and Pittman, Jaylen and Evans, Richard},
  date = {2023-04-19},
  pages = {1--34},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581225},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581225},
  urldate = {2023-04-27},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/T7MTVQQL/Mirowski et al. - 2023 - Co-Writing Screenplays and Theatre Scripts with La.pdf}
}

@online{mishraPromptAidPromptExploration2023,
  title = {{{PromptAid}}: {{Prompt Exploration}}, {{Perturbation}}, {{Testing}} and {{Iteration}} Using {{Visual Analytics}} for {{Large Language Models}}},
  shorttitle = {{{PromptAid}}},
  author = {Mishra, Aditi and Soni, Utkarsh and Arunkumar, Anjana and Huang, Jinbin and Kwon, Bum Chul and Bryan, Chris},
  date = {2023-04-08},
  eprint = {2304.01964},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.01964},
  urldate = {2023-07-31},
  abstract = {Large Language Models (LLMs) have gained widespread popularity due to their ability to perform ad-hoc Natural Language Processing (NLP) tasks with a simple natural language prompt. Part of the appeal for LLMs is their approachability to the general public, including individuals with no prior technical experience in NLP techniques. However, natural language prompts can vary significantly in terms of their linguistic structure, context, and other semantics. Modifying one or more of these aspects can result in significant differences in task performance. Non-expert users may find it challenging to identify the changes needed to improve a prompt, especially when they lack domain-specific knowledge and lack appropriate feedback. To address this challenge, we present PromptAid, a visual analytics system designed to interactively create, refine, and test prompts through exploration, perturbation, testing, and iteration. PromptAid uses multiple, coordinated visualizations which allow users to improve prompts by using the three strategies: keyword perturbations, paraphrasing perturbations, and obtaining the best set of in-context few-shot examples. PromptAid was designed through an iterative prototyping process involving NLP experts and was evaluated through quantitative and qualitative assessments for LLMs. Our findings indicate that PromptAid helps users to iterate over prompt template alterations with less cognitive overhead, generate diverse prompts with help of recommendations, and analyze the performance of the generated prompts while surpassing existing state-of-the-art prompting interfaces in performance.},
  pubstate = {preprint},
  keywords = {/unread,notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/UHTM6TRT/Mishra et al. - 2023 - PromptAid Prompt Exploration, Perturbation, Testi.pdf;/Users/xinyuech/Zotero/storage/XB4PZ9L8/2304.html}
}

@article{montenegroDialogueActTaxonomyVirtual2019,
  title = {A {{Dialogue-Act Taxonomy}} for a {{Virtual Coach Designed}} to {{Improve}} the {{Life}} of {{Elderly}}},
  author = {Montenegro, CÃ©sar and LÃ³pez Zorrilla, Asier and Mikel Olaso, Javier and Santana, Roberto and Justo, Raquel and Lozano, Jose A. and Torres, MarÃ­a InÃ©s},
  date = {2019-09},
  journaltitle = {Multimodal Technologies and Interaction},
  volume = {3},
  number = {3},
  pages = {52},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2414-4088},
  doi = {10.3390/mti3030052},
  url = {https://www.mdpi.com/2414-4088/3/3/52},
  urldate = {2023-04-24},
  abstract = {This paper presents a dialogue act taxonomy designed for the development of a conversational agent for elderly. The main goal of this conversational agent is to improve life quality of the user by means of coaching sessions in different topics. In contrast to other approaches such as task-oriented dialogue systems and chit-chat implementations, the agent should display a pro-active attitude, driving the conversation to reach a number of diverse coaching goals. Therefore, the main characteristic of the introduced dialogue act taxonomy is its capacity for supporting a communication based on the GROW model for coaching. In addition, the taxonomy has a hierarchical structure between the tags and it is multimodal. We use the taxonomy to annotate a Spanish dialogue corpus collected from a group of elder people. We also present a preliminary examination of the annotated corpus and discuss on the multiple possibilities it presents for further research.},
  issue = {3},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/ERBT5QP8/Montenegro et al. - 2019 - A Dialogue-Act Taxonomy for a Virtual Coach Design.pdf}
}

@article{mullerIndividualPerceptionsShared2020,
  title = {Individual Perceptions of Shared Mental Models of Information and Communication Technology ({{ICT}}) and Virtual Team Coordination and Performanceâ€”{{The}} Moderating Role of Flexibility in {{ICT}} Use},
  author = {MÃ¼ller, Rebecca and Antoni, Conny Herbert},
  date = {2020},
  journaltitle = {Group Dynamics: Theory, Research, and Practice},
  volume = {24},
  pages = {186--200},
  publisher = {{Educational Publishing Foundation}},
  location = {{US}},
  issn = {1930-7802},
  doi = {10.1037/gdn0000130},
  abstract = {Coordination and performance of virtual teams depend on the use of information and communication technology (ICT). Team members use many ICTs to collaborate with each other. Research has shown that shared mental models (SMM) improve team coordination and performance. Based on these results, we expect that for virtual teams, ICT SMM are positively related to team coordination and performance. Specifically, the relationship between ICT SMM and coordination is stronger if virtual team members have less flexibility in ICT use. We expect that ICT SMM explain incremental variance of team coordination and performance beyond teamwork and taskwork SMM. One hundred forty-one employees of two IT companies working in 31 virtual teams participated. Results of multilevel model analyses supported the positive relation between individual perceptions of ICT SMM and team coordination and performance, but not for objective ICT SMM. Results of analyses with aggregated team data indicate the same direction. Results showed that individual perceptions of ICT SMM explained incremental variance of team coordination beyond individual perceptions of teamwork and taskwork SMM. The relation between individual perceptions of ICT SMM and team coordination was moderated by flexibility in ICT use. Individual perceptions of ICT SMM seem to be relevant for virtual teamwork. Longitudinal and experimental studies exploring the differential causal effects of SMM subtypes on team coordination and performance seem to be promising. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {notion}
}

@article{murrayInformationProcessingOverload2019,
  title = {Information {{Processing}} and {{Overload}} in {{Group Conversation}}: {{A Graph-Based Prediction Model}}},
  shorttitle = {Information {{Processing}} and {{Overload}} in {{Group Conversation}}},
  author = {Murray, Gabriel},
  date = {2019-09},
  journaltitle = {Multimodal Technologies and Interaction},
  volume = {3},
  number = {3},
  pages = {46},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2414-4088},
  doi = {10.3390/mti3030046},
  url = {https://www.mdpi.com/2414-4088/3/3/46},
  urldate = {2023-03-21},
  abstract = {Based on analyzing verbal and nonverbal features of small group conversations in a task-based scenario, this work focuses on automatic detection of group member perceptions about how well they are making use of available information, and whether they are experiencing information overload. Both the verbal and nonverbal features are derived from graph-based social network representations of the group interaction. For the task of predicting the information use ratings, a predictive model using random forests with verbal and nonverbal features significantly outperforms baselines in which the mean or median values of the training data are predicted, as well as significantly outperforming a linear regression baseline. For the task of predicting information overload ratings, the multimodal random forests model again outperforms all other models, including significant improvement over linear regression and gradient boosting models. However, on that task the best model is not significantly better than the mean and median baselines. For both tasks, we analyze performance using the full multimodal feature set versus using only linguistic features or only turn-taking features. While utilizing the full feature set yields the best performance in terms of mean squared error (MSE), there are no statistically significant differences, and using only linguistic features gives comparable performance. We provide a detailed analysis of the individual features that are most useful for each task. Beyond the immediate prediction tasks, our more general goal is to represent conversational interaction in such a way that yields a small number of features capturing the group interaction in an easily interpretable manner. The proposed approach is relevant to many other group prediction tasks as well, and is distinct from both classical natural language processing (NLP) as well as more current deep learning/artificial neural network approaches.},
  issue = {3},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/G6PG7KUM/Murray - 2019 - Information Processing and Overload in Group Conve.pdf}
}

@inproceedings{nguyenArgvizInteractiveVisualization2013,
  title = {Argviz: {{Interactive Visualization}} of {{Topic Dynamics}} in {{Multi-party Conversations}}},
  shorttitle = {Argviz},
  booktitle = {Proceedings of the 2013 {{NAACL HLT Demonstration Session}}},
  author = {Nguyen, Viet-An and Hu, Yuening and Boyd-Graber, Jordan and Resnik, Philip},
  date = {2013-06},
  pages = {36--39},
  publisher = {{Association for Computational Linguistics}},
  location = {{Atlanta, Georgia}},
  url = {https://aclanthology.org/N13-3009},
  urldate = {2023-03-22},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/7WI752QP/Nguyen et al. - 2013 - Argviz Interactive Visualization of Topic Dynamic.pdf}
}

@article{nussbaumPuttingPiecesTogether2007,
  title = {Putting the Pieces Together: {{Online}} Argumentation Vee Diagrams Enhance Thinking during Discussions},
  shorttitle = {Putting the Pieces Together},
  author = {Nussbaum, E. Michael and Winsor, Denise L. and Aqui, Yvette M. and Poliquin, Anne M.},
  date = {2007-12-01},
  journaltitle = {International Journal of Computer-Supported Collaborative Learning},
  shortjournal = {Computer Supported Learning},
  volume = {2},
  number = {4},
  pages = {479--500},
  issn = {1556-1615},
  doi = {10.1007/s11412-007-9025-1},
  url = {https://doi.org/10.1007/s11412-007-9025-1},
  urldate = {2023-06-02},
  abstract = {We examine the effect of online Argumentation Vee Diagrams (AVDs) on the quality of studentsâ€™ argumentation during asynchronous, online discussions. With AVDs, students develop arguments on both sides of a controversial issue and then develop an integrated, overall final conclusion. In this study, students used AVDs individually before composing discussion notes, and thenâ€”at the end of the discussionâ€”jointly created a group AVD using Wiki technology. Compared to a control group, the experimental intervention was found to significantly enhance the integration of arguments and counterarguments (specifically, compromises) and fostered opinion change. For AVDs to be effective, however, it was found to be necessary to include specific scaffolds on how to evaluate argument strength and/or to provide practice and feedback in using the AVDs.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/DSACAW68/Nussbaum et al. - 2007 - Putting the pieces together Online argumentation .pdf}
}

@inproceedings{oehlModelingGroundingProcesses2010,
  title = {Modeling Grounding Processes in Chat-based CSCL},
  author = {Oehl, Michael and Berwe, Theodor and Wahl, Mathias and Pfister, Hans-Ruediger},
  date = {2010-06-29},
  pages = {3774--3779},
  publisher = {{Association for the Advancement of Computing in Education (AACE)}},
  url = {https://www.learntechlib.org/primary/p/35187/},
  urldate = {2023-03-15},
  abstract = {In the field of computer-supported collaborative learning (CSCL), the grounding theory according to Clark (1996) is widely used to explain how co-construction of knowledge is achieved in learning groups. Communication problems such as incoherence or inadequate coordination are common in simultaneous, text-based chat tools resulting in impaired grounding processes, which again may affect the learning outcomes. Thus collaboration scripts like learning protocols are implemented, increasing the structure of chat discourses in order to reduce communication problems and support grounding...},
  eventtitle = {EdMedia + Innovate Learning},
  isbn = {978-1-880094-81-5},
  langid = {chinese},
  keywords = {notion}
}

@article{okadaEvidenceBasedDialogue2008,
  title = {Evidenceâ€based {{Dialogue Maps}} as a Research Tool to Investigate the Quality of School Pupilsâ€™ Scientific Argumentation},
  author = {Okada, Alexandra and Buckingham Shum, Simon},
  date = {2008-11-01},
  journaltitle = {International Journal of Research \& Method in Education},
  volume = {31},
  number = {3},
  pages = {291--315},
  publisher = {{Routledge}},
  issn = {1743-727X},
  doi = {10.1080/17437270802417184},
  url = {https://doi.org/10.1080/17437270802417184},
  urldate = {2023-08-21},
  abstract = {This pilot study focuses on the potential of Evidenceâ€based Dialogue Mapping as a participatory action research tool to investigate young teenagersâ€™ scientific argumentation. Evidenceâ€based Dialogue Mapping is a technique for representing graphically an argumentative dialogue through Questions, Ideas, Pros, Cons and Data. Our research objective is to better understand the usage of Compendium, a Dialogue Mapping software tool, as both (1) a learning strategy to scaffold school pupilsâ€™ argumentation, and (2) as a method to investigate the quality of their argumentative essays. The participants were a science teacherâ€researcher, a knowledge mapping researcher and 20 pupils, 12â€“13 years old, in a summer science course for â€˜gifted and talentedâ€™ children in the UK. This study draws on multiple data sources: discussion forum, science teacherâ€researchersâ€™ and pupilsâ€™ Dialogue Maps, pupil essays and reflective comments about the uses of mapping for writing. Through qualitative analysis of two case studies, we examine the role of Evidenceâ€based Dialogue Maps as a mediating tool in scientific reasoning: as conceptual bridges for linking and making knowledge intelligible; as support for the linearization task of generating a coherent document outline; as a reflective aid to rethinking reasoning in response to teacher feedback; and as a visual language for making arguments tangible via cartographic conventions.},
  keywords = {/unread,notion,å‚ä¸æ€§è¡ŒåŠ¨ç ”ç©¶,åŸºäºè¯æ®çš„å¯¹è¯å›¾,é’å°‘å¹´çš„ç§‘å­¦è®ºè¯},
  file = {/Users/xinyuech/Zotero/storage/ZEZ59AC4/Okada and Buckingham Shum - 2008 - Evidenceâ€based Dialogue Maps as a research tool to.pdf}
}

@article{osinskiSuccessfulKnowledgeIntegration2019,
  title = {Towards {{Successful Knowledge Integration}} in {{Online Collaboration}}: {{An Experiment}} on the {{Role}} of {{Meta-Knowledge}}},
  shorttitle = {Towards {{Successful Knowledge Integration}} in {{Online Collaboration}}},
  author = {Osinski, Meike and Rummel, Nikol},
  date = {2019-11-07},
  journaltitle = {ACM äººæœºäº¤äº’è®ºæ–‡é›†},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  pages = {31:1--31:17},
  doi = {10.1145/3359133},
  url = {https://doi.org/10.1145/3359133},
  urldate = {2023-03-15},
  abstract = {æˆåŠŸçš„çŸ¥è¯†æ•´åˆï¼Œå³æœªå…±äº«ä¿¡æ¯çš„ç³»ç»Ÿç»¼åˆï¼Œæ˜¯æˆåŠŸçš„å…³é”®ï¼Œä½†åŒæ—¶å¯¹äºå…·æœ‰åˆ†å¸ƒå¼çŸ¥è¯†çš„åœ¨çº¿åä½œå›¢é˜Ÿæ¥è¯´ä¹Ÿæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„å†’é™©ã€‚ä¾‹å¦‚ï¼Œå…·æœ‰å¼‚è´¨çŸ¥è¯†çš„å›¢é˜Ÿé€šå¸¸å¯¹è°çŸ¥é“ä»€ä¹ˆåªæœ‰æ¨¡ç³Šç”šè‡³é”™è¯¯çš„æƒ³æ³•ã€‚å¦‚æœåä½œä¼™ä¼´å½¼æ­¤ä¸è®¤è¯†å¹¶ä¸”ä»…åœ¨çº¿äº¤æµï¼Œåˆ™æƒ…å†µä¼šæ›´åŠ å¤æ‚ã€‚å…ˆå‰çš„ç ”ç©¶å‘ç°å…ƒçŸ¥è¯†ï¼Œå³å…³äºè‡ªå·±å’Œåˆä½œä¼™ä¼´çŸ¥è¯†é¢†åŸŸçš„çŸ¥è¯†ï¼Œæ˜¯ä¸€ç§å¾ˆæœ‰å‰é€”ä½†å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶çš„ä¿ƒè¿›çŸ¥è¯†æ•´åˆçš„æ–¹æ³•ã€‚é€šè¿‡æˆ‘ä»¬çš„å®éªŒç ”ç©¶ï¼Œæˆ‘ä»¬æ—¨åœ¨è§£å†³å…³äºå…ƒçŸ¥è¯†åœ¨åŸºäºç½‘ç»œçš„åä½œä¸­çš„ä½œç”¨çš„ç ”ç©¶çš„è¿«åˆ‡éœ€è¦ã€‚æˆ‘ä»¬â€œæ¨¡æ‹Ÿâ€ é€šè¿‡å°†ç‰¹å®šä¿¡æ¯åˆ†é…ç»™åœ¨éšè—é…ç½®æ–‡ä»¶ä»»åŠ¡ä¸­è¿›è¡ŒåŒäººåä½œçš„å­¦ç”Ÿï¼Œå…·æœ‰å¼‚è´¨çŸ¥è¯†çš„åˆä½œä¼™ä¼´ä¹‹é—´åŸºäºèŠå¤©çš„åä½œã€‚ä¸ºäº†ä¸ºè¿™é¡¹ä»»åŠ¡æ‰¾åˆ°æ­£ç¡®çš„è”åˆè§£å†³æ–¹æ¡ˆï¼Œåˆä½œä¼™ä¼´å¿…é¡»æ±‡é›†ä»–ä»¬å…±äº«çš„ï¼Œä½†æ›´é‡è¦çš„æ˜¯ä»–ä»¬æœªå…±äº«çš„ä¿¡æ¯ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†ä¸¤ç§æƒ…å†µï¼šåœ¨å®éªŒæ¡ä»¶ä¸‹ï¼Œé€šè¿‡å‘åˆä½œä¼™ä¼´æä¾›å½¼æ­¤è§’è‰²çš„è‡ªæˆ‘ä»‹ç»æ¥ä¿ƒè¿›å…ƒçŸ¥è¯†ï¼Œè¿™æŒ‡å‘ä»–ä»¬ç‹¬ç‰¹çš„çŸ¥è¯†é¢†åŸŸï¼Œè€Œæ§åˆ¶æ¡ä»¶ä¸‹çš„å‚ä¸è€…æ²¡æœ‰æ”¶åˆ°æ­¤ä¿¡æ¯ã€‚ç»“æœè¡¨æ˜å…ƒçŸ¥è¯†æ“ä½œå¯¹åä½œçš„ä¸¤ä¸ªå…³é”®å› ç´ æœ‰ç§¯æå½±å“ï¼šçŸ¥è¯†æ•´åˆå’Œäº¤äº’è®°å¿†ç³»ç»Ÿ (TMS) çš„æ„å»ºã€‚},
  issue = {CSCW},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/XIFJ3WDB/Osinski and Rummel - 2019 - Towards Successful Knowledge Integration in Online.pdf}
}

@book{paulusOxfordHandbookGroup2019,
  title = {The {{Oxford Handbook}} of {{Group Creativity}} and {{Innovation}}},
  author = {Paulus, Paul B. and Nijstad, Bernard A.},
  date = {2019-04-30},
  eprint = {BNqUDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Oxford University Press}},
  abstract = {Although creativity is often considered an individual ability or activity, innovation in teams and organizations involves collaboration of people with diverse perspectives, knowledge, and skills. The effective development of collaborative innovations and solutions to problems is critical to the success of teams and organizations, but research has also demonstrated many factors which tend to limit the effectiveness of collaborative innovation of groups and teams. This volume highlights recent theoretical, empirical, and practical developments that provide a solid basis for the practice of collaborative innovation and future research. It draws from a broad range of research perspectives including cognition, social influence, groups, teams, creativity, communication, networks, information systems, organizational psychology, engineering, computer science, and the arts. This volume is an important source of information for students, scholars, practitioners, and others interested in understanding the complexity of the group creative process and tapping the creative potential of groups and teams.},
  isbn = {978-0-19-094253-3},
  langid = {english},
  pagetotal = {401},
  keywords = {notion}
}

@inproceedings{pavelVideoDigestsBrowsable2014,
  title = {Video Digests: A Browsable, Skimmable Format for Informational Lecture Videos},
  shorttitle = {Video Digests},
  booktitle = {Proceedings of the 27th Annual {{ACM}} Symposium on {{User}} Interface Software and Technology},
  author = {Pavel, Amy and Reed, Colorado and Hartmann, BjÃ¶rn and Agrawala, Maneesh},
  date = {2014-10-05},
  pages = {573--582},
  publisher = {{ACM}},
  location = {{Honolulu Hawaii USA}},
  doi = {10.1145/2642918.2647400},
  url = {https://dl.acm.org/doi/10.1145/2642918.2647400},
  urldate = {2023-08-16},
  abstract = {Increasingly, authors are publishing long informational talks, lectures, and distance-learning videos online. However, it is difficult to browse and skim the content of such videos using current timeline-based video players. Video digests are a new format for informational videos that afford browsing and skimming by segmenting videos into a chapter/section structure and providing short text summaries and thumbnails for each section. Viewers can navigate by reading the summaries and clicking on sections to access the corresponding point in the video. We present a set of tools to help authors create such digests using transcript-based interactions. With our tools, authors can manually create a video digest from scratch, or they can automatically generate a digest by applying a combination of algorithmic and crowdsourcing techniques and then manually refine it as needed. Feedback from first-time users suggests that our transcript-based authoring tools and automated techniques greatly facilitate video digest creation. In an evaluative crowdsourced study we find that given a short viewing time, video digests support browsing and skimming better than timeline-based or transcript-based video players.},
  eventtitle = {{{UIST}} '14: {{The}} 27th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-3069-5},
  langid = {english},
  keywords = {ğŸ’›ğŸ’›},
  file = {/Users/xinyuech/Zotero/storage/GQQCEX5Z/Pavel et al. - 2014 - Video digests a browsable, skimmable format for i.pdf}
}

@inproceedings{pengSlideGestaltAutomatic2023,
  title = {Slide {{Gestalt}}: {{Automatic Structure Extraction}} in {{Slide Decks}} for {{Non-Visual Access}}},
  shorttitle = {Slide {{Gestalt}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Peng, Yi-Hao and Chi, Peggy and Kannan, Anjuli and Morris, Meredith Ringel and Essa, Irfan},
  date = {2023-04-19},
  pages = {1--14},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580921},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580921},
  urldate = {2023-05-03},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/SKSKMFL4/Peng et al. - 2023 - Slide Gestalt Automatic Structure Extraction in S.pdf}
}

@article{piRelationOpennessCreativity2022,
  title = {The Relation between Openness and Creativity Is Moderated by Attention to Peersâ€™ Ideas in Electronic Brainstorming},
  author = {Pi, Zhongling and Yang, Jiumin and Hu, Weiping and Hong, Jianzhong},
  date = {2022-02-04},
  journaltitle = {Interactive Learning Environments},
  volume = {30},
  number = {2},
  pages = {344--352},
  publisher = {{Routledge}},
  issn = {1049-4820},
  doi = {10.1080/10494820.2019.1655458},
  url = {https://doi.org/10.1080/10494820.2019.1655458},
  urldate = {2023-03-15},
  abstract = {An emerging body of research has focused on studentsâ€™ creativity in group contexts, with the assumption that students could be inspired by peersâ€™ ideas. Although studentsâ€™ openness and attention to peersâ€™ ideas are claimed to play important roles in their creativity in group settings, there is little empirical research that tests this assumption. This study examined the moderating effect of attention to peersâ€™ ideas in the relation between openness and creativity in electronic brainstorming. Participants were 91 undergraduate students who took about 10 min to complete a creative idea generation task during electronic brainstorming. Regression analyses found that students who were characterized by high openness were more creative, but only when they showed more attention to peersâ€™ ideas. This suggests that electronic brainstorming can be useful for enhancing the creativity of some students.},
  keywords = {notion}
}

@inproceedings{reitmaierSituatingAutomaticSpeech2023,
  title = {Situating {{Automatic Speech Recognition Development}} within {{Communities}} of {{Under-heard Language Speakers}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Reitmaier, Thomas and Wallington, Electra and Klejch, OndÅ™ej and Markl, Nina and Lam-Yee-Mui, LÃ©a-Marie and Pearson, Jennifer and Jones, Matt and Bell, Peter and Robinson, Simon},
  date = {2023-04-19},
  pages = {1--17},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581385},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581385},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/LJA7Q8KR/Reitmaier et al. - 2023 - Situating Automatic Speech Recognition Development.pdf}
}

@inproceedings{rongUnderstandingPersonalData2023,
  title = {Understanding {{Personal Data Tracking}} and {{Sensemaking Practices}} for {{Self-Directed Learning}} in {{Non-classroom}} and {{Non-computer-based Contexts}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Rong, Ethan Z. and Zhou, Mo Morgana and Gao, Ge and Lu, Zhicong},
  date = {2023-04-19},
  pages = {1--16},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581364},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581364},
  urldate = {2023-05-03},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/YKUJ9ADT/Rong et al. - 2023 - Understanding Personal Data Tracking and Sensemaki.pdf}
}

@inproceedings{sarkarKGCRuSERecurrentWalks2022,
  title = {{{KG-CRuSE}}: {{Recurrent Walks}} over {{Knowledge Graph}} for {{Explainable Conversation Reasoning}} Using {{Semantic Embeddings}}},
  shorttitle = {{{KG-CRuSE}}},
  booktitle = {Proceedings of the 4th {{Workshop}} on {{NLP}} for {{Conversational AI}}},
  author = {Sarkar, Rajdeep and Arcan, Mihael and McCrae, John},
  date = {2022},
  pages = {98--107},
  publisher = {{Association for Computational Linguistics}},
  location = {{Dublin, Ireland}},
  doi = {10.18653/v1/2022.nlp4convai-1.9},
  url = {https://aclanthology.org/2022.nlp4convai-1.9},
  urldate = {2023-05-11},
  abstract = {Knowledge-grounded dialogue systems utilise external knowledge such as knowledge graphs to generate informative and appropriate responses. A crucial challenge of such systems is to select facts from a knowledge graph pertinent to the dialogue context for response generation. This fact selection can be formulated as path traversal over a knowledge graph conditioned on the dialogue context. Such paths can originate from facts mentioned in the dialogue history and terminate at the facts to be mentioned in the response. These walks, in turn, provide an explanation of the flow of the conversation. This work proposes KG-CRUSE, a simple, yet effective LSTM based decoder that utilises the semantic information in the dialogue history and the knowledge graph elements to generate such paths for effective conversation explanation. Extensive evaluations showed that our model outperforms the stateof-the-art models on the OpenDialKG dataset on multiple metrics.},
  eventtitle = {Proceedings of the 4th {{Workshop}} on {{NLP}} for {{Conversational AI}}},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/4AV7WHWJ/Sarkar et al. - 2022 - KG-CRuSE Recurrent Walks over Knowledge Graph for.pdf}
}

@inproceedings{sasakiReachingFinalConsensus2020,
  title = {Reaching a {{Final Consensus}} in a {{Discussion}}: The {{Impact}} of {{Real-time Intention Expression Related}} to {{Categories}}},
  shorttitle = {Reaching a {{Final Consensus}} in a {{Discussion}}},
  booktitle = {2020 13th {{International Conference}} on {{Human System Interaction}} ({{HSI}})},
  author = {Sasaki, Chihiro and Oshima, Chika and Kajihara, Shin and Nakayama, Koichi},
  date = {2020-06},
  pages = {106--111},
  issn = {2158-2254},
  doi = {10.1109/HSI49210.2020.9142630},
  abstract = {A facilitator is effective for ensuring smooth and appropriate decision-making in group discussions. In this study, we developed the â€œDiscussion Board Systemâ€ for the purpose of reproducing a part of the facilitator's function and grasping the intentions of discussion participants in real time. Each discussion participant had their own terminal on which the application was installed. The participants could show the agreement or disagreement with each keyword extracted from the other participants' utterances by moving the keywords to item boxes on their individual screens. The movements of the keywords were not visible to other participants before the discussion was over, thus each participant's screen could be considered a â€œsemi-personal space.â€ In an experiment using the system, the progress and decisions of all participants were compared with each individual participant's intentions, as shown by their moving of keywords. A final decision could include the intentions of a â€œsilent denier,â€ which is difficult to elicit in consideration of human relationships during typical discussions. Moreover, even though the screens were not shared among participants, the moving of each keyword to the item box could be regarded as a simple approval action of the participant's opinion. Thus, one of the positive effects of a facilitator, â€œfostering a sense of satisfactionâ€ among participants, may be realized by the system.},
  eventtitle = {2020 13th {{International Conference}} on {{Human System Interaction}} ({{HSI}})},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/URDKI9DM/Sasaki et al. - 2020 - Reaching a Final Consensus in a Discussion the Im.pdf}
}

@inproceedings{satoGroupnamicsDesigningInterface2023,
  title = {Groupnamics: {{Designing}} an {{Interface}} for {{Overviewing}} and {{Managing Parallel Group Discussions}} in an {{Online Classroom}}},
  shorttitle = {Groupnamics},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Sato, Arissa J. and Sramek, Zefan and Yatani, Koji},
  date = {2023-04-19},
  pages = {1--18},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581322},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581322},
  urldate = {2023-08-16},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {ğŸ§¡ğŸ§¡ğŸ§¡ğŸ§¡},
  file = {/Users/xinyuech/Zotero/storage/GGHVPNHS/Sato et al. - 2023 - Groupnamics Designing an Interface for Overviewin.pdf}
}

@article{schelbleLetThinkTogether2022,
  title = {Let's {{Think Together}}! {{Assessing Shared Mental Models}}, {{Performance}}, and {{Trust}} in {{Human-Agent Teams}}},
  author = {Schelble, Beau G. and Flathmann, Christopher and McNeese, Nathan J. and Freeman, Guo and Mallick, Rohit},
  date = {2022-01-14},
  journaltitle = {ACM äººæœºäº¤äº’ä¼šè®®å½•},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {13:1--13:29},
  doi = {10.1145/3492832},
  url = {https://doi.org/10.1145/3492832},
  urldate = {2023-03-15},
  abstract = {è®¡ç®—æœºæ”¯æŒçš„ååŒå·¥ä½œä¸­çš„ä¸€é¡¹æ–°å…´ç ”ç©¶è®®ç¨‹ä¾§é‡äºäººç±»ä»£ç†å›¢é˜Ÿå’Œäººå·¥æ™ºèƒ½ä»£ç†åœ¨ç°ä»£å›¢é˜Ÿåˆä½œä¸­çš„ä½œç”¨å’Œå½±å“ã€‚ç‰¹åˆ«æ˜¯ï¼Œä¸€ä¸ªæœªè¢«å……åˆ†ç ”ç©¶çš„å…³é”®é—®é¢˜å›´ç»•ç€äººç±»ä»£ç†å›¢é˜Ÿä¸­å›¢é˜Ÿè®¤çŸ¥çš„æ„å»ºã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ä¸äººç±»å›¢é˜Ÿç›¸æ¯”ï¼Œäººç±»ä»£ç†å›¢é˜Ÿä¸­å›¢é˜ŸåŠ¨åŠ›å­¦çš„ç‹¬ç‰¹æ€§ï¼Œä»¥åŠå›¢é˜Ÿç»„æˆå¯¹æ„ŸçŸ¥å›¢é˜Ÿè®¤çŸ¥ã€å›¢é˜Ÿç»©æ•ˆå’Œä¿¡ä»»çš„å½±å“ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä¸€ç§æ··åˆ\hspace{0pt}\hspace{0pt}æ–¹æ³•ï¼ŒåŒ…æ‹¬ä¸‰ç§å›¢é˜Ÿç»„æˆæ¡ä»¶ï¼ˆå…¨äººç±»ã€äººç±»-äººç±»ä»£ç†ã€äººç±»-ä»£ç†-ä»£ç†ï¼‰ï¼Œå®Œæˆäº†å›¢é˜Ÿæ¨¡æ‹Ÿ NeoCITIES å¹¶å®Œæˆäº†å…±äº«å¿ƒæ™ºæ¨¡å‹ã€ä¿¡ä»»å’Œæ„ŸçŸ¥æµ‹é‡ã€‚ç»“æœå‘ç°ï¼Œäººç±»ä»£ç†å›¢é˜Ÿåœ¨å›¢é˜Ÿè®¤çŸ¥çš„è¿­ä»£å‘å±•ä»¥åŠæ²Ÿé€šå¯¹åŠ é€Ÿå…¶å‘å±•çš„é‡è¦æ€§æ–¹é¢ä¸äººç±»å›¢é˜Ÿç›¸ä¼¼ï¼›ç„¶è€Œï¼Œäººç±»ä»£ç†å›¢é˜Ÿçš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œä¸è¡ŒåŠ¨ç›¸å…³çš„æ²Ÿé€šå’Œæ˜ç¡®çš„å…±åŒç›®æ ‡æœ‰åˆ©äºå‘å±•å›¢é˜Ÿè®¤çŸ¥ã€‚æ­¤å¤–ï¼Œå½“åªä¸ä»£ç†äººè€Œä¸ä¸å…¶ä»–äººåˆä½œæ—¶ï¼Œäººç±»ä»£ç†å›¢é˜Ÿå¯¹ä»£ç†é˜Ÿå‹çš„ä¿¡ä»»ç¨‹åº¦è¾ƒä½ï¼Œä¸äººç±»å›¢é˜Ÿç›¸æ¯”ï¼Œä¸ä»£ç†é˜Ÿå‹çš„å›¢é˜Ÿè®¤çŸ¥ç¨‹åº¦è¾ƒä½ï¼Œå¹¶ä¸”ä¸çº¯äººç±»å›¢é˜Ÿç›¸æ¯”ï¼Œå›¢é˜Ÿå¿ƒæ™ºæ¨¡å‹ç›¸ä¼¼æ€§æ°´å¹³æ˜æ˜¾ä¸ä¸€è‡´ã€‚è¿™é¡¹ç ”ç©¶åœ¨ä¸‰ä¸ªé‡è¦æ–¹é¢ä¸ºè®¡ç®—æœºæ”¯æŒçš„ååŒå·¥ä½œåšå‡ºäº†è´¡çŒ®ï¼š1) é€šè¿‡é˜æ˜åœ¨åä½œç¯å¢ƒä¸­æ“ä½œçš„äººä¸ä»£ç†ä¹‹é—´çš„å…³ç³»ï¼Œæ¨è¿›ç°æœ‰çš„äººç±»ä»£ç†å›¢é˜Ÿç ”ç©¶ï¼Œ2) è¡¨å¾äººç±»ä»£ç†å›¢é˜Ÿä¸­çš„å›¢é˜Ÿè®¤çŸ¥å‘å±•ï¼›3ï¼‰æ¨è¿›ç°å®ä¸–ç•Œçš„è®¾è®¡å»ºè®®ï¼Œä»¥ä¿ƒè¿›ä»¥äººä¸ºæœ¬çš„å›¢é˜Ÿä»£ç†å¹¶æ›´å¥½åœ°æ•´åˆä¸¤è€…ã€‚},
  issue = {GROUP},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/U7V84X7U/Schelble et al. - 2022 - Let's Think Together! Assessing Shared Mental Mode.pdf}
}

@article{schmittCognitiveOverloadDigital2021,
  title = {From Cognitive Overload to Digital Detox: {{Psychological}} Implications of Telework during the {{COVID-19}} Pandemic},
  shorttitle = {From Cognitive Overload to Digital Detox},
  author = {Schmitt, Josephine B. and Breuer, Johannes and Wulf, Tim},
  date = {2021-11-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {124},
  pages = {106899},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106899},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563221002223},
  urldate = {2023-03-21},
  abstract = {For most people, telework during the COVID-19 pandemic necessitates the increased use of digital tools. Although working from home can enhance flexibility, it comes with various psychological challenges, all of which can be substantially exacerbated for people during the COVID-19 pandemic. The increased need to use digital tools can create cognitive overload that may negatively impact work productivity and well-being. The idea of digital detox has received increasing attention in the last few years as a means for recovering from stress caused by the use of digital media. This paper presents an analysis of the relationships between the use of digital work tools, the feeling of cognitive overload, digital detox measures, perceived work performance, and well-being. Results from an online survey (N~=~403) conducted during the period of strict lockdown measures in Germany in April and May 2020 indicate that the relationship between the use of text-based tools and well-being, but not perceived job performance, is mediated by cognitive overload. These relationships were not found for the use of videoconferencing tools. However, for users of these tools, the number of digital detox measures moderates the relationship between cognitive overload and the perception of work demands.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/3MD2P6GU/Schmitt et al. - 2021 - From cognitive overload to digital detox Psycholo.pdf;/Users/xinyuech/Zotero/storage/Z9HBHB3I/S0747563221002223.html}
}

@article{schnaubertGroupAwarenessRegulation2022,
  title = {Group Awareness and Regulation in Computer-Supported Collaborative Learning},
  author = {Schnaubert, Lenka and Bodemer, Daniel},
  date = {2022-03-01},
  journaltitle = {International Journal of Computer-Supported Collaborative Learning},
  shortjournal = {Intern. J. Comput.-Support. Collab. Learn},
  volume = {17},
  number = {1},
  pages = {11--38},
  issn = {1556-1615},
  doi = {10.1007/s11412-022-09361-1},
  url = {https://doi.org/10.1007/s11412-022-09361-1},
  urldate = {2022-11-02},
  abstract = {Group awareness is of critical relevance for collaborative learning and interaction and is thus often referred to in CSCL research. However, the concept is only vaguely defined as some kind of understanding or perception of characteristics of learning partners or the collaborating group. Most CSCL research activities concerned with group awareness aim at modifying learners' awareness using so-called group awareness tools. However, there are much less attempts to measure group awareness and to conceptualize its formation. Thus, building on existing group awareness research, this article derives a conceptualization with six defining aspects of group awareness: (1) group awareness is cognitive, (2) group awareness is conscious, (3) group awareness is current, (4) group awareness is individual, (5) group awareness is social, and (6) group awareness is perceived as valid. Additionally, while it is often assumed that group awareness builds on self-regulatory skills, its role in regulating behavior and cognition within a social context is seldom explored. Thus, this article aims at defining and analyzing the concept of group awareness, specifying its relation to regulatory processes, and sketching possible research paths whilst building on, complementing, and informing tool-driven research.},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/LKHMB67E/Schnaubert and Bodemer - 2022 - Group awareness and regulation in computer-support.pdf}
}

@inproceedings{schumannSupportingInitialTrust2012,
  title = {Supporting Initial Trust in Distributed Idea Generation and Idea Evaluation},
  booktitle = {Proceedings of the 2012 {{ACM International Conference}} on {{Supporting Group Work}}},
  author = {Schumann, Jana and Shih, Patrick C. and Redmiles, David F. and Horton, Graham},
  date = {2012-10-27},
  series = {{{GROUP}} '12},
  pages = {199--208},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2389176.2389207},
  url = {https://doi.org/10.1145/2389176.2389207},
  urldate = {2023-03-14},
  abstract = {å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼Œåˆ†å¸ƒå¼åä½œå›¢é˜Ÿå†…éƒ¨çš„å¤šæ ·æ€§å¯ä»¥å¸¦æ¥åˆ›æ–°ï¼Œä½†å¿…é¡»å­˜åœ¨ä¿¡ä»»æ‰èƒ½å…¬å¼€è¡¨è¾¾åˆ›æ–°æ€æƒ³å¹¶å»ºç«‹æ€æƒ³å¯ä¿¡åº¦ã€‚æœ€åˆçš„ä¿¡ä»»å¯¹äºå›¢é˜Ÿæˆå‘˜ä»æœªé¢å¯¹é¢å¹¶ä¸”åªæœ‰éå¸¸æœ‰é™çš„æ—¶é—´æ¥å®Œæˆä»»åŠ¡çš„åˆ†å¸ƒå¼å›¢é˜Ÿè‡³å…³é‡è¦ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç¡®å®šäº†è§£å…¶ä»–å›¢é˜Ÿæˆå‘˜çš„å…·ä½“ä¿¡æ¯æ˜¯å¦å¯ä»¥å¢å¼ºæœ€åˆçš„ä¿¡ä»»å¹¶æé«˜åˆ›æ„ç”Ÿæˆå’Œåˆ›æ„è¯„ä¼°ä¼šè®®çš„ç”Ÿäº§åŠ›å’Œæ»¡æ„åº¦ã€‚åœ¨ä¸€é¡¹å®éªŒä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜é€šè¿‡å‘ˆç°ç›¸å…³ä¿¡æ¯å…ƒç´ ï¼ˆä¾‹å¦‚é¢†åŸŸä¸“ä¸šçŸ¥è¯†å’Œä¸ªäººçˆ±å¥½ï¼‰å¯ä»¥æˆåŠŸå¢å¼ºè®¤çŸ¥å’Œæƒ…æ„Ÿä¿¡ä»»ï¼Œå¹¶ä¸”å¯ä»¥å¯¹æƒ³æ³•ç”Ÿæˆä¼šè®®ä¸­æƒ³æ³•çš„è´¨é‡å’Œæ•°é‡ä»¥åŠå‚ä¸è€…å¯¹æƒ³æ³•è¯„ä¼°ä¼šè®®ä¸­çš„è¯„çº§ç»“æœçš„æ»¡æ„åº¦äº§ç”Ÿç§¯æå½±å“ã€‚ç„¶è€Œï¼Œæ¥æ”¶ä¸ªäººä¿¡æ¯çš„å‚ä¸è€…å¸¸å¸¸å°†å…¶è¯¯è§£ä¸ºä¸“ä¸šèƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜æè¿°äº†åœ¨æƒ³æ³•ç”Ÿæˆä¼šè®®ä¸­è§‚å¯Ÿåˆ°çš„æ€§åˆ«å·®å¼‚ï¼Œå¹¶è®¨è®ºå¦‚ä½•æ›´å¥½åœ°è®¾è®¡æœªæ¥ç³»ç»Ÿä»¥æ”¯æŒæƒ³æ³•ç”Ÿæˆå’Œæƒ³æ³•è¯„ä¼°æ´»åŠ¨ã€‚},
  isbn = {978-1-4503-1486-2},
  keywords = {notion}
}

@inproceedings{shinChatbotsFacilitatingConsensusBuilding2022,
  title = {Chatbots {{Facilitating Consensus-Building}} in {{Asynchronous Co-Design}}},
  booktitle = {The 35th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Shin, Joongi and Hedderich, Michael A. and Lucero, AndrÃ©S and Oulasvirta, Antti},
  date = {2022-10-29},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Bend OR USA}},
  doi = {10.1145/3526113.3545671},
  url = {https://dl.acm.org/doi/10.1145/3526113.3545671},
  urldate = {2023-03-21},
  eventtitle = {{{UIST}} '22: {{The}} 35th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-9320-1},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/RKLGG7CJ/Shin et al. - 2022 - Chatbots Facilitating Consensus-Building in Asynch.pdf}
}

@article{shinIntegratingAIHumanHuman2023,
  title = {Integrating {{AI}} in {{Human-Human Collaborative Ideation}}},
  author = {Shin, Joongi and Koch, Janin and Lucero, AndrÃ©s and Dalsgaard, Peter and Mackay, Wendy E},
  date = {2023},
  abstract = {People can generate more innovative ideas when they collaborate with one another, collectively exploring ideas and exchanging viewpoints. Advancements in artificial intelligence have opened up new opportunities in peopleâ€™s creative activities where individual users ideate with diverse forms of AI. For instance, AI agents and intelligent tools have been designed as ideation partners that provide inspiration, suggest ideation methods, or generate alternative ideas. However, what AI can bring to collaborative ideation among a group of users has not been fully understood. Compared to ideating with individuals, ideating with multiple users would require understanding usersâ€™ social interaction, transforming individual efforts into a group effort, andâ€”in the endâ€”making users satisfied that they collaborated with other group members. This workshop aims to bring together a community of researchers and practitioners to explore the integration of AI in human-human collaborative ideation. The exploration will center around identifying the potential roles of AI as well as the process and form of collaborative ideation, considering what users want to do with AI or humans.},
  langid = {english},
  keywords = {ğŸ’›ğŸ’›,notion},
  file = {/Users/xinyuech/Zotero/storage/DEEL9547/Shin et al. - 2023 - Integrating AI in Human-Human Collaborative Ideati.pdf}
}

@inproceedings{shinIntroBotExploringUse2023,
  title = {{{IntroBot}}: {{Exploring}} the {{Use}} of {{Chatbot-assisted Familiarization}} in {{Online Collaborative Groups}}},
  shorttitle = {{{IntroBot}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Shin, Donghoon and Kim, Soomin and Shang, Ruoxi and Lee, Joonhwan and Hsieh, Gary},
  date = {2023-04-19},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580930},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580930},
  urldate = {2023-08-16},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {/unread,ğŸ§¡ğŸ§¡ğŸ§¡ğŸ§¡},
  file = {/Users/xinyuech/Zotero/storage/9HK9M8BT/Shin et al. - 2023 - IntroBot Exploring the Use of Chatbot-assisted Fa.pdf}
}

@article{shumHypermediaSupportArgumentation,
  title = {5 {{Hypermedia Support}} for {{Argumentation-}}},
  author = {Shum, S J Buckingham and Selvin, A M and Sierhuis, M and Conklin, J and Haley, C B and Nuseibeh, B},
  abstract = {Having developed, used and evaluated some of the early IBISbased approaches to design rationale (DR) such as gIBIS and QOC in the late 1980s/mid-1990s, we describe the subsequent evolution of the argumentation-based paradigm through software support, and perspectives drawn from modeling and meeting facilitation. Particular attention is given to the challenge of negotiating the overheads of capturing this form of rationale. Our approach has maintained a strong emphasis on keeping the representational scheme as simple as possible to enable real time meeting mediation and capture, attending explicitly to the skills required to use the approach well, particularly for the sort of participatory, multistakeholder requirements analysis demanded by many design problems. However, we can then specialize the notation and the way in which the tool is used in the service of specific methodologies, supported by a customizable hypermedia environment, and interoperable with other software tools. After presenting this approach, called Compendium, we present examples to illustrate the capabilities for support security argumentation in requirements engineering, template driven modeling for document generation, and IBIS-based indexing of and navigation around video records of meetings.},
  langid = {english},
  keywords = {/unread,notion},
  file = {/Users/xinyuech/Zotero/storage/CCI8XHIW/Shum et al. - 5 Hypermedia Support for Argumentation-.pdf}
}

@inproceedings{siangliulueCollaborativeIdeationScale2015,
  title = {Toward {{Collaborative Ideation}} at {{Scale}}: {{Leveraging Ideas}} from {{Others}} to {{Generate More Creative}} and {{Diverse Ideas}}},
  shorttitle = {Toward {{Collaborative Ideation}} at {{Scale}}},
  booktitle = {Proceedings of the 18th {{ACM Conference}} on {{Computer Supported Cooperative Work}} \& {{Social Computing}}},
  author = {Siangliulue, Pao and Arnold, Kenneth C. and Gajos, Krzysztof Z. and Dow, Steven P.},
  date = {2015-02-28},
  pages = {937--945},
  publisher = {{ACM}},
  location = {{Vancouver BC Canada}},
  doi = {10.1145/2675133.2675239},
  url = {https://dl.acm.org/doi/10.1145/2675133.2675239},
  urldate = {2023-03-16},
  abstract = {A growing number of large collaborative idea generation platforms promise that by generating ideas together, people can create better ideas than any would have alone. But how might these platforms best leverage the number and diversity of contributors to help each contributor generate even better ideas? Prior research suggests that seeing particularly creative or diverse ideas from others can inspire you, but few scalable mechanisms exist to assess diversity. We contribute a new scalable crowd-powered method for evaluating the diversity of sets of ideas. The method relies on similarity comparisons (is idea A more similar to B or C?) generated by non-experts to create an abstract spatial idea map. Our validation study reveals that human raters agree with the estimates of dissimilarity derived from our idea map as much or more than they agree with each other. People seeing the diverse sets of examples from our idea map generate more diverse ideas than those seeing randomly selected examples. Our results also corroborate findings from prior research showing that people presented with creative examples generated more creative ideas than those who saw a set of random examples. We see this work as a step toward building more effective online systems for supporting large scale collective ideation.},
  eventtitle = {{{CSCW}} '15: {{Computer Supported Cooperative Work}} and {{Social Computing}}},
  isbn = {978-1-4503-2922-4},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/LCR8S4UE/Siangliulue et al. - 2015 - Toward Collaborative Ideation at Scale Leveraging.pdf}
}

@inproceedings{siangliulueIdeaHoundImprovingLargescale2016,
  title = {{{IdeaHound}}: {{Improving Large-scale Collaborative Ideation}} with {{Crowd-Powered Real-time Semantic Modeling}}},
  shorttitle = {{{IdeaHound}}},
  booktitle = {Proceedings of the 29th {{Annual Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Siangliulue, Pao and Chan, Joel and Dow, Steven P. and Gajos, Krzysztof Z.},
  date = {2016-10-16},
  pages = {609--624},
  publisher = {{ACM}},
  location = {{Tokyo Japan}},
  doi = {10.1145/2984511.2984578},
  url = {https://dl.acm.org/doi/10.1145/2984511.2984578},
  urldate = {2023-03-21},
  eventtitle = {{{UIST}} '16: {{The}} 29th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-4189-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/B4YRSKWW/Siangliulue et al. - 2016 - IdeaHound Improving Large-scale Collaborative Ide.pdf}
}

@inproceedings{siangliulueProvidingTimelyExamples2015,
  title = {Providing {{Timely Examples Improves}} the {{Quantity}} and {{Quality}} of {{Generated Ideas}}},
  booktitle = {Proceedings of the 2015 {{ACM SIGCHI Conference}} on {{Creativity}} and {{Cognition}}},
  author = {Siangliulue, Pao and Chan, Joel and Gajos, Krzysztof Z. and Dow, Steven P.},
  date = {2015-06-22},
  pages = {83--92},
  publisher = {{ACM}},
  location = {{Glasgow United Kingdom}},
  doi = {10.1145/2757226.2757230},
  url = {https://dl.acm.org/doi/10.1145/2757226.2757230},
  urldate = {2023-05-08},
  eventtitle = {C\&{{C}} '15: {{Creativity}} and {{Cognition}}},
  isbn = {978-1-4503-3598-0},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/FK68P7GC/Siangliulue et al. - 2015 - Providing Timely Examples Improves the Quantity an.pdf}
}

@inproceedings{smithVisualizationComponentsPersistent2001,
  title = {Visualization Components for Persistent Conversations},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Smith, Marc A. and Fiore, Andrew T.},
  date = {2001-03},
  pages = {136--143},
  publisher = {{ACM}},
  location = {{Seattle Washington USA}},
  doi = {10.1145/365024.365073},
  url = {https://dl.acm.org/doi/10.1145/365024.365073},
  urldate = {2023-05-08},
  eventtitle = {{{CHI01}}: {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-58113-327-1},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/72TPW58F/Smith and Fiore - 2001 - Visualization components for persistent conversati.pdf}
}

@online{songUnderstandingPeopleNeeds2023,
  title = {Understanding People's Needs in Viewing Diverse Social Opinions about Controversial Topics},
  author = {Song, Hayeong and Qi, Zhengyang and Stasko, John and Yang, Diyi},
  date = {2023-04-23},
  eprint = {2304.11561},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.1109/PacificVis56936.2023.00008},
  url = {http://arxiv.org/abs/2304.11561},
  urldate = {2023-04-27},
  abstract = {Social media (i.e., Reddit) users are overloaded with people's opinions when viewing discourses about divisive topics. Traditional user interfaces in such media present those opinions in a linear structure, which can limit users in viewing diverse social opinions at scale. Prior work has recognized this limitation, that the linear structure can reinforce biases, where a certain point of view becomes widespread simply because many viewers seem to believe it. This limitation can make it difficult for users to have a truly conversational mode of mediated discussion. Thus, when designing a user interface for viewing people's opinions, we should consider ways to mitigate selective exposure to information and polarization of opinions. We conducted a needs-finding study with 11 Reddit users, who follow climate change threads and make posts and comments regularly. In the study, we aimed to understand key limitations in people viewing online controversial discourses and to extract design implications to address these problems. Our findings discuss potential future directions to address these problems.},
  pubstate = {preprint},
  keywords = {ğŸ’™,notion},
  file = {/Users/xinyuech/Zotero/storage/HPPHYWI8/Song et al. - 2023 - Understanding people's needs in viewing diverse so.pdf;/Users/xinyuech/Zotero/storage/LEPLV6KJ/2304.html}
}

@inproceedings{sonItOkayBe2023,
  title = {It Is {{Okay}} to Be {{Distracted}}: {{How Real-time Transcriptions Facilitate Online Meeting}} with {{Distraction}}},
  shorttitle = {It Is {{Okay}} to Be {{Distracted}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Son, Seoyun and Choi, Junyoug and Lee, Sunjae and Song, Jean Y and Shin, Insik},
  date = {2023-04-19},
  pages = {1--19},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580742},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580742},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/2TIHKV9H/Son et al. - 2023 - It is Okay to be Distracted How Real-time Transcr.pdf}
}

@article{stewartSayYouSay2019,
  title = {I {{Say}}, {{You Say}}, {{We Say}}: {{Using Spoken Language}} to {{Model Socio-Cognitive Processes}} during {{Computer-Supported Collaborative Problem Solving}}},
  shorttitle = {I {{Say}}, {{You Say}}, {{We Say}}},
  author = {Stewart, Angela E.B. and Vrzakova, Hana and Sun, Chen and Yonehiro, Jade and Stone, Cathlyn Adele and Duran, Nicholas D. and Shute, Valerie and D'Mello, Sidney K.},
  date = {2019-11-07},
  journaltitle = {ACM äººæœºäº¤äº’è®ºæ–‡é›†},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  pages = {194:1--194:19},
  doi = {10.1145/3359296},
  url = {https://dl.acm.org/doi/10.1145/3359296},
  urldate = {2023-03-24},
  abstract = {åä½œè§£å†³é—®é¢˜ (CPS) æ˜¯ä¸€é¡¹è‡³å…³é‡è¦çš„ 21 ä¸–çºªæŠ€èƒ½ï¼›ç„¶è€Œï¼Œå½“å‰çš„æŠ€æœ¯æ— æ³•æœ‰æ•ˆæ”¯æŒ CPS æµç¨‹ï¼Œå°¤å…¶æ˜¯è¿œç¨‹ã€è®¡ç®—æœºæ”¯æŒçš„äº¤äº’ã€‚ä¸ºäº†å¼€å‘ä¸‹ä¸€ä»£è®¡ç®—æœºæ”¯æŒçš„åä½œç³»ç»Ÿï¼Œé€šè¿‡ç›‘è§†å’Œå“åº”å±•å¼€çš„åä½œæ¥å¢å¼º CPS è¿‡ç¨‹å’Œç»“æœï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸‰ä¸ªå…³é”® CPS è¿‡ç¨‹çš„è‡ªåŠ¨æ£€æµ‹ï¼Ÿæ„å»ºå…±äº«çŸ¥è¯†ã€è°ˆåˆ¤/åè°ƒå’Œç»´æŠ¤å›¢é˜ŸåŠŸèƒ½ ? æºè‡ªç»è¿‡éªŒè¯çš„ CPS æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ•°æ®ç”± 32 ä¸ªä¸‰åˆä¼šç»„æˆï¼Œä»–ä»¬çš„ä»»åŠ¡æ˜¯ä½¿ç”¨å•†ä¸šè§†é¢‘ä¼šè®®è½¯ä»¶åä½œè§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰è®¡ç®—æœºç¼–ç¨‹ä»»åŠ¡ 20 åˆ†é’Ÿã€‚æˆ‘ä»¬ä½¿ç”¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç”Ÿæˆäº† 11,163 æ¡è¯è¯­çš„è½¬å½•æœ¬ï¼Œå®ƒä½¿ç”¨ä¸€ç»„è¡Œä¸ºæŒ‡æ ‡è®­ç»ƒäººç±»ç¼–ç ä¸Šè¿°ä¸‰ä¸ª CPS è¿‡ç¨‹çš„è¯æ®ã€‚æˆ‘ä»¬æ—¨åœ¨ä»¥ç‹¬ç«‹äºå›¢é˜Ÿçš„æ–¹å¼ï¼ˆå½“å‰ç ”ç©¶ï¼‰è‡ªåŠ¨åŒ–å—è¿‡è®­ç»ƒçš„äººç±»è¯„åˆ†è€…ä»£ç ï¼Œä»¥æä¾›è‡ªåŠ¨å®æ—¶æˆ–ç¦»çº¿åé¦ˆï¼ˆæœªæ¥å·¥ä½œï¼‰ã€‚æˆ‘ä»¬ä½¿ç”¨éšæœºæ£®æ—åˆ†ç±»å™¨å¯¹å•è¯æœ¬èº«ï¼ˆn-gram åŒ…ï¼‰æˆ–è¯­è¨€æŸ¥è¯¢å­—æ•°ç»Ÿè®¡ (LIWC) å·¥å…·ä¸­çš„å•è¯ç±»åˆ«ï¼ˆä¾‹å¦‚ï¼Œæƒ…ç»ªã€æ€ç»´æ–¹å¼ã€ç¤¾ä¼šç»“æ„ï¼‰è¿›è¡Œè®­ç»ƒã€‚å°½ç®¡è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä¸å®Œå–„ï¼Œä½† n-gram æ¨¡å‹åœ¨æ„å»ºå…±äº«çŸ¥è¯†ã€åå•†/åè°ƒå’Œç»´æŠ¤å›¢é˜ŸåŠŸèƒ½æ–¹é¢åˆ†åˆ«è·å¾—äº† 0.85ã€0.77 å’Œ 0.77 çš„ AUROCï¼ˆæ¥å—è€…æ“ä½œç‰¹å¾æ›²çº¿ä¸‹é¢ç§¯ï¼‰åˆ†æ•°ï¼›è¿™äº›åæ˜ äº† 70\%ã€54\% å’Œ 54\% çš„æ”¹è¿›ã€‚LIWC ç±»åˆ«æ¨¡å‹å–å¾—äº†ç±»ä¼¼çš„åˆ†æ•°ï¼Œåˆ†åˆ«ä¸º 0.82ã€0.74 å’Œ 0.73ï¼ˆç›¸å¯¹äºæ¦‚ç‡æé«˜äº† 64\%ã€48\% å’Œ 46\%ï¼‰ã€‚æ­¤å¤–ï¼ŒLIWC æ¨¡å‹æ´¾ç”Ÿçš„åˆ†æ•°é¢„æµ‹ CPS ç»“æœæ›´ç±»ä¼¼äºäººç±»ä»£ç ï¼Œè¯æ˜äº†é¢„æµ‹æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬è®¨è®ºäº†å°†æˆ‘ä»¬çš„æ¨¡å‹åµŒå…¥åˆ°åä½œç•Œé¢ä¸­ä»¥è¿›è¡Œè¯„ä¼°å’ŒåŠ¨æ€å¹²é¢„ï¼Œä»¥æ”¹å–„ CPS ç»“æœã€‚},
  issue = {CSCW},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/UJPYJ73A/Stewart et al. - 2019 - I Say, You Say, We Say Using Spoken Language to M.pdf}
}

@article{stolckeDialogueActModeling,
  title = {Dialogue {{Act Modeling}} for {{Automatic Tagging}} and {{Recognition}} of {{Conversational Speech}}},
  author = {Stolcke, Andreas and Coccaro, Noah and Bates, Rebecca and Taylor, Paul},
  journaltitle = {Computational Linguistics},
  volume = {26},
  number = {3},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/TE2S7N43/Stolcke et al. - Dialogue Act Modeling for Automatic Tagging and Re.pdf}
}

@online{suhSensecapeEnablingMultilevel2023,
  title = {Sensecape: {{Enabling Multilevel Exploration}} and {{Sensemaking}} with {{Large Language Models}}},
  shorttitle = {Sensecape},
  author = {Suh, Sangho and Min, Bryan and Palani, Srishti and Xia, Haijun},
  date = {2023-05-19},
  eprint = {2305.11483},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.11483},
  urldate = {2023-08-16},
  abstract = {People are increasingly turning to large language models (LLMs) for complex information tasks like academic research or planning a move to another city. However, while they often require working in a nonlinear manner - e.g., to arrange information spatially to organize and make sense of it, current interfaces for interacting with LLMs are generally linear to support conversational interaction. To address this limitation and explore how we can support LLM-powered exploration and sensemaking, we developed Sensecape, an interactive system designed to support complex information tasks with an LLM by enabling users to (1) manage the complexity of information through multilevel abstraction and (2) seamlessly switch between foraging and sensemaking. Our within-subject user study reveals that Sensecape empowers users to explore more topics and structure their knowledge hierarchically. We contribute implications for LLM-based workflows and interfaces for information tasks.},
  pubstate = {preprint},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction},
  file = {/Users/xinyuech/Zotero/storage/PZ9ZN7NV/Suh et al. - 2023 - Sensecape Enabling Multilevel Exploration and Sen.pdf;/Users/xinyuech/Zotero/storage/X3M756S6/2305.html}
}

@article{sunHowStudentsGenerate2022,
  title = {How Do Students Generate Ideas Together in Scientific Creativity Tasks through Computer-Based Mind Mapping?},
  author = {Sun, Meng and Wang, Minhong and Wegerif, Rupert and Peng, Jun},
  date = {2022-01-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {176},
  pages = {104359},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2021.104359},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131521002360},
  urldate = {2023-03-15},
  abstract = {Creativity is widely described as a key â€˜21st Century skillâ€™. Science education in schools has emphasized the development of science inquiry and problem-solving skills with the support of technology, and paid insufficient attention to creative thinking skills for producing innovative ideas or solutions. This paper presents an exploratory study aiming to investigate how secondary school students engage in scientific creativity tasks with the support of technology, in particular how they generate ideas in small groups via applying relevant thinking strategies, engaging in social communication, and constructing a computer-based mind map to facilitate group thinking. The participants were 24 Grade 11 students from a high school, who worked on a set of scientific creativity tasks in 6 groups. Epistemic network analysis of group conversations reveals that constructing a mind map helped students to retain ideas for elaboration and evaluation, stimulate new threads of discussion, and regulate task progression. Compared to low-performing groups, high-performing groups engaged more in divergent thinking, mind mapping, and regulative discussions, in addition to making these activities more closely connected with idea generation. These findings have implications for the design of technology-supported educational interventions intended to promote and improve group creativity in science education.},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/8PI9EVJ8/Sun et al. - 2022 - How do students generate ideas together in scienti.pdf;/Users/xinyuech/Zotero/storage/N6IRNPNW/S0360131521002360.html}
}

@inproceedings{tangConceptGuideSupportingOnline2021,
  title = {{{ConceptGuide}}: {{Supporting Online Video Learning}} with {{Concept Map-based Recommendation}} of {{Learning Path}}},
  shorttitle = {{{ConceptGuide}}},
  booktitle = {Proceedings of the {{Web Conference}} 2021},
  author = {Tang, Chien-Lin and Liao, Jingxian and Wang, Hao-Chuan and Sung, Ching-Ying and Lin, Wen-Chieh},
  date = {2021-04-19},
  pages = {2757--2768},
  publisher = {{ACM}},
  location = {{Ljubljana Slovenia}},
  doi = {10.1145/3442381.3449808},
  url = {https://dl.acm.org/doi/10.1145/3442381.3449808},
  urldate = {2023-05-23},
  eventtitle = {{{WWW}} '21: {{The Web Conference}} 2021},
  isbn = {978-1-4503-8312-7},
  langid = {english},
  file = {/Users/xinyuech/Zotero/storage/8A7W2BGB/Tang et al. - 2021 - ConceptGuide Supporting Online Video Learning wit.pdf}
}

@article{thomasVisualizingConversationsGroup2020,
  title = {Visualizing Conversations {{In}} Group Therapy: Developing a Tool to Visualize Conversations and Improve Therapist Skills.},
  shorttitle = {Visualizing Conversations {{In}} Group Therapy},
  author = {Thomas, Libby},
  date = {2020},
  url = {https://repository.library.northeastern.edu/files/neu:bz60mb52t},
  urldate = {2023-04-24},
  abstract = {Society has a growing need for trained, insightful therapists. Group therapy is a popular and effective form of psychiatric treatment but documenting and reviewing large amounts of information from long group sessions is time-consuming, both for therapists and their supervisors. The increased availability and accuracy of automatically generated session transcripts gives designers an opportunity to design tools that smooth the way to clearer insight for therapists and improved care for patients. This thesis introduces prototypes for a visualization tool to help therapists and their supervisors explore patterns, conversation topics, dynamics in group therapy. The tool will allow users to search session transcripts, view outcome trends for individuals and groups, and visualize group dynamics over time. It is my hope that the work presented in this thesis will not only be considered in the context of mental healthcare, but will serve as a springboard for designers to experiment and visualize group conversations in a variety of contexts. Funding for the preparation of this thesis was provided by the National Institute of Mental Health under award 1-R56-MH-118550-01.--Author's abstract},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/N6QKX5AH/Thomas - 2020 - Visualizing conversations In group therapy develo.pdf}
}

@article{valkIdeationCompassSupporting2022,
  title = {The {{Ideation Compass}}: Supporting Interdisciplinary Creative Dialogues with Real Time Visualization},
  shorttitle = {The {{Ideation Compass}}},
  author = {VÃ¤lk, Sander and Thabsuwan, Chitipat and Mougenot, CÃ©line},
  date = {2022-11-21},
  journaltitle = {International Journal of Design Creativity and Innovation},
  volume = {0},
  number = {0},
  pages = {1--18},
  publisher = {{Taylor \& Francis}},
  issn = {2165-0349},
  doi = {10.1080/21650349.2022.2142674},
  url = {https://doi.org/10.1080/21650349.2022.2142674},
  urldate = {2023-03-16},
  abstract = {This study presents the potential of live topic visualization in supporting creative dialogs during remote idea generation. We developed a novel Creativity Support Tool (CST) to explore the effects of the live topic visualization. The tool emphasizes the interdisciplinary knowledge background of participants. Using Natural Language Processing (NLP) and topic modeling, the tool provides users with a live visual mapping of the domains and topics being orally discussed. To understand the toolâ€™s user perceived effects, we conducted evaluation sessions and interviews with participants (N = 10) from two different disciplinary backgrounds: design and bioscience. The findings show that live visualization of domains and topics supported self-reflection during individual and collaborative creativity and encouraged a balanced discussion, which can mitigate discipline-based fixation in ideation.},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/TGFDG8N7/VÃ¤lk et al. - 2022 - The Ideation Compass supporting interdisciplinary.pdf}
}

@inproceedings{viegasStudyingCooperationConflict2004,
  title = {Studying Cooperation and Conflict between Authors with {\emph{History Flow}} Visualizations},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {ViÃ©gas, Fernanda B. and Wattenberg, Martin and Dave, Kushal},
  date = {2004-04-25},
  pages = {575--582},
  publisher = {{ACM}},
  location = {{Vienna Austria}},
  doi = {10.1145/985692.985765},
  url = {https://dl.acm.org/doi/10.1145/985692.985765},
  urldate = {2023-04-06},
  eventtitle = {{{CHI04}}: {{CHI}} 2004 {{Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-58113-702-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/EZCNK3J2/ViÃ©gas et al. - 2004 - Studying cooperation and conflict between authors .pdf}
}

@inproceedings{wangCallistoCapturingWhy2020,
  title = {Callisto: {{Capturing}} the "{{Why}}" by {{Connecting Conversations}} with {{Computational Narratives}}},
  shorttitle = {Callisto},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wang, April Yi and Wu, Zihan and Brooks, Christopher and Oney, Steve},
  date = {2020-04-21},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{Honolulu HI USA}},
  doi = {10.1145/3313831.3376740},
  url = {https://dl.acm.org/doi/10.1145/3313831.3376740},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '20: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-6708-0},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/GXSQSBW3/Wang et al. - 2020 - Callisto Capturing the Why by Connecting Conver.pdf}
}

@inproceedings{wangIdeaExpanderSupporting2010,
  title = {Idea Expander: Supporting Group Brainstorming with Conversationally Triggered Visual Thinking Stimuli},
  shorttitle = {Idea Expander},
  booktitle = {Proceedings of the 2010 {{ACM}} Conference on {{Computer}} Supported Cooperative Work},
  author = {Wang, Hao-Chuan and Cosley, Dan and Fussell, Susan R.},
  date = {2010-02-06},
  series = {{{CSCW}} '10},
  pages = {103--106},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/1718918.1718938},
  url = {https://doi.org/10.1145/1718918.1718938},
  urldate = {2023-03-15},
  abstract = {åˆ›é€ åŠ›æ˜¯è®¸å¤šäººç±»è§£å†³é—®é¢˜å’Œåˆ›æ–°çš„æ ¸å¿ƒã€‚å¤´è„‘é£æš´è¿‡ç¨‹è¯•å›¾åˆ©ç”¨å›¢é˜Ÿåˆ›é€ åŠ›ï¼Œä½†å›¢é˜ŸåŠ¨åŠ›æœ‰æ—¶ä¼šé™åˆ¶å…¶æ•ˆç”¨ã€‚æˆ‘ä»¬æ¨å‡ºäº† IdeaExpanderï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡æ ¹æ®å°ç»„å¯¹è¯æ™ºèƒ½é€‰æ‹©å›¾ç‰‡åˆºæ¿€æ¥æ”¯æŒå°ç»„å¤´è„‘é£æš´çš„å·¥å…·ã€‚è®¾è®¡åŸºäºæ„ŸçŸ¥ã€æ€ç»´å’Œæ²Ÿé€šå¦‚ä½•ç›¸äº’ä½œç”¨çš„ç†è®ºï¼›ä¸€é¡¹è¯•ç‚¹ç ”ç©¶ (N=16) è¡¨æ˜ï¼Œå®ƒå¢åŠ äº†ä¸ªäººçš„æƒ³æ³•äº§ç”Ÿï¼Œå¹¶ä¸”äººä»¬é‡è§†å®ƒã€‚},
  isbn = {978-1-60558-795-0},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/AE64YDGK/Wang et al. - 2010 - Idea expander supporting group brainstorming with.pdf}
}

@article{wangLearningPerformanceBehavioral2020,
  title = {Learning Performance and Behavioral Patterns of Online Collaborative Learning: {{Impact}} of Cognitive Load and Affordances of Different Multimedia},
  shorttitle = {Learning Performance and Behavioral Patterns of Online Collaborative Learning},
  author = {Wang, Cixiao and Fang, Ting and Gu, Yinxuan},
  date = {2020-01-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {143},
  pages = {103683},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2019.103683},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131519302362},
  urldate = {2023-03-22},
  abstract = {In online collaborative learning, discussions have been widely utilized as an educational activity, and much research has been conducted on the process and behaviors involved in synchronous or asynchronous discussions. However, research on behavioral patterns in collaborative learning environments with different formats of learning materials has not been addressed in detailed yet. In this study, we designed three versions of media to present the same learning contents: interactive version, video version, and text version. The differences among the above three versions are the form of information organization and the interaction mode between students and the given version. There were 131 eighth graders from three classes participated in this study. They were asked to complete a group worksheet through online discussion while engaging with the given learning materials. In order to explore students' online collaborative behavioral patterns while engaging with different multimedia, this study proposed a verb-dominated coding scheme for synchronous online collaborative learning and conducted a lag sequential analysis. The findings indicate that Class A (interactive version) formed an active learning atmosphere, while Class B (video version) spent more time on showing disagreement due to overloaded working memory caused by improper information presentation. In contrast, Class C (text version) had high efficiency in information exchanges because of the convenience of information acquisition. Besides, Class A gained the highest scores in group worksheet and invested moderate cognitive load. Class B had unsatisfactory learning performance on group worksheet along with the highest cognitive load. Class C invested the lowest cognitive load and had better knowledge retention than Class A, as shown in the results of the post-test a week later.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/Q63RUCYA/S0360131519302362.html}
}

@online{wangPopBlendsStrategiesConceptual2023,
  title = {{{PopBlends}}: {{Strategies}} for {{Conceptual Blending}} with {{Large Language Models}}},
  shorttitle = {{{PopBlends}}},
  author = {Wang, Sitong and Petridis, Savvas and Kwon, Taeahn and Ma, Xiaojuan and Chilton, Lydia B.},
  date = {2023-02-19},
  eprint = {2111.04920},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2111.04920},
  urldate = {2023-04-19},
  abstract = {Pop culture is an important aspect of communication. On social media people often post pop culture reference images that connect an event, product or other entity to a pop culture domain. Creating these images is a creative challenge that requires finding a conceptual connection between the users' topic and a pop culture domain. In cognitive theory, this task is called conceptual blending. We present a system called PopBlends that automatically suggests conceptual blends. The system explores three approaches that involve both traditional knowledge extraction methods and large language models. Our annotation study shows that all three methods provide connections with similar accuracy, but with very different characteristics. Our user study shows that people found twice as many blend suggestions as they did without the system, and with half the mental demand. We discuss the advantages of combining large language models with knowledge bases for supporting divergent and convergent thinking.},
  pubstate = {preprint},
  keywords = {ğŸ§¡ğŸ§¡ğŸ§¡ğŸ§¡,notion},
  file = {/Users/xinyuech/Zotero/storage/G3PSMFYZ/Wang et al. - 2023 - PopBlends Strategies for Conceptual Blending with.pdf;/Users/xinyuech/Zotero/storage/5G3L6Z37/2111.html}
}

@inproceedings{wangSlide4NCreatingPresentation2023,
  title = {{{Slide4N}}: {{Creating Presentation Slides}} from {{Computational Notebooks}} with {{Human-AI Collaboration}}},
  shorttitle = {{{Slide4N}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wang, Fengjie and Liu, Xuye and Liu, Oujing and Neshati, Ali and Ma, Tengfei and Zhu, Min and Zhao, Jian},
  date = {2023-04-19},
  pages = {1--18},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3580753},
  url = {https://dl.acm.org/doi/10.1145/3544548.3580753},
  urldate = {2023-05-07},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {ğŸ§¡ğŸ§¡ğŸ§¡ğŸ§¡,notion},
  file = {/Users/xinyuech/Zotero/storage/ZR22UERN/Wang et al. - 2023 - Slide4N Creating Presentation Slides from Computa.pdf}
}

@article{wegerifExploringCreativeThinking2010,
  title = {Exploring Creative Thinking in Graphically Mediated Synchronous Dialogues},
  author = {Wegerif, Rupert and McLaren, Bruce M. and Chamrada, Marian and Scheuer, Oliver and Mansour, Nasser and MikÅ¡Ã¡tko, Jan and Williams, Mriga},
  date = {2010-04-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  series = {Learning in {{Digital Worlds}}: {{Selected Contributions}} from the {{CAL}} 09 {{Conference}}},
  volume = {54},
  number = {3},
  pages = {613--621},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2009.10.015},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131509003054},
  urldate = {2023-05-24},
  abstract = {This paper reports on an aspect of the EC funded Argunaut project which researched and developed awareness tools for moderators of online dialogues. In this study we report on an investigation into the nature of creative thinking in online dialogues and whether or not this creative thinking can be coded for and recognized automatically such that moderators can be alerted when creative thinking is occurring or when it has not occurred after a period of time. We outline a dialogic theory of creativity, as the emergence of new perspectives from the interplay of voices, and the testing of this theory using a range of methods including a coding scheme which combined coding for creative thinking with more established codes for critical thinking, artificial intelligence pattern-matching techniques to see if our codes could be read automatically from maps and â€˜key event recallâ€™ interviews to explore the experience of participants. Our findings are that: (1) the emergence of new perspectives in a graphical dialogue map can be recognized by our coding scheme supported by a machine pattern-matching algorithm in a way that can be used to provide awareness indicators for moderators; (2) that the trigger events leading to the emergence of new perspectives in the online dialogues studied were most commonly disagreements and (3) the spatial representation of messages in a graphically mediated synchronous dialogue environment such as Digalo may offer more affordance for creativity than the much more common scrolling text chat environments. All these findings support the usefulness of our new account of creativity in online dialogues based on dialogic theory and demonstrate that this account can be operationalised through machine coding in a way that can be turned into alerts for moderators.},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/5WWZ8WIW/Wegerif et al. - 2010 - Exploring creative thinking in graphically mediate.pdf;/Users/xinyuech/Zotero/storage/P9F2VQHY/S0360131509003054.html}
}

@report{wenTransactivityPredictorFuture2016,
  title = {Transactivity as a {{Predictor}} of {{Future Collaborative Knowledge Integration}} in {{Team-Based Learning}} in {{Online Courses}}},
  author = {Wen, Miaomiao and Maki, Keith and Wang, Xu and Dow, Steven P. and Herbsleb, James and Rose, Carolyn},
  date = {2016},
  journaltitle = {International Educational Data Mining Society},
  institution = {{International Educational Data Mining Society}},
  url = {https://eric.ed.gov/?id=ED592733},
  urldate = {2023-03-21},
  abstract = {To create a satisfying social learning experience, an emerging challenge in educational data mining is to automatically assign students into effective learning teams. In this paper, we utilize discourse data mining as the foundation for an online team-formation procedure. The procedure features a deliberation process prior to team assignment, where participants hold discussions both to prepare for the collaboration task and provide indicators that are then used during automated team assignment. We automatically assign teams in a way that maximizes average observed pairwise transactivity exchange within teams, whereas in a control condition, teams are assigned randomly. We validate our team-formation procedure in a crowdsourced online environment that enables effective isolation of variables, namely Amazon's Mechanical Turk. We compare group knowledge integration outcomes between the two team assignment conditions. Our results demonstrate that transactivity-based team assignment is associated with significantly greater knowledge integration (p {$<$} 0.05, effect size 3 standard deviations). [For the full proceedings, see ED592609.]},
  langid = {english},
  keywords = {notion},
  annotation = {ERIC Number: ED592733},
  file = {/Users/xinyuech/Zotero/storage/QM7PTZLY/Wen et al. - 2016 - Transactivity as a Predictor of Future Collaborati.pdf}
}

@inproceedings{wuPromptChainerChainingLarge2022,
  title = {{{PromptChainer}}: {{Chaining Large Language Model Prompts}} through {{Visual Programming}}},
  shorttitle = {{{PromptChainer}}},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems Extended Abstracts}}},
  author = {Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J},
  date = {2022-04-27},
  pages = {1--10},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3491101.3519729},
  url = {https://dl.acm.org/doi/10.1145/3491101.3519729},
  urldate = {2023-04-27},
  abstract = {While LLMs have made it possible to rapidly prototype new ML functionalities, many real-world applications involve complex tasks that cannot be easily handled via a single run of an LLM. Recent work has found that chaining multiple LLM runs together (with the output of one step being the input to the next) can help users accomplish these more complex tasks, and in a way that is perceived to be more transparent and controllable. However, it remains unknown what users need when authoring their own LLM chains â€“ a key step to lowering the barriers for non-AI-experts to prototype AI-infused applications. In this work, we explore the LLM chain authoring process. We find from pilot studies that users need support transforming data between steps of a chain, as well as debugging the chain at multiple granularities. To address these needs, we designed PromptChainer, an interactive interface for visually programming chains. Through case studies with four designers and developers, we show that PromptChainer supports building prototypes for a range of applications, and conclude with open questions on scaling chains to even more complex tasks, as well as supporting low-fi chain prototyping.},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9156-6},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/VL8IQYZJ/Wu et al. - 2022 - PromptChainer Chaining Large Language Model Promp.pdf}
}

@article{xiaCrossTalkIntelligentSubstrates2023,
  title = {{{CrossTalk}}: {{Intelligent Substrates}} for {{Language-Oriented Interaction}} in {{Video-Based Communication}} and {{Collaboration}}},
  author = {Xia, Haijun and Wang, Tony and Gunturu, Aditya and Jiang, Peiling and Duan, William and Yao, Xiaoshuo},
  date = {2023},
  langid = {english},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/UNUYLY7K/Xia et al. - 2023 - CrossTalk Intelligent Substrates for Language-Ori.pdf}
}

@article{xiaPersuaVisualInteractive2022,
  title = {Persua: {{A Visual Interactive System}} to {{Enhance}} the {{Persuasiveness}} of {{Arguments}} in {{Online Discussion}}},
  shorttitle = {Persua},
  author = {Xia, Meng and Zhu, Qian and Wang, Xingbo and Nie, Fei and Qu, Huamin and Ma, Xiaojuan},
  date = {2022-11-07},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  eprint = {2204.07741},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {1--30},
  issn = {2573-0142},
  doi = {10.1145/3555210},
  url = {http://arxiv.org/abs/2204.07741},
  urldate = {2023-04-19},
  abstract = {Persuading people to change their opinions is a common practice in online discussion forums on topics ranging from political campaigns to relationship consultation. Enhancing people's ability to write persuasive arguments could not only practice their critical thinking and reasoning but also contribute to the effectiveness and civility in online communication. It is, however, not an easy task in online discussion settings where written words are the primary communication channel. In this paper, we derived four design goals for a tool that helps users improve the persuasiveness of arguments in online discussions through a survey with 123 online forum users and interviews with five debating experts. To satisfy these design goals, we analyzed and built a labeled dataset of fine-grained persuasive strategies (i.e., logos, pathos, ethos, and evidence) in 164 arguments with high ratings on persuasiveness from ChangeMyView, a popular online discussion forum. We then designed an interactive visual system, Persua, which provides example-based guidance on persuasive strategies to enhance the persuasiveness of arguments. In particular, the system constructs portfolios of arguments based on different persuasive strategies applied to a given discussion topic. It then presents concrete examples based on the difference between the portfolios of user input and high-quality arguments in the dataset. A between-subjects study shows suggestive evidence that Persua encourages users to submit more times for feedback and helps users improve more on the persuasiveness of their arguments than a baseline system. Finally, a set of design considerations was summarized to guide future intelligent systems that improve the persuasiveness in text.},
  issue = {CSCW2},
  keywords = {notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/I62NK3R3/Xia et al. - 2022 - Persua A Visual Interactive System to Enhance the.pdf;/Users/xinyuech/Zotero/storage/VJBHDQVW/2204.html}
}

@inproceedings{xingImprovingUnsupervisedDialogue2021,
  title = {Improving {{Unsupervised Dialogue Topic Segmentation}} with {{Utterance-Pair Coherence Scoring}}},
  booktitle = {Proceedings of the 22nd {{Annual Meeting}} of the {{Special Interest Group}} on {{Discourse}} and {{Dialogue}}},
  author = {Xing, Linzi and Carenini, Giuseppe},
  date = {2021-07},
  pages = {167--177},
  publisher = {{Association for Computational Linguistics}},
  location = {{Singapore and Online}},
  url = {https://aclanthology.org/2021.sigdial-1.18},
  urldate = {2023-06-05},
  abstract = {Dialogue topic segmentation is critical in several dialogue modeling problems. However, popular unsupervised approaches only exploit surface features in assessing topical coherence among utterances. In this work, we address this limitation by leveraging supervisory signals from the utterance-pair coherence scoring task. First, we present a simple yet effective strategy to generate a training corpus for utterance-pair coherence scoring. Then, we train a BERT-based neural utterance-pair coherence model with the obtained training corpus. Finally, such model is used to measure the topical relevance between utterances, acting as the basis of the segmentation inference. Experiments on three public datasets in English and Chinese demonstrate that our proposal outperforms the state-of-the-art baselines.},
  eventtitle = {{{SIGDIAL}} 2021},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/6ZRGMUFF/Xing and Carenini - 2021 - Improving Unsupervised Dialogue Topic Segmentation.pdf}
}

@article{xuIdeateRelateExamplesGallery2021,
  title = {{{IdeateRelate}}: {{An Examples Gallery That Helps Creators Explore Ideas}} in {{Relation}} to {{Their Own}}},
  shorttitle = {{{IdeateRelate}}},
  author = {Xu, Xiaotong (Tone) and Xiong, Rosaleen and Wang, Boyang and Min, David and Dow, Steven P.},
  date = {2021-10-13},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  pages = {1--18},
  issn = {2573-0142},
  doi = {10.1145/3479496},
  url = {https://dl.acm.org/doi/10.1145/3479496},
  urldate = {2023-03-20},
  abstract = {Creating truly original ideas requires extensive knowledge of existing ideas. Navigating prior examples can help people to understand what has already been done and to assess the quality of their own ideas through comparison. The creativity literature has suggested that the conceptual distance between a proposed solution and a potential inspiration can influence one's thinking. However, less is known about how creators might use data about conceptual distance when exploring a large repository of ideas. To investigate this, we created a novel tool for exploring examples called IdeateRelate that visualizes 600+ COVID-related ideas, organized by their similarity to a new idea. In an experiment that compared the IdeateRelate visualization to a simple list of examples, we found that users in the Viz condition leveraged both semantic and categorical similarity, curated a more similar set of examples, and adopted more language from examples into their iterated ideas (without negatively affecting the overall novelty). We discuss implications for creating adaptive interfaces that provide creative inspiration in response to designers' ideas throughout an iterative design process.},
  issue = {CSCW2},
  langid = {english},
  keywords = {notion},
  file = {/Users/xinyuech/Zotero/storage/88SRGQFU/Xu et al. - 2021 - IdeateRelate An Examples Gallery That Helps Creat.pdf}
}

@inproceedings{yangCatchLiveRealtimeSummarization2022,
  title = {{{CatchLive}}: {{Real-time Summarization}} of {{Live Streams}} with {{Stream Content}} and {{Interaction Data}}},
  shorttitle = {{{CatchLive}}},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Yang, Saelyne and Yim, Jisu and Kim, Juho and Shin, Hijung Valentina},
  date = {2022-04-29},
  pages = {1--20},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3491102.3517461},
  url = {https://dl.acm.org/doi/10.1145/3491102.3517461},
  urldate = {2023-08-16},
  abstract = {Live streams usually last several hours with many viewers joining in the middle. Viewers who join in the middle often want to understand what has happened in the stream. However, catching up with the earlier parts is challenging because it is difcult to know which parts are important in the long, unedited stream while also âˆ—This work was done while the author was an intern at Adobe Research.},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9157-3},
  langid = {english},
  keywords = {/unread,â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,ğŸ’™},
  file = {/Users/xinyuech/Zotero/storage/F8TTUCKW/Yang et al. - 2022 - CatchLive Real-time Summarization of Live Streams.pdf}
}

@inproceedings{yangSoftVideoImprovingLearning2022,
  title = {{{SoftVideo}}: {{Improving}} the {{Learning Experience}} of {{Software Tutorial Videos}} with {{Collective Interaction Data}}},
  shorttitle = {{{SoftVideo}}},
  booktitle = {27th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Yang, Saelyne and Yim, Jisu and Baigutanova, Aitolkyn and Kim, Seoyoung and Chang, Minsuk and Kim, Juho},
  date = {2022-03-22},
  pages = {646--660},
  publisher = {{ACM}},
  location = {{Helsinki Finland}},
  doi = {10.1145/3490099.3511106},
  url = {https://dl.acm.org/doi/10.1145/3490099.3511106},
  urldate = {2023-08-15},
  abstract = {Many people rely on tutorial videos when learning to perform tasks using complex software. Watching the video for instructions and applying them to target software requires frequent going backand-forth between the two, which incurs cognitive overhead. Furthermore, users need to constantly compare the two to see if they are following correctly, as they are prone to missing out on subtle differences. We propose SoftVideo, a prototype system that helps users plan ahead before watching each step in tutorial videos and provides feedback and help to users on their progress. SoftVideo is powered by collective interaction data, as experiences of previous learners with the same goal can provide insights into how they learned from the tutorial. By identifying the difficulty and relatedness of each step from the interaction logs, SoftVideo provides information on each step such as its estimated difficulty, lets users know if they completed or missed a step, and suggests tips such as relevant steps when it detects users struggling. To enable such a data-driven system, we collected and analyzed video interaction logs and the associated Photoshop usage logs for two tutorial videos from 120 users. We then defined six metrics that portray the difficulty of each step, including the time taken to complete a step and the number of pauses in a step, which were also used to detect usersâ€™ struggling moments by comparing their progress to the collected data. To investigate the feasibility and usefulness of SoftVideo, we ran a user study with 30 participants where they performed a Photoshop task by following along a tutorial video with SoftVideo. Results show that participants could proactively and effectively plan their pauses and playback speed, and adjust their concentration level. They were also able to identify and recover from errors with the help SoftVideo provides.},
  eventtitle = {{{IUI}} '22: 27th {{International Conference}} on {{Intelligent User Interfaces}}},
  isbn = {978-1-4503-9144-3},
  langid = {english},
  keywords = {notion,Unsure/Archive},
  file = {/Users/xinyuech/Zotero/storage/ZY7P48DC/Yang et al. - 2022 - SoftVideo Improving the Learning Experience of So.pdf}
}

@article{yuExploringHowWorkspace2022,
  title = {Exploring {{How Workspace Awareness Cues Affect Distributed Meeting Outcome}}},
  author = {Yu, Fangyu and Zhang, Peng and Ding, Xianghua and Lu, Tun and Gu, Ning},
  date = {2022-04-24},
  journaltitle = {International Journal of Humanâ€“Computer Interaction},
  volume = {0},
  number = {0},
  pages = {1--20},
  publisher = {{Taylor \& Francis}},
  issn = {1044-7318},
  doi = {10.1080/10447318.2022.2064063},
  url = {https://doi.org/10.1080/10447318.2022.2064063},
  urldate = {2022-08-05},
  abstract = {Nowadays, using the online whiteboard to share knowledge in distributed meetings has become a common practice. Existing studies and practices have attempted to visualize attendeesâ€™ interactive activities in whiteboard tools to support the virtual teamâ€™s workspace awareness (WA). However, the impact of such visual cues on meeting success remains unclear. For this purpose, we primarily explore whether and to what extent WA cues are conducive to meeting outcome. This study applies activity theory to guide our prototype design and research analysis. A customized web-based whiteboard interface is implemented under two conditions. We conduct a study with 42 subjects in a distributed meeting scenario via a controlled experiment. Also, we analyze the system affordance via user experience. The results demonstrate that the benefits of WA cues to meeting outcome are especially embodied in goal attainment and quality of contributions, but not effectively supported in productivity and user satisfaction. Moreover, subjects report that they do not feel distracted by the systemâ€™s visual cues because they do not notice those cues most of the time and use them only when needed. Drawing upon findings from our trial work, we provide several implications for designing a collaborative knowledge-sharing environment to assist the visual support of WA in distributed meetings.},
  keywords = {/unread,notion}
}

@article{zhangFacilitatingGlobalTeam2022,
  title = {Facilitating {{Global Team Meetings Between Language-Based Subgroups}}: {{When}} and {{How Can Machine Translation Help}}?},
  shorttitle = {Facilitating {{Global Team Meetings Between Language-Based Subgroups}}},
  author = {Zhang, Yongle and Asamoah Owusu, Dennis and Carpuat, Marine and Gao, Ge},
  date = {2022-04-07},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  pages = {90:1--90:26},
  doi = {10.1145/3512937},
  url = {https://dl.acm.org/doi/10.1145/3512937},
  urldate = {2023-03-24},
  abstract = {Global teams frequently consist of language-based subgroups who put together complementary information to achieve common goals. Previous research outlines a two-step work communication flow in these teams. There are team meetings using a required common language (i.e., English); in preparation for those meetings, people have subgroup conversations in their native languages. Work communication at team meetings is often less effective than in subgroup conversations. In the current study, we investigate the idea of leveraging machine translation (MT) to facilitate global team meetings. We hypothesize that exchanging subgroup conversation logs before a team meeting offers contextual information that benefits teamwork at the meeting. MT can translate these logs, which enables comprehension at a low cost. To test our hypothesis, we conducted a between-subjects experiment where twenty quartets of participants performed a personnel selection task. Each quartet included two English native speakers (NS) and two non-native speakers (NNS) whose native language was Mandarin. All participants began the task with subgroup conversations in their native languages, then proceeded to team meetings in English. We manipulated the exchange of subgroup conversation logs prior to team meetings: with MT-mediated exchanges versus without. Analysis of participants' subjective experience, task performance, and depth of discussions as reflected through their conversational moves jointly indicates that team meeting quality improved when there were MT-mediated exchanges of subgroup conversation logs as opposed to no exchanges. We conclude with reflections on when and how MT could be applied to enhance global teamwork across a language barrier.},
  issue = {CSCW1},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸},
  file = {/Users/xinyuech/Zotero/storage/4PKNSFHL/Zhang et al. - 2022 - Facilitating Global Team Meetings Between Language.pdf}
}

@inproceedings{zhangIceBreakingTechnologyRobots2023,
  title = {Ice-{{Breaking Technology}}: {{Robots}} and {{Computers Can Foster Meaningful Connections}} between {{Strangers}} through {{In-Person Conversations}}},
  shorttitle = {Ice-{{Breaking Technology}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zhang, Alex Wuqi and Lin, Ting-Han and Zhao, Xuan and Sebo, Sarah},
  date = {2023-04-19},
  pages = {1--14},
  publisher = {{ACM}},
  location = {{Hamburg Germany}},
  doi = {10.1145/3544548.3581135},
  url = {https://dl.acm.org/doi/10.1145/3544548.3581135},
  urldate = {2023-06-26},
  eventtitle = {{{CHI}} '23: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9421-5},
  langid = {english},
  keywords = {notion,ğŸ©·ğŸ©·ğŸ©·},
  file = {/Users/xinyuech/Zotero/storage/W9FHG52W/Zhang et al. - 2023 - Ice-Breaking Technology Robots and Computers Can .pdf}
}

@online{zhangVISARHumanAIArgumentative2023,
  title = {{{VISAR}}: {{A Human-AI Argumentative Writing Assistant}} with {{Visual Programming}} and {{Rapid Draft Prototyping}}},
  shorttitle = {{{VISAR}}},
  author = {Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun},
  date = {2023-04-16},
  eprint = {2304.07810},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.07810},
  urldate = {2023-04-19},
  abstract = {In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confirmed the usability and effectiveness of VISAR in facilitating the argumentative writing planning process.},
  pubstate = {preprint},
  keywords = {â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸,notion},
  file = {/Users/xinyuech/Zotero/storage/DVD7MEXE/Zhang et al. - 2023 - VISAR A Human-AI Argumentative Writing Assistant .pdf;/Users/xinyuech/Zotero/storage/V2LV7VAR/2304.html}
}
