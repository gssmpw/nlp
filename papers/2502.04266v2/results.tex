%In this section we present the main results and findings of our study, divided by the steps of our incremental methodology and questions we aimed to address within each of the steps. 
We organized the results as answers to the main questions guiding our work. We ask if our bots (or proxy-users) see different results when querying search engines and, if so, how user's features affect those differences (section 4.1). This was done incrementally, by varying the level of bot customization: first varying only the location (\textit{Type 1}), then varying both location and browser language (\textit{Type 2}), and finally varying location, browser language, and browsing history (\textit{Type 3}). Next, we tested whether disparities in result URLs also correspond to meaningful differences in content (section 4.2) and/or content leaning (section 4.3) towards Israel or Palestine.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\columnwidth]{Figures/figure_2.pdf}
    \caption{Panel A: Average difference ($D = 1 - RBO$) between search engine results for Type 1 bot pairs in the same location (light green) and different locations (dark green), for general (left) and specific (right, dashed) queries. Panel B: Average $D$ for Type 2 bots with the same (light yellow) and different (dark yellow) locations and browser languages, across query types and search engines. Panel C: Average $D$ for Type 3 bots with the same (light blue) and different (dark blue) location, browser language and browsing history. Panel D: Average $D$ for the 10 common specific queries across bot types, comparing bots with the same specifications (right) and different (left) across types (colors). Error bars represent 95\% confidence intervals based on the bootstrapped distribution. P-values were calculated with Mann-Whitney U test and adjusted with Bonferroni correction.*** denotes significant differences with p-value less than 0.001, ** less than 0.01, and * less than 0.05. Statistical details in Tables \ref{tab:p_values_adjusted_step_1}, \ref{tab:p_values_adjusted_step_2}, \ref{tab:p_values_adjusted_step_3}, \ref{tab:p_values_comparison_different_steps}.}
    \Description{}
    \label{fig:main_plot}
\end{figure}
%Do users see different resents for the same queries on search engines?  In this work we started by asking whether search engines results are impacted by location, browsing language and browsing history and whether this impact is more pronounced for queries of such a sensitive topic as the Israel-Palestine conflict or for general common queries. 
%In the next section, we detail our results. 

\subsection{Quantifying the Impact of Profiles and of Queries on Search Engine Results}
\subsubsection{Does geographical location influence Search Engine Results?}
\hfill\\
As discussed in the methods and summarized in Table \ref{engines_policies}, search engines typically report customizing results based on location or proxy location. This is useful when searching for a restaurant but might prove problematic when queries are on geographical conflicts. To examine how location affects search engine results, we deployed \textit{Type 1} bots in four distinct regions: Israel (IL), Saudi Arabia (SA), United States (US), and Brazil (BR) - details in the Methods. For each location, the bots queried the three search engines, and gathered the page results (URLs and their respective order) for every query, grouped as either conflict-specific or general.

Figure \ref{fig:main_plot}, panel A (green), summarizes these results, by comparing $D = 1 - RBO$ measurements (horizontally) for each search engine (vertically), with a high $D$ meaning that (the top) results were very different. Light green corresponds to the average $D$ values for bots deployed from the same location (e.g. one in BR bot compared to other BR bot) and dark green the same comparison but for bots deployed from different locations (e.g. BR bots vs US bots). 
%As the order in which the results are displayed is important (\cite{Fay2024b}), $D$ is weighed to prioritize the top results and a low  Then, the most common URL was identified and the second row, panel B, depicts the proportion of results that matched that most common result in each rank position. 
We found a tendency of larger variation between locations (dark green) than within locations (light green), the  difference being more pronounced for DuckDuckGo (p-values in Appendix, Table \ref{tab:p_values_adjusted_step_1}). These differences are even larger for queries related with the conflict, such as "Al-Shifa hospital" and "Hamas rapes" (dashed columns) when compared to more general searches, such as "Home workout routines" or "Popular books 2024" (solid columns). These findings persist even when controlling for query length (Appendix, Figure \ref{rbo_queries_same_size}), and applying other metrics, such as edit distance and intersection of lists (Appendix, Figure \ref{fig:other_metrics_step_1}). 
%Specifically, when comparing the values of $D=1 - RBO$ for "general" and "specific" queries with the same number of words, the same patterns hold. This rules out the possibility that the higher $D$ values observed for the "specific" group of queries are simply due to their longer average length.



%\newtcolorbox{mybox}[1]{colback=gray!5!white,
%colframe=lightgray!75!black,fonttitle=\bfseries,
%title={#1},
%boxsep=1mm, % Decreases the internal padding
%left=1mm, right=1mm, top=1mm, bottom=1mm % Sets specific padding values
%}

% \begin{mybox}{Finding 1}
% As anticipated, based on search engine customization policies, location significantly influences results. Importantly, this effect is more pronounced for conflict-related queries.
% \end{mybox}

\begin{takeaway}
\takeawaytitle{} As anticipated, based on search engine customization policies, location significantly influences results. Importantly, this effect is more pronounced for conflict-related queries.
\end{takeaway}

% \subsection{The impact of increasing bots profiling on search engine results}

% In this work, we aimed to test how different features of online profiles affect search engine results. We did this by gradually adding features to the bots' profiles when they made the searches. The goal was to make the bots more like real users and simultaneously measure how each new feature influenced the personalization of search engine results. As detailed in the Methods after testing the impact of location in search engine results (step 1) we added browser language (step 2) and browser history to our bots (step 3). The results are detailed in the following sections. 

\subsubsection{Does browser language impact search engine results?}
\hfill\\
In the second phase of our experiment, we configured \textit{Type 2} bots not only to be deployed from different locations, but also to interact with the search engines using the primary language of each chosen location (see Methods). These bots performed the same "general" and "specific" queries as before, under the hypothesis that this combination would further intensify the customization of search outcomes.

Figure \ref{fig:main_plot}, panel B (yellow), shows this: changing browser language leads to a greater divergence in search results across all search engines, particularly when comparing bots from different locations (light versus dark yellow columns) and, again, these variations are even more pronounced for conflict-related queries (dashed versus solid columns), with the data from Google revealing a particularly notable increase in the displayed URLs. Results for edit distance and list intersection can be seen in Figure \ref{fig:other_metrics_step_2}.


% \begin{mybox}{Finding 2} 
% The combination of location and browser language increases the personalization of search results, especially for Google. This effect is more prominent for conflict-related queries. 
% \end{mybox}

\begin{takeaway}
    \takeawaytitle{}
    The combination of location and browser language increases the customization of search results, especially for Google. This effect is more prominent for conflict-related queries.
\end{takeaway}

\subsubsection{Does browsing history impact search engine results?}
\hfill\\
It is debatable the extent to which search-engines personalize the displayed content based on the user's past browsing experience, and the studied search engines claim not to do it as long as users are not logged in (Background and Table \ref{engines_policies}). To test this, we directed the bots to visit (and collect cookies from) twenty websites, either related or unrelated to the conflict, prior to querying the search engines (\textit{Type 3} bots). If search engines do not personalize based on browsing history, these cookies should have no impact, and the results would mirror those of \textit{Type 2} (location and language) bots.
However, Figure \ref{fig:main_plot}, panel C (blue) shows that the average $D$ is even higher across all platforms, particularly for different locations (light versus dark blue) and for conflict-related queries (dashed versus solid columns). This held true even for DuckDuckGo, which claims not to use any user data, and for Google, despite the bots having no Google accounts. These findings remained consistent even when we compared the average $D$ values for only the 10 queries performed in this final experimental step (Figure \ref{fig:main_plot}, panel D, and Appendix, Figures \ref{fig:comparison_steps}).

Figure \ref{fig:main_plot}, panel D summarizes these findings: including browsing history (\textit{Type 3}, blue) increases variability in $D$, when compared to either \textit{Type 1} (green), or \textit{Type 2} (yellow) bots, and even more so for bots deployed in different locations (lighter versus darker colors). However, these differences were only significant in the case of Google (Appendix, Table  \ref{tab:p_values_comparison_different_steps} and \ref{table:stat_results}), possibly because of the very short, and not very nuanced, browsing profiles. Results for edit distance and list intersection can be seen in Figure \ref{fig:other_metrics_step_3}. 
%Future research should focus on creating more comprehensive and nuanced browsing history profiles. Nonetheless, it is noteworthy that, for Google, the comparisons of results of bots with different browsing histories were significant. 



% \begin{mybox}{Finding 3} Despite claims of limited or no personalization based on user information, browsing history influences the search engine displayed results, particularly for conflict-related queries. \end{mybox}

\begin{takeaway}
\takeawaytitle{}
Despite claims of limited or no personalization based on user information, browsing history influences the search engine displayed results, particularly for conflict-related queries.    
\end{takeaway}

% Once again we asked whether these differences in URLs also corresponded to differences in the topology of the results, that is, that search engines were not only retrieving different URLs possibly corresponding to more local sources, but whether they were actively retrieving different pages topologies. In Figure \ref{fig:rbo_per_category_website}, panel C, we observe that when we calculate the $D = 1-RBO$ for categories of websites and not URLs for Step 3, that differences become even more significant and once again, particularly, for the "specific" group of queries. 

\subsection{Differences in Search Engine Suggested Content}

One important question is whether the observed differences, especially between \textit{Type 1} and \textit{Type 2} bots, are mostly do to the search engines directing users to very similar content but in different local domains, which would appear as different URLs (for example, similar healthy recipes in different languages). To test this, we automatically classified all identified domains by category (e.g. News, E-Commerce Sports - see Methods and Appendix, Table \ref{tab:categories_category} and Figures \ref{categories_websites_general}, \ref{categories_websites_specific}) and recalculated $D$ for each category of websites. 

\begin{table}[t]
    \caption{Unique domains found by the bots in Step 1 of the experiment by search engine and for each category of queries.}
    \label{tab:categories_websites}
    \centering
    \begin{tabular}{p{1.2cm} p{1.2cm} p{4.3cm}} % Ensure width units (cm)
    \toprule
    Search\newline Engine & Query\newline Type &  Top 3 categories of \newline domains (\% prevalence) \\
    \midrule
    \multirow{2}{*}{\small DuckGo} & \small general & \small Lifestyle (26\%), Health (18\%), Entertainment (13\%)\\
    \cline{2-3}
    & \small specific & \small News (83\%), Reference (7\%), Education (3\%)\\
    \cline{1-3}
    \multirow{2}{*}{\small Google} & \small general & \small Lifestyle (16\%), Health (14\%), Business (10\%)\\
    \cline{2-3}
    & \small specific & \small News (61\%), Reference (17\%), Non-Profit (6\%)\\
    \cline{1-3}
    \multirow{2}{*}{\small Yahoo} & \small general & \small Lifestyle (26\%), Health (18\%), Entertainment (13\%)\\
    \cline{2-3}
    & \small specific & \small News (82\%), Reference (8\%), Education (4\%)\\
    \bottomrule
    \end{tabular}
\end{table}

As the number of categories is much smaller than the initial number of URLs (or even domains), the variability measured by $D$ is expected to be much smaller. However, Figure \ref{fig:rbo_per_category_website} shows that there are still important differences, except in the case of Yahoo. For Google and DuckDuckGo, we find larger $D$ values between bot profiles than within them (light versus darker colors), particularly for those that have collected cookies (blue colors) and even more so in the case of conflict-related queries (dashed columns). The same is verified for edit distance and list intersection (Figures \ref{fig:other_metrics_step_2}, \ref{fig:other_categories_step_2}, \ref{fig:other_categories_step_3}). Interestingly, these differences are still higher for the "specific" category of websites even when a single category, "News", (Table \ref{tab:categories_websites} and Appendix, Figure \ref{categories_websites_specific}) dominates the results. Together, this indicates that searches from different bot profiles retrieve not only different content, but also that this content is sufficiently different to be classified into broad, distinct categories.

%the proportion of results per website category is significantly smaller for the "general" results compared to the "specific" results (see Table \ref{tab:categories_websites}). This outcome is expected, as the topics in the general query category are considerably more diverse than those in the specific category (refer to Appendix, Table 5). 

%Recalculating $D$ (as shown in Figure \ref{fig}) to focus solely on domain categories reduces variance, resulting in a smaller y-scale than in Figure \ref{fig:main_plot}. Importantly, more differences exist between bot profiles than within them, indicating that searches from different bot profiles retrieve varied content and exhibit distinct topologies. Furthermore, the larger variance associated with general queries remains evident, particularly among Type 3 bots (in blue), despite the reduced variance in categories for this group. These analyses demonstrate that bots often return different content for identical queries based on their apparent profile.

\begin{figure}[t]
    \centering    \includegraphics[width=1\columnwidth]{Figures/rbo_categories.pdf}
    \Description{}
    \caption{Comparisons of ranked categories of websites for the three types of bots as in Figure 2. Only search results classified with a maximum of four different categories were considered, controlling for the number of queries per group. Error bars represent 95\% confidence intervals based on the bootstrapped distribution. P-values were calculated with Mann-Whitney U test and adjusted with Bonferroni correction.** denotes significant differences with a p-value less than 0.01 and * less than 0.05. Statistical details in Appendix, Tables \ref{tab:p_values_adjusted_categories_step_1}, \ref{tab:p_values_adjusted_categories_step_2}, \ref{tab:p_values_adjusted_categories_step_3}.}
    \label{fig:rbo_per_category_website}
\end{figure}

% \begin{mybox}{Finding 4}
% Distinct bot profiles are directed to URLs with different content. In the case of Google and DuckDuckGo, these differences are particularly pronounced for conflict-related, especially for bots that have collected cookies.
% \end{mybox}

\begin{takeaway}
    \takeawaytitle{}
    Distinct bot profiles are directed to URLs with different content. In the case of Google and DuckDuckGo, these differences are particularly pronounced for conflict-related, especially for bots that have collected cookies.
\end{takeaway}

% \subsection{The impact of increasing bots profiling on search engine results}

% In this work, we aimed to test how different features of online profiles affect search engine results. We did this by gradually adding features to the bots' profiles when they made the searches. The goal was to make the bots more like real users and simultaneously measure how each new feature influenced the personalization of search engine results. As detailed in the Methods after testing the impact of location in search engine results (step 1) we added browser language (step 2) and browser history to our bots (step 3). The results are detailed in the following sections. 

% We then asked if this variation in displayed URLs also corresponded to differences and content. The results displayed in \ref{fig: rbo_per_category_website}, panel B, show that our observations hold even when we calculate $D = 1-RBO$ for categories of websites. That is, search engines are presenting more divergent content to bots located at different countries and searching with different browser languages, with this content diverging more for searches specific to the conflict. 


\subsection{Leaning of Search Engine Results}

Even if the results and the page contents are different (and even if these differences increase when the profile of the bots becomes more detailed), it could still be argued that there is so much randomness in the algorithmic decisions of search-engines, that the observed variance would probably be inconsequential. Conversely, if the algorithms of search engines use information such as location and past browsing experience to customize political content, this could further amplify preexisting views. % and, as been extensively argued in the case of social networks, lead to the creation of "Echo-chamber" effects (REF). 
Therefore, we asked whether the differences in content, particularly in the case of the conflict-specific URLs, also reflect differences in leaning. We focused on the "News" category of websites, as it corresponds to the majority of results in the conflict-specific group of queries (Table \ref{tab:categories_websites}), and evaluated their leaning using both human coders and ChatGPT (Methods and Appendix, Figure \ref{prompt_leaning} and \ref{mturker_instructions}). 
As Figure \ref{leaning} shows, ChatGPT (top) classifies as neutral many more news than the human coders (bottom), with the MTurkers classifying more content as pro-Israel than pro-Palestine (more analysis on the level of agreement between chatGPT and MTurkers in Appendix, Figure \ref{heat_map}). Focusing on ChatGPT results, interestingly, we observe that as generally more news are classified as pro-Palestine (yellow - top panel), for all search engines, when we analyze the leaning of news present in the top 3 results, the number of pro-Israel significantly increases (particularly for Google). With Google having a tendency of showing even less pro-Palestine results for IL and US in the top 3 results. The same happens for DuckDuckGo. Impressively, Yahoo is quite consistent about the number of leaning articles showed to bots with different locations. 

When we focus on MTurk classifications (bottom panel), we observe the same tendency of decreasing the number of pro-Palestine articles in the top 3 results, with this behavior being more pronounced for IL for both DuckduckGo and Google. 

%\begin{mybox}{Finding 5}
%Bots located at different locations receive content with different %leanings regarding the conflict, according to both ChatGPT and %Mturkers. Duckduckgo and Google tend to show more pro-Israel content in their top 3 results, with a decrease in pro-Palestine, and this decrease is dependent of the bot location. 
%\end{mybox}

\begin{takeaway}
\takeawaytitle{}
Bots at different locations receive content with different leanings regarding the conflict, according to both ChatGPT and MTurkers. Duckduckgo and Google tend to show more pro-Israel content in their top 3 results than in All, with a decrease in pro-Palestine, dependent on the bot location.
\end{takeaway}

% \begin{table}[t]
%     \caption{Percentage of the most common 10 news websites.}
%     \label{tab:unique_domains_step_1}
%     \centering
%     \begin{tabular}{p{1cm} p{1.5cm} p{1cm} p{0.5cm} p{0.5cm} p{0.5cm} p{0.5cm} p{0.5cm}}
%     \toprule
%     Search Engine & Location & Type & NYT & CNN & BBC & Reuters & Aljazeera \\
%     \midrule
%     \multirow{6}{*}{Bing} & \multirow{3}{*}{BR} & step\_1 & 16.21 & 16.13 & 11.64 & 9.99 & 8.03 \\
%     & & step\_2 & 11.21 & 12.62 & 18.69 & 6.07 & 6.85 \\
%     & & step\_3 & 7.99 & 13.44 & 20.24 & 5.44 & 9.35 \\
%     \midrule
%     & \multirow{3}{*}{IL} & step\_1 & 14.02 & 10.58 & 8.26 & 7.15 & 14.21 \\
%     & & step\_2 & 9.09 & 10.39 & 5.19 & 11.69 & 20.78 \\
%     & & step\_3 & 9.00 & 14.00 & 7.00 & 2.00 & 24.00 \\
%     \midrule
%     \multirow{6}{*}{Duckduckgo} & \multirow{3}{*}{BR} & step\_1 & 17.09 & 12.56 & 6.43 & 7.64 & 11.66 \\
%     & & step\_2 & 12.59 & 14.63 & 15.11 & 6.95 & 8.99 \\
%     & & step\_3 & 10.99 & 14.15 & 17.41 & 5.11 & 7.29 \\
%     \midrule
%     & \multirow{3}{*}{IL} & step\_1 & 17.33 & 13.64 & 8.51 & 7.49 & 9.85 \\
%     & & step\_2 & 13.97 & 10.22 & 12.59 & 4.36 & 12.97 \\
%     & & step\_3 & 16.44 & 6.75 & 11.04 & 3.93 & 13.62 \\
%     \midrule
%     \multirow{6}{*}{Google} & \multirow{3}{*}{BR} & step\_1 & 3.73 & 0.00 & 3.73 & 17.91 & 16.42 \\
%     & & step\_2 & 0.00 & 9.05 & 12.22 & 11.76 & 13.12 \\
%     & & step\_3 & 2.75 & 2.67 & 9.58 & 16.40 & 18.06 \\
%     \midrule
%     \multirow{6}{*}{Yahoo} & \multirow{3}{*}{BR} & step\_1 & 15.36 & 10.38 & 8.75 & 3.97 & 9.56 \\
%     & & step\_2 & 14.42 & 12.73 & 11.42 & 4.12 & 9.18 \\
%     & & step\_3 & 16.73 & 11.23 & 11.10 & 5.38 & 9.14 \\
%     \midrule
%     & \multirow{3}{*}{US-NY} & step\_1 & 16.02 & 9.03 & 9.24 & 3.90 & 10.37 \\
%     & & step\_2 & 16.36 & 12.83 & 10.97 & 3.90 & 9.85 \\
%     & & step\_3 & 15.31 & 9.01 & 10.10 & 4.03 & 10.01 \\
%     \bottomrule
%     \end{tabular}
% \end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=1\columnwidth]{Figures/leaning.pdf}
    \caption{Proportion of news articles classified as being "neutral" (grey), "pro-Israel" and "slightly pro-Israel" (blue tones) and as being "pro-Palestine" and "slightly pro-Palestine" (yellow tones), for each country (y-axis) and search engine. The top panel shows ChatGPT classification considering all news results and the news present in the first 3 results of the pages. Bottom panel, 
    same, but with human classification.}
    \label{leaning}
    \Description{}
\end{figure}

