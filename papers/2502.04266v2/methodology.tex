Our methodology relies on a Web crawling system, specifically developed to explore how search engine results may change for different user profiles. It enables the execution of Web crawlers (\textit{bots}) that can mimic typical online user behavior, be deployed to different locations, and make queries that are either related to the Israel-Palestine conflict or more general, non-sensitive queries. Figure \ref{scheme_methodology} summarizes our methodology for developing and implementing this querying and auditing system. It is divided into three main stages: \textit{1)} design of each bot, including its incremental feature design and deployment, \textit{2)} audit of search engine results, and \textit{3)} evaluation of search result differences in terms of URLs, content, and possible leaning.

\subsection{Bots and their Incremental Design}
The reasoning for using bots is twofold: (1) this approach allows precise control over key aspects of their online profiles. Unlike real user data, this systems makes it possible to isolate and analyze how specific factors, such as location or browsing history, influence search engine results. (2) Bots eliminate the ethical concerns of asking real users for their profiles or search histories, as this sometimes implies access to personal and sensitive information. Moreover, asking individuals to query search engines for potentially sensitive content, could affect their future online experience.

\subsubsection{Bots:} We developed each bot by extending the functionalities of OpenWPM\footnote{\url{https://github.com/openwpm/OpenWPM}} (Version 0.28.0), a community-trusted and flexible instrument for internet measurements and automating web browsing\cite{englehardt2016census}. 
Given the public policies of search engines (Table \ref{engines_policies}), previous results \cite{inconsistent_search_results, partisan_audience_bias, political_personalization}, and the geographical implications of the Israel-Palestine conflict, this work explores the influence of bots' (1) location, (2) browser language, and (3) browsing history on search engine results.
The bots were built using selenium and deploy version 123 of the Firefox browser, which can be parallelized and allows control of location and browsing settings such as language, cookies, and other forms of tracking, as detailed below:

\mypara{Location:} To change the location of the bots, Firefox settings were adjusted to use residential ISP proxies provided by Bright Data\footnote{\url{https://brightdata.com}}. %Similar to a typical VPN system, 
ISP proxies act as intermediate remote services for Internet access, masking the original source of the HTTP request. Using this system, the bots were placed in one of four locations: Israel (IL), Saudi Arabia (SA), Brazil (BR), and New York, United States (US-NY). Israel was selected due to its direct involvement in the conflict, with a majority Jewish and Hebrew-speaking population. Since Bright Data did not offer ISP proxies for Palestine, Lebanon, or Iran, Saudi Arabia was chosen for its majority Muslim and Arabic-speaking population. New York and Brazil were chosen as not-directly involved controls: New York due to its sizable Jewish community \cite{pew2015religious}, and the U.S.'s strong support for Israel, and Brazil as a more neutral location \cite{pew2013brazil}, with less support for Israel, and having a predominantly Christian population.

\mypara{Browser Language:} To simulate Internet access with browsers in the predominant language of the aforementioned locations, the Firefox language settings for each bot location were adjusted accordingly: Hebrew for Israel, Arabic for Saudi Arabia, Portuguese for Brazil, and English for the United States.

\mypara{Browsing History:} Online activity and browsing history (website visits, content interactions, etc.) can be tracked through cookies placed by first- and third-party sites, or by the specific configuration of the device and browser used to access the internet (fingerprinting)~\cite{cookiless_monster, stop_tracking_me_bro, webbrowsing_fingerprinting}. By instructing the bots to visit different online content (and saving the resulting tracking data), we aimed to create distinct browsing histories outside of the search engine platforms.

We created two types of browsing profiles by having the bots visit two types of URLs: (1) of local news that contained one of the keywords ``Palestine,'' ``Israel,'' ``Hamas,'' and ``Netanyahu'' (conflict-related, or specific), or (2) of local news that included the keywords ``movie,'' ``health,'' ``well-being,'' ``dinner recipe,'' and ``sports'' (non-conflict related, or general). The words were translated to the used languages (Hebrew, Arabic, Portuguese), to collect local news in the most spoken language of the country.
In both cases, the URLs were obtained through Media Cloud\footnote{\url{https://www.mediacloud.org/}}, a free and community supported tool that allows the retrieval of news articles from keywords, while filtering for location and time. The two lists of news URLs were obtained for each of the four selected locations, from October 7, 2023 to March 30, 2024.

%Extending predefined functions of the OpenWPM tool, 
The bots were instructed to visit sequentially 20 randomly selected websites, from one of the two lists (Figure~\ref{scheme_methodology}, 1A). During these visits, the bots collected and saved all tracking data (such as cookies, JavaScript fingerprinting files, and HTTP requests -- Figure~\ref{scheme_methodology}, 1B). This data was then stored in Firefox's profiles, which contained the bots' full browsing history and tracking information. 

\subsubsection{Incremental Design and Deployment:} 
To study the impact of these three features (location, browser language, and browsing history) on search engine results, we deployed three types of bots with an increasing number of features. \textit{Type 1} are bots specified to be solely associated to one of the four locations, \textit{Type 2} are bots that have both different location and browsing languages, and \textit{Type 3} are bots that diverge in their location, browser language, and browsing history (Figure~\ref{scheme_methodology}). Importantly, the bots of \textit{Type 3} were deployed simultaneously with bots having no browsing history (equivalent to a bot of \textit{Type 2}) as a temporal control. The table on the right side of Figure~\ref{scheme_methodology} presents a summary of the features used by each type of bot, as well as the number (last column) deployed by type. 


% \noindent\textbf{Type 1 - Location only:} OpenWPM bots are built using the selenium tool and they deployed the 123 version of the Firefox browser. In this step we adapted the settings of the Firefox to accommodate for a Internet Service Providers (ISP) proxies provided by BrightData \cite{brightdata}. 

% Using the Israeli-Palestinian conflict as a case study, the locations of the bots were selected taking into consideration its geographical implications. Therefore, we placed bots in one of four locations - Israel (IL), Saudi Arabia (SA), Brazil (BR) and the United States (US, specifically, New York). Israel was chosen given its direct implication with the conflict, having a majority Jewish and hebrew-speaking population. BrightData did not offer ISP proxies for Palestine and Saudi Arabia was chosen for having a majority Muslim and Arabic-speaking community. New York and Brazil were chosen as non-directly involved controls. New York was chosen because it hosts a considerable Jewish community \cite{pew2015religious} and the US has shown strong support for Israel. Brazil was chosen as a more neutral location \cite{pew2013brazil}, where the population is mostly Christian and Portuguese-speaking.

% In this experimental phase, using Type 1 bots, we deployed 10 bots per location, each with a unique IP address. Since not all ISP proxies were consistently successful, we initially deployed 10 bots to ensure a statistically significant number of successful audits per location. 

% \vspace{0.2cm}
% \noindent\textbf{Type 2 - Location + browser language:} Building on the bot profiling, we deployed a second type of bot that varied not only by location but also by the browser language used to access and query search engines. This was achieved by adjusting the language settings in the Firefox browser. Each bot's browser was configured to match the primary language spoken in the country where it was deployed: Hebrew for Israel, Arabic for Saudi Arabia, Portuguese for Brazil, and English for the U.S. (New York). As in the previous phase, 10 different bots were deployed for each location and language combination.

% \vspace{0.2cm}
% \noindent\textbf{Type 3 - Location + browser language + browsing history:} In the third phase of our experimental design, we deployed bots that varied not only by location and browser language but also by their browsing history. This was achieved by using predefined functions in the OpenWPM tool to instruct the bots to visit 20 different websites, randomly selected from one of two lists. During these visits, the bots collected and saved all tracking data (such as cookies, JavaScript fingerprinting files, and HTTP requests). This data was then stored in Firefox browser profiles, which contained the bots' full browsing history and tracking information. These profiles were then used to conduct the search engine audits described below.

% Two distinct types of browsing histories were created: one focused on conflict-related content and another on unrelated, neutral content. To achieve this, we built two separate lists of news URLs—conflict-related and non-conflict-related—that the bots were instructed to visit, as previously detailed. For both lists, we used Media Cloud to retrieve all news URLs published between July 10, 2023 (the start of the conflict), and March 30, 2024, in four different languages (English, Portuguese, Arabic, and Hebrew). The conflict-related history contained visits to URLs with the following keywords: "Palestine," "Israel," "Hamas," and "Netanyahu". For the unrelated browsing history, the URLs included terms such as: "movie," "health," "well-being," "dinner recipe," and "sports."

% Three different bots were deployed per browsing history associated with each location and respective language. For control purposes, these bots performed the search engine audit, simultaneously with two stateless bots, as summarized in Table \ref{bot_configurations}.

% \begin{table}[t]
% \centering
% \begin{tabular}{>{\raggedright\arraybackslash}p{0.6cm}|>{\raggedright\arraybackslash}p{1.2cm}|>{\raggedright\arraybackslash}p{1.4cm}|>{\raggedright\arraybackslash}p{1.7cm}|>{\raggedright\arraybackslash}p{1.5cm}}
% \toprule
% \textbf{Type} & \textbf{Location} & \textbf{Browser Language} & \textbf{Browsing History} & \textbf{N\newline bots} \\ 
% \midrule
% & IL & \_ & \_ & 10 \\ 
% Type & BR & \_ & \_ & 10 \\ 
% \centering{1} & SA & \_ & \_ & 10 \\ 
% & US-NY & \_ & \_ & 10 \\ 
% \midrule
% & IL & he & \_ & 10 \\ 
% Type & BR & pt-BR & \_ & 10 \\ 
% \centering{2}& SA & ar & \_ & 10 \\ 
% & US-NY & en-US & \_ & 10 \\ 
% \midrule
% & \multirow{3}{*}{IL} & \multirow{3}{*}{he} & conflict\_news & 3 \\ 
% &  &  & general\_news & 3 \\ 
% &  &  & stateless & 2 \\ \cline{2-5}
% & \multirow{3}{*}{BR} & \multirow{3}{*}{pt-BR} & conflict\_news & 3 \\ 
% &  &  & general\_news & 3 \\ 
% Type &  &  & stateless & 2 \\ \cline{2-5}
% \centering{3} & \multirow{3}{*}{SA} & \multirow{3}{*}{ar} & conflict\_news & 3 \\ 
% &  &  & general\_news & 3 \\ 
% &  &  & stateless & 2 \\ \cline{2-5}
% & \multirow{3}{*}{US-NY} & \multirow{3}{*}{en-US} & conflict\_news & 3 \\ 
% &  &  & general\_news & 3 \\ 
% &  &  & stateless & 2 \\ 
% \bottomrule
% \end{tabular}
% \caption{Summary of bot types, the features used and respective number of bots associated with each configuration.}
% \label{bot_configurations}
% \end{table}


\subsection{Search Engine Audit} 
In our study, three search engines were audited - DuckDuckGo, Google and Yahoo. Google was chosen for being the most used search engine worldwide; DuckDuckGo for its emphasis on privacy; and Yahoo for its association with a popular email service and extensive claims of extensive personalization.  

\subsubsection{Audit:} In each search engine audit, multiple bots -- each associated with different online user characteristics (see Table in Figure~\ref{scheme_methodology}) -- are simultaneously deployed on the same search engine. These bots input identical queries and collect the resulting URLs along with their rankings. This process is repeated across various queries and applied to the three search engines. To minimize the risk of carry-over effects (where previous searches could influence current results~\cite{personalization_web_search}), each audit begins with the same initial user profiles, launched in fresh browser instances.

Three audits were conducted between March 30 and May 4, with each audit lasting an average of two days and involving the deployment of bots of all types (Appendix, Figure~\ref{timeline}). Notably, in audits using Type 2 (location + browser language) and Type 3 (location + browser language + browsing history) bots, search engines automatically prioritized local results based on the language. 

To account for potential temporal fluctuations in ranking algorithms, two strategies were employed: (1) conducting simultaneous searches on the same search engine to minimize short-term variations, and (2) performing audits at least twice over distinct time points to address longer-term changes. 

\subsubsection{Search engine queries:}
Queries were split into two categories: ``general'' (denoted by the solid columns in the figures presenting our results, i.e., Figures~\ref{fig:main_plot} and~\ref{fig:rbo_per_category_website}) and ``conflict-specific'' (dashed columns in said figures). The first category comprises 27 popular and conflict-independent queries such as ``Home workout routines'', ``Popular books 2024'', ``how to tie a tie''. (Table~\ref{tab:queries_long_table}, column 2). 
The second category, specific to the conflict (e.g., ``military complex Al-Shifa hospital,'' ``Hamas rapes''), were defined in collaboration with the NGO HoneyComb, an investigative journalism association that tracks controversial online content, including disinformation. HoneyComb provided 10 distinct topics that were expanded using ChatGPT 3.5, to generate 27 specific queries (Table~\ref{tab:queries_long_table}, column 1).

A total of 27 queries per group (general and conflict-specific) were executed during the search engine audits for both Type 1 and Type 2. The audit deploying Type 3 bots performed a subset of 10 queries of the original set (Appendix, Table \ref{tab:queries_long_table}, text in bold). To maintain statistical integrity, each comparison of results ensured a consistent number of bots (accounting for occasional IP failures, Appendix \ref{number_successful_ports}) and queries per location (Appendix \ref{tab:number_queries_successful}). 

% \subsubection{VPN system, locations and languages}
% %add the bright data, details etc
% Bot location was set using Internet Service Providers (ISP) proxies provided by BrightData \cite{brightdata}. Each bot could be associated with only one of four locations: Israel (IL), Saudi Arabia (SA), Brazil (BR) and the United States (US, specifically, New York).
% Israel was chosen given its direct implication with the conflict, having a majority Jewish and hebrew-speaking population. BrightData did not offer ISP proxies for Palestine and Saudi Arabia was chosen for having a majority Muslim and Arabic-speaking community. New York and Brazil were chosen as non-directly involved controls. New York was chosen because it hosts a considerable Jewish community \cite{pew2015religious} and the US has shown strong support for Israel. Brazil was chosen as a more neutral location \cite{pew2013brazil}, where the population is mostly Christian and Portuguese-speaking. 

% \subsection{Incremental Personalization Approach}

% \subsubsection{Step 1 - Different geolocations}

% %Given the geolocation constraints of the Israel - Palestine conflict we started this study by asking: what impact does varying geographical locations have on the information retrieved from search engines? Particularly for queries related to the conflict? To evaluate the level of personalization due to location, we deployed bots solely diverging in their locations. To change the location of the 
% To investigate the impact of geolocation, ten different stateless bots were deployed per location, ensuring that each bot used a different IP address. Therefore, on each of these audits, forty bots (10 bots x four locations), simultaneously queried the same search engine. The queries were randomly selected from Table 1. 
% This process iterated until all search engines (Google, Bing, Yahoo, and DuckDuckGo) and all queries were examined (Figure \ref{scheme_figure}). 
% In this step, all the bots were deployed fixing the browser-language of the OpenWPM browser (Firefox) to English, to isolate the potential impact of geolocation. 

% \subsubsection{Step 2 - Different Languages}

% %In this study, our focus extended beyond exploring the isolated impact of individual web user features on search engine personalization. Rather, our primary interest lays in understanding the cumulative effect of multiple features operating together, as we believe this better simulates the overall personalization a general user receives. Therefore, in 
% To investigate the impact of language, step 1 was repeated with the different reference languages (Hebrew for Israel, Arabic for Saudi Arabia, American English for the United States and Brazilian Portuguese for Brazil - Figure \ref{scheme_figure}). As changing the language of the browser did not automatically changed the language of all search engines (and defining the language of the search engine could trigger or not the option of local results), all settings - browser, search-engine and searches were set independently, asking search-engines to prioritize local results. 

% \subsubsection{Step 3 - Previous Browsing History}

% To investigate the influence of browsing history on search engine outcomes we built different online profiles prior to deploying the bots to the search-engines.

% %. Our focus was in  understanding how different online information consumption habits — such as engagement with content related with the conflict or unrelated (e.g., health, sports, fashion, movies) — shape search engine results. In other words we questioned whether having a previous browsing history of consuming information related with the conflict affected search engine results. 

% The bots were directed to visit news articles related or not-related with the conflict. Through these visits they collected cookies (from the websites and encountered adds), allowing for increased personalization.
% The visited URLs were selected through Media Cloud from 7/10/2023 (when the conflict started) to 30/03/2024, in the 4 different languages (English, Portuguese, Arabic and Hebrew). 
% The URLs related with the Israel-Palestine conflict included the keywords palestine, israel, hamas and netanyahu and the URLs unrelated with the conflict included the keywords ''movie, health well-being, dinner recipe and sports.
% Three bots (profiles) were created per category (related or not-related), by visiting 20 random URLs from one or from the other group, for each of the four locations. 
% A total of 24 profiled bots (3 profiles x 2 categories x 4 locations + 2 stateless = 24) plus 2 stateless bots, (no browsing history) were deployed to the three search engines. They were set to use the location's majority language and performed 10 of the possible specific or non-specific queries (randomly selected from Table 1).   

% \subsection{Temporal variation}
% %if we do the 4th period, describe here

\subsection{Quantifying Differences in Search Results}

After collecting search engine results and their respective rankings, the differences across different bot profiles were analyzed. This analysis was conducted in the three stages described next.
%: (1) Quantifying differences in URLs, (2) Quantifying differences in content, and (3) Measuring leaning of the search results.

\subsubsection{Quantifying Differences in URLs:}
To compare two lists of URLs returned by search engines queries (i.e., [website\_1.com, website\_2.com, ...] vs. [website\_3.com, website\_1.com, ...]), both the provided links and their order was considered, as users typically prioritize top results over lower-ranked ones \cite{Fay2024b}. The Rank-Biased Overlap (RBO) metric \cite{similar_measure} was used, which calculates how similar two lists are (0 totally different, 1 equal), considering the order of the items and different list sizes \cite{similar_measure}:

\[
\text{RBO}(S, T, p) = (1 - p) \sum_{d=1}^{\infty} p^{d-1} \cdot \frac{|S_{1:d} \cap T_{1:d}|}{d}
\]
where $S$ and $T$ are two ranked lists, $d$ is the rank and $p$ determines the top-weightiness of the metric. For our analysis, $p$ was set to 0.7, meaning that the first 10 results account for 99\% of the total value of the calculated RBO. The differences between two lists of search engine URLs results were calculated as $D = 1 - RBO$. Other metrics, such as edit distance and intersections of lists were also applied and gave similar results. 

\subsubsection{Quantifying Differences in Content}
To account for the possibility that the bots are receiving similar results through different local or language specific URLs (e.g.wikipedia.il vs. wikipedia.br), we classified all domains encountered (by the three types of bots, for both types of queries) in broad categories (e.g. Entertainment, News, etc.). The classification was initially done automatically by ChatGPT-4o, and then manually verified by one of the researchers for all domains (Appendix, Table \ref{tab:categories_category}).
%to classify all these domains according to their type and category . 
After this classification was performed, the same measurement, $D = 1 - RBO$ was computed, but considering lists of websites categories ([[News\_1, Political\_1, ...] vs. [Political\_1, News\_1...]), instead of the URL lists. 

\subsubsection{Quantifying Differences in Leaning}
To quantify whether the bots received results with particular leanings regarding the conflict, we focused on the URLs from domains classified as ``News'', for the 10 searches that were common to bots of all three types (see Appendix, Table \ref{tab:queries_long_table}). These articles were scraped, all domain-related information removed, and their title and content collected and automatically translated to English, to minimize possible coder bias from knowing the language or the news source.

Two approaches were used to quantify leaning on a common scale (pro-Israel, slightly pro-Israel, neutral, slightly pro-Palestine, pro-Palestine): asking the GPT-4o API (Appendix, Figure \ref{prompt_leaning}), and asking workers hired through the MTurk platform (Appendix, Figure \ref{mturker_instructions}). In both cases, the prompt was: ``Pro-Israel or pro-Palestine means that the text favors the narrative of that side of the conflict, or elicits sympathy towards it.'' MTurkers that classified texts had to pass two attention controls in a recruitment stage and during the entire classification task (per survey). For our analysis, we exclusively selected news texts that were classified by at least two MTurkers, with both attributing the same classification to the text.
 