Here, we discuss some of the weaknesses and threats to validity: %Some of the strengths of this study, such as not using human data and using an incremental, combinatorial approach, also work as weaknesses as detailed below:

\mypara{1. Non-human queries}: Despite our best efforts, the bots do not perfectly mimic humans and, if identified as bots, the search engines might handle the their queries differently than they would the human-generated traffic. To minimize this, we coded the bots to act more human-like (introducing delays, natural ``typing'', avoiding VPN farms, etc.) and we have reason to believe that they were only rarely identified as such (e.g. we received few ``captcha'' requests and only some queries failed). Also, the bots have none (\textit{Type 1} and \textit{Type 2}) to limited (\textit{Type 3}) browsing history, and this could limit personalization of the results.  However, that even such a conservative approach managed to reveal significant differences for conflict-specific queries, should raise important alarms, as these are likely to be even higher for human queries. In the future, audits could enhance the realism of the bots by increasing browsing history (breadth and size) and adding features such as search language or social media profiles.
    
\mypara{2. Combinatorial complexity}: The incremental and combinatorial system design led to a rapid increase in the number of variables, making exhaustive testing complex and expensive. \textit{Type 3} bots only queried approximately one third of the original list and we used a conservative approach to their selection: the selected 10 queries were the ones for which \textit{Type 1} and \textit{Type 2} bots had the smallest differences in $D$, between locations. Thus, it is possible that if other queries had been chosen the observed effects would have been larger, but it is unlikely they would have been smaller.

\mypara{3. Geographical IP limitations}: No IP addresses were used from countries historically more supportive of Palestine, such as Lebanon and Iran. Our choice of Saudia Arabia was not ideal, particularly as most searches were done in English, and this omission may limit the identification of clearly pro-Palestine content in this region. Even though we used residential proxies, typically very hard to identify, occasionally they failed for unknown reasons (see Appendix \ref{number_successful_ports}). 
    
\mypara{4. Dynamic nature of search engines}: That the algorithms of search engines are both fast-evolving and proprietary means that even minor variations in the timing of our audits could yield different results. To control for such temporal fluctuations, particularly during such a fast-evolving situation, we repeated the same queries for stateless Type 2 bots three times and observed no temporal trend (Appendix, Figures \ref{time_control_1}, \ref{time_control_2}, \ref{time_control_3}, \ref{time_control_4}). Future studies should update testing protocols more frequently and include more queries, search engines, and LLM-based interfaces.
 
\mypara{5. Analysis of leaning}: There is no objective metric of leaning and there were significant differences in classification between ChatGPT and human coders. In particular, ChatGPT was more likely to consider as neutral, news that the humans identified as being more favorable to Israel. Future work should have more coders, from different locations and/or include expert coders.
