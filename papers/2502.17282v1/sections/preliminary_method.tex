\section{Preliminary}

We begin by discussing the key elements and the pipeline of model selection, followed by the evolution of related works.


\begin{figure*}[t]
    \centering
    \vspace{-10pt}
    \includegraphics[width=0.98\textwidth]{figures/compared.pdf}
    \caption{\textbf{Illustration of Model Routing with Capability Instructions: A Comparison with Re-ranking Based Methods.} The goal of model router is to select the optimal model for a given user instruction without access to ground truth and enhance overall performance. Previous re-ranking methods require inference for each candidate. \textsc{Model-SAT} employs a lightweight aptitude test to create capability representations. It learns the intrinsic relationship between model representations and the instructions to be assigned, significantly speeding up model routing and streamlining deployment.}
    \label{fig:related_works}
    \vspace{-10pt}
\end{figure*}

\subsection{Instruction, Output, and Answer}

Consider a test instruction dataset $\mathcal{D}_{\text{test}} = \left\{ \left(\mathbf{x}_i, \mathbf{a}_i \right)\right\}_{i=1}^{N}$ with $N$ labeled samples. The $\mathbf{x}_i$ and $\mathbf{a}_i$ represent the instruction and its corresponding answer, respectively.
Given an LLM or its extension, represented as $f$, the output generated for instruction $\mathbf{x}_i$ is denoted as $\mathbf{o}_i$, \textit{i.e.}, $f(\mathbf{x}_i) = \mathbf{o}_i$.
There are no restrictions on the language, domain, or modality of $\mathbf{x}_i$; In this paper, we focus on decoder-only text generation models, which means that $\mathbf{a}_i$ is typically presented in text form.
For the model $f$ to excel at instruction $\mathbf{x}_i$, it is equivalent to obtaining a high score on the evaluation $\operatorname{eval}\left( \mathbf{o}_i, \mathbf{a}_i \right)$.

\subsection{Pipeline of Model Routing}

Consider a candidate model zoo composed of many trained LLMs, $\mathcal{M} = \left\{f^m\right\}_{m=1}^{M}$. Model routing involves selecting a model from the zoo for each instruction $\mathbf{x}_i$ in the test dataset $\mathcal{D}_{\text{test}}$.
Specifically, the sequence of selected models is formalized as $\boldsymbol{f} = (f_1, f_2, \dots, f_N)$, where $f_i \in \mathcal{M}$.
We define the optimal model $\hat{f}$ for instruction $\mathbf{x}_i$ as the model that maximizes the score: $\operatorname{eval}\left(\hat{f}(\mathbf{x}_i), \mathbf{a}_i \right)$.
The objective of the instruction-level model routing is:
\begin{equation}
    \hat{\boldsymbol{f}} = \left( \underset{ {f}^m \in \mathcal{M} }{\arg \min } \; \ell \left({f}^m \left( \mathbf{x}_i \right),\; \mathbf{a}_i \right) \right)_{i = 1}^{N}\;,\label{eq:objective}
\end{equation}
where $\ell \left( \cdot \right)$ represents the loss function associated with the metrics between $\mathbf{o}^m_i = f^m(\mathbf{x}_i)$ and the ground truth $\mathbf{a}_i$.
The model routing bottleneck arises from the number of instructions on which no model in the zoo performs well.

\subsection{Revisit from Requirement, Target, and Key Inputs}

\textbf{Routing target} of \textit{parameter initialization} or \textit{models with zero-shot capabilities}: Early model router~\cite{tran2019transferability, nguyen2020leep,DBLP:conf/cvpr/TanLH21,DBLP:conf/eccv/DingCLCS22} efforts primarily focus on identifying a good training initialization that facilitates fine-tuning downstream tasks to achieve optimal performance. In this context, candidate models likely required additional training to adapt to the target task.
Recently, guided by scaling laws, foundational models like LLMs have experienced remarkable advancements in their zero-shot capabilities~\cite{touvron2023llama2,wei2022finetuned,team2023gemini}.
Extended models have demonstrated considerable potential in multilingual, multi-domain, and multimodal applications. For instance, Llama 3.1~\cite{dubey2024llama3herdmodels} serves as a multilingual agent, Qwen2-Math~\cite{yang2024qwen2technicalreport} tackles several Olympiad-level problems, and GPT-4o~\cite{openai2023gpt4} processes information from multiple sources.

\begin{figure*}[t]
    \centering
    \vspace{-10pt}
    \includegraphics[width=0.98\textwidth]{figures/example_cap_instruction.pdf}
    \caption{\textbf{One example of a Capability Instruction.} It is an instruction for model routing that inquires whether a model can handle a specific user instruction. It comprises three components: the capability representation $\texttt{c}^m$ based on the streamlined aptitude test, the user instruction $\mathbf{x}_i$ to be assigned, and a performance inquiry prompt $\texttt{p}$. This instruction is inputted into the \textsc{Model-SAT} Capability LLM, which outputs the probability that the model can perform the user instruction well.}
    \label{fig:capability_instruction}
    \vspace{-5pt}
\end{figure*}

\begin{figure}[t]
    \vspace{-10pt}
    \centering
    \includegraphics[width=0.48\textwidth]{figures/architecture.pdf}
    \caption{The Architecture of \textsc{Model-SAT}.}
    \label{fig:architecture}
    \vspace{-10pt}
\end{figure}

\textbf{Routing requirements} with \textit{target instruction annotation}, \textit{backpropagation delay}, or \textit{candidate output}: Some works~\cite{bao2019information,li2021ranking,DBLP:conf/icml/YouLWL21,deshpande2021linearized,DBLP:conf/cvpr/PandyAUFM22} design the proxy metric of transferability, which approximates the lower bound of fine-tuned performance. These works often rely on certain source clues, labeled instructions, or backpropagation steps to assess the transferability from the source pre-trained model to the target dataset.
Additionally, some re-ranking-based works~\cite{DBLP:journals/corr/abs-2311-06720,bge_embedding,zhang2024mgte} train an extra model to learn the contrastive relationships between the instruction and the candidate inference outputs $\left\{ \mathbf{o}^m_i \right\}_{m=1}^{M}$, routing the optimal one linked to model $f^m$.
However, obtaining all inferences may introduce significant delays when the number of models $M$ in the repository becomes excessively large~\cite{shnitzer2023large,lu2023routing,hu2024routerbench}.
Our \textsc{Model-SAT} aims to route models without annotation or inference requirements, considering candidates as black boxes.
A central feature is constructing model representations for each model and learning the adjusted relationship between it and the target instructions.

\textbf{Key input} -- \textit{model representation} for model routing:
When routing a model for instruction, the router requires the key representation that captures the model's characteristics. We followed the concept of learnware~\cite{DBLP:journals/fcsc/Zhou16a}, leveraging a small amount of model-proficient data to construct shared specifications~\cite{DBLP:journals/chinaf/ZhouT24,DBLP:conf/kdd/TanLBTZLXZYZ24}.
Other relevant methods leverage forward behavior or results on target as model representation, which inevitably introduces inference delays.
Recently, some approaches~\cite{lu2024blending,srivatsa2024harnessing,ding2024hybrid,DBLP:journals/corr/abs-2410-03834} have started to utilize learnable parameters as model representations.
For instance, some introduce a surrogate scorer as the corresponding model representation, learning the mapping from the task to the accuracy of candidate model outputs.
Model Spider~\cite{DBLP:conf/nips/ZhangHDZY23} takes this concept by encoding the model representation into a learnable vector, which acts as the input token for a Transformer-based router. However, learnable representation face challenges when new models are introduced, as they require extensive historical performance for costly pre-training of the router.
Our solution uses text-only descriptions of capabilities. New models can create representations by inferring 50 quick tasks, each with 20 shots.
