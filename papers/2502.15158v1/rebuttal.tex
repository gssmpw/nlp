Dear INTERSPEECH 2024 Technical Committees,

We are grateful for the insightful reviews and valuable feedback provided on Paper 1971. We appreciate the opportunity to address the reviewers' concerns.

Reviewer #4: Comparison with Similar Ideas (eg: Chunk-Based)
Our approach was indeed compared to the chunk-based method [13, 17, 18], a relevant technique. The results of this method are presented in Table 2 (A, C), and all experiments are clearly outlined in Section 3.1.

Reviewer #5: Experiment on additional dataset
While not mentioned, we also applied our techniques to a large-scale dataset (25.000 hours), achieving improvements in practical application. Unfortunately, due to confidentiality constraints, we were unable to include this dataset and its results in the end. However, we ensure the effectiveness of our proposal across various domains and datasets.

Reviewer #7: 
1. Confusion about AED Model Applicability
We acknowledge the confusion regarding the phrase "applicable for any streaming E2E ASR models built on attention-based architecture" for label-synchronous AED models. When referring to "streaming E2E ASR models," we meant inherently streamable models (time-synchronous) that don't require additional modules for streaming like CTC or RNN-T. AED models, with cross-attention, are not inherently streamable as the language part needs the whole speech for complete text output. While alignment modules like trigger attention can make AED streamable, combining it with TSCA is beyond this paper's scope. We will revise the phrase for clarity in the final version.
2. Latency Discussion
We regret the omission of absolute latency figures due to space constraints. Nonetheless, the influence of TSCA on relative latency can be inferred from the selection of chunk size and right context size.

We appreciate the reviewers for pointing out errors and providing suggestions for our paper, which will be duly addressed in the final version. 
Thank you for being so considerate!
