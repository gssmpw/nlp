@article{reid2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Reid, Machel and Savinov, Nikolay and Teplyashin, Denis and Lepikhin, Dmitry and Lillicrap, Timothy and Alayrac, Jean-baptiste and Soricut, Radu and Lazaridou, Angeliki and Firat, Orhan and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{bertsch2024context,
  title={In-context learning with long-context models: An in-depth exploration},
  author={Bertsch, Amanda and Ivgi, Maor and Alon, Uri and Berant, Jonathan and Gormley, Matthew R and Neubig, Graham},
  journal={arXiv preprint arXiv:2405.00200},
  year={2024}
}

@article{gao2022pal,
  title={PAL: Program-aided Language Models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  journal={arXiv preprint arXiv:2211.10435},
  year={2022}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{suzgun2022challenging,
  title={Challenging big-bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@article{samek2021explaining,
  title={Explaining deep neural networks and beyond: A review of methods and applications},
  author={Samek, Wojciech and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Anders, Christopher J and M{\"u}ller, Klaus-Robert},
  journal={Proceedings of the IEEE},
  volume={109},
  number={3},
  pages={247--278},
  year={2021},
  publisher={IEEE}
}

@book{williams2006gaussian,
  title={Gaussian processes for machine learning},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@article{williams1995gaussian,
  title={Gaussian processes for regression},
  author={Williams, Christopher and Rasmussen, Carl},
  journal={Advances in neural information processing systems},
  volume={8},
  year={1995}
}

@article{agarwal2024many,
  title={Many-shot in-context learning},
  author={Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Chan, Stephanie and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and Co-Reyes, John D and Chu, Eric and others},
  journal={arXiv preprint arXiv:2404.11018},
  year={2024}
}

@article{jiang2024many,
  title={Many-Shot In-Context Learning in Multimodal Foundation Models},
  author={Jiang, Yixing and Irvin, Jeremy and Wang, Ji Hun and Chaudhry, Muhammad Ahmed and Chen, Jonathan H and Ng, Andrew Y},
  journal={arXiv preprint arXiv:2405.09798},
  year={2024}
}

@article{li2023context,
  title={In-context learning with many demonstration examples},
  author={Li, Mukai and Gong, Shansan and Feng, Jiangtao and Xu, Yiheng and Zhang, Jun and Wu, Zhiyong and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2302.04931},
  year={2023}
}


@article{golchin2024memorization,
  title={Memorization In In-Context Learning},
  author={Golchin, Shahriar and Surdeanu, Mihai and Bethard, Steven and Blanco, Eduardo and Riloff, Ellen},
  journal={arXiv preprint arXiv:2408.11546},
  year={2024}
}

@article{song2024can,
  title={Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See More, Judge Better!},
  author={Song, Mingyang and Zheng, Mao and Luo, Xuan},
  journal={arXiv preprint arXiv:2406.11629},
  year={2024}
}


@inproceedings{zhou-etal-2023-survival,
    title = "Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning",
    author = "Zhou, Han  and
      Wan, Xingchen  and
      Vuli{\'c}, Ivan  and
      Korhonen, Anna",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.870",
    doi = "10.18653/v1/2023.findings-emnlp.870",
    pages = "13064--13077",
    abstract = "Prompt-based learning has been an effective paradigm for large pretrained language models (LLM), enabling few-shot or even zero-shot learning. Black-box prompt search has received growing interest recently for its distinctive properties of gradient-free optimization, proven particularly useful and powerful for model-as-a-service usage. However, the discrete nature and the complexity of combinatorial optimization hinder the efficiency of modern black-box approaches. Despite extensive research on search algorithms, the crucial aspect of search space design and optimization has been largely overlooked. In this paper, we first conduct a sensitivity analysis by prompting LLM, revealing that only a small number of tokens exert a disproportionate amount of influence on LLM predictions. Leveraging this insight, we propose the Clustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple black-box search method that first clusters and prunes the search space to focus exclusively on influential prompt tokens. By employing even simple search methods within the pruned search space, ClaPS achieves state-of-the-art performance across various tasks and LLMs, surpassing the performance of complex approaches while significantly reducing search costs. Our findings underscore the critical role of search space design and optimization in enhancing both the usefulness and the efficiency of black-box prompt-based learning.",
}

@article{khattab2023dspy,
  title={Dspy: Compiling declarative language model calls into self-improving pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T and Moazam, Hanna and others},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}

@inproceedings{xia2024less,
  author       = {Mengzhou Xia and
                  Sadhika Malladi and
                  Suchin Gururangan and
                  Sanjeev Arora and
                  Danqi Chen},
  title        = {{LESS:} Selecting Influential Data for Targeted Instruction Tuning},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=PG5fV50maR},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/XiaMGA024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zhou2023lima,
  author       = {Chunting Zhou and
                  Pengfei Liu and
                  Puxin Xu and
                  Srinivasan Iyer and
                  Jiao Sun and
                  Yuning Mao and
                  Xuezhe Ma and
                  Avia Efrat and
                  Ping Yu and
                  Lili Yu and
                  Susan Zhang and
                  Gargi Ghosh and
                  Mike Lewis and
                  Luke Zettlemoyer and
                  Omer Levy},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {{LIMA:} Less Is More for Alignment},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/ac662d74829e4407ce1d126477f4a03a-Abstract-Conference.html},
  timestamp    = {Fri, 01 Mar 2024 16:26:20 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/ZhouLX0SMMEYYZG23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{anil2024many,
  title={Many-shot jailbreaking},
  author={Anil, Cem and Durmus, Esin and Sharma, Mrinank and Benton, Joe and Kundu, Sandipan and Batson, Joshua and Rimsky, Nina and Tong, Meg and Mu, Jesse and Ford, Daniel and others},
  journal={Anthropic, April},
  year={2024}
}

@inproceedings{zong2024long,
  title={Long-context vision large language models: Empirical insights and a baseline},
  author={Zong, Yongshuo and Elezi, Ismail and Yang, Yongxin and Deng, Jiankang and Hospedales, Timothy},
  booktitle={Workshop on Long Context Foundation Models},
  year={2024}
}

@article{zhao2024probing,
  title={Probing the Decision Boundaries of In-context Learning in Large Language Models},
  author={Zhao, Siyan and Nguyen, Tung and Grover, Aditya},
  journal={arXiv preprint arXiv:2406.11233},
  year={2024}
}


@inproceedings{brown2020language,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{lu-etal-2022-fantastically,
    title = "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity",
    author = "Lu, Yao  and
      Bartolo, Max  and
      Moore, Alastair  and
      Riedel, Sebastian  and
      Stenetorp, Pontus",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.556",
    doi = "10.18653/v1/2022.acl-long.556",
    pages = "8086--8098",
    abstract = "When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models. We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are {``}fantastic{''} and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true few-shot setting as it requires additional annotated data. Instead, we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts. Our method yields a 13{\%} relative improvement for GPT-family models across eleven different established text classification tasks.",
}

@inproceedings{
zhou2024batch,
title={Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering},
author={Han Zhou and Xingchen Wan and Lev Proleev and Diana Mincu and Jilin Chen and Katherine A Heller and Subhrajit Roy},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=L3FHMoKZcS}
}

@inproceedings{zhao2021calibrate,
  author       = {Zihao Zhao and
                  Eric Wallace and
                  Shi Feng and
                  Dan Klein and
                  Sameer Singh},
  title        = {Calibrate Before Use: Improving Few-shot Performance of Language Models},
  booktitle    = {Proceedings of the 38th International Conference on Machine Learning,
                  {ICML} 2021, 18-24 July 2021, Virtual Event},
  pages        = {12697--12706},
  year         = {2021},
}

@article{wei2023larger,
  title={Larger language models do in-context learning differently},
  author={Wei, Jerry and Wei, Jason and Tay, Yi and Tran, Dustin and Webson, Albert and Lu, Yifeng and Chen, Xinyun and Liu, Hanxiao and Huang, Da and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2303.03846},
  year={2023}
}

@inproceedings{liu-etal-2022-makes,
    title = "What Makes Good In-Context Examples for {GPT}-3?",
    author = "Liu, Jiachang  and
      Shen, Dinghan  and
      Zhang, Yizhe  and
      Dolan, Bill  and
      Carin, Lawrence  and
      Chen, Weizhu",
    booktitle = "Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures",
    month = may,
    year = "2022",
    address = "Dublin, Ireland and Online",
    publisher = "Association for Computational Linguistics",
    pages = "100--114",
}

@article{marion2023less,
  title={When less is more: Investigating data pruning for pretraining llms at scale},
  author={Marion, Max and {\"U}st{\"u}n, Ahmet and Pozzobon, Luiza and Wang, Alex and Fadaee, Marzieh and Hooker, Sara},
  journal={arXiv preprint arXiv:2309.04564},
  year={2023}
}

@inproceedings{min-etal-2022-rethinking,
    title = "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
    author = "Min, Sewon  and
      Lyu, Xinxi  and
      Holtzman, Ari  and
      Artetxe, Mikel  and
      Lewis, Mike  and
      Hajishirzi, Hannaneh  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    pages = "11048--11064",
}


@InProceedings{liu2024dual,
  title = 	 {Dual Operating Modes of In-Context Learning},
  author =       {Lin, Ziqian and Lee, Kangwook},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {30135--30188},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/lin24l/lin24l.pdf},
  url = 	 {https://proceedings.mlr.press/v235/lin24l.html},
  abstract = 	 {In-context learning (ICL) exhibits dual operating modes: <b><em>task learning</em></b>, i.e., acquiring a new skill from in-context samples, and <b><em>task retrieval</em></b>, i.e., locating and activating a relevant pretrained skill. Recent theoretical work proposes various mathematical models to analyze ICL, but they cannot fully explain the duality. In this work, we analyze a generalized probabilistic model for pretraining data, obtaining a quantitative understanding of the two operating modes of ICL. Leveraging our analysis, we provide the first explanation of an unexplained phenomenon observed with real-world large language models (LLMs). Under some settings, the ICL risk initially increases and then decreases with more in-context examples. Our analysis offers a plausible explanation for this "early ascent" phenomenon: a limited number of in-context samples may lead to the retrieval of an incorrect skill, thereby increasing the risk, which will eventually diminish as task learning takes effect with more in-context samples. We also analyze ICL with biased labels, e.g., zero-shot ICL, where in-context examples are assigned random labels, and predict the bounded efficacy of such approaches. We corroborate our analysis and predictions with extensive experiments with Transformers and LLMs.}
}

@inproceedings{levy-etal-2023-diverse,
    title = "Diverse Demonstrations Improve In-context Compositional Generalization",
    author = "Levy, Itay  and
      Bogin, Ben  and
      Berant, Jonathan",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.78",
    doi = "10.18653/v1/2023.acl-long.78",
    pages = "1401--1422",
    abstract = "In-context learning has shown great success in i.i.d semantic parsing splits, where the training and test sets are drawn from the same distribution. In this setup, models are typically prompted with demonstrations that are similar to the input utterance. However, in the setup of compositional generalization, where models are tested on outputs with structures that are absent from the training set, selecting similar demonstrations is insufficient, as often no example will be similar enough to the input. In this work, we propose a method to select diverse demonstrations that aims to collectively cover all of the structures required in the output program, in order to encourage the model to generalize to new structures from these demonstrations. We empirically show that combining diverse demonstrations with in-context learning substantially improves performance across three compositional generalization semantic parsing datasets in the pure in-context learning setup and when combined with finetuning.",
}

@inproceedings{levy-etal-2024-task,
    title = "Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models",
    author = "Levy, Mosh  and
      Jacoby, Alon  and
      Goldberg, Yoav",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.818",
    doi = "10.18653/v1/2024.acl-long.818",
    pages = "15339--15353",
    abstract = "This paper explores the impact of extending input lengths on the capabilities of Large Language Models (LLMs). Despite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood. We investigate this aspect by introducing a novel QA reasoning framework, specifically designed to assess the impact of input length. We isolate the effect of input length using multiple versions of the same sample, each being extended with padding of different lengths, types and locations. Our findings show a notable degradation in LLMs{'} reasoning performance at much shorter input lengths than their technical maximum. We show that the degradation trend appears in every version of our dataset, although at different intensities.Additionally, our study reveals that the traditional metric of next word prediction correlates negatively with performance of LLMs{'} on our reasoning dataset. We analyse our results and identify failure modes that can serve as useful guides for future research, potentially informing strategies to address the limitations observed in LLMs.",
}

@inproceedings{
zelikman2022star,
title={{ST}aR: Bootstrapping Reasoning With Reasoning},
author={Eric Zelikman and Yuhuai Wu and Jesse Mu and Noah Goodman},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=_3ELRdg2sgI}
}

@inproceedings{wang-etal-2023-self-instruct,
    title = "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    author = "Wang, Yizhong  and
      Kordi, Yeganeh  and
      Mishra, Swaroop  and
      Liu, Alisa  and
      Smith, Noah A.  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.754",
    doi = "10.18653/v1/2023.acl-long.754",
    pages = "13484--13508",
    abstract = "Large {``}instruction-tuned{''} language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33{\%} absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5{\%} absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.",
}

@inproceedings{
zhang2023automatic,
title={Automatic Chain of Thought Prompting in Large Language Models},
author={Zhuosheng Zhang and Aston Zhang and Mu Li and Alex Smola},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=5NTt8GFjUHkr}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{han2024parameter,
  title={Parameter-efficient fine-tuning for large models: A comprehensive survey},
  author={Han, Zeyu and Gao, Chao and Liu, Jinyang and Zhang, Sai Qian and others},
  journal={arXiv preprint arXiv:2403.14608},
  year={2024}
}

@article{li2024can,
  title={Can llm already serve as a database interface? a big bench for large-scale database grounded text-to-sqls},
  author={Li, Jinyang and Hui, Binyuan and Qu, Ge and Yang, Jiaxi and Li, Binhua and Li, Bowen and Wang, Bailin and Qin, Bowen and Geng, Ruiying and Huo, Nan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@book{garnett2023bayesian,
  title={Bayesian optimization},
  author={Garnett, Roman},
  year={2023},
  publisher={Cambridge University Press}
}

@article{frazier2018tutorial,
  title={A tutorial on Bayesian optimization},
  author={Frazier, Peter I},
  journal={arXiv preprint arXiv:1807.02811},
  year={2018}
}

@article{claude,
title={The Claude 3 Model Family: Opus, Sonnet, Haiku},
author={Anthropic},
year={2024}
}


@inproceedings{wan-etal-2023-better,
    title = "Better Zero-Shot Reasoning with Self-Adaptive Prompting",
    author = "Wan, Xingchen  and
      Sun, Ruoxi  and
      Dai, Hanjun  and
      Arik, Sercan  and
      Pfister, Tomas",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.216",
    doi = "10.18653/v1/2023.findings-acl.216",
    pages = "3493--3514",
    abstract = "Modern large language models (LLMs) have demonstrated impressive capabilities at sophisticated tasks, often through step-by-step reasoning similar to humans. This is made possible by their strong few- and zero-shot abilities {--} they can effectively learn from a handful of handcrafted, completed responses ({``}in-context examples{''}), or are prompted to reason spontaneously through specially designed triggers. Nonetheless, some limitations have been observed. First, performance in the few-shot setting is sensitive to the choice of the examples, whose design requires significant human effort. Moreover, given the diverse downstream tasks of LLMs, it may be difficult or laborious to handcraft per-task labels. Second, while the zero-shot setting does not require handcrafting, its performance is limited due to the lack of guidance to the LLMs. To address these limitations, we propose Consistency-based Self-adaptive Prompting (COSP), a novel prompt design method for LLMs. Requiring neither handcrafted responses nor ground-truth labels, COSP selects and builds the set of examples from the LLM zero-shot outputs via carefully designed criteria combining consistency, diversity and repetition. In the zero-shot setting for three different LLMs, we show that using only LLM predictions, COSP significantly improves performance up to 15{\%} compared to zero-shot baselines and matches or exceeds few-shot baselines at a range of reasoning tasks.",
}


@inproceedings{oswald2023gd,
  author       = {Johannes von Oswald and
                  Eyvind Niklasson and
                  Ettore Randazzo and
                  Jo{\~{a}}o Sacramento and
                  Alexander Mordvintsev and
                  Andrey Zhmoginov and
                  Max Vladymyrov},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Transformers Learn In-Context by Gradient Descent},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {35151--35174},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v202/von-oswald23a.html},
  timestamp    = {Mon, 28 Aug 2023 17:23:09 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/OswaldNRSMZV23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{rubin-etal-2022-learning,
    title = "Learning To Retrieve Prompts for In-Context Learning",
    author = "Rubin, Ohad  and
      Herzig, Jonathan  and
      Berant, Jonathan",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.191",
    doi = "10.18653/v1/2022.naacl-main.191",
    pages = "2655--2671",
    abstract = "In-context learning is a recent paradigm in natural language understanding, where a large pre-trained language model (LM) observes a test instance and a few training examples as its input, and directly decodes the output without any update to its parameters. However, performance has been shown to strongly depend on the selected training examples (termed prompts). In this work, we propose an efficient method for retrieving prompts for in-context learning using annotated data and an LM. Given an input-output pair, we estimate the probability of the output given the input and a candidate training example as the prompt, and label training examples as positive or negative based on this probability. We then train an efficient dense retriever from this data, which is used to retrieve training examples as prompts at test time. We evaluate our approach on three sequence-to-sequence tasks where language utterances are mapped to meaning representations, and find that it substantially outperforms prior work and multiple baselines across the board.",
}

@article{nguyen2023context,
  title={In-context example selection with influences},
  author={Nguyen, Tai and Wong, Eric},
  journal={arXiv preprint arXiv:2302.11042},
  year={2023}
}

@article{xu2024context,
  title={In-context learning with retrieved demonstrations for language models: A survey},
  author={Xu, Xin and Liu, Yue and Pasupat, Panupong and Kazemi, Mehran and others},
  journal={arXiv preprint arXiv:2401.11624},
  year={2024}
}

@inproceedings{chen-etal-2023-self,
    title = "Self-{ICL}: Zero-Shot In-Context Learning with Self-Generated Demonstrations",
    author = "Chen, Wei-Lin  and
      Wu, Cheng-Kuang  and
      Chen, Yun-Nung  and
      Chen, Hsin-Hsi",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.968",
    doi = "10.18653/v1/2023.emnlp-main.968",
    pages = "15651--15662",
    abstract = "Large language models (LLMs) have exhibited striking in-context learning (ICL) ability to adapt to target tasks with a few input-output demonstrations. For better ICL, different methods are proposed to select representative demonstrations from existing training corpora. However, such settings are not aligned with real-world practices, as end-users usually query LMs without access to demonstration pools. In this work, we introduce Self-ICL{---}a simple framework which bootstraps LMs{'} intrinsic capabilities to perform zero-shot ICL. Given a test input, Self-ICL first prompts the model to generate pseudo-inputs. Next, the model predicts pseudo-labels for the pseudo-inputs via zero-shot prompting. Finally, we perform ICL for the test input with the pseudo-input-label pairs as demonstrations. Evaluation on 23 BIG-Bench Hard tasks shows Self-ICL outperforms zero-shot baselines on both average accuracy and head-to-head comparison. Moreover, with zero-shot chain-of-thought, Self-ICL achieves results comparable to using real demonstrations. Additionally, we conduct a range of analyses to validate Self-ICL{'}s effectiveness and provide insights for its behaviors under different settings.",
}

@article{hao2022structured,
  title={Structured prompting: Scaling in-context learning to 1,000 examples},
  author={Hao, Yaru and Sun, Yutao and Dong, Li and Han, Zhixiong and Gu, Yuxian and Wei, Furu},
  journal={arXiv preprint arXiv:2212.06713},
  year={2022}
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@article{anonymous2024chase,
  title={Chase-sql: Multi-path reasoning and preference optimized candidate selection in text-to-sql},
  author={Pourreza, Mohammadreza and Li, Hailong and Sun, Ruoxi and Chung, Yeounoh and Talaei, Shayan and Kakkar, Gaurav Tarlok and Gan, Yu and Saberi, Amin and Ozcan, Fatma and Arik, Sercan O},
  journal={International Conference on Learning Representations (ICLR)},
  year={2025}
}

@inproceedings{
wan2024teach,
title={Teach Better or Show Smarter? On Instructions and Exemplars in Automatic Prompt Optimization},
author={Xingchen Wan and Ruoxi Sun and Hootan Nakhost and Sercan O. Arik},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=IdtoJVWVnX}
}

@inproceedings{wan-etal-2023-universal,
    title = "Universal Self-Adaptive Prompting",
    author = "Wan, Xingchen  and
      Sun, Ruoxi  and
      Nakhost, Hootan  and
      Dai, Hanjun  and
      Eisenschlos, Julian  and
      Arik, Sercan  and
      Pfister, Tomas",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.461",
    doi = "10.18653/v1/2023.emnlp-main.461",
    pages = "7437--7462",
    abstract = "A hallmark of modern large language models (LLMs) is their impressive general zero-shot and few-shot abilities, often elicited through in-context learning (ICL) via prompting. However, while highly coveted and being the most general, zero-shot performances in LLMs are still typically weaker due to the lack of guidance and the difficulty of applying existing automatic prompt design methods in general tasks when ground-truth labels are unavailable. In this study, we address this by presenting Universal Self-Adaptive Prompting (USP), an automatic prompt design approach specifically tailored for zero-shot learning (while compatible with few-shot). Requiring only a small amount of unlabeled data and an inference-only LLM, USP is highly versatile: to achieve universal prompting, USP categorizes a possible NLP task into one of the three possible task types and then uses a corresponding selector to select the most suitable queries and zero-shot model-generated responses as pseudo-demonstrations, thereby generalizing ICL to the zero-shot setup in a fully automated way. We evaluate USP with PaLM and PaLM 2 models and demonstrate performances that are considerably stronger than standard zero-shot baselines and often comparable to or even superior to few-shot baselines across more than 40 natural language understanding, natural language generation, and reasoning tasks.",
}

@article{opsahl2024optimizing,
  title={Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs},
  author={Opsahl-Ong, Krista and Ryan, Michael J and Purtell, Josh and Broman, David and Potts, Christopher and Zaharia, Matei and Khattab, Omar},
  journal={arXiv preprint arXiv:2406.11695},
  year={2024}
}

@article{zhan2020expected,
  title={Expected improvement for expensive optimization: a review},
  author={Zhan, Dawei and Xing, Huanlai},
  journal={Journal of Global Optimization},
  volume={78},
  number={3},
  pages={507--544},
  year={2020},
  publisher={Springer}
}

@inproceedings{chugh2020scalarizing,
  title={Scalarizing functions in Bayesian multiobjective optimization},
  author={Chugh, Tinkle},
  booktitle={2020 IEEE Congress on Evolutionary Computation (CEC)},
  pages={1--8},
  year={2020},
  organization={IEEE}
}

@inproceedings{bowman1976relationship,
  title={On the relationship of the Tchebycheff norm and the efficient frontier of multiple-criteria objectives},
  author={Bowman Jr, V Joseph},
  booktitle={Multiple Criteria Decision Making: Proceedings of a Conference Jouy-en-Josas, France May 21--23, 1975},
  pages={76--86},
  year={1976},
  organization={Springer}
}

@article{steuer1983interactive,
  title={An interactive weighted Tchebycheff procedure for multiple objective programming},
  author={Steuer, Ralph E and Choo, Eng-Ung},
  journal={Mathematical programming},
  volume={26},
  pages={326--344},
  year={1983},
  publisher={Springer}
}

@inproceedings{paria2020flexible,
  title={A flexible framework for multi-objective bayesian optimization using random scalarizations},
  author={Paria, Biswajit and Kandasamy, Kirthevasan and P{\'o}czos, Barnab{\'a}s},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={766--776},
  year={2020},
  organization={PMLR}
}

@article{knowles2006parego,
  title={ParEGO: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems},
  author={Knowles, Joshua},
  journal={IEEE transactions on evolutionary computation},
  volume={10},
  number={1},
  pages={50--66},
  year={2006},
  publisher={IEEE}
}

@article{li2024retrieval,
  title={Retrieval augmented generation or long-context llms? a comprehensive study and hybrid approach},
  author={Li, Zhuowan and Li, Cheng and Zhang, Mingyang and Mei, Qiaozhu and Bendersky, Michael},
  journal={arXiv preprint arXiv:2407.16833},
  year={2024}
}

@article{patel2022bidirectional,
  title={Bidirectional language models are also few-shot learners},
  author={Patel, Ajay and Li, Bryan and Rasooli, Mohammad Sadegh and Constant, Noah and Raffel, Colin and Callison-Burch, Chris},
  journal={arXiv preprint arXiv:2209.14500},
  year={2022}
}

@article{han2021unsupervised,
  title={Unsupervised neural machine translation with generative language models only},
  author={Han, Jesse Michael and Babuschkin, Igor and Edwards, Harrison and Neelakantan, Arvind and Xu, Tao and Polu, Stanislas and Ray, Alex and Shyam, Pranav and Ramesh, Aditya and Radford, Alec and others},
  journal={arXiv preprint arXiv:2110.05448},
  year={2021}
}

@article{balandat2020botorch,
  title={BoTorch: A framework for efficient Monte-Carlo Bayesian optimization},
  author={Balandat, Maximilian and Karrer, Brian and Jiang, Daniel and Daulton, Samuel and Letham, Ben and Wilson, Andrew G and Bakshy, Eytan},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21524--21538},
  year={2020}
}

@article{gardner2018gpytorch,
  title={Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration},
  author={Gardner, Jacob and Pleiss, Geoff and Weinberger, Kilian Q and Bindel, David and Wilson, Andrew G},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{guzman-etal-2019-flores,
    title = "The {FLORES} Evaluation Datasets for Low-Resource Machine Translation: {N}epali{--}{E}nglish and {S}inhala{--}{E}nglish",
    author = "Guzm{\'a}n, Francisco  and
      Chen, Peng-Jen  and
      Ott, Myle  and
      Pino, Juan  and
      Lample, Guillaume  and
      Koehn, Philipp  and
      Chaudhary, Vishrav  and
      Ranzato, Marc{'}Aurelio",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1632",
    doi = "10.18653/v1/D19-1632",
    pages = "6098--6111",
    abstract = "For machine translation, a vast majority of language pairs in the world are considered low-resource because they have little parallel data available. Besides the technical challenges of learning with limited supervision, it is difficult to evaluate methods trained on low-resource language pairs because of the lack of freely and publicly available benchmarks. In this work, we introduce the FLORES evaluation datasets for Nepali{--}English and Sinhala{--} English, based on sentences translated from Wikipedia. Compared to English, these are languages with very different morphology and syntax, for which little out-of-domain parallel data is available and for which relatively large amounts of monolingual data are freely available. We describe our process to collect and cross-check the quality of translations, and we report baseline performance using several learning settings: fully supervised, weakly supervised, semi-supervised, and fully unsupervised. Our experiments demonstrate that current state-of-the-art methods perform rather poorly on this benchmark, posing a challenge to the research community working on low-resource MT. Data and code to reproduce our experiments are available at \url{https://github.com/facebookresearch/flores}.",
}


@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{das2021case,
  title={Case-based reasoning for natural language queries over knowledge bases},
  author={Das, Rajarshi and Zaheer, Manzil and Thai, Dung and Godbole, Ameya and Perez, Ethan and Lee, Jay-Yoon and Tan, Lizhen and Polymenakos, Lazaros and McCallum, Andrew},
  journal={arXiv preprint arXiv:2104.08762},
  year={2021}
}

@article{lee2024gecko,
  title={Gecko: Versatile text embeddings distilled from large language models},
  author={Lee, Jinhyuk and Dai, Zhuyun and Ren, Xiaoqi and Chen, Blair and Cer, Daniel and Cole, Jeremy R and Hui, Kai and Boratko, Michael and Kapadia, Rajvi and Ding, Wen and others},
  journal={arXiv preprint arXiv:2403.20327},
  year={2024}
}

@article{hu2023amortizing,
  title={Amortizing intractable inference in large language models},
  author={Hu, Edward J and Jain, Moksh and Elmoznino, Eric and Kaddar, Younesse and Lajoie, Guillaume and Bengio, Yoshua and Malkin, Nikolay},
  journal={arXiv preprint arXiv:2310.04363},
  year={2023}
}

@article{ru2020interpretable,
  title={Interpretable neural architecture search via bayesian optimisation with weisfeiler-lehman kernels},
  author={Ru, Binxin and Wan, Xingchen and Dong, Xiaowen and Osborne, Michael},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{chen2025reliable,
  title={Reliable Text-to-SQL with Adaptive Abstention},
  author={Chen, Kaiwen and Chen, Yueting and Yu, Xiaohui and Koudas, Nick},
  journal={arXiv preprint arXiv:2501.10858},
  year={2025}
}

@article{lamb2016professor,
  title={Professor forcing: A new algorithm for training recurrent networks},
  author={Lamb, Alex M and ALIAS PARTH GOYAL, Anirudh Goyal and Zhang, Ying and Zhang, Saizheng and Courville, Aaron C and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{zhou-etal-2024-fairer,
    title = "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments",
    author = "Zhou, Han  and
      Wan, Xingchen  and
      Liu, Yinhong  and
      Collier, Nigel  and
      Vuli{\'c}, Ivan  and
      Korhonen, Anna",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.72/",
    doi = "10.18653/v1/2024.emnlp-main.72",
    pages = "1241--1252",
    abstract = "Large language models (LLMs) have shown promising abilities as cost-effective and reference-free evaluators for assessing language generation quality. In particular, pairwise LLM evaluators, which compare two generated texts and determine the preferred one, have been employed in a wide range of applications. However, LLMs exhibit preference biases and worrying sensitivity to prompt designs. In this work, we first reveal that the predictive preference of LLMs can be highly brittle and skewed, even with semantically equivalent instructions. We find that fairer predictive preferences from LLMs consistently lead to judgments that are better aligned with humans. Motivated by this phenomenon, we propose an automatic Zero-shot Evaluation-oriented Prompt Optimization framework, ZEPO, which aims to produce fairer preference decisions and improve the alignment of LLM evaluators with human judgments. To this end, we propose a zero-shot learning objective based on the preference decision fairness. ZEPO demonstrates substantial performance improvements over state-of-the-art LLM evaluators, without requiring labeled data, on representative meta-evaluation benchmarks. Our findings underscore the critical correlation between preference fairness and human alignment, positioning ZEPO as an efficient prompt optimizer for bridging the gap between LLM evaluators and human judgments."
}


@inproceedings{wan2021think,
  title={Think Global and Act Local: Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces},
  author={Wan, Xingchen and Nguyen, Vu and Ha, Huong and Ru, Binxin and Lu, Cong and Osborne, Michael A},
  booktitle={International Conference on Machine Learning},
  pages={10663--10674},
  year={2021},
  organization={PMLR}
}

@article{daulton2022bayesian,
  title={Bayesian optimization over discrete and mixed spaces via probabilistic reparameterization},
  author={Daulton, Samuel and Wan, Xingchen and Eriksson, David and Balandat, Maximilian and Osborne, Michael A and Bakshy, Eytan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12760--12774},
  year={2022}
}

