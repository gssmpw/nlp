% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage{float}
\usepackage[final]{acl}
\usepackage{ragged2e} % Load the package
% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{color}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{comment}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{todonotes}
\usepackage{subcaption}
\usepackage{tcolorbox}
\usepackage{enumitem}
\usepackage{colortbl}


\definecolor{darkgreen}{rgb}{0,0.5,0}


\title{Incongruence Identification in Eyewitness Testimony}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}


% \author{
%     Akshara Nair$^{1}$ \quad Zeba Afrozr$^{2}$ \quad Md Shad Akhtar$^{3}$ \\
%     $^3$Indraprastha Institute of Information Technology Delhi, India \\
%     \texttt{@affiliation1.edu, email2@affiliation2.edu, email3@affiliation3.edu}
% }

\author{
    Akshara Nair \quad Zeba Afroz \quad Md Shad Akhtar \\
    IIIT-Delhi, New Delhi, India \\
    \texttt{\{akshara22008, zebaa, shad.akhtar\}@iiitd.ac.in}
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}
\newcommand{\dataset}{{\tt MIND}}
% \newcommand{\task}{{\tt MIND}}
\newcommand{\model}{{\tt INTEND}}



\begin{document}
\maketitle
\begin{abstract}
Incongruence detection in eyewitness' narratives is critical for understanding the reliability of testimonies, yet traditional approaches often fail to address the nuanced inconsistencies inherent in such accounts. In this paper, we introduce a novel task of incongruence detection in eyewitness testimonies. Given a pair of testimonies consisting of multiple pairs of questions and answers by two subjects, we identify contextually-related incongruence between the two subjects. We also mark the span of incongruence in the utterances. To achieve this, we develop \dataset\ (\textbf{M}ult\textbf{I}-eyewit\textbf{N}ess \textbf{D}eception) -- a comprehensive dataset consisting of 2,979 pairs of contextually related answers designed to capture both explicit and implicit contradictions. Further, we propose an \textbf{IN}struction-\textbf{T}un\textbf{E}d i\textbf{N}congruity \textbf{D}etection framework based on the $6Ws$ and Multi-Hop reasoning approach, aka. \model. Drawing from investigative techniques, \model\ addresses the task as a cloze-style problem, concentrating on the \textit{who}, \textit{what}, \textit{when}, \textit{where}, and \textit{why} aspects of the context. Our findings show that prompt tuning, especially when utilizing our proposed framework, enhances the detection of incongruences by a margin of $+5.63\%$. %Notably, we accomplish this by annotating merely $151$ samples with $6Ws$. 
We compare our approach with multiple fine-tuning and prompt-tuning techniques on MLMs and LLMs. Empirical results demonstrate convincing performance improvements in F1-score over fine-tuned and regular prompt-tuned techniques, highlighting the effectiveness of our approach.
\end{abstract}

\section{Introduction}

Eyewitness testimony has long been seen as an essential component of judicial and investigative processes, providing human perspectives that can reveal the truth about an occurrence. However, when many eyewitnesses submit statements, differences or contradictions, known as inter-eyewitness incongruence, may arise. Moreover, inter-eyewitness incongruence can occur for various point of references, such as the order of events, descriptions of the people involved, specifics of the activities committed, etc. These inconsistencies call into question the entire knowledge of the event and raise serious doubts about the testimonies' trustworthiness and credibility.
% Inter-eyewitness incongruence occurs when various eyewitnesses make contradictory accounts about the same point of reference, such as the order of events, descriptions of the people involved, or specifics of the activities committed. 
Historically, research on eyewitness testimony has concentrated chiefly on the linguistic examination of individual narratives \cite{doggett-cantarero-2016-identifying,sola2023analysing,Rachel}, often limiting the analysis to one perspective and interaction with other testimonies has been rarely explored. These approaches limit our knowledge of how inconsistencies occur and how they affect the overall narrative of an event and its key details. 



\begin{table}[t]
    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{p{20em}cp{20em}}
         \multicolumn{3}{l}{\textbf{Context:} \textit{What did the girl with black curly hair do after reaching the house of a man in the black jacket?}}  \\ \toprule 
         \textbf{Testimony $T1$:} So, when she reached [\textcolor{red!90}{\textit{Frederick's house, she knocked, then she hid.  When Frederick came out, she snapped his neck and killed him}}]$I_1$.  Then she entered the house to check for other members. Going to the first floor, she knocked on a door, a man came out, and [\textcolor{blue!90}{\textit{she threw him off the roof, causing him to die}}]$I_2$.  Then she entered the room from which the man came, where she found a woman lying on the bed, whom she proceeded to shoot. & & \textbf{Testimony $T2$:} When she get there, she found a boy so she thought he might be the son of that person so  [\textcolor{red!90}{\textit{she didn’t want to kill him but he attacked on that curly hair girl then in response to that curly hair girl like killed him}}]$I_1$ and then she entered in that person's house and she knock the door in which that person was there and and hide in a corner and then that man cried that who is this but she didn't reply and then [\textcolor{blue!90}{\textit{when he opened the door she killed and she attacked that man with the knife and killed him}}]$I_2$. \\ \toprule
         
         \textbf{Identified Incongruences:} \\
         \multicolumn{3}{l}{\multirow{3}{43.5em}{ \begin{itemize}
             \item \textcolor{red}{$I_1$:} $T1$ and $T2$ describe different sequences and outcomes for the girl’s actions upon arriving at the house., In T1, she kills someone inside the house after knocking on the door, while in T2, she kills Frederick immediately after he opens the door and before checking for other members.
              \item \textcolor{blue}{$I_2$:} $T1$ describes a knife attack leading to death, whereas T2 describes a man falling from the roof. \end{itemize}}} \\ \\
              \\ \\ \\ \\

              % \item $I_1$: $T1$ and $T2$ describe different sequences and outcomes for the girl’s actions upon arriving at the house., In T1, she kills someone inside the house after knocking on the door, while in T2, she kills Frederick immediately after he opens the door and before checking for other members.\end{itemize}}} \\ \\ \\ \\ 
    \end{tabular}}
    \caption{For a given context, $T_1$ and $T_2$ are testimonies from two witnesses taken in isolation. $I_1$ and $I_2$ are the spans of identified incongruencies.}
    \label{tab:example}
    \vspace{-1mm}
\end{table}

Traditional approaches for contradiction detection have relied on explicit linguistic cues like antonym, negation, and quantitative incompatibilities to discover contradictions. For instance, the detection of contradictions often involves recognizing antonyms (e.g., `full' vs. `empty'), the presence of negation (e.g., `is' vs. `is not'), or discrepancies in numerical information (e.g., `three' vs. `five') \cite{stanfordNLP,CCI}. However, these algorithms fail to detect subtle and implicit errors that are frequent in eyewitness testimonies. 
Moreover, most existing datasets and algorithms classify entire pair of sentence as either contraditing or not, but they do not identify the exact spans or segments of text where the contradiction occurs. The absence of adequate reasoning for these incongruences is a critical challenge that needs to be fully addressed. This shortcoming is primarily due to the lack of ground truth data that pinpoints the specific spans where contradictions exist. Without this level of detail, it is difficult to identify the nature of the contradiction and effectively address it, especially in the context of analyzing multiple witness statements.
\vspace{-0.26cm}
\paragraph{Motivation: }
Consistent testimonies from various eyewitnesses imply dependability and variations may indicate dishonesty or attempts to mislead investigators. Our attempt to explore the task of  detecting incongruence and providing appropriate reasoning in terms of textual for contradictions within testimonies is motivated by the critical importance in exposing potential dissimulation and mendacity. By pinpointing the exact segments where contradictions occur, span extraction provides irrefutable evidence and reason of these inconsistencies. This method transforms abstract incongruence into concrete, verifiable data, allowing for a more precise and informed evaluation of testimonies.
Table \ref{tab:example} exemplifies how two testimonies, $T1$ and $T2$, offer differing accounts of the same event. The discrepancies, $I1$ and $I2$, reveal variations in the sequence and outcomes of events, such as differing accounts of killing inside or outside the house and whether a man is killed by a knife or a fall. Pinpointing these nuanced discrepancies provide a clearer understanding of the conflicting narratives.

% \hl{Table 1 should be dicussed here. Argue for motivation with the help of example.}

To this end, we develop \dataset, a multi-eyewitness deception detection dataset. It contains $389$ eyewitness testimonial statements related to $149$ events, each event observed by one, two, or three eyewitnesses, and $2,979$ pairs of testimonies with linked context-answer pairs, where each context is a predefined question about a subevent and the answers are the eyewitnesses' statements related to that context.
% The development of methods for detecting incongruence and extracting specific spans of contradictions within testimonies is motivated by the critical importance in exposing potential dissimulation and mendacity. By pinpointing the exact segments where contradictions occur, span extraction provides irrefutable evidence of these inconsistencies. This method transforms abstract incongruence into concrete, verifiable data, allowing for a more precise and informed evaluation of testimonies.
% Identifying these anomalies is critical because  The existing methodologies need to be revised to capture the subtle contradictions that emerge in complex, perspective-based narratives, mainly when these narratives are situated inside the same or related settings.
Further to enhance the reliability and accuracy of eyewitness testimonies, we propose an instruction-tuned incongruity detection framework, \model. Unlike conventional contradiction detection systems designed for short, factual texts, \model\ focuses on identifying discrepancies within complex narratives that address similar or related topics. 
Traditionally, the 5W approach \footnote{https://en.wikipedia.org/wiki/Five\_Ws.} -- focusing on who, what, when, where, and why -- has been a cornerstone of investigative techniques \cite{mott1942trends}. Building on this foundation, we introduce an expanded 6Ws framework, emphasizing on who (identity), what (action), what (object), when (timeline), where (location), and why (reason). By analyzing agreements, contradictions, and omissions within these six areas, we hypothesize that this method will reveal subtle yet significant differences that may not be apparent when using traditional approaches.

% \hl{Need brief of \model. 6Ws. Similar to abstract but slightly more details 2-3 lines.}
%, as illustrated in Table \ref{tab:example}.

% Unlike typical contradiction detection systems, which function on short, factual texts, MIND focuses on spotting narrative discrepancies within larger, complicated narratives that answer the same or related topics.

For the reasoning task, we identify the exact spans where they occur in a pair of testimonies and identify their incongruence alignment. We adopt a multi-hop strategy to extract subtle intricacies of incongruency in three steps, i.e., \textit{identify fine-grained key details}, \textit{infer incongruent reasons}, and \textit{extract conflicting spans}.
% \hl{Same for multi-hop.}
Our evaluation on \dataset\ demonstrate significant improvements in F1-scores against various MLMs and LLMs for both tasks.


% To benchmark \dataset, we investigate alternative instruction tuning strategies using Large Language Models.

\subsection{Contributions:} We summarize our contributions as:


% \begin{itemize}
%     \item We introduce a \textbf{novel task} of incongruence span detection aimed at extracting contradicting spans between the answers of two witnesses to a given question.
%     \item We create a comprehensive \textbf{new dataset \dataset } for
%     incongruence detection and span extraction task
%     \item We propose a \textbf{instruction-tuned incongruity detection framework \model\ }for incongruence detection task. We create and demonstrated the effectiveness of various prompt templates in detecting incongruence.
%     \item Propose a \textbf{ multi-hop reasoning framework} inspired by \cite{fei2023reasoning} for extracting incongruent spans.
%     \item We conduct \textbf{extensive human evaluation} to assess the quality of the generated contradictory spans, using metrics such as contradiction clarity, logical exclusivity, context relevance, and coverage by our proposed model.
  
% \end{itemize}

\begin{itemize}[itemsep=0pt, ]
    \item We introduce a \textbf{novel task} of incongruence detection and reasoning task aimed at extracting contradicting statements between two testimonies.
    \item We develop \dataset\ -- a comprehensive \textbf{dataset} to train and evaluate the incongruence detection and reasoning tasks.
    \item We propose \model\footnote{Supplementary accompanies the code.}, a novel instruction-tuned framework supplemented with the $6Ws$ and multi-hop strategies for the detection and reasoning tasks, respectively.
    
    % incongruity detection framework \model{}} for the incongruence detection task. We create and demonstrate the effectiveness of various prompt templates in detecting incongruence.
    % \item We propose a \textbf{multi-hop reasoning framework} inspired by \cite{fei2023reasoning} for extracting incongruent spans.
    % \item We conduct \textbf{extensive human evaluation} to assess the quality of the generated contradictory spans, using metrics such as contradiction clarity, logical exclusivity, context relevance, and coverage by our proposed model.
\end{itemize}

\section{Related Work}
\paragraph{Existing Datasets:} One of the key areas where detecting incongruence is crucial is during interrogations, where individuals may attempt to deceive by presenting statements that contradict established evidence, facts, or the testimonies of other witnesses. Deception research primarly uses two types of dataset. Real-life and Mock. The Real Life Trial dataset \cite{perez2015verbal}\,includes misleading and honest footage extracted from courtroom footage while Mock datasets , generated under controlled conditions, include the work by \cite{CSC} with 32 hours of deceptive speech.
The Bag-of-Lies dataset by\cite{Bag-of-lies}, contains visual, audio, EEG, and eye gaze data collected in real-life situations utilizing standard mobile devices and sensors.
\vspace{-0.3cm}
\paragraph{Contradiction Detection:} A large portion of contradiction detection research falls under the scope of Natural Language Inference where the objective is to determine whether a hypothesis is entailing, contradicting or undetermined given a premise \cite{stanford-nlp-manning}. Early efforts focussed on sentence-level entailment, such as the work of \cite{Khot_Sabharwal_Clark_2018} \cite{schuster-etal-2022-stretching} extended NLI to longer documents with SeNtLI, through it retained sentence-level decomposition, which restricted context preservation.
However, no existing work effectively detects contradictions in personal narratives involving differing perspective.
\vspace{-0.3cm}
\paragraph{Large Language Models: } LLMs have recently gained popularity in various natural language processing tasks \cite{gpt}. Open-source models like Llama \cite{dubey2024llama} and Mistral \cite{jiang2023mistral} excel in handling complex tasks through natural language instructions. Instruction tuning, which fine-tunes LLMs using datasets paired with specific instructions, has also become widespread (Jiao et al., 2023a; Wang et al., 2023b; Zhang et al., 2023; Cheng et al., 2023), enabling the models to make task-specific predictions.

Additionally, recent works have started to leverage the common sense understanding of these models\cite{paranjape-etal-2021-prompting}. Research by \cite{fei2023reasoning,jiang-etal-2022-understanding} has demonstrated the value of multi-hop reasoning in enhancing model performance, especially in tasks that demand deep contextual understanding. The reasoning ability is essential for semantic understanding task like contradiction detection, where the model must grasp subtle nuances and approach the problem by mimicking human-like, step-by-step thinking. To the best of our knowledge no existing work detects contradictions in personal narratives involving multiple events or differing perspectives from various individuals, and all current approaches follow a binary method. In contrast, \model\ distinguishes itself by operating at both the binary and span levels, addressing the gap in analyzing complex, multi-perspective datasets.

\section{Dataset}
As discussed earlier, existing datasets on deception detection \cite{perez2015verbal,CSC,Bag-of-lies} do not support the proposed task of incongruence detection for eyewitness testimonies. Moreover, these datasets frequently disregard several perspectives on a particular matter, resulting in potential prejudices and an inadequate comprehension of deceitful conduct. To this end, we develop \dataset\ in two stages. At first, we adopted wizard-of-oz setup to collect testimonies in a controlled interrogation environment specifically designed to replicate real-life situations. Subsequently, we employ annotators to tag necessary labels. 

\subsection{Data Collection}
In this section, we lay out detailed process of the data collection phase.
\begin{itemize}
    \item \textbf{Event Selection:} Initially, we meticulously selected high-quality videos focusing majorly on crime-related topics such as, robbery, theft, murder, etc. We follow these guidelines to ensure a comprehensive representation of criminal contexts:
        \begin{itemize}
            \item \textbf{Realism:} We compile films that primarily depict  criminal incidents or situations. A few non-crime scenarios have been included as well, but they are kept to a minimum to maintain focus.
            \item \textbf{Diversity:} The dataset encompasses a diverse array of criminal scenarios, specifically designed to challenge witnesses and elicit scenario-specific deception, enabling the analysis of how individuals fabricate in various contexts.
        \end{itemize} 
    
    \item \textbf{Preparing witness:} Next, we show these videos to human actors (aka. witness) about a particular situation. This step mimics the real-life experience of a person who witnessed the event. We allowed a cooling-off period (15 mins to a few days) to witness before the interrogation. 
    
    \item \textbf{Controlled Interrogation:} During interrogation, witnesses are asked to recollect their observations of the event and record their testimonies as response to the interrogator's question. Interrogator's questions encompass both direct inquiries on the witnessed events and subsequent assessments to gauge the coherence and precision of the answers. Meanwhile, some of the witnesses are instructed to occasionally deceit at their own discretion -- the interrogator is aware of what event has happened (e.g., murder) but they are unaware of the details of the events, such as, suspect, timeline, equipment used for the crime, etc. The various manifestations of deceit encompass. 
        % \begin{itemize}
        %     \item \textbf{Concealment:} When a witness intentionally omits or downplays specific details about the perpetrator, activities, or setting.
        %     \item \textbf{Fabrication:} When a witness deliberately creates false information, including making up events or providing falsified responses.
        %     \item \textbf{Distortion:} When a witness intentionally alters details or characteristics of an observed event.
        % \end{itemize}
        \begin{itemize}
            \item \textbf{Concealment:} Intentional omission or downplaying of details about the perpetrator, activities, or setting by a witness.
            \item \textbf{Fabrication:} Deliberate creation of false information.
            \item \textbf{Distortion:} Intentional alteration of details or characteristics of an observed event by a witness.
        \end{itemize}
    \item \textbf{Transcription:} Following the interview, we transcribe the testimonies into specified textual format.
    \item \textbf{Statistics:} Table \ref{tab:stat} reports statistics of \dataset. We collect $149$ videos across $17$ different events. The average duration of collected videos is approximately $12$ minutes with a minimum and maximum duration of $\sim4$ and $\sim20$ minutes, respectively. In total, we recorded $380$ testimonies with an average duration of $9.5$ minutes per testimony. In each testimony, there are $\sim15$ rounds of interrogator's questions and witness's response on average.  
\end{itemize}


    \begin{table}[t]
        \centering
        \resizebox{\columnwidth}{!}{
        \begin{tabular}{c|l|p{20em}}
           & \textbf{Metric} & \textbf{Value} \\ \toprule
           \multirow{6}{*}{\rotatebox{90}{Events}} & Number of Events & 149 \\
           & Avg. length of event videos & 12 minutes \\
           & Event topics & 17 [\textit{fraud}, \textit{kidnap}, \textit{robbery}, \textit{non-crime}, \textit{self-harm}, \textit{phishing}, \textit{murder}, \textit{gangsterism}, \textit{drug trafficking}, \textit{homicide}, \textit{accident}, \textit{racketeering}, \textit{fight}, \textit{bribery}, \textit{forgery}, \textit{bullying}, and \textit{sexual assault}]   \\ \midrule
           
           \multirow{3}{*}{\rotatebox{90}{Testimony}} & Number of Testimonies & 389 \\ 
           & Total Q\&A Pair Count & 6,000 \\ 
           & Interrogation Duration & 9 minutes 30 seconds (average) \\ \midrule

           \multirow{5}{*}{\rotatebox{90}{Incongruity}} & Number of unique Contexts & 1317 \\
           & Number of testimony pairs & 2979 \\
           & Number of Incongruent pairs  &  1850 \\ 
           & Number of Non-incongruent pairs & 1129 \\
           & Avg. number of Incongruent tokens & 10.34 \\ 
           
           \bottomrule
        \end{tabular}}
        \caption{Statistics of \dataset.}
        \label{tab:stat}
    \end{table}

\vspace{-0.3cm}
\subsection{Incongruence Annotations}
Following the data collection phase, we move onto preparing the dataset for incongruence identification in witness testimonies. For each event, we carefully drafted contextual questions resonating subtopics of the event. Subsequently, for each context, we identified portion of the testimonies  relevant to the context from a pair of testimonies, $T1$ and $T2$. Finally, annotators\footnote{We employ 4 annotators, 2 male and 2 female, who volunteered for the task. They belong to the age group of 25-30 years and are linguistics experts.} carefully annotate the inconsistent sections with contradicting information. This procedure entailed pinpointing textual spans reflecting the location of inconsistencies, providing a higher degree of information. To maintain uniformity and precision, we train annotators with an annotation guidelines and mandated them to adhere to them while annotating. We conduct multiple rounds of training sessions to ensure that annotators are adequately comfortable with the guidelines. Refer to Appendix~\ref{sec:appendixA} for detailed annotation guidelines.

\paragraph{Statistics:} Our dataset comprises 1,317 distinct contexts, encompassing a total of 2,979 testimony pairs. Within these pairs, 1,850 are identified as incongruent, while the remaining 1,129 are classified as non-incongruent. The average number of tokens in incongruent pairs is $10.34$, reflecting the typical span of identified incongruences within the testimonies. We summarize dataset statistics in Table \ref{tab:stat}. 


\input{prompt_6w}
% \hl{Similar to Table 2, add a table as well.}
    % \begin{table}[t]
    %     \centering
    %     \resizebox{\columnwidth}{!}{
    %     \begin{tabular}{l|p{20em}}
    %        \textbf{Metric} & \textbf{Value} \\ \toprule
    %        Number of Participants & 3 \\
    %        Number of testimony pairs & 2979 \\
    %        Number of Contexts & 1317 \\
    %        Number of Incongruent pairs  &  1850 \\ 
    %        Total number of Non-incongruent pairs & 1129 \\
    %        Average number of Incongruent tokens & 10.34 \\ 
    %        % Total number of Non - incongruent pairs: &  \\
    %         \\ \bottomrule
    %     \end{tabular}}
    %     \caption{Summary statistics.}
    %     \label{tab:stat}
    % \end{table}

\section{Methodology}
In this section, we formulate our problem definitions and describe our proposed approach, \model. 

\subsection{Problem Formulation}
Given a triplet of context $C$ and a pair of testimonies, $T1$ and $T2$, we formulate following two tasks as follows:

\begin{itemize}
    \item \textbf{Incongruence Detection:} In this task, we identify the implied incongruence between $T1$ and $T2$ considering the context $C$ as a binary task, i.e., \textit{True} or \textit{False}. 

    \item \textbf{Incongruence Reasoning \& Alignment:} For each incongruent testimony pair, we generate reasoning for the incongruence by identifying contradiction in both testimonies and extract spans of text $[p_1, p_2, \cdots, p_n] \in T_1$ and $[q_1, q_2, \cdots, q_k] \in T_2$ that reveal contradictory information.     
\end{itemize}

\subsection{Proposed Methodology:  \model}
In this section, we lay out the details of \model. Our method combines instruction tuning along with the novel $6Ws$ approach and a multi-hop reasoning framework for the identification and reasoning tasks, respectively.

\paragraph{Incongruence Detection:} The $6W$ prompt, inspired by \citet{mott1942trends}, is a structured strategy for comparing two testimonies by evaluating certain features known as the ``\textit{6 W-type questions}". In particular, it strives to reveal the following details: 
\textbf{Identity: }\textit{who was the subject?}; \textbf{Action:} \textit{what action did they do?}; \textbf{Object:} \textit{what object was used?}; \textbf{Location:} \textit{where it was done?}; \textbf{Time:} \textit{when did it happen?}; and \textbf{Reason:} \textit{why they did it?}. 

This method seeks to find \textit{consistency}, \textit{discrepancies}, or \textit{absences} in the details offered by witnesses. In our proposed method, we leverages the nuances of these $6W$ parameters in prompt. By incorporating these factors, we hypothesize that the prompt construction would direct the model's attention to specific areas of the testimony, allowing for a more detailed comparison. For each $W$ in $6Ws$, we prompt the model if ``witness A's details \texttt{[mask]} witness B's details, where \texttt{[mask]} is defined as one of the three labels: `\textit{agrees}', `\textit{contradict}', or `\textit{absent}'. The label \textit{agrees} is expected when both testimonies provide consistent or additional details that complement each other, whereas, the label \textit{contradict} is used when testimonies directly contradict each other. In cases where one testimony lacks information on a topic covered by the other is labelled as \textit{absent}. These labels instruct the model to compare each component of the testimonies independently, allowing for more precise detection of contradictions or agreements between the witnesses' claims. An instance of a prompt with $6Ws$ statements is shown in Figure \ref{fig:prompt:6w}. 

\input{multi_hop_table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \paragraph{Incongruent Reasoning and Alignment:} Testimonies frequently contain intricate details and subtle discrepancies that may not be well represented in a small training set commonly utilized for few-shot learning. On the other hand, fine-tuning necessitates a large amount of labeled data, which can be expensive and time-consuming to obtain, especially given the variety and nuanced inconsistencies found in testimony.

% \paragraph{Incongruent Reasoning and Alignment:} Testimonies often include intricate details and subtle discrepancies that are poorly represented in the small training sets typical of few-shot learning. Meanwhile, fine-tuning requires substantial labeled data, which is costly and time-intensive to gather, especially given the nuanced inconsistencies in testimony.

% To address these challenges, we developed a \textbf{multi-hop reasoning} framework inspired by the work of \citet{fei2023reasoning,chain-of-thought}. This framework leverages common sense understanding to enhance the extraction of contradictory spans by integrating information from multiple text segments and iteratively linking and reasoning across them. This approach allows the model to better understand the context surrounding contradictions, leading to more accurate detection and extraction of incongruent spans. Additionally, we experimented with varying the number of reasoning hops to assess their impact on performance, with detailed results provided in Appendix~\ref{sec:appendixE}.

% We employ a three-hop strategy using distinct prompts to progressively enhance \model's reasoning abilities. This structured methodology addresses the problem's complexities by incrementally refining the model's understanding.
% \begin{itemize}
%     \item \underline{Identifying Fine-grained Key Details}: The first prompt aims to extract critical facts from both accounts relevant to the given inquiry. This step ensures the model accurately captures precise information in each testimony, laying a solid foundation for subsequent reasoning.
%     \item \underline{Incongruence Reasoning}: The second prompt requires applying common sense and logical reasoning to detect potential discrepancies between the accounts. By analyzing the context and content, the model identifies subtle inconsistencies that may not be immediately evident.
%     \item \underline{Extracting Conflicting Spans}: The final step focuses on pinpointing specific text spans with contradictions based on the prior rationale. This ensures precision in identifying and extracting segments that directly contradict one another.
% \end{itemize}



% This incremental reasoning approach mimics human behavior, progressing from simpler to complex problems, and simplifies span extraction while addressing challenges in incongruence prediction. By leveraging \model's multi-hop ability to integrate and reason across layers of information, we achieve precise and reliable identification of inconsistent spans. Table \ref{tab:multi-hop} illustrates the three-hop strategy: \textit{identify key details}, \textit{infer reasoning}, and \textit{extract incongruent spans}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Incongruent Reasoning and Alignment:} Testimonies frequently contain intricate details and subtle discrepancies that may not be well represented in a small training set commonly utilized for few-shot learning. On the other hand, fine-tuning necessitates a large amount of labeled data, which can be expensive and time-consuming to obtain, especially given the variety and nuanced inconsistencies found in testimony.

To overcome these issues, we created a \textbf{multi-hop reasoning} framework based on the work of \citet{fei2023reasoning,chain-of-thought}. This framework utilizes the ability of common sense understanding and improves the extraction of contradicting spans by combining information from numerous segments of text and repeatedly linking and reasoning across them. This enables the model to gain a thorough understanding of the context around contradictions, resulting in more accurate detection and extraction of incongruent spans. Additionally, we experimented with varying the number of reasoning hops to assess their impact on performance. Detailed results provided in Appendix~\ref{sec:appendixE}.

% \begin{figure*}
%     \centering
%     \includegraphics[width=1\linewidth]{THOR LATEST.drawio.png}
%     \caption{Caption}
%     \label{fig:enter-label}
% \end{figure*}

% \subsubsection{Three-Hop Reasoning}

We adopt three-hop strategy with different prompts to gradually improve \model's reasoning capabilities. This organized approach addresses the intricacies of the problem by gradually refining the model's understanding.

\begin{itemize}
    \item \underline{Identifying Fine-grained Key Details}: The first prompt focuses on extracting fine-grained critical facts from the two accounts that relate to the supplied inquiry. This stage ensures that the model correctly understands the precise information presented in each testimony, establishing the groundwork for later reasoning.
    \item \underline{Incongruence Reasoning}: The second task requires using common sense and logical reasoning to uncover probable discrepancies between the accounts. By examining the context and content of the testimony, the model can uncover small inconsistencies that may not be immediately obvious.
    \item \underline{Extracting Conflicting Spans}: The third task focuses on extracting specific text spans that have contradictions using the rationale from the previous stage. This stage entails identifying the specific segments that contradict each other, guided by the previous conclusions, and guaranteeing precision in contradiction identification.
\end{itemize}

This incremental reasoning approach mimics human-like behaviour, which progresses from simpler to more complicated problems, simplifies span extraction while effectively tackling the challenges of direct incongruence prediction. By exploiting \model's multi-hop capacity to integrate and reason through various layers of information, we obtain inconsistent spans more precisely and reliably. Table \ref{tab:multi-hop} depicts a three-hop strategy to \textit{identify the key-details}, \textit{infer the reasoning}, and \textit{extract the incongruent span}.


\section{Experiments, Results, and Analysis}

This section presents the experimental setup, the results obtained, and a detailed analysis of our findings.

\input{results}
\input{result-span}

\subsection{Baselines}
We adopt three classes of baseline methods for comparison: 

\subsubsection{\textbf{a)} Pre-trained MLM with finetuning:}
We fine-tune three transformer models -- Longformer \cite{beltagy2020longformer}, Big-Bird \cite{zaheer2020big}, and Big-Bird-MNLI fine-tuned on the MNLI dataset. We select these baseline for their capacity to handle larger context of up to $4K$ tokens as the max combined input size is $\sim600$ tokens -- surpassing the $512$ token limit of standard models like BERT, RoBERTa, etc.

\subsubsection{\textbf{b)} Pre-trained MLM with prompt tuning:}
Inspired by the works of \cite{prompt_liu,schick2021exploitingclozequestionsshot}, we develop and fine-tune MLM models using two distinct prompt templates using \texttt{[input]} defined as a question-answer triplet, \textbf{Question Prompt:} 
     ``\texttt{[input]} Is there a direct contradiction between the statements made by Witness A and Witness B? \texttt{[mask]}." and \textbf{Regular Prompt:} 
     ``\texttt{[input]} A? \texttt{[mask]} B."

% \begin{itemize}
%     \item \textbf{Question Prompt:} 
%     ``\texttt{[input]} Is there a direct contradiction between the statements made by Witness A and Witness B? \texttt{[mask]}." 
    
%     \item \textbf{Regular Prompt:} 
%     ``\texttt{[input]} A? \texttt{[mask]} B."
% \end{itemize}


\subsubsection{\textbf{c)} Pre-trained LLM with instruction tuning:}
We utilized four large language models (LLMs) for our experiments: LLama-3 \cite{dubey2024llama}, Mistral \cite{jiang2023mistral}, Gemma \cite{team2024gemma}, and Qwen \cite{bai2023qwen}. We instruction-tuned each one using the question prompt described above as the instructions.


\subsection{Experimental Settings}
We perform experiments on \dataset\ and use 65:35 split
to create train (1938), and test (1049) sets. 
For 6W instruction tuning, we annotate 151 samples with 6W template where the [mask] in the template(refer to Figure \ref{fig:prompt:6w}) is replaced with correct label(agrees, contradicts, absent) and use them as training set. We employ classical evaluation metrics, such as, precision, recall, and F1-score for both tasks. Additionally, we report \textit{coverage} for the span extraction task, which computes the overlaps between the predicted span considering the given testimony. This is crucial as \model\ employs LLMs to generate the spans instead of extracting it. Thus, we calculate the ratio of tokens in the predicted span belonging to the testimony or otherwise. Hence, we define \textit{coverage} as: 
$$ \text{Coverage} = \frac{|\text{Predicted Span} \cap \text{Testimony}|}{|\text{Predicted Span}|}
$$
Implementation details are furnished in the Appendix~\ref{sec:appendixB}. 

\input{error-analysis}
\input{Human_eval}
\vspace{-0.3cm}
\subsection{Results}
We report precision, recall, and F1-scores for incongruence detection in Table \ref{table:performance}. In Table \ref{table:performance:PLM}, we list comparative results in a fine-tuned and two prompt-tuned settings for three MLM models, i.e., Longformer, Big-Bird, and Bird-MNLI. Though we observe minimal variations across different tuning strategies, Big-Bird reports the best F1-score of $0.64$ in the prompt-tuned settings. In comparison, Longformer yields the most significant improvement when moving from fine-tuning (F1-score of $0.59$) to question-prompt-tuning (F1-score of $0.63$), highlighting its potential for improved performance with more tailored prompts. Moreover, question-prompt-tuned models score relatively better than the other two settings for all models.  

Similarly, we report the results for instruction-tuned LLMs including our proposed \model\ model in Table \ref{table:performance:LLM}. With question-prompts, Mistral [7B] reports the best F1-score of $0.71$. In comparison, other LLMs, such as, Llama-3 [8B], Qwen [7B], and Gemma [9B], report inferior F1-scores of $0.67$, $0.67$, and $0.65$, respectively. Overall, performances of LLMs with question prompts are better than the question-prompt-tuned MLM models. Finally, we report the performance of \model\ with $6Ws$ prompts. It is evident from Table \ref{table:performance} that \model\ demonstrates the best performance of $0.75$ F1-score with Mistal [7B] as the foundational model -- a clear improvement of $+5.63\%$ in F1-score against Mistal [7B] with question-prompts. Furthermore, we observe that \model\ yields improved performance for each LLM in the range of $[3-8\%]$ against the question-prompt strategy. This indicates the significance of constructing our instructions with $6Ws$ prompts.

Table \ref{table:performance:span} shows comparative results on the incongruence reasoing and alignment task. As mentioned earlier, we project the incongruence reasoning task as the span identification task through a generative framework. In the few-shot setup, QWEN-2 [7B] exhibits the best performance with an F1-score of $0.447$ in T1 and $0.441$ in T2 for the span identification task. It also yields the best F1-score of $0.466$ for the alignment task.
In contrast, the multi-hop approach significantly outperforms the few-shot baselines by a margin of $>9\%$ in F1-score for both span identification and alignment task.
Llama-3 demonstrates an F1-score of $0.49 (+9.63\%)$ on T1 and $0.49  (+12.92\%$) on T2 for the span identification task. In the alignment task as well, it records an F1-score of $0.51$, which $+9.87\%)$ improvement against the best baseline. Gemma, as the second-best model, also reports notable improvements. It achieves an F1-score of $0.49 (+9.63\%)$ on T1, $0.489 (+10.8\%)$ on T2, F1-score of $0.507 (+8.79\%)$ in the alignement task.
We also observe that the coverage improves for most of models in the multi-hop setup. It signifies that the generated spans increasingly aligned with the relevant testimonies. Additionally, we experiment with GPT-4o mini. See Appendix~\ref{sec:appendixF}.

\subsection{Error Analysis}

We investigate model's outcome for specific errors. Table \ref{tab:error} displays two randomly selected sample (due to brevity, we present other error cases in Appendix~\ref{sec:appendixD}) from the \dataset\ dataset along with its predicted and reference incongruent spans. We also incorporate the best-performing baseline, Llama-3(Few-Shot), for a fair comparison. 

% \input{error-analysis}




    




    




\subsection{Human Evaluation}

To conduct human evaluation, we randomly sample the outputs of 15 test set examples for both the baseline and multi-hop Llama-3 models. Thirty human evaluators rate the quality of the generated spans across four categories: \textit{clarity}, \textit{mutual exclusivity}, \textit{context relevance}, and \textit{coverage}, considering identified incongruencies. Each category has three rating levels: poor, fair, and good. Evaluators also assess whether all relevant contradictions are captured and whether unnecessary contradictions are included, choosing between two options: yes or no. This ensures the models' completeness and precision. For detailed evaluation criteria, refer to Appendix~\ref{sec:appendixC}. Table \ref{tab:Human-eval} shows the percentage of times evaluators preferred each model's outputs across the defined categories.
 
% To conduct human evaluation, we randomly sample the output of 15 samples from the test set for both the baseline and the multi-hop Llama-3 models. We ask 30 human evaluators to rate the quality of the generated spans across four key categories, i.e., \textit{clarity}, \textit{mutual exclusivity}, \textit{context relevance}, and \textit{coverage} considering the identified incongruency. Each category maps onto three ratings levels -- poor, fair, and good. Additionally, we ask the evaluators to assess whether all relevant contradictions are captured for a given input and whether any unnecessary contradictions are included, providing them with two options: yes or no. This ensures the completeness and the precision of the models. For a detailed breakdown of the evaluation criteria and definitions, please refer to the Appendix ~\ref{sec:appendix}. Table \ref{tab:Human-eval} reports the percentage of the times evaluators preferred each model's output across the defined categories.
% This ensures the completeness and the precision of the models in capturing relevant contradictions and avoiding extraneous or irrelevant ones. 
% For a detailed breakdown of the evaluation criteria and definitions, please refer to the Appendix ~\ref{sec:appendix}. Table \ref{tab:Human-eval} reports the percentage of the times evaluators preferred each model's output across the defined categories of \textit{good}, \textit{fair}, or \textit{poor}.
% We observe that evaluators consistently find the contradictions generated by our model \model\ to be clearer, more logically sound, mutually exclusive, contextually relevant, and precise compared to the baseline model, reinforcing the overall effectiveness and supporting the assertion of \model's superiority. 


% \input{Human_eval}






\section{Conclusion}
% In this paper, we introduce a novel task of multi-eyewitness incongruence detection, aiming at detecting incongrunce in two witness statement and precisely extracting the exact span responsible for these incongruencies. To support this research, we develop a new dataset, \dataset\ containing context paired with responses from two testimonies, along with annotated incongruent spans. Further, we present \model\ a novel instruction tuning based on 6Ws for incongruence detection and multi hop reasoning framework  for incongruence span extraction. Our evaluation demonstrates that \model\
% outperforms baselines across three sets of evaluation metrics. In addition, human evaluation validate the quality of the spans generated by \model\ in the form of high scores on different metrics defined for extracted contradiction spans. We believe that our contributions will inspire further exploration in the domain of eyewitness testimony analysis and explanability.

In this paper, we introduce a novel task of multi-eyewitness incongruence detection, focusing on identifying and extracting spans responsible for inconsistencies in two witness statements. To support this, we develop \dataset, a dataset pairing contexts with testimony responses and annotated incongruent spans. We also propose \model, an instruction-tuned framework based on 6Ws for detecting incongruence and a multi-hop reasoning approach for span extraction. Our evaluation shows \model\ outperforms baselines across various metrics, with human evaluations validating the quality of generated spans. We hope our contributions inspire further research in eyewitness testimony analysis and explainability.

\section{Limitations}

This study has two key limitations. First, the annotations used in our work relied on expert human annotators, ensuring precision in identifying nuanced incongruences. However, this reliance on manual processes highlights the need for semi-automated methods to enhance scalability without compromising accuracy. Second, the framework was evaluated primarily in the domain of crime-related narratives. While this ensured depth and relevance within the chosen context, extending the framework to other domains, such as medical or historical testimonies, would broaden its generalizability.

% This approach, while pioneering in detecting and reasoning about inconsistencies in eyewitness testimony, is not without limits. The multi-hop reasoning architecture, while successful, is complex and prone to error propagation, with flaws in early reasoning phases influencing subsequent stages. Furthermore, the computational demands of large language models (LLMs) may limit the framework's scalability for larger datasets or real-time applications.


\section{Ethical Considerations}

This study adhered to strict ethical guidelines during data collection and analysis to ensure fairness, transparency, and respect for privacy. The testimonies used in the MIND dataset were collected under controlled conditions with informed consent from all participants. However, applying the proposed framework to real-world scenarios raises ethical concerns, such as the potential misuse of automated incongruence detection systems in legal or investigative contexts without proper oversight. It is crucial to emphasize that this framework is intended as an aid to human decision-making rather than a replacement. Future implementations must prioritize transparency, accountability, and ethical usage to mitigate biases and prevent unjust outcomes.


% The work presented in this study has been conducted with the utmost adherence to ethical standards. All data used in the development of the dataset is entirely simulated and does not involve any real-life or sensitive personal information. The testimonies were created in controlled, fictional settings with human participants providing input in response to fabricated scenarios, ensuring that no privacy concerns or ethical violations occurred during data collection. Furthermore, all participants involved in the data creation process, including annotators and individuals acting as witnesses, provided informed consent, and their contributions were anonymized and securely handled to protect their identities.



\bibliography{custom}

\appendix

\section{Annotation Guidelines}
\label{sec:appendixA}

\input{hops_results}
\input{GPT}

To maintain uniformity and precision, we train annotators with an annotation guidelines and mandated them to adhere to them while annotating. We conduct multiple rounds of training sessions to ensure that annotators are adequately comfortable with the guidelines. 
\begin{itemize}
    \item \underline{Context Definition:} Use predetermined questions to define the context for each event. Ensure that the context is clearly and accurately established for every annotation task.
    
    \item \underline{Utterance Extraction:} Extract utterances from witness testimonies that directly respond to the established context. Each extracted utterance should be relevant and provide information related to the specific context.
    

    \item \underline{Collecting Responses:} Gather responses from different eyewitnesses for the same predetermined question. Ensure that each witness’s response is properly attributed and associated with the correct context.
    
    \item \underline{Contradiction Examination:} For each pair of responses from different witnesses, examine them for contradictions within the same context based on the following criteria:
        \begin{itemize}
            \item \text{Identity Differences}: Discrepancies in who is involved in the event.
            \item \text{Actions Described}: Inconsistencies in the actions or behaviors described by the witnesses.
            \item \text{Object Inconsistencies}: Differences in the objects or items mentioned.
            \item \text{Timing Discrepancies}: Variations in the timing or sequence of events.
            \item \text{Location Variations}: Differences in the locations or settings described.
            \item \text{Motivation Differences}: Variations in the perceived motivations or intentions of individuals involved.
        \end{itemize}
    

    \item \underline{Identification and Marking:} Identify and mark specific phrases or segments that are logically inconsistent when the context is similar. Use the tag \( I_n \) for indicating incongruencies and \( C_n \) for context, where \( n \) represents the contradiction and question number, respectively.
    
    \item \underline{Labeling:} Label the context and answer triplets (responses from two different witnesses for the same question) as \textbf{1} (if the responses are logically inconsistent) or  \textbf{0} (if the responses are not logically inconsistent).
\end{itemize}
% \newpage
\input{ error_analysis_appendix}
% \input{ hops_results}
% \input{ GPT}


% % \subsection{HyperParameters}
\section{HyperParameters}
\label{sec:appendixB}
Both MLM and LLM models were configured with a context length of 1024 tokens and trained using the Adam optimizer \cite{loshchilov2019decoupledweightdecayregularization} at a learning rate of 2e-4 for 7 epochs with a batch size of 8. For Instruction tuning, Unsloth was employed for parameter-efficient fine-tuning during instruction tuning. The lora\_alpha parameter \cite{hu2021loralowrankadaptationlarge} was set to 16, and lora\_dropout was set to 0. 
% \raggedright
For Few shot and Multi-Hop Setting, the model generates up to 512 tokens, with a specific end-of-sequence token guiding the termination (eos\_token\_id=terminators). The sampling mechanism is active (do\_sample=True), with a temperature of 0.6 and a top\_p value of 0.9 to balance diversity and coherence.
All the experiments were performed on V100 PCIe Tesla GPUs.
% \par


% % \subsection{Human Evaluation}
\section{Human Evaluation}
\label{sec:appendixC}
Evaluators were given 15 inputs, which had 29 outputs generated by the LLama(FS) setup and 27 outputs generated by the LLama(MH) setup.
The Evaluators assesses the contradictions based on the following questions:
\begin{enumerate}
    \item \textbf{Contradiction Clarity:}  How clear is the contradiction between the statements?
    \begin{itemize}
        \item poor: The statements do not contradict each other at all. They describe unrelated facts or facts that are complementing each other
        \item Fair: The statements weakly contradict each other. They may describe different aspects of the same subject in a way that implies some opposition, but the contradiction is not clear or strong.
        \item Good: The statements clearly and directly contradict each other.
    \end{itemize}
    \item \textbf{Logical Exclusivity:} How logically exclusive are the statements?

    \begin{itemize}
        \item poor: The statements are logically consistent. Both statements can be true simultaneously without any logical conflict.
        \item Fair: The statements have some logical inconsistencies, but there are ways to interpret the statements that make them not fully contradictory.
        \item Good: The statements are logically exclusive. They present mutually exclusive facts or states that cannot both be true at the same time. 
    \end{itemize}
    \item \textbf{Context Relevance:}How relevant is the contradiction to the context or question being asked?
    \begin{itemize}
    \item poor: Contradiction is irrelevant to the context or question. Model hallucinates or address unrelated topics.
        \item Fair:  The statements are related but the contradiction may not be crucial or highly significant to the context.
        \item Good: Contradiction is highly relevant and significant.
    \end{itemize}
    \item \textbf{Coverage:} How well does the statement address all necessary aspects of the contradiction? 
    \begin{itemize}
        \item Poor:Key aspects are missing or irrelevant details are included
        \item Fair: Covers some necessary aspects but misses or adds unnecessary information.
        \item Good: Fully covers all necessary aspects without excess information.
    \end{itemize}
\end{enumerate}


% \section{Error Analysis}

% We categorize the errors into four distinct types, encompassing the correct and incorrect predictions of both incongruent and congruent pairs. In the first context, the first hop accurately captured the key details, noting that Shaun is being assisted by the corner in both testimonies, although the nature of the help differs. However, in the subsequent hop, the model faltered in reasoning. It established that assistance was provided in both accounts and recognized the difference in the nature of the help but focused primarily on whether help was given, rather than on the nature of the assistance. Consequently, the model concluded that there was no contradiction, as help was reported in both statements. This conclusion overlooked the context's specific inquiry into the nature of the assistance. Hence, this indicates that there was an issue with the reasoning in the second hop concerning the context. Meanwhile, the baseline model, while detecting the contradiction, inaccurately identified the boundaries of the conflicting spans. In the second context,  the models misinterpreted consistent statements as contradictions, particularly in the 2nd and 3rd hops, where subtle differences in the testimonies led to erroneous conclusions. Similarly, the baseline model also incorrectly predicts contradictions in logically consistent narratives; we observe that both systems strive to understand logically inclusive statements. Overall, the analysis highlights the models' difficulties with reasoning and fine-grained span identification, underscoring the need for enhanced capabilities in detecting incongruence in complex narrative data.





% \subsection{Error Analysis}
\section{Error Analysis}
\label{sec:appendixD}

We categorized the errors into three types:
\begin{enumerate}
    \item \textbf{Reasoning Errors:} These occur when the models fail to reason and identify contradictions.
    \item \textbf{Boundary Errors:} These occur when the models reason correctly but provide only partial answers.
    \item \textbf{Inference Errors:} These arise when models, despite correct reasoning, fail to infer correctly based on instructions, such as when the output doesn't match the required format.
\end{enumerate}

The Error Analysis Table in the main paper depicts the reasoning errors. In the first context, the first hop accurately captured the essential details, noting that Shaun is being assisted by the corner in both testimonies, although the nature of the help differs. However, in the subsequent hop, the model failed in reasoning. It established that assistance was provided in both accounts and recognized the difference, like the help, but focused primarily on whether help was given, rather than on the nature of the assistance. Consequently, the model concluded that there was no contradiction, as help was reported in both statements. This conclusion overlooked the context's specific inquiry into the nature of the assistance. Hence, this indicates an issue with the reasoning in the second hop concerning the context. Meanwhile, the baseline model, while detecting the contradiction, inaccurately identified the boundaries of the conflicting spans. In the second context,  the models misinterpreted consistent statements as contradictions, particularly in the 2nd and 3rd hops, where subtle differences in the testimonies led to erroneous conclusions. The baseline model also incorrectly predicts contradictions in logically consistent narratives; we observe that both systems strive to understand logically inclusive statements. Similarly, Boundary and inference errors are depicted in the second and fourth context of table \ref{tab:error-appendix} respectively. Overall, we observed that \model\ significantly outperforms the best-performing baseline system, providing empirical evidence that it can be effectively used for incongruent span identification.

% \input{ error_analysis_appendix}

% \subsection{HOPS}
\section{Analysis of Reasoning Hops Configuration}
\label{sec:appendixE}
We evaluated the performance of our framework with one-hop, two-hop, and three-hop configurations to analyze the impact of reasoning hops on incongruity detection. The three-hop configuration aligns with the subtasks: (Hop 1) Identifying Fine-grained Key Details, (Hop 2) Inferring Incongruence Reason, and (Hop 3) Extracting Conflicting Spans, and achieved the best performance as it allowed the model to focus on each subtask independently. In the one-hop setup, the model struggled to combine detail extraction, reasoning, and contradiction identification into a single step, leading to a significant performance drop due to cognitive overload. The two-hop configuration, which merged detail extraction with reasoning in the first hop and focused on contradiction extraction in the second, showed moderate improvement but still suffered from task interference in the first hop. Table \ref{tab:hops-results} shows the results for the LLAMA-3 (8B) model, where the three-hop approach consistently outperformed the others across precision, recall, and F1 metrics for both tasks and incongruence alignment. 



% \subsection{GPT-4}
\section{Performance Comparison with GPT-4o Mini}
\label{sec:appendixF}
we experiment with GPT-4o mini to benchmark its performance against INTEND’s existing setup using LLaMA-3 (8B). We observe that the performance of INTEND with both models is extremely competitive. The results are shown in the table \ref{tab:GPT-results}.
\newpage
% \input{ hops_results}
% \input{ GPT}

\end{document}
