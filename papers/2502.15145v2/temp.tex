\subsection{Estimation of $\alpha$}
In this subsection, we give a theoretical upper bound of the estimation error of $\alpha$. 
\begin{theorem}[Estimation of $\alpha$]\label{thm:est of alpha}
    Assume that we execute the Algorithm \ref{alg: vpo-fl-general} with the Assumption \ref{assum:gap}, then for each $t \in [T],$ with probability at least $1-\delta$ we have 
    \begin{align}
        \|\alpha^* - \alpha^t\|_\infty \le \frac{1}{t}\sum_{k=1}^{t}\|\alpha^* - \hat{\alpha}^k\|_\infty\le \gamma^{-1}\cdot \widetilde{\cO}\left(\mathrm{poly}(m,e^B, \exp(1/\beta), d,\log(1/\delta))\right)\cdot \frac{1}{\sqrt{t}}.\label{eq:estimate alpha final result}
    \end{align}
\end{theorem}
\begin{proof}
First,  for any $k \in [t],$  we estimate $\hat{\alpha}$ with $\tilde{\theta}_1^k, \tilde{\theta}_2^k, \cdots, \tilde{\theta}_m^k$, where $\tilde{\theta}_i^k = \argmin_\theta L_i^k(\theta)$ only minimizes the log-likelihood loss without optimistic exploration. Define $\delta_i^k(x,y)=\left|r_i^{\tilde{\theta}_i^k}(x,y_1) - r_i^{\tilde{\theta}_i^k}(x,y_2) - (r_i^*(x,y_1) - r_i^*(x,y_2))\right|$.
then, by theorem \ref{thm:mle}, with probability $1-\delta$ we have 
\begin{align*}
    \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}&\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}^2\\
    &\le 2 \log (d_\cF(1/k^2)/\delta)+1/k,
\end{align*}
    where $\cF = \{\mathrm{Softmax}(x_i)\mid 1\le i\le m, x_i \le 1\}$, and the log of $\varepsilon-$covering number $\log (d_\cF(1/k^2)) = \widetilde{\cO}(m)$.

    thus by the Cauchy's inequality, we can get 
    \begin{align}
        &\sqrt{2k\log(d_\cF(1/k^2)/\delta)+1}\nonumber \\&\ge \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}\nonumber\\
        &\ge \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}\nonumber\\
        &\qquad - \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\hat{\alpha}_i^k\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}.\label{alpha:step1}
    \end{align}

    Now we bound the difference of $\alpha$ based on the difference of the softmax distribution.

    Fixed $k$, since the upper bound of $0\le r_i^{\tilde{\theta}_i^{k}}(x,y) \le B$ and $0\le r^*(x,y) \le B$, define $X_i = |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|\le B$ and $X_i^* = |r^*_i(x,y_1) - r^*_i(x,y_2)|\le B$, then 
    \begin{align*}
        &\left\|\textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\hat{\alpha}_i^{k}\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\|_{\mathrm{TV}}\\
        &= \sum_i \left|\frac{e^{X_i\cdot \hat{\alpha}_i^k}}{\sum_j e^{X_i\cdot \hat{\alpha}_j^k}}-\frac{e^{X_j^*\cdot \hat{\alpha}_i^k}}{\sum_j e^{X_j^*\cdot \hat{\alpha}_j^k}}\right|\\
        &=\sum_i \left|\frac{\sum_{j\neq i}e^{X_j^*\cdot \hat{\alpha}_j^k+X_i\hat{\alpha}_i^k }-e^{X_j\cdot \hat{\alpha}_j^k+X_i^*\hat{\alpha}_i^k }}{(\sum_j e^{X_j\cdot \hat{\alpha}_j^k})(\sum_j e^{X_j^*\cdot \hat{\alpha}_j^k})}\right|\\
        &\le \sum_i \left|\frac{\sum_{j\neq i}e^{X_j^* \hat{\alpha}_j^k+X_i\hat{\alpha}_i^k}(e^{\delta_j^{k} \hat{\alpha}_j^k + \delta_i^{k} \hat{\alpha}_i^k}-1)}{m^2}\right|,\end{align*}
where the last inequality uses the fact that $\sum_{j}e^{X_j\cdot \hat{\alpha}_i^k} \ge m$ and $\sum_j e^{X_j^* \hat{\alpha}_j^k} \ge m$.
Now since $e^{X_j^* \hat{\alpha}_j^k + X_i \hat{\alpha}_i^k}\le e^{B(\hat{\alpha}_i^k + \hat{\alpha}_j^k)}\le e^B$, and $e^a-1\le e^B\cdot a$ for every $0\le a \le B$, we can have 
        \begin{align*}
        &\le \sum_i \left|\frac{\sum_{j\neq i}e^{2B}(\delta_j^{k} \hat{\alpha}_j^k + \delta_i^{k} \hat{\alpha}_i^k)}{m^2}\right|\\
        &\le \frac{e^{2B}}{m^2}\sum_i \sum_{j\neq i}(\delta_j^{k} \hat{\alpha}_j^k + \delta_i^{k} \hat{\alpha}_i^k)\\
        &\le \frac{e^{2B}}{m}\sum_i \delta_i^{k} \hat{\alpha}_i^k.
    \end{align*}

    Now 
    choose the index $l = \argmax_{i \in [m]} X_i^* \circ |\alpha_{i}^* - \hat{\alpha}_i^k|$, and WLOG, assume $\hat{\alpha}_{l}^k = \alpha_{l}^* + \varepsilon$,
    then 
    we can bound 
    \begin{align*}
        &\left\|\textrm{Softmax}(\hat{\alpha}_{l}^k \cdot |r_{l}^*(x,y_1)-r_{l}^*(x,y_2)|)-\textrm{Softmax}(\alpha_{l}^*\cdot |r_{l}^*(x,y_1)-r_{l}^*(x,y_2)|)\right\|_{\mathrm{TV}}\\
        &\ge \left|\frac{e^{X_{l}^*\hat{\alpha}_l^k}}{\sum_j e^{X_j^*\hat{\alpha}_j^k}} - \frac{e^{X_l^*\cdot \alpha_l^*}}{\sum_j e^{X_j^*\alpha_j^*}}\right|\\
        &= \left|\frac{e^{X_l^*(\alpha_l^* + \varepsilon)}}{e^{X_l^*(\alpha_l^* + \varepsilon)}+\sum_{j\neq l} e^{X_j^*\hat{\alpha}_j^k}} - \frac{e^{X_l^*\cdot \alpha_l^*}}{e^{X_l^* \alpha_l^*}+\sum_{j\neq l} e^{X_j^*\alpha_j^*}}\right|\\
        &=\left|\frac{\sum_{j\neq l}e^{X_j^* \alpha_j^* + X_l^*(\alpha_l^* + \varepsilon)}-e^{X_j^* \hat{\alpha}_j^k + X_l^* \alpha_l^*}}{(\sum_j e^{X_j^*\hat{\alpha}_j^k})(\sum_j e^{X_j^*\alpha_j^*})}\right|.
    \end{align*}
    Now by the selection of the $l$, we can have 
    $$X_j^* \alpha_j^* + X_l^*(\alpha_l^* + \varepsilon) \ge X_j^* \hat{\alpha}_j^k + X_l^* \alpha_l^*,$$
    hence 
    $$e^{X_j^* \alpha_j^* + X_l^*(\alpha_l^* + \varepsilon)}\ge e^{X_j^* \hat{\alpha}_j^k + X_l^* \alpha_l^*}.$$
    Also, since $\sum_i\alpha_i^* = \sum_i \hat{\alpha}_i^k = 1,$ and the fact that $\hat{\alpha}_l^k = \alpha_l^* + \varepsilon,$ we can further derive 
    $$\sum_{j\neq l} \alpha_j^* = \sum_{j\neq l} \hat{\alpha}_j^k + \varepsilon.$$

    then at least one $j'\neq l$ such that $\alpha_{j'}^* \ge \hat{\alpha}_{j'}^k + \varepsilon/m$.
    then 
    \begin{align*}
        e^{X_{j'}^* \alpha_{j'}^*+ X_l^*(\alpha_l^*+\varepsilon)}-e^{\hat{\alpha}_{j'}^k X_{j'}^* + X_l^*\alpha_l^*}&\ge ^{X_{j'}^* \hat{\alpha}_{j'}^k+ X_l^*(\alpha_l^*+\varepsilon)}-e^{\hat{\alpha}_{j'}^k X_{j'}^* + X_l^*\alpha_l^*}
        \\&\ge e^{X_l^*(\alpha_l^* + \varepsilon)} - e^{X_l^* \alpha_l^*}\\
        &\ge e^{\alpha_l^* X_l^*}(e^{\varepsilon X_l^*}-1)\\
        &\ge e^{\alpha_l^* X_l^*}\cdot \varepsilon X_l^*.
    \end{align*}
    Thus,
    \begin{align*}
        &\left\|\textrm{Softmax}(\hat{\alpha}_l^k \cdot |r_l^*(x,y_1)-r_l^*(x,y_2)|)-\textrm{Softmax}(\alpha_l^*\cdot |r_l^*(x,y_1)-r_l^*(x,y_2)|)\right\|_{\mathrm{TV}}\\
        &\ge \frac{e^{\alpha_l^* X_l^*}}{(\sum_j e^{X_j^*\hat{\alpha}_j^k})(\sum_j e^{X_j^*\alpha_j^*})} \cdot \varepsilon X_l^*\\
        &\ge \frac{1}{(me^B)^2}  \cdot |\hat{\alpha}_l^k - \alpha_l^*| X_l^*.
    \end{align*}
    Now define $X^* =  (X_1^*, X_2^*, \cdots, X_m^*)^\top \in \RR^m$ and $|\alpha^* - \hat{\alpha}^k| = (|\alpha_1^*-\hat{\alpha}_1^k|, \cdots, |\alpha_m^*-\hat{\alpha}_m^k|)^\top \in \RR^m.$ We can get 
    $$\|X^*\circ |\alpha^* - \hat{\alpha}^k|\|_\infty\le m^2e^{2B} \left\|\textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\|_{\mathrm{TV}},$$
    where $X\circ Y$ denotes the Hadamard product.
    then take the expectation we can get 
    \begin{align*}
        &\EE_{x,y\sim \cD_s}\|X^*\circ |\alpha^* - \hat{\alpha}^k|\|_\infty\\&\qquad \le m^2e^{2B} \EE_{x,y\sim \cD_s}\left\|\textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\|_{\mathrm{TV}}.
    \end{align*}


    
%     Now suppose $i' = \argmax_i |\alpha_i^*- \hat{\alpha}_i^k|$, then by the definition of $i$ and $i'$, we have 
%     \begin{align*}
%         \|\alpha^* - \hat{\alpha}^k\|_\infty &= |\alpha_{i'}^* - \hat{\alpha}_{i'}^t|\\
%         & \le \frac{X_{i'}|\alpha_{i'}^* - \hat{\alpha}_{i'}^t|}{X_i} \cdot \gamma\\
%         &\le \gamma |\alpha_i^* - \hat{\alpha}_i^k| = \varepsilon\gamma.    \end{align*}
% Hence 
% \begin{align*}
%     &\left\|\textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\|_{\mathrm{TV}}\\
%     &\ge \frac{1}{(me^2)^2} \gamma \cdot \varepsilon\\
%     &\ge \frac{1}{(me^2)^2} \gamma^2\|\alpha^* - \hat{\alpha}^k\|_\infty
% \end{align*}

% Now we have 
% \begin{align*}
%     &2\log(|\cF|/\delta) \\
%     &\ge \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}^2\\
%     &\ge \frac{1}{t}\left(\sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}\right)^2.
% \end{align*}
    % Hence 
    % \begin{align*}
    %     &\sqrt{2t\log(|\cF|/\delta)}\\&\ge \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}\\
    %     &\ge \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}\\
    %     &\qquad - \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\hat{\alpha}_i^k\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}\\
    %     &\ge \frac{(t-1)\gamma^2}{m^2e^{2B}}\|\alpha^* - \hat{\alpha}^k\|_\infty \\
    %     &\qquad - \sum_{s=1}^{k-1}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x^s,y_1^s)-r_i^{\tilde{\theta}_i^k}(x^s,y_2^s)|)-\textrm{Softmax}(\hat{\alpha}_i^k\cdot |r_i^*(x^s,y_1^s)-r_i^*(x^s,y_2^s)|)\right\| _{\mathrm{TV}} - O(\sqrt{t})\\
    %     &\ge \frac{(t-1)\gamma^2}{m^2e^{2B}}\|\alpha^* - \hat{\alpha}^k\|_\infty - \frac{e^{2B}}{m}\sum_{s=1}^{k-1}\sum_i \delta_i^{k}(x^s,y^s)\hat{\alpha}_i^k
    % \end{align*}

     Hence, by Eq.\eqref{alpha:step1}, we have
    \begin{align*}
        &\sqrt{2k\log(d_\cF(1/k^2)/\delta)+1}\\
        &\ge \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)-\textrm{Softmax}(\alpha_i^*\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}\\
        &\qquad - \sum_{s=1}^{k-1} \EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\hat{\alpha}_i^k\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}}\\
        &\ge \sum_{s=1}^{k-1}\EE_{x, y\sim \cD_s}\frac{1}{m^2e^{2B}}\|X^*(x,y)|\alpha^* - \hat{\alpha}^k|\|_\infty \\
        &\qquad - \sum_{s=1}^{k-1}\EE_{x, y\sim \cD_s}\left\| \textrm{Softmax}(\hat{\alpha}_i^k \cdot |r_i^{\tilde{\theta}_i^k}(x,y_1)-r_i^{\tilde{\theta}_i^k}(x,y_2)|)-\textrm{Softmax}(\hat{\alpha}_i^k\cdot |r_i^*(x,y_1)-r_i^*(x,y_2)|)\right\| _{\mathrm{TV}} \\
        &\ge \sum_{s=1}^{k-1}\EE_{x, y\sim \cD_s}\frac{1}{m^2e^{2B}}\|X^*(x,y)\cdot |\alpha^* - \hat{\alpha}^k|\|_\infty - \frac{e^{2B}}{m}\sum_{s=1}^{k-1} \EE_{x,y\sim \cD_s}[\delta_i^{k}(x,y)\hat{\alpha}_i^k].
    \end{align*}
    Hence we finally get 
    \begin{align}
        \sum_{s=1}^{k-1}\EE_{x, y\sim \cD_s}\|X^*(x,y)\circ|\alpha^* - \hat{\alpha}^k|\|_\infty &\le m^2e^{2B}\left(\sqrt{2k\log(d_\cF(1/k^2)/\delta)+1} + \frac{e^{2B}}{m} \sum_{s=1}^{k-1}\sum_{i=1}^m \delta_i^{k}(x^s,y^s) \hat{\alpha}_i^k\right)\nonumber\\
        & = \mathrm{poly}(m, \exp(B))\cdot \widetilde{\cO}\left(\sqrt{km\log (1/\delta))} + \sum_{s=1}^{k-1}\sum_{i=1}^m \EE_{y_1,y_2\sim \pi^s}[\delta_i^{k}(x,y)]\hat{\alpha}_i^k\right).\label{alpha:step2}
    \end{align}
    the last inequality holds by Azuma-Hoeffding's inequality with probability at least $1-\delta$. 
    % then because $\|X^*(x,y)\cdot |\alpha^* - \hat{\alpha}^k|\|_\infty \le B$ is bounded ,  by the Azuma-Hoeffding's inequality we can derive 
    % \begin{align*}
    %     &\sum_{s=1}^{k-1}\EE_{y_1\sim \pi^j, y_2\sim \pi_{\text{base}}}\|X^*(x,y)\circ|\alpha^* - \hat{\alpha}^k|\|_\infty \\&\qquad = \mathrm{poly}(m, \exp(B))\cdot \widetilde{\cO}\left(\sqrt{t\log (|\cF|/\delta))} + \sum_{s=1}^{k-1}\sum_{i=1}^m \EE_{y_1\sim \pi^j, y_2\sim \pi_{\textrm{base}}}[\delta_i^{k}(x,y)]\hat{\alpha}_i^k\right) + \cO(B\sqrt{t}\log(1/\delta))\\
    %     &\qquad = \mathrm{poly}(m, \exp(B))\cdot \widetilde{\cO}\left(\sqrt{t}\log (|\cF|/\delta)) + \sum_{s=1}^{k-1}\sum_{i=1}^m \EE_{y_1\sim \pi^j, y_2\sim \pi_{\textrm{base}}}[\delta_i^{k}(x,y)]\hat{\alpha}_i^k\right).
    % \end{align*}
    Now by Lemma \ref{lemma:policy diff}, we can get  $\sup_{s,x,y}\frac{\pi^*(y\mid x)}{\pi^s(y\mid x)} \le  \exp(4/\beta)$ and $\sup_{x,y}\frac{\pi_{\mathrm{ref}}(y\mid x)}{\pi^s(y\mid x)} \le \exp(4/\beta)$, we can get 
    \begin{align}
    \gamma(k-1) \|\alpha^* - \hat{\alpha}^{k}\|_\infty
        &\le (k-1) \EE_{y_1\sim \pi^*,y_2\sim \pi_{\mathrm{ref}}}\|X^*(x,y)\circ|\alpha^* - \hat{\alpha}^k|\|_\infty\nonumber\\
        &\le  \exp(8/\beta)
        \sum_{s=1}^{k-1}\EE_{y_1,y_2\sim \pi^s}\|X^*(x,y)\circ|\alpha^* - \hat{\alpha}^s|\|_\infty. \label{alpha:step3}
        \end{align}
The first inequality uses the Assumption \ref{assum:gap} that $\EE_{y_1\sim \pi^*, y_2\sim \pi_{\mathrm{ref}}}[X_i^*(x,y)] \ge \gamma $. Now combining Eq.\eqref{alpha:step2} and Eq.\eqref{alpha:step3}, we can further get 
        \begin{align}
        \gamma(k-1)\|\alpha^* - \hat{\alpha}^k\|_\infty &\le  \exp(8/\beta)\cdot \mathrm{poly}(m, \exp(B))\cdot \widetilde{\cO}\left(\sqrt{km\log (1/\delta))} +  \sum_{s=1}^{k-1}\sum_{i=1}^m \EE_{y_1,y_2\sim \pi^s}[\delta_i^{k}(x,y)]\hat{\alpha}_i^k\right)\nonumber\\
        &\le \exp(8/\beta)\cdot \mathrm{poly}(m, \exp(B))\cdot \widetilde{\cO}\left(\sqrt{km\log (1/\delta))} +  \sum_{s=1}^{k-1}\sum_{i=1}^m \EE_{y_1,y_2\sim \pi^s}[\delta_i^{k}(x,y)]\right).\label{eq:estimate alpha step 1}
    \end{align}
    Now we further derive the  final result.
    Frist, by $\alpha^t = \frac{1}{t}\sum_{k=1}^t \hat{\alpha}^k$, we can get 
    \begin{align}
        \|\alpha^* - \alpha^t\|_\infty &\le \frac{1}{t}\sum_{k=1}^{t}\|\alpha^* - \hat{\alpha}^k\|_\infty\nonumber\\
        &\le \frac{\gamma^{-1}\exp(8/\beta)\cdot \mathrm{poly}(m,\exp(B))}{t}\cdot \sum_{k=1}^t\widetilde{\cO}\left(\frac{\sqrt{m\log(1/\delta)}}{\sqrt{k}} + \frac{1}{k} \sum_{s=1}^{k-1}\sum_{i=1}^m \EE_{y_1,y_2\sim \pi^s}[\delta_i^{k}(x,y)]\right).\label{eq:alpha1}
    \end{align}

    Now we derive the final result. First, we can get
\begin{align*}\delta_i^k(x^s,y^s) 
& = \left| \langle \tilde{\theta}_i^k-\theta_i^*, \phi_i(x^s,y_1^s) - \phi_i(x^s, y_2^s) \rangle\right|\\
& \le \|\tilde{\theta}_i^k - \theta_i^* \|_{\Sigma_{\cD_i^{k-1}}}\cdot \|\phi_i(x^s,y_1^s)- \phi_i(x^s, y_2^s)\|_{(\Sigma_{\cD_i^{k-1}})^{-1}},
\end{align*}
where $\cD_{i}^{k-1} = \{s \in [k-1]\mid I_s = i\}$ and $\Sigma_{\cD_i^{k-1}} = \sum_{s \in \cD_i^{k-1}}\phi_i(x^s,y^s)\phi_i(x^s,y^s)^\top $ is the covariance matrix. 
then by Lemma 3.1 in \cite{zhu2023principled}, we can get $\|\tilde{\theta}_i^k - \theta_i^*\|_{\Sigma_{\cD_i^{k-1}}} \le C(d, B, \delta) = \textrm{poly}(d,B, \log(1/\delta))$ for some constant $C(d,B,\delta)$, and then we can get 
\begin{align*}
    \delta_i^k(x^s,y^s) \le C(d,B,\delta)\cdot \|\phi_i(x^s,y_1^s)- \phi_i(x^s, y_2^s)\|_{(\Sigma_{\cD_i^{k-1}})^{-1}}.
\end{align*}
Now apply the same technique in Eq.\eqref{eq:estimate technique}, we can get 
\begin{align*}
    \sum_{i=1}^m \sum_{k=1}^t \sum_{s=1}^{k-1} \EE_{y_1,y_2\sim \pi^s} \frac{1}{k}[\delta_i^k(x,y)\hat{\alpha}_i^k] &\le me^B\sum_{k=1}^t \sum_{i=1}^m \sum_{s \in \cD_i^{k-1}}\EE_{y_1,y_2\sim \pi^s} \frac{1}{k}[\delta_i^k(x,y)\hat{\alpha}_{i}^k]\\
    & =me^B\sum_{i=1}^m\sum_{s=1}^t  \EE_{y_1,y_2\sim \pi^s} \sum_{k>s} \left[\frac{1}{k}\delta_{I_s}^k(x,y)\hat{\alpha}_{I_s}^k\right]\\
    & \le me^B\sum_{s=1}^t  \EE_{y_1,y_2\sim \pi^s} \sum_{k>s} \left[\frac{1}{k}\delta_{I_s}^k(x,y)\right].
\end{align*}
The second line is because that, the summation is over
\begin{align*}\{(k,i,s)\mid k \in [t],i \in [m] ,s \in \cD_i^{k-1}\}&=\{(k,i,s)\mid k \in [t], i \in [m], s \le k-1, I^s = i\}\\
&=\{(k,i,s)\mid s \in [t], k > s, i = I^s\}.\end{align*}
the last inequality uses the fact that $\hat{\alpha}_{I_s}^k\le 1$.
then we can use the Azuma-Hoeffding's inequality to further get 
\begin{align}
    \sum_{i=1}^m \sum_{k=1}^t \sum_{s=1}^{k-1} \EE_{y_1,y_2\sim \pi^s} \frac{1}{k}[\delta_i^k(x,y)\hat{\alpha}_i^k] &\le me^B\sum_{k=1}^t  \sum_{k\ge  s} \left[\frac{1}{k}\delta_{I_s}^k(x^s,y^s)\right] + \cO(\sqrt{t}\log (t/\delta))\nonumber\\&\le me^B\sum_{k=1}^t  \sum_{k\ge  s} \left[\frac{1}{k}C(d,B,\delta)\cdot \|\phi_{I_s}(x^s,y_1^s) - \phi_{I_s}(x^s, y_2^s)\|_{\Sigma_{\cD_{I_s}^{k-1}}}\right]\nonumber\\&\qquad  + \cO(\sqrt{t}\log (t/\delta))\label{eq:alpha2}
\end{align}
with probability at least $1-\delta$.
Now to present the proof in a simple way, we simplify $\Sigma_{\cD_{I_s}^{k-1}} $ as $\Sigma^{k-1,(I_s)}$.
We will have 
\begin{align}
    & me^B\sum_{s=1}^t \sum_{k>s} \left[\frac{1}{k}\cdot C(d,B,\delta) \cdot \|\phi_{I_s}(x^s,y_1^s)- \phi_{I_s}(x^s, y_2^s)\|_{(\Sigma^{k-1,(s)})^{-1}}\right]\nonumber\\
    &\le  me^B\sum_{s=1}^t \sum_{k>s}\frac{1}{k}\cdot C(d,B,\delta) \cdot \|\phi_{I_s}(x^s,y_1^s)- \phi_{I_s}(x^s, y_2^s)\|_{(\Sigma^{s,(s)})^{-1}}\nonumber\\
    &\le  me^B\sum_{s=1}^t C(d,B,\delta)\|\phi_{I_s}(x^s,y_1^s)- \phi_{I_s}(x^s, y_2^s)\|_{(\Sigma^{s,(s)})^{-1}}\sum_{k>s}^t \frac{1}{k}\nonumber\\
    &\le \frac{\log t}{\kappa_1} \cdot \sum_{s=1}^t C(d,B,\delta)\|\phi_{I_s}(x^s,y_1^s)- \phi_{I_s}(x^s, y_2^s)\|_{(\Sigma^{s,(s)})^{-1}}.\label{eq:alpha3}
    \end{align}
Now, we can decompose $\{1,2,\cdots, t\}$ into $m$ different set $\cD_i = \{s \in [t]: I_s = i\}$. then, we fixed $i$ and denote $M_s=\|\phi_i(x^s,y_1^s)-\phi_i(x^s,y_2^s)\|^2_{(\Sigma_{\cD_{I_s}^{s}})^{-1}}$ with $\|M_s\| \le B^2$, by Cauchy's inequality,
\begin{align}
    &\sum_{s \in \cD_i}\|\phi_{I_s}(x^s,y_1^s)- \phi_{I_s}(x^s, y_2^s)\|_{(\Sigma^{s,(s)})^{-1}}\nonumber\\
    &\le \sqrt{t}\sqrt{\sum_{s \in \cD_i}M_s}\nonumber\\
    &\le \sqrt{t}\sqrt{\sum_{s \in \cD_i}M_s\II\{M_s\le 1\}} + \sqrt{t}\sqrt{\sum_{s \in \cD_i}M_s \II\{M_s > 1\}}\nonumber\\
    &\le \sqrt{t}\cdot \left(\sqrt{\sum_{s \in \cD_i}\min\{1,M_s\}} + \sqrt{B^2\sum_{s \in \cD_i}\II\{M_s>1\}}\right)\nonumber\\
    &\le \widetilde{\cO}(Bd\sqrt{t}).\nonumber
\end{align}
Then, by summing over $i \in [m]$, we can get 
    \begin{align}
    &\frac{\log t}{\kappa_1} \cdot \sum_{s=1}^t C(d,B,\delta)\|\phi_{I_s}(x^s,y_1^s)- \phi_{I_s}(x^s, y_2^s)\|_{(\Sigma_{\cD_i}^{j})^{-1}}\nonumber\\
    &\le \frac{\log t}{\kappa_1} \cdot C(d,B,\delta) \cdot m \cdot \widetilde{\cO}(Bd\sqrt{t})\nonumber\\
    & = \widetilde{\cO}(m^2 e^B\cdot Bd\cdot C(d,B,\delta)\sqrt{t}). \label{ineq: bound(C)}
    \end{align}
    Now combining Eq.\eqref{eq:alpha1}, Eq.\eqref{eq:alpha2}, Eq.\eqref{eq:alpha3} and Eq.\eqref{ineq: bound(C)}, we can finally get 
    \begin{align*}
        \|\alpha^* - \alpha^t\|_\infty \le \frac{1}{t}\sum_{k=1}^{t}\|\alpha^* - \hat{\alpha}^k\|_\infty&\le \gamma^{-1}\exp(8/\beta)\cdot \widetilde{\cO}\left(\mathrm{poly}(m,e^B, d,\log(1/\delta))\right)\cdot \frac{1}{\sqrt{t}}\\
        &=\gamma^{-1}\cdot \widetilde{\cO}\left(\mathrm{poly}(m,e^B, \exp(1/\beta),d,\log(1/\delta))\right)\cdot \frac{1}{\sqrt{t}}
    \end{align*}
    with probability at least $1-3\delta$. By substituting $\delta/3$ with $\delta$, we complete the proof.
 \end{proof}
   
    % Hence we finally get 
    % \begin{align*}
    %     \|\alpha^* - \hat{\alpha}^k\|_\infty &\le \frac{m^2e^{2B}}{\gamma^2(t-1)}\left(\sqrt{2k\log(d_\cF(1/k^2)/\delta)+1} + \frac{e^{2B}}{m} \sum_{s=1}^{k-1}\sum_{i=1}^m \delta_i^{k}(x^s,y^s) \hat{\alpha}_i^k\right)\\
    %     & = \cO\left(\frac{1}{\sqrt{t}} + \frac{1}{t}\sum_{s=1}^{k-1}\sum_{i=1}^m \delta_i^{k}(x^s,y^s)\hat{\alpha}_i^k\right).
    % \end{align*}
    % Now since $\delta_i^{k}(x^s,y^s) = \langle \theta_i^t - \theta_i^*, \phi_i(x^s,y_1^s), \phi_i(x^s,y_2^s)\rangle$, then by the MLE result, we can further get 
    % $$\|\theta_i^t - \theta_i^*\|_{\Sigma_{\cD_i}^{t}}\le C\sqrt{d+\log(1/\delta)}:=C(d,B,\delta).$$

    % Now by Cauchy's inequality, 
    % \begin{align*}
    %     \delta_i^{k}(x^s,y^s) \le C(d,B,\delta) \|\phi_i(x^s,y_1^s)-\phi_i(x^s,y_2^s)\|_{(\Sigma_{\cD_i}^t)^{-1}}.
    % \end{align*}
    % then (this should be careful by $I(\|\phi_i(\cdot,\cdot)\|_\Sigma \ge 1)$
    % \begin{align*}
    %     \|\alpha^* - \hat{\alpha}^k\|_\infty &=\cO\left(\frac{1}{\sqrt{t}} + \frac{1}{t}\sum_{s=1}^{k-1}\sum_{i=1}^m \delta_i^{k}(x^s,y^s)\hat{\alpha}_i^k\right)\\
    %     &\le \cO\left(\frac{1}{\sqrt{t}} + \frac{1}{t}C(d,B,\delta)\sum_{s=1}^{k-1}\sum_{i=1}^m \hat{\alpha}_i^k \|\phi_i(x^s,y_1^s)-\phi_i(x^s,y_2^s)\|_{(\Sigma_{\cD_i}^t)^{-1}}\right)\\
    %     &\le \cO\left(\frac{1}{\sqrt{t}} + \frac{1}{t}C(d,B,\delta)\sum_{s=1}^{k-1}\sum_{i=1}^m \hat{\alpha}_i^k \|\phi_i(x^s,y_1^s)-\phi_i(x^s,y_2^s)\|_{(\Sigma_{\cD_i}^j)^{-1}}\right)\\
    %     & = \cO\left(\frac{1}{\sqrt{t}} + \frac{1}{\sqrt{t}}C(d,B,\delta) \sum_{s=1}^{k-1}\sum_{i=1}^m \hat{\alpha}_i^k \|\phi_i(x^s,y_1^s)-\phi_i(x^s,y_2^s)\|_{(\Sigma_{\cD_i}^j)^{-1}}^2\right)\\
    %     &= \cO\left(\frac{C(d,B,\delta)}{\sqrt{t}}\right).
    % \end{align*}

    % then final    assumption is that $\sum_{i=1}^m \hat{\alpha}_i^k \Sigma_{\cD_i}^j\succeq C_j\cdot \Sigma_\cD^j$
    % \textcolor{red}{this assumption is dependent on the online process! Not make sense}

    
    % Now we only prove when the absolute value disappear. the other side holds by symmetry.
    
    % Suppose $\sum_j e^{X_j^*\hat{\alpha}_j^k} \le \sum_j e^{X_j^*\alpha_j^*}$, thus the RHS is not less than 
    % $$\frac{e^{X_i^* \hat{\alpha}_i^k}-e^{X_i^* \alpha_i^*}}{\sum_j e^{X_j^* \hat{\alpha}_j^k}}$$
    
    % then 
    % define $S_1 = \{j \in [m]: \hat{\alpha}_j^k \ge \alpha_j^*\}$, $S_2 = [m]\setminus S_1$, 
    % we have 
    % $$\sum_{j \in S_1} e^{X_j^*\hat{\alpha}_j^k}-e^{X_j^*\alpha_j^*} \le \sum_{j \in S_2}e^{X_j^*\alpha_j^*}-e^{X_j^*\hat{\alpha}_j^k}.$$

    % Now 

