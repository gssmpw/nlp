\section*{Limitations}

Despite presenting a comprehensive and robust evaluation framework, our work has certain limitations that we want to highlight here:
%
One key limitation is the potential biases in the LLMs used for both rating and synthetic data generation. These biases can affect the evaluation process and perpetuate biases, especially in automated interpretability. For instance, an LLM might recognize a feature encoding a concept in English as directly representing that concept, whereas the same feature in another language might be classified with the additional specification of the language. This discrepancy could lead to unintended biases when steering models based on these interpretations. Similar issues may arise from biases present in the pre-training datasets used in our evaluation procedure.
%
Another limitation is related to the steering behavior in the faithfulness pipeline. Our current implementation does not explicitly verify whether the generated sequences under modification remain grammatically correct and semantically meaningful. However, minor modifications to the prompt could potentially address this issue in the future.
%
Finally, our faithfulness measure is not well-suited for handling inhibitory neurons. A neuron may causally inhibit the presence of a concept in a modelâ€™s output, but our metric, by design, does not effectively capture decreases in the appearance of sparse concepts. This limitation arises both from the definition of our faithfulness metric and the inherent challenges in measuring such suppression effects for already sparse concepts.