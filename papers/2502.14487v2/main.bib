@inproceedings{bu2022optimized,
  title={Optimized potential initialization for low-latency spiking neural networks},
  author={Bu, Tong and Ding, Jianhao and Yu, Zhaofei and Huang, Tiejun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2022}
}

@inproceedings{bu2023rate,
  title={Rate gradient approximation attack threats deep spiking neural networks},
  author={Bu, Tong and Ding, Jianhao and Hao, Zecheng and Yu, Zhaofei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7896--7906},
  year={2023}
}

@inproceedings{DBLP:conf/iclr/BuFDDY022,
  author       = {Tong Bu and
                  Wei Fang and
                  Jianhao Ding and
                  Penglin Dai and
                  Zhaofei Yu and
                  Tiejun Huang},
  title        = {Optimal {ANN-SNN} Conversion for High-accuracy and Ultra-low-latency
                  Spiking Neural Networks},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  year         = {2022},
}

@inproceedings{DBLP:conf/icml/JiangAMX023,
  author       = {Haiyan Jiang and
                  Srinivas Anumasa and
                  Giulia De Masi and
                  Huan Xiong and
                  Bin Gu},
  title        = {A Unified Optimization Framework of {ANN-SNN} Conversion: Towards
                  Optimal Mapping from Activation Values to Firing Rates},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  year         = {2023},
}

@inproceedings{DBLP:conf/iclr/DengG21,
  author       = {Shikuang Deng and
                  Shi Gu},
  title        = {Optimal Conversion of Conventional Artificial Neural Networks to Spiking
                  Neural Networks},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021,
                  Virtual Event, Austria, May 3-7, 2021},
  year         = {2021},
}

@inproceedings{DBLP:conf/ijcai/DingY0H21,
  author       = {Jianhao Ding and
                  Zhaofei Yu and
                  Yonghong Tian and
                  Tiejun Huang},
  title        = {Optimal {ANN-SNN} Conversion for Fast and Accurate Inference in Deep
                  Spiking Neural Networks},
  booktitle    = {Proceedings of the Thirtieth International Joint Conference on Artificial
                  Intelligence, {IJCAI} 2021, Virtual Event / Montreal, Canada, 19-27
                  August 2021},
  year         = {2021},
}

@inproceedings{han2020deep,
  title={Deep spiking neural network: Energy efficiency through time based coding},
  author={Han, Bing and Roy, Kaushik},
  booktitle={European Conference on Computer Vision},
  year={2020},
  organization={Springer}
}

@article{krizhevsky2010cifar,
  title={Cifar-10 (canadian institute for advanced research)},
  author={Krizhevsky, Alex and Nair, Vinod and Hinton, Geoffrey},
  journal={URL http://www. cs. toronto. edu/kriz/cifar. html},
  year={2010}
}

@article{hodgkin1952quantitative,
  title={A quantitative description of membrane current and its application to conduction and excitation in nerve},
  author={Hodgkin, Alan L and Huxley, Andrew F},
  journal={The Journal of physiology},
  volume={117},
  number={4},
  pages={500},
  year={1952},
  publisher={Wiley-Blackwell}
}

@article{izhikevich2003simple,
  title={Simple model of spiking neurons},
  author={Izhikevich, Eugene M},
  journal={IEEE Transactions on neural networks},
  volume={14},
  number={6},
  pages={1569--1572},
  year={2003},
  publisher={IEEE}
}



@article{liu2001spike,
  title={Spike-frequency adaptation of a generalized leaky integrate-and-fire model neuron},
  author={Liu, Ying-Hui and Wang, Xiao-Jing},
  journal={Journal of computational neuroscience},
  volume={10},
  number={1},
  pages={25--45},
  year={2001},
  publisher={Springer}
}

@article{wu2018spatio,
  title={Spatio-temporal backpropagation for training high-performance spiking neural networks},
  author={Wu, Yujie and Deng, Lei and Li, Guoqi and Zhu, Jun and Shi, Luping},
  journal={Frontiers in neuroscience},
  volume={12},
  pages={331},
  year={2018},
  publisher={Frontiers Media SA}
}


@article{neftci2019surrogate,
  title={Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks},
  author={Neftci, Emre O and Mostafa, Hesham and Zenke, Friedemann},
  journal={IEEE Signal Processing Magazine},
  volume={36},
  number={6},
  pages={51--63},
  year={2019},
  publisher={IEEE}
}

@article{zenke2021remarkable,
  title={The remarkable robustness of surrogate gradient learning for instilling complex function in spiking neural networks},
  author={Zenke, Friedemann and Vogels, Tim P},
  journal={Neural computation},
  volume={33},
  number={4},
  pages={899--925},
  year={2021},
  publisher={MIT Press}
}
% %%% introduction

@article{cao2015spiking,
  title={Spiking deep convolutional neural networks for energy-efficient object recognition},
  author={Cao, Yongqiang and Chen, Yang and Khosla, Deepak},
  journal={International Journal of Computer Vision},
  volume={113},
  number={1},
  pages={54--66},
  year={2015},
  publisher={Springer}
}

@inproceedings{diehl2015fast,
  title={Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing},
  author={Diehl, Peter U and Neil, Daniel and Binas, Jonathan and Cook, Matthew and Liu, Shih-Chii and Pfeiffer, Michael},
  booktitle={2015 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2015},
  organization={ieee}
}
@article{diehl2015unsupervised,
  title={Unsupervised learning of digit recognition using spike-timing-dependent plasticity},
  author={Diehl, Peter U and Cook, Matthew},
  journal={Frontiers in computational neuroscience},
  volume={9},
  pages={99},
  year={2015},
  publisher={Frontiers Media SA}
}

@article{sengupta2019going,
  title={Going deeper in spiking neural networks: {VGG} and residual architectures},
  author={Sengupta, Abhronil and Ye, Yuting and Wang, Robert and Liu, Chiao and Roy, Kaushik},
  journal={Frontiers in neuroscience},
  volume={13},
  pages={95},
  year={2019},
  publisher={Frontiers Media SA}
}
@article{zhang2020temporal,
  title={Temporal spike sequence learning via backpropagation for deep spiking neural networks},
  author={Zhang, Wenrui and Li, Peng},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12022--12033},
  year={2020}
}

@inproceedings{
deng2022temporal,
title={Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting},
author={Shikuang Deng and Yuhang Li and Shanghang Zhang and Shi Gu},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=_XNtisL32jv}
}

@article{rueckauer2016theory,

AUTHOR={Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih-Chii},   
	 
TITLE={Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification},      
	
JOURNAL={Frontiers in Neuroscience},      
	
VOLUME={11},           
	
YEAR={2017},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fnins.2017.00682},       
	
DOI={10.3389/fnins.2017.00682},      
	
ISSN={1662-453X},   
   
ABSTRACT={Spiking neural networks (SNNs) can potentially offer an efficient way of doing inference because the neurons in the networks are sparsely activated and computations are event-driven. Previous work showed that simple continuous-valued deep Convolutional Neural Networks (CNNs) can be converted into accurate spiking equivalents. These networks did not include certain common operations such as max-pooling, softmax, batch-normalization and Inception-modules. This paper presents spiking equivalents of these operations therefore allowing conversion of nearly arbitrary CNN architectures. We show conversion of popular CNN architectures, including VGG-16 and Inception-v3, into SNNs that produce the best results reported to date on MNIST, CIFAR-10 and the challenging ImageNet dataset. SNNs can trade off classification error rate against the number of available operations whereas deep continuous-valued neural networks require a fixed number of operations to achieve their classification error rate. From the examples of LeNet for MNIST and BinaryNet for CIFAR-10, we show that with an increase in error rate of a few percentage points, the SNNs can achieve more than 2x reductions in operations compared to the original CNNs. This highlights the potential of SNNs in particular when deployed on power-efficient neuromorphic spiking neuron chips, for use in embedded applications.}
}

%   title={Theory and tools for the conversion of analog to spiking convolutional neural networks},
%   author={Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael},
%   journal={arXiv preprint arXiv:1612.04052},
%   year={2016}
% }

@INPROCEEDINGS{deng2009imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}

@inproceedings{zheng2021going,
  title={Going deeper with directly-trained larger spiking neural networks},
  author={Zheng, Hanle and Wu, Yujie and Deng, Lei and Hu, Yifan and Li, Guoqi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={12},
  pages={11062--11070},
  year={2021}
}

@inproceedings{han2020rmp,
  title={{RMP-SNN}: Residual membrane potential neuron for enabling deeper high-accuracy and low-latency spiking neural network},
  author={Han, Bing and Srinivasan, Gopalakrishnan and Roy, Kaushik},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={13558--13567},
  year={2020}
}

@inproceedings{li2021free,
  title={A free lunch from ANN: Towards efficient, accurate spiking neural networks calibration},
  author={Li, Yuhang and Deng, Shikuang and Dong, Xin and Gong, Ruihao and Gu, Shi},
  booktitle={International Conference on Machine Learning},
  pages={6316--6325},
  year={2021},
  organization={PMLR}
}

@article{rueckauer2017conversion,
  title={Conversion of continuous-valued deep networks to efficient event-driven networks for image classification},
  author={Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih-Chii},
  journal={Frontiers in neuroscience},
  volume={11},
  pages={682},
  year={2017},
  publisher={Frontiers Media SA}
}

%%%%% Implicit variable
@article{mehlitz2021implicit,
  title={On implicit variables in optimization theory},
  author={Mehlitz, Patrick and Benko, Mat{\'u}{\v{s}}},
  journal={Journal of Nonsmooth Analysis and Optimization},
  volume={2},
  year={2021},
  publisher={Episciences. org}
}

@inproceedings{wu2019direct,
  title={Direct training for spiking neural networks: Faster, larger, better},
  author={Wu, Yujie and Deng, Lei and Li, Guoqi and Zhu, Jun and Xie, Yuan and Shi, Luping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},

  pages={1311--1318},
  year={2019}
}

% %%% Some new papers.



@article{deng2021optimal,
  title={Optimal conversion of conventional artificial neural networks to spiking neural networks},
  author={Deng, Shikuang and Gu, Shi},
  journal={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{bu2022optimal,
  title={Optimal {ANN-SNN} conversion for high-accuracy and ultra-low-latency spiking neural networks},
  author={Bu, Tong and Fang, Wei and Ding, Jianhao and Dai, PengLin and Yu, Zhaofei and Huang, Tiejun},
  booktitle={International Conference on Learning Representations},
  year={2022}
}
% %%% Some new papers.
@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}
@book{braspenning1995artificial,
  title={Artificial neural networks: an introduction to ANN theory and practice},
  author={Braspenning, Petrus J and Thuijsman, Frank and Weijters, Antonius Jozef Martha Maria},
  volume={931},
  year={1995},
  publisher={Springer Science \& Business Media}
}
@article{roy2019towards,
  title={Towards spike-based machine intelligence with neuromorphic computing},
  author={Roy, Kaushik and Jaiswal, Akhilesh and Panda, Priyadarshini},
  journal={Nature},
  volume={575},
  number={7784},
  pages={607--617},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{pei2019towards,
  title={Towards artificial general intelligence with hybrid Tianjic chip architecture},
  author={Pei, Jing and Deng, Lei and Song, Sen and Zhao, Mingguo and Zhang, Youhui and Wu, Shuang and Wang, Guanrui and Zou, Zhe and Wu, Zhenzhi and He, Wei and others},
  journal={Nature},
  volume={572},
  number={7767},
  pages={106--111},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{debole2019truenorth,
  title={TrueNorth: Accelerating from zero to 64 million neurons in 10 years},
  author={DeBole, Michael V and Taba, Brian and Amir, Arnon and Akopyan, Filipp and Andreopoulos, Alexander and Risk, William P and Kusnitz, Jeff and Otero, Carlos Ortega and Nayak, Tapan K and Appuswamy, Rathinakumar and others},
  journal={Computer},
  volume={52},
  number={5},
  pages={20--29},
  year={2019},
  publisher={IEEE}
}
@inproceedings{zhu2022event,
  title={Event-based Video Reconstruction via Potential-assisted Spiking Neural Network},
  author={Zhu, Lin and Wang, Xiao and Chang, Yi and Li, Jianing and Huang, Tiejun and Tian, Yonghong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3594--3604},
  year={2022}
}
@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}
@inproceedings{cheng2020lisnn,
  title={LISNN: Improving spiking neural networks with lateral interactions for robust object recognition.},
  author={Cheng, Xiang and Hao, Yunzhe and Xu, Jiaming and Xu, Bo},
  booktitle={IJCAI},
  pages={1519--1525},
  year={2020}
}
@inproceedings{kamata2022fully,
  title={Fully spiking variational autoencoder},
  author={Kamata, Hiromichi and Mukuta, Yusuke and Harada, Tatsuya},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},

  pages={7059--7067},
  year={2022}
}
@article{yang2019dashnet,
  title={DashNet: a hybrid artificial and spiking neural network for high-speed object tracking},
  author={Yang, Zheyu and Wu, Yujie and Wang, Guanrui and Yang, Yukuan and Li, Guoqi and Deng, Lei and Zhu, Jun and Shi, Luping},
  journal={arXiv preprint arXiv:1909.12942},
  year={2019}
}
@inproceedings{kim2020spiking,
  title={Spiking-yolo: spiking neural network for energy-efficient object detection},
  author={Kim, Seijoon and Park, Seongsik and Na, Byunggook and Yoon, Sungroh},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
 
  pages={11270--11277},
  year={2020}
}

@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}



% %%% Appendix dataset intro
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year={2009},
  journal={https://www.cs.toronto.edu/~kriz/cifar.html},
  publisher={Citeseer}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{rathi2020enabling,
title={Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation},
author={Nitin Rathi and Gopalakrishnan Srinivasan and Priyadarshini Panda and Kaushik Roy},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=B1xSperKvH}
}

@article{duan2022temporal,
  title={Temporal effective batch normalization in spiking neural networks},
  author={Duan, Chaoteng and Ding, Jianhao and Chen, Shiyan and Yu, Zhaofei and Huang, Tiejun},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34377--34390},
  year={2022}
}

@article{ding2021optimal,
  title={Optimal ann-snn conversion for fast and accurate inference in deep spiking neural networks},
  author={Ding, Jianhao and Yu, Zhaofei and Tian, Yonghong and Huang, Tiejun},
  journal={In International Joint Conference on Artificial Intelligence},
  pages={2328--2336},
  year={2021}
}

@incollection{bottou2012stochastic,
  title={Stochastic gradient descent tricks},
  author={Bottou, L{\'e}on},
  booktitle={Neural networks: Tricks of the trade},
  pages={421--436},
  year={2012},
  publisher={Springer}
}

@article{le2015tiny,
  title={Tiny imagenet visual recognition challenge},
  author={Le, Ya and Yang, Xuan},
  journal={CS 231N},
  volume={7},
  number={7},
  pages={3},
  year={2015}
}

@article{kim2020yolo, title={Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object Detection}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/6787}, DOI={10.1609/aaai.v34i07.6787}, abstractNote={&lt;p&gt;Over the past decade, deep neural networks (DNNs) have demonstrated remarkable performance in a variety of applications. As we try to solve more advanced problems, increasing demands for computing and power resources has become inevitable. Spiking neural networks (SNNs) have attracted widespread interest as the third-generation of neural networks due to their event-driven and low-powered nature. SNNs, however, are difficult to train, mainly owing to their complex dynamics of neurons and non-differentiable spike operations. Furthermore, their applications have been limited to relatively simple tasks such as image classification. In this study, we investigate the performance degradation of SNNs in a more challenging regression problem (i.e., object detection). Through our in-depth analysis, we introduce two novel methods: channel-wise normalization and signed neuron with imbalanced threshold, both of which provide fast and accurate information transmission for deep SNNs. Consequently, we present a first spiked-based object detection model, called Spiking-YOLO. Our experiments show that Spiking-YOLO achieves remarkable results that are comparable (up to 98%) to those of Tiny YOLO on non-trivial datasets, PASCAL VOC and MS COCO. Furthermore, Spiking-YOLO on a neuromorphic chip consumes approximately 280 times less energy than Tiny YOLO and converges 2.3 to 4 times faster than previous SNN conversion methods.&lt;/p&gt;}, number={07}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Kim, Seijoon and Park, Seongsik and Na, Byunggook and Yoon, Sungroh}, year={2020}, month={Apr.}, pages={11270-11277} }

@ARTICLE{li2022bsnn,
  
AUTHOR={Li, Yang and Zhao, Dongcheng and Zeng, Yi},   
	 
TITLE={BSNN: Towards faster and better conversion of artificial neural networks to spiking neural networks with bistable neurons},      
	
JOURNAL={Frontiers in Neuroscience},      
	
VOLUME={16},           
	
YEAR={2022},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fnins.2022.991851},       
	
DOI={10.3389/fnins.2022.991851},      
	
ISSN={1662-453X},   
   
ABSTRACT={The spiking neural network (SNN) computes and communicates information through discrete binary events. Recent work has achieved essential progress on an excellent performance by converting ANN to SNN. Due to the difference in information processing, the converted deep SNN usually suffers serious performance loss and large time delay. In this paper, we analyze the reasons for the performance loss and propose a novel bistable spiking neural network (BSNN) that addresses the problem of the phase lead and phase lag. Also, we design synchronous neurons (SN) to help efficiently improve performance when ResNet structure-based ANNs are converted. BSNN significantly improves the performance of the converted SNN by enabling more accurate delivery of information to the next layer after one cycle. Experimental results show that the proposed method only needs 1/4–1/10 of the time steps compared to previous work to achieve nearly lossless conversion. We demonstrate better ANN-SNN conversion for VGG16, ResNet20, and ResNet34 on challenging datasets including CIFAR-10 (95.16% top-1), CIFAR-100 (78.12% top-1), and ImageNet (72.64% top-1).}
}

@article{maas1997third,
title = {Networks of spiking neurons: The third generation of neural network models},
journal = {Neural Networks},
volume = {10},
number = {9},
pages = {1659-1671},
year = {1997},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(97)00011-7},
url = {https://www.sciencedirect.com/science/article/pii/S0893608097000117},
author = {Wolfgang Maass},
keywords = {Spiking neuron, Integrate-and-fire neutron, Computational complexity, Sigmoidal neural nets, Lower bounds},
abstract = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology.}
}

@article{pfeiffer2018deep,
  title={Deep learning with spiking neurons: opportunities and challenges},
  author={Pfeiffer, Michael and Pfeil, Thomas},
  journal={Frontiers in neuroscience},
  pages={774},
  year={2018},
  publisher={Frontiers}
}
@inproceedings{wang2022signed,
  title     = {Signed Neuron with Memory: Towards Simple, Accurate and High-Efficient ANN-SNN Conversion},
  author    = {Wang, Yuchen and Zhang, Malu and Chen, Yi and Qu, Hong},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on
               Artificial Intelligence, {IJCAI-22}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Lud De Raedt},
  pages     = {2501--2508},
  year      = {2022},
  month     = {7},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2022/347},
  url       = {https://doi.org/10.24963/ijcai.2022/347},
}

@article{li2021differentiable,
  title={Differentiable spike: Rethinking gradient-descent for training spiking neural networks},
  author={Li, Yuhang and Guo, Yufei and Zhang, Shanghang and Deng, Shikuang and Hai, Yongqing and Gu, Shi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23426--23439},
  year={2021}
}

@article{fang2021deep,
  title={Deep residual learning in spiking neural networks},
  author={Fang, Wei and Yu, Zhaofei and Chen, Yanqi and Huang, Tiejun and Masquelier, Timoth{\'e}e and Tian, Yonghong},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={21056--21069},
  year={2021}
}

@misc{loihi2,
  title = {Taking {N}euromorphic {C}omputing 
to the {N}ext {L}evel with {L}oihi 2},
  howpublished = {\url{https://download.intel.com/newsroom/2021/new-technologies/neuromorphic-computing-loihi-2-brief.pdf}},
  note = {Accessed: 16-05-2023}
}

@misc{simonyan2015deep,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{he2016residual,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  doi={10.1109/CVPR.2016.90}}



@misc{devries2017improved,
      title={Improved Regularization of Convolutional Neural Networks with Cutout}, 
      author={Terrance DeVries and Graham W. Taylor},
      year={2017},
      eprint={1708.04552},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{cubuc2019autoaugment,
  author={Cubuk, Ekin D. and Zoph, Barret and Mané, Dandelion and Vasudevan, Vijay and Le, Quoc V.},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={AutoAugment: Learning Augmentation Strategies From Data}, 
  year={2019},
  volume={},
  number={},
  pages={113-123},
  doi={10.1109/CVPR.2019.00020}}
@article{attwell2001energy,
author={ATtwell D and Laughlin SB},
title={ An energy budget for signaling in the grey matter of the brain},
year = {2001},
journal = { J. Cereb. Blood Flow Metab.},
volume ={10},
pages={1133-45}
}

@article{maass2004power,
title = {On the computational power of circuits of spiking neurons},
journal = {Journal of Computer and System Sciences},
volume = {69},
number = {4},
pages = {593-616},
year = {2004},
issn = {0022-0000},
doi = {https://doi.org/10.1016/j.jcss.2004.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0022000004000406},
author = {Wolfgang Maass and Henry Markram},
abstract = {Complex real-time computations on multi-modal time-varying input streams are carried out by generic cortical microcircuits. Obstacles for the development of adequate theoretical models that could explain the seemingly universal power of cortical microcircuits for real-time computing are the complexity and diversity of their computational units (neurons and synapses), as well as the traditional emphasis on offline computing in almost all theoretical approaches towards neural computation. In this article, we initiate a rigorous mathematical analysis of the real-time computing capabilities of a new generation of models for neural computation, liquid state machines, that can be implemented with—in fact benefit from—diverse computational units. Hence, realistic models for cortical microcircuits represent special instances of such liquid state machines, without any need to simplify or homogenize their diverse computational units. We present proofs of two theorems about the potential computational power of such models for real-time computing, both on analog input streams and for spike trains as inputs.}
}

@book{arfken1967math,
  abstract = {A textbook on mathematical physics. Chapter titles are: vector
                  analysis; coordinate systems; tensor analysis; determinants,
                  matrices, and group theory; infinite series; functions of a
                  complex variable {I}; functions of a complex variables {II}
                  --- calculus of residues; differential equations;
                  Sturm-Liouville theory --- orthogonal functions; the gamma
                  function (factorial function); Bessel functions; Legendre
                  functions; special functions; Fourier series; integral
                  transforms; integral equations; calculus of
                  variations. Appendices on real zeroes of a function, and
                  Gaussian quadrature are also included.},
  added-at = {2013-03-22T02:46:59.000+0100},
  address = {San Diego},
  annote = {First edition published in 1967.},
  author = {Arfken, George},
  year = 1985
}

@inproceedings{yang2021backpropagated,
  title={Backpropagated neighborhood aggregation for accurate training of spiking neural networks},
  author={Yang, Yukun and Zhang, Wenrui and Li, Peng},
  booktitle={International Conference on Machine Learning},
  pages={11852--11862},
  year={2021},
  organization={PMLR}
}

@article{stockl2021optimized,
  title={Optimized spiking neurons can classify images with high accuracy through temporal coding with two spikes},
  author={St{\"o}ckl, Christoph and Maass, Wolfgang},
  journal={Nature Machine Intelligence},
  volume={3},
  number={3},
  pages={230--238},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{deng2023surrogate,
  title={Surrogate Module Learning: Reduce the Gradient Error Accumulation in Training Spiking Neural Networks},
  author={Deng, Shikuang and Lin, Hao and Li, Yuhang and Gu, Shi},
  booktitle={International Conference on Machine Learning},
  year={2023}
}

@article{qiao2015reconfigurable,
  title={A reconfigurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128K synapses},
  author={Qiao, Ning and Mostafa, Hesham and Corradi, Federico and Osswald, Marc and Stefanini, Fabio and Sumislawska, Dora and Indiveri, Giacomo},
  journal={Frontiers in neuroscience},
  volume={9},
  pages={141},
  year={2015},
  publisher={Frontiers Media SA}
}


@inproceedings{DBLP:conf/cvpr/RadosavovicKGHD20,
  author       = {Ilija Radosavovic and
                  Raj Prateek Kosaraju and
                  Ross B. Girshick and
                  Kaiming He and
                  Piotr Doll{\'{a}}r},
  title        = {Designing Network Design Spaces},
  booktitle    = {2020 {IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2020, Seattle, WA, USA, June 13-19, 2020},
  year         = {2020},
}

@inproceedings{DBLP:conf/icml/TanL19,
  author       = {Mingxing Tan and
                  Quoc V. Le},
  editor       = {Kamalika Chaudhuri and
                  Ruslan Salakhutdinov},
  title        = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  booktitle    = {Proceedings of the 36th International Conference on Machine Learning,
                  {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}},
  year         = {2019},
}

@inproceedings{DBLP:conf/iclr/DengLZG22,
  author       = {Shikuang Deng and
                  Yuhang Li and
                  Shanghang Zhang and
                  Shi Gu},
  title        = {Temporal Efficient Training of Spiking Neural Network via Gradient
                  Re-weighting},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  year         = {2022},
}

@inproceedings{DBLP:conf/nips/FangYCHMT21,
  author       = {Wei Fang and
                  Zhaofei Yu and
                  Yanqi Chen and
                  Tiejun Huang and
                  Timoth{\'{e}}e Masquelier and
                  Yonghong Tian},
  title        = {Deep Residual Learning in Spiking Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems 34: Annual Conference
                  on Neural Information Processing Systems 2021, NeurIPS 2021, December
                  6-14, 2021, virtual},
  year         = {2021},
}

@article{DBLP:journals/pami/YaoZZHDTXL23,
  author       = {Man Yao and
                  Guangshe Zhao and
                  Hengyu Zhang and
                  Yifan Hu and
                  Lei Deng and
                  Yonghong Tian and
                  Bo Xu and
                  Guoqi Li},
  title        = {Attention Spiking Neural Networks},
  journal      = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  year         = {2023},
}

@inproceedings{DBLP:conf/nips/YaoHZ000L23,
  author       = {Man Yao and
                  Jiakui Hu and
                  Zhaokun Zhou and
                  Li Yuan and
                  Yonghong Tian and
                  Bo Xu and
                  Guoqi Li},
  title        = {Spike-driven Transformer},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
}

@article{DBLP:journals/corr/abs-2305-05954,
  author       = {Chenlin Zhou and
                  Han Zhang and
                  Zhaokun Zhou and
                  Liutao Yu and
                  Zhengyu Ma and
                  Huihui Zhou and
                  Xiaopeng Fan and
                  Yonghong Tian},
  title        = {Enhancing the Performance of Transformer-based Spiking Neural Networks
                  by SNN-optimized Downsampling with Precise Gradient Backpropagation},
  journal      = {CoRR},
  year         = {2023},
}

@article{DBLP:journals/corr/abs-2304-11954,
  author       = {Chenlin Zhou and
                  Liutao Yu and
                  Zhaokun Zhou and
                  Han Zhang and
                  Zhengyu Ma and
                  Huihui Zhou and
                  Yonghong Tian},
  title        = {Spikingformer: Spike-driven Residual Learning for Transformer-based
                  Spiking Neural Network},
  journal      = {CoRR},
  year         = {2023},
}

@article{DBLP:journals/corr/abs-2401-02020,
  author       = {Zhaokun Zhou and
                  Kaiwei Che and
                  Wei Fang and
                  Keyu Tian and
                  Yuesheng Zhu and
                  Shuicheng Yan and
                  Yonghong Tian and
                  Li Yuan},
  title        = {Spikformer {V2:} Join the High Accuracy Club on ImageNet with an {SNN}
                  Ticket},
  journal      = {CoRR},
  year         = {2024},
}

@article{zhang2024sglformer,
  title={SGLFormer: Spiking Global-Local-Fusion Transformer with High Performance},
  author={Zhang, Han and Zhou, Chenlin and Yu, Liutao and Huang, Liwei and Ma, Zhengyu and Fan, Xiaopeng and Zhou, Huihui and Tian, Yonghong},
  journal={Frontiers in Neuroscience},
  year={2024},
  publisher={Frontiers}
}

@inproceedings{zhuonline,
  title={Online Stabilization of Spiking Neural Networks},
  author={Zhu, Yaoyu and Ding, Jianhao and Huang, Tiejun and Xie, Xiaodong and Yu, Zhaofei},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
}

@inproceedings{DBLP:conf/nips/DuanDCY022,
  author       = {Chaoteng Duan and
                  Jianhao Ding and
                  Shiyan Chen and
                  Zhaofei Yu and
                  Tiejun Huang},
  title        = {Temporal Effective Batch Normalization in Spiking Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
}

@inproceedings{DBLP:conf/aaai/QiuZC0DL24,
  author       = {Xuerui Qiu and
                  Rui{-}Jie Zhu and
                  Yuhong Chou and
                  Zhaorui Wang and
                  Liang{-}Jian Deng and
                  Guoqi Li},
  title        = {Gated Attention Coding for Training High-Performance and Efficient
                  Spiking Neural Networks},
  booktitle    = {Thirty-Eighth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2024, Thirty-Sixth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2024, Fourteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2014, February 20-27, 2024, Vancouver,
                  Canada},
  year         = {2024},
}

@inproceedings{DBLP:conf/aaai/GuoCLPZHM24,
  author       = {Yufei Guo and
                  Yuanpei Chen and
                  Xiaode Liu and
                  Weihang Peng and
                  Yuhan Zhang and
                  Xuhui Huang and
                  Zhe Ma},
  title        = {Ternary Spike: Learning Ternary Spikes for Spiking Neural Networks},
  booktitle    = {Thirty-Eighth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2024, Thirty-Sixth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2024, Fourteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2014, February 20-27, 2024, Vancouver,
                  Canada},
  year         = {2024},
}

@inproceedings{conf/iclr/Datta24,
  author       = {Gourav Datta*, Zeyu Liu*, Peter A Beerel},
  title        = {Can we get the best of both Binary Neural Networks and Spiking Neural Networks for Efficient 
                  Computer Vision?},
  booktitle    = {The Twelfth International Conference on Learning Representations, {ICLR} 2024,
                 Austria, May 6-11, 2024},
  year         = {2024},
}

@inproceedings{DBLP:conf/iclr/HaoDB0Y23,
  author       = {Zecheng Hao and
                  Jianhao Ding and
                  Tong Bu and
                  Tiejun Huang and
                  Zhaofei Yu},
  title        = {Bridging the Gap between ANNs and SNNs by Calibrating Offset Spikes},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  year         = {2023},
}

@article{jiangspatio24,
  title={Spatio-Temporal Approximation: A Training-Free SNN Conversion For Transformers},
  author={Jiang, Yizhou and Hu, Kunlin and Zhang, Tianren and Gao, Haichuan and Liu, Yuqian and Fang, Ying and Chen, Feng},
  booktitle    = {The Twelfth International Conference on Learning Representations, {ICLR} 2024,
                 Austria, May 6-11, 2024},
  year         = {2024},
}

@inproceedings{hao2023progressive,
  title={A Progressive Training Framework for Spiking Neural Networks with Learnable Multi-hierarchical Model},
  author={Hao, Zecheng and Shi, Xinyu and Huang, Zihan and Bu, Tong and Yu, Zhaofei and Huang, Tiejun},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{DBLP:conf/nips/XiaoMZHL22,
  author       = {Mingqing Xiao and
                  Qingyan Meng and
                  Zongpeng Zhang and
                  Di He and
                  Zhouchen Lin},
  title        = {Online Training Through Time for Spiking Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
}

@inproceedings{DBLP:conf/nips/YaoLM022,
  author       = {Xingting Yao and
                  Fanrong Li and
                  Zitao Mo and
                  Jian Cheng},
  title        = {{GLIF:} {A} Unified Gated Leaky Integrate-and-Fire Neuron for Spiking
                  Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
}

@inproceedings{DBLP:conf/aaai/HaoBD0Y23,
  author       = {Zecheng Hao and
                  Tong Bu and
                  Jianhao Ding and
                  Tiejun Huang and
                  Zhaofei Yu},
  title        = {Reducing {ANN-SNN} Conversion Error through Residual Membrane Potential},
  booktitle    = {Thirty-Seventh {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2023, Thirty-Fifth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2023, Thirteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2023, Washington, DC, USA, February
                  7-14, 2023},
  year         = {2023},
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@misc{torchvision2016,
    title        = {TorchVision: PyTorch's Computer Vision library},
    author       = {TorchVision maintainers and contributors},
    year         = 2016,
    journal      = {GitHub repository},
    publisher    = {GitHub},
    howpublished = {\url{https://github.com/pytorch/vision}}
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@inproceedings{DBLP:conf/ijcai/Li022,
  author       = {Yang Li and
                  Yi Zeng},
  title        = {Efficient and Accurate Conversion of Spiking Neural Network with Burst
                  Spikes},
  booktitle    = {Proceedings of the Thirty-First International Joint Conference on
                  Artificial Intelligence, {IJCAI} 2022, Vienna, Austria, 23-29 July
                  2022},
  year         = {2022},
}

@article{DBLP:journals/pami/HuZJP23,
  author       = {Yangfan Hu and
                  Qian Zheng and
                  Xudong Jiang and
                  Gang Pan},
  title        = {Fast-SNN: Fast Spiking Neural Network by Converting Quantized {ANN}},
  journal      = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  year         = {2023},
}

@inproceedings{DBLP:conf/nips/LiGKP23,
  author       = {Yuhang Li and
                  Tamar Geller and
                  Youngeun Kim and
                  Priyadarshini Panda},
  title        = {{SEENN:} Towards Temporal Spiking Early Exit Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
}

@inproceedings{DBLP:conf/iccv/LiJF23,
  author       = {Chen Li and
                  Edward G. Jones and
                  Steve Furber},
  title        = {Unleashing the Potential of Spiking Neural Networks with Dynamic Confidence},
  booktitle    = {{IEEE/CVF} International Conference on Computer Vision, {ICCV} 2023,
                  Paris, France, October 1-6, 2023},
  year         = {2023},
}


@article{DBLP:journals/corr/abs-1811-10766,
  author       = {Jacques Kaiser and
                  Hesham Mostafa and
                  Emre Neftci},
  title        = {Synaptic Plasticity Dynamics for Deep Continuous Local Learning},
  journal      = {CoRR},
  year         = {2018},
}

@inproceedings{DBLP:conf/iclr/RathiSP020,
  author       = {Nitin Rathi and
                  Gopalakrishnan Srinivasan and
                  Priyadarshini Panda and
                  Kaushik Roy},
  title        = {Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike
                  Timing Dependent Backpropagation},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  year         = {2020},
}

@article{DBLP:journals/corr/abs-2205-07473,
  author       = {Ziming Wang and
                  Shuang Lian and
                  Yuhao Zhang and
                  Xiaoxin Cui and
                  Rui Yan and
                  Huajin Tang},
  title        = {Towards Lossless {ANN-SNN} Conversion under Ultra-Low Latency with
                  Dual-Phase Optimization},
  journal      = {CoRR},
  year         = {2022},
}

@article{DBLP:journals/tnn/RathiR23,
  author       = {Nitin Rathi and
                  Kaushik Roy},
  title        = {{DIET-SNN:} {A} Low-Latency Spiking Neural Network With Direct Input
                  Encoding and Leakage and Threshold Optimization},
  journal      = {{IEEE} Trans. Neural Networks Learn. Syst.},
  year         = {2023},
}

@inproceedings{guo2022recdis,
  title={Recdis-SNN: Rectifying membrane potential distribution for directly training spiking neural networks},
  author={Guo, Yufei and Tong, Xinyi and Chen, Yuanpei and Zhang, Liwen and Liu, Xiaode and Ma, Zhe and Huang, Xuhui},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2022}
}

@inproceedings{meng2022training,
  title={Training high-performance low-latency spiking neural networks by differentiation on spike representation},
  author={Meng, Qingyan and Xiao, Mingqing and Yan, Shen and Wang, Yisen and Lin, Zhouchen and Luo, Zhi-Quan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},  
  year={2022}
}

@article{wei2023bayesian,
  title={Bayesian Bi-clustering of Neural Spiking Activity with Latent Structures},
  author={Wei, Ganchao},
  booktitle    = {The Twelfth International Conference on Learning Representations, {ICLR} 2024,
                 Austria, May 6-11, 2024},
  year         = {2024},
}

@inproceedings{DBLP:conf/nips/WeiSW22,
  author       = {Ganchao Wei and
                  Ian H. Stevenson and
                  Xiaojing Wang},
  title        = {Bayesian Clustering of Neural Spiking Activity Using a Mixture of
                  Dynamic Poisson Factor Analyzers},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
}

@inproceedings{ho2021tcl,
  title={TCL: an ANN-to-SNN conversion with trainable clipping layers},
  author={Ho, Nguyen-Dong and Chang, Ik-Joon},
  booktitle={2021 58th ACM/IEEE Design Automation Conference (DAC)},
  year={2021},
  organization={IEEE}
}

@article{Sengupta2018Going,
  title={Going Deeper in Spiking Neural Networks: VGG and Residual Architectures},
  author={Sengupta, Abhronil and Ye, Yuting and Wang, Robert and Liu, Chiao and Roy, Kaushik},
  journal={Frontiers in Neuroence},
  year={2018},
}

@article{DBLP:journals/tnn/WuCZLLT23,
  author       = {Jibin Wu and
                  Yansong Chua and
                  Malu Zhang and
                  Guoqi Li and
                  Haizhou Li and
                  Kay Chen Tan},
  title        = {A Tandem Learning Rule for Effective Training and Rapid Inference
                  of Deep Spiking Neural Networks},
  journal      = {{IEEE} Trans. Neural Networks Learn. Syst.},
  year         = {2023},
}

@inproceedings{DBLP:conf/iclr/OConnorGRW18,
  author       = {Peter O'Connor and
                  Efstratios Gavves and
                  Matthias Reisser and
                  Max Welling},
  title        = {Temporally Efficient Deep Learning with Spikes},
  booktitle    = {6th International Conference on Learning Representations, {ICLR} 2018,
                  Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  year         = {2018},
}

@inproceedings{zenke2018superspike,
  title={Superspike: Supervised learning in multilayer spiking neural networks},
  author={Zenke, Friedemann and Ganguli, Surya},
  journal={Neural computation},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{wei2023temporal,
  title={Temporal-coded spiking neural networks with dynamic firing threshold: Learning with event-driven backpropagation},
  author={Wei, Wenjie and Zhang, Malu and Qu, Hong and Belatreche, Ammar and Zhang, Jian and Chen, Hong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},  
  year={2023}
}

@inproceedings{zhu2024exploring,
  title={Exploring Loss Functions for Time-based Training Strategy in Spiking Neural Networks},
  author={Zhu, Yaoyu and Fang, Wei and Xie, Xiaodong and Huang, Tiejun and Yu, Zhaofei},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@inproceedings{zhang2023memory,
  title={Memory-Efficient Reversible Spiking Neural Networks},
  author={Zhang, Hong and Zhang, Yu},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  year={2024}
}

@article{rathi2023exploring,
  title={Exploring neuromorphic computing based on spiking neural networks: Algorithms to hardware},
  author={Rathi, Nitin and Chakraborty, Indranil and Kosta, Adarsh and Sengupta, Abhronil and Ankit, Aayush and Panda, Priyadarshini and Roy, Kaushik},
  journal={ACM Computing Surveys},
  year={2023},
}

@article{lapicque1907recherches,
  title={Recherches quantitatives sur l’excitation electrique des nerfs},
  author={Lapicque, LM},
  journal={J Physiol Paris},
  year={1907}
}

@article{DBLP:journals/nn/Maass97,
  author       = {Wolfgang Maass},
  title        = {Networks of spiking neurons: The third generation of neural network
                  models},
  journal      = {Neural Networks},
  year         = {1997},
}

@article{DBLP:journals/tnn/Izhikevich03,
  author       = {Eugene M. Izhikevich},
  title        = {Simple model of spiking neurons},
  journal      = {{IEEE} Trans. Neural Networks},
  year         = {2003},
}


@article{fang2023spikingjelly,
  title={SpikingJelly: An open-source machine learning infrastructure platform for spike-based intelligence},
  author={Fang, Wei and Chen, Yanqi and Ding, Jianhao and Yu, Zhaofei and Masquelier, Timoth{\'e}e and Chen, Ding and Huang, Liwei and Zhou, Huihui and Li, Guoqi and Tian, Yonghong},
  journal={Science Advances},
  year={2023},
  publisher={American Association for the Advancement of Science}
}

@article{dalgaty2024mosaic,
  title={Mosaic: in-memory computing and routing for small-world spike-based neuromorphic systems},
  author={Dalgaty, Thomas and Moro, Filippo and Demira{\u{g}}, Yi{\u{g}}it and De Pra, Alessio and Indiveri, Giacomo and Vianello, Elisa and Payvand, Melika},
  journal={Nature Communications},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{DBLP:journals/corr/abs-2401-01141,
  author       = {Alessio Carpegna and
                  Alessandro Savino and
                  Stefano Di Carlo},
  title        = {Spiker+: a framework for the generation of efficient Spiking Neural
                  Networks {FPGA} accelerators for inference at the edge},
  journal      = {CoRR},
  year         = {2024},
}

@inproceedings{DBLP:conf/iccv/GuoZCPLZHM23,
  author       = {Yufei Guo and
                  Yuhan Zhang and
                  Yuanpei Chen and
                  Weihang Peng and
                  Xiaode Liu and
                  Liwen Zhang and
                  Xuhui Huang and
                  Zhe Ma},
  title        = {Membrane Potential Batch Normalization for Spiking Neural Networks},
  booktitle    = {{IEEE/CVF} International Conference on Computer Vision, {ICCV} 2023,
                  Paris, France, October 1-6, 2023},
  year         = {2023},
}

@inproceedings{DBLP:conf/nips/KimKK20a,
  author       = {Jinseok Kim and
                  Kyungsu Kim and
                  Jae{-}Joon Kim},
  title        = {Unifying Activation- and Timing-based Learning Rules for Spiking Neural
                  Networks},
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference
                  on Neural Information Processing Systems 2020, NeurIPS 2020, December
                  6-12, 2020, virtual},
  year         = {2020},
}

@inproceedings{bellec2018long,
  title={Long short-term memory and learning-to-learn in networks of spiking neurons},
  author={Bellec, Guillaume and Salaj, Darjan and Subramoney, Anand and Legenstein, Robert and Maass, Wolfgang},
  journal={Advances in neural information processing systems},  
  year={2018}
}

@inproceedings{fang2021incorporating,
  title={Incorporating learnable membrane time constant to enhance learning of spiking neural networks},
  author={Fang, Wei and Yu, Zhaofei and Chen, Yanqi and Masquelier, Timoth{\'e}e and Huang, Tiejun and Tian, Yonghong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  year={2021}
}

@inproceedings{bojkovic2024data,
  title={Data Driven Threshold and Potential Initialization for Spiking Neural Networks},
  author={Bojkovic, Velibor and Anumasa, Srinivas and De Masi, Giulia and Gu, Bin and Xiong, Huan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2024},
}

@article{mukhoty2024direct,
  title={Direct Training of SNN using Local Zeroth Order Method},
  author={Mukhoty, Bhaskar and Bojkovi{\'c}, Velibor and de Vazelhes, William and Zhao, Xiaohan and De Masi, Giulia and Xiong, Huan and Gu, Bin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{DBLP:journals/ploscb/BouhadjarWDT22,
  author       = {Younes Bouhadjar and
                  Dirk J. Wouters and
                  Markus Diesmann and
                  Tom Tetzlaff},
  title        = {Sequence learning, prediction, and replay in networks of spiking neurons},
  journal      = {PLoS Comput. Biol.},
  year         = {2022},
}

@article{DBLP:journals/corr/abs-2312-17582,
  author       = {De Ma and
                  Xiaofei Jin and
                  Shichun Sun and
                  Yitao Li and
                  Xundong Wu and
                  Youneng Hu and
                  Fangchao Yang and
                  Huajin Tang and
                  Xiaolei Zhu and
                  Peng Lin and
                  Gang Pan},
  title        = {Darwin3: {A} large-scale neuromorphic chip with a Novel {ISA} and
                  On-Chip Learning},
  journal      = {CoRR},
  year         = {2023},
}

@inproceedings{bal2023spikingbert,
  title={Spikingbert: Distilling bert to train spiking language models using implicit differentiation},
  author={Bal, Malyaban and Sengupta, Abhronil},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  year={2024}
}


@article{DBLP:journals/corr/abs-2302-13939,
  author       = {Rui{-}Jie Zhu and
                  Qihang Zhao and
                  Jason K. Eshraghian},
  title        = {SpikeGPT: Generative Pre-trained Language Model with Spiking Neural
                  Networks},
  journal      = {CoRR},
  year         = {2023},
}


@inproceedings{wang2023masked,
  title={Masked spiking transformer},
  author={Wang, Ziqing and Fang, Yuetong and Cao, Jiahang and Zhang, Qiang and Wang, Zhongrui and Xu, Renjing},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},  
  year={2023}
}

@article{DBLP:journals/iclr/SpikePoint,
  author       = {Hongwei Ren and
                  Yue Zhou and
                  Yulong Huang and
                  Haotian Fu and
                  Xiaopeng Lin and
                  Jie Song and
                  Bojun Cheng},
  title        = {SpikePoint: An Efficient Point-based Spiking Neural Network for Event
                  Cameras Action Recognition},
  booktitle    = {The Twelfth International Conference on Learning Representations, {ICLR} 2024,
                 Austria, May 6-11, 2024},
  year         = {2024},
}

@inproceedings{DBLP:conf/aaai/WangZHWZX23,
  author       = {Qingyu Wang and
                  Tielin Zhang and
                  Minglun Han and
                  Yi Wang and
                  Duzhen Zhang and
                  Bo Xu},
  title        = {Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient
                  Automatic Speech Recognition},
  booktitle    = {Thirty-Seventh {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2023, Thirty-Fifth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2023, Thirteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2023, Washington, DC, USA, February
                  7-14, 2023},
  year         = {2023},
}


@inproceedings{liu2022spikeconverter,
  title={Spikeconverter: An efficient conversion framework zipping the gap between artificial neural networks and spiking neural networks},
  author={Liu, Fangxin and Zhao, Wenbo and Chen, Yongbiao and Wang, Zongwu and Jiang, Li},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={2},
  pages={1692--1701},
  year={2022}
}


@inproceedings{DBLP:conf/iccv/GuoLCZPZHM23,
  author       = {Yufei Guo and
                  Xiaode Liu and
                  Yuanpei Chen and
                  Liwen Zhang and
                  Weihang Peng and
                  Yuhan Zhang and
                  Xuhui Huang and
                  Zhe Ma},
  title        = {RMP-Loss: Regularizing Membrane Potential Distribution for Spiking
                  Neural Networks},
  booktitle    = {{IEEE/CVF} International Conference on Computer Vision, {ICCV} 2023,
                  Paris, France, October 1-6, 2023},  
  year         = {2023},
}

@book{izhikevich2007dynamical,
  title={Dynamical systems in neuroscience},
  author={Izhikevich, Eugene M},
  year={2007},
  publisher={MIT press}
}

@article{connors1990intrinsic,
  title={Intrinsic firing patterns of diverse neocortical neurons},
  author={Connors, Barry W and Gutnick, Michael J},
  journal={Trends in neurosciences},
  volume={13},
  number={3},
  pages={99--104},
  year={1990},
  publisher={Elsevier}
}

@article{llinas1982electrophysiology,
  title={Electrophysiology of mammalian thalamic neurones in vitro},
  author={Llin{\'a}s, Rodolfo and Jahnsen, Henrik},
  journal={Nature},
  volume={297},
  number={5865},
  pages={406--408},
  year={1982},
  publisher={Nature Publishing Group UK London}
}

@article{krahe2004burst,
  title={Burst firing in sensory systems},
  author={Krahe, R{\"u}diger and Gabbiani, Fabrizio},
  journal={Nature Reviews Neuroscience},
  volume={5},
  number={1},
  pages={13--23},
  year={2004},
  publisher={Nature Publishing Group UK London}
}

@article{shadlen1994noise,
  title={Noise, neural codes and cortical organization},
  author={Shadlen, Michael N and Newsome, William T},
  journal={Current opinion in neurobiology},
  volume={4},
  number={4},
  pages={569--579},
  year={1994},
  publisher={Elsevier}
}

@article{faisal2008noise,
  title={Noise in the nervous system},
  author={Faisal, A Aldo and Selen, Luc PJ and Wolpert, Daniel M},
  journal={Nature reviews neuroscience},
  volume={9},
  number={4},
  pages={292--303},
  year={2008},
  publisher={Nature Publishing Group}
}

@article{softky1993highly,
  title={The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs},
  author={Softky, William R and Koch, Christof},
  journal={Journal of neuroscience},
  volume={13},
  number={1},
  pages={334--350},
  year={1993},
  publisher={Soc Neuroscience}
}

@article{maass1997networks,
  title={Networks of spiking neurons can emulate arbitrary Hopfield nets in temporal coding},
  author={Maass, Wolfgang and Natschl{\"a}ger, Thomas},
  journal={Network: Computation in Neural Systems},
  volume={8},
  number={4},
  pages={355--371},
  year={1997},
  publisher={Taylor \& Francis}
}

@article{pagliarini2019probabilistic,
  title={A probabilistic synapse with strained MTJs for spiking neural networks},
  author={Pagliarini, Samuel N and Bhuin, Sudipta and Isgenc, Mehmet Meric and Biswas, Ayan Kumar and Pileggi, Larry},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={31},
  number={4},
  pages={1113--1123},
  year={2019},
  publisher={IEEE}
}

@article{stein2005neuronal,
  title={Neuronal variability: noise or part of the signal?},
  author={Stein, Richard B and Gossen, E Roderich and Jones, Kelvin E},
  journal={Nature Reviews Neuroscience},
  volume={6},
  number={5},
  pages={389--397},
  year={2005},
  publisher={Nature Publishing Group UK London}
}

@article{hu2023fast,
  title={Fast-SNN: fast spiking neural network by converting quantized ANN},
  author={Hu, Yangfan and Zheng, Qian and Jiang, Xudong and Pan, Gang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@inproceedings{shen2024conventional,
  title={Are Conventional SNNs Really Efficient? A Perspective from Network Quantization},
  author={Shen, Guobin and Zhao, Dongcheng and Li, Tenglong and Li, Jindong and Zeng, Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27538--27547},
  year={2024}
}

@article{wu2024ftbc,
  title={FTBC: Forward Temporal Bias Correction for Optimizing ANN-SNN Conversion},
  author={Wu, Xiaofeng and Bojkovic, Velibor and Gu, Bin and Suo, Kun and Zou, Kai},
  journal={ECCV},
  year={2024}
}

@article{das2023design,
  title={A design flow for scheduling spiking deep convolutional neural networks on heterogeneous neuromorphic system-on-chip},
  author={Das, Anup},
  journal={ACM Transactions on Embedded Computing Systems},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{song2021design,
  title={A design flow for mapping spiking neural networks to many-core neuromorphic hardware},
  author={Song, Shihao and Varshika, M Lakshmi and Das, Anup and Kandasamy, Nagarajan},
  booktitle={2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)},
  pages={1--9},
  year={2021},
  organization={IEEE}
}


@inproceedings{varshika2022design,
  title={Design of many-core big little $\mu$Brains for energy-efficient embedded neuromorphic computing},
  author={Varshika, M Lakshmi and Balaji, Adarsha and Corradi, Federico and Das, Anup and Stuijt, Jan and Catthoor, Francky},
  booktitle={2022 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={1011--1016},
  year={2022},
  organization={IEEE}
}

@article{pehle2022brainscales,
  title={The BrainScaleS-2 accelerated neuromorphic system with hybrid plasticity},
  author={Pehle, Christian and Billaudelle, Sebastian and Cramer, Benjamin and Kaiser, Jakob and Schreiber, Korbinian and Stradmann, Yannik and Weis, Johannes and Leibfried, Aron and M{\"u}ller, Eric and Schemmel, Johannes},
  journal={Frontiers in Neuroscience},
  volume={16},
  pages={795876},
  year={2022},
  publisher={Frontiers Media SA}
}

@article{furber2014spinnaker,
  title={The spinnaker project},
  author={Furber, Steve B and Galluppi, Francesco and Temple, Steve and Plana, Luis A},
  journal={Proceedings of the IEEE},
  volume={102},
  number={5},
  pages={652--665},
  year={2014},
  publisher={IEEE}
}

@article{gonzalez2024spinnaker2,
  title={SpiNNaker2: A large-scale neuromorphic system for event-based and asynchronous machine learning},
  author={Gonzalez, Hector A and Huang, Jiaxin and Kelber, Florian and Nazeer, Khaleelulla Khan and Langer, Tim and Liu, Chen and Lohrmann, Matthias and Rostami, Amirhossein and Sch{\"o}ne, Mark and Vogginger, Bernhard and others},
  journal={arXiv preprint arXiv:2401.04491},
  year={2024}
}

@article{merolla2014million,
  title={A million spiking-neuron integrated circuit with a scalable communication network and interface},
  author={Merolla, Paul A and Arthur, John V and Alvarez-Icaza, Rodrigo and Cassidy, Andrew S and Sawada, Jun and Akopyan, Filipp and Jackson, Bryan L and Imam, Nabil and Guo, Chen and Nakamura, Yutaka and others},
  journal={Science},
  volume={345},
  number={6197},
  pages={668--673},
  year={2014},
  publisher={American Association for the Advancement of Science}
}

@article{davies2018loihi,
  title={Loihi: A neuromorphic manycore processor with on-chip learning},
  author={Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Cao, Yongqiang and Choday, Sri Harsha and Dimou, Georgios and Joshi, Prasad and Imam, Nabil and Jain, Shweta and others},
  journal={Ieee Micro},
  volume={38},
  number={1},
  pages={82--99},
  year={2018},
  publisher={IEEE}
}

@inproceedings{yaoTemporalwiseAttentionSpiking2021,
  title = {Temporal-Wise Attention Spiking Neural Networks for Event Streams Classification},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Yao, Man and Gao, Huanhuan and Zhao, Guangshe and Wang, Dingheng and Lin, Yihan and Yang, Zhaoxu and Li, Guoqi},
  year = {2021},
  pages = {10221--10230},
  file = {C\:\\Users\\16124\\Zotero\\storage\\AQRLNQFP\\Yao et al_2021_Temporal-wise attention spiking neural networks for event streams classification.pdf}
}

@inproceedings{fangIncorporatingLearnableMembrane2021,
  title = {Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Fang, Wei and Yu, Zhaofei and Chen, Yanqi and Masquelier, Timoth{\'e}e and Huang, Tiejun and Tian, Yonghong},
  year = {2021},
  pages = {2661--2671},
  file = {C\:\\Users\\16124\\Zotero\\storage\\H9CLAZ9S\\Fang et al_2021_Incorporating learnable membrane time constant to enhance learning of spiking.pdf}
}


@article{liDifferentiableSpikeRethinking2021,
  title = {Differentiable Spike: {{Rethinking}} Gradient-Descent for Training Spiking Neural Networks},
  shorttitle = {Differentiable Spike},
  author = {Li, Yuhang and Guo, Yufei and Zhang, Shanghang and Deng, Shikuang and Hai, Yongqing and Gu, Shi},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {23426--23439},
  file = {C\:\\Users\\16124\\Zotero\\storage\\DKGUP45I\\Li et al_2021_Differentiable spike.pdf}
}

@inproceedings{mengTrainingHighPerformanceLowLatency2022,
  title = {Training {{High-Performance Low-Latency Spiking Neural Networks}} by {{Differentiation}} on {{Spike Representation}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Meng, Qingyan and Xiao, Mingqing and Yan, Shen and Wang, Yisen and Lin, Zhouchen and Luo, Zhi-Quan},
  year = {2022},
  pages = {12444--12453},
  file = {C\:\\Users\\16124\\Zotero\\storage\\PZBKWWTJ\\Meng et al_2022_Training High-Performance Low-Latency Spiking Neural Networks by.pdf}
}


@article{zhouSpikformerWhenSpiking2022,
  title = {Spikformer: {{When Spiking Neural Network Meets Transformer}}},
  shorttitle = {Spikformer},
  author = {Zhou, Zhaokun and Zhu, Yuesheng and He, Chao and Wang, Yaowei and Yan, Shuicheng and Tian, Yonghong and Yuan, Li},
  year = {2022},
  journal = {arXiv preprint arXiv:2209.15425},
  eprint = {2209.15425},
  archiveprefix = {arxiv},
  file = {C\:\\Users\\16124\\Zotero\\storage\\6L5EUSZT\\Zhou et al_2022_Spikformer.pdf}
}

@inproceedings{wang2024adaptive,
  title={Adaptive Calibration: A Unified Conversion Framework of Spiking Neural Network},
  author={Wang, Ziqing and Fang, Yuetong and Cao, Jiahang and Ren, Hongwei and Xu, Renjing},  
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2025}
}

@article{li2017cifar10,
  title={Cifar10-dvs: an event-stream dataset for object classification},
  author={Li, Hongmin and Liu, Hanchao and Ji, Xiangyang and Li, Guoqi and Shi, Luping},
  journal={Frontiers in neuroscience},
  volume={11},
  pages={309},
  year={2017},
  publisher={Frontiers Media SA}
}

