\clearpage
\onecolumn
\section*{Appendix}

\section{Influence of different sampling methods}
\label{app:avgpool}
To support our hypothesis of using the average pooling, we test it with stride sampling, which selects pixels with constant strides.
In principle, the stride sampling would not change the distribution of perturbations. Therefore, it serves as a baseline to compare the influence of distributions.

We test four types of noise distributions: (1) Gaussian $\mathcal{N}(0, 0.3^2)$, (2) Mixture of Gaussian (MoG), $0.5\cdot\mathcal{N}(-1.0, 0.5^2) + 0.5\cdot\mathcal{N}(1.0, 0.5^2)$, (3) Beta distribution, $\text{Beta}(0.5, 0.5) - 0.5$, and (4) Uniform distribution, $\text{Uniform}(-0.5, 0.5)$. For MoG, Beta and uniform noises, we scale them to have the same signal-to-noise ratio with the Gaussian distribution. We add the noises on the Girl image \cite{loeschcke2024coarse} with resolution $1024 \times 1024$. First, we show the noise distributions in \Cref{fig:app-sampling}. As can be seen, the Avg Pooling strategy transforms the non-Gaussian noises into Gaussian-like noises, while the Stride sampling would not. Second, we run the PuTT algorithm with different sampling methods for 100 times. The violin plot of denoising results are shown in \Cref{fig:app-denoising}.
In Gaussian distribution, the Stride sampling is better than AvgPooling. While for non-Gaussian noises, the AvgPooling is more robust and better than Stride.
The denoising results indicate that the average pooling can handle different types of noises, which is consistent with our hypothesis. However, as we introduced, this might not be enough, since we need to deal with the original image and noises in the final stage.

\begin{figure}[h]
    \centering
    \subfigure[MoG with Avg Pooling]{%
        \includegraphics[width=0.47\linewidth]{figures/appendix/downsampling_mog_avg.png} % Replace with your image
    }
    \subfigure[MoG with Stride Sampling]{%
        \includegraphics[width=0.47\linewidth]{figures/appendix/downsampling_mog_stride.png} % Replace with your image
    }

    \subfigure[Beta with Avg Pooling]{%
        \includegraphics[width=0.47\linewidth]{figures/appendix/downsampling_beta_avg.png} % Replace with your image
    }
    \subfigure[Beta with Stride Sampling]{%
        \includegraphics[width=0.47\linewidth]{figures/appendix/downsampling_beta_stride.png} % Replace with your image
    }

    \subfigure[Uniform with Avg Pooling]{%
        \includegraphics[width=0.47\linewidth]{figures/appendix/downsampling_uniform_avg.png} % Replace with your image
    }
    \subfigure[Uniform with Stride Sampling]{%
        \includegraphics[width=0.47\linewidth]{figures/appendix/downsampling_uniform_stride.png} % Replace with your image
    }
    \caption{Histogram figures of noises under different sampling methods.}
    \label{fig:app-sampling}
\end{figure}


\begin{figure}[h]
    \centering
    \subfigure[PSNR]{%
    \includegraphics[width=0.4\linewidth]{figures/appendix/psnr_violin.png} % Replace with your image
    }\hspace{2em}
    \subfigure[SSIM]{%
    \includegraphics[width=0.4\linewidth]{figures/appendix/ssim_violin.png} % Replace with your image
    }
    \caption{Violin plot of denoising results using different sampling methods. (a) PSNR results. (b) SSIM results.}
    \label{fig:app-denoising}
\end{figure}

\section{Tensor network decomposition}\label{app:TN}


\subsection{Matrix Product Operators}
A matrix product operator (MPO) \cite{mcculloch2008infinite,hubig2017generic} is the TN representation of
a linear operator acting on a TT format, which makes it highly efficient to handle large operators.
Namely, a linear operator
\(
\vectcal{A}: \Real^{I_1 \times \ldots \times I_D} \to \Real^{J_1 \times \ldots \times J_D} \,.
\)
Namely, if $\vectcal{Y}=\vectcal{A}\vectcal{X}$, then each entry of $\vectcal{Y}$ is given as
\[
{y}_{\mathbf{i}}= \sum_{i_1=1}^{I_1} \cdots \sum_{i_D=1}^{I_D} \vect{A}^1_{j_1,i_1} \vect{A}^2_{j_2,i_2} \ldots \vect{A}^D_{j_D,i_D} \vect{X}^1_{i_1} \vect{X}^2_{i_2} \ldots \vect{X}^D_{i_D}  \,,
\]

\subsection{Prolongation Operator}\label{app:TN.P}
This work uses a specific MPO, known as the
prolongation operator $\vectcal{P}_d$ \cite{lubasch2018multigrid}, to upsample a QTT format
of an image from resolution $d-1$ to $d$.

Consider a one-dimensional vector $\vect{x}_d \in \Real^{2^d}$.
The matrix $\vect{P}_{2^d \to 2^{d+1}}$ upsamples $\vect{x}_d$ to $\vect{x}_{d+1}$ by linear interpolation between adjacent points.
For example, for $d=2$,
\[
\vect{P}_{4 \to 8} =
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0.5 & 0.5 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0.5 & 0.5 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0.5 & 0.5 \\
0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0.5
\end{bmatrix}
\]
The matrix $\vect{P}_{2^d \to 2^{d+1}}$ can be written
as an MPO $\vectcal{P}_{d+1}$ entry-wise
\[
p_{j_1,\ldots, j_d, i_1, \ldots, i_{d+1}} = \vect{P}^1_{j_1,i_1} \ldots \vect{P}^{d}_{j_d,i_d} \vect{P}^{d+1}_{i_{d+1}} \,.
\]
The entries are given explicitly \cite{lubasch2018multigrid} as
\begin{align}
    \vect{P}^l_{1,1}(1,1) &= \vect{P}^l_{2,2}(1,1) = \vect{P}^l_{2,1}(1,2) = \vect{P}^l_{1,2}(2,2) = 1, \forall l \in [d] \notag \\
    \vect{P}^{d+1}_{1}(1) &= 1 \,, \vect{P}^{d+1}_{2}(1) = \vect{P}^{d+1}_{2}(2) = 0.5 \notag \,,
\end{align}
and other entries are zero.

The prolongation operator described above applies to the QTT format of
one-dimensional vectors. In general, this operator is the tensor product of the one-dimensional operators on each dimension: $\vectcal{P}_d^{(2)}=\vectcal{P}_d \otimes \vectcal{P}_d$ for 2-dimensions (images)
and $\vectcal{P}_d^{(3)}=\vectcal{P}_d \otimes \vectcal{P}_d \otimes \vectcal{P}_d$ for 3-dimensions (3D objects).
For simplicity, since this work concerns only images,
the superscript is omitted, denoting
the prolongation operator as $\vectcal{P}_d$.

Ultimately, for a resolution $d$ image $\vect{x}_d$, and
$\vectcal{X}_d = \quant(\vect{x}_d)$,
the upsampled image is resolution $d+1$, given as $\text{P}_d(\vect{x}_{d}) = \quant^{-1}(\vectcal{P}_d\vectcal{X}_d)$,
where the linear function $\text{P}_d(\cdot)$ acts on the image level.

\subsection{Recap of PuTT \cite{loeschcke2024coarse}}
\label{app:TN.putt}

A $2^D \times 2^D$ image, denoted as $\vect{x}_D$, can be quantized in to a $D$th
order tensor $\vectcal{X}_D=\text{Q}(\vect{x}_D)$.
Firstly, $\vect{x}_D$ is downsampled by average pooling to $\vect{x}_{D-l}$, correspondingly possesing a quantization $\vectcal{X}_{D-l}$.
Then, $D-l$ QTT cores of ${X}_{D-l}$ can be optimized by backpropagation, returning $\vectcal{Y}_{D-l}$.
The QTT cores of next resolution $\vectcal{X}_{D-l+1}$
can be optimized similarly, initialized by the prologation $\vectcal{P}_{D-l+1} (\vect{y}_{D-l})$.
Repeat the process until the original resolution. \cite{loeschcke2024coarse} demonstrates impressive reconstruction
capability of PuTT thanks to the QTT structure and coarse-to-fine approach.
The pseudocode is given in \cref{alg:putt}.

\begin{algorithm}[H]
    \caption{PuTT \cite{loeschcke2024coarse}}
    \label{alg:putt}
    \begin{algorithmic}
        \STATE \textbf{Input:} Image $\vect{x}_D$, number of iterations $T$,
        upsampling iterations $(t_1, \ldots, t_l)$.
        \STATE \textbf{Output:} TT reconstruction $\vect{y}_D = \text{PuTT}(\vect{x}_D)$.
        \STATE $d\gets D-l \,, \vect{x}_{d}\gets\avgpool(\vect{x}_D) \,, \vectcal{X}_{d}\gets \quant(\vect{x}_d)$
        \FOR{$t=1\to T$}
        \IF{$t \in (t_1, \ldots, t_l)$}
            \STATE $d \gets d+1$
            \STATE $\vect{x}_{d} \gets \avgpool(\vect{x}_D)$
            \STATE $\vectcal{X}_{d} \gets \quant(\vect{x}_d)$
        \ENDIF
        \STATE Loss $\ell \gets \text{MSE}(\vectcal{Y}_d-\vectcal{X}_d)$
        \STATE Update QTT cores $\vectcal{Y}_d$ by backpropagation
        \ENDFOR
        \STATE \textbf{return} $\vect{y}_D = \quant^{-1}(\vectcal{Y}_D)$
    \end{algorithmic}
\end{algorithm}

However, while PuTT aims to obtain better initialization by downsampling for better optimization and reconstruction, it does not account for adversarial examples or analyze the impact of downsampling on perturbations. Additionally, PuTT also minimizes the reconstruction loss on the input image, which inevitably results in the reconstruction of the perturbations. In contrast, we focus on the perturbations and propose a new optimization process introduced in the next section, aiming to reconstruct clean examples.

\section{More details of experimental settings}
\label{app:settings}

\subsection{Implementation details of adversarial attacks}
\textbf{AutoAttack} \quad We evaluate our method of defending against AutoAttack \citep{croce2020reliable} and compare with the state-of-the-art methods as listed RobustBench benchmark (https://robustbench.github.io). For a comprehensive evaluation, we conduct experiments under all adversarial attack settings. Specifically, we set $\epsilon=8/255$ and $\epsilon=0.5/1.0$ for AutoAttack $l_{\inf}$ and AutoAttack $l_2$ threats on CIFAR-10. On CIFAR-100, we set $\epsilon=8/255$ for AutoAttack $l_{\inf}$. On ImageNet, we set $\epsilon=4/255$ for AutoAttack $l_{\inf}$.

\textbf{PGD+EOT} \quad We evaluate our method of defending against PGD+EOT \citep{madry2018towards,athalye2018synthesizing} and present the comparisons of AT methods, AP methods, and our method. Following the guidelines of \citet{lee2023robust}, we set $\epsilon=8/255$ for PGD+EOT $l_{\inf}$ threats on CIFAR-10, where the update iterations of PGD is 200 with 20 EOT samples.



\subsection{Implementation details of our method}
For CIFAR-10, CIFAR-100 with resolution $32 \times 32$ and ImageNet with resolution $224 \times 224$, we first upsample them into resolution $2^D \times 2^D$ image $x_{D}$. Based on the initial experimental results, we set  $D = 8$, $l = 1$, $\alpha=0.1$, $\eta=0.1$ and $N=1$ for the following experiments. The table results presented in the paper are conducted under these hyperparameters. This trick creates a large enough image to downsample until the perturbations are well mixed into Gaussian noise. Furthermore, without this initial step, the semantic information can become almost indistinguishable after several downsampling steps, especially for low-resolution images.
For example, if a $32\times 32$ image is reduced with the factor of 8, the resolution $4\times 4$ image is of poor quality. Additionally, to more clearly observe the denoising effects in visualization results, we upsample the images to resolution $D=11$ with $\alpha=0.05$, $\eta=0.1$ and $N=3$ for the experiments in \Cref{fig:visual}, and comparisons in different downsampled images in \Cref{fig:distribution}. The code will be available upon acceptance, with more details provided in the configuration files.

\subsection{Implementation details of evaluation metrics}

We evaluate the performance of defense methods using multiple metrics: Standard accuracy and robust accuracy \citep{szegedy2013intriguing} on classification tasks. For denoising tasks, we measure the Normalized Root Mean Squared Error \citep[NRMSE,][]{botchkarev2018performance}, Structural Similarity Index Measure \citep[SSIM,][]{hore2010image}, Peak Signal-to-Noise Ratio (PSNR) metrics between a reference image $\vect{x}$ and its reconstruction $\vect{y}$, where pixel values are in $[0,1]$.
In denoising and reconstruction tasks, a lower NRMSE, a higher SSIM, and a higher PSNR generally indicate better performance.

% \textbf{Normalized Root Mean Squared Error}
% \[
% \text{NRMSE}(\vect{x}, \vect{y}) = \frac{\norm{\vect{x}-\vect{y}}_2}{\norm{\vect{x}}_2} \,.
% \]

% \textbf{Structural Similarity Index Measure \cite{hore2010image}} \quad
% \[
% \text{SSIM}(\vect{x}, \vect{y}) = \frac{(2\mu_x \mu_y + C_1)(2\sigma_{xy} + C_2)}
% {(\mu_x^2 + \mu_y^2 + C_1)(\sigma_x^2 + \sigma_y^2 + C_2)}
% \]

% where:
% \begin{itemize}
%     \item \( \mu_x \) and \( \mu_y \) are the mean pixel values of images \( \vect{x} \) and \( \vect{y} \).
%     \item \( \sigma_x^2 \) and \( \sigma_y^2 \) are the variances of \( \vect{x} \) and \( \vect{y} \).
%     \item \( \sigma_{xy} \) is the covariance between \( \vect{x} \) and \( \vect{y} \).
%     \item \( C_1 \) and \( C_2 \) are small constants to stabilize the division.
% \end{itemize}

% \textbf{Peak Signal-to-Noise Ratio} \quad
% \[
% \text{PSNR}(\vect{x}, \vect{y}) = 10 \log_{10} \left( \frac{1}{\text{MSE}(\vect{x}, \vect{y})} \right) \,.
% \]



\section{Inference time cost}
\begin{table}[htbp]
\centering
\caption{Inference time}
\vskip 0.15in
\label{tab:inference-time}
\begin{tabular}{cccc}
\toprule
Methods & CIFAR-10 & CIFAR-100 & ImageNet \\
\midrule
AT & 0.002 s & 0.002 s & 0.005 s \\
DM-based AP & 1.49 s & 1.50 s & 5.11 s \\
Ours & 12.39 s & 11.81 s & 14.10 s \\
% Ours & 11.30/12.39 s & 11.27/11.81 s & 14.10 s \\
\bottomrule
\bottomrule
\end{tabular}
\vskip -0.1in
\end{table}

\Cref{tab:inference-time} shows the inference time of different methods on CIFAR-10, CIFAR-100, and ImageNet, which is measured on a single image. Specifically, AP method purifies CIFAR data at a resolution of $32 \times 32$ and ImageNet data at $256 \times 256$, whereas our method operates at a resolution of $256 \times 256$ across all datasets. As a form of Test-Time Training, our method inevitably increases inference cost. In a comparison at the same resolution of ImageNet, the AP method require 5.11 seconds, whereas our method takes 14.10 seconds. This overhead stems from the inherent limitations of iterative optimization processes and affects their practicality in real-world applications. We leave the study of integrating our TN-based AP technique with more advanced and faster optimization strategies for future research.


\section{Zero-shot adversarial defense}

AT and AP methods depend heavily on external training dataset, overlooking the
potential internal priors in the input itself.
Among adversarial defense techniques, untrained neural networks such
as deep image prior (DIP) \cite{ulyanov2018deep} and masked autoencoder (MAE) \cite{he2022masked} have been
utilized to avoid the need of extra training data \cite{dipdefend2020,dai2022deep,lyu2023maedefense}.
However, although such deep learning models achieve high-quality reconstruction results,
they have been shown to be susceptible to revive also the adversarial noise.
This section compares two representative untrained models DIP and MAE.

\begin{table}[h]
    \caption{Comparison with untrained neural networks against AutoAttack $l_\infty$ threat ($\epsilon=8/255$) on CIFAR-10.}
    \vskip 0.15in
    \label{tab:trainingfree}
    \begin{center}
    \begin{tabular}{ccccc}
    \toprule
    Defense method & Acc. & NRMSE & SSIM & PSNR  \\
    \midrule
    \multicolumn{5}{l}{Clean examples} \\
    \midrule
    DIP & 90.43 & 0.0464 & 0.9565 & 32.13 \\
    MAE & 88.28 & 0.0847 & 0.8842 & 26.90  \\
    Ours & 82.23 & 0.0644 & 0.9203 & 29.06 \\
    \midrule
    \multicolumn{5}{l}{Adversarial examples} \\
    \midrule
    DIP & 38.28 & 0.0451 & 0.9467 & 32.53  \\
    MAE & 1.56 & 0.0914 & 0.8472 & 26.24  \\
    Ours & 55.27 & 0.0748 & 0.8707 & 27.77 \\
    \bottomrule
    \bottomrule
    \end{tabular}
    \end{center}
    \vskip -0.1in
\end{table}

\cref{tab:trainingfree} shows that although DIP and MAE have achieved remarkable
standard accuracy and reconstruction quality, they deteriorate significantly
under attack.

\section{More discussion}
As we all know, the adversarial challenge of attack and defense is endless. This contradiction arises from the fundamental difference between adversarial attacks and defenses. Attacks are inherently destructive, whereas defenses are protective. This adversarial relationship places the attacker in an active position, while the defender remains passive. As a result, attackers can continually explore new attack strategies against a fixed model to degrade its predictive performance, ultimately leading to the failure of conventional defenses.
The introduction of TNP has the potential to address this issue. As a model-free technique, TNP generates tensor representations solely based on the input information. These representations dynamically change with each input, preventing attackers from exploiting a fixed model to generate effective adversarial examples. This defensive mechanism allows TNP to maintain a more proactive stance in the ongoing competition between adversarial attacks and defenses.


\section{Histogram and kernel density estimation results}
\label{app:distribution}
\Cref{fig:app-distribution} shows the histogram and kernel density estimation of adversarial perturbations on 10 images. The distribution of those perturbations progressively aligns with that of Gaussian noise as the downsampling process progresses.
\begin{figure}[ht]
\vskip 0.2in
    \centering
    \includegraphics[width=\linewidth]{figures/fig_appdistribution.pdf}
    \caption{The histogram and kernel density estimation of adversarial perturbations in the downsampled images.}
    \label{fig:app-distribution}
    \vskip -0.1in
\end{figure}


\section{Visualization}
\begin{figure}[ht]
\vskip 0.2in
    \centering
    \includegraphics[width=0.9\linewidth]{figures/fig_appvisual.pdf}
    \caption{Clean examples (Top), adversarial examples (Middle) and reconstructed examples (Bottom) of CIFAR-10.}
    \label{fig:app-visual}
    \vskip -0.1in
\end{figure}




