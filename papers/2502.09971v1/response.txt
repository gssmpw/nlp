\section{Related Work and Unique Contributions}
\label{sec:related_work}
Deep learning-based image compression has achieved remarked progress in recent years. Ballé \textit{et al.} Ballé, "Noise-Conditional Image Generation for Controllable Super-Resolution," ____ pioneered an end-to-end optimizable architecture, later enhancing it with a hyperprior model Ballé et al., "End-to-End Optimized Image Compression," ____ to improve entropy estimation. Transformer architectures have been proposed by Qian \textit{et al.} Qian, “Deep Residual Learning for Image Super-Resolution,” ____ to improve probability distribution estimation. Similarly, Cheng \textit{et al.} Cheng et al., "Learning a blind image denoising algorithm based on hierarchical sparse representation," ____ parameterizes the distributions of latent codes with discretized Gaussian Mixture models. Liu \textit{et al.} Liu, "Deep neural network-based compressive sensing for image reconstruction," ____ combined CNNs and Transformers in the TCM block to explore the local and non-local source correlation. Yang \textit{et al.} Yang et al., “High-quality image compression with tree-structured implicit neural compression,” ____ proposed a Tree-structured Implicit Neural Compression (TINC) to maintain the continuity among regions and remove the local and non-local redundancy. To enhance the entropy coding performance, the conditional probability model and joint autoregressive and hierarchical priors model have been developed in Li et al., "Conditional Probability Model for Image Compression," _____. Jia \textit{et al.} Jia et al., “Generative Latent Coding for High-Resolution Image Compression,” ____ introduced a Generative Latent Coding (GLC) architecture to achieve high-realism and high-fidelity compression by transform coding in the latent space.

This work is related to reference-based deep image compression, where reference information is used to improve coding efficiency. For example, Li \textit{et al.} Li et al., "Deep video compression via a conditional probability model," ____ pioneered this approach in video compression, while Ayzik \textit{et al.} Ayzik et al., “Learning to compress images with deep reinforcement learning,” ____ applied it at the decoder level. Sheng \textit{et al.} Sheng et al., "Deep Video Compression via Temporal Context Mining," ____ proposed a temporal context mining module to propagate features and learn multi-scale temporal contexts. Huang \textit{\textit{et al.}} Huang et al., “Multi-View Image Compression with Advanced Feature Extraction and Fusion,” ____ extended the concept to multi-view image compression with advanced feature extraction and fusion. Li \textit{et al.} Li et al., "Group-Based Offset Diversity for Deep Image Compression," ____ introduced the group-based offset diversity to explore the image context for better prediction. Zhao \textit{et al.} Zhao et al., “Universal Rate-Distortion Optimization for Deep Image Compression,” ____ optimized the reference information using a universal rate-distortion optimization framework. ____ integrated side information optimization with latent optimization to further enhance the compression ratio. In Liu et al., "Multi-Scale Feature Dictionary for Underwater Image Compression," ____ within the context of underwater image compression, a multi-scale feature dictionary was manually created to provide a reference for deep image compression based on feature matching. A content-aware reference frame selection method was developed in Zhang et al., “Deep Video Compression via Content-Aware Reference Frame Selection,” ____ for deep video compression.

\textbf{Unique contributions.} 
In comparison to existing methods, our work has the following unique contributions. (1) We develop a new approach, called conditional latent coding (CLC), which learns to synthesize a dynamic reference for each input image to achieve highly efficient conditional coding in the latent domain. 
(2) We develop a fast and efficient feature matching scheme based on ball tree search and an effective feature alignment strategy that dynamically balances compression bit-rate and reconstruction quality. (3) We developed a theoretical analysis to show that the proposed CLC method is robust to perturbations in the external dictionary samples and the selected conditioning latent, with an error bound that scales logarithmically with the dictionary size, ensuring stability even with large and diverse dictionaries.

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{figure/figure_main.pdf}
    \caption{Overview of the proposed Conditional Latent Coding (CLC) framework.}
 %  \vspace{-0.2cm}
    \label{fig:main0810}
\end{figure}