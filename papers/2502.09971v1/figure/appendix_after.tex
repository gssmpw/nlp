% \def\year{2022}\relax
% %File: formatting-instructions-latex-2022.tex
% %release 2022.1
% \documentclass[letterpaper]{article} % DO NOT CHANGE THIS
% \usepackage[submission]{aaai25}  % DO NOT CHANGE THIS
% % \usepackage{hyperref}       % hyperlinks
% % \usepackage[hidelinks]{hyperref}
% \usepackage{url}            % simple URL typesetting
% \usepackage{booktabs}       % professional-quality tables
% \usepackage{amsfonts}       % blackboard math symbols
% \usepackage{nicefrac}       % compact symbols for 1/2, etc.
% \usepackage{microtype}      % microtypography
% \usepackage{xcolor}         % colors
% \usepackage{multirow}
% % \usepackage{wrapfig}
% \usepackage{rotating}
% % \usepackage{colortbl}
% \usepackage{graphicx}
% \usepackage{subcaption}
% \usepackage{amsmath,amsfonts,amssymb,amsthm}
% \usepackage{enumitem}
% % \usepackage[numbers]{natbib}
% % \usepackage{amsmath}
% \usepackage[linesnumbered, ruled, vlined]{algorithm2e}
% \usepackage{caption}
% \usepackage{colortbl}      % Additional color options for tables
% % \usepackage{authblk}
% \definecolor{lightgray}{gray}{0.9}
% \definecolor{red}{rgb}{1,0,0}

% % Define a command to display the gain in red
% \newcommand{\gain}[1]{\textcolor{red}{(+#1)}}
% % \newtheorem{assumption}{Assumption}
% % \newtheorem{theorem}{Theorem}
% % \newtheorem{lemma}{Lemma}
% \newcommand{\norm}[1]{\left\lVert#1\right\rVert}
% \newcommand{\abs}[1]{\left\lvert#1\right\rvert}
% % \newcommand{\mathbb{E}}{\mathbb{E}}
% % \newcommand{\mathbb{R}}{\mathbb{R}}
% \newcommand{\supp}{\mathrm{supp}}
% \newcommand{\argmin}{\mathop{\mathrm{arg,min}}}
% \newcommand{\Proj}{\mathcal{P}}
% \newtheorem{assumption}{Assumption}
% \newtheorem{lemma}{Lemma}
% \newtheorem{theorem}{Theorem}
% \newtheorem{remark}{Remark}
% \setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.
% \newcommand{\step}[1]{\noindent\textbf{Step #1.} }
% % \usepackage{amsmath}
% % These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
% \usepackage{newfloat}
% \usepackage{listings}
% \lstset{%
% 	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
% 	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
% 	aboveskip=0pt,belowskip=0pt,%
% 	showstringspaces=false,tabsize=2,breaklines=true}
% % \floatstyle{ruled}
% % \newfloat{listing}{tb}{lst}{}
% % \floatname{listing}{Listing}
% %
% %\nocopyright
% %
% % PDF Info Is REQUIRED.
% % For /Title, write your title in Mixed Case.
% % Don't use accents or commands. Retain the parentheses.
% % For /Author, add all authors within the parentheses,
% % separated by commas. No accents, special characters
% % or commands are allowed.
% % Keep the /TemplateVersion tag as is
% \pdfinfo{
% /Title (AAAI Press Formatting Instructions for Authors Using LaTeX -- A Guide)
% /Author (AAAI Press Staff, Pater Patel Schneider, Sunil Issar, J. Scott Penberthy, George Ferguson, Hans Guesgen, Francisco Cruz, Marc Pujol-Gonzalez)
% /TemplateVersion (2022.1)
% }

% % DISALLOWED PACKAGES
% % \usepackage{authblk} -- This package is specifically forbidden
% % \usepackage{balance} -- This package is specifically forbidden
% % \usepackage{color (if used in text)
% % \usepackage{CJK} -- This package is specifically forbidden
% % \usepackage{float} -- This package is specifically forbidden
% % \usepackage{flushend} -- This package is specifically forbidden
% % \usepackage{fontenc} -- This package is specifically forbidden
% % \usepackage{fullpage} -- This package is specifically forbidden
% % \usepackage{geometry} -- This package is specifically forbidden
% % \usepackage{grffile} -- This package is specifically forbidden
% % \usepackage{hyperref} -- This package is specifically forbidden
% % \usepackage{navigator} -- This package is specifically forbidden
% % (or any other package that embeds links such as navigator or hyperref)
% % \indentfirst} -- This package is specifically forbidden
% % \layout} -- This package is specifically forbidden
% % \multicol} -- This package is specifically forbidden
% % \nameref} -- This package is specifically forbidden
% % \usepackage{savetrees} -- This package is specifically forbidden
% % \usepackage{setspace} -- This package is specifically forbidden
% % \usepackage{stfloats} -- This package is specifically forbidden
% % \usepackage{tabu} -- This package is specifically forbidden
% % \usepackage{titlesec} -- This package is specifically forbidden
% % \usepackage{tocbibind} -- This package is specifically forbidden
% % \usepackage{ulem} -- This package is specifically forbidden
% % \usepackage{wrapfig} -- This package is specifically forbidden
% % DISALLOWED COMMANDS
% % \nocopyright -- Your paper will not be published if you use this command
% % \addtolength -- This command may not be used
% % \balance -- This command may not be used
% % \baselinestretch -- Your paper will not be published if you use this command
% % \clearpage -- No page breaks of any kind may be used for the final version of your paper
% % \columnsep -- This command may not be used
% % \newpage -- No page breaks of any kind may be used for the final version of your paper
% % \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% % \pagestyle -- This command may not be used
% % \tiny -- This is not an acceptable font size.
% % \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% % \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

% \setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% % The file aaai22.sty is the style file for AAAI Press
% % proceedings, working notes, and technical reports.
% %

% % Title

% % Your title must be in mixed case, not sentence case.
% % That means all verbs (including short verbs like be, is, using,and go),
% % nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% % articles, conjunctions, and prepositions are lower case unless they
% % directly follow a colon or long dash
% \title{Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression Supplemental Material}
% % \author{
% %     %Authors
% %     % All authors must be in the same font size and format.
% %     Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
% %     AAAI Style Contributions by Pater Patel Schneider,
% %     Sunil Issar,\\
% %     J. Scott Penberthy,
% %     George Ferguson,
% %     Hans Guesgen,
% %     Francisco Cruz\equalcontrib,
% %     Marc Pujol-Gonzalez\equalcontrib
% % }
% % \affiliations{
% %     %Afiliations
% %     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
% %     % If you have multiple authors and multiple affiliations
% %     % use superscripts in text and roman font to identify them.
% %     % For example,

% %     % Sunil Issar, \textsuperscript{\rm 2}
% %     % J. Scott Penberthy, \textsuperscript{\rm 3}
% %     % George Ferguson,\textsuperscript{\rm 4}
% %     % Hans Guesgen, \textsuperscript{\rm 5}.
% %     % Note that the comma should be placed BEFORE the superscript for optimum readability

% %     2275 East Bayshore Road, Suite 160\\
% %     Palo Alto, California 94303\\
% %     % email address must be in roman text type, not monospace or sans serif
% %     publications22@aaai.org
% % %
% % % See more examples next
% % }

% %Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it



% % REMOVE THIS: bibentry
% % This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
% \usepackage{bibentry}
% % END REMOVE bibentry

% \begin{document}

% \maketitle


% \appendix
\section{Theoretical Proof}

\subsection{Problem Formulation}

Let $x \in \mathbb{R}^d$ be the original image, and $\tilde{x} \in \mathbb{R}^d$ be the reference image used for side information. We define encoders $G_1: \mathbb{R}^d \to \mathbb{R}^r$ and $G_2: \mathbb{R}^d \to \mathbb{R}^r$ for the original and reference images respectively, and a decoder $D: \mathbb{R}^r \times \mathbb{R}^r \to \mathbb{R}^d$.

The rate-distortion optimization problem is formulated as:
\begin{equation}\label{eq:RD_optimization}
\min_{G_1, G_2, D} \ \mathbb{E}_{x, \tilde{x}} \left[ R\left( G_1(x), G_2(\tilde{x}) \right) + \lambda \cdot D\left( x, D\left( G_1(x), G_2(\tilde{x}) \right) \right) \right],
\end{equation}
where $R(\cdot, \cdot)$ is the rate (compression) loss, $D(\cdot, \cdot)$ is the distortion loss (e.g., reconstruction error), and $\lambda > 0$ is a weighting parameter balancing rate and distortion.

\subsection{Assumptions}

\begin{assumption}\label{assump:spiked_covariance}
\textbf{Spiked Covariance Model for Images:}

The original image $x$ follows a spiked covariance model:
\begin{equation}\label{eq:spiked_model_original}
x = U^* s + \xi,
\end{equation}
where:
\begin{itemize}
    \item $U^* \in \mathbb{R}^{d \times r}$ is the true low-rank feature matrix with orthonormal columns ($U^{*T} U^* = I_r$).
    \item $s \in \mathbb{R}^r$ is the latent representation, with $\mathbb{E}[s] = 0$ and $\mathbb{E}[s s^T] = \Sigma_s$.
    \item $\xi \in \mathbb{R}^d$ is additive noise, independent of $s$, with zero mean and covariance $\Sigma_{\xi} = \sigma_{\xi}^2 I_d$.
\end{itemize}
\end{assumption}

\begin{assumption}\label{assump:reference_image}
\textbf{Reference Image with Irrelevant Parts:}

The reference image $\tilde{x}$ is given by:
\begin{equation}\label{eq:reference_image_model}
\tilde{x} = U^* (\rho s + \sqrt{1 - \rho^2} s_\perp) + \tilde{\xi},
\end{equation}
where:
\begin{itemize}
    \item $\rho \in [0,1]$ represents the correlation between $x$ and $\tilde{x}$.
    \item $s_\perp \in \mathbb{R}^r$ is independent of $s$, with $\mathbb{E}[s_\perp] = 0$ and $\mathbb{E}[s_\perp s_\perp^T] = \Sigma_s$.
    \item $\tilde{\xi} \in \mathbb{R}^d$ is additive noise, independent of $s$ and $s_\perp$, with zero mean and covariance $\Sigma_{\tilde{\xi}} = \sigma_{\tilde{\xi}}^2 I_d$.
    \item The total irrelevant proportion in $\tilde{x}$ is characterized by $p = 1 - \rho^2$.
\end{itemize}
\end{assumption}

\begin{assumption}\label{assump:entropy_model}
\textbf{Entropy Model for Rate Loss:}

The rate loss is based on a Gaussian entropy model:
\begin{equation}\label{eq:rate_loss}
R(z, \tilde{z}) = \mathbb{E}_{z, \tilde{z}} \left[ - \log_2 p_\theta( z \mid \tilde{z} ) \right],
\end{equation}
where $p_\theta( z \mid \tilde{z} )$ is a conditional Gaussian distribution:
\begin{equation}\label{eq:conditional_gaussian}
p_\theta( z \mid \tilde{z} ) = \mathcal{N}\left( z; \mu( \tilde{z} ), \Sigma_z \right),
\end{equation}
with $\mu( \tilde{z} )$ and $\Sigma_z$ being the mean and covariance conditioned on $\tilde{z}$.
\end{assumption}

\begin{assumption}\label{assump:distortion_loss}
\textbf{Distortion Loss:}

The distortion loss is defined as the mean squared error between the original image and the reconstructed image:
\begin{equation}\label{eq:distortion_loss}
D( x, \hat{x} ) = \| x - \hat{x} \|_2^2,
\end{equation}
where $\hat{x} = D( G_1(x), G_2(\tilde{x}) )$.
\end{assumption}

\begin{assumption}\label{assump:subgaussian_noise}
\textbf{Sub-Gaussian Noise:}

The noise vectors $\xi$ and $\tilde{\xi}$ are sub-Gaussian with parameter $\sigma^2$, i.e., for any $u \in \mathbb{R}^d$ with $\| u \|_2 = 1$,
\begin{equation}
\mathbb{P}\left( | u^T \xi | \geq t \right) \leq 2 \exp\left( - \frac{ t^2 }{ 2 \sigma^2 } \right), \quad \forall t > 0.
\end{equation}
\end{assumption}

\subsection{Main Results}

\begin{lemma}\label{lem:conditional_entropy}
Under Assumptions \ref{assump:spiked_covariance}--\ref{assump:entropy_model}, the rate loss $R(z, \tilde{z})$ can be expressed as:
\begin{equation}\label{eq:rate_loss_expression}
R(z, \tilde{z}) = \frac{1}{2 \ln 2} \left( r \ln (2 \pi e) + \ln \det( \Sigma_z ) \right).
\end{equation}
\end{lemma}

\begin{proof}
Since $p_\theta( z \mid \tilde{z} )$ is a Gaussian distribution, the differential entropy is:
\begin{equation}
h( z \mid \tilde{z} ) = \frac{1}{2} \ln \left( (2 \pi e)^r \det( \Sigma_z ) \right).
\end{equation}
Thus, the rate loss is:
\begin{equation}
R(z, \tilde{z}) = - \mathbb{E}_{z, \tilde{z}} \left[ \log_2 p_\theta( z \mid \tilde{z} ) \right] = \frac{1}{\ln 2} h( z \mid \tilde{z} ),
\end{equation}
which leads to Equation (\ref{eq:rate_loss_expression}).
\end{proof}

\begin{theorem}\label{thm:recovery_error_bound}
Under Assumptions \ref{assump:spiked_covariance}--\ref{assump:subgaussian_noise}, let $\hat{G}_1$ be the estimated encoder for the original image obtained from solving the optimization problem (\ref{eq:RD_optimization}). Then, for any $\delta \in (0,1)$, with probability at least $1 - \delta$, the following holds:
\begin{equation}\label{eq:sin_theta_bound}
\left\| \sin \Theta\left( \operatorname{span}( \hat{G}_1 ), \operatorname{span}( U^* ) \right) \right\|_F \leq C \cdot \frac{ \sqrt{ r ( \sigma_{\xi}^2 + \sigma_{\tilde{\xi}}^2 ) \log( d / \delta ) } }{ (1 - \rho) \lambda_{\min}( \Sigma_s ) \sqrt{ n } },
\end{equation}
where:
\begin{itemize}
    \item $C > 0$ is an absolute constant.
    \item $\rho$ is defined in Assumption \ref{assump:reference_image}, representing the correlation between $x$ and $\tilde{x}$.
    \item $\lambda_{\min}( \Sigma_s )$ is the minimum eigenvalue of $\Sigma_s$.
    \item $n$ is the number of training samples.
\end{itemize}
\end{theorem}

\begin{proof}
\textbf{Step 1: Formulate the Empirical Covariance Matrix}

Let $\{ x_i, \tilde{x}_i \}_{i=1}^n$ be $n$ independent samples drawn according to the model in Assumptions \ref{assump:spiked_covariance} and \ref{assump:reference_image}. Define the empirical covariance matrix:
\begin{equation}\label{eq:empirical_covariance}
S = \frac{1}{n} \sum_{i=1}^n x_i x_i^T = U^* \Sigma_s U^{*T} + \Sigma_{\xi} + \Delta,
\end{equation}
where $\Delta$ represents the sampling error.

\textbf{Step 2: Bound the Sampling Error}

Using the Matrix Bernstein Inequality for sub-Gaussian variables (see Tropp, 2012), we have:
\begin{equation}\label{eq:bernstein_bound}
\left\| \Delta \right\|_2 \leq \sigma_{\xi}^2 \sqrt{ \frac{ 2 \log( d / \delta ) }{ n } } + \sigma_{\xi}^2 \frac{ 2 \log( d / \delta ) }{ 3 n },
\end{equation}
with probability at least $1 - \delta$.

\textbf{Step 3: Analyze the Eigenvalue Gap}

The population covariance matrix is:
\begin{equation}
\Sigma_x = \mathbb{E}[ x x^T ] = U^* \Sigma_s U^{*T} + \Sigma_{\xi}.
\end{equation}
The eigenvalues of $\Sigma_x$ consist of $r$ large eigenvalues corresponding to the signal components and $d - r$ smaller eigenvalues corresponding to the noise.

The eigenvalue gap between the $r$-th and $(r+1)$-th eigenvalue is at least:
\begin{equation}\label{eq:eigenvalue_gap}
\delta_{\text{gap}} = \lambda_{\min}( U^* \Sigma_s U^{*T} ) - \lambda_{\max}( \Sigma_{\xi} ) = \lambda_{\min}( \Sigma_s ) - \sigma_{\xi}^2.
\end{equation}

\textbf{Step 4: Apply Davis-Kahan Sin Theta Theorem}

Let $\hat{U}$ be the matrix of leading $r$ eigenvectors of $S$. By the Davis-Kahan theorem, the subspace distance is bounded as:
\begin{equation}\label{eq:dk_bound}
\left\| \sin \Theta( \operatorname{span}( \hat{U} ), \operatorname{span}( U^* ) ) \right\|_F \leq \frac{ \sqrt{ 2 } \left\| \Delta \right\|_2 }{ \delta_{\text{gap}} }.
\end{equation}

\textbf{Step 5: Incorporate the Reference Image}

The presence of $\tilde{x}$ introduces additional noise due to the irrelevant components. From Assumption \ref{assump:reference_image}, the irrelevant proportion is $p = 1 - \rho^2$. This affects the effective eigenvalue gap, reducing it to:
\begin{equation}\label{eq:effective_gap}
\delta_{\text{eff}} = \lambda_{\min}( \Sigma_s ) (1 - \rho) - \sigma_{\xi}^2 - \sigma_{\tilde{\xi}}^2.
\end{equation}

\textbf{Step 6: Final Bound}

Combining Equations (\ref{eq:bernstein_bound}), (\ref{eq:dk_bound}), and (\ref{eq:effective_gap}), we have:
\begin{equation}\label{eq:final_bound}
\left\| \sin \Theta( \operatorname{span}( \hat{U} ), \operatorname{span}( U^* ) ) \right\|_F \leq \frac{ C \cdot ( \sigma_{\xi}^2 + \sigma_{\tilde{\xi}}^2 ) \sqrt{ \frac{ \log( d / \delta ) }{ n } } }{ \lambda_{\min}( \Sigma_s ) (1 - \rho) - \sigma_{\xi}^2 - \sigma_{\tilde{\xi}}^2 }.
\end{equation}

For sufficiently large $n$ and small noise levels such that $\lambda_{\min}( \Sigma_s ) (1 - \rho ) > \sigma_{\xi}^2 + \sigma_{\tilde{\xi}}^2$, the denominator is positive.

\textbf{Step 7: Simplify and Conclude}

Assuming $\sigma_{\xi}^2 + \sigma_{\tilde{\xi}}^2$ is small compared to $\lambda_{\min}( \Sigma_s ) (1 - \rho )$, we can approximate:
\begin{equation}
\left\| \sin \Theta( \operatorname{span}( \hat{U} ), \operatorname{span}( U^* ) ) \right\|_F \leq C' \cdot \frac{ \sqrt{ r ( \sigma_{\xi}^2 + \sigma_{\tilde{\xi}}^2 ) \log( d / \delta ) } }{ (1 - \rho ) \lambda_{\min}( \Sigma_s ) \sqrt{ n } }.
\end{equation}

This completes the proof.

\end{proof}

\begin{remark}
The factor $\frac{1}{1 - \rho}$ reflects the system's sensitivity to the correlation between the original and reference images. As $\rho \to 1$, indicating highly correlated images, the denominator approaches zero, and the bound grows large, showing that the system becomes more sensitive to irrelevant parts in $\tilde{x}$.
\end{remark}

\begin{remark}
This result shows a trade-off between the sample size $n$, the dimensionality $d$, the signal-to-noise ratio (through $\lambda_{\min}( \Sigma_s )$, $\sigma_{\xi}^2$, $\sigma_{\tilde{\xi}}^2$), and the correlation $\rho$ between $x$ and $\tilde{x}$. Increasing $n$ or the eigenvalue gap improves the bound, while higher noise levels or higher correlation (leading to larger $p = 1 - \rho^2$) degrade the performance.
\end{remark}

\begin{remark}
If we let $\tau = p = 1 - \rho^2$ represent the proportion of irrelevant information, as $\tau \to 1$, the bound grows as $O\left( \frac{1}{1 - \sqrt{1 - \tau}} \right)$, which can be approximated as $O\left( \frac{1}{1 - \rho} \right)$ for small $\tau$. This indicates a nonlinear degradation in feature learning efficiency, and the system maintains stability only when $\tau < \tau_c$ for some critical tolerance rate $\tau_c$.
\end{remark}

\begin{remark}
The above analysis assumes that the noise levels $\sigma_{\xi}^2$ and $\sigma_{\tilde{\xi}}^2$ are small compared to the signal strength $\lambda_{\min}( \Sigma_s )$. In practice, this means that the data should have a sufficiently strong signal component relative to noise for effective learning.
\end{remark}

\begin{remark}
The use of the Matrix Bernstein Inequality allows for tight probabilistic bounds on the sampling error, leveraging the sub-Gaussian nature of the noise. This is crucial for high-dimensional settings where $d$ is large.
\end{remark}

% \subsection{Discussion}

% This theorem provides a bound on how close the learned features (represented by $\text{Pr}(\hat{G}_1)$) are to the true features (represented by $U^*$). The bound depends on several factors:

% 1. The number of training samples $n$: As $n$ increases, the bound decreases at a rate of $O(1/\sqrt{n})$.

% 2. The proportion of irrelevant parts in the reference image $p$: As $p$ increases, the bound increases, but not catastrophically.

% 3. The intrinsic dimension $r$ and the effective rank of the noise $r(\Sigma_\xi)$: These determine the complexity of the learning problem.

% 4. The dimension of the data $d$: The bound has a mild logarithmic dependence on $d$.

% The inclusion of the entropy model in the rate loss allows us to more accurately capture the true compression performance. This result suggests that even when the reference image contains irrelevant parts or errors, the method can still learn features close to the true features, provided that the proportion of irrelevant parts is not too large and there are enough training samples.

\section{Robustness Experiments}

To validate our theoretical analysis and assess the robustness of the proposed CLC method, we conducted experiments simulating perturbations in the conditional latent. Controlled errors were introduced during both training and inference stages to evaluate the method's resilience to imperfect feature matching.

Specifically, we define a perturbation level $\epsilon \in [0, 0.5]$, which represents the probability of random feature matching. For each feature in the conditional latent, the correct match is used with probability $1-\epsilon$, and a random match from the dictionary is used with probability $\epsilon$. This perturbation is applied consistently during both training and inference, allowing the model to adapt to the noise during training while simultaneously testing its robustness during inference.

To quantify the impact of these perturbations, we adopt the Performance Reduction (PR) metric as defined in \cite{huang2023learned}:

\begin{equation}
    \text{PR} = 1 - \frac{\text{performance improvement w/ perturbation}}{\text{performance improvement w/o perturbation}},
\end{equation}

where performance improvement is measured in terms of PSNR and MS-SSIM gains over the baseline model without conditional latent coding.

Figure \ref{fig:robustness} illustrates the PR of CLC under varying levels of perturbation for both PSNR and MS-SSIM metrics. The results indicate that CLC exhibits significant robustness at lower perturbation levels. For instance, at $\epsilon = 0.1$, the PR values are 3.7\% for PSNR and 4.5\% for MS-SSIM, demonstrating a minimal impact on performance. However, as $\epsilon$ increases, the PR values rise more sharply, with PSNR and MS-SSIM reaching 43.5\% and 47.8\%, respectively, at $\epsilon = 0.5$. This trend aligns with our theoretical predictions, where the performance degradation accelerates as perturbations exceed certain thresholds.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figure/robustness_plot.pdf}
    \caption{Performance Reduction (PR) of CLC under varying perturbation levels. Lower PR indicates higher robustness.}
    \label{fig:robustness}
\end{figure}
These results confirm that while CLC can tolerate moderate levels of feature mismatch, higher levels of perturbation lead to a substantial increase in performance reduction, highlighting the importance of accurate feature matching.

\section{Additional Visualization Results}

To provide a more comprehensive understanding of the performance of our proposed method, we present additional visualization results in this section. Figures \ref{fig:visual2} and \ref{fig:visual3} showcase the reconstructed images generated by our method under typical conditions.

In these figures, the regions highlighted within the red and blue boxes represent magnified areas of the images. The red boxes focus on key details such as texture and edge sharpness, while the blue boxes highlight other regions of interest. These zoomed-in areas allow for a closer inspection of the image quality, demonstrating how our method effectively preserves fine details and maintains high visual fidelity across different scenarios.

Overall, these visual results further confirm the effectiveness of our approach in producing high-quality reconstructions with detailed preservation of critical image features.

\begin{figure*}[t]
    \centering
    \begin{minipage}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/visual2.pdf}
        \caption{Visualization of reconstructed images using our method. The red and blue boxes highlight magnified areas for detailed inspection.}
        \label{fig:visual2}
    \end{minipage}
    
    \vspace{10pt} % 调整上下图像之间的间距
    
    \begin{minipage}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/visual3.pdf}
        \caption{Visualization of reconstructed images using our method. The red and blue boxes highlight magnified areas for detailed inspection.}
        \label{fig:visual3}
    \end{minipage}
\end{figure*}

\section{Future Work}
While our current work has demonstrated the effectiveness of conditional latent coding (CLC) in deep image compression, its potential extends to broader vision tasks. The dynamic reference synthesis mechanism could be adapted for pose estimation \cite{shen2024imagpose,shenadvancing,li2024deviation,li2024translating}, where conditional feature alignment might enhance keypoint localization through self-supervised learning paradigms like \cite{chen2024learning}. The multi-scale dictionary construction and adaptive fusion strategies could further benefit ultra-high-resolution image segmentation \cite{sun2024ultrahighresolutionsegmentationboundaryenhanced,sunprogram,yin2024class} and remote sensing image enhancement \cite{ma2024logcanadaptivelocalglobalclassaware,10095835,tao2023dudb}, particularly when combined with token-based representation learning \cite{chen2024tokenunify}.

For medical imaging applications, our framework could integrate with 3D vision-language pretraining \cite{chen2023generative,liu2023t3d} and cross-dimension distillation \cite{liu2024cross} to handle multimodal data synthesis. The topological constraints in \cite{RAMMVC,scMFC} may synergize with our latent space modeling to improve structural coherence in electron microscopy segmentation \cite{chen2024learning} and CT text-image retrieval \cite{chen2024bimcv}. The error-bound analysis (Theorem 1) could also enhance medical image compression through knowledge distillation \cite{yang2024unicompress} while maintaining diagnostic fidelity.

In autonomous driving systems \cite{Zhang2023EHSSAE,zhang2024mapexpertonlinehdmap}, our method's robustness could be strengthened by unsupervised domain adaptation techniques \cite{deng2024unsupervised} to handle sensor noise. For multi-view estimation \cite{Yuan2024h,Yuan2024i,Yuan2024j}, the dictionary-based conditioning might unify cross-view correlations through reinforcement learning frameworks \cite{chen2023self}. However, as generative components may introduce noise \cite{qian2024maskfactory}, future work should explore quality evaluation metrics for synthesized latents and develop noise-robust training strategies like selective feature pruning \cite{chen2024tokenunify} or adversarial validation \cite{deng2024unsupervised}, ensuring reliability in downstream tasks while maintaining computational efficiency \cite{yang2024unicompress}.

\section{Pseudo-code for Encoding and Decoding}
To clearly illustrate the implementation of our proposed Conditional Latent Coding (CLC) method, we provide detailed pseudo-code. The pseudo-code covers the main steps for both encoding and decoding, including feature extraction, reference retrieval, conditional latent synthesis, and finally entropy coding and image reconstruction. The details of the encoding pseudo-code can be found in Algorithm \ref{clc_algorithm}, and the decoding pseudo-code is provided in Algorithm \ref{decodeclc}.


\begin{algorithm}[h]
\caption{Conditional Latent Coding (CLC)}
\label{clc_algorithm}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{Image $x$, Feature dictionary $D$}
\Output{Compressed bitstream}

\BlankLine
\textbf{Function ConstructDictionary($R$):} \\
\For{each image $x_i$ in reference dataset $R$}{
    $v_i \gets \text{spp}(f_\theta(x_i))$ \\
    $\hat{v}_i \gets \text{PCA}(v_i)$
}
\texttt{Clusters:} $\{C_1, C_2, ..., C_K\} \gets \text{MiniBatchKMeans}(\{\hat{v}_i\})$ \\
Dictionary: $D \gets \{d_j = \text{argmin}_{\hat{v} \in C_j} \|\hat{v} - \mu_j\|_2\}_{j=1}^K$ \\
\Return $D$

\BlankLine
\textbf{Function ConditionalLatentCoding($x, D$):} \\
$y \gets g_a(x)$ \\
$X_r^M \gets \text{QueryDictionary}(D, f_\theta(x))$ \\
$Y_r^M \gets g_a(X_r^M)$

\BlankLine
\textbf{Conditional Latent Matching (CLM):} \\
$S_{ij} \gets \frac{\exp(\langle\phi(y_i), \phi(y_{r,j})\rangle/\tau)}{\sum_k \exp(\langle\phi(y_i), \phi(y_{r,k})\rangle/\tau)}$ \\
$y_m \gets F_m(y, Y_r^M; \theta_m)$ \\
$y_a \gets F_a(y, y_m; \theta_a)$

\BlankLine
\textbf{Conditional Latent Synthesis (CLS):} \\
$\alpha \gets \sigma(F_w([y, y_a]; \theta_f))$ \\
$\mu(y, y_a) \gets \alpha \odot y + (1 - \alpha) \odot y_a$ \\
$y_f \sim \mathcal{N}(\mu(y, y_a), \sigma^2(y, y_a))$

\BlankLine
\textbf{Entropy Coding:} \\
$z \gets h_a(y_f)$ \\
$\hat{z} \gets Q(z)$ \\
\For{$i \gets 1$ \KwTo $K$}{
    $p(y_f^i | y_f^{<i}, \hat{z}) \sim \mathcal{N}(\mu_i, \sigma_i^2)$ \\
    $r_i \gets y_f^i - \hat{y}_f^i$
}

\Return EncodedBitstream
\end{algorithm}

\begin{algorithm}[h]
\caption{Decoding with Conditional Latent Coding (CLC)}
\label{decodeclc}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{Encoded bitstream $b$}
\Input{Feature reference dictionary $D = \{d_1, d_2, \dots, d_K\}$}
\Output{Reconstructed image $\hat{x}$}

\BlankLine
\textbf{Step 1: Extract and Decode Hyperprior} \\
Decode hyperprior $z$ from $b$: $z \gets \text{Decode}(b)$ \\
Use $z$ to estimate the initial latent representation $\hat{y}_f$: $\hat{y}_f \gets h_a^{-1}(z)$

\BlankLine
\textbf{Step 2: Retrieve Reference Features} \\
Extract features from $\hat{y}_f$ to query the dictionary $D$ \\
Retrieve top $M$ matching features $Y_r^M = \{\hat{y}_r^1, \hat{y}_r^2, \dots, \hat{y}_r^M\}$

\BlankLine
\textbf{Step 3: Conditional Latent Synthesis} \\
\For{$m \gets 1$ \KwTo $M$}{
    Perform feature matching and alignment: \\
    $\hat{y}_a^m \gets \text{Align}(\hat{y}_f, \hat{y}_r^m)$
}
Fuse aligned features to obtain final latent $\hat{y}$: \\
$\hat{y} \gets \sum_{m=1}^M \alpha_m \cdot \hat{y}_a^m$ \\
where $\alpha_m$ are dynamically computed fusion weights

\BlankLine
\textbf{Step 4: Entropy Decoding and Reconstruction} \\
Entropy decode each slice of $\hat{y}$ using $z$: \\
\For{$i \gets 1$ \KwTo $K$}{
    Decode slice $\hat{y}_i$ from $b$ using context: \\
    $\hat{y}_i \gets \text{EntropyDecode}(b, \hat{y}_{<i}, z)$
}

\BlankLine
\textbf{Step 5: Image Reconstruction} \\
Reconstruct the final image $\hat{x}$ from $\hat{y}$ using synthesis transform $g_s$: \\
$\hat{x} \gets g_s(\hat{y})$

\Return $\hat{x}$
\end{algorithm}

\section{Social Impact}

The proposed Conditional Latent Coding (CLC) framework presents significant implications for the field of deep image compression, particularly in terms of its potential for broader societal applications. By leveraging a fixed, pre-constructed feature dictionary, the CLC method enables end-to-end efficient compression without the need for complex or resource-intensive processing during runtime. This approach not only improves compression efficiency but also reduces the computational load, making it highly suitable for deployment in resource-constrained environments such as mobile devices, IoT systems, and edge computing. The ability to achieve high-quality compression with minimal overhead could lead to more widespread adoption of advanced image compression techniques, improving the accessibility and efficiency of digital communications and storage across diverse sectors.




% \bibliographystyle{plain}
% \bibliography{aaai25}
% \end{document}
