
\section{Introduction}

Conformal prediction (CP) \cite{gammerman1998learning, Vovk_Gammerman_Shafer05, Shafer_Vovk08} has emerged as a simple framework to quantify the prediction uncertainty of machine learning algorithms without relying on distributional assumptions on the data. For a sequence of observed data, and a new input point,
$$D_n = \{(x_1, y_1), ..., (x_n, y_n)\} \text{ and } x_{n+1},$$
the objective is to construct a set that contains the unobserved response $y_{n+1}$ with a specified confidence level $100(1- \alpha)\%$. This involves evaluating scores $S(x, y, \hat y)\in\mathbb{R}$ such as the prediction error of a model $\hat y$, for each observation $(x, y)$ in $D_n$ and ranking these score values. The conformal prediction set for the new input $x_{n+1}$ is the collection of all possible responses $y$ whose score $S(x_{n+1}, y, \hat y)$ ranks small enough to meet the prescribed confidence threshold, compared to the scores $S(x_i, y_i, \hat y)$ in the observed data. 

CP has undergone tremendous developments in recent years ~\citep{barber2023conformal,park2024semiparametric,tibshirani2019conformal, guha2024conformal} which mirror its increased applicability to challenging settings \citep{straitouri2023improving,lu2022fair}. To name a few, it has been applied for designing uncertainty sets in active learning \citep{Ho_Wechsler08}, anomaly detection \citep{Laxhammar_Falkman15, Bates_Candes_Lei_Romano_Sesia21}, few-shot learning \citep{Fisch_Schuster_Jaakkola_Barzilay21}, time series \citep{Chernozhukov_Wuthrich_Zhu18, Xu_Xie20, chernozhukov2021exact, Lin_Trivedi_Sun22, zaffran2022adaptive}, or to infer performance guarantees for statistical learning algorithms \citep{Holland20, Cella_Martin20}; and recently to Large Language Models \cite{kumar2023conformal, quach2023conformal}. We refer to the extensive reviews in \citep{balasubramanian2014conformal} for other applications in machine learning.  \looseness=-1

By design, CP requires the notion of order, as the inclusion of a candidate response depends on its relative ranking to the scores observed previously. Hence, the classical strategies developed so far largely target score functions with univariate outputs. This limits their applicability to multivariate responses, as ranking multivariate scores $S(x, y, \hat y) \in \mathbb{R}^d, d\geq 2$ is not as straightforward as ranking univariate scores in $\mathbb{R}$. 

\textbf{Ordering Vector Distributions using Optimal Transport.} In parallel to these developments, and starting with the seminal reference of \citep{chernozhukov2017} and more generally the pioneering work of \citep{hallin2021,hallin2022center,hallin2023efficient}, multiple references have explored the possibilities offered by the optimal transport theory to define a meaningful ranking or ordering in a multidimensional space. Simply put, the analog of a rank function computed on the data can be found in the optimal \citeauthor{Bre91} map that transports the data measure to a uniform, symmetric, centered measure of reference in $\mathbb{R}^d$. As a result, a simple notion of a univariate rank for a vector $z\in\mathbb{R}^d$ can be found by evaluating the distance of the image of $z$ (according to that optimal map) to the origin. This approach ensures that the ordering respects both the geometry, i.e., the spatial arrangement of the data and its distribution: points closer to the center get lower ranks.\looseness=-1

\paragraph{Contributions}
We propose to leverage recent advances in computational optimal transport~\citep{PeyCut19}, using notably differentiable transport map estimators~\citep{pooladian2021entropic,cuturi2019differentiable}, and apply such map estimators in the definition of multivariate score functions. More precisely:
\begin{itemize}[leftmargin=.2cm,itemsep=.0cm,topsep=0cm,parsep=2pt]
\item \OTCP: We extend conformal prediction techniques to multivariate score functions by leveraging optimal transport ordering, which offers a principled way to define and compute a higher-dimensional quantile and cumulative distribution function. As a result, we obtain distribution-free uncertainty sets that capture the joint behavior of multivariate predictions that enhance the flexibility and scope of conformal predictions.
\item We propose a computational approach to this theoretical ansatz using the entropic map~\citep{pooladian2021entropic} computed from solutions to the \citeauthor{Sinkhorn64} problem~\citep{cuturi2013sinkhorn}. We prove that our approach preserves the coverage guarantee while being tractable.
\item We show the application of \OTCP\ using a recently released benchmark of regression tasks~\citep{dheur2025multioutputconformalregressionunified}.
\end{itemize}
We acknowledge the concurrent proposal of \citet{thurin2025optimaltransportbasedconformalprediction}, who adopt a similar approach to ours, with, however, a few important practical differences, discussed in more detail in Section~\ref{sec:concurrent}.
