@inproceedings{prairie1,
  title={Integrating diverse learning tools using the {PrairieLearn} platform},
  author={West, Matthew and Walters, Nathan and Silva, Mariana and Bretl, Timothy and Zilles, Craig},
  booktitle={SPLICE Workshop at SIGCSE},
  year={2021}
}




@article{a1,
  title={Large language models for education: {A} survey and outlook},
  author={Wang, Shen and Xu, Tianlong and Li, Hang and Zhang, Chaoli and Liang, Joleen and Tang, Jiliang and Yu, Philip S and Wen, Qingsong},
  journal={arXiv preprint arXiv:2403.18105},
  year={2024}
}

@article{a2,
  title={Large Language Models for Education: {A} Survey},
  author={Xu, Hanyi and Gan, Wensheng and Qi, Zhenlian and Wu, Jiayang and Yu, Philip S},
  journal={arXiv preprint arXiv:2405.13001},
  year={2024}
}

@inproceedings{a3,
  title={Insights from social shaping theory: {T}he appropriation of large language models in an undergraduate programming course},
  author={Padiyath, Aadarsh and Hou, Xinying and Pang, Amy and Viramontes Vargas, Diego and Gu, Xingjian and Nelson-Fromm, Tamara and Wu, Zihan and Guzdial, Mark and Ericson, Barbara},
  booktitle={ACM Conference on International Computing Education Research},
  year={2024}
}


@incollection{a4,
  title={{CS1-LLM}: Integrating {LLMs into CS1} instruction},
  author={Vadaparty, Annapurna and Zingaro, Daniel and Smith IV, David H and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo},
  booktitle={Innovation and Technology in Computer Science Education},
  year={2024}
}


@article{a5,
  title={Evaluating Students' Open-ended Written Responses with {LLMs}: Using the {RAG} Framework for {GPT-3.5, GPT-4, Claude-3, and Mistral-Large}},
  author={Jauhiainen, Jussi S and Guerra, Agust{\'\i}n Garagorry},
  journal={arXiv preprint arXiv:2405.05444},
  year={2024}
}


@inproceedings{a6,
  title={Detecting {LLM}-generated text in computing education: {C}omparative study for {ChatGPT} cases},
  author={Orenstrakh, Michael Sheinman and Karnalim, Oscar and Suarez, Carlos Anibal and Liut, Michael},
  booktitle={IEEE Annual Computers, Software, and Applications Conference},
  year={2024}
}
@article{a7,
  title={Survey on plagiarism detection in large language models: {T}he impact of {ChatGPT and Gemini} on academic integrity},
  author={Pudasaini, Shushanta and Miralles-Pechu{\'a}n, Luis and Lillis, David and Salvador, Marisa Llorens},
  journal={arXiv preprint arXiv:2407.13105},
  year={2024}
}

@article{a8,
  title={Testing of detection tools for {AI}-generated text},
  author={Weber-Wulff, Debora and Anohina-Naumeca, Alla and Bjelobaba, Sonja and Folt{\`y}nek, Tom{\'a}{\v{s}} and Guerrero-Dib, Jean and Popoola, Olumide and {\v{S}}igut, Petr and Waddington, Lorna},
  journal={International Journal for Educational Integrity},
  year={2023}
}


@article{a9,
  title={Can Large Language Models Automatically Score Proficiency of Written Essays?},
  author={Mansour, Watheq and Albatarni, Salam and Eltanbouly, Sohaila and Elsayed, Tamer},
  journal={arXiv preprint arXiv:2403.06149},
  year={2024}
}


@article{b1,
  title={Solving math word problems by combining language models with symbolic solvers},
  author={He-Yueya, Joy and Poesia, Gabriel and Wang, Rose E and Goodman, Noah D},
  journal={arXiv preprint arXiv:2304.09102},
  year={2023}
}


@article{b2,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}


@inproceedings{b3,
  title={Evaluating the effectiveness of {LLMs} in introductory computer science education: {A} semester-long field study},
  author={Lyu, Wenhan and Wang, Yimeng and Chung, Tingting and Sun, Yifan and Zhang, Yixuan},
  booktitle={ACM Conference on Learning at Scale},
  year={2024}
}


@article{b4,
  title={THE IMPACT OF LARGE LANGUAGE MODEL-ASSISTED LEARNING VERSUS TRADITIONAL LEARNING METHODS ON UNIVERSITY STUDENTS LEARNING OUTCOMES AND KNOWLEDGE RETENTION},
  author={Milo{\v{s}}evi{\'c}, Sini{\v{s}}a and Arapovi{\'c}, Adisa Omerbegovi{\'c} and Duerod, Malcolm}
}


@article{b5,
  title={Examining the Influence of Varied Levels of Domain Knowledge Base Inclusion in {GPT}-based Intelligent Tutors},
  author={Castleman, Blake and Turkcan, Mehmet Kerem},
  journal={arXiv preprint arXiv:2309.12367},
  year={2023}
}

@article{b6,
  title={Waiting, banning, and embracing: {An} empirical analysis of adapting policies for generative AI in higher education},
  author={Xiao, Ping and Chen, Yuanyuan and Bao, Weining},
  journal={arXiv preprint arXiv:2305.18617},
  year={2023}
}


@article{b7,
author = {Perkins, Mike and Furze, Leon and Roe, Jasper and MacVaugh, Jason},
year = {2024},
title = {The Artificial Intelligence Assessment Scale {(AIAS): A} Framework for Ethical Integration of Generative {AI} in Educational Assessment},
journal = {Journal of University Teaching and Learning Practice}
}



@article{b8,
  title={Assessing Large Language Models in Mechanical Engineering Education: {A} Study on Mechanics-Focused Conceptual Understanding},
  author={Tian, Jie and Hou, Jixin and Wu, Zihao and Shu, Peng and Liu, Zhengliang and Xiang, Yujie and Gu, Beikang and Filla, Nicholas and Li, Yiwei and Liu, Ning and others},
  journal={arXiv preprint arXiv:2401.12983},
  year={2024}
}

@article{b9,
  title={{LLM} circuit analyses are consistent across training and scale},
  author={Tigges, Curt and Hanna, Michael and Yu, Qinan and Biderman, Stella},
  journal={arXiv preprint arXiv:2407.10827},
  year={2024}
}


@article{c1,
  title={Capabilities of large language models in control engineering: A benchmark study on {GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra}},
  author={Kevian, Darioush and Syed, Usman and Guo, Xingang and Havens, Aaron and Dullerud, Geir and Seiler, Peter and Qin, Lianhui and Hu, Bin},
  journal={arXiv preprint arXiv:2404.03647},
  year={2024}
}

@mastersthesis{c2,
  title={Large Language Models for Programming Industrial Control Systems and Mitigating Real-World Software Vulnerabilities},
  author={Dharmaji, Rahul},
  year={2024},
  school={University of California, Irvine}
}



@article{c3,
  title={Understanding the Impact of Applying Large Language Model in Engineering Design Education},
  author={Zhang, Chonghui and Zhao, Yaoyao Fiona and El Haddad, Randous},
  journal={Journal of Computing and Information Science in Engineering},
  year={2025},
  publisher={American Society of Mechanical Engineers Digital Collection}
}


@inproceedings{c4,
  title={Evaluating the effectiveness of {LLMs} in introductory computer science education: {A} semester-long field study},
  author={Lyu, Wenhan and Wang, Yimeng and Chung, Tingting and Sun, Yifan and Zhang, Yixuan},
  booktitle={ACM Conference on Learning@ Scale},
  pages={63--74},
  year={2024}
}


@article{c5,
  title={An Exploratory Study on Upper-Level Computing Students' Use of Large Language Models as Tools in a Semester-Long Project},
  author={Tanay, Ben Arie and Arinze, Lexy and Joshi, Siddhant S and Davis, Kirsten A and Davis, James C},
  journal={arXiv preprint arXiv:2403.18679},
  year={2024}
}