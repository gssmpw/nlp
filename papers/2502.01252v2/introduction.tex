\section{Introduction}
% \hp{refer to the group resources Google doc for how to write an abstract. Introduction is an extended version of the abstract.  Write in a way as if you are telling a story. I suggest to first have the outline/flow as bulletins, and then start writing.}


% 具体itemize 安排
%	第一、二段：零和Game的广泛存在，有很多求解算法（2-3句）；介绍symmetric game的各种研究，体现出研究广泛（3句）；但现实生活中，asymmetric game是非常多的，特别是在组合优化问题上，然后举例子。
%	第三段：说明一些asymmetric且finite的论文及其例子（2句）：但是仍然局限在finite这一设定下。目前的很多问题，其strategy set仍是infinite compact的状态 under the setting of asymmetric players，然后举一些例子。
%	引出问题：’Can reinforcement learning solve asymmetric combinatorial-continuous zero-sum games?’


% Zero-sum game is a paradigm within game theory aimed at depicting relationships among players in an adversarial state, where the increase in one player's rewards inevitably leads to a decrease in the other's \citep{lipton1994simple}. It is prevalent in various domains of life and industry, exemplified by scenarios such as board games \citep{ghory2004reinforcement}, poker \citep{zinkevich2007regret}, and price games \citep{kakkar2022blockchain}. Despite the existence assurance of Nash Equilibrium (NE) in large-scale matrix games, the challenge of solving or approximating NE persists. From fictitious play (FP) \citep{brown1951iterative}, and double oracle (DO) \citep{mcmahan2003planning} to PSRO \citep{lanctot2017unified}, numerous algorithms have progressively endeavored to find NE while providing a theoretical analysis of algorithmic convergence and degree of approximation \citep{jafari2001no, waugh2015unified, balandat2016minimizing, dinh2022online, tang2023regret}. 

Zero-sum games depict a game theoretic paradigm among adversarial players, where the increase in one player's rewards inevitably leads to a decrease in the other's \citep{lipton1994simple}. It is prevalent in various real-world domains such as board games \citep{ghory2004reinforcement}, poker \citep{zinkevich2007regret}, and price games \citep{kakkar2022blockchain}. Since solving NE plays a vital role in the game theory, from fictitious play \citep{brown1951iterative}, and double oracle (DO) \citep{mcmahan2003planning} to Policy-Space Response Oracles \citep{lanctot2017unified}, numerous algorithms have endeavored to find NE while providing a theoretical analysis of algorithmic convergence and approximation \citep{jafari2001no, waugh2015unified, balandat2016minimizing, dinh2022online, tang2023regret}. 

% Under the zero-sum setting, symmetry or asymmetry is one important classification \citep{amir2008symmetric, cox2013provision, stella2018bio}. A \textit{symmetric} game describes the specific interaction where players can be interchanged \citep{cheng2004notes}. First, all the players have the same strategy set. Besides, their payoff matrix needs to be symmetric too, equivalent to the same role played in the game. If one of these two conditions is violated, the game is \textit{asymmetric}. Because of the symmetric property in the payoff matrix, symmetric games have been a perennial topic for researchers, not only in the theoretical game field \citep{} but in practical applications \citep{}. However, in many scenarios, the strategy spaces of the players are often asymmetric like Leduc Poker \citep{tuyls2018generalised}, network security games \citep{wilder2018equilibrium}, and cash-in-transit VRP \citep{ghannadpour2020new}.

One way to classify zero-sum games is based on the symmetry of the players' strategy spaces \citep{amir2008symmetric, cox2013provision, stella2018bio}. A \textit{symmetric} game describes a scenario where players can be interchanged \citep{cheng2004notes}, meaning that all the players have the same strategy set and payoff matrices. Otherwise, the game is \textit{asymmetric}. Symmetric games have been well-studied in terms of both theories \citep{tuyls2018symmetric, hefti2017equilibria} and applications \citep{bichler2021learning, altman2011symmetric}, partly due to their simple and structural properties. However, in many scenarios such as Leduc Poker \citep{tuyls2018generalised}, network security games \citep{wilder2018equilibrium}, and cash-in-transit VRP \citep{ghannadpour2020new}, the strategy spaces of the players are asymmetric.


Despite the extensive literature on asymmetric games, most current studies remain confined to relatively traditional backgrounds such as the Battle of the Sexes game \citep{tuyls2018symmetric} and Leduc Poker \citep{tuyls2018generalised}. As a kind of strategy space that is ubiquitous in real-world applications, much less exploration has been made toward asymmetric games with combinatorial strategy spaces, except for some sporadic studies like min-max traveling distance of multi-VRP \citep{narasimha2013ant}, security scheduling with attacker \citep{jain2011double}, max-min influence maximization \citep{chen2016robust}, etc. Typically, these studies assume finite action spaces for all players in asymmetric game settings. These studies neglect another broad class of asymmetric games where the other player's strategy space is not only asymmetric but also infinite compact (e.g., real-valued vector intervals). Such infinite compact strategy spaces in asymmetric games have broad implications in the real world, which can be interpreted as the physical or environmental parameters of COPs, such as the attractive degrees to targets in the security game \citep{xu2021robust}, uncertain network edge weights in influence maximization problems \citep{kalimeris2019robust} and  
 unknown outer condition effect on the charging demand in facility location problems \citep{an2020battery, TIRKOLAEE2020340}, and customer demand in routing problems \citep{FLORIO20231081}.

Formally, we define this class of games as a two-player Asymmetric Combinatorial-Continuous zEro-Sum (ACCES) game with dynamics of simultaneous move and static form. Player 1’s strategy space is combinatorial, while Player 2’s is infinite and compact with a continuous utility function. As an illustrative example (more examples in Section \ref{sec_exp}), we consider a patrolling game between a defender (Player 1) and an attacker (Player 2). To prevent attacks from the attacker, the defender chooses a feasible route to patrol a subset $\Pi$ of all targets $\{1, 2, …, N\}$ meanwhile satisfying the total distance constraint $L_{all}$ because of limited patrol time. For the attacker, the strategy is the attack probability vector $\{p_1, p_2, …, p_N\}$ for the target set. Besides, each target $i \in \{1, 2, …, N\}$ has its own value $v_i$. The utility function for the defender is the expectation of successfully protected target values, i.e. $ U_d = \sum_{i=1}^N p_i v_i \mathbb{I}_{\Pi}$. The attacker’s utility function is then: $U_a = - U_d$.

% Formally, we define this class of games as a two-player Asymmetric Combinatorial-Continuous zEro-Sum (ACCES) game, where one player's strategy space is combinatorial, while the other player's is infinite and compact with a continuous utility function. As an illustrative example (more examples in Section \ref{sec_exp}), we consider a patrolling game between a defender and an attacker. Given a set of targets $\{1,\ldots,N\}$, the defender aims to prevent attacks from the attacker by patrolling a set of targets $\Pi$ within the total distance constraint because of limited patrol time. So the strategy set of the defender consists of all feasible routes satisfying the distance constraints. For the attacker, the strategy is the attack probability $p_i$ on each target which is within the interval $[0, 1]$. Each target $i\in\{1,..., N\}$ has its own value $v_i$, so that the utility function for the defender is the expectation of successfully protected target values, i.e. \textcolor{blue}{$U_d = \sum_{i=1}^{N} p_i v_i \mathbb{I}_{\Pi}$}. The \textcolor{blue}{attacker's utility function is then: $U_a = -U_d$}.
%这里讲一下RL4CO的发展和表现亮眼，有效求解各种问题。


For this new class of games, our key research question is:

\textit{``Whether and how can we solve asymmetric combinatorial-continuous zero-sum games?"}
%\hp{If we introduce RL4CO earlier above, then we  can change it back to Can RL solve ... }
%\hp{changed the question so that we do not need to involve RL early.}
% To answer this question, it poses a couple of challenges. First ..., Second, ... \hp{Please use this format to describe the challenges.} 

% To answer this question, it poses a couple of challenges, both in theory (the first and second) and practical implementation (the third). 
This question can be decomposed into the following sub-questions: 

\textbf{1) Does NE exist?} Before finding solutions to ACCES games, the first question is whether such games are guaranteed to have NE. Due to the asymmetry of the game, especially the different, less-structured properties of the strategy sets (combinatorial-continuous), this question is much less straightforward than established results in matrix games \citep{nash1950non}, market games \citep{peck1992market}, and continuous games \citep{glicksberg1952further, fan1952fixed, reny2005non}, for which the existence of NE has already been proven.
% -- one finite and another infinite, the continuity of the utility function needs to be analyzed again from the definition, which is true obviously in matrix games \citep{nash1950non}, market games \citep{peck1992market}, and continuous games \citep{glicksberg1952further, fan1952fixed, reny2005non}. Besides, only if the existence is guaranteed, it is necessary to continue to develop the corresponding equilibrium-solving algorithm. 

% \hp{Needs to be more specific: why asymmetry leads to new challenges? Is it straightforward to extend from symmetric games or other asymmetric games to ACCES games?}

% \hp{Use a bolded phrase to summarize each challenge -- e.g., \textbf{Equilibrium existence.} \textbf{Degree of convergence to equilibrium.} etc.}

\textbf{2) Is there any algorithm that can converge to NE?} If the existence of NE holds, the next question is then to find an algorithm that can converge to the NE. 
%algorithms should be redesigned and prove the degree of convergence to equilibrium. 
Due to the infinite strategy set of one player, common equilibrium-seeking algorithms \citep{mcmahan2003planning, dinh2022online} in matrix games lose their convergence guarantees because they rely on the finiteness of strategy sets to terminate iterations. On the other hand, classic algorithms in continuous games \citep{balandat2016minimizing, Adam2021DOcontin} do not work for ACCES games because the continuity of the unity function no longer holds with the discrete (combinatorial) strategy set of the other player.

\textbf{3) Is there a practical algorithm that we can actually implement in the real world?} While it is critical to understand the theoretical questions above, an equally important practical question is -- how can we design efficient and practical algorithms to actually solve the ACCES games? This is extremely challenging as even a sub-problem of finding the best response for the combinatorial strategy space of one player is known to be NP-hard, let alone the entire ACCES game. %Can reinforcement learning discover the equilibrium while playing the role of best response for the combinatorial player? 
%For COPs that are discrete and non-convex, solving for the optimal value independently, even though other players' strategies are fixed, poses a significant computational challenge, let alone dealing with the extensive computation of best responses within the game. 
%This challenge is particularly acute for NP-hard problems \citep{papadimitriou1998combinatorial}, such as the Traveling Salesman Problem (TSP), Capacitated Vehicle Routing Problem (CVRP), and Integer Knapsack Problem (IM), where finding exact solutions in polynomial time is infeasible unless $P=NP$. 

% \hp{This should be part of the description of our solution.}
% With the rapid development of Reinforcement Learning (RL), utilizing RL to solve CO problems has emerged as a more efficient and generalizable approach \citep{bello2016neural, kool2018attention, kool2022deep} compared to approximation and heuristic algorithms. Incorporating RL algorithms as the best response for combinatorial players to accelerate equilibrium computation is both reasonable and effective.


We give a YES answer to each of the three sub-questions. Our main contributions are as follows. 

1) We are the first to summarize and define the class of ACCES games, elucidating its rationale and practical significance via examples from min-max games and security games. 

2) We prove the existence of mixed NE in ACCES games through the finite-game approximation, which relies on two important properties that have yet to be established, the weakly sequential compactness and continuity of expected utility function. To address this gap, we prove these properties in Section 4, which provides further insight into developing solution algorithms for ACCES games. 

% 2) We prove two important properties of ACCES games, the weakly sequential compactness and continuity of expected utility function, which lay the foundation for the proof of the existence of NE, which further sheds insights into the development of solution algorithms to the ACCES games. 

3) We propose two solution algorithms, CCDO and CCDO-RL, for solving the ACCES games. CCDO extends the idea of double oracle (DO)-based solutions from zero-sum finite games \citep{mcmahan2003planning} to ACCES games, while with different convergence guarantee results. Due to the NP-hardness in most COPs, it is infeasible to find the exact best response for the combinatorial player in a limited time. Therefore it's critical to consider the solution algorithm and convergence analysis with approximate best responses (ABRs). We bridge this gap by proposing CCDO-RL which adopts RL as an efficient sub-routine to compute the ABRs, inspired by recent advancements in applying reinforcement learning to learn fast, effective, and generalizable solutions for COPs \citep{khalil2017learning,nazari2018reinforcement,deudon2018learning,bengio2020machine,Chen2021rl4im,berto2023rl4co}. Furthermore, novel convergence analysis of CCDO-RL is studied, along with different ABRs' influence on convergence have been discussed in Section 5. 

% 3) We propose two solution algorithms, CCDO and CCDO-RL, for solving the ACCES games, {\color{red}and provide novel convergence analysis on them.} CCDO extends the idea of double oracle (DO)-based solutions to zero-sum {\color{red}matrix} games \cite{mcmahan2003planning} to ACCES games. Due to the NP-hardness in most CO problems, it is infeasible to find the exact best response for the combinatorial player in a limited time. Inspired by recent advancements in applying reinforcement learning \cite{sutton2018reinforcement} to learn fast, effective, and generalizable solutions for COPs ~\citep{khalil2017learning,nazari2018reinforcement,deudon2018learning,bengio2020machine,kool2018attention,berto2023rl4co}, CCDO is further extended to incorporate an approximate best response solver for both players based on RL (especially the combinatorial player), which we call CCDO-RL. The convergence analyses for both algorithms are provided.

4) We validate our algorithms on three distinct instances of ACCES games -- adversarial covering salesman problem (ACSP), adversarial capacitated vehicle routing problem (ACVRP), and patrolling game (PG). Empirical results are well aligned with our theoretical insights: our proposed CCDO-RL algorithm can learn to converge to NE in all game instances. For the player with the combinatorial strategy space, our algorithm is better than baselines regardless of the type of adversary or problem size, especially in terms of generalizability.

% 4) We validate our algorithms on three distinct ACCES game instances -- covering salesman problem (CSP), capacitated vehicle routing problem (CVRP), and orienteering problem (OP). Empirical results are well aligned with our theoretical insights: our proposed CCDO-RL algorithm is able to learn to converge to NE in all the game instances. As a by-product, CCDO-RL yields a robust policy for the combinatorial player against adversarial perturbations from the continuous player, a result that might be of its own interest to the robust RL \cite{morimoto2001robust,Levy2020large,zhang2024regularized} community.


% demonstrate the algorithm's effectiveness in solving each problem while ensuring fast convergence within the entire game framework. Moreover, we illustrate that our learned algorithm maintains good performance across unseen graphs, thereby expanding its applicability in real-world scenarios.



 

% 1) To tackle the above issues, in the theory aspect, we initially establish a formal model for ACCES games, elucidating its rationale and practical significance through illustrations drawn from min-max games and security games. Subsequently, we analyze two important properties of ACCES games, the weakly sequential compactness and continuity of expected utility function, running through the proof of NE's existence and convergence, and then establish the existence of equilibrium in this game, forming the foundation for the development of pertinent algorithms. 



% \hp{What are the technical novelties in our proofs? Need to highlight them here.} 

% 2) Following this, to find the equilibrium, we propose the combinatorial-continuous double oracle (CCDO) algorithms under the best response assumption. Due to the NP-hardness in most CO problems, it's infeasible to find the exact best response for the combinatorial player in a limited time. So we further design the combinatorial-continuous double oracle approximate algorithm (CCDOA) corresponding to the approximate best response of the combinatorial player which is more appropriate to our game setting and algorithm implementation. We prove the convergence of these two algorithms and analyze the computational complexity, primarily focusing on the approximate version due to its computational efficiency.

% DO is originally proposed to solve NE in the large zero-sum matrix games \citep{mcmahan2003planning}. The key idea is to iteratively compute the mixed NE in the subgame and expand the subgame by the best response (BR) to the current NE of the subgame.
% Reinforcement learning \cite{sutton2018reinforcement} has been broadly demonstrated as a promising tool for COPs due to its ability to learn fast and generalizable solutions to even unseen COP instances while maintaining close-to-optimal solution quality~\citep{khalil2017learning,nazari2018reinforcement,deudon2018learning,bengio2020machine,kool2018attention,berto2023rl4co}. 


%\hp{This should be integrated to point 2.} \yh{I think the convergence and sample complexity should be categorized into the theoretical contribution}

% 3) From the application perspective, with the aim of expediting computation time for the combinatorial player while maintaining the generalization required by studies in the CO field, RL algorithms for CO are integrated into this asymmetric zero-sum game framework, serving as the approximate best response for the CO player. %To validate the efficacy of the proposed algorithm, we apply it to three COPs under various game settings. 
% Experimental results demonstrate the algorithm's effectiveness in solving each problem while ensuring fast convergence within the entire game framework. Moreover, we illustrate that our learned algorithm maintains good performance across unseen graphs, thereby expanding its applicability in real-world scenarios.
% \begin{itemize}
%     \item Facing this realistic and non-trivial problem, we design the asymmetric combinatorial-continuous zero-sum game (Not just focusing on uncertain CO, but also CO with adversaries).
%     \item Abstract the game setting and prove the existence and convergence of equilibrium in our setting.
%     \item Analyse the computational complexity based on PSRO framework.
%     \item  Improve the PSRO with RL4CO algorithms, which can have an effective performance in two-player zero-sum games, concerned about uncertain CO, security games, etc.
% \end{itemize}
% Note: Not just focused on the series of uncertain CO problems, but also more broader background where two players intercept each other to degrade their score, such as a security game on CO where one is an attacker and another is a defender.
