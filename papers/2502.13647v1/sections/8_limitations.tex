\section{Limitations}
We aim to establish a robust instruction-tuning dataset for Kazakh, authentically reflecting the cultural and linguistic richness of the language. Unlike many existing datasets, which rely on translated resources or machine-generated responses, our dataset is entirely crafted from Kazakh-specific content, ensuring greater alignment with the cultural values and linguistic nuances of the region. However, we recognize several limitations in our work:
\begin{compactitem}
\item \textbf{Cultural Representation:} The dataset emphasizes topics deeply rooted in Kazakh culture, traditions, and societal norms, ensuring relevance and cultural authenticity. However, certain culturally sensitive topics, such as those involving religious matters, were intentionally omitted to avoid controversy and maintain neutrality.
\item  \textbf{Language Variations:} Kazakh is a rich language with significant regional variations in vocabulary and usage. While our dataset primarily focuses on standard Kazakh, it does not explicitly account for regional dialects or variations, potentially limiting its applicability to speakers outside the standard dialect's scope.
\item \textbf{Modeling Limitations:} Our works is a proof of concept, and it was not aimed at creation of SOTA models for Kazakh. That is why we experiment with smaller models and do not apply any training tricks such as tokenizer adaptaion for Kazakh.
\item \textbf{Possible Data Drift:} We also acknowledge that despite of being very conservative by nature, some institutional procedures can change over time, that is why it is possible that the data provided in our IFT dataset will get less actual. To handle this issue we are planning updating the datasets annually.
    % \item \textbf{Evaluation Generalizability: }
    % A limitation of our current evaluation framework is its focus on fluency, correctness, and ambiguity, which primarily assess the quality of the generated outputs without addressing their factual alignment. This limitation is particularly significant for fact-heavy datasets, such as governmental data, where ensuring factual consistency is crucial. To address this limitation in future work, we plan to introduce a fact recall metric inspired by the methodology described in \cite{schlichtkrull-2024-generating}. This approach involves comparing the generated outputs against a "ground truth" derived from fact extraction and reverse instruction processes applied to real-world texts. 
    
    % \item \textbf{Cultural Representation:} The dataset emphasizes topics deeply rooted in Kazakh culture, traditions, and societal norms, ensuring relevance and cultural authenticity. However, certain culturally sensitive topics, such as those involving political or religious matters, were intentionally omitted to avoid controversy and maintain neutrality.
    % \item \textbf{Language Variations:} Kazakh is a rich language with significant regional variations in vocabulary and usage. While our dataset primarily focuses on standard Kazakh, it does not explicitly account for regional dialects or variations, potentially limiting its applicability to speakers outside the standard dialect's scope.
    % \item \textbf{Safety Concerns:} Despite the dataset’s comprehensive coverage, the fine-tuned models may exhibit some degree of hallucination or inaccuracies due to the dataset's relatively small size and lack of further alignment processes, such as Reinforcement Learning from Human Feedback (RLHF). These limitations may impact the models’ ability to produce reliable outputs in all scenarios.
    % \item \textbf{Tokenizer Adaptation:} The study utilized the default tokenizer provided with the pre-trained large language models, such as LLaMA and Qwen, without making modifications or reconstructing it for Kazakh. While customizing the tokenizer could potentially enhance the model's performance by better capturing the nuances of the Kazakh language, this step was considered beyond the scope of the project. The focus remained on the instruction-tuning process and dataset creation, leaving tokenizer optimization for future work.
\end{compactitem}

\section{Ethics}
We adhered to the internal policies of web resources while scraping data and included only publicly available information verified by authorities.

While our method enhances LLMs' understanding of Kazakhstan's institutional nuances, users should not blindly trust generated responses. LLM outputs serve as a starting point, and users remain responsible for fact-checking due to potential hallucinations.

All human subjects in our study provided informed consent, were fully aware of the study's objectives, and had the right to withdraw at any time. They were also appropriately compensated as part of their job.

% \todo[inline]{Add something about ethics. E.g., possibility to abuse this work, how annotators were paid, etc. Example commented out below.}


% \paragraph{Intended Use and Misuse Potential}

% The main drive behind the creation of our dataset 
% was to advance research on automated narrative classification and the
% detection of deceptive content across
% multiple languages and domains. However, given that possible risk
% of exploiting the dataset to boost the production of 
% biased manipulative disinformation attempts, we advise responsible use.

% \paragraph{Environmental Impact}
% The deployment of LLMs might have a large carbon footprint, especially when training new models. In the context of the reported experiments, we did not train any new LLMs, but only used existing trained models in an in-context zero-shot scenarios, which is relatively cheap in terms of computing.

% \paragraph{Fairness}

% The majority of the annotators, primarily researchers with 
% linguistic background and prior annotation experience, come 
% from the institutions of the co-authors of this manuscript.
% They were fairly remunerated as part of their job. 

% The remaining part of the annotator pool consisted of (a) 
% some students from the respective academic organizations, 
% (b) few external experienced analysts paid at rates set by 
% their contracting institutions, and (c) experts from a 
% contracted a professional annotation company, who were compensated 
% according to rates based on their country of residence.
