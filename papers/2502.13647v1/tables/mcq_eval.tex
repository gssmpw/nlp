% \begin{table*}[ht!]
% \centering
% \renewcommand{\arraystretch}{1} % Adjust row height
% \scalebox{0.7}{
% \begin{tabular}{lcccccccc}
% \toprule
% \textbf{Model name} & \multicolumn{4}{c}{\textbf{Dastur}} & \multicolumn{4}{c}{\textbf{Constitution}} \\  
% \cmidrule(lr){2-5} \cmidrule(lr){6-9}
% & \textbf{No Fine-Tuning} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours} 
% & \textbf{No Fine-Tuning} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours}  \\
% \midrule
% Gemma 2 - 9b & 0.498 & 0.5133 & 0.543 & \textbf{0.566 $\uparrow$}\\
% Qwen 2.5 - 7b - 9B & 0.403 & 0.421 & 0.443 &\textbf{0.465 $\uparrow$}\\
% Falcon 3 - 10b & 0.45 & 0.458 & 0.464 & \textbf{0.4718 $\uparrow$}
% % & \textbf{0.47 $\uparrow$} & \textbf{0.69 $\downarrow$} & \textbf{3.23 $\uparrow$} 
% % & \textbf{0.53 $\uparrow$} & \textbf{0.62 $\downarrow$}  \\ 
% % Qwen 2.5 - 7B\\
% \\
% \midrule
% \end{tabular}}
% \caption{Comparison of Fine-tuning Conditions Across Models}
% \label{tab:finetuning-comparison}
% \end{table*}


% \begin{table*}[ht!]
% \centering
% \renewcommand{\arraystretch}{1.9} % Adjust row height
% \scalebox{0.6}{
% \begin{tabular}{lcccccccccccc}
% \toprule
% \textbf{Model name} & \multicolumn{4}{c}{\textbf{Dastur}} & \multicolumn{4}{c}{\textbf{Constitution}} & \multicolumn{4}{c}{\textbf{Human Rights}} \\  
% \cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
% & \textbf{No Fine-Tuning} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours} 
% & \textbf{No Fine-Tuning} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours}  
% & \textbf{No Fine-Tuning} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours}  \\
% \midrule
% Gemma 2 - 9b & 0.498 & 0.513 & 0.543 & \textbf{0.566 $\uparrow$} 
%              & 0.600 & 0.627 & 0.640 & \textbf{0.650 $\uparrow$} 
%              & 0.405 & 0.430 & 0.465 & \textbf{0.480 $\uparrow$} \\

% Qwen 2.5 - 7b - 9B & 0.403 & 0.421 & 0.443 &\textbf{0.465 $\uparrow$} 
%                    & 0.520 & 0.609 & 0.670 & \textbf{0.680 $\uparrow$} 
%                    & 0.300 & 0.330 & 0.365 & \textbf{0.375$\uparrow$} \\

% Falcon 3 - 10b & 0.450 & 0.458 & 0.464 & \textbf{0.4718 $\uparrow$}  
%                & 0.430 & 0.450 & 0.490 & \textbf{0.520 $\uparrow$}  
%                & 0.215 & 0.234 & 0.250 & \textbf{0.275 $\uparrow$} \\

% \midrule
% \end{tabular}}
% \caption{Comparison of Fine-tuning Conditions Across Models for Dastur, Constitution, and Rights}
% \label{tab:finetuning-comparison}
% \end{table*}
% \begin{table*}[ht!]
% \centering
% \renewcommand{\arraystretch}{1.9} % Adjust row height
% \scalebox{0.5}{
% \begin{tabular}{lcccccccccccccccc}
% \toprule
% \textbf{Model name} & \multicolumn{5}{c}{\textbf{Dastur}} & \multicolumn{5}{c}{\textbf{Constitution}} & \multicolumn{5}{c}{\textbf{Human Rights}} \\  
% \cmidrule(lr){2-6} \cmidrule(lr){7-11} \cmidrule(lr){12-16}
% & \textbf{No Fine-Tuning} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours} & \textbf{RAG}  
% & \textbf{No Fine-Tuning} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours} & \textbf{RAG}  
% & \textbf{No Fine-Tuning} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours} & \textbf{RAG}  \\
% \midrule
% Gemma 2 - 9b & 0.498 & 0.513 & 0.543 & \textbf{0.566 } & \textit{0.533}
%              & 0.600 & 0.627 & 0.640 & \textbf{0.650 } &\textit{0.655} 
%              & 0.405 & 0.430 & 0.465 & \textbf{0.480 } & \textit{0.450}  \\
%
% Qwen 2.5 - 7b - 9B & 0.403 & 0.421 & 0.443 &\textbf{0.465 } & \textit{0.410}  
%                    & 0.520 & 0.609 & 0.670 & \textbf{0.680 $\uparrow$} & \textit{0.523}  
%                    & 0.300 & 0.330 & 0.365 & \textbf{0.375} & \textit{0.325} \\
%
% Falcon 3 - 10b & 0.450 & 0.458 & 0.464 & \textbf{0.4718 }  &  \textit{0.460} 
%                & 0.430 & 0.450 & 0.490 & \textbf{0.520 $\uparrow$}  & \textit{0.3864}  
%                & 0.215 & 0.234 & 0.250 & \textbf{0.275 }  & \textit{0.220} \\
%
% \midrule
% \end{tabular}}
% \caption{Comparison of Fine-tuning Conditions Across Models for Dastur, Constitution, and Rights}
% \label{tab:finetuning-comparison}
% \end{table*}

\begin{table}[t!]
\centering
\renewcommand{\arraystretch}{1.2} % Adjust row height for compactness
\resizebox{\columnwidth}{!}{ % Automatically scales the table to fit within column width
\begin{tabular}{lccccc}
\toprule
\textbf{Model} & \textbf{Vanilla} & \textbf{RAG} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours}  \\  
\midrule
\multicolumn{6}{l}{\cellcolor{blue!7}\textbf{Dastur}} \\
Gemma & 0.498 & {0.533} & 0.513 & 0.543 & \textbf{0.566}  \\

Qwen & 0.403 & {0.410} & 0.421 & 0.443 &\textbf{0.465 }  \\

Falcon & 0.450 & {0.460} & 0.458 & 0.464 & \textbf{0.471 }   \\
\midrule
\multicolumn{6}{l}{\cellcolor{blue!7}\textbf{Constitution}} \\
Gemma & 0.600 & {\textbf{0.655}} & 0.627 & 0.640 & {0.650 }  \\

Qwen & 0.520 & {0.523} & 0.609 & 0.670 & \textbf{0.680 }  \\

Falcon & 0.430 & {0.386} & 0.450 & 0.490 & \textbf{0.520 }  \\
\midrule
\multicolumn{6}{l}{\cellcolor{blue!7}\textbf{Human Rights and Society}} \\
Gemma & 0.405 & 0.450 & 0.430 & 0.465 & \textbf{0.480 }  \\

Qwen & 0.300 & 0.325 & 0.330 & 0.365 & \textbf{0.375}  \\

Falcon & 0.215 & 0.220 & 0.234 & 0.250 & \textbf{0.275 }  \\
\bottomrule
\end{tabular}}
\caption{Zero-shot accuracies of language models in different datasets: (1) Datasur, (2) Constitution, and (3) Human Rights and Society}
\label{tab:result_mcq}
\end{table}


% \begin{table}[t!]
% \centering
% \renewcommand{\arraystretch}{1.2} % Adjust row height for compactness
% \resizebox{\columnwidth}{!}{ % Automatically scales the table to fit within column width
% \begin{tabular}{lccccc}
% \toprule
% \textbf{Model} & \textbf{Vanilla} & \textbf{RAG} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours}  \\  
% \midrule
% Gemma & 0.600 & {0.655} & 0.627 & 0.640 & \textbf{0.650 }  \\

% Qwen & 0.520 & {0.523} & 0.609 & 0.670 & \textbf{0.680 }  \\

% Falcon & 0.430 & {0.386} & 0.450 & 0.490 & \textbf{0.520 }  \\

% \midrule
% \end{tabular}}
% \caption{Comparison of fine-tuning conditions across models for Constitution.}
% \label{tab:finetuning-constitution}
% \end{table}


% \begin{table}[t!]
% \centering
% \renewcommand{\arraystretch}{1.2} % Adjust row height for compactness
% \resizebox{\columnwidth}{!}{ % Automatically scales the table to fit within column width
% \begin{tabular}{lccccc}
% \toprule
% \textbf{Model} & \textbf{No Fine-Tuning} & \textbf{RAG} & \textbf{Alpaca} & \textbf{Ours} & \textbf{Alpaca + Ours}  \\  
% \midrule
% Gemma & 0.405 & 0.450 & 0.430 & 0.465 & \textbf{0.480 }  \\

% Qwen & 0.300 & 0.325 & 0.330 & 0.365 & \textbf{0.375}  \\

% Falcon & 0.215 & 0.220 & 0.234 & 0.250 & \textbf{0.275 }  \\

% \midrule
% \end{tabular}}
% \caption{Comparison of fine-tuning conditions across models for Human Rights and the Society.}
% \label{tab:finetuning-humanrights}
% \end{table}
