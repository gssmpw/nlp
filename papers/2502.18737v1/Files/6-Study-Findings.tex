\begin{figure*}[t]
  \centering
  \includegraphics[width=1.025\linewidth]{Figures/likert_plot.pdf}
  \caption{(Left) Participants’ responses when rating the 6-point Likert statements for IntentTagger and Chat-based Interface, \rev{ranked from largest to smallest effects}; (Right) Dots show the mean difference of IntentTagger compared to Chat-based Interface; Bars are the 95\% CIs calculated with the studentized bootstrap method. }
  
  \Description{The figure shows participants’ responses to 6-point Likert scale statements comparing the IntentTagger and Chat-based Interface systems across various dimensions. The left side of the chart displays bar graphs representing the percentage of agreement (from “Strongly Disagree” to “Strongly Agree”) for each statement, with IntentTagger responses in light brown and Chat-based Interface responses in teal. Statements include aspects such as the ability to provide more information, control over the slide generation process, receiving valuable suggestions, task efficiency, and output alignment with expectations. The right side shows the mean difference between the two interfaces, indicated by black dots, with bars representing 95\% confidence intervals using the studentized bootstrap method. The chart highlights significant contrasts in user perceptions of both systems.}
  \label{fig:survey-results}
\end{figure*}




\section{Study Findings}


Participants went through the tasks without abandoning them. 

\subsection{Key differences: Chat vs Intent Tag-based Interactions (RQ1)}

\subsubsection{Observations}

In the two comparative tasks (phase \rev{2}), participants had to create a presentation about Nikola Tesla or Marie Curie on six slides using engaging images and language suitable for teenagers, based on a provided Word document containing information from a Wikipedia article.
Here, we report on the observed key differences between participants' processes during these tasks when working with the chat-based system and IntentTagger. 
\\ \\ 
\textbf{Chat-based System.} In the chat-based system, participants typically began by providing a straightforward task prompt, such as \textit{“Create a new presentation from /Tesla.docx about Nikola Tesla for teenagers on six slides.”} However, the system consistently generated a 20-slide PowerPoint presentation based on all content from the document in a generic way, including generic and vaguely related stock images. When participants tried to refine their prompts, such as specifying the desired number of slides or requesting specific content to be highlighted, the system frequently ignored these requests and generated a new slide deck similar to the previous one. 
As a consequence, participants found themselves repeating their instructions or trying different phrasings to guide the system, often without noticeable changes. The system frequently returned messages like, \textit{“I don't recognize that wording as something I can do,”} offering alternative actions that were not relevant to the task. Consequently, participants spend most of their time trying out different text prompts to get the system to generate a more targeted, shorter presentation; however, in all cases, without success. Occasionally, participants went on to tweak the layout and visual style of single slides using the Designer feature by selecting a layout from a design gallery list. While they managed to adjust the style of single slides in isolation, they could not achieve a consistent look and feel for the entire deck this way.



\textbf{IntentTagger}
With IntentTagger, participants typically began by providing the Word document as a reference tag and then continued by providing further concept tags for key elements like the number of slides, audience, and the focus areas of the content.
In addition, many participants used the reference tag's text selection widget to specify specific sections of the provided Word document to ensure that only relevant information was included in the presentation. After specifying tags matching the task brief, most participants also made use of the image suggestion feature from which they added some images to the content source tag group. Then, after generating slides, they either continued to make refinements on single slides and then updated the deck's style based on the adjusted slide, or they continued refining the entire deck by adding or modifying intent tags on the deck steering canvas. Participants also frequently used the system’s tag suggestions to refine the presentation's content and visual style.

From a usability perspective, some participants struggled initially with understanding how to effectively use the intent tags, particularly in determining how granular or broad their tags should be or to which tag group certain tags would belong. However, they soon became more confident and many participants commented on the ability to better convey their intent with intent tags and tag groups: \textit{"it definitely feels like I get something close to what I had in mind [...] Looks like something efficient, I will be happy to use it in my work."} (P09)








\subsubsection{Questionnaire}

In the comparative post-task surveys, participants rated all nine 6-point statements higher for Intent Tagger (Figure \ref{fig:survey-results}). 
\rev{Participants expressed a \textbf{significant improvement in intent elicitation and alignment with IntentTagger} over the chat-based system regarding the 
\textbf{iterative process} (\textit{“After I see the generated slides, I can provide more information to refine the generation toward my intended outcome”}, $MD = 2.83$), 
\textbf{control over guiding the system} (\textit{“I feel that I have control over guiding the slide generation process toward my intended outcome”}, $MD = 2.67$), 
\textbf{intent communication} (\textit{“It is easy to communicate my intentions to the generative system”}, $MD = 1.83$),  
\textbf{meta intent elicitation} (\textit{“The system helps me to become more aware about my own intentions and expectations during the task and to express these to the AI system”}, $MD = 1.58$) and  \textbf{alignment with their expectations} ($M = 0.92$).
Participants also valued the \textbf{guidance for slide creation} of IntentTagger higher (\textit{“The system provides valuable tips and suggestions that helped me to improve the presentation”}, $MD = 2.58$) 
and felt they were able to \textbf{conduct the task more successfully} ($MD = 2.33$) and \textbf{efficiently} ($MD = 2.33$) than with the chat-based system. 
They also felt that IntentTagger would be \textbf{better than the technique they usually use} ($MD = 2.0$).}





\begin{table*}[t]
\caption{Overview of semi-structured task results (phase 3); reporting the self-chosen topic of the slide deck and task process summary statistics; *Note: During P04’s session, the image suggestions failed to load due to an API outage.}
\begin{tabularx}{\textwidth}{p{0.5cm}p{3cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}
\hline
\rotatebox{55}{\textbf{ID}}
& \rotatebox{55}{\begin{tabular}[c]{@{}l@{}}\textbf{Slide Deck} \\ \textbf{Topic}\end{tabular}}
& \rotatebox{55}{\begin{tabular}[c]{@{}l@{}}\textbf{Task Time}\\(mm:ss)\end{tabular}}
& \rotatebox{55}{\begin{tabular}[c]{@{}l@{}}\textbf{\# Outlines} \\ \textbf{Generated}\end{tabular}}
& \rotatebox{55}{\begin{tabular}[c]{@{}l@{}}\textbf{\# Decks} \\ \textbf{Generated}\end{tabular}} 
& \rotatebox{55}{\textbf{\# Total Tags }} 
& \rotatebox{55}{\begin{tabular}[c]{@{}l@{}}\textbf{\# \rev{ConceptTag}} \\ \textbf{Sugg Included}\end{tabular}} 
& \rotatebox{55}{\begin{tabular}[c]{@{}l@{}}\textbf{\# ImgTag} \\ \textbf{Sugg Included}\end{tabular}} 
& \rotatebox{55}{\begin{tabular}[c]{@{}l@{}}\textbf{\% Sugg} \\ \textbf{Included}\end{tabular}} 
& \rotatebox{55}{\begin{tabular}[c]{@{}l@{}}\textbf{\# Drop-Dwn} \\ \textbf{Included}\end{tabular}} \\
\hline
P01         & Hiking                                                                 & 11:19                                                                    & 3                                                                      & 4                                                                   & 14                                                            & 3                                                                    & 4                                                                      & 50\%                                                                          & 3                                                                        \\
P02         & Yoga                                                                   & 06:32                                                                    & 3                                                                      & 3                                                                   & 21                                                            & 12                                                                   & 5                                                                      & 81\%                                                                          & 2                                                                        \\
P03         & Kayaking                                                               & 07:01                                                                    & 3                                                                      & 2                                                                   & 25                                                            & 13                                                                   & 5                                                                      & 72\%                                                                          & 1                                                                        \\
P04*        & Homemade Pizza                                                         & 08:55                                                                    & 2                                                                      & 3                                                                   & 20                                                            & 17                                                                   & 0*                                                                      & 85\%                                                                          & 4                                                                        \\
P05         & Growing dahlias                                                        & 08:12                                                                    & 2                                                                      & 5                                                                   & 16                                                            & 6                                                                    & 5                                                                      & 69\%                                                                          & 1                                                                        \\
P06         & Racing road bikes                                          & 08:20                                                                    & 2                                                                      & 1                                                                   & 14                                                            & 4                                                                    & 3                                                                      & 50\%                                                                          & 2                                                                        \\
P07         & Skateboarding                                                          & 07:53                                                                    & 1                                                                      & 3                                                                   & 12                                                            & 8                                                                    & 3                                                                      & 92\%                                                                          & 2                                                                        \\
P08         & Dungeons and dragons                                                   & 06:42                                                                    & 2                                                                      & 1                                                                   & 21                                                            & 9                                                                    & 6                                                                      & 71\%                                                                          & 0                                                                        \\
P09         & Practicing Taekwondo                                                   & 11:43                                                                    & 5                                                                      & 3                                                                   & 11                                                            & 5                                                                    & 3                                                                      & 73\%                                                                          & 2                                                                        \\
P10         & Tennis                                                                 & 09:01                                                                    & 3                                                                      & 4                                                                   & 16                                                            & 8                                                                    & 3                                                                      & 69\%                                                                          & 0                                                                        \\
P11         & Why trombone is cool                                                   & 09:07                                                                    & 3                                                                      & 2                                                                   & 16                                                            & 8                                                                    & 4                                                                      & 75\%                                                                          & 0                                                                        \\
P12         & Paddle boarding                                                        & 09:07                                                                    & 2                                                                      & 2                                                                   & 24                                                            & 17                                                                   & 6                                                                      & 96\%                                                                          & 2                                                                        \\
\hline
\textit{Mean}        &                                                                        & \textit{08:39}                                                                    & \textit{2.6}                                                                    & \textit{2.8 }                                                                & \textit{17.5}                                                          & \textit{9.2}                                                                  & \textit{3.9 }                                                                   & \textit{73.5\%}                                                                        & \textit{1.6}  \\
\bottomrule
\end{tabularx}
\Description{The table presents task statistics for 12 participants (P01 to P12) who created slide decks on self-chosen topics. Columns include Task Time (duration in minutes and seconds), \# Outlines Generated, # Decks Generated, \# Total Tags, \# Tag Suggestions Included, \# Image Suggestions Included, \% Suggestions Included, and \# Drop-Downs Included. Topics range from “Hiking” to “Paddle Boarding.” Mean values are provided at the bottom. Notable rows include P04, where image suggestions failed to load due to an API outage. Participants varied in their use of system-generated suggestions, with a mean of 73.5\% suggestions included and an average task time of 08:39.}\label{tab:task4-results}
\end{table*}



\begin{figure*}[t]
  \centering
  \includegraphics[width=1.15\linewidth]{Figures/task4_event_plot.pdf}
  \caption{Timeline plots visualizing participants' interaction events of the semi-structured task (phase 3); 
  upper lanes show events related to outline and slide generation; 
  center lanes show interactions with concept tags; lower lanes show interactions with image reference tags;
  \rev{tag modifications via the \textit{Opposite Slider Widget} are omitted since only a few participants occasionally explored slider options but without applying these to the slide generation (see section \ref{Interactions_With_System_Suggested_Tags})  }
  *Note: During P04’s session, the image suggestions failed due to an API outage. }
  \Description{The figure shows timeline plots visualizing participants’ interaction events during the semi-structured task (Phase 3). Each row represents a participant (P01 to P12), with interactions plotted over time (in minutes) on the x-axis. The Upper Lane captures interactions related to slide generation and outlines, including events like Grounding from Text Prompt, (Re)generate Outline, and Apply Variation to Slide, marked by distinct shapes and colors. The Center Lane records interactions with concept tags, such as Requesting Tag Suggestions, Creating New Tag, and Overriding Tag. The Lower Lane shows interactions with image reference tags, such as Requesting Image Suggestions and Including Image Suggestion. P04 is marked with an asterisk indicating that image suggestions failed to load due to an API outage.}
  \label{fig:timelines}
\end{figure*}


\subsection{Observed Content Creation Workflows Using Intent Tags (RQ2)}

During the semi-structured task \textit{(study phase 3)} participants created a presentation from scratch about a personal hobby by using IntentTagger within 7 – 12 minutes (see Table \ref{tab:task4-results}).
Most participants started by using the \textit{Grounding from text prompt} feature to formulate an initial longer text prompt, which the system decomposed into an initial set of intent tags from where the participants continued to work on the Deck Steering Canvas (see Figure \ref{fig:timelines} upper lanes). 
Only two participants (P03 and P10) decided to start by adding concept tags manually.
On average, at the end of their sessions, users had 17.5 active intent tags (concept and image tags combined) and had generated 2.6 outlines and 2.8 slide decks. Of those tags, on average, 9.5 were tags users took from the system's suggested concept tags, and 3.9 were image tags (ranging between 50–96\% of active tags that users chose to include from system suggestions). 
Optionally, we included screenshots in the Appendix to give an impression of the variety of participant-created slide decks and tag steering boards.

\subsubsection{\textbf{Workflows}}
\rev{All participants generated an outline before generating a slide deck (see Figure \ref{fig:timelines} upper lanes). 
While this order was partially driven by IntentTagger’s requirement for an outline to enable slide deck generation, many participants also expressed in the post-task interviews that this order felt intuitive to them (see section \ref{supporting-diverse-presentation-needs}).} 
Almost all users first specified several intent tags for the narrative before generating a first outline after 2-4 minutes. 
However, two users (P05 and P08) generated a first outline before making substantial tag edits and then refined these using tags. 
Most participants did exclusively steer the outline and slide deck generation using intent tags, while three users (P04, P07, P08) made manual edits to the outline at a point.
In addition, most users worked exclusively in the Deck Steering Canvas, but three users (P09, P11, P12) also used the Slide Steering Overlay to adjust single slides and then updated the deck's style from that slide. 
Overall, a common pattern was adding or editing intent tags in the Narrative tag group and then optionally generating a first outline and slide deck. From there, most people continued adjusting the visual style through tags, and lastly, they added image tags to the content sources group. 


\subsubsection{\textbf{Prompting With Intent Tags}}

Participants demonstrated a variety of approaches when prompting with intent tags, particularly when dealing with ambiguous or open-ended tags like color or style. For example, one participant specified the header color as \textit{“Gold”} and the color scheme as \textit{“Dark and Moody”} (P11), while another participant used hexadecimal notation \textit{(”\#FF33CC”)} for body color (P05). 


\textbf{Users' Initial Uncertainty Around Tag Naming}

Despite the flexibility, some participants experienced uncertainty about how to “correctly” name certain tags, particularly when it came to specifying the number of slides. The task required a seven-slide presentation, and users created tags like \textit{“Number of Slides: 7,” “Slide number: 7 slides,” and “length: 7 slides in total.”} During the think-aloud sessions, participants expressed hesitation about whether they were using the right terminology. However, after seeing the generated slide deck, they gained confidence in the system’s ability to interpret a variety of tag expressions effectively.

\textbf{Users' Initial Uncertainty Around Tag Placing}

Interestingly, while most participants placed the tag for the number of slides within the narrative tag group, there was some variation in how users organized their tags. For instance, one participant placed the slide number tag under visual style (P08), while another placed it in the content sources group (P10). Regardless of where the tag was placed, the system consistently produced a seven-slide presentation. This adaptability underscored the system’s capacity to handle user input flexibly, ensuring that the end result matched the users’ intent even when the tags were categorized differently.

\textbf{Flexible Handling of Longer Prompts}

One participant created an exceptionally long and detailed prompt when using the initial grounding through text prompt, which led to the generation of tags containing chains of comma-separated phrases. While these tags were visually less ideal and cluttered the workspace, the system still managed to process them effectively (P08).

\textbf{User-Driven Tag Hierarchy and Organizational Strategies}


In addition to varying naming conventions, some participants developed a sense of structure and hierarchy by visually organizing the tags within the tag groups. Although the generative system currently does not inherently recognize such tag hierarchies, it was interesting to observe how participants imposed their own sense of order. 
Another strategy for creating hierarchy through tags was observed when P01 explicitly labeled tags to represent an ordered flow, such as \textit{“Topic 1: hiking”} and \textit{“Topic 2: hiking shoes.”} 


Overall, the variety of tag naming and placement strategies showed that while some users were initially unsure about the “right” way to prompt the system, they quickly became more comfortable with the process and how to utilize the tag's granularity and various levels of ambiguity.


\subsubsection{\textbf{Interactions With System Suggested Tags}} \label{Interactions_With_System_Suggested_Tags}

Participants actively engaged with system-suggested tags early in their content creation process, with all users requesting tag suggestions within the first three minutes. This was typically followed by an intense phase of tag selection and editing that lasted 1 – 3 minutes (see clusters of red vertical strokes ||| in Figure \ref{fig:timelines}). 
For example, in a presentation about road cycling, the system suggested visual style tags like \textit{“fonts: sporty and dynamic”} and \textit{“backgrounds: scenic roadways,”} which the participant included (P06). Similarly, in a kayaking presentation, the system suggested \textit{“Font: Casual and Readable”} and \textit{“Icons: Outdoor activity symbols,”} demonstrating the system’s ability to offer contextually relevant suggestions that aligned with participants’ content themes (P03).

\textbf{Users leveraged suggestions to guide and refine the narrative structure.}
For narrative content, the system’s suggestions also played a pivotal role in helping participants develop the flow and focus of their presentations. For instance, during a presentation on the \textit{“Introduction and benefits of yoga,”} the system suggested tags such as \textit{“Audience: Beginners”} and \textit{“Benefits: Mental Clarity,”} which the user incorporated into their narrative structure (P02). These suggestions helped guide users in tailoring their presentation content to the intended audience and goals, adding more depth to the narrative while reducing the cognitive load of coming up with all the necessary elements from scratch.

\textbf{Users frequently explored and chose drop-down suggestions.}
We observed several distinct patterns in how participants interacted with and utilized the suggested tags: In some cases, users directly dragged the suggested tag into a relevant group and then changed its value by selecting an option from the alternatives drop-down widget (see sequences of a red vertical stroke followed by an orange circle |\ding{108} in Figure \ref{fig:timelines}, center lane).

For example, when the system suggested \textit{“cycling: cycling for fitness”} for the topic of road riding, one participant dragged it into the narrative group and then refined it by selecting \textit{“cycling for environmental benefit”} from the dropdown (P06, see Figure \ref{fig:timelines} around minute 2). 

\textbf{Users frequently overrode system suggestions.}
Another pattern we frequently observed was that participants often took more exploratory approaches, such as dragging the tag into the group and examining the available dropdown values before manually overriding the tag’s value or label to better suit their vision (see sequences of a red vertical stroke followed by a purple square |\ding{110} in Figure \ref{fig:timelines}, center lanes).


\textbf{Participants requested image suggestions in quick succession.}
Image suggestions triggered by the system followed different workflows, as the system provided five different images each time, prompting some participants to drag and drop the suggested images into the content sources before triggering the system again for more options. 
(see sequences of a cyan triangle followed by pink vertical strokes \ding{116} | in Figure \ref{fig:timelines}, lower lanes)


\textbf{Users explored the slider but not for steering. }
Additionally, while participants occasionally explored slider options to see the opposite ends of a spectrum, this was done more for curiosity than for direct steering slide generation. 
This indicates a potential area for further refinement in how the slider functionality is integrated into the generation process.


\textbf{In the Slide Steering Overlay, users primarily used "Grounding Tags" for adjustments. }
Lastly, those participants who used the Slide Steering Overlay to adjust single slides primarily engaged with the tags that the system had generated through its grounding from slide feature (see sequences of a grey diamond in the upper lanes followed by events in the center lanes in Figure \ref{fig:timelines}, upper lanes). For example, when P09 invoked the \textit{Tag Steering Overlay} for adjusting a single slide, the system created multiple tags representing the slide’s current state, one in the visual style group stating \textit{“Color: Red and Black Text.”} To make adjustments, the user first explored the drop-down widget’s alternative suggestions and then overrode the tag’s value with \textit{“blue, red, and white,”} resulting in a slide variation with red and white text on a blue background. 



\subsection{Users’ Perceived Benefits and Challenges for Working with Intent Tags (RQ3)}

We clustered the perceived benefits and challenges for users working with intent tags into three themes: \textit{Expressing intents with tags}, \textit{catering users' presentation needs and workflows}, and \textit{meta-intent elicitation}. 



\subsubsection{\textbf{\rev{Expressing Intents with Tags}}} \label{expressing-intents-with-tags}


All participants found intent tags advantageous compared to chat-based prompts, appreciating their conciseness and the ease of specifying inputs without needing to write out long sentences: \textit{"it's quite like fun to be able to sort of click and not have to write out a lot [...] I think the benefit of having these labels [over chat-based] is the conciseness. I don't have that pressure to have to form a sentence."} (P02)




\textbf{Users liked micro-prompting for its granularity and control.}
Many participants also appreciated the granularity and control of intent tags while being able to quickly see which presentation-related aspects they can specify: \textit{"I really liked that granularity where you could specify, like, this is exactly the font style and I want the kind of theme of it. I like that aspect a lot [...] visually seeing these buckets of information where I can specify different tags. I think that is helpful."} (P07)



\textbf{Users valued the structure that tag grouping provided.}
Many participants found the tag groups (e.g., narrative, content source, visual style) intuitive and helpful for sequencing and structuring their process and thinking more explicitly about presentation-related aspects: \textit{"I think that narrative is super cool in terms of thinking about the audience [...] it helped me be more explicit about who my audience is in the deck that I'm creating. And it helped me make the right deck faster."} (P11)



\textbf{Users expected to define their own tag groups.}
However, other users questioned the necessity of pre-defined groups, suggesting the ability to customize or even work without tag groupings, which might better align with their workflow, as their needs can vary between different slide decks: \textit{"But also I would want the ability to just make my own [groups] because I think between different slide decks, it would change"} (P08)


\textbf{Users needed a moment to get used to tags' flexible terminology. }
Some participants experienced initial uncertainty around the terminology of intent tags, particularly when classifying and naming tags or choosing appropriate groups: \textit{"So I found it slightly intimidating at the beginning because there is some kind of arbitrary way of classifying."} (P09)
However, with experimentation and practice, they realized these decisions were not critical as the system does not rely on precise syntax but allows for flexible ways of specifying tags:
\textit{"But after doing it for a while, it seems like it's not that important either. Like, this decision of what to put in the title and this kind of things... As far as I'm putting text, I figure that it does something."} (P09)




\textbf{Users appreciated the preview features. }
Many appreciated the preview feature as it provided a sense of security and confidence when using the system. Knowing that they could see a preview before finalizing their choices reduced the fear of unexpected outcomes but also helped their imagination:
\textit{"I thought that the slider was neat. [...] I do appreciate how I'm not just imagining, like on a scale from one to five, how much detail do you want? I don't know... So, I appreciate that it has a little preview down there. That's neat."} (P05)

\textbf{Users expressed a desire for predefined tags. }
Some participants also noted that starting with a blank tag canvas could be overwhelming, so having a set of predefined tags (such as audience, narrative style, and number of slides) would provide guidance and help users get started: \textit{"Let's say empty tags where there's maybe already kind of like a label... like audience, but there's no audience mentioned yet. But for some people, they don't think about audience before they make a PowerPoint. So, just to be like, hey, who is this for? Is sometimes the most helpful feedback you can give someone. So you can get it here."} (P05)


\textbf{Users expected to rank tags. }
Some participants also expressed the need for a feature that allows them to rank or prioritize tags based on their importance to the presentation. One participant (P03) mentioned how they tried to emphasize certain points by grouping similar tags together, such as audience and objective, and incorporating system-suggested tags. They also noted that some tags, like colors or themes, were less important to them. 




\subsubsection{\textbf{\rev{Supporting Diverse Presentation Needs and Workflows}}} \label{supporting-diverse-presentation-needs}

In the interviews, participants also reflected on their general professional slide-creation experience and how IntentTagger could enhance or alleviate their process. Many described the challenges of traditional tools where the manual slide-by-slide process of creating a deck often feels tedious and uninspiring: \textit{"This was a really fun way to create a deck. I think it would appeal to most people that work in PowerPoint, because I don't think most people in PowerPoint creating decks just don't enjoy it unless they do."} (P02) 




\textbf{Users valued the system for overcoming ‘blank page’ barrier.}
Many participants found the system particularly helpful in overcoming the initial challenges of starting a presentation, which they identified as one of the hardest parts of any creative project. The ability to quickly generate a basic draft allowed them to move past the initial “blank page” barrier, making it easier to start thinking about additional content and refinements. This was especially valuable for those who often start presentations from scratch, as the system provided a visual outline that lowered the barrier to getting started, allowing them to focus more on editing and refining the content: \textit{"... I feel like the system got the basics going, which then prompted me to think of additional things to add on top."} (P05)


\textbf{Participants appreciated IntentTagger's flexibility in supporting diverse workflows.}
Participants appreciated the system’s ability to support various workflows, whether by starting with a detailed outline, a brain dump, or a narrative-first approach. 
Some participants highlighted the system’s flexibility in allowing them to begin with content and then refine it iteratively, while others valued the ability to focus on narrative and then move on to visual elements. 
The system’s adaptability to different working styles, such as sequential versus big-picture thinking, was also noted as beneficial. 

\textbf{Participants appreciated the outline editor for structuring ideas and overview.}
Additionally, the Outline Editor was particularly praised for helping users map out their ideas and providing a clear presentation overview, making it easier to refine individual slides or the entire deck as needed. 
One participant (P06) also preferred a more sequential workflow, suggesting that instead of showing all tag groups at once, they could focus on one at a time. 


\begin{figure*}[t]
  \centering
  \includegraphics[width=\linewidth]{Figures/UX-scenarios.png}
  \caption{UX interface sketches illustrating alternative use-cases for Intent Tagging-based steering of GenAI content creation; (Left) Blog post creator: (1) Steering of a post generation through intent tags in a side panel; (2) new tag suggestion can be requested per group; (middle) Video creator: Steering of a selected video clip through intent tags; (4) additionally, Keyframe Tags allow to control temporal aspects of the clip generation in the timeline view; (Right) 3D scene creator: (5) Steering of a 3D scene generation through intent tags.  }
  \Description{ The figure shows three interface sketches demonstrating different use cases for Intent Tagging-based content creation: (1) Blog Post Creator: On the left, the system is steering the generation of a blog post titled “Learn How To Code” with tags such as “Audience: Novices” and “Layout: Editorial.” New tags can be requested for each group. (2) Video Creator: In the middle, a video clip featuring a male dancer is being steered through tags like “Camera Angle: Medium Shot” and “Sound Effects: Footsteps.” Keyframe Tags at the bottom allow control over the movement speed in the timeline, from slow to fast. (3) 3D Scene Creator: On the right, a 3D scene of a street corner is being generated with tags like “Textures: Weathered,” “Environment: Street Corner,” and “Lighting: Moonlight.” Intent Tags control elements of the visual style, animation, and setting of the scene.}
  \label{fig:ux-scenarios}
\end{figure*}



\textbf{Users saw value in tags for tailoring presentations to different purposes.}
Furthermore, some users mentioned the system’s tag-based approach could be useful for creating different versions of presentations tailored to specific audiences or contexts. The ability to easily drag tags in and out allowed for quick adjustments, making it convenient to include or exclude certain content based on the needs of a shorter talk, a quick checkup, or a presentation adapted for a particular audience:
\textit{"Sometimes I need to make different versions of presentations [...] This tag system of dragging things out would be an easy way to include and exclude some things if I needed to."} (P03)


\textbf{Participants appreciated the fluid integration of deck-wide and slide-specific edits.}
Participants valued the system’s ability to manage both the entire deck and individual slides, appreciating the flexibility to make broad changes across the deck or to focus on specific slides for detailed adjustments. This dual approach was seen as more efficient compared to traditional slide authoring workflows, where changes often have to be made slide-by-slide: \textit{"I think that having this create the whole deck in one shot is super time-saving, and I don't expect it to be hit in one shot. And having the option to click into each slide, and if I like what I do here and want to apply it to the rest... I like the ability to go from everything, update everything, zoom in on one, and then experiment on that one. And then again, update all."} (P02)



\textbf{Users demanded more control by locking specific design elements. }
While they appreciated the flexibility and ambiguity offered by the system, participants expressed a desire for more control over certain aspects of their presentations by being able to lock or pin specific slide elements (like background colors, fonts, or other design choices) once they were satisfied with them to prevent them from changing unexpectedly during further generation cycles: \textit{"I do love the slider. I only just don't love that if I slide it one way and I get the color I want that it can subsequently change. I want to be able to anchor it."} (P11)







\subsubsection{\textbf{\rev{Meta-Intent Elicitation: Helping Creators Figure Out What They Want and Need}}}


One of the key benefits highlighted by participants was the system’s ability to help them discover and refine their intentions when creating presentations. Many mentioned that in their daily work, the process of selecting the right content and design elements was often difficult without clear guidance or inspiration. The system’s suggestions helped participants think more critically about their choices and provided new ideas they might not have initially considered. This process of "meta-intent" elicitation allowed users to identify important elements that they may have overlooked or not realized they wanted to include, making it easier to achieve their desired outcome: \textit{"I thought it was cool and interesting because it suggests things that I just didn't think about... And I like these suggestions because I don't always know what are the best style choices for something." (P03)}




\textbf{Participants appreciated the system guidance's gradual granularity}
Participants appreciated the system's converging granularity through its suggestions, allowing them to gradually refine their presentations in more specific and thoughtful ways:\textit{"I feel like [IntentTagger] suggests a lot more things that I can control. Versus with [the chat-based system], there are like four prompts and they're like buckets of things you can do rather than the specific things you can tweak. And so for me, this system of these tags feels like I can get more granular towards some kind of vision that I want because I think inherently I'm making some of those choices."} (P12)   
This guidance made the process more engaging and aligned with their vision while also simplifying the decision-making process by presenting contextually relevant options and ideas to respond to: \textit{"It kind of breaks down those decision points that I'm doing sort of subconsciously in a way that is fairly easy. And, like, it suggests a lot of different things [...] it feels like I can get to a decent outcome fairly quickly."} (P12)




\textbf{Participants imagined Intent Tagging to be beneficial for prototyping presentations and initial brainstorming.}
For some participants who reported frequently struggling to organize their thoughts or create structured presentations, the system could also serve as a useful tool for brainstorming and organizing their thoughts. Through the drag-and-drop interface, participants imagined to quickly include or exclude elements, allowing them to organize and prototype their presentations more intuitively and efficiently: \textit{"I can organize my thoughts down and drag things in I want to include, drag things out that I want to exclude."} (P03)

\textbf{Some users felt overwhelmed by visual clutter and suggestions.}
However, while the majority of participants found the amount and visual arrangement of the system-suggested tags helpful, a few noted that too many suggestions could feel visually cluttered and overwhelming. Some expressed a preference for a more simplified or list-based representation, allowing them to focus more easily on the suggestions without feeling overwhelmed by the options: \textit{"...so a bit more visual hierarchy, maybe less overloaded with suggestions."} (P01)




\textbf{Participants praised the slider for stimulating their critical thinking.}
Additionally, features such as the opposite slider helped participants think more deeply about the intention behind their choices. By offering a way to explore different dimensions of a tag or design element, participants were able to visualize various possibilities and fine-tune their decisions in a way that aligned with their goals and encouraged reflection on the impact of their choices: \textit{"I really like the slider idea of like... 'oh, you have this idea, but then you want to see what the opposite end is,' and you can put a slider on that value [...] it just makes you think more about your intention of what you're trying to do."} (P04)





\section{Intent Tagging Interactions Beyond Slide Deck Creation}

To illustrate how intent tagging could be utilized to facilitate human-GenAI co-creation interactions across diverse rich content creation tasks beyond slide deck creation, we explored alternative \textbf{user experience (UX) interface scenarios} for rich content creation applications. 
Some of these were inspired by participants' speculations during the interviews on how IntentTagger could be helpful in applications like Excel for complex data visualizations, educational materials, and tasks such as creating videos or book reports. 

In a design sprint, we sketched out three UX interface scenarios for intent tag-based steering of GenAI-driven creation of blog posts, videos, and 3D scenes (Figure \ref{fig:ux-scenarios}). 
We defined different tag groups for each application, matching the creation task's high-level categories.  
We also explored how to possibly expand the "tag vocabulary" and their functionalities by, for example, envisioning \textit{Keyframe Tags} to allow control over temporal aspects of clips in the video creator  (Figure \ref{fig:ux-scenarios}-4). 
Overall, while only sketches, these explorations aim to highlight the versatility of intent tagging for steering rich content generation across a range of applications and interfaces to be further explored in future research. 




