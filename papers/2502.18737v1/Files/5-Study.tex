

\section{User Study}
To better understand the possible benefits and limitations of intent tagging-based interactions, we conducted a lab user study aimed at providing insights into these research questions:
\begin{itemize}[font=\bfseries,
  align=left]
    \item[RQ1] \textit{What are the key differences between chat-based and intent tag-based interactions with GenAI?}
    \item[RQ2] \textit{How do people work with intent tags?}
    \item[RQ3] \textit{What are users’ perceived benefits and challenges for GenAI-driven slide creation with intent tags?}
   
 \end{itemize}


\rev{For RQ1, we decided to compare intent tag-based interactions with chat-based and design gallery-based approaches (text prompting and choosing from a set of options) since these represent the currently most common forms of interacting with GenAI for content creation in commercial systems, such as in OpenAI's ChatGPT/DALL-E \cite{betker_improving_2023}, Adobe's Firefly \cite{adobe_adobe_2024} or Microsoft's PowerPoint Copilot \cite{microsoft_powerpoint_2024b} and Designer \cite{microsoft_powerpoint_2024a} features.}  


\subsection{Participants}
We recruited 12 participants\textit{ (8 self-identified as females, 3 males, and 1 non-binary, age M=31.6 years (SD = 7.65 ))} with professional slide presentation creation experience via email lists at a large software company. The participant pool consisted of individuals with diverse job titles, and the majority of selected participants used PowerPoint at least multiple times per month in their jobs (see Table \ref{tab:participants} in the Appendix). All participants had previous experience using the \textit{Designer} and \textit{Copilot} features in PowerPoint, ensuring existing familiarity with generative AI functionalities for slide deck creation. Participants signed an IRB-approved consent form and were compensated with a \$50 gift card after study completion. 

\subsection{Procedure and Tasks} \label{sec:study-procedure}
The lab study was structured into four phases: 

\textbf{1) On-Boarding (20 min):} At the beginning of the session, after a general study introduction, participants watched a video tutorial demonstrating IntentTagger's core functionalities with a step-by-step example. Following the video, participants were asked to complete two five-minute guided hands-on structured tasks (editing an existing slide and making adjustments to an entire deck) to familiarize themselves with the tools' interface and operation.

\textbf{2) Comparative Tasks ( 2 x 10 min): }
After the onboarding phase, participants completed two comparative tasks, each lasting \rev{10} minutes, to evaluate their ability to create presentations using IntentTagger and a baseline system. 
\rev{In both tasks, participants were asked to create a 6-slide presentation aimed at educating teenagers about the inventions and scientific discoveries of a historical figure (\textit{“The Discoveries of Marie Curie”} or \textit{“The Inventions of Nikola Tesla”}).
Participants alternated between using IntentTagger and Microsoft PowerPoint \cite{microsoft_powerpoint_2024} across the two tasks in randomized order. 
For PowerPoint, participants were restricted to using only the integrated Copilot feature \cite{microsoft_powerpoint_2024b} (chatbot interface with optional document upload) and the Designer feature \cite{microsoft_powerpoint_2024a} (design gallery for slide layouts) for slide generation and modification. 
As a starting point, participants were provided with a Word document containing the relevant Wikipedia article in both tasks.} 
Participants were required to think aloud during the tasks, and after completing each task, they filled out a survey with attitudinal 6-point Likert scale questions. 
To mitigate order effects, the order of systems and presentation topics was randomized across participants. 

\textbf{3) \rev{Semi-structured} Task (10 min):}
In the third phase, participants were tasked with creating a 7-slide presentation from scratch using IntentTagger. 
They chose a topic related to a hobby they enjoy, aiming to convince others of its value and explain how to get started. 
Participants had ten minutes to complete the task, using only the prototype system without directly editing text or images on the canvas. 
They were required to think aloud as they worked, and before starting, they briefly described their topic and intentions for the presentation. 
\rev{We created this task to encourage participants to engage more freely with IntentTagger’s features, focusing on content creation and presentation design related to a topic they are knowledgeable about and emotionally connected to.
Since IntentTagger's deck generation time increases per slide, we deliberately limited the number of slides to six and seven per task in phases 2 and 3 to keep the processing time for each cycle within 15 seconds.}

\textbf{4) Exit Interview (20 min): }
In the final phase, participants participated in a semi-structured interview to provide feedback on their experience with IntentTagger, focusing on its overall utility, comparison with tools like PowerPoint’s Copilot, and the effectiveness of intent tagging interactions for slide creation. They shared insights on the tool’s strengths, areas for improvement, and potential integration into their professional workflows.



\subsection{Collected Data, Measures, and Analysis}

Across the study, we collected the following data:
\begin{itemize}
\item  Video, screen, and audio recordings and machine-generated transcripts of the task think-aloud sessions 
\item Audio recordings and machine-generated transcripts of the post-task interviews 
\item Post-task survey data
\item Participant-created presentations and related IntentTagger project files
\end{itemize}

To compare chat-based and intent tag-based interactions (Q1), we analyzed the post-task surveys from phase 2 that probed on participants' perceived ease of use, efficiency, and control over the slide generation process on a 6-point Likert scale. We applied the Wilcoxon signed-rank test to assess statistical significance and calculated 95\% confidence intervals for mean differences via bootstrapping with 10,000 replications using R \cite{rcoreteam_language_2024}. This approach has been suggested for similar data and studies \cite{zhu_assessing_2018, masson_statslator_2023}. 


To answer how people work with intent tags (Q2), we conducted a video interaction analysis \cite{baumer_comparing_2011} of the video recordings collected in the semi-structured task \textit{(study phase 3)}. We manually coded participants' interactions with IntentTagger's features in Atlas.ti \cite{atlas.ti_atlasti_2024}, such as their interactions with tags or the moments they triggered the outline and slide generation.  

Finally, to investigate users’ perceived benefits and challenges of intent tags (Q3), we conducted a reflexive thematic analysis \cite{braun_reflecting_2019} of the interview transcripts. We followed an iterative inductive coding process (using Marvin \cite{marvin_marvin_2024}) and generated themes through affinity diagramming using Miro \cite{miro_miro_2024}.
