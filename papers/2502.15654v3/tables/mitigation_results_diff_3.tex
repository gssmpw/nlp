\begin{table*}[t]
    \small
    \centering
    \setlength{\tabcolsep}{4pt}
    \resizebox{0.9\linewidth}{!}{%
    \begin{tabular}{@{}llccccccccc@{}}
        \toprule
        \bf Model & \bf Decoding & $\alpha$, $\beta$, $\gamma$ & \bf Perplexity$\downarrow$ & \bf Accuracy$\uparrow$ & \bf Diversity$\uparrow$ & \bf Self-BLEU$\downarrow$ & \bf MAUVE$\uparrow$ & \bf Readability$\uparrow$ \\
        \midrule
        \multirow{6}{*}{\texttt{GPT-2}} 
        & \multirow{3}{*}{top-$k$} 
            & $.5$, $1$, $0$   & $\textcolor{blue}{-7.28\%}$ & $\textcolor{blue}{+2.37\%}$ & $\textcolor{blue}{+4.54\%}$  & $\textcolor{blue}{-1.77\%}$  & $\textcolor{blue}{+0.46\%}$  & $\textcolor{blue}{+9.03\%}$  \\
        &   & $.5$, $.5$, $.5$ & $\textcolor{blue}{-5.94\%}$ & $\textcolor{blue}{+1.72\%}$ & $\textcolor{blue}{+2.43\%}$ & $\textcolor{blue}{-4.28\%}$ & $\textcolor{blue}{+3.99\%}$ & $\textcolor{blue}{+10.16\%}$  \\
        &   & $1$, $1$, $0$   & $\textcolor{blue}{-4.45\%}$ & $\textcolor{blue}{+1.49\%}$ & $\textcolor{blue}{+3.59\%}$  & $\textcolor{blue}{-3.58\%}$  & $\textcolor{blue}{+1.36\%}$  & $\textcolor{blue}{+6.76\%}$  \\
        \cmidrule{2-9}
        & \multirow{3}{*}{sampling}  
            & $.5$, $1$, $0$ & $\textcolor{blue}{-7.41\%}$ & $\textcolor{blue}{+1.50\%}$ & $\textcolor{red}{-1.30\%}$ & $\textcolor{red}{+36.71\%}$  & $\textcolor{blue}{+74.06\%}$  & $\textcolor{blue}{+50.23\%}$ \\
        &   & $.5$, $.5$, $.5$ & $\textcolor{blue}{-6.54\%}$ & $\textcolor{blue}{+1.50\%}$ & $\textcolor{red}{-1.07\%}$ & $\textcolor{red}{+21.39\%}$ & $\textcolor{blue}{+16.38\%}$ & $\textcolor{blue}{+25.45\%}$ \\
        &   & $1$, $1$, $0$ & $\textcolor{blue}{-25.65\%}$ & $\textcolor{blue}{+0.96\%}$ & $\textcolor{red}{-0.71\%}$ & $\textcolor{red}{+20.70\%}$ & $\textcolor{blue}{+16.42\%}$  & $\textcolor{blue}{+20.99\%}$  \\
        \midrule
        \multirow{6}{*}{\texttt{SmolLM2}}  
        & \multirow{3}{*}{top-$k$} 
            & $.5$, $1$, $0$ & $\textcolor{blue}{-3.56\%}$ & $\textcolor{blue}{+0.40\%}$ & $\textcolor{blue}{+10.51\%}$  & $\textcolor{blue}{-5.42\%}$ & $\textcolor{blue}{+2.29\%}$ & $\textcolor{red}{-2.50\%}$  \\
        &   & $.5$, $.5$, $.5$ & $\textcolor{blue}{-3.50\%}$ & $\textcolor{blue}{+0.53\%}$ & $\textcolor{blue}{+7.37\%}$ & $\textcolor{blue}{-5.38\%}$  & $\textcolor{red}{-0.71\%}$  & $\textcolor{red}{-2.30\%}$\\
        &   & $1$, $1$, $0$ & $\textcolor{blue}{-2.52\%}$ & $\textcolor{blue}{+0.48\%}$ & $\textcolor{blue}{+6.07\%}$  & $\textcolor{blue}{-4.77\%}$ & $\textcolor{blue}{+6.03\%}$ & $\textcolor{red}{-1.97\%}$ \\
        \cmidrule{2-9}
        & \multirow{3}{*}{temperature}  
            & $.5$, $1$, $0$ & $\textcolor{blue}{-3.06\%}$ & $\textcolor{blue}{+0.19\%}$ & $\textcolor{blue}{+19.77\%}$  & $\textcolor{blue}{-6.86\%}$ & $\textcolor{red}{-13.09\%}$ & $\textcolor{red}{-2.76\%}$  \\
        &   & $.5$, $.5$, $.5$ & $\textcolor{blue}{-2.37\%}$ & $\textcolor{blue}{+0.27\%}$ & $\textcolor{blue}{+11.79\%}$  & $\textcolor{blue}{-6.43\%}$  & $\textcolor{blue}{+13.72\%}$  & $\textcolor{red}{-0.98\%}$ \\
        &   & $1$, $1$, $0$ & $\textcolor{blue}{-1.49\%}$ & $\textcolor{blue}{+0.27\%}$ & $\textcolor{blue}{+11.16\%}$ & $\textcolor{blue}{-7.11\%}$ & $\textcolor{red}{-10.49\%}$  & $\textcolor{red}{-2.64\%}$ \\
        \bottomrule
    \end{tabular}
    }%
    \caption{Percentage of change in data quality when using our proposed mitigation strategy versus the baseline. Results are shown for top-$k$ decoding and sampling/temperature for different values of $\alpha$, $\beta$, and $\gamma$ (\textcolor{blue}{blue} / \textcolor{red}{red}: \textcolor{blue}{positive} / \textcolor{red}{negative} results, $\uparrow$ / $\downarrow$: higher / lower is better).}
    \label{tab:data_quality_mitigation}
\end{table*}
