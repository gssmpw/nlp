The last part of the planning module, shown in~\autoref{fig:arch_LLM_pKB}, is the optimisation module which allows for shrinking the plan by scheduling the task (temporal plan) and allocating the resources. In order to do this, we instantiate a MILP problem, the solution of which must satisfy constraints ensuring that we are not violating precedence relationships and invalidating the obtained planned. 

We start by taking the work from~\cite{cimatti_strong_2015}, in which the authors describe how it is possible to obtain a plan with lower makespan by reordering some tasks. In particular, we adopt the following concepts from~\cite{cimatti_strong_2015}:
\begin{itemize}
    \item Let $f(l)=\{a\in DA \vert l\in \eff{a}\}$ be the set of actions that achieve a literal $l$, and 
    \item let $\displaystyle p(l,a,r)\doteq a<r \wedge \bigwedge_{a_i\in f(l)\setminus\{a,r\}}(a_i<a\vee a_i>r)$ be the temporal constraint stating which is the last achiever $a$ of an action $r$ for a literal $l$. 
\end{itemize}
The constraints that must hold are the following:
\begin{equation}
    \label{eq:constraint1_old}
    %\footnotesize
    \bigvee_{a_j\in f(l)\setminus\{a\}} p(l,a_j,a).
\end{equation}
Which states that at least an action with effect $l$ should occur before $a$.
\begin{equation}
    \label{eq:constraint2}
    %\footnotesize
    \bigwedge_{a_j\in f(l)} \left(p(l,a_j,a) \rightarrow \bigwedge_{a_t\in f(\lnot l)\setminus\{a\}}(a_t<a_j \vee a_t>a)\right).
\end{equation}
\begin{equation}
    \label{eq:constraint3}
    %\footnotesize
    \bigwedge_{a_j\in f(\lnot l)\wedge l\in \pc{a}} ((a_j<\aStart{a}) \vee (a_j>\aEnd{a})).
\end{equation}
Which state that between the last achiever $a_j$ of a literal $l$ for an action $a$ and the action $a$ there must not be an action $a_t$ negating said literal. This condition is also enforced by~\autoref{eq:constraint3} that constrains actions negating the literal to happen before the action $a$ has started or after it has finished.

Notice though that in this work, the authors have considered achievers and not enablers. The difference is that an action $a_j$ is an achiever of $a_i$ if $a_j$ \emph{adds} a fluent $l$ that is needed by $a_j$. Enablers instead consider the case in which fluents are also removed. 
%
Since these constraints only consider achievers and not enablers, we need to extend them. We redefine the previous as:
\begin{itemize}
    \item let $f(l)=\{a\in DA \vert add(l)\in \eff{a}\}$ be the set of actions that achieve a literal $l$, and 
    \item let $f(\lnot l)=\{a\in DA \vert del(l) \in \eff{a}\}$ be the set of actions that delete a literal $l$, and
    \item let $F(l) = f(l)\cup f(\lnot l)$ be the union set of $f(l)$ and $f(\lnot l)$, and
    \item let $\displaystyle p(l,a,r)\doteq a<r \wedge \bigwedge_{a_i\in F(l) \setminus\{a,r\}}(a_i<a\vee a_i>r)$ be the last enabler $a$ of an action $r$ for a literal $l$. 
\end{itemize}
Consequently, we need to:
\begin{itemize}
    \item revise~\autoref{eq:constraint1_old} to include all enablers:
        \begin{equation}
            \label{eq:constraint1}
            %\footnotesize
            \bigvee_{a_j\in F(l)\setminus\{a\}} p(l,a_j,a).
        \end{equation}
    \item add two constraints similar to~\autoref{eq:constraint2} and~\autoref{eq:constraint3} to ensure that a predicate that was removed is not added again before the execution of the action:
    \begin{equation}
        \label{eq:constraint2_1}
        %\footnotesize
        \bigwedge_{a_j\in f(\lnot l)} \left(p(l,a_j,a) \rightarrow \bigwedge_{a_t\in f(l)\setminus\{a\}}(a_t<a_j \vee a_t>a)\right).
    \end{equation}
    \begin{equation}
        \label{eq:constraint3_1}
        %\footnotesize
        \bigwedge_{a_j\in f(l)\wedge (\lnot l)\in \pc{a}} ((a_j<\aStart{a}) \vee (a_j>\aEnd{a})).
    \end{equation}    
\end{itemize}

The second aspect of the MILP problem concerns resource allocation. Indeed, as stated before, there are some predicates that are parameterised on resources, e.g., \texttt{available(A)} states whether an agent \texttt{A} is available or not, but it does not ground the value of \texttt{A}. %
One possibility would be to allocate the resources using Prolog, as done in~\cite{saccon2023prolog}, but this choice is greedy since Prolog grounds information with the first predicate that satisfy \texttt{A}. To reduce the makespan of the plan and improve the quality of the same, we delay the grounding to an optimisation phase, leaving Prolog to capture the relationships between actions.

As a first step, we are also going to assume that all the actions coming from a mapping of a higher-level action and that are not mapped into lower-level actions shall maintain the same parameterised predicates as the higher-level action. So the constraint in~\autoref{eq:constraint6} must hold.
\begin{equation}
    \label{eq:constraint6}
    \bigwedge_{a_j\in m(a_i) \wedge m(a_j)\notin M} \left(\bigwedge_{p(x_i) \in \pc{a_i} \wedge p(x_j) \in \pc{a_j}} x_i=x_j \right).
\end{equation}
Moreover, for these constraints, we will consider only predicates that are part of the set $K$, that is predicates that are not resources $R\cap K=\emptyset$.

The objective now is three-fold: 
\begin{itemize}
    \item identify a cost function,
    \item summarise the previous constraints, and
    \item construct a MILP problem to be solved.
\end{itemize}

In this work, the first point is straightforward: we want to minimise the makespan, i.e., the total duration required to complete all tasks or activities.

For the second point, we are trying to find a way to put the previous constraints,~\cref{eq:constraint1,eq:constraint2,eq:constraint2_1,eq:constraint3,eq:constraint3_1,eq:constraint4,eq:constraint5,eq:constraint6} in a compact formulation or structure. We opted to extract the information regarding the enablers using Prolog and to place it into a $N\times N$ matrix $C$, where $N$ is the number of actions and each cell $C_{ij}$ is $1$ if $a_i$ is an enabler of $a_j$ (without considering resources), 0 otherwise. 

We now need to address the resource allocation aspect, specifically, how to distribute the available resources $R$ among the various actions. When performing this task, there are primarily two factors to consider:
\begin{itemize}
    \item A resource cannot be utilised for multiple actions simultaneously.
    \item If two actions share the same resource, they must occur sequentially, meaning one action enables the other.
\end{itemize}

For the first factor, we need to make sure that, for each resource type $r\in R$, the number of actions using the resource at the same time must not be higher than the number of resources of that type available, as shown in~\autoref{eq:resAllocation}.
\begin{equation}
    \displaystyle\forall t \in\{t_0, t_{\tn{END}}\},\,\vert r\vert \geq\sum_{a_i\in TO} t\in\{\aStart{a_i}, \aEnd{a_i}\} \wedge \left( \exists~l(\pmb{x})\in \pc{a_i}\vert r\in\pmb{x}\right).
    \label{eq:resAllocation}
\end{equation}

The second factor must instead be merged with also the precedence constraints embedded in $C$. In particular, we want to express that actions $a_i, a_j$ are in a casual relationship if $C_{ij}=1$ or if they share the same resource. This can be expressed with the following constraint: 
\begin{equation}
    C_{ij} \vee \exists r\in R : r\in\fl{a_i} \wedge r\in\fl{a_j}
    \label{eq:precedence}
\end{equation}
Note that $\fl{a}$ was defined in the problem definition paragraph and represents the set of variables and literals used by the predicates in the preconditions of $a$. 

Finally, we need to set up the MILP problem that consists in finding an assignment of the parameters, of the actions' duration and of the causal relationships, such that the depth of the graph $\mathcal{G}$ representing the plan is minimised. This problem can be expressed as shown in~\autoref{eq:optimization_1}.

%\begin{figure*}[h]
%    \centering
    \begin{equation}
    \everymath={\displaystyle}
    \begin{array}{r@{\hspace*{8mm}}l}
        \label{eq:optimization_1}
        \min_{\mathcal{P}, \mathcal{T}} & t_{\tn{END}} \\
        %&\\
        \textrm{s.t.}   & C_{ij} \vee \exists r\in R : r\in\fl{a_i} \wedge r\in\fl{a_j}, \\
                              & \quad \quad \forall t \in\{t_0, t_{\tn{END}}\}, \\
                              & \quad \quad \quad \quad \vert r\vert > \!\!\sum_{a_i\in TO} \left(t\in\{\aStart{a_i}, \aEnd{a_i}\} \wedge \exists~l(\pmb{x})\in \pc{a_i}\vert r\in\pmb{x}\right).\\
    \end{array}
    \end{equation}
%\end{figure*}

As mentioned before, the MILP part is implemented in Python3 using OR-Tools from Google. The program also checks the consistency of the PO matrix $C$, by making sure that all the actions must have a path to the final actions. 
The output of the MILP solution is basically an STN, which describes both the causal relationship between the actions and also the intervals around the duration of the actions. The initial and final nodes of the STN are factitious as they do not correspond to actual actions, but they simply represent the start and the end of the plan.
The STN is extracted by considering the causal relationship from the $C$ matrix taken as input, and by adding the causal relationship given by the resource allocation task. 
Once we have the STN, we can extract a \bt, which can then be directly executed by integrating it in ROS2. 

\subsubsection{Plan Optimization -- Example}
\label{sssec:PORunExample}
As we said at the end of~\autoref{sssec:PORunEx}  on the running example, that particular plan is not optimisable as the actions are executed in sequence. Let's then consider a slight modification, which consists in finding a plan to move the two blocks in two new positions instead of stacking them in one position. We also have a new agent that can be used to carry out part of the work. 
Our new plan and actions' enablers are the following one:

\begin{minted}[fontsize=\footnotesize]{text}
[0] init()[]
[1] move_table_to_table_start(a1, b1, 1, 1, 1, 2), [0]
[2] move_arm_start(a1, 1, 1), [0,1]
[3] move_arm_end(a1, 1, 1), [0,1,2]
[4] grip_start(a1), [0,1,2,3]
[5] grip_end(a1), [0,1,2,3,4]
[6] move_arm_start(a1, 1, 2), [0,1,2,3,4,5]
[7] move_arm_end(a1, 1, 2), [0,1,2,3,4,5,6]
[8] release_start(a1), [0,1,2,3,4,5,6,7]
[9] release_end(a1), [0,1,2,3,4,5,6,7,8]
[10] move_table_to_table_end(a1, b1, 1, 1, 1, 2), [0,1,2,3,4,5,6,7,8,9]
[11] move_table_to_table_start(a1, b2, 3, 1, 3, 2), [0,10]
[12] move_arm_start(a1, 3, 1), [0,11]
[13] move_arm_end(a1, 3, 1), [0,11,12]
[14] grip_start(a1), [0,11,12,13]
[15] grip_end(a1), [0,11,12,13,14]
[16] move_arm_start(a1, 3, 2), [0,11,12,13,14,15]
[17] move_arm_end(a1, 3, 2), [0,11,12,13,14,15,16]
[18] release_start(a1), [0,11,12,13,14,15,16,17]
[19] release_end(a1), [0,11,12,13,14,15,16,17,18]
[20] move_table_to_table_end(a1, b2, 3, 1, 3, 2), [0,10,11,12,13,14,15,16,17,18,19]
[21] end(), [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
\end{minted}

Indeed, action $a_9$ may or may not be an enabler of action $a_{10}$ depending on the resource allocation of the MILP solution. If we have just one agent, then $a_9\in\ach{a_{10}}$, if instead we have more than one agent, then $a_9\not\in\ach{a_{10}}$ and the two actions can be executed at the same time and the plan would be:

\begin{minted}[fontsize=\footnotesize]{text}
[0] init()
[1] move_table_to_table_start(a1, b1, 1, 1, 1, 2)
[2] move_arm_start(a1, 1, 1)
[3] move_arm_end(a1, 1, 1)
[4] grip_start(a1)
[5] grip_end(a1)
[6] move_arm_start(a1, 1, 2)
[7] move_arm_end(a1, 1, 2)
[8] release_start(a1)
[9] release_end(a1)
[10] move_table_to_table_end(a1, b1, 1, 1, 1, 2)
[11] move_table_to_block_start(a2, b2, 3, 1, 3, 2)
[12] move_arm_start(a2, 3, 1)
[13] move_arm_end(a2, 3, 1)
[14] grip_start(a2)
[15] grip_end(a2)
[16] move_arm_start(a2, 3, 2)
[17] move_arm_end(a2, 3, 2)
[18] release_start(a2)
[19] release_end(a2)
[20] move_table_to_block_end(a2, b2, 3, 1, 3, 2)
[21] end()
\end{minted}

% \enrcom{Should I also include a figure? MR: I do not think so!}

% \subsubsection{Plan Generation - Example}