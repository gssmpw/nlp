\subsection{Task Planning}
Multi-agent robotics is a rapidly growing field with applications in various domains like search and rescue, warehouse logistics, and planetary exploration. A critical capability for these robots is the ability to plan and execute tasks efficiently, especially in dynamic environments where conditions can change quickly. Temporal task planning focuses on generating sequences of actions for agents to achieve specific goals, while considering the timing and order of these actions. This ensures that actions are performed at the right time and potential conflicts between agents are avoided.  
Traditional task planning approaches often rely on pre-defined models of the environment and robot capabilities. These models may not accurately reflect the real world, especially in situations with unexpected obstacles or changes in the environment. Additionally, such methods often struggle to handle efficiently scenarios involving multiple agents that need to coordinate their actions to achieve a common goal.

\subsection{Logic Programming}
Logic programming offers a powerful framework for representing knowledge and reasoning about actions and their effects. Prolog, a prominent logic programming language, has been extensively used for task planning due to its expressiveness and ability to handle symbolic reasoning. Prolog allows developers to define facts and rules that represent the state of the world, preconditions and effects of actions, and temporal constraints. %While Prolog offers advantages in representing complex knowledge, its computational efficiency can be a challenge for large-scale planning problems. 
ASP (Answer Set Programming): This declarative language allows representing planning problems as a set of rules. A solver then identifies a minimal set of rules (answer set) that satisfies the initial state and goal of the plan.
PDDL (Planning Domain Definition Language): This language provides a standardized way to describe planning problems, including actions, preconditions, and effects. PDDL planners can then use this standardized format to reason about different planning domains.
GOLOG (Goal Logic): This language combines the expressiveness of logic with the ability to reason about actions and their effects. GOLOG allows representing plans with goals, preconditions, and actions, facilitating reasoning about complex planning problems.
Datalog: This logic programming language focuses on querying and manipulating data. While not directly designed for planning, Datalog can be used for specific aspects of task planning, such as reasoning about preconditions and identifying valid action sequences based on knowledge base information.
The choice of the formalism depends on the specific needs of the planning problem. Prolog might be a good choice for representing complex knowledge and reasoning about actions, while ASP or PDDL might be preferred for their standardized formats and efficient planning algorithms.

\subsection{Large Language Models}
Large Language Models (LLMs) have shown remarkable capabilities in processing and understanding large amounts of natural language text.  Recent research suggests that LLMs can be leveraged to extract knowledge from various sources and populate knowledge bases (KBs). These KBs can then be used for reasoning and planning tasks. The potential benefit of using LLMs lies in their ability to automatically acquire and integrate knowledge from diverse sources, potentially leading to more robust and adaptable planning systems.

% Researchers are exploiting Large Language Models as tools to achieve different goals, such as reasoning, planning, manipulation, navigation, and simulation frameworks.

% \subsection{Planning with Large Language Models}
% PaLM-SayCan \cite{ahn2022can} uses LLM's semantic capabilities to process natural language commands. This framework allows robots to perform tasks humans assign using the value function. It uses a logarithmic estimation of the value and affordance functions to determine an action's feasibility. Given the current environment and status, it will take the most likely action to succeed.

% PaLM-E \cite{driess2023palm} integrates real-world sensory input, bridging the gap between perception and language.

% LM-Nav \cite{shah2023lm} leverages language to improve communication between users and robots. The LM-Nav system has three components: a vision-navigation model (VNM), a vision-language model (VLM), and a large language model (LLM).

% The SayCan framework \cite{ahn2022i} combines human high-level instructions and their corresponding robot basic tasks into prompts.

% % Learningg from data
% Language-guided robot skill learning \cite{ha2023scaling} is a way for robots to learn new skills. It uses a large language model to make language-labeled robot data that is then distilled into a solid multi-task language-conditioned visuo-motor policy. This makes success rates 33.2 percent higher across five domains. REFLECT \cite{liu2023reflect} is a framework based on LLM that automatically uses observations from multiple senses to find and analyze failed robot actions. This gives language-based planning helpful information about why the actions failed.


% % Task Planning
% In \cite{ding2023task}, the authors explore the possibilities of language models applied to task and motion planning situations while limiting the LLM planner to a feasible set of activities. Plans produced by LLM are translated into code from natural language in \cite{li2023interactive}. 

% In Code as Policies (CaP) \cite{codeAsPolicies}, an LLM produces programs (Language Model-Generated Program LMP). The LLM can use known or undefined functions that will be described later. They then run the Python code with some safety checks.

% The Interactive Task Planning (ITP) framework \cite{IntTPLLM} is made up of two LLMs. The first makes a high-level plan based on task guidelines, user requests, and completed steps that have been remembered. The second one connects each high-level step of the plan to a low-level function from a robot skill library.

% \textbf{Text2Motion} \cite{Lin_2023}: Task and Motion Planning (TAMP) is a problem-solving method where a robot solves long-horizon tasks using symbolic and geometric reasoning. Classical TAMP solvers iterate between task planning and motion planning for complex tasks. It addresses challenges concerning the reliable use of LLMs in TAMP settings. The framework uses an LLM and a library of skills, each with a policy and parameterized manipulation primitive. The framework is agnostic of the approach used to obtain these models and conveys the state of the environment to the LLM as natural language. Text2Motion also assumes knowledge of task-relevant objects and their poses to plan feasible trajectories for long-horizon tasks.

% \textbf{TidyBot} \cite{Wu_2023}: The study evaluates a text-based benchmark dataset and a real-world robotic system, finding that it achieves an accuracy of 91.2 percent on unseen objects across all scenarios. In real-world test scenarios, TidyBot correctly puts away 85.0 percent of objects. The approach can be extended to infer generalized rules for manipulating primitive selection and object placement. The study adds to the idea that text summarization with LLMs can be used to generalize in robotics. It also includes a publicly available benchmark dataset for testing how well the approach works on a real-world mobile manipulation system and how well it generalizes receptacle selection preferences. The approach uses off-the-shelf LLMs with no additional training or data collection, leveraging LLMs' commonsense knowledge and summarization abilities to build generalizable personalized preferences for each user. The study also shows that the summarization ability of LLMs enables generalization in robotics.

% \textbf{Common sense-based Open-World Planning (COWP)} \cite{ding2023integrating}: is an open-world planning approach for robots that addresses open-world planning problems. COWP uses action knowledge to enable zero-shot prompting for planning and situation handling, unlike ProgPrompt, which relies on example solutions. COWP extracts commonsense knowledge from LLMs and incorporates rule-based action knowledge from human experts. Reasoning with action knowledge ensures the soundness of task plans generated by COWP while querying LLMs guarantees the openness of COWP to unforeseen situations.

% \textbf{LMZSP (Language Models as Zero-Shot Planners)} \cite{huang2022language}: It utilizes LLMs to generate task plans without relying on domain-specific action knowledge. However, due to its lack of environmental awareness and inability to receive feedback, LMZSP often produces plans involving unavailable or irrelevant objects for the current context.

% \textbf{LLM+P} \cite{liu2023llmp}: incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem and returns a correct or optimal plan for solving that problem in natural language. It does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to find a solution quickly, and then translating the found solution back into natural language. The research aims to enable LLMs to solve planning problems correctly without altering the LLMs themselves, even with finetuning. The methodology, called LLM+P, outputs a problem description suitable as input to a general-purpose planner, solves the problem using the general-purpose planner, and converts the output of the planner back to natural language.

% \textbf{Long-Step Robot Control}\cite{wake2023chatgpt}: In this study, the authors describe a method for translating natural-language instructions into executable robot actions using OpenAI's ChatGPT in a few-shot setting. The authors propose customizable input prompts for ChatGPT to integrate with robot execution systems or visual recognition programs, adapt to various environments, and create multi-step task plans. The approach receives instructions and textual environmental data and outputs a task plan and updated environment. These ecological data are reused in subsequent task planning, eliminating the need for extensive record-keeping. A quantitative evaluation using VirtualHome showed that 36 percent of task planning met both executability and correctness, and the rate approached 100 percent after several rounds of feedback. 


% \textbf{ProgPrompt} \cite{singh2022progprompt}: Robot plans are represented as Pythonic programs using Python prompting. The program consists of API calls to action primitives, comments summarizing actions, and assertions for tracking execution. The plan functions include API calls to action primitives, comments to outline actions, and assertions for monitoring execution. The program also provides information about the environment and primitive actions to the LLM through prompt construction. The generated plans typically contain actions an agent can take and objects available in the given environment. The LLM fully inferred the plan based on the prompt and executed it on a virtual agent or a physical robot system. The process is tested in the Virtual Home (VH) environment, a deterministic simulation platform for typical household activities. The technique uses a dataset of 70 household tasks and incorporates environmental state feedback in response to assertions. The system's performance is evaluated using success rate, executability, and goal condition recall.


% The LLM is provided with:
% \begin{itemize*}[label=-]
%     \item action primitives 
%     \item available objects 
%     \item example task
%     \item next task description
% \end{itemize*}
% The LLM generates a plan, and assertion checks are enforced. 



% However, specific issues have been observed in the studies above: The tasks with the same meaning but varying degrees of precision and logic using the same prompt impact the quality of the results. It has also been noted that there is a limit to the logical complexity of tasks that can be processed concurrently. It should be highlighted that the GPT's or LLM's capacity for language comprehension does not improve its comprehension of the need to break down tasks recursively. It is also because the framework difference exists, as all the methodologies do not comprise the same components.