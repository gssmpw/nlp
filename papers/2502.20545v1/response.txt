The problem of determining whether a multivariate polynomial is nonnegative is inherently linked to the task of finding its global minimum—a fundamental challenge in the optimization community **Nesterov, "Polynomial Optimization"**. Testing whether a general polynomial is nonnegative is provably NP-hard, even for polynomials of relatively low degrees or with a small number of variables. For instance, it has been shown that finding the global minimum of general even-degree polynomials of degree at least four is NP-hard **Lasserre, "Global Optimization with Polynomials"**.


Due to the computational intractability of the general problem, we seek special cases of polynomials where the challenging nonnegativity constraints can be replaced with more manageable conditions. The sum of squares (SoS) condition, a mathematical technique in polynomial optimization where a polynomial is expressed as a sum of squared polynomials, provides a sufficient criterion for polynomial nonnegativity. 
The SoS property is particularly useful because it allows the nonnegativity problem to be reformulated as a semidefinite programming (SDP) problem, for which efficient algorithms, such as interior-point methods, exist. 
 In certain special cases, nonnegativity and SoS are equivalent; for example, any nonnegative quadratic polynomial or any nonnegative even-degree univariate polynomial can always be expressed as a sum of squares **Curto, "Sums of Hermitian Squares"**. For more complex polynomials, the Lasserre hierarchy provides a systematic way to approximate nonnegativity using a sequence of SoS relaxations **Lasserre, "Global Optimization with Polynomials"**. This method constructs a sequence of SDP problems that yield increasingly tighter approximations to nonnegativity. 

%However, current classic solvers are generally impractical for large-scale problems. Specifically, for a polynomial with  $n$ variables and a degree of $2d$, the SDP's dimension is given by $N = \binom{n+2d}{2d}$, making it challenging to scale to larger problems. 
Many large-scale problems exhibit structured sparsity patterns, enabling the application of a sparsity-adapted hierarchy of SDP relaxations **Kushner, "Approximation Algorithms for Large-Scale Semidefinite Programs"**. Additional techniques for addressing large-scale problems include Structured DSoS and SDSoS programming, as well as Bounded Degree SoS (BSoS) **Anjos, "Structured Semidefinite Programs and Sums of Squares Relaxations"**.
These approaches take advantage of the structure of the problem (sparsity) to generate smaller SDPs. There are also methods to reformulate the original optimization problem to reduce the size of the optimization. For instance, the optimization of a multivariate fourth-order (quartic) homogeneous polynomial under quadratic constraints can be relaxed into a quadratic SDP **Güler, "Quadratic Semidefinite Programming"**. In contrast to the SoS approach, which gives a matrix variable of size at least $N \times N$, the quadratic SDP system has a size of $n \times n$ only. The resulting quadratic SDP can be well approximated in polynomial time in some cases, but it remains NP-hard. 
Yet, these methods primarily depend on the specific structure of the problem, and generally, the scalability of characterizing polynomial nonnegativity remains a significant challenge in the literature.