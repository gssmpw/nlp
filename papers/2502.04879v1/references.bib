@inproceedings{hardt2023collectiveaction,
author = {Hardt, Moritz and Mazumdar, Eric and Mendler-D\"{u}nner, Celestine and Zrnic, Tijana},
title = {Algorithmic collective action in machine learning},
year = {2023},
booktitle = {Proceedings of the International Conference on Machine Learning},
articleno = {510},
numpages = {17},
location = {Honolulu, Hawaii, USA},
}

@article{olson1965logic,
   title={The Logic of Collective Action: Public Goods and the Theory of Groups},
   author={Olson, Mancur},
   journal={Harvard University Press},
   year={1965}
}

@article{chen2017targetedba,
   title={Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning},
   author={Xinyun Chen and Chang Liu and Bo Li and Kimberly Lu and Dawn Song},
   journal={arXiv preprint arXiv:1712.05526},
   year={2017}
}

@article{gu2019badnets,
  author={Gu, Tianyu and Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal={IEEE Access}, 
  title={BadNets: Evaluating Backdooring Attacks on Deep Neural Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={47230-47244},
  keywords={Training;Machine learning;Perturbation methods;Computational modeling;Biological neural networks;Security;Computer security;machine learning;neural networks}
}

@article{tian2022survey,
author = {Tian, Zhiyi and Cui, Lei and Liang, Jie and Yu, Shui},
title = {A Comprehensive Survey on Poisoning Attacks and Countermeasures in Machine Learning},
year = {2022},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {8},
journal = {ACM Comput. Surv.},
articleno = {166},
numpages = {35},
keywords = {Deep learning, federated learning, poisoning attack, backdoor attack}
}

@article{guo2021survey,
  title={An Overview of Backdoor Attacks Against Deep Neural Networks and Possible Defences},
  author={Wei Guo and Benedetta Tondi and Mauro Barni},
  journal={IEEE Open Journal of Signal Processing},
  year={2021},
  volume={3},
  pages={261-287}
}

@inproceedings{manoj2021backdoor,
author = {Manoj, Naren Sarayu and Blum, Avrim},
title = {Excess capacity and backdoor poisoning},
year = {2021},
booktitle = {Proceedings of the International Conference on Neural Information Processing Systems},
articleno = {1558},
numpages = {12}
}

@article{grosse2022backdoor,
title = {Backdoor smoothing: Demystifying backdoor attacks on deep neural networks},
journal = {Computers \& Security},
volume = {120},
pages = {102814},
year = {2022},
author = {Kathrin Grosse and Taesung Lee and Battista Biggio and Youngja Park and Michael Backes and Ian Molloy},
keywords = {ML security, Deep learning backdoors, ML poisoning, Training time attacks, Training time defenses}
}

@article{cina2023survey,
author = {Cin\`{a}, Antonio Emanuele and Grosse, Kathrin and Demontis, Ambra and Vascon, Sebastiano and Zellinger, Werner and Moser, Bernhard A. and Oprea, Alina and Biggio, Battista and Pelillo, Marcello and Roli, Fabio},
title = {Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {13s},
journal = {ACM Comput. Surv.},
articleno = {294},
numpages = {39},
keywords = {Poisoning attacks, backdoor attacks, machine learning, computer vision, computer security}
}

@InProceedings{xian2023understanding,
  title = 	 {Understanding Backdoor Attacks through the Adaptability Hypothesis},
  author =       {Xian, Xun and Wang, Ganghua and Srinivasa, Jayanth and Kundu, Ashish and Bi, Xuan and Hong, Mingyi and Ding, Jie},
  booktitle = 	 {Proceedings of the International Conference on Machine Learning},
  pages = 	 {37952--37976},
  year = 	 {2023}
}

@inproceedings{wang2023demystifying,
  title = {Demystifying Poisoning Backdoor Attacks from a Statistical Perspective},
  author = {Wang, Ganghua and Xian, Xun and Srinivasa, Jayanth and Kundu, Ashish and Bi, Xuan and Hong, Mingyi and Ding, Jie},
  corresponding = {Ganghua Wang and Xun Xian},
  equalcontribution = {true},
  booktitle = {International Conference on Learning Representations},
  year = {2024}
}

@inproceedings{li2024backdoorcnn,
author = {Li, Boqi and Liu, Weiwei},
title = {A theoretical analysis of backdoor poisoning attacks in convolutional neural networks},
year = {2024},
booktitle = {Proceedings of the International Conference on Machine Learning},
articleno = {1136},
numpages = {34},
location = {Vienna, Austria}
}

@article{cina2022backdoorlearningcurvesexplaining,
  title    = {Backdoor learning curves: Explaining backdoor poisoning beyond
              influence functions},
  author   = {Cin{\`a}, Antonio Emanuele and Grosse, Kathrin and Vascon,
              Sebastiano and Demontis, Ambra and Biggio, Battista and Roli,
              Fabio and Pelillo, Marcello},
  journal  = {International Journal of Machine Learning and Cybernetics},
  year     =  2024
}

@inproceedings{hardt2016strategicclassification,
author = {Hardt, Moritz and Megiddo, Nimrod and Papadimitriou, Christos and Wootters, Mary},
title = {Strategic Classification},
year = {2016},
booktitle = {Proceedings of the Conference on Innovations in Theoretical Computer Science},
pages = {111–122},
numpages = {12},
keywords = {classification, game theory, learning theory},
location = {Cambridge, Massachusetts, USA}
}

@inproceedings{zrnic2021wholeads,
author = {Zrnic, Tijana and Mazumdar, Eric and Sastry, S. Shankar and Jordan, Michael I.},
title = {Who leads and who follows in strategic classification?},
year = {2021},
booktitle = {Proceedings of the International Conference on Neural Information Processing Systems},
articleno = {1169},
numpages = {13},
}

@article{albert2020politicsadversarialmachinelearning,
   title={Politics of Adversarial Machine Learning},
   author={Kendra Albert and Jonathon Penney and Bruce Schneier and Ram Shankar Siva Kumar},
   journal={arXiv preprint arXiv:2002.05648},
   year={2020}
}

@inproceedings{vincent2021dataleverage,
author = {Vincent, Nicholas and Li, Hanlin and Tilly, Nicole and Chancellor, Stevie and Hecht, Brent},
title = {Data Leverage: A Framework for Empowering the Public in its Relationship with Technology Companies},
year = {2021},
booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
pages = {215–227},
numpages = {13},
keywords = {conscious data contribution, data leverage, data poisoning, data strikes},
location = {Virtual Event, Canada}
}

@article{albert2021adversarialgoodadversarialml,
   title={Adversarial for Good? {H}ow the Adversarial {ML} Community's Values Impede Socially Beneficial Uses of Attacks},
   author={Kendra Albert and Maggie Delano and Bogdan Kulynych and Ram Shankar Siva Kumar},
   journal={arXiv preprint arXiv:2107.10302},
   year={2021}
}

@article{creager2023online,
   title={Online algorithmic recourse by collective action},
   author={Creager, Elliot and Zemel, Richard},
   journal={ICML Workshop on Algorithmic Recourse},
   year={2021}
}

@inproceedings{vincent2019strikes,
author = {Vincent, Nicholas and Hecht, Brent and Sen, Shilad},
title = {``{D}ata Strikes”: Evaluating the Effectiveness of a New Form of Collective Action Against Technology Companies},
year = {2019},
booktitle = {The World Wide Web Conference},
pages = {1931–1943},
numpages = {13},
keywords = {Data strikes, online collective action, recommender systems}
}

@article{vincent2021datacontribution,
author = {Vincent, Nicholas and Hecht, Brent},
title = {Can ``Conscious Data Contribution" Help Users to Exert ``Data Leverage" Against Technology Companies?},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
journal = {Proc. ACM Hum.-Comput. Interact.},
articleno = {103},
numpages = {23},
keywords = {conscious data contribution, data as labor, data leverage}
}

@article{howardEtAl,
    author = {Steven R. Howard and Aaditya Ramdas and Jon McAuliffe and Jasjeet Sekhon},
    title = {Time-uniform {C}hernoff bounds via nonnegative supermartingales},
    volume = {17},
    pages = {257-317},
    journal = {Probability Surveys},
    year = 2020
}