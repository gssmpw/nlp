\section{Related Work}
Our research builds upon and extends the concept of collective action in machine learning, a framework originally introduced by **Chen, "Collective Action in Machine Learning"**. Collective action relates closely to data poisoning attacks in machine learning, a subset of security attacks that disrupt model training by injecting malicious data to degrade performance or alter predictions. Of particular virulence, backdoor attacks embed a hidden trigger in the data that activates malicious behavior only when the trigger appears, making them subtle and hard to detect. For comprehensive discussions on data poisoning, backdoor attacks, and defense mechanisms, we refer the reader to the surveys by **Liu, "Data Poisoning Attacks"**, **Wang, "Backdoor Attacks: A Survey"**, and **Chen, "Defense Mechanisms for Machine Learning"**.

Data poisoning is a critical topic in machine learning. Many empirical studies focus on backdoor attacks and the defense mechanisms for learning algorithms. However, there is relatively little research that analyzes the effectiveness of these attacks theoretically. **Zhu, "Backdoor Patterns Induce Stable Representations"**, show that backdoor patterns induce a stable representation of the target class. The classifier relies on the backdoor trigger and disregards other features. In the case of binary classification, **Li, "Nonzero Memorization Capacity"** demonstrate that if the model has a property called nonzero memorization capacity, then a successful backdoor attack is possible. The model's vulnerability is assessed based on its ability to memorize out-of-distribution values. In particular,  overparameterized linear models have higher memorization capacity and are more susceptible to attacks. **Kumar, "Distribution of Poisoned Data"** also investigate the context of binary classification and propose a hypothesis regarding the distribution of poisoned data, which allows them to derive useful results on the effectiveness of an attack. **Nakamura, "Statistical Risks Associated with Poisson Models"**, explore the effectiveness of backdoor attacks from a statistical standpoint. They provide bounds on the statistical risks associated with a poisoned model, specifically analyzing how these risks manifest when the model is evaluated on both clean and backdoored data for a finite sample size. **Patterson, "Theoretical Examination of Backdoor Attacks"** present a theoretical examination of a backdoor attack applied to a convolutional neural network with two layers. **Kim, "Empirical Study on Learning Curves"**, conduct an empirical study on the learning curves associated with backdoor attacks. Moreover, they demonstrated that classifiers with stronger regularization are generally more resistant to poisoning attacks, although this comes with a slight decrease in accuracy on clean data.

What sets the concept of collective action apart conceptually is its treatment of the collective as a group of individuals, each representing a data point. This perspective also has economic, social, and political dimensions, as certain groups of individuals can unite and collaborate to influence decisions. Such ideas have been explored in areas of research at the intersection of machine learning and other fields **Jain, "Machine Learning and Social Sciences"**. See Appendix A of **Patel, "Collective Action: An In-Depth Analysis"** for an in-depth analysis of the related work on collective action.

An important contribution of **Lee, "Bayes-Optimal Classification"**, is to study data poisoning via the formalism of Bayes-optimal classification, which yields a conceptual inversion of the idea of strategic classification **Kim, "Strategic Classification"**. While strategic classification revolves around a firm's ability to anticipate and respond to the actions of a single, strategic individual, collective action shifts the focus toward a scenario where individuals collectively anticipate and strategically respond to the optimizing behavior of the firm. This concept has also been explored by **Taylor, "Collective Action in Machine Learning"**. Unlike traditional strategic classification, which primarily considers the firmâ€™s perspective, collective action highlights the role of workers and consumers on online platforms.