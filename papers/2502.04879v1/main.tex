\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{bbold}
\usepackage{multirow}
\usepackage{geometry}
\usepackage{natbib}
\usepackage{parskip}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{authblk}

\geometry{a4paper, margin=1in}

\usepackage[colorlinks,citecolor=blue,linkcolor=blue,urlcolor=blue]{hyperref}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage[capitalize,noabbrev]{cleveref}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\crefname{hypothesis}{Assumption}{Hypotheses}
\newcommand{\hypothesis}[2]{%
  \refstepcounter{hypothesis}%
  \noindent\textbf{Assumption (A#1):} \textit{#2} \label{hyp:A#1}%
}

\newcounter{hypothesis}

\title{Statistical Collusion by Collectives on Learning Platforms}

\author[1]{Etienne Gauthier\thanks{\texttt{etienne.gauthier@inria.fr}}}
\author[1]{Francis Bach}
\author[1,2]{Michael I. Jordan}

\affil[1]{Inria, Ecole Normale Supérieure, PSL Research University}
\affil[2]{Department of Electrical Engineering and Computer Sciences, University of California, Berkeley}

\renewcommand\Authands{ and }

\begin{document}

\maketitle

\begin{abstract}
As platforms increasingly rely on learning algorithms, collectives may form and seek ways to influence these platforms to align with their own interests. This can be achieved by coordinated submission of altered data. To evaluate the potential impact of such behavior, it is essential to understand the computations that collectives must perform to impact platforms in this way. In particular, collectives need to make a priori assessments of the effect of the collective before taking action, as they may face potential risks when modifying their data. Moreover they need to develop implementable coordination algorithms based on quantities that can be inferred from observed data. We develop a framework that provides a theoretical and algorithmic treatment of these issues and present experimental results in a product evaluation domain.
\end{abstract}

\section{Introduction}
The dynamic interaction among agents and algorithms creates a complex ecosystem where unanticipated individual and collective behavior can emerge. The study of such behavior is crucial for understanding how to design systems that are robust, fair, and aligned with societal values. 

In a network, agents often have diverse motivations and multiple incentives. When the incentives of the interacting agents do not fully align with those of the designer of the learning system, the former may wish to influence the learning process.  This becomes salient in the common case in which a learning system interacts with a large number of agents. Such agents may collaborate, forming a cartel, by pooling their data and devising a common strategy.  Accordingly, even if the learning algorithm is robust to single-agent adversarial behavior, the collective may be able to exert a significant influence on the algorithm. This concept of collective action has its origins in economic theories \cite{olson1965logic} and has been more recently explored in the context of machine learning \cite{hardt2023collectiveaction}. It is crucial to understand how such collectives can influence learning algorithms to better comprehend the dynamics within the network of agents and to deploy algorithms that are reliable and aligned with the majority interests of consumers. We will focus specifically on the case of a platform that deploys a learning algorithm and interacts with a population of consumers. 

\vspace{-0.19em}
\paragraph{Collective Action in Machine Learning.}

We draw on the work of \citet{hardt2023collectiveaction}, who investigate the following problem: a population of individuals $(x,y) \in \mathcal{X} \times \mathcal{Y}$, drawn i.i.d.~from a distribution $\mathcal{D}$, interacts with a platform. A collective of relative size $\alpha \in (0,1)$ forms within this population with the goal of influencing the platform. The collective's influence is quantified by a success metric~$S(\alpha)$, the definition of which depends on the collective's objective. To influence the platform, members of the collective modify their data according to a common strategy~$h: \mathcal{X}\times\mathcal{Y} \rightarrow  \mathcal{X}\times\mathcal{Y}$, which maps the original features and labels of the data to modified features and labels. The platform observes a mixture of distributions $\alpha \tilde{\mathcal{D}} + (1-\alpha)\mathcal{D}$, where $\tilde{\mathcal{D}}$ is the distribution of $h(z)$ with $z \sim \mathcal{D}$. The platform selects a classifier based on this distribution. Thus, the objective for the collective is to choose a strategy $h$ that maximizes its success~$S(\alpha)$. \citet{hardt2023collectiveaction} propose strategies $h$ for two distinct goals: \emph{signal planting} and \emph{signal erasing}. They derive lower bounds on the success $S(\alpha)$, enabling the identification of a minimum collective size $\alpha^*$ such that $S(\alpha) \ge S^*$ for all $\alpha \ge \alpha^*$, where $S^*$ is a target threshold.

Unfortunately, several of the strategies $h$ studied by \citet{hardt2023collectiveaction} are not available in practice to the collective. Furthermore, the bounds obtained on the success $S(\alpha)$ depend on key parameters that are unknown to the collective. Lastly, in practice, the collective seeks a priori guarantees of success before altering its data, as modifying the data may expose members to risk. In this paper, we introduce a new framework to enable members of the collective to learn strategies $h$ efficiently and to infer the parameters that determine their success on the platform.

\paragraph{Contributions.}

Our primary contribution is the introduction of a novel framework which empowers collectives via statistical inference. This statistical framework allows for the derivation of three key results, each tied to a distinct objective that a collective may pursue to influence a platform: signal planting, signal erasing, and a new objective we introduce, \emph{signal unplanting}.

We thoroughly explore strategies that a collective can employ to achieve each of these goals and provide theoretical guarantees for the effectiveness of these strategies. The statistical inference capabilities of the collective serve two main purposes: first, to estimate the most effective strategies for influencing the platform, and second, to infer key parameters that determine the collective’s success. This dual approach allows the collective to predict its potential impact on the platform with high probability.

Our framework reduces to that of \citet{hardt2023collectiveaction} in the infinite data regime, although we note that we improve on earlier results in this regime---our lower bounds are tighter than those from \citet{hardt2023collectiveaction}. Our main focus, however, is the setting in which the signal set is finite.  We obtain bounds in this setting that form staircase-like curves. This result provides a new interpretation of data poisoning bounds: the success of attacks depends not just on the signal set to be poisoned as a whole but more precisely on each feature within it. Each feature has a resistance to poisoning, requiring a specific level of attack to breach it, resulting in these staircase patterns. When the steps are close enough, these curves resemble the smooth sigmoid shapes seen in data poisoning literature.

We construct a synthetic dataset to validate our theoretical findings and to examine the influence of various parameters empirically. Our empirical results highlight, among other things, that the effectiveness of the collective depends not only on its \emph{relative} size compared to the total number of agents interacting with the platform but also on its \emph{absolute} size. A larger collective, in absolute terms, can obtain better statistical estimates and thus more accurately infer optimal strategies. This result implies that larger platforms may be more vulnerable to collective action. 

\section{Related Work}
Our research builds upon and extends the concept of collective action in machine learning, a framework originally introduced by \citet{hardt2023collectiveaction}. Collective action relates closely to data poisoning attacks in machine learning, a subset of security attacks that disrupt model training by injecting malicious data to degrade performance or alter predictions. Of particular virulence, backdoor attacks embed a hidden trigger in the data that activates malicious behavior only when the trigger appears, making them subtle and hard to detect. For comprehensive discussions on data poisoning, backdoor attacks, and defense mechanisms, we refer the reader to the surveys by \citet{tian2022survey}, \citet{guo2021survey}, and \citet{cina2023survey}.

Data poisoning is a critical topic in machine learning. Many empirical studies focus on backdoor attacks and the defense mechanisms for learning algorithms. However, there is relatively little research that analyzes the effectiveness of these attacks theoretically. \citet{grosse2022backdoor} show that backdoor patterns induce a stable representation of the target class. The classifier relies on the backdoor trigger and disregards other features. In the case of binary classification, \citet{manoj2021backdoor} demonstrate that if the model has a property called nonzero memorization capacity, then a successful backdoor attack is possible. The model's vulnerability is assessed based on its ability to memorize out-of-distribution values. In particular,  overparameterized
linear models have higher memorization capacity and are more susceptible to attacks. \citet{xian2023understanding} also investigate the context of binary classification and propose a hypothesis regarding the distribution of poisoned data, which allows them to derive useful results on the effectiveness of an attack. \citet{wang2023demystifying} explore the effectiveness of backdoor attacks from a statistical standpoint. They provide bounds on the statistical risks associated with a poisoned model, specifically analyzing how these risks manifest when the model is evaluated on both clean and backdoored data for a finite sample size. \citet{li2024backdoorcnn} present a theoretical examination of a backdoor attack applied to a convolutional neural network with two layers. \citet{cina2022backdoorlearningcurvesexplaining}  conduct an empirical study on the learning curves associated with backdoor attacks. Moreover, they demonstrated that classifiers with stronger regularization are generally more resistant to poisoning attacks, although this comes with a slight decrease in accuracy on clean data. 

What sets the concept of collective action apart conceptually is its treatment of the collective as a group of individuals, each representing a data point. This perspective also has economic, social, and political dimensions, as certain groups of individuals can unite and collaborate to influence decisions. Such ideas have been explored in areas of research at the intersection of machine learning and other fields \cite{vincent2019strikes, albert2020politicsadversarialmachinelearning, vincent2021dataleverage, albert2021adversarialgoodadversarialml, creager2023online,  vincent2021datacontribution}. See Appendix A of \citet{hardt2023collectiveaction} for an in-depth analysis of the related work on collective action.

An important contribution of \citet{hardt2023collectiveaction} is to study data poisoning via the formalism of Bayes-optimal classification, which yields a conceptual inversion of the idea of strategic classification \cite{hardt2016strategicclassification}. While strategic classification revolves around a firm's ability to anticipate and respond to the actions of a single, strategic individual, collective action shifts the focus toward a scenario where individuals collectively anticipate and strategically respond to the optimizing behavior of the firm. This concept has also been explored by \citet{zrnic2021wholeads}. Unlike traditional strategic classification, which primarily considers the firm’s perspective, collective action highlights the role of workers and consumers on online platforms.

\section{Statistical Algorithmic Collective Action in Classification}

First, we will describe the new setting for deriving theoretical bounds in collective action that are effectively computable by the collective. We then present our three main results, which   address three different objectives for the collective. Two of these objectives are classic goals of collective action: signal planting and signal erasing. Additionally, we introduce a new objective: signal unplanting, where the collective aims to prevent an association between the signal set and a certain label. We will explore strategies and provide theoretical guarantees for each of these objectives.

\subsection{Setting}

We consider a platform that deploys a learning algorithm in a universe $\mathcal{X} \times \mathcal{Y}$. We assume that $\mathcal{X} \times \mathcal{Y}$ is finite. Each individual corresponds to a single data point $(x,y) \in \mathcal{X} \times \mathcal{Y}$.

The platform trains a classifier $\hat{f}$ on a training dataset. The training dataset is composed of $N$ consumers which are initially drawn i.i.d.\ according to some distribution $\mathcal{D}$. Among these consumers, a certain number $n < N$ forms a collective to strategically influence the firm's behavior. The collective shares a common strategy $h: \mathcal{X} \times \mathcal{Y} \rightarrow \mathcal{X} \times \mathcal{Y}$. The $N-n$ base consumers and the $n$ members of the collective together form an empirical distribution of consumers $\hat{\mathcal{P}}$, and the corresponding dataset constitutes the training set. The collective wants to obtain guarantees on the influence they have on the platform at test time.

\textbf{Notation.} Given a distribution $\mathcal{Q}$ over $\mathcal{X} \times \mathcal{Y}$, we denote by $\mathcal{Q}_\mathcal{X}$ the marginal distribution over features. We will  simply write $\mathcal{Q}$ when the context allows. We denote by $\tilde{\mathcal{D}}$ the distribution of $h(z), z \sim \mathcal{D}$. More generally, for a dataset $D$, we write $\tilde{D}:= \{h(z) \mid z \in D \}$ (as a multiset) for the same dataset after applying strategy~$h$. We will also write, for $E \subseteq \mathcal{X} \times \mathcal{Y}$, $\underset{z \sim D}{\hat{\mathbb{P}}}(z \in E) := \frac{1}{\# D } \sum_{z_i \in D} \mathbb{1}_{\left\{z_i \in E \right\}}$ the empirical probability of the event $E$ induced by a dataset~$D$. We use $\hat{\mathbb{P}}$ to denote empirical probabilities, and $\mathbb{P}$ for population probabilities. When the variables do not need to be explicitly stated, we may write $\underset{D}{\hat{\mathbb{P}}}(E)$ and $\underset{D}{\mathbb{P}}(E)$  instead of $\underset{z \sim D}{\hat{\mathbb{P}}}(z \in E)$ and $\underset{z \sim D}{\hat{\mathbb{P}}}(z \in E)$ respectively.

\textbf{The collective.} Given a test set of consumers $D_{\rm test} \overset{i.i.d.}{\sim} \mathcal{D}$, the collective's goal is to obtain guarantees with high probability on their success $\hat{S}(n)$ as a function of $D_{\rm test}$. The definition of $\hat{S}(n)$ is based on the objective desired by the collective. We will consider three objectives: signal planting, signal unplanting, and signal erasing. The collective modifies its data using strategy $h$ to maximize its success. 

We assume that the collective has access to the value $N$. This is a weak assumption because it is common in practice. For example, if the platform is a polling institute seeking to understand participants' voting preferences based on their demographic data, the total number of people surveyed is usually publicly available. 

Unless stated otherwise, the collective has access only to their own data and not to the data of consumers who are not part of the collective. The collective can pool its data to infer quantities that depend on the underlying distribution. Throughout this paper, we will use Hoeffding's concentration inequality (Lemma \ref{lma:hoeffding}) for  simplicity. We will denote Hoeffding error terms as follows:
\[
R_{\delta}(k) := \sqrt{\frac{\log(1/\delta)}{2k}},
\]
for any $\delta > 0$ and $k \in \mathbb{N^*}$. We note that Hoeffding’s inequality can be loose, for example when applied to sums of Bernoulli random variables with means close to zero. One can address this issue by using other concentration inequalities such as Bernstein; the framework we present here can readily incorporate such choices.

\textbf{The platform.} The firm observes an empirical distribution of consumers $\hat{\mathcal{P}}$. It selects a classifier $\hat{f}$ based on this distribution $\hat{\mathcal{P}}$. Following \citet{hardt2023collectiveaction}, we characterize classifiers $\hat{f}$ by their suboptimality in terms of total variation distance with respect to the observed distribution $\hat{\mathcal{P}}$:

\begin{definition}
Let  $\varepsilon> 0$. A classifier $\hat{f}: \mathcal{X} \rightarrow \mathcal{Y}$ is $\varepsilon$-suboptimal on a set $\mathcal{X}' \subseteq \mathcal{X}$ under the distribution $\hat{\mathcal{P}}$ if there exists a distribution $\tilde{\mathcal{P}}$ with $TV(\hat{\mathcal{P}}, \tilde{\mathcal{P}}) \le \varepsilon$ such that
\[
\hat{f}(x) \in \underset{y \in \mathcal{Y}}{\text{argmax }} \tilde{\mathcal{P}}(x,y)
\]
for all $x \in \mathcal{X}'$. Here, $TV(\hat{\mathcal{P}}, \tilde{\mathcal{P}}) := \displaystyle\sup_{E \subseteq \mathcal{X}\times\mathcal{Y}} \lvert \hat{\mathcal{P}}(E)- \tilde{\mathcal{P}}(E)\rvert$ denotes the total variation distance between $\hat{\mathcal{P}}$ and $\tilde{\mathcal{P}}$.
\end{definition}

The parameter $\varepsilon$ roughly controls how much the classifier can make use of statistics that go beyond simple frequency counts. It accounts for classifiers that consider feature interactions and capture complex patterns in the data.

\subsection{Signal planting}

In signal planting, we are given a transformation $g:\mathcal{X} \rightarrow \mathcal{X}$ and a target label $y^* \in \mathcal{Y}$. The map $g$ induces a signal set defined by $\tilde{\mathcal{X}} := \{g(x) \mid x \in \mathcal{X} \}$. The success is defined as
\[
\hat{S}(n) := \underset{x \sim D_{\rm test}}{\hat{\mathbb{P}}}(\hat{f}(g(x)) = y^*),
\]
where $D_{\rm test} \overset{i.i.d.}{\sim} \mathcal{D}$ is the test set. In other words, the collective aims to enforce an association between the signal set $\tilde{\mathcal{X}}$ and a target label $y^*$ at test time.

\subsubsection{Feature-label signal planting}

A natural goal for the collective is to maximize its success, $\hat{S}(n)$. To ensure that its efforts are effective, the collective aims to establish theoretical lower bounds on $\hat{S}(n)$, as these provide a guarantee of success. To do so, the collective can play the feature-label signal planting strategy defined below. 

\begin{definition}[Feature-label signal planting strategy]
\label{def:fl_strat}
We define the \emph{feature-label signal planting strategy} as
\[ h(x, y) = (g(x), y^*) . \]
\end{definition}

We analyze the effect of this strategy on the learning platform. Formally, we are given three independent datasets: a dataset $D^{(n)} \overset{i.i.d.}{\sim} \mathcal{D}$ of $n$ consumers which are part of the collective; a dataset $D^{(N-n)} \overset{i.i.d.}{\sim} \mathcal{D}$ of $N-n$ consumers which are not part of the collective; and a dataset $D_{\rm test} \overset{i.i.d.}{\sim} \mathcal{D}$ of $N_{\rm test}$ consumers forming the test dataset. We recall that $\tilde{D}^{(n)} := \{h(z) \mid z \in  D^{(n)}\}$ (as a multiset). The training set of the platform's classifier is the concatenation of $\tilde{D}^{(n)}$ and $D^{(N-n)}$. In other words, the platform observes the distribution:
\[
\hat{\mathcal{P}}(x_0, y_0) := \frac{n}{N} \underset{\tilde{D}^{(n)}}{\hat{\mathbb{P}}}(x_0, y_0) + \frac{N-n}{N} \underset{D^{(N-n)}}{\hat{\mathbb{P}}}(x_0, y_0).
\]
The platform then chooses a classifier $\hat{f}$ based on $\hat{\mathcal{P}}$. We can now state the main result for signal planting:

\begin{theorem}[Signal planting lower bound, feature-label signal planting strategy]
\label{thm:sp}
    Let $\delta > 0$, and write $\tilde{\delta} := \delta /(2 + 2\# \tilde{\mathcal{X}} + 2\# \tilde{\mathcal{X}}\# \mathcal{Y})$. Then, by playing the feature-label signal planting strategy against a classifier that is $\varepsilon$-suboptimal on $\tilde{\mathcal{X}}$, the collective achieves with probability at least $1 - \delta$ (over the draw of the consumers):
    \begin{align}
    \label{ineq:sp}
    \begin{split}
        \hat{S}(n) &\ge \underset{\tilde{x} \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}} \left[  \frac{n}{N}\left(\underset{\tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}) - 2R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n)\right)- \frac{\varepsilon}{1-\varepsilon}> 0 \right]\\
        &\quad - R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test}),
    \end{split}
    \end{align}
    where
    $\Delta_{\tilde{x}}^{(n)} := \underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\max } \underset{D^{(n)} }{\hat{\mathbb{P}}}(\tilde{x},y') - \underset{D^{(n)} }{\hat{\mathbb{P}}}(\tilde{x}, y^*)$.
\end{theorem}

Proofs and additional remarks can be found in Appendix~\ref{app:theorems}. Note that lower bound (\ref{ineq:sp}) is fully computable by the collective as it depends only on datasets $D^{(n)}$ and $\tilde{D}^{(n)}$. $D^{(n)}$ is obtained through data pooling by the collective’s members, and $\tilde{D}^{(n)}$ is computed by applying strategy $h$ to the dataset~$D^{(n)}$. Details on the algorithm for computing the lower bound are provided in Appendix \ref{app:algo}, and the code is available at \url{https://github.com/GauthierE/statistical-collusion}.

The interpretation of lower bound (\ref{ineq:sp}) is that success increases step by step: each feature $\tilde{x}$ in the signal set $\tilde{\mathcal{X}}$ has a certain \emph{resistance} to being planted. As the relative size of the collective $n/N$ gradually increases, features $\tilde{x}$ are \emph{cracked} as their resistance breaks, in decreasing order of resistance. Fo each feature $\tilde{x}$, its resistance depends on three terms.  The first one, here $\frac{n}{N}(\underset{\tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}) - 2R_{\tilde{\delta}}(n))$, represents how prevalent the feature $\tilde{x}$ is in the modified data: the more frequently $\tilde{x}$ appears in the poisoned data, the greater the collective's ability to influence the associated label. The second term, here $-\frac{N-n}{N} (\Delta_{\tilde{x}}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n))$, captures the counteracting influence of non-collective individuals in the population, quantifying how much they might limit the collective's success in planting the signal. It indicates how strongly the target label is associated with the signal set: the more frequent $y^*$ is in the signal set, the easier it is to plant the signal; if other labels are far more likely than $y^*$, planting the signal becomes more difficult. The third term, $- \frac{\varepsilon}{1-\varepsilon}$, represents the platform's ability to adapt to the distribution of its users. As $\varepsilon \mapsto \frac{\varepsilon}{1-\varepsilon}$ increases with $\varepsilon$, it benefits the collective to have $\varepsilon$ close to zero, limiting the platform's flexibility and resulting in a tighter bound.

The first term scales approximately linearly with $n$, by a factor of $n/N$, while the second term decreases by $1-n/N$. However, the dependence is more complex than purely linear. The bound involves estimation terms $R_{\tilde{\delta}}(n)$, which decay at a rate proportional to $n^{-1/2}$  as $n$ increases. The bound also depends on $R_{\tilde{\delta}}(N-n)$, but these terms can be negligible as long as $n$ remains much smaller than $N$.

Also, the cardinality of $\tilde{\mathcal{X}}$ affects the definition of $\tilde{\delta}$, and thus the estimation terms $R_{\tilde{\delta}}$. The smaller $\#\tilde{\mathcal{X}}$ is, the better the collective's estimates will be, resulting in sharper bounds.

\subsubsection{Feature-only signal planting}

Note that the feature-label signal planting strategy assumes that the members of the collective can change both their features and their labels. This might not always be feasible in practice, where labels can be immutable. In this situation, a natural strategy for the collective is to change its feature $x$ to $g(x)$ when $y=y^*$. This strategy was explored by \citet{hardt2023collectiveaction}. However, it is preferable for the collective to additionally change its feature $x$ to some $x_0$ that is not in the signal set $\tilde{\mathcal{X}}$ when $y \neq y^*$. This ensures that not only does the feature belong to the signal set $\tilde{\mathcal{X}}$ when the label is $y^*$, but also that if a feature is in the signal set $\tilde{\mathcal{X}}$, the associated label is necessarily $y^*$. This dual condition strengthens the association between the signal set $\tilde{\mathcal{X}}$ and the target label $y^*$. In this case, we can directly say that the term $\underset{\tilde{D}^{(n)} }{\hat{\mathbb{P}}}(g(x'),y')$ with $y' \neq y^*$ that would appear in the proof of Theorem \ref{thm:sp_fo} is equal to zero, leading to a sharper bound.

\begin{definition}[Feature-only signal planting strategy]
\label{def:fo_strat}
We define the feature-only signal planting strategy as
\[
h(x, y) =
\begin{cases} 
(g(x), y^*) & \text{if } y = y^*, \\
(x_0, y) & \text{otherwise},
\end{cases}
\]
where $x_0 \in \mathcal{X} \backslash \tilde{\mathcal{X}}$ is any feature that does not belong to the signal set $\tilde{\mathcal{X}}$. Note that $x_0$ does not have to be fixed across all initial data points $(x,y)$. 
\end{definition}

We can generalize Theorem \ref{thm:sp} to the feature-only strategy:

\begin{theorem}[Signal planting lower bound, feature-only signal planting strategy]
\label{thm:sp_fo}
    Let $\delta > 0$, and write $\tilde{\delta} := \delta /(2 +  2\# \tilde{\mathcal{X}} +  2\# \tilde{\mathcal{X}}\# \mathcal{Y})$. Then, by playing the feature-only signal planting strategy against a classifier that is $\varepsilon$-suboptimal on $\tilde{\mathcal{X}}$, the collective achieves with probability at least $1 - \delta$ (over the draw of the consumers):
    \begin{align}
    \label{ineq:sp_fo}
    \begin{split}
        \hat{S}(n) &\ge \underset{x' \sim D^{(n)}}{\hat{\mathbb{P}}} \left[  \frac{n}{N}\left(\underset{\tilde{D}^{(n)} }{\hat{\mathbb{P}}}(g(x'), y^*) - 2R_{\tilde{\delta}}(n)\right)-\frac{N-n}{N} \left(\Delta_{g(x')}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n)\right)- \frac{\varepsilon}{1-\varepsilon}> 0 \right]\\
        &\quad- R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test}),
    \end{split}
    \end{align}
where $\Delta_{g(x')}^{(n)}$ is defined in Theorem \ref{thm:sp}.
\end{theorem}

We can straightforwardly compare lower bounds (\ref{ineq:sp}) and (\ref{ineq:sp_fo}). The only difference is that in (\ref{ineq:sp_fo}), we have $\underset{\tilde{D}^{(n)} }{\hat{\mathbb{P}}}(g(x'),y^*)$ instead of $\underset{\tilde{D}^{(n)} }{\hat{\mathbb{P}}}(g(x'))$. This comparison directly measures the impact of not modifying labels on the collective's influence. In the following, we will always assume that the collective can modify its labels.

Signal planting relies on a straightforward strategy: flooding the platform with as many pairs $(g(x),y^*)$ as possible. This strategy is simple and does not require the collective to perform any statistical estimation. Statistical inference is only necessary for the collective to calculate the lower bound on success, not for defining the optimal strategy $h$. In the next two sections, we examine two objectives that additionally require statistical estimation to infer the optimal strategy $h$: signal unplanting and signal erasing.

\subsection{Signal unplanting}

The setting is essentially the same as before; the only difference is the success of the collective is defined as follows:
\[
\hat{S}(n) := \underset{x \sim D_{\rm test}}{\hat{\mathbb{P}}}\left(\hat{f}(g(x)) \neq y^*\right).
\]
The collective’s goal is now to prevent an association between the signal set $\tilde{\mathcal{X}} = \{g(x) \mid x \in \mathcal{X}\}$ and the target label $y^*$.

\subsubsection{Naive strategy}

A simple and naive strategy for the collective is to flood the platform with feature-label pairs of the form $(g(x),y')$ for some fixed $y' \neq y^*$. Indeed, for any $y' \neq y^*$, we have that
\begin{align*}
    \hat{S}(n) &= \underset{x \sim D_{\rm test}}{\hat{\mathbb{P}}}\left(\hat{f}(g(x)) \neq y^*\right) \\
    &\ge \underset{x \sim D_{\rm test}}{\hat{\mathbb{P}}}\left( \hat{f}(g(x)) = y'\right) =: \hat{S}_{y'}(n).
\end{align*}
Therefore, the collective can compute lower bounds on~$\hat{S}_{y'}(n)$ for all $y' \neq y^*$ using Theorem \ref{thm:sp}. It can then play the strategy $h(x,y)=(g(x),\bar{y})$ where $\bar{y}$ is the label that maximizes the lower bounds on $\hat{S}_{y'}(n)$ for $y' \neq y^*$. Note that this is equivalent to planting a signal with transformation $g$ and target label $\bar{y}$, so we obtain the same guarantees as in Theorem \ref{thm:sp}.

\subsubsection{Adaptive strategy}

The collective can also use an adaptive strategy, meaning that each member of the collective $(x,y)$ can change its feature-label pair to some $(g(x), y_{g(x)})$ where the modified label $y_{g(x)}$ depends on $g(x)$ and is no longer fixed. The plan for the collective is to estimate the optimal label using a subset of $n_{\rm est} < n$ randomly chosen participants. Formally, we assume that $D^{(n)}$ is the concatenation of two independent datasets $D^{(n_{\rm est})}$ and $D^{(n-n_{\rm est})}$ drawn from $\mathcal{D}$. A natural strategy for the collective is to change every pair $(x,y)$ into $(g(x),\hat{y}_{g(x)})$ where for $\tilde{x} \in \tilde{\mathcal{X}}$:
\begin{equation}
\label{def:y_unplanting}
\hat{y}_{\tilde{x}} := \underset{y' \in \mathcal{Y}\backslash\{y^*\}}{\text{argmax }} \underset{D^{(n_{\rm est})} }{\hat{\mathbb{P}}}(\tilde{x}, y' ).
\end{equation}

We formalize this strategy in the following definition.

\begin{definition}[Signal unplanting strategy]
\label{def:su_strat}
We define the \emph{signal unplanting strategy} as
\[
h(x, y) = (g(x), \hat{y}_{g(x)}),
\]
where $\hat{y}_{\tilde{x}}$ is defined in Equation (\ref{def:y_unplanting}). 
\end{definition}

Intuitively, this strategy means that the collective aims to select the most likely label among all labels different from~$y^*$, given a feature $g(x)$.

\begin{theorem}[Signal unplanting lower bound]
\label{thm:su}
    Let $\delta > 0$, and write $\tilde{\delta} := \delta /(2 + 6\# \tilde{\mathcal{X}})$. Let $n_{\rm est} < n$. Then, by playing the signal unplanting strategy above against a classifier that is $\varepsilon$-suboptimal on $\tilde{\mathcal{X}}$, the collective achieves with probability at least $1 - \delta$ (over the draw of the consumers):
    \begin{align}
    \label{ineq:su}
    \begin{split}
        \hat{S}(n) &\ge \underset{\tilde{x} \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}} \left[  \frac{n}{N}\left(\underset{ \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}) - 2R_{\tilde{\delta}}(n)\right)-\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(n-n_{\rm est})} + 2R_{\tilde{\delta}}(n-n_{\rm est}) + 2R_{\tilde{\delta}}(N-n)\right)- \frac{\varepsilon}{1-\varepsilon}> 0 \right]\\
        &\quad - R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test}),
    \end{split}
    \end{align}
    where $\Delta_{\tilde{x}}^{(n-n_{\rm est})} := \underset{D^{(n-n_{\rm est})} }{\hat{\mathbb{P}}}(\tilde{x},y^*) - \underset{D^{(n-n_{\rm est})} }{\hat{\mathbb{P}}}(\tilde{x}, \hat{y}_{\tilde{x}})$.
\end{theorem}

\subsection{Signal erasing}

In the previous subsections, we examined how the collective can plant a signal by using a natural strategy, which consists in simply flooding the platform with feature-label pairs of the form $h(x,y) = (g(x), y^*)$, and how it can unplant a signal by estimating the most probable label different from $y^*$. In this section, we study another objective: signal erasing.

We consider a transformation $g: \mathcal{X} \rightarrow \mathcal{X}$. The success of the collective is now defined by:
\[
\hat{S}(n) := \underset{x \sim D_{\rm test}}{\hat{\mathbb{P}}}\left(\hat{f}(g(x)) = \hat{f}(x)\right).
\]
As outlined by \citet{hardt2023collectiveaction}, maximizing $\hat{S}(n)$ aligns with reducing the impact of $g$ on the learning algorithm. The term signal erasing is motivated by the example in tabular data where $g$ preserves certain features while removing others, for instance by setting some features to a fixed value. This effectively removes the impact of the erased features, provided these features are independent of the other ones.

In this part, we will make the following mild assumptions.

\hypothesis{1}{\textit{$\exists \eta > 0, \forall \tilde{x} \in \tilde{\mathcal{X}}, \exists y^*_{\tilde{x}} \in \mathcal{Y}: \forall y' \neq y^*_{\tilde{x}}, \underset{\mathcal{D}}{\mathbb{P}}(\tilde{x},y^*_{\tilde{x}}) > \underset{\mathcal{D}}{\mathbb{P}}(\tilde{x}, y') + \eta$.}}

Intuitively, \Cref{hyp:A1} implies two things. Firstly, each feature $\tilde{x} \in \tilde{\mathcal{X}}$ is sufficiently frequent in the base distribution. Secondly, given a feature $\tilde{x} \in \tilde{\mathcal{X}}$, there exists a label $y^*_{\tilde{x}}$ that is consequently more probable than the other labels in the base distribution.

\hypothesis{2}{\textit{The transformation $g$ is idempotent: $g(g(x))=g(x)$ for all $x \in \mathcal{X}$.}}

To understand \Cref{hyp:A2}, consider data poisoning in image classification. \Cref{hyp:A2} holds in data poisoning strategies where the trigger is a fixed, opaque watermark, as in the case of binary masks \cite{gu2019badnets}, where applying the mask twice is equivalent to applying it once. However, this is not true for strategies like pixel blending \cite{chen2017targetedba}. In contrast, \Cref{hyp:A2} naturally applies to tabular data, where the collective can apply a transformation $g$ to map a feature to a constant value.

Now, we outline a scheme that the collective can use to compute a lower bound. The basic idea is that each member $(x,y)$ of the collective keeps its feature $x$ but changes its label to the most likely label $y^*_{g(x)}$ based on the feature $g(x)$. This approach encourages the platform to predict the same label for both $x$ and $g(x)$, hence erasing the signal. The scheme is the following: first, the collective pools its data to predict the optimal $y^*_{\tilde{x}}$ for each $\tilde{x} \in \tilde{\mathcal{X}}$. Then, the collective applies some strategy $h$ based on the first step to erase the signal. Assuming the collective can compute the optimal label $y^*_{\tilde{x}}$ for each $\tilde{x} \in \tilde{\mathcal{X}}$, the erasure strategy is formally defined as follows:

\begin{definition}[Erasure strategy]
\label{def:se_strat}
We define the erasure strategy as
\[
h(x,y) = (x, y^*_{g(x)}),
\]
where $y^*_{\tilde{x}}$ is given in \Cref{hyp:A1} for each $\tilde{x} \in \tilde{\mathcal{X}}$. 
\end{definition}

We can now state the main result in signal erasing:

\begin{theorem}[Signal erasing lower bound]
\label{thm:se}
    Let $\delta > 0$, and write $\tilde{\delta} := \delta /(2 + \# \tilde{\mathcal{X}}\# \mathcal{Y} + 2\# \mathcal{X} + 2\# \mathcal{X}\# \mathcal{Y} )$. Assume that $\frac{2 \log(1/\tilde{\delta})}{\eta^2} \le n \le N-\frac{2 \log(1/\tilde{\delta})}{\eta^2}$ where $\eta$ is given in \Cref{hyp:A1}. Then, with probability at least $1 - \delta$ (over the draw of the consumers), the collective can compute $y^*_{\tilde{x}}$ for all $\tilde{x} \in \tilde{\mathcal{X}}$ and by playing the erasure strategy it achieves against a classifier that is $\varepsilon$-suboptimal on $\mathcal{X}$: 
  \begin{align}
  \label{ineq:se}
    \begin{split}
        \hat{S}(n) &\ge \underset{x' \sim D^{(n)}}{\hat{\mathbb{P}}} \left[  \frac{n}{N}\left(\underset{ D^{(n)}}{\hat{\mathbb{P}}}(x') - 2R_{\tilde{\delta}}(n)\right)-\frac{N-n}{N} \left(\Delta_{x'}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n)\right) - \frac{\varepsilon}{1-\varepsilon} > 0 \right]\\
        & \quad - R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test}),
    \end{split}
  \end{align}
    where $\Delta_{x'}^{(n)} := \underset{y' \in \mathcal{Y}\backslash \{y^*_{g(x')} \}}{\max } \underset{D^{(n)} }{\hat{\mathbb{P}}}(x', y') - \underset{D^{(n)} }{\hat{\mathbb{P}}}(x',y^*_{g(x')} )$.
\end{theorem} 

In signal erasing, just like in signal unplanting, the collective leverages its own data to compute the strategy $h$. However, the technique differs. In signal unplanting, the collective uses a fraction of its members to estimate the optimal label to play. Whereas in signal erasing, the collective, provided that it is sufficiently large, utilizes all of its data to compute the most likely label given a feature $\tilde{x}$, which exists under \Cref{hyp:A1}.

\section{Experimental Evaluation}
\label{sec:experimental-evaluation}

In our experiments, we simulate a platform that collects data on vehicles, where each sample represents a car. The features of each car include characteristics such as \textit{Model Type}, \textit{Fuel Type}, and \textit{Country of Manufacture}. The labels assigned to each vehicle reflect the car’s evaluation, categorized into four classes: Excellent, Good, Average, or Poor. Further details on the dataset and the specific parameters used in the experiments can be found in Appendix \ref{app:addition-details-experiment}.

We consider a scenario where a collective seeks to influence the platform by lobbying against a particular category of vehicles, specifically SUVs with specific features. The collective defines a signal set $\tilde{\mathcal{X}}$ through a transformation~$g$ fixing all feature values except \textit{Country of Manufacture}. They may want to plant a signal targeting a label $y^*$ = Poor. They might also aim to unplant signals, specifically working to associate elements of $\tilde{\mathcal{X}}$ with labels $y \neq$ Excellent.

\subsection{Signal planting}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{signal-planting.pdf}
    \caption{\textbf{Signal planting with feature-label strategy.} Comparison of the theoretical lower bound from Theorem \ref{thm:sp} and the true success $\hat{S}(n)$ observed at test time for different values of $n$ and a fixed value of $N = 1,000,000$. For all target labels, the lower bound indicates that approximately 10$\%$ of the total number of agents interacting with the platform is necessary to significantly influence it. In reality, the success observed at test time shows that just under 5$\%$ of members is sufficient, except for the target label $y^*$= Excellent, which is already consistently the most frequent and does not require any planting.}
    \label{fig:signal-planting}
    \vspace{1em} 
\end{figure}

In Figure \ref{fig:signal-planting}, we plot the lower bounds from Theorem \ref{thm:sp} for various values of $n$ and compare them to the true success $\hat{S}(n)$ observed at test time. We fit sigmoid functions to interpolate the obtained values. The lower bounds are indeed lower than the success, and the gap between the two is not excessively large. This gap could potentially be narrowed using more advanced statistical inference methods. Interestingly, even though in practice the label $y^*$ =~Excellent is already the most frequent label for every element of the signal set $\tilde{\mathcal{X}}$ and does not technically need to be planted---i.e., $\hat{S}(n) = 1$ for all $n$---the collective is still not guaranteed to have influence over the signal for small values of $n$. This stems from statistical uncertainties, which our framework highlights, causing the collective to consistently overestimate the number of agents needed for a given success.

\begin{figure}[h!]
    \centering
    \includegraphics[width=.6\textwidth]{signal-planting-N.pdf}
    \caption{\textbf{Signal planting with feature-label strategy.} Lower bound from Theorem \ref{thm:sp} with $y^*$ = Poor for different values of $n$ with $N=500,000$, $N=1,000,000$, and $N=2,000,000$.}
    \label{fig:signal-planting-N}
    \vspace{1em}
\end{figure}

Figure \ref{fig:signal-planting-N} shows how the lower bound varies with $N$. For a fixed fraction $n/N$, larger $N$ improves the collectives's estimation ability as $n$ grows, reducing error terms $R_{\tilde{\delta}}(n)$. This suggests that platforms interacting with large user bases are more exposed to collectives altering their data. While this observation is specific to signal planting, it is even more relevant when optimal strategies need to be estimated, as in signal unplanting.

\subsection{Signal unplanting}

We now focus on signal unplanting with a target $y \neq$ Excellent, where the collective aims for the platform to predict a label other than Excellent for samples in the signal set $\tilde{\mathcal{X}}$.

\begin{figure*}[h!]
    \centering
    \includegraphics[width=\textwidth]{signal-unplanting.pdf} 
    \caption{\textbf{Signal unplanting.} (a) Comparison of lower bounds from Theorem \ref{thm:su} for different values of $n_{\rm est}$. (b) Comparison between the adaptive strategy with  $n_{\rm est}= 2,000$ and naive planting strategies targeting labels $y^* \in \{ \text{Good, Average, Poor}\}$. (c) Comparison of the lower bound achieved by the adaptive strategy with $n_{\rm est}= 2,000$ and the actual success $\hat{S}(n)$ observed at test time.}
    \label{fig:signal-unplanting}
    \vspace{1em} 
\end{figure*}

The lower bound obtained in Theorem \ref{thm:su} depends on $n_{\rm est}$, the size of the sub-collective used to determine the strategy~$h$. As shown in Figure \ref{fig:signal-unplanting} (a), $n_{\rm est}$ involves a trade-off: small values lead to erratic strategy estimates and weaker bounds, while overly large values increase the $R_{\tilde{\delta}}(n-n_{\rm est})$ term, also weakening the bound. A good balance is achieved at $n_{\rm est} = 2,000$. 

Figure \ref{fig:signal-unplanting} (b) compares this adaptive strategy with $n_{\rm est} = 2,000$ to naive strategies planting labels $y^* \in \{\text{Good, Average, Poor}\}$. The adaptive strategy consistently outperforms the naive ones by providing a higher lower bound. However, it's worth noting that the naive strategy of planting the signal with $y^*$ = Good performs well for this dataset. This is due to the fact that most elements in the signal set $\tilde{\mathcal{X}}$ have Good as the second most likely label after Excellent.

In Figure \ref{fig:signal-unplanting} (c), we compare the lower bound with $n_{\rm est} = 2,000$ and the actual success $\hat{S}(n)$ achieved at test time. The lower bound suggests that the collective would need to represent around $10\%$ of the agents interacting with the platform to have a significant impact, while in practice, only about $3\%$ was sufficient.

\subsection{Comparative analysis}
\label{ss:comparative_analysis}

Our finite-sample framework differs from that presented by \citet{hardt2023collectiveaction}, which focuses on a population-level analysis. The connection is that the limit of our framework in the infinite data regime boils down to that of \citet{hardt2023collectiveaction}. Specifically, for $\alpha \in (0,1)$. let $n, N, N_{\rm test} \rightarrow \infty$ such that $n/N \rightarrow \alpha$. In this case, our statistical algorithmic collective action framework simplifies to that of algorithmic collective action. In Figure \ref{fig:comparison-prior-bounds}, we compare the bounds we obtain under the infinite data regime with those of \citet{hardt2023collectiveaction}. The bounds presented in our work are tighter than those obtained by \citet{hardt2023collectiveaction}. We provide a proof and additional remarks in Appendix \ref{app:infinite-data-regime}.

\begin{figure}[h]
    \centering
    \includegraphics[width=.6\textwidth]{comparison-prior-bounds.pdf}
    \caption{\textbf{Signal planting.} Comparison of signal planting lower bounds with target $y^* =$ Poor using feature-label (F-L) and feature-only (F-O) strategies. Our bounds in the infinite data regime are compared to bounds from \citet{hardt2023collectiveaction}, when $\varepsilon=0$.}
    \label{fig:comparison-prior-bounds}
    \vspace{1em} 
\end{figure}

Interestingly, in the case of a discrete signal set, as used in our experiments, our lower bounds take on a \emph{staircase} shape rather than a smooth sigmoid. This mirrors the shape of the curves observed in signal unplanting in Figure \ref{fig:signal-unplanting}, which would also appear in Figure \ref{fig:signal-planting} and Figure \ref{fig:signal-planting-N} if we used finer increments of $n$. In contrast, the bounds from \citet{hardt2023collectiveaction} do not capture this phenomenon.

\section{Discussion}

In this work, we introduced a framework where collectives aiming to influence a platform can leverage their local information by pooling their data. Our approach captures the key desideratum that collectives may not only want to observe the outcomes of their actions at test time but also anticipate lower bounds on their success. Moreover, it allows the collective to implement practical strategies based on parameters they do not directly observe, by using statistical estimation. The ability to anticipate outcomes and make informed decisions based on pooled data represents an advancement in understanding how collectives can interact with and influence platforms. However, there is room for further exploration. 

We used Hoeffding's inequality as a proof of concept, but it is worth studying improved concentration inequalities for obtaining estimates of success for collectives. It is also possible to reverse the concentration inequalities to derive upper bounds on success, but the challenge lies in the fact that these upper bounds are often trivial. In ongoing work, we are exploiting recent developments in concentration inequalities due to~\citet{howardEtAl}. 

We focused on classification, but extensions to other objectives, such as regression, would be useful. We also assumed that the feature space $\mathcal{X}$ is finite to use a limited number of events in the union bounds. It would be natural to remove this assumption by using a covering of $\tilde{\mathcal{X}}$, provided it is compact, to derive more general bounds for signal planting and unplanting. 

Finally, a key assumption in collective action is that individuals are identically distributed. However, those who join a collective are often distributed differently from the general population---e.g., a collective against SUVs is likely to have fewer SUV-related data points and more data on smaller vehicles. Extending the framework to account for a heterogeneous population is an important direction for future work.



\section*{Acknowledgements}

The authors would like to thank Eugène Berta, Sacha Braun, Yurong Chen, and David Holzmüller for their helpful comments and suggestions. Funded by the European Union (ERC-2022-SYG-OCEAN-101071601). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. This publication is part of the Chair ``Markets and Learning", supported by Air Liquide, BNP PARIBAS ASSET MANAGEMENT Europe, EDF, Orange and SNCF, sponsors of the Inria Foundation. This work has also received support from the French government, managed by the National Research Agency, under the France 2030 program with the reference ``PR[AI]RIE-PSAI" (ANR-23-IACL-0008).

\bibliography{references}
\bibliographystyle{icml2025}

\newpage
\appendix
\onecolumn

\section{Additional Details on Experiments}
\label{app:addition-details-experiment}

We generate a dataset of 3,000,000 instances. Each instance represents a car, characterized by multiple categorical features that capture key aspects of vehicle design, performance, and manufacturing.

The features included in this synthetic dataset are as follows:
\begin{itemize}
    \item \textit{Model Type}: the type of vehicle, categorized as Sedan, SUV, Coupe, Hatchback, Convertible, Wagon, Minivan, or Truck.
    \item \textit{Fuel Type}: the fuel used by the vehicle, which can be Gasoline, Diesel, Electric, or Hybrid.
    \item \textit{Transmission Type}: the type of transmission, classified as Manual, Automatic, or CVT.
    \item \textit{Drive Type}: the drive configuration of the vehicle, identified as FWD (Front-Wheel Drive), RWD (Rear-Wheel Drive), or AWD (All-Wheel Drive).
    \item \textit{Safety Rating}: the safety rating of the vehicle, rated from 1 star to 5 stars.
    \item \textit{Interior Material}: the material used for the vehicle's interior, which can be Cloth, Leather, or Synthetic.
    \item \textit{Infotainment System}: the level of the infotainment system, ranging from Basic, Advanced, Premium, or None.
    \item \textit{Country of Manufacture}: the country where the vehicle was manufactured, that we will denote by C1, C2, C3, C4, and C5.
    \item \textit{Warranty Length}: the length of the vehicle's warranty, available in options of 3 years, 5 years, 7 years, or 10 years.
    \item \textit{Number of Doors}: the number of doors on the vehicle, which can be 2, 4, or 5.
    \item \textit{Number of Seats}: The seating capacity of the vehicle, with options for 2, 4, 5, or 7 seats.
    \item \textit{Air Conditioning}: indicates whether the vehicle is equipped with air conditioning (Yes or No).
    \item \textit{Navigation System}: the level of the navigation system, which can be None, Basic, or Advanced.
    \item \textit{Tire Type}: the type of tires used, categorized as All-Season, Summer, or Winter.
    \item \textit{Sunroof}: indicates whether the vehicle has a sunroof (Yes or No).
    \item \textit{Sound System}: the quality of the sound system, which can be Standard, Premium, High-end, or None.
    \item \textit{Cruise Control}: indicates whether the vehicle is equipped with cruise control (Yes or No).
    \item \textit{Bluetooth Connectivity}: indicates whether the vehicle has Bluetooth connectivity (Yes or No).
\end{itemize}

Additionally, each car is assigned a \textit{Car Evaluation} label based on a scoring system that considers various factors such as safety rating, fuel type, warranty length, and others. The possible evaluation outcomes are classified into four categories: Excellent, Good, Average, and Poor.

We generate separate consumer datasets, sampled without replacement from this base dataset. Unless otherwise specified, we choose $N = 1,000,000$ for the training set and $N_{\rm test} = 100,000$ for the test set. In all the experiments, we set $\delta=0.05$ and $\varepsilon=0$. 

In our experiments, the collective attempts to influence the platform by targeting features with specific characteristics defined through the transformation $g$: \textit{Model Type} = SUV, \textit{Fuel Type} = Diesel, \textit{Transmission Type} = Manual, \textit{Drive Type} = RWD, \textit{Safety Rating} = 4 stars, \textit{Interior Material} = Synthetic, \textit{Infotainment System} = Premium, \textit{Warranty Length} = 10 years, \textit{Number of Doors} = 5, \textit{Number of Seats} = 5, \textit{Air Conditioning} = Yes, \textit{Navigation System} = Advanced, \textit{Tire Type} = All-Season, \textit{Sunroof} = Yes, \textit{Sound System} = Premium, \textit{Cruise Control} = Yes, and \textit{Bluetooth Connectivity} = Yes. In the dataset containing 3 million samples, the signal set $\tilde{\mathcal{X}}$ induced by $g$ comprises exactly 208,871 samples, which represents just under 7\% of the entire training set. Table \ref{tab:distribution} provides details on the label frequencies within the signal set.

\begin{table}[ht]
\centering
\caption{Distribution of labels for elements in $\tilde{\mathcal{X}}$, characterized by their \textit{Country of Manufacture.}}
\vskip 0.15in
\label{tab:distribution}
\begin{tabular}{llr}
\toprule
\textbf{Country of Manufacture} & \textbf{Label} & \textbf{Sample Count} \\
\midrule
\multirow{4}{*}{C1}         & Excellent & 18410 \\
                             & Good      & 9228 \\
                             & Average   & 0 \\
                             & Poor      & 1471 \\
\midrule
\multirow{4}{*}{C2} & Excellent & 18504 \\
                             & Good      & 9214 \\
                             & Average   & 0 \\
                             & Poor      & 1461 \\
\midrule
\multirow{4}{*}{C3}       & Excellent & 58083 \\
                             & Good      & 29170 \\
                             & Average   & 0 \\
                             & Poor      & 4619 \\
\midrule
\multirow{4}{*}{C4}     & Excellent & 17491 \\
                             & Good      & 0 \\
                             & Average   & 2946 \\
                             & Poor      & 8911 \\
\midrule
\multirow{4}{*}{C5}       & Excellent & 18589 \\
                             & Good      & 9290 \\
                             & Average   & 0 \\
                             & Poor      & 1484 \\
\midrule
\multirow{4}{*}{Total}       & Excellent & 131077 \\
                             & Good      & 56902 \\
                             & Average   & 2946 \\
                             & Poor      & 17946 \\
\bottomrule
\end{tabular}
\end{table}

For further details on the dataset composition, we refer to the code available at: \url{https://github.com/GauthierE/statistical-collusion}.

\newpage
\section{Algorithms}
\label{app:algo}

\begin{algorithm}[H]
\caption{Signal planting lower bound -- feature-label strategy}
\label{alg:sp}
\begin{algorithmic}[1]
    \STATE Input: $\mathcal{X}, \mathcal{Y}, N, N_{\rm test}, n < N,  D^{(n)}, g, y^*, \delta > 0, \varepsilon > 0$
    \STATE Define $\tilde{\mathcal{X}} := \left\{g(x) \mid x \in \mathcal{X}\right\}$
    \STATE Observe $D^{(n)}$ and compute $\Delta_{\tilde{x}}^{(n)}$ for every $\tilde{x} \in \tilde{\mathcal{X}}$
    \STATE Define $h: (x,y) \mapsto (g(x),y^*)$
    \STATE Compute $\tilde{D}^{(n)}$ by applying $h$ to all samples in $D^{(n)}$
    \STATE Compute $\underset{\tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x})$ for every $\tilde{x} \in \tilde{\mathcal{X}}$
    \STATE Define $\tilde{\delta} := \delta /(2 + 2\# \tilde{\mathcal{X}} + 2\# \tilde{\mathcal{X}}\# \mathcal{Y})$
    \STATE Compute $R_{\tilde{\delta}}(n)$, $R_{\tilde{\delta}}(N-n)$, and $R_{\tilde{\delta}}(N_{\rm test})$ 
    \STATE Compute and return:\\ $\underset{\tilde{x} \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}} \left[  \frac{n}{N}\left(\underset{\tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}) - 2R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n)\right) - \frac{\varepsilon}{1-\varepsilon}> 0 \right] - R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test})$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Signal planting lower bound -- feature-only strategy}
\label{alg:sp_fo}
\begin{algorithmic}[1]
    \STATE Input: $\mathcal{X}, \mathcal{Y}, N, N_{\rm test}, n < N,  D^{(n)}, g, y^*, \delta > 0, \varepsilon > 0$
    \STATE Define $\tilde{\mathcal{X}} := \left\{g(x) \mid x \in \mathcal{X}\right\}$ and select some $x_0 \notin \tilde{\mathcal{X}}$
    \STATE Observe $D^{(n)}$ and compute $\Delta_{\tilde{x}}^{(n)}$ for every $\tilde{x} \in \tilde{\mathcal{X}}$
    \STATE Define $h: (x,y) \mapsto \begin{cases} 
    (g(x), y^*) & \text{if } y = y^*, \\
    (x_0, y) & \text{otherwise}
    \end{cases}$
    \STATE Compute $\tilde{D}^{(n)}$ by applying $h$ to all samples in $D^{(n)}$
    \STATE Compute $\underset{\tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}, y^*)$ for every $\tilde{x} \in \tilde{\mathcal{X}}$
    \STATE Define $\tilde{\delta} := \delta /(2 + 2\# \tilde{\mathcal{X}} + 2\# \tilde{\mathcal{X}}\# \mathcal{Y})$
    \STATE Compute $R_{\tilde{\delta}}(n)$, $R_{\tilde{\delta}}(N-n)$, and $R_{\tilde{\delta}}(N_{\rm test})$ 
    \STATE Compute and return:\\ $\underset{x' \sim D^{(n)}}{\hat{\mathbb{P}}} \left[  \frac{n}{N}\left(\underset{\tilde{D}^{(n)} }{\hat{\mathbb{P}}}(g(x'), y^*) - 2R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{g(x')}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n)\right)- \frac{\varepsilon}{1-\varepsilon}> 0 \right] - R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test})$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Signal unplanting lower bound -- adaptive strategy}
\label{alg:su}
\begin{algorithmic}[1]
    \STATE Input: $\mathcal{X}, \mathcal{Y}, N, N_{\rm test}, n < N, n_{\rm est} < n, D^{(n_{\rm est})}, D^{(n-n_{\rm est})}, g, y^*, \delta > 0, \varepsilon > 0$
    \STATE Define $\tilde{\mathcal{X}} := \left\{g(x) \mid x \in \mathcal{X}\right\}$
    \STATE Observe $D^{(n_{\rm est})}$ and compute $\hat{y}_{\tilde{x}} := \underset{y' \in \mathcal{Y}\backslash\{y^*\}}{\text{argmax }} \underset{D^{(n_{\rm est})} }{\hat{\mathbb{P}}}(\tilde{x}, y' )$ for every $\tilde{x} \in \tilde{\mathcal{X}}$
    \STATE Observe $D^{(n-n_{\rm est})}$ and compute $\Delta_{\tilde{x}}^{(n-n_{\rm est})}$ for every $\tilde{x} \in \tilde{\mathcal{X}}$
    \STATE Define $h: (x,y) \mapsto (g(x), \hat{y}_{g(x)})$
    \STATE Compute $\tilde{D}^{(n)}$ by applying $h$ to all samples in $D^{(n)}$ defined as the concatenation of $D^{(n_{\rm est})}$  and $D^{(n-n_{\rm est})}$
    \STATE Compute $\underset{\tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x})$ for every $\tilde{x} \in \tilde{\mathcal{X}}$
    \STATE Define $\tilde{\delta} := \delta /(2 + 6\# \tilde{\mathcal{X}} )$
    \STATE Compute $R_{\tilde{\delta}}(n)$, $R_{\tilde{\delta}}(n-n_{\rm est})$, $R_{\tilde{\delta}}(N-n)$, and $R_{\tilde{\delta}}(N_{\rm test})$ 
    \STATE Compute and return:\\ $\underset{\tilde{x} \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}} \left[  \frac{n}{N}\left(\underset{ \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}) - 2R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(n-n_{\rm est})} + 2R_{\tilde{\delta}}(n-n_{\rm est}) + 2R_{\tilde{\delta}}(N-n)\right) - \frac{\varepsilon}{1-\varepsilon}> 0 \right] - R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test})$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Signal erasing lower bound -- under \Cref{hyp:A1} and \Cref{hyp:A2}}
\label{alg:se}
\begin{algorithmic}[1]
    \STATE Input: $\mathcal{X}, \mathcal{Y}, N, N_{\rm test}, n < N, D^{(n)}, g, \delta > 0, \varepsilon > 0$
    \STATE Define $\tilde{\mathcal{X}} := \left\{g(x) \mid x \in \mathcal{X}\right\}$
    \STATE Observe $D^{(n)}$ and compute $y^*_{\tilde{x}} = \underset{y' \in \mathcal{Y}}{\text{argmax}} \underset{D^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}, y')$ for every $\tilde{x} \in \tilde{\mathcal{X}}$ and $\Delta_{x'}^{(n)}$ for every $x' \in \mathcal{X}$
    \STATE Compute $\underset{D^{(n)}}{\hat{\mathbb{P}}}(x')$ for every $x' \in \mathcal{X}$
    \STATE Define $\tilde{\delta} := \delta /(2 + \# \tilde{\mathcal{X}}\# \mathcal{Y} + 2\# \mathcal{X} + 2\# \mathcal{X}\# \mathcal{Y} )$
    \STATE Compute $R_{\tilde{\delta}}(n)$, $R_{\tilde{\delta}}(N-n)$, and $R_{\tilde{\delta}}(N_{\rm test})$ 
    \STATE Compute and return:\\ $\underset{x' \sim D^{(n)}}{\hat{\mathbb{P}}} \left[  \frac{n}{N}\left(\underset{ D^{(n)}}{\hat{\mathbb{P}}}(x') - 2R_{\tilde{\delta}}(n)\right)-\frac{N-n}{N} \left(\Delta_{x'}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n)\right) -\frac{\varepsilon}{1-\varepsilon} > 0 \right] - R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test})$
\end{algorithmic}
\end{algorithm}

Note that Algorithm \ref{alg:se} yields a valid lower bound if $\frac{2 \log(1/\tilde{\delta})}{\eta^2} \le n \le N-\frac{2 \log(1/\tilde{\delta})}{\eta^2}$ where $\eta$ is given in \Cref{hyp:A1}.

\section{Additional Experiments}
\label{app:additional-exp}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{signal-planting-fo.pdf}
    \caption{\textbf{Signal planting with feature-only strategy.} Comparison of the theoretical lower bound from Theorem \ref{thm:sp_fo} and the true success $\hat{S}(n)$ observed at test time for different values of $n$ and a fixed value of $N = 1,000,000$.}
    \label{fig:signal-planting-fo}
    \vspace{1em} 
\end{figure}

For the feature-only signal planting strategy, we selected $x_0$ constant equal to: \textit{Model Type} = Sedan, \textit{Fuel Type} = Diesel, \textit{Transmission Type} = Automatic, \textit{Drive Type} = RWD, \textit{Safety Rating} = 1 star, \textit{Interior Material} = Synthetic, \textit{Infotainment System} = Premium, \textit{Warranty Length} = 7 years, \textit{Number of Doors} = 5, \textit{Number of Seats} = 5, \textit{Air Conditioning} = Yes, \textit{Navigation System} = Advanced, \textit{Tire Type} = All-Season, \textit{Sunroof} = No, \textit{Sound System} = Premium, \textit{Cruise Control} = No, and \textit{Bluetooth Connectivity} = No.

In Figure \ref{fig:signal-planting-fo}, we can see that both the lower bounds and the actual success rates at test time are lower compared to the feature-label strategy observed in Figure \ref{fig:signal-planting}. This is expected since the collective has less leverage with the feature-only strategy, as it cannot modify its labels. Specifically, for planting $y^*=$ Average and $y^*=$ Poor, it appears that only collectives representing the majority of agents interacting with the learning platform are likely to have a significant impact, while the lower bounds remain uninformative unless the collective represents nearly all agents.


\section{Lemmas}

\begin{lemma}[Hoeffding's Inequality]
\label{lma:hoeffding}
Let \( X_1, X_2, \ldots, X_n \) be independent random variables such that \( a_i \leq X_i \leq b_i \) for all \( i \). Let \( \overline{X} = \frac{1}{n} \sum_{i=1}^n X_i \). Then for any \(t > 0\),
\[
\underset{X_1,...,X_n}{\mathbb{P}}\left(\overline{X} - \mathbb{E}[\overline{X}] \geq t \right) \leq \exp\left( -\frac{2n^2t^2}{\sum_{i=1}^n (b_i - a_i)^2} \right).
\]
\end{lemma}
Note that by applying Lemma \ref{lma:hoeffding} to the random variables $-X_i$ we obtain that:
\[
\underset{X_1,...,X_n}{\mathbb{P}}\left(\overline{X} - \mathbb{E}[\overline{X}] \leq -t \right) \leq \exp\left( -\frac{2n^2t^2}{\sum_{i=1}^n (b_i - a_i)^2} \right).
\]

\begin{lemma}[\cite{hardt2023collectiveaction}, Lemma B.1]
\label{lma:tv_epsilon}
Suppose that \(\mathcal{P}\) and \(\mathcal{P}'\) are two distributions such that \( \text{TV}(\mathcal{P}, \mathcal{P}') \leq \varepsilon \). Take any two events \( E_1 \) and \( E_2 \) measurable under \(\mathcal{P}\) and \(\mathcal{P}'\). If \( \mathcal{P}(E_1) > \mathcal{P}(E_2) + \frac{\varepsilon}{1 - \varepsilon} \), then \( \mathcal{P}'(E_1) > \mathcal{P}'(E_2) \).
\end{lemma}

\label{app:lemmas}

\section{Proofs and additional remarks}
\label{app:theorems}

\subsection{Proof of Theorem \ref{thm:sp}}

\begin{proof}
    The proof relies on applying union bound to several concentration inequalities. Here, we will use Hoeffding's inequality (Lemma \ref{lma:hoeffding}).
    
    First, assume that $\varepsilon = 0$ for simplicity. Let $\tilde{x} \in \tilde{\mathcal{X}}$. By applying Hoeffding's inequality to the $n$ independent random variables $\mathbb{1}_{\left\{\tilde{x}_i'=\tilde{x}\right\}} \in [0,1]$ for $\tilde{x}_i' \in \tilde{D}^{(n)}$, we have that
        \begin{equation}
    \label{eq1}
 \underset{\tilde{x}' \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}) \le \underset{\tilde{x}' \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x}'=\tilde{x}) + R_{\tilde{\delta}}(n)
    \end{equation}
    with probability at least $1-\tilde{\delta}$ over the draw of $D^{(n)}$. Similarly,
    \begin{equation}
    \label{eq2}
         \underset{\tilde{x}' \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x}'=\tilde{x}) \le \underset{\tilde{x}' \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}) + R_{\tilde{\delta}}(n)
    \end{equation}
    holds with probability at least $1-\tilde{\delta}$ over the draw of $D^{(n)}$. For any fixed $\tilde{x} \in \tilde{\mathcal{X}}$ and $y' \in \mathcal{Y} \backslash \{y^* \}$, the following inequalities also hold individually with probability at least $1-\tilde{\delta}$ over the draw of consumers: 
    \begin{equation}
    \label{eq3}
     \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') \le \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y') + R_{\tilde{\delta}}(N-n)
    \end{equation}
    \begin{equation}
    \label{eq4}
     \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y^*)  \le \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*) + R_{\tilde{\delta}}(N-n)
    \end{equation}
    Similarly:
        \begin{equation}
    \label{eq3p}
     \underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*) \le \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y^*) + R_{\tilde{\delta}}(n)
    \end{equation}
    \begin{equation}
    \label{eq4p}
     \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y')  \le \underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') + R_{\tilde{\delta}}(n)
    \end{equation}
    We also have that
    \begin{equation}
    \label{eq5}
    \underset{x \sim D_{\rm test}}{\hat{\mathbb{P}}}(\hat{f}(g(x)) = y^*) \ge  \underset{x \sim \mathcal{D}}{\mathbb{P}}(\hat{f}(g(x)) = y^*) - R_{\tilde{\delta}}(N_{\rm test})
    \end{equation}
with probability at least $1-\tilde{\delta}$, where the probability is taken over $D_{\rm test}$ conditionally on $D^{(n)}$ and  $D^{(N-n)}$, so in particular it holds marginally over all consumers. Lastly, we have with probability at least $1-\tilde{\delta}$ over the draw of $D^{(n)}$:
    \begin{equation}
    \label{eq6}
    \begin{split}
 &\underset{\tilde{x} \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}} \left(  \frac{n}{N}\left(\underset{\tilde{x}' \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x}'=\tilde{x}) - R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(\mathcal{D})} + 2R_{\tilde{\delta}}(N-n)\right) > 0\right) \le\\
 &\underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}} \left(  \frac{n}{N}\left(\underset{\tilde{x}' \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x}'=\tilde{x}) - R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(\mathcal{D})} + 2R_{\tilde{\delta}}(N-n)\right) > 0\right) + R_{\tilde{\delta}}(n) 
    \end{split}
    \end{equation}
where $\Delta_{\tilde{x}}^{(\mathcal{D})} := \underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\max } \left(\underset{(x,y) \sim \mathcal{D} }{\mathbb{P}}(x=\tilde{x}, y=y') - \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y^*)\right)$.\\

Now, we use union bound with these $2 + 2\# \tilde{\mathcal{X}} + 2\# \tilde{\mathcal{X}}\# \mathcal{Y}$ inequalities above, so that all the following calculations hold with probability at least $1-\delta$ over the draw of consumers. First, Inequality (\ref{eq5}) yields:
\begin{align*}
    \hat{S}(n) &\ge \underset{x \sim \mathcal{D}}{\mathbb{P}}(\hat{f}(g(x)) = y^*) - R_{\tilde{\delta}}(N_{\rm test})\\
    &= \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\hat{f}(\tilde{x}) = y^*) - R_{\tilde{\delta}}(N_{\rm test})
\end{align*}
by definition of $h$. Now see that for any $\tilde{x} \in \tilde{\mathcal{X}}$ we have that
    \begin{align*}
        \hat{f}(\tilde{x}) = y^* &\Longleftarrow \forall y' \neq y^*, \hat{\mathcal{P}}(\tilde{x},y^*) > \hat{\mathcal{P}}(\tilde{x},y')\\
        &\Longleftrightarrow \forall y' \neq y^*, \frac{n}{N}\underset{(\tilde{x}',\tilde{y}') \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}, \tilde{y}'=y^*) + \frac{N-n}{N}\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*)\\
        & >  \frac{n}{N}\underset{(\tilde{x}',\tilde{y}') \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}, \tilde{y}'=y') + \frac{N-n}{N}\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') \\
        &\Longleftrightarrow \forall y' \neq y^*, \frac{n}{N}\underset{\tilde{x}' \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}) + \frac{N-n}{N}\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*)\\
        & >  \frac{N-n}{N}\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') \\
        &\Longleftrightarrow \frac{n}{N}\underset{\tilde{x}' \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}) \\
        &- \frac{N-n}{N} \underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\text{max }} \left( \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') - \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*)\right) > 0\\
        &\Longleftarrow \frac{n}{N}\left(\underset{\tilde{x}' \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x}'=\tilde{x}) - R_{\tilde{\delta}}(n) \right) - \frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(\mathcal{D})} +2R_{\tilde{\delta}}(N-n) \right) > 0
    \end{align*}
    
    where the last implication comes from Inequality (\ref{eq2}) and because
    \begin{align*}
        & \underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\text{max }} \left(\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') - \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*)\right)\\
        &\le \underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\text{max }} \left(\underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y') - \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y^*)\right) + 2R_{\tilde{\delta}}(N-n)\\
        &= \Delta_{\tilde{x}}^{(\mathcal{D})} +2R_{\tilde{\delta}}(N-n)\\
    \end{align*}
    by Inequality (\ref{eq3}) on $\tilde{\mathcal{X}} \times \mathcal{Y} \backslash \{y^* \}$ and Inequality (\ref{eq4}) on $\tilde{\mathcal{X}} \times \{y^* \}$. Therefore, we have that:
    \begin{align*}
    \begin{split}
        &\hat{S}(n) \ge \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}} \left(  \frac{n}{N}\left(\underset{\tilde{x}' \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x}'=\tilde{x}) - R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(\mathcal{D})} + 2R_{\tilde{\delta}}(N-n)\right) > 0\right)\\
        &- R_{\tilde{\delta}}(N_{\rm test})
    \end{split}
    \end{align*}
    and so by applying Inequality (\ref{eq6}) we deduce that:
        \begin{align*}
    \begin{split}
        &\hat{S}(n) \ge \underset{\tilde{x} \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}} \left(  \frac{n}{N}\left(\underset{\tilde{x}' \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x}'=\tilde{x}) - R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(\mathcal{D})} + 2R_{\tilde{\delta}}(N-n)\right) > 0\right)\\
        &- R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test}).
    \end{split}
    \end{align*}
    Finally, note that:
       \begin{align*}
         \Delta_{\tilde{x}}^{(\mathcal{D})} &= \underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\max } \left(\underset{(x,y) \sim \mathcal{D} }{\mathbb{P}}(x=\tilde{x}, y=y') - \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y^*)\right) \\
        &\le \underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\text{max }} \left(\underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') - \underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*)\right) + 2R_{\tilde{\delta}}(n)\\
        &= \Delta_{\tilde{x}}^{(n)} +2R_{\tilde{\delta}}(n)\\
    \end{align*}
    by Inequality (\ref{eq3p}) on $\tilde{\mathcal{X}} \times  \{y^* \}$ and Inequality (\ref{eq4p}) on $\tilde{\mathcal{X}} \times \mathcal{Y} \backslash \{y^* \}$. So together with Inequality (\ref{eq1}), we conclude that:
    \begin{align*}
    \begin{split}
        \hat{S}(n) &\ge \underset{\tilde{x} \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}} \left(  \frac{n}{N}\left(\underset{\tilde{x}' \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}) - 2R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n)\right) > 0 \right)\\
        & - R_{\tilde{\delta}}(n) - R_{\tilde{\delta}}(N_{\rm test}).
    \end{split}
    \end{align*}

    The case $\varepsilon > 0$ is similar, noting that for any $\tilde{x} \in \tilde{\mathcal{X}}$:
    \begin{align*}
        \hat{f}(\tilde{x}) = y^* &\Longleftarrow \forall y' \neq y^*, \tilde{\mathcal{P}}(\tilde{x},y^*) > \tilde{\mathcal{P}}(\tilde{x},y')\\
        &\Longleftarrow \forall y' \neq y^*, \hat{\mathcal{P}}(\tilde{x},y^*) > \hat{\mathcal{P}}(\tilde{x},y') + \frac{\varepsilon}{1-\varepsilon} \text{\quad by Lemma \ref{lma:tv_epsilon}}
    \end{align*} 
    and with slight modifications to Inequality (\ref{eq6}) to incorporate the term $\frac{\varepsilon}{1-\varepsilon}$.
\end{proof}

If there exists a subset $\mathcal{X}_0 \subseteq \tilde{\mathcal{X}}$ such that $\# \mathcal{X}_0 < \# \tilde{\mathcal{X}} $ and $\underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x} \in \mathcal{X}_0)$ is significant, it may be preferable to condition the probability based on whether or not the feature belongs to $\mathcal{X}_0$, and to disregard the term conditioned on not being in $\mathcal{X}_0$. In this case, the union bound should be applied only to $\tilde{x} \in \mathcal{X}_0$.

The proof of Theorem \ref{thm:sp_fo} is essentially the same than the proof of Theorem \ref{thm:sp}. One difference is that we can not simplify $\underset{x \sim \mathcal{D}}{\mathbb{P}}(\hat{f}(g(x)) = y^*) = \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}}(\hat{f}(\tilde{x}) = y^*)$ as we did in the proof of Theorem \ref{thm:sp}. Therefore, the calculations must be carried out directly using the term $g(x)$.

\subsection{Proof of Theorem \ref{thm:su}}

\begin{proof}
    The proof closely follows that of Theorem \ref{thm:sp}, so we will only highlight the main differences. We focus on the case where $\varepsilon=0$; the case where $\varepsilon>0$ can be handled similarly to the proof of Theorem \ref{thm:sp}.

    Let $\tilde{x} \in \tilde{\mathcal{X}}$. We have:
    \begin{align*}
        \hat{f}(\tilde{x}) \neq y^* &\Longleftarrow \exists y' \neq y^* \colon \hat{\mathcal{P}}(\tilde{x},y^*) < \hat{\mathcal{P}}(\tilde{x},y') \\
        &\Longleftarrow \hat{\mathcal{P}}(\tilde{x},y^*) < \hat{\mathcal{P}}(\tilde{x},\hat{y}_{\tilde{x}}) \\
        &\Longleftrightarrow \frac{n}{N}\underbrace{\underset{(\tilde{x}',\tilde{y}') \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}, \tilde{y}'=y^*)}_{=0} + \frac{N-n}{N}\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*)\\
        & <  \frac{n}{N}\underbrace{\underset{(\tilde{x}',\tilde{y}') \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}, \tilde{y}'=\hat{y}_{\tilde{x}})}_{= \underset{\tilde{x}'\sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x})} + \frac{N-n}{N}\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=\hat{y}_{\tilde{x}})\\
        &\Longleftrightarrow \frac{n}{N}\underset{\tilde{x}'\sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}) \\
        &-\frac{N-n}{N} \underbrace{\left(\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*) - \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=\hat{y}_{\tilde{x}}) \right)}_{=: \Delta_{\tilde{x}}^{(N-n)}} > 0\\
    \end{align*}
    and see that
    \begin{align*}
        \Delta_{\tilde{x}}^{(N-n)} &\le \underbrace{\underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y^*) - \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=\hat{y}_{\tilde{x}})}_{=: \Delta_{\tilde{x}}^{(\mathcal{D})}} + 2 R_{\tilde{\delta}}(N-n)
    \end{align*}
    by applying Hoeffding's inequality to both empirical probabilities. Note that Hoeffding's inequality for the term $\underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=\hat{y}_{\tilde{x}})$ holds in probability over $D^{(N-n)}$ conditionnally on $D^{(n_{\rm est})}$. It should only be applied $\#  \tilde{\mathcal{X}}$ times here contrary to $\#  \tilde{\mathcal{X}} (\# \mathcal{Y} -1)$ times in signal planting because $\hat{y}_{\tilde{x}}$ is fixed conditionnally on $D^{(n_{\rm est})}$. Then, since the inequality holds in probability over $D^{(N-n)}$ conditionnally on $D^{(n_{\rm est})}$, in particular it holds marginally over all consumers.
    
    The conclusion is similar to that of Theorem \ref{thm:sp}. We just need to apply the same argument as above to use Hoeffding's inequality: $\underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=\hat{y}_{\tilde{x}}) \ge \underset{(x,y) \sim D^{(n-n_{\rm est})}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=\hat{y}_{\tilde{x}}) - R_{\tilde{\delta}}(n-n_{\rm est})$.
\end{proof}

In fact, it is possible to obtain a slightly better bound than (\ref{ineq:su}). Indeed, to bound $\Delta_{\tilde{x}}^{(\mathcal{D})}$, one can use Hoeffding's inequality on $D^{(n)}$ instead of $D^{(n-n_{\rm est})}$ for the term $\underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y^*)$. We kept the inequality (\ref{ineq:su}) as it is to simplify the expression of the bound and make the interpretation of the different terms easier.

\subsection{Interpretation of the bound from Theorem \ref{thm:su}}

As the signal planting lower bound (\ref{ineq:sp}), the signal unplanting lower bound (\ref{ineq:su}) also depends on three distinct terms:
\begin{itemize}
    \item   $\frac{n}{N}\left(\underset{\tilde{x}' \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}'=\tilde{x}) - 2R_{\tilde{\delta}}(n)\right)$
    \item $-\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(n-n_{\rm est})} + 2R_{\tilde{\delta}}(n-n_{\rm est}) + 2R_{\tilde{\delta}}(N-n)\right)$
    \item $-\frac{\varepsilon}{1-\varepsilon}$
\end{itemize}

The first and third terms play the same role as in signal planting. The main difference here is the second term $-\frac{N-n}{N} \left(\Delta_{\tilde{x}}^{(n-n_{\rm est})} + 2R_{\tilde{\delta}}(n-n_{\rm est}) + 2R_{\tilde{\delta}}(N-n)\right)$. The term $\Delta_{\tilde{x}}^{(n-n_{\rm est})}$ represents how much more probable the target label $y^*$ is compared to other labels given a feature belonging to $\tilde{\mathcal{X}}$. If $y^*$ is much more probable than the other labels, it will be difficult to unplant the signal. Conversely, if $y^*$ is not the most probable, it will be easier to unplant the signal. The collective's plan relies on the choice of $n_{\rm est}<n$. If $n_{\rm est}$ is large, it will be more likely for the collective to select the best possible label given a modified feature $\tilde{x}$ to maximize the impact of the strategy $h$. However, if $n_{\rm est}$ is too large compared to $n$, the estimation error $2R_{\tilde{\delta}}(n-n_{\rm est})$ may become too significant. Therefore, there is a trade-off for the optimal choice of the value $n_{\rm est}$. This trade-off depends on the specific dataset being considered.

\subsection{Proof of Theorem \ref{thm:se}}

\begin{proof}   
    Assume that $\varepsilon = 0$. The case of $\varepsilon > 0$ is handled in the same way as in signal planting and signal unplanting. By Hoeffding's inequality, we know that the following inequalities each hold with probability at least $1-\tilde{\delta}$ (over the draw of consumers), for some fixed $\tilde{x} \in \tilde{\mathcal{X}}$ and $y' \in \mathcal{Y}\backslash \{y^*_{\tilde{x}} \}$:
        \begin{equation}
    \label{eq7}
 \underset{(x,y) \sim \tilde{\mathcal{D}}}{\mathbb{P}}(x=\tilde{x},y=y^*_{\tilde{x}}) \le  \underset{(x,y) \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x},y=y^*_{\tilde{x}})  + R_{\tilde{\delta}}(n)
    \end{equation}
    \begin{equation}
    \label{eq8}
         \underset{(x,y) \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x},y=y')   \le \underset{(x,y) \sim \tilde{\mathcal{D}}}{\mathbb{P}}(x=\tilde{x},y=y')  + R_{\tilde{\delta}}(n)
    \end{equation}
   Similarly, for some fixed $x' \in \mathcal{X}$ and $y' \in \mathcal{Y}\backslash \{y^*_{g(x')} \}$:
        \begin{equation}
    \label{eq9}
         \underset{x \sim D^{(n)}}{\hat{\mathbb{P}}}(x=x')   \le \underset{x \sim \mathcal{D}}{\mathbb{P}}(x=x')  + R_{\tilde{\delta}}(n)
    \end{equation}
            \begin{equation}
    \label{eq10}
            \underset{x \sim \mathcal{D}}{\mathbb{P}}(x=x') \le \underset{x \sim D^{(n)}}{\hat{\mathbb{P}}}(x=x') + R_{\tilde{\delta}}(n)
    \end{equation}
    \begin{equation}
    \label{eq11}
     \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=x', y=y') \le \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=x', y=y') + R_{\tilde{\delta}}(N-n)
    \end{equation}
    \begin{equation}
    \label{eq12}
     \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=x', y=y^*_{g(x')})  \le \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=x', y=y^*_{g(x')}) + R_{\tilde{\delta}}(N-n)
    \end{equation}
        \begin{equation}
    \label{eq13}
     \underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=x', y=y^*_{g(x')}) \le \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=x', y=y^*_{g(x')}) + R_{\tilde{\delta}}(n)
    \end{equation}
    \begin{equation}
    \label{eq14}
     \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=x', y=y')  \le \underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=x', y=y') + R_{\tilde{\delta}}(n)
    \end{equation}
    We also have that
    \begin{equation}
    \label{eq15}
    \underset{x' \sim D_{\rm test}}{\hat{\mathbb{P}}}(\hat{f}(g(x')) = \hat{f}(x')) \ge  \underset{x' \sim \mathcal{D}}{\mathbb{P}}(\hat{f}(g(x')) = \hat{f}(x')) - R_{\tilde{\delta}}(N_{\rm test})
    \end{equation}
and
    \begin{equation}
    \label{eq16}
    \begin{split}
 &\underset{x' \sim D^{(n)}}{\hat{\mathbb{P}}} \left(  \frac{n}{N}\left(\underset{x \sim \mathcal{D}}{\mathbb{P}}(x=x') - R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{x'}^{(\mathcal{D})} + 2R_{\tilde{\delta}}(N-n)\right) > 0\right) \le\\
 &\underset{x' \sim \mathcal{D}}{\mathbb{P}} \left(  \frac{n}{N}\left(\underset{x \sim \mathcal{D}}{\mathbb{P}}(x=x') - R_{\tilde{\delta}}(n)\right) -\frac{N-n}{N} \left(\Delta_{x'}^{(\mathcal{D})} + 2R_{\tilde{\delta}}(N-n)\right) > 0\right) + R_{\tilde{\delta}}(n) 
    \end{split}
    \end{equation}
where $\Delta_{x'}^{(\mathcal{D})} := \underset{y' \in \mathcal{Y}\backslash \{y^*_{g(x')} \}}{\max } \left(\underset{(x,y) \sim \mathcal{D} }{\mathbb{P}}(x=x', y=y') - \underset{(x,y) \sim \mathcal{D} }{\mathbb{P}}(x=x', y=y^*_{g(x')} )\right)$.

We apply union bound to the $2 + \# \tilde{\mathcal{X}}\# \mathcal{Y} + 2\# \mathcal{X} + 2\# \mathcal{X}\# \mathcal{Y} $ inequalities above, so that the calculations below hold with probability at least $1-\delta$.

Let $\tilde{x} \in \tilde{\mathcal{X}}$. By \Cref{hyp:A1} we know that:
\begin{align}
\underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y^*_{\tilde{x}}) > \underset{(x,y) \sim \mathcal{D}}{\mathbb{P}}(x=\tilde{x}, y=y') + \eta
\label{eq:intermediate_signal_erasing}
\end{align}

for all $y' \neq y^*_{\tilde{x}}$. So by using Inequality (\ref{eq7}) and Inequality (\ref{eq8}):
\[
\underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*_{\tilde{x}}) + R_{\tilde{\delta}}(n) > \underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') - R_{\tilde{\delta}}(n) + \eta
\]
for all $\forall y' \neq y^*_{\tilde{x}}$. Provided that $n \ge \frac{2 \log(1/\tilde{\delta})}{\eta^2}$, we have that $\eta - 2R_{\tilde{\delta}}(n) > 0$ and so we deduce that
\[
\underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*_{\tilde{x}}) > \underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y')
\]
for all $\forall y' \neq y^*_{\tilde{x}}$.\\

Therefore, for each $\tilde{x} \in \tilde{\mathcal{X}}$, the collective can compute $y^*_{\tilde{x}}$ by using $D^{(n)}$ as follows:
\begin{align}
y^*_{\tilde{x}} = \underset{y' \in \mathcal{Y}}{\text{argmax}} \underset{(x,y) \sim D^{(n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y'). 
\label{eq:signal_erasing_y^*}
\end{align}

Then, the collective plays the erasure stategy $h(x,y) = (x, y^*_{g(x)}).$

Now see that using Inequality (\ref{eq11}) and Inequality (\ref{eq12}) together with Inequality (\ref{eq:intermediate_signal_erasing}) yields that
\[
\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*_{\tilde{x}}) + R_{\tilde{\delta}}(N-n) > \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') - R_{\tilde{\delta}}(N-n) + \eta
\]
for all $ y' \neq y^*_{\tilde{x}}$. Provided that $n \le N - \frac{2 \log(1/\tilde{\delta})}{\eta^2}$, we have that $\eta - 2R_{\tilde{\delta}}(N-n) > 0$ and so we deduce that
\[
\underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y^*_{\tilde{x}}) > \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y')
\]
for all $\forall y' \neq y^*_{\tilde{x}}$. This implies that
\begin{align}
\underset{y' \in \mathcal{Y}}{\text{argmax}} \underset{(x,y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=\tilde{x}, y=y') = y^*_{\tilde{x}}. 
\label{eq:argmaxNn}
\end{align}
So for all $x' \in \mathcal{X}$ we have:
\begin{align*}
    y^*_{g(x')} &= \underset{y' \in \mathcal{Y}}{\text{argmax}} \left\{ \frac{n}{N} \underbrace{\underset{(\tilde{x}, \tilde{y}) \sim \tilde{D}^{(n)}}{\hat{\mathbb{P}}}(\tilde{x}=g(x'), \tilde{y}=y')}_{=0 \text{ if } y' \neq y^*_{g(x')} \text{ since } g(g(x'))=g(x') } + \frac{N-n}{N} \underbrace{ \underset{(x, y) \sim D^{(N-n)}}{\hat{\mathbb{P}}}(x=g(x'), y=y')}_{\text{maximized in } y^*_{g(x')} \text{ by Equation } (\ref{eq:argmaxNn})} \right\}\\
    &= \underset{y' \in \mathcal{Y}}{\text{argmax}} \ \hat{\mathcal{P}}(g(x'), y')\\
    &= \hat{f}(g(x')).
\end{align*}

Therefore
\begin{align*}
    \hat{S}(n) &= \underset{x' \sim D_{\rm test}}{\hat{\mathbb{P}}}\left(\hat{f}(x')=\hat{f}(g(x'))\right) \\
    &\ge \underset{x' \sim \mathcal{D}}{\mathbb{P}}\left(\hat{f}(x')=\hat{f}(g(x'))\right) - R_{\tilde{\delta}}(N_{\rm test}) \text{\quad by Inequality (\ref{eq15})}\\
    &= \underset{x' \sim \mathcal{D}}{\mathbb{P}}\left(\hat{f}(x')=y^*_{g(x')} \right) - R_{\tilde{\delta}}(N_{\rm test}).
\end{align*}
Now let $x' \in \mathcal{X}$. A calculation similar to the one in the proof of Theorem \ref{thm:sp} shows that
\[
        \hat{f}(x') = y^*_{g(x')} \Longleftarrow \frac{n}{N}\left(\underset{x \sim \mathcal{D}}{\mathbb{P}}(x=x') - R_{\tilde{\delta}}(n) \right) - \frac{N-n}{N} \left(\Delta_{x'}^{(\mathcal{D})} +2R_{\tilde{\delta}}(N-n) \right) > 0.
\]
Here we reused Inequality (\ref{eq11}) and Inequality (\ref{eq12}), together with Inequality (\ref{eq10}) and the fact that $\tilde{\mathcal{D}}_{\mathcal{X}} = \mathcal{D}_{\mathcal{X}}$ by definition of $h$.

Therefore
    \begin{align*}
        &\hat{S}(n) \ge \underset{x' \sim \mathcal{D}}{\mathbb{P}} \left(\frac{n}{N}\left(\underset{x \sim \mathcal{D}}{\mathbb{P}}(x=x') - R_{\tilde{\delta}}(n) \right) - \frac{N-n}{N} \left(\Delta_{x'}^{(\mathcal{D})} +2R_{\tilde{\delta}}(N-n) \right) > 0\right)- R_{\tilde{\delta}}(N_{\rm test})
    \end{align*}
    and so by applying Inequality (\ref{eq16}) we deduce that
        \begin{align*}
        &\hat{S}(n) \ge \underset{x' \sim D^{(n)}}{\mathbb{P}} \left(\frac{n}{N}\left(\underset{x \sim \mathcal{D}}{\mathbb{P}}(x=x') - R_{\tilde{\delta}}(n) \right) - \frac{N-n}{N} \left(\Delta_{x'}^{(\mathcal{D})} +2R_{\tilde{\delta}}(N-n) \right) > 0\right)- R_{\tilde{\delta}}(n)- R_{\tilde{\delta}}(N_{\rm test}).
    \end{align*}

We conclude with Inequality (\ref{eq9}), Inequality (\ref{eq13}), and Inequality (\ref{eq14}).
\end{proof}

The result of Theorem \ref{thm:se} depends on whether the collective is large enough to compute the optimal label $y^*_{\tilde{x}}$ for each $\tilde{x} \in \tilde{\mathcal{X}}$. Specifically, $n$ must exceed $\frac{2 \log(1/\tilde{\delta})}{\eta^2}$. In Figure \ref{fig:eta}, we plot $\frac{2 \log(1/\tilde{\delta})}{\eta^2}$ as a function of $\eta$ with the parameters used in our experiment in Section \ref{sec:experimental-evaluation} and detailed in Appendix \ref{app:addition-details-experiment}: $\# \mathcal{X}  = 2,388,787,200$; $\# \tilde{\mathcal{X}}= 5$; and $\# \mathcal{Y} = 4$.

\begin{figure}[H]
    \centering
    \includegraphics[width=.6\textwidth]{eta.pdf}
    \caption{Plot of the minimum value of $n$ as a function of $\eta$ for computing the erasure strategy.}
    \label{fig:eta}
\end{figure}

For example, suppose the collective consists of $n = 100,000$ members. Then, if $\eta$ exceeds approximately 0.03, the signal-erasing bound \ref{ineq:se} from Theorem \ref{thm:se} holds.

\subsection{Interpretation of the bound from Theorem \ref{thm:se}}

The signal erasing lower bound \ref{ineq:se} depends on three distinct terms:
\begin{itemize}
    \item   $\frac{n}{N}\left(\underset{x \sim D^{(n)}}{\hat{\mathbb{P}}}(x=x') - 2R_{\tilde{\delta}}(n)\right)$
    \item $ -\frac{N-n}{N} \left(\Delta_{x'}^{(n)} + 2R_{\tilde{\delta}}(n) + 2R_{\tilde{\delta}}(N-n)\right)$
    \item $-\frac{\varepsilon}{1-\varepsilon}$
\end{itemize}

The second term captures how optimal the label for the feature $g(x)$ is for the feature $x$ as well, thus reflecting the initial sensitivity of the signal, which aligns with the intuition discussed by \citet{hardt2023collectiveaction}.

There are two major differences between signal erasing and signal planting or unplanting. First, the term $\frac{n}{N}\left(\underset{x \sim D^{(n)}}{\hat{\mathbb{P}}}(x=x') - 2R_{\tilde{\delta}}(n)\right)$ is significantly weaker in the case of signal erasing because it depends on $\mathcal{X}$ rather than $\tilde{\mathcal{X}}$, making the probability much lower. Second, the term $\tilde{\delta}$ is much smaller, making the estimation terms much more significant. In most cases, we can expect the obtained bound in Theorem \ref{thm:se} to be impractical because the estimation terms will be too large. The bound in Theorem \ref{thm:se} becomes useful only when we have a large number of data points relative to the size of the universe $\mathcal{X} \times \mathcal{Y}$.  

We provide an analysis of the estimation terms to better understand their influence not only in signal erasing but also in signal planting and signal unplanting. We illustrate it with a basic example in Figure~\ref{fig:comparison_R}. We fix $\delta = 0.05$. We consider a binary classification problem: $\# \mathcal{Y} = 2$. In this case, the values of $\tilde{\delta}$ are as follows: $\delta/(2+6\#\tilde{\mathcal{X}})$ in signal planting and signal unplanting, and $\delta/(2+4\#\tilde{\mathcal{X}}+6\#\mathcal{X}) \approx \delta/(2+6\#\mathcal{X})$ in signal erasing, assuming the reasonable hypothesis that $\#\tilde{\mathcal{X}} \ll \#\mathcal{X}$. Therefore, we focus on the estimation terms $R_{\tilde{\delta}}(n)$ with $\tilde{\delta}$ of the form $\delta/(2+6\gamma)$ where $\gamma$ varies. For simplicity, we assume that $\#\tilde{\mathcal{X}}$ and $\#\mathcal{X}$ are powers of two: $\gamma = 2^m$ for some $m \ge 1$. 

\begin{figure}[h]
    \centering
    \includegraphics[width=.6\textwidth]{comparison_R.pdf}
    \caption{Plot of estimation terms $R_{\tilde{\delta}}(n)$ as a function of $n$ for various values of $m$, where $\tilde{\delta} = \delta/(2+6\times2^m)$.}
    \label{fig:comparison_R}
\end{figure}

Given a target error estimation $R_*$, the value $n$ at which $R_{\tilde{\delta}}(n) \le R_*$ is approximately equal to $n \approx \frac{\log(2)}{2R_*^2} m + \frac{\log(6)+\log(1/\delta)}{2R_*^2}$. This value of $n$ scales linearly with $m$.

This simple analysis highlights an interesting phenomenon: the lower bounds obtained are influenced not only by the ratio $n/N$ (i.e., how large $n$ is relative to $N$) but also by the absolute size of $n$ in relation to the universe $\mathcal{X} \times \mathcal{Y}$. This is crucial for obtaining estimation terms $R_{\tilde{\delta}}(n)$ that are as small as possible. The intuition that $n$ needs to be sufficiently large relative to $N$ is already present in the work by \citet{hardt2023collectiveaction}. Our research sheds light on the additional requirement that $n$ should also be large in comparison to the size of the considered universe $\mathcal{X} \times \mathcal{Y}$.


\section{Bounds in the Infinite Data Regime}
\label{app:infinite-data-regime}

As discussed in Subsection \ref{ss:comparative_analysis}, we can compare our results with those presented by \citet{hardt2023collectiveaction} in the infinite data regime when $n, N, N_{\rm test} \rightarrow \infty$ and $n/N \rightarrow \alpha$ for some $\alpha \in (0,1)$. We provide further details on this comparison here.

In the infinite data regime, the framework is the same than in algorithmic collective action: the platform observes the distribution
\[
\mathcal{P}(x_0, y_0) := \alpha \underset{\tilde{\mathcal{D}}}{\mathbb{P}}(x_0, y_0) + (1-\alpha) \underset{\mathcal{D}}{\mathbb{P}}(x_0, y_0)
\]
and selects a classfier $f$ based on the distribution $\mathcal{P}$:
\begin{definition}
\label{def:suboptimal}
Let  $\varepsilon> 0$. A classifier $f: \mathcal{X} \rightarrow \mathcal{Y}$ is $\varepsilon$-suboptimal on a set $\mathcal{X}' \subseteq \mathcal{X}$ under the distribution $\mathcal{P}$ if there exists a distribution $\tilde{\mathcal{P}}$ with $TV(\mathcal{P}, \tilde{\mathcal{P}}) \le \varepsilon$ such that
\[
f(x) \in \underset{y \in \mathcal{Y}}{\text{argmax }} \tilde{\mathcal{P}}(x,y)
\]
for all $x \in \mathcal{X}'$.
\end{definition}

With these notations, we can redefine the successes for the various objectives of the collective and derive lower bounds on these successes. Note that to obtain the bounds below, it is no longer necessary to assume that $\mathcal{X}$ is finite, since this assumption is only used to apply the union bound a finite number of times when the collective performs statistical inference with its finite-sample dataset.

\subsection{Signal planting}

The success is defined as
\[
S(\alpha) := \underset{x \sim \mathcal{D}}{\mathbb{P}}(f(g(x)) = y^*).
\]
The bound (\ref{ineq:sp}) from Theorem \ref{thm:sp} under the feature-label strategy becomes:
    \begin{align}
    \label{ineq:sp_idr}
        S(\alpha) &\ge \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}} \left[  \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha)\Delta_{\tilde{x}}^{(\mathcal{D})}- \frac{\varepsilon}{1-\varepsilon}> 0 \right]
    \end{align}
where $\Delta_{\tilde{x}}^{(\mathcal{D})} = \underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\max } \left(\underset{\mathcal{D} }{\mathbb{P}}(\tilde{x}, y') - \underset{\mathcal{D}}{\mathbb{P}}(\tilde{x}, y^*)\right)$.

Similarly, the bound (\ref{ineq:sp_fo}) from Theorem \ref{thm:sp_fo} under the feature-only strategy becomes:
    \begin{align}
    \label{ineq:sp_fo_idr}
        S(\alpha) &\ge \underset{x \sim \mathcal{D}}{\mathbb{P}} \left[  \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(g(x),y^*)-(1-\alpha)\Delta_{g(x)}^{(\mathcal{D})}- \frac{\varepsilon}{1-\varepsilon}> 0 \right].
    \end{align}


\subsection{Signal unplanting}

The success is defined as
\[
S(\alpha) := \underset{x \sim \mathcal{D}}{\mathbb{P}}(f(g(x)) \neq y^*).
\]

The signal unplanting strategy relies on the choice of some parameter $n_{\rm est} < n$ to estimate the most likely label $y_{g(x)} \neq y^*$ given some feature $g(x)$. In the infinite data regime, we assume that $n_{\rm est} \rightarrow \infty$ and $n-n_{\rm est} \rightarrow \infty$.
The bound (\ref{ineq:su}) from Theorem \ref{thm:su} becomes:
    \begin{align}
    \label{ineq:su_idr}
        S(\alpha) &\ge \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}} \left[  \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha)\Delta_{\tilde{x}}^{(\mathcal{D})}- \frac{\varepsilon}{1-\varepsilon}> 0 \right]
    \end{align}
where $\Delta_{\tilde{x}}^{(\mathcal{D})} = \underset{ \mathcal{D}}{\mathbb{P}}(\tilde{x}, y^*) - \underset{\mathcal{D}}{\mathbb{P}}(\tilde{x}, y_{\tilde{x}})$.

\subsection{Signal erasing}

The success is defined as
\[
S(\alpha) := \underset{x \sim \mathcal{D}}{\mathbb{P}}(f(g(x)) = f(x)).
\]

The erasure strategy relies on the ability to compute the optimal label $y^*_{g(x)}$ for every feature $g(x)$. In the infinite data regime, we assume that the collective has access to $y^*_{g(x)}$. The bound (\ref{ineq:se}) from Theorem \ref{thm:se} becomes:
    \begin{align}
    \label{ineq:se_idr}
        S(\alpha) &\ge \underset{x \sim \mathcal{D}}{\mathbb{P}} \left[  \alpha\underset{\mathcal{D}}{\mathbb{P}}(x)-(1-\alpha)\Delta_{x}^{(\mathcal{D})}- \frac{\varepsilon}{1-\varepsilon}> 0 \right]
    \end{align}
where $\Delta_{x}^{(\mathcal{D})} := \underset{y' \in \mathcal{Y}\backslash \{y^*_{g(x)} \}}{\max } \underset{\mathcal{D}}{\mathbb{P}}(x, y') - \underset{\mathcal{D}}{\mathbb{P}}(x,y^*_{g(x)})$.

\subsection{Comparison with Prior Lower Bounds}

In the original version of their work, \citet{hardt2023collectiveaction} adopt the same definition of $\varepsilon$-suboptimality as in our work. However, there was an issue with their proof in the case where $\varepsilon > 0$. For this reason, we restrict our comparison to the bounds in the case where $\varepsilon=0$. 

\begin{proposition}[Bounds comparison in signal planting when $\varepsilon=0$]
    Assume that the collective plays the feature-label signal planting strategy against a classifier that is $\varepsilon$-suboptimal (in the sense of Definition \ref{def:suboptimal}) on $\tilde{\mathcal{X}}$. Then the collective achieves:
    \begin{align*}
    S(\alpha) &\ge \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}} \left[  \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha)\Delta_{\tilde{x}}^{(\mathcal{D})}> 0 \right]\\
    &\ge 1-\frac{1-\alpha}{\alpha} \underset{\mathcal{D}}{\mathbb{P}}\left(\tilde{\mathcal{X}}\right) \underset{\tilde{x} \in \tilde{\mathcal{X}}}{\max} \  \underset{y \in \mathcal{Y}}{\max} \left(\underset{\mathcal{D}}{\mathbb{P}}(y | \tilde{x}) - \underset{\mathcal{D}}{\mathbb{P}}(y^* | \tilde{x}) \right)
    \end{align*}
    where the first inequality is simply Inequality (\ref{ineq:sp_idr}) and the last term is the lower bound originally provided by \citet{hardt2023collectiveaction}.
\end{proposition}

\begin{proof}
    For all $\tilde{x} \in \tilde{\mathcal{X}}$, we have:
    \begin{align*}
    \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha)\Delta_{\tilde{x}}^{(\mathcal{D})} &= \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha)\underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\max } \left(\underset{\mathcal{D} }{\mathbb{P}}(\tilde{x}, y') - \underset{\mathcal{D}}{\mathbb{P}}(\tilde{x}, y^*)\right)\\
    &= \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha)\underset{y' \in \mathcal{Y}\backslash \{y^* \}}{\max } \left(\underset{\mathcal{D} }{\mathbb{P}}(y'|\tilde{x}) - \underset{\mathcal{D}}{\mathbb{P}}(y^* |\tilde{x})\right)\underset{\mathcal{D} }{\mathbb{P}}(\tilde{x})\\
    &\ge \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha) \ \underset{\tilde{x} \in \tilde{\mathcal{X}}}{\max } \ \underset{y' \in \mathcal{Y}}{\max } \left(\underset{\mathcal{D} }{\mathbb{P}}(y'|\tilde{x}) - \underset{\mathcal{D}}{\mathbb{P}}(y^* |\tilde{x})\right)\underset{\mathcal{D} }{\mathbb{P}}(\tilde{x})
    \end{align*}
    Therefore 
    \begin{align*}
        \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}} \left[  \alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha)\Delta_{\tilde{x}}^{(\mathcal{D})}> 0 \right] &\ge \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}} \left[\alpha\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})-(1-\alpha) \ \underset{\tilde{x} \in \tilde{\mathcal{X}}}{\max } \ \underset{y \in \mathcal{Y}}{\max } \left(\underset{\mathcal{D} }{\mathbb{P}}(y|\tilde{x}) - \underset{\mathcal{D}}{\mathbb{P}}(y^* |\tilde{x})\right)\underset{\mathcal{D} }{\mathbb{P}}(\tilde{x}) > 0 \right] \\
        &=\underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{P}} \left[1-\frac{1-\alpha}{\alpha} \ \underset{\tilde{x} \in \tilde{\mathcal{X}}}{\max } \ \underset{y \in \mathcal{Y}}{\max } \left(\underset{\mathcal{D} }{\mathbb{P}}(y|\tilde{x}) - \underset{\mathcal{D}}{\mathbb{P}}(y^* |\tilde{x})\right)\frac{\underset{\mathcal{D} }{\mathbb{P}}(\tilde{x})}{\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})} > 0 \right]\\
        &= \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{E}}\left[ \mathbb{1}_{\left\{ 1-\frac{1-\alpha}{\alpha} \ \underset{\tilde{x} \in \tilde{\mathcal{X}}}{\max } \ \underset{y \in \mathcal{Y}}{\max } \left(\underset{\mathcal{D} }{\mathbb{P}}(y|\tilde{x}) - \underset{\mathcal{D}}{\mathbb{P}}(y^* |\tilde{x})\right)\frac{\underset{\mathcal{D} }{\mathbb{P}}(\tilde{x})}{\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})} > 0  \right\}}  \right]\\
        &\ge \underset{\tilde{x} \sim \tilde{\mathcal{D}}}{\mathbb{E}}\left[ 1-\frac{1-\alpha}{\alpha} \ \underset{\tilde{x} \in \tilde{\mathcal{X}}}{\max } \ \underset{y \in \mathcal{Y}}{\max } \left(\underset{\mathcal{D} }{\mathbb{P}}(y|\tilde{x}) - \underset{\mathcal{D}}{\mathbb{P}}(y^* |\tilde{x})\right)\frac{\underset{\mathcal{D} }{\mathbb{P}}(\tilde{x})}{\underset{\tilde{\mathcal{D}}}{\mathbb{P}}(\tilde{x})}    \right]\\
        &= 1-\frac{1-\alpha}{\alpha} \underset{\mathcal{D}}{\mathbb{P}}\left(\tilde{\mathcal{X}}\right) \underset{\tilde{x} \in \tilde{\mathcal{X}}}{\max} \  \underset{y \in \mathcal{Y}}{\max} \left(\underset{\mathcal{D}}{\mathbb{P}}(y | \tilde{x}) - \underset{\mathcal{D}}{\mathbb{P}}(y^* | \tilde{x}) \right)
    \end{align*}
\end{proof}

The authors subsequently revised their proof when $\varepsilon > 0$ by modifying the suboptimality definition, which we refer to as $\varepsilon$-conditional suboptimality to provide clarity and distinguish between the two definitions: 

\begin{definition}
Let  $\varepsilon> 0$. A classifier $f: \mathcal{X} \rightarrow \mathcal{Y}$ is $\varepsilon$-conditionally suboptimal on a set $\mathcal{X}' \subseteq \mathcal{X}$ under the distribution $\mathcal{P}$ if there exists a distribution $\tilde{\mathcal{P}}$ with $TV(\mathcal{P}_{Y \mid X=x}, \tilde{\mathcal{P}}_{Y \mid X=x}) \le \varepsilon$ such that
\[
f(x) \in \underset{y \in \mathcal{Y}}{\text{argmax }} \tilde{\mathcal{P}}(x,y)
\]
for all $x \in \mathcal{X}'$.
\end{definition}

Using this definition of conditional suboptimality, we could derive bounds similar to those given in (\ref{ineq:sp}), (\ref{ineq:sp_fo}), (\ref{ineq:su}), (\ref{ineq:se}), (\ref{ineq:sp_idr}), (\ref{ineq:sp_fo_idr}), (\ref{ineq:su_idr}), and (\ref{ineq:se_idr}), and conduct the same kind of comparisons with the bounds from \citet{hardt2023collectiveaction}.

\end{document}
