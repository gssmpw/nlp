@inproceedings{10.5555/3041838.3041846,
author = {Brinker, Klaus},
title = {Incorporating diversity in active learning with support vector machines},
year = {2003},
isbn = {1577351894},
publisher = {AAAI Press},
abstract = {In many real world applications, active selection of training examples can significantly reduce the number of labelled training examples to learn a classification function. Different strategies in the field of support vector machines have been proposed that iteratively select a single new example from a set of unlabelled examples, query the corresponding class label and then perform retraining of the current classifier. However, to reduce computational time for training, it might be necessary to select batches of new training examples instead of single examples. Strategies for single examples can be extended straightforwardly to select batches by choosing the h > 1 examples that get the highest values for the individual selection criterion. We present a new approach that is especially designed to construct batches and incorporates a diversity measure. It has low computational requirements making it feasible for large scale problems with several thousands of examples. Experimental results indicate that this approach provides a faster method to attain a level of generalization accuracy in terms of the number of labelled examples.},
booktitle = {Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
pages = {59–66},
numpages = {8},
location = {Washington, DC, USA},
series = {ICML'03}
}

@ARTICLE{10433480,
  author={Raiaan, Mohaimenul Azam Khan and Mukta, Md. Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
  journal={IEEE Access}, 
  title={A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges}, 
  year={2024},
  volume={12},
  number={},
  pages={26839-26874},
  keywords={Cognition;Artificial intelligence;Transformers;Training;Taxonomy;Task analysis;Surveys;Natural language processing;Question answering (information retrieval);Information analysis;Linguistics;Large language models (LLM);natural language processing (NLP);artificial intelligence;transformer;pre-trained models;taxonomy;application},
  doi={10.1109/ACCESS.2024.3365742}}

@INPROCEEDINGS{5206627,
  author={Joshi, Ajay J. and Porikli, Fatih and Papanikolopoulos, Nikolaos},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Multi-class active learning for image classification}, 
  year={2009},
  volume={},
  number={},
  pages={2372-2379},
  keywords={Image classification;Training data;Humans;Iterative algorithms;Layout;Labeling;Sampling methods;Measurement uncertainty;Size measurement;Object recognition},
  doi={10.1109/CVPR.2009.5206627}}

@inproceedings{QBC,
author = {Seung, H. S. and Opper, M. and Sompolinsky, H.},
title = {Query by committee},
year = {1992},
isbn = {089791497X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/130385.130417},
doi = {10.1145/130385.130417},
abstract = {We propose an algorithm called query by commitee, in which a committee of students is trained on the same data set. The next query is chosen according to the principle of maximal disagreement. The algorithm is studied for two toy models: the high-low game and perceptron learning of another perceptron. As the number of queries goes to infinity, the committee algorithm yields asymptotically finite information gain. This leads to generalization error that decreases exponentially with the number of examples. This in marked contrast to learning from randomly chosen inputs, for which the information gain approaches zero and the generalization error decreases with a relatively slow inverse power law. We suggest that asymptotically finite information gain may be an important characteristic of good query algorithms.},
booktitle = {Proceedings of the Fifth Annual Workshop on Computational Learning Theory},
pages = {287–294},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {COLT '92}
}

@article{Rae2021,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Scott and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@inproceedings{androutsopoulos2000an,
  title={An experimental comparison of naive Bayesian and keyword-based anti-spam filtering with personal e-mail messages},
  author={Androutsopoulos, Ion and Koutsias, John and Chandrinos, Vangelis and Spyropoulos, Constantine D},
  booktitle={Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={160--167},
  year={2000},
  organization={ACM}
}

@article{angluin1988queries,
  title={Queries and concept learning},
  author={Angluin, Dana},
  journal={Machine learning},
  volume={2},
  pages={319--342},
  year={1988},
  publisher={Springer}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{cohn1994improving,
  title={Improving generalization with active learning},
  author={Cohn, David and Atlas, Les and Ladner, Richard},
  journal={Machine learning},
  volume={15},
  pages={201--221},
  year={1994},
  publisher={Springer}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{kowsari2019text,
  title={Text classification algorithms: A survey},
  author={Kowsari, Kamran and Heidarysafa, Mojtaba and Brown, Donald E and Meimandi, Kiana Jafari and Barnes, Laura E},
  journal={Information},
  volume={10},
  number={4},
  pages={150},
  year={2019},
  publisher={MDPI}
}

@inproceedings{lewis1994sequential,
  title={A sequential algorithm for training text classifiers},
  author={Lewis, David D and Gale, William A},
  booktitle={Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={3--12},
  year={1994},
  organization={Springer-Verlag New York, Inc.}
}

@inproceedings{liu2019roberta,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  booktitle={Proceedings of the Association for Computational Linguistics (ACL)},
  year={2019},
  url={https://arxiv.org/abs/1907.11692}
}

@inproceedings{pang2002thumbs,
  title={Thumbs up?: sentiment classification using machine learning techniques},
  author={Pang, Bo and Lee, Lillian and Vaithyanathan, Shivakumar},
  booktitle={Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10},
  pages={79--86},
  year={2002},
  organization={Association for Computational Linguistics}
}

@article{sebastiani2002machine,
  title={Machine learning in automated text categorization},
  author={Sebastiani, Fabrizio},
  journal={ACM computing surveys (CSUR)},
  volume={34},
  number={1},
  pages={1--47},
  year={2002},
  publisher={ACM New York, NY, USA}
}

@inproceedings{sener2018active,
    title={Active Learning for Convolutional Neural Networks: A Core-Set Approach},
    author={Ozan Sener and Silvio Savarese},
    booktitle={International Conference on Learning Representations},
    year={2018},
    url={https://openreview.net/forum?id=H1aIuk-RW},
}

@inproceedings{settles-craven-2008-analysis,
    title = "An Analysis of Active Learning Strategies for Sequence Labeling Tasks",
    author = "Settles, Burr  and
      Craven, Mark",
    editor = "Lapata, Mirella  and
      Ng, Hwee Tou",
    booktitle = "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2008",
    address = "Honolulu, Hawaii",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D08-1112/",
    pages = "1070--1079"
}

@inproceedings{tong2002support,
  title={Support vector machine active learning with applications to text classification},
  author={Tong, Simon and Koller, Daphne},
  booktitle={Journal of Machine Learning Research},
  year={2002}
}

@article{zhang2015text,
  title={A sensitivity analysis of (and practitioners' guide to) convolutional neural networks for sentence classification},
  author={Zhang, Ye and Wallace, Byron C},
  journal={arXiv preprint arXiv:1510.03820},
  year={2015}
}

