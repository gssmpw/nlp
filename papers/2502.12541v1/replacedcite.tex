\section{Related Work and Problem Statement}
\label{related_work}
This section explores four key areas related to the scenarios identified in the Introduction, providing a foundation for the research objectives addressed in this study.
\subsection{Patch-Wise HSI Classification}
HSI classification assigns semantic labels to pixels, but pixel-wise classification is prone to noise, inter-class similarities, and intra-class variabilities. To mitigate these challenges, patch-wise learning frameworks have been widely adopted, incorporating spatial context by using small local patches around each pixel. This spectral-spatial approach has consistently outperformed purely spectral-only or spatial-only methods.

With recent deep learning advancements, patch-wise HSI classification techniques have achieved remarkable results. Early approaches used deep 2D-CNNs ____, later evolving into hybrid 3D-2D CNNs for improved spectral-spatial feature extraction ____. Attention-enhanced 3D-CNNs further boosted accuracy by emphasizing salient features ____. RNNs were introduced for spectral-spatial modeling, with some methods separately processing spectral and spatial dependencies before fusing them ____, while others combined CNNs and RNNs for cascaded feature integration ____ or employed multi-directional RNNs for refined representation learning ____. More recently, ViTs have emerged as state-of-the-art solutions, with approaches like SpectralFormer, which refines Transformer encoders through band-grouping strategies ____, and tokenized ViTs, which integrate 3D-2D CNNs ____. Other architectures include hierarchical Transformers for joint spectral-spatial feature extraction ____ and multi-scale attention mechanisms that enhance spatial pattern recognition ____. Additionally, some methods incorporate multi-directional positional embeddings from RNNs to enable purely sequential spectral-spatial processing ____.


Despite these advancements, the reliance on small patch sizes inherently limits the receptive field, failing to capture large-scale spatial structures. This limitation is particularly problematic for complex land-cover regions and boundary areas. While increasing the patch size can provide richer contextual information, it also introduces interfering pixels, leading to feature blending and degraded classification accuracy ____. Additionally, small patch-based methods often suffer from noise-like misclassifications in uniform and homogeneous regions, where inconsistent predictions create isolated errors that disrupt spatial coherence. This issue resembles the "salt-and-pepper" effect, undermining classification reliability in otherwise smooth areas. Furthermore, down-sampling-based decoders struggle to preserve fine details, making optimal patch selection a persistent challenge. Overcoming these limitations and striking the right balance between patch size and contextual coverage remains a promising research direction in this field.


\subsection{Image Segmentation with U-Net}
Image segmentation, which assigns semantic labels to each pixel, plays a crucial role in fields such as medical imaging, RS, autonomous driving, and robotics. Deep learning has significantly advanced segmentation accuracy, with U-Net ____ emerging as one of the most influential architectures. Originally designed for biomedical tasks, U-Net’s symmetric encoder-decoder structure and skip connections enable the fusion of deep semantic features with fine-grained spatial details, leading to precise pixel-level classification. Segmentation models operate on larger spatial regions, capturing broader context and improving boundary delineation, establishing meaningful spatial relationships.

Building on U-Net’s success, various enhancements have been developed. U-Net++ ____ improves skip connections with dense blocks for enhanced feature fusion, while 3D U-Nets ____ handle volumetric data. Attention U-Nets ____ integrate attention mechanisms for complex scene understanding. More recently, Transformer-based U-Nets have been introduced to capture long-range dependencies. TransUnet ____ incorporates a Transformer encoder with a U-shaped decoder for improved global-local feature modeling, while SwinUnet ____ utilizes Swin Transformers ____ to enhance multi-scale feature representation through hierarchical self-attention.

In RS field, segmentation models have been widely applied to large-scale optical aerial and satellite imagery for land-cover mapping. Approaches such as CNN-Transformer hybrid U-Nets ____, multi-modal fusion networks combining CNN and ViT features ____, and multi-scale convolutional attention with cross-shaped window Transformers ____ have achieved satisfying results in large-scale RS segmentation.

Applying segmentation frameworks directly to HSI classification presents several challenges. Segmentation models typically assume fully labeled datasets, while HSI ground-truths often contain extensive unlabeled regions with limited annotations, which can mislead model training. Additionally, the traditional patch-wise learning framework struggles to support larger region cropping due to the limited spatial dimensions of HSI data. As a result, most current HSI studies rely on patch-wise or pixel-wise classification, leaving large-scale segmentation largely under-explored. To address these limitations, our study aims to introduce a segmentation-based paradigm for HSI classification, moving beyond traditional small patch-wise approaches to enable larger context-aware feature learning. Given the absence of prior work applying segmentation techniques to HSI classification, we carefully select the well-known SwinUnet as our research benchmark , which we aim to modify and improve to achieve superior results.


\subsection{Multi-Source Data Collaboration}
To enhance HSI classification, numerous studies have incorporated auxiliary data sources such as LiDAR, SAR, and MSI, leveraging their complementary properties to generate more discriminative features. For instance, LiDAR-derived digital surface models (DSM) provide valuable elevation information, improving semantic differentiation in land-cover analysis.

Recent efforts have explored various multi-source fusion techniques. HSI-MSI fusion has been improved using depthwise feature interaction networks with CNNs  ____. HSI-MSI-SAR integration has been addressed through shared and specific feature learning models ____. Meanwhile, symmetric fusion Transformers with local-global mixture modules have been employed for HSI-LiDAR fusion, promoting more robust multi-source learning ____. Other advanced strategies include masked auto-encoders for multi-source data reconstruction prior to classification ____ and HSI-X networks, such as multistage information-complementary fusion models using flexible mixup ____ and local-to-global cross-modal attention-aware architectures for effective feature alignment across modalities ____. While these approaches have demonstrated effectiveness, several critical issues remain.

Existing fusion methods typically adopt early fusion (Fig. \ref{concept}(b)), where auxiliary data is combined with HSI before encoding, or late fusion (Fig. \ref{concept}(c)), where features are merged after separate encoders process each modality. Both strategies lack interactive feature exchange between modalities within the encoder and decoder, and they primarily rely on small patch-based learning frameworks. Early fusion risks suboptimal representations, as it fails to preserve modality-specific characteristics (e.g., SAR data affected by speckle noise may degrade fusion quality). Late fusion, in contrast, treats each modality independently, limiting its ability to capture complementary relationships. Moreover, most approaches employ simple down-sampling-based fully connected layers as decoders, which further restricts multi-source feature refinement. Thus, an effective fusion framework should enable modality collaboration across both encoding and decoding stages, particularly within models utilizing larger receptive fields under segmentation techniques. However, this remains an under-explored research direction.


\subsection{Semi-Supervised Learning with Pseudo Labeling}
Acquiring pixel-level annotations for HSI is both costly and time consuming, requiring domain expertise and extensive ground verification. As a result, HSI datasets typically contain a significant number of unlabeled pixels, which are often assigned a generic background label (e.g., 0). Traditional HSI classification methods train models exclusively on labeled regions, evaluating performance on the remaining labeled pixels while ignoring the distribution of unlabeled regions. While this approach may achieve acceptable accuracy, it fails to utilize valuable spectral and spatial information hidden within the unlabeled data, limiting the model’s generalization capability.

Semi-supervised learning (SSL) and pseudo-labeling have emerged as effective strategies to incorporate unlabeled data into training. Some approaches generate pseudo-labels through cluster assignments, leveraging large amounts of unlabeled data to refine feature learning ____. Other methods pre-train deep CNN-RNN models on pseudo-labeled samples before fine-tuning them on limited labeled data ____. Probabilistic frameworks have also been explored, where pseudo-labels are assigned based on Gaussian distributions to maximize feature consistency ____. More advanced techniques focus on reducing pseudo-label noise by filtering out low-confidence samples. Some methods distinguish between reliable and unreliable pseudo-labels, incorporating only high-confidence samples into the training process ____. Others iteratively refine pseudo-labels through multi-scale super-pixel segmentation and spectral-spatial distance analysis ____. Additionally, uncertainty-aware selection strategies based on Bayesian networks have been introduced to iteratively update pseudo-labels while minimizing misclassification risks ____.

Despite these advancements, existing HSI pseudo-labeling strategies face several limitations. Most approaches rely on static pseudo-label assignments, which remain fixed throughout training and fail to adapt as the model evolves. Additionally, fixed thresholding criteria are commonly used to determine pseudo-label reliability, yet these thresholds may not accurately reflect confidence variations or data complexity. Lastly, most methods treat all unlabeled pixels equally, overlooking the potential benefits of selectively incorporating only the most informative samples. These constraints limit the model’s ability to fully leverage unlabeled data, necessitating more adaptive and dynamic pseudo-labeling frameworks for HSI classification.