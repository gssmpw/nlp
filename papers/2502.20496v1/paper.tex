%
\documentclass[acmsmall,screen,nonacm]{acmart}

%

%
%
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%
%
%
%
%
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%
%
\acmJournal{JACM}
\acmVolume{37}
\acmNumber{4}
\acmArticle{111}
\acmMonth{8}

%
%
%
%
%
%

%

\usepackage{main}

%
%
%
%
%

\begin{document}

%

%
\title{Abstraction Functions as Types}
\subtitle{Modular Verification of Algorithms and Data Structures}
%
%
%

\begin{abstract}
  Modular development of programs relies on the principle that library code may be freely replaced without affecting client behavior.
  %
  While an interface mediating this interaction should require a precise behavior of its implementations, allowing for downstream verification of client code, it should do so in a manner that allows private algorithmic and representation choices to vary freely.
  In this work we demonstrate how such modularity can be achieved in dependent type theory using a phase distinction between private algorithmic content and public client-facing behavior.
  We observe that modalities associated with such a phase distinction and their corresponding theorems, particularly noninterference and fracture, give rise to precise descriptions of common constructions surrounding algorithms and data structures.
  Using a modal construction to classify types that sufficiently restrict client-facing behavior, we use the noninterference property for the phase to state and prove a modularity property guaranteeing that implementations may be freely replaced without affecting behavior.
  We then cast the fracture property in the light of abstraction functions, showing internally that every type consists of a private algorithmic component, a public behavioral component representing an abstract data type, and an abstraction function between them that is uniformly activated by the behavioral phase for streamlined verification of client correctness.
  Finally, we use phased quotient types to ergonomically mark private data for behavioral deletion.
  We situate this development in a univalent adaptation of \calf{}, a dependent type theory for cost analysis, in order to amplify these points: beyond hiding private implementation details, we treat cost as a private matter that may be varied freely without affecting the behavior of clients.
\end{abstract}
 
%

\author{Harrison Grodin}
\orcid{0000-0002-0947-3520}
\email{hgrodin@cs.cmu.edu}

%
%
%
%
%
%
%
%
%

\author{Runming Li}
\orcid{}
\email{runmingl@cs.cmu.edu}

%
%
%
%
%
%
%
%
%

\author{Robert Harper}
\orcid{0000-0002-9400-2941}
\email{rwh@cs.cmu.edu}

\affiliation{
  \institution{Carnegie Mellon University}
  \department{Computer Science Department}
  \streetaddress{5000 Forbes Ave.}
  \city{Pittsburgh}
  \state{PA}
  \postcode{15213}
  \country{USA}
}

\begin{CCSXML}
  <ccs2012> <concept> <concept_id>10003752.10003790.10011740</concept_id>
     <concept_desc>Theory of computation~Type theory</concept_desc>
     <concept_significance>500</concept_significance> </concept> <concept>
     <concept_id>10003752.10003790.10002990</concept_id> <concept_desc>Theory of
     computation~Logic and verification</concept_desc>
     <concept_significance>500</concept_significance> </concept> <concept>
     <concept_id>10011007.10011006.10011008.10011009.10011012</concept_id>
     <concept_desc>Software and its engineering~Functional
     languages</concept_desc> <concept_significance>300</concept_significance>
     </concept> <concept>
     <concept_id>10003752.10010124.10010131.10010137</concept_id>
     <concept_desc>Theory of computation~Categorical semantics</concept_desc>
     <concept_significance>300</concept_significance> </concept> <concept>
     <concept_id>10003752.10010124.10010138.10010143</concept_id>
     <concept_desc>Theory of computation~Program analysis</concept_desc>
     <concept_significance>300</concept_significance> </concept> </ccs2012>
\end{CCSXML}

  \ccsdesc[500]{Theory of computation~Type theory}
  \ccsdesc[500]{Theory of computation~Logic and verification}
  \ccsdesc[300]{Software and its engineering~Functional languages}
  \ccsdesc[300]{Theory of computation~Program analysis}
  \ccsdesc[300]{Theory of computation~Categorical semantics}

%

\keywords{phase distinction, noninterference, information flow, modal type theory, abstraction, abstraction function, abstract data type, data structure, algorithm, equational reasoning, verification, mechanized proof, proof assistants}

\maketitle

%
\section{Introduction}\label{sec:introduction}

Software development is fundamentally a community effort, spread over space and time, with no one person having a complete mastery of the code involved.
Therefore, the single most effective tool in software development is the composition of programs from reusable, replaceable parts that are not under the control or influence of any one developer.
Developers rely on abstractions---some form of \emph{type}---to describe the assumptions that clients may rely upon when using a component, and, correspondingly, the obligations that implementors must provide.
The essence of modularity is that implementations of the same abstraction may be freely swapped out without any impact on the behavior of the surrounding program.

%
%
%
%

Consider one such abstraction, the queue abstract data type $\Name{Queue}$, and suppose some client code $f : \Name{Queue} \to X$ implements a type $X$ using its input queue implementation as library code.
The essence of modularity is the guarantee that queue implementations can be freely replaced without affecting the functional behavior of $f$:
\begin{center}
  for all $q,q' : \Name{Queue}$, we have that $f(q) = f(q')$.
\end{center}
Assuming that there is some basic implementation, $q_0 : \Name{Queue}$, this description amounts to saying that the type $\Name{Queue}$ is contractible (\ie, singleton, terminal, or equivalent to the unit type).
This idea is harmonious with the intuitive understanding a client should have about queues: the behavior should be completely pinned down.
%
We could achieve such a contractible type by defining
\[ \Name{Queue} \isdef \sum_{q : \Name{PreQueue}} q = q_0, \]
where $\Name{PreQueue}$ describes a type equipped with queue operations and the constraint $q = q_0$ restricts the type and operations in $q$ to match the behavior mandated by the specification $q_0$.

Say the specification $q_0$ has representation type $\listty{\nat}$, a canonical form for queues.
Then, other implementations would have to come equipped with a proof that their implementation type is equivalent to $\listty{\nat}$, and the queue operations cohere according to this equivalence.
The cleverness of an implementation typically serves to improve upon the efficiency of the naive code given as the behavioral specification $q_0$.
While the type $\listty{\nat} \times \listty{\nat}$ used to implement batched queues does not immediately satisfy this property, \citet{angiuli-cavallo-mortberg-zeuner>2021} demonstrate how to use quotient types in a univalent setting to identify states that induce equivalent client behavior.
For example, we could quotient the type $\listty{\nat} \times \listty{\nat}$ by equivalence under the function
$\Impl{revAppend} : \listty{\nat} \times \listty{\nat} \to \listty{\nat}$
which converts a pair of lists representing a queue to their single-list correspondent.

%
%
%
%

Although the use of contractible types as specifications achieves modularity, it is at the expense of concerns about efficiency.
The identification of data with equivalent functional behavior is pervasive: one cannot hope to uniformly extract the code that does not depend on its presence.
%
%
However, the purpose of an implementation other than the specification is \emph{efficiency}: although its behavior is fixed, the cleverness of its implementation serves to improve upon the naive code given as the behavioral specification.
It is paramount, therefore, to retain \emph{differences} between algorithms and data structures that implement a given behavior: although a queue can be thought of as a list of elements when analyzing behavior, a more clever representation (\eg, a pair of lists without a quotient) may be preferable internally.
%
%

%
%

To mediate this tension between efficient code and behavioral verification, we introduce a synthetic \emph{phase distinction}~\citep{sterling-harper>2021} between private \emph{algorithmic} choices and public \emph{behavior}.
If we then relax the requirement on $\Name{Queue}$, asking only for it to be \emph{behaviorally} contractible, we allow the retention of algorithmic content that differs between queue implementations even though equivalent states must be \emph{behaviorally} identified.
We then get a weakened property that guarantees modularity of behavior:
\begin{center}
  for all $q,q' : \Name{Queue}$, we have that $\eqOp{f(q)}{f(q')}$,
\end{center}
where $\eqOp{x}{x'}$ denotes \emph{behavioral} equivalence.
To implement queues using a pair of lists, we may then choose to activate the quotient only in the behavioral phase.

Technically, this phase is realized as a proposition $\beh$ in dependent type theory corresponding to the assumption of operating with concern only for functional behavior.
The proposition gives rise to various devices in type theory, including a \emph{behavioral modality} for entering the behavioral phase, an \emph{algorithmic modality} for marking data as behaviorally-irrelevant~\citep{rijke-shulman-spitters>2020}.
The modularity property can be proved from these modalities within the type theory.

The use of a phase distinction allows us to integrate both algorithmic and behavioral concerns into a single program, justified by the \emph{fracture theorem}~\citep[\S 3.4]{rijke-shulman-spitters>2020}.
%
%
%
This theorem says that every type can be fractured into (or reconstructed from) three parts: a public behavioral type $\BEH{X}$, a private algorithmic type $\ALGO{X}$, and an \emph{abstraction function}~\cite{hoare>1972} $\alpha : \ALGO{X} \to \BEH{X}$ that converts the concrete representation of type $\ALGO{X}$ to the abstract behavior of type $\BEH{X}$.
In other words, every representation type inherently comes equipped have a conversion to its behavioral representation type, concisely stated by the following slogan:
\begin{center}
  \emph{Types are abstraction functions.}
\end{center}
Semantically, every type may be interpreted as a presheaf that incorporates both algorithmic and behavioral content, which can be constructed synthetically within type theory using the fracture theorem.
For example, we will arrange for the presheaf
\[ \Presheaf[\Impl{revAppend}]{\listty{\nat} \times \listty{\nat}}{\listty{\nat}} \]
to be the semantics of the type implementing batched queues, storing a pair of lists as the efficient algorithmic representation alongside the single-list behavioral perspective.
The included $\Impl{revAppend}$ function will fire automatically in the behavioral phase, irreversibly fusing the pair of lists into the simpler single-list representation for behavioral verification.

We situate our story in \calf{}, a type theory for synthetic cost analysis, which advocates for the use of such a phase under which cost annotations are erased~\citep{niu-sterling-grodin-harper>2022}.
%
Our development builds on this perspective, continuing to treat cost annotations as private \emph{algorithmic} data although extending the use case of behaviorally contractible types to classify types that provide a sufficiently descriptive behavioral verification.
%
We demonstrate the need for a more liberal use of the algorithmic modality and related erasure techniques: if implementations are to meet a unique behavior specified by an algorithmic interface, we show that the types involved must explicitly mark their own private data for redaction.
We now introduce these ideas formally, recalling key elements of the phased \calf{} type theory and theorems about the phase modalities.


\subsection{Effectful dependent type theory}

To support effectful programs in dependent type theory, we operate in a dependent type theory that distinguishes between running computations and inert values, both in terms and types.
We work in a version of call-by-push-value~\cite{levy>2003}, inspired by \citet{ahman-ghani-plotkin>2016,vakar>thesis,pedrot-tabareau>2019,krishnaswami-pradic-benton>2015}.
We include features of the Enriched Effect Calculus \cite{egger-mogelberg-simpson>2009,egger-mogelberg-simpson>2014}, adapted to the dependent setting.
Additionally, we use the linear universe structure of \citet{krishnaswami-pradic-benton>2015} (with levels omitted for simplicity), writing $\tpv$ for the universe of value types and $\tpc$ for the universe of computation types (both of which are, themselves, value types).
\begin{align*}
  \text{Val.} \quad X,Y,Z &\coloncolonequals \U{A} \mid \nat \mid \listty{X} \mid 1 \mid \textstyle\sum_{x : X} Y(x) \mid \prod_{x : X} Y(x) \mid A \lolli B \mid \tpv \mid \tpc \mid x =_X x' \\
  \text{Comp.} \quad A,B,C &\coloncolonequals \F{X} \mid \textstyle\prod_{x : X}A(x)
\end{align*}
We freely use standard abbreviations and notations for readability, such as $X \pto A \isdef \prod_{x : X} A$. %
We use common notations for programs involving these types, such as pattern matching on $\ret{x}$ (the introduction form for the $\F{X}$ type) as the elimination form for $\F{X}$.
Following \calf{}~\citep{niu-sterling-grodin-harper>2022}, we also use the ``less bureaucratic'' form of adjoint type theory in which the introduction and elimination forms for the $\U{A}$ type are left implicit.

In \cref{sec:free} we assume commutativity of the effects present and use the monoidal structure $(\top, \otimes)$ given by linear/non-linear type theory~\cite{benton>1995,krishnaswami-pradic-benton>2015}:
\begin{align*}
  A,B,C &\coloncolonequals \dots \mid \top \mid A \otimes B
\end{align*}


\subsection{Univalent equality}\label{sec:extensionality}

This work takes place in a univalent type theory~\cite{univalentfoundations>2013,rijke>2022} equipped with proof-relevant extensional equality $x =_X x'$ (\ie, path types).
%
%
We assume the following extensionality principles for equality:
\begin{subequations}
\begin{align}
  f =_{\prod_{x : X} Y(x)} f' &\isdef \prod_{x : X} f(x) =_{Y(x)} f'(x) \label{eq:eq-pi} \\
  (x, y) =_{\sum_{x : X} Y(x)} (x', y') &\isdef \sum_{p : x =_X x'} p_*(y) =_{Y(x')} y' \label{eq:eq-sigma} \\
  X =_{\tpv} X' &\isdef \sum_{f : X \to X'} \IsEquiv[\tpv]{f} \label{eq:eq-tpv} \\
  A =_{\tpc} A' &\isdef \sum_{f : A \lolli A'} \IsEquiv[\tpc]{f} \label{eq:eq-tpc}
\end{align}
\end{subequations}
In a univalent setting equality of dependent products and sums are given extensionally.
Moreover, the principle of univalence says that equality at the universes of value types $\tpv$ and computation types $\tpc$ is equivalence~\citep[Chapter 9]{rijke>2022}, using linear functions as maps between computation types~\citep{egger-mogelberg-simpson>2009,egger-mogelberg-simpson>2014}, where
\begin{align*}
  \IsEquiv[\tpv]{f : X \to X'} &\isdef \sum_{s, r : X' \to X} (s \mathbin{;} f = \text{id}_{X'}) \times (f \mathbin{;} r = \text{id}_{X}) \\
  \IsEquiv[\tpc]{f : A \lolli A'} &\isdef \sum_{s, r : A' \lolli A} (s \mathbin{;} f = \text{id}_{A'}) \times (f \mathbin{;} r = \text{id}_{A})
\end{align*}
say that $f$ is an equivalence when it admits both a section and a retraction.
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

Although we are working in a univalent setting, the types we consider will all be set-truncated (aside from the universes $\tpv$ and $\tpc$).
Thus, when we define a higher inductive type (in this work, only quotient types), we omit explicit set-truncation for brevity.

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%

%
%
%

%
%
%
%
%
%
%
%
%
%
%
%

%

%
%
%
%

%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%


\subsection{Behavioral phase distinction}
To facilitate the development proposed above, we postulate a synthetic \emph{phase distinction}~\citep{sterling-harper>2021,sterling>thesis} that allows the uniform isolation of the behavioral semantics of programs.
%
Specifically, the \emph{behavioral phase}%
\footnote{We use the ``behavioral/algorithmic'' terminology in place of the ``extensional/intensional'' terminology from previous developments of \calf{}~\cite{niu-sterling-grodin-harper>2022,grodin-niu-sterling-harper>2024}, avoiding confusion with the unrelated ideas of extensional/intensional type theory and mathematical extensionality principles while emphasizing the abstraction viewpoint of this work.}
is a postulated proposition $\beh : \tpv$ that, when inhabited, erases details relevant only for efficiency, leaving behind only the behavior for analysis of correctness.
Because $\beh$ is a proposition, we always use variable name $\b : \beh$ for convenience.

%

\subsubsection{Behavioral and algorithmic modalities}
Associated with the proposition $\beh$ are a pair of idempotent monadic modalities, the behavioral modality and the algorithmic modality~\cite{rijke-shulman-spitters>2020}.

\begin{definition}
  The \emph{behavioral modality} $\Op X \isdef \beh \to X$ is the reader monad for the type $\beh$, imposing the behavioral phase to suppress cost information and isolate the behavioral aspect of a type $X$.
  We say a type $X$ is \emph{behavioral} when $\Op X \iso X$,%
  \footnote{In other work this notion has been referred to as open-modal/$\Op$-modal~\cite{rijke-shulman-spitters>2020}, $\beh$-transparent~\cite{sterling-harper>2022,sterling>2022-logical-relations}, and (purely) extensional~\cite{niu-sterling-grodin-harper>2022,grodin-niu-sterling-harper>2024} types.}
  and we call an inhabitant of a behavioral type a \emph{behavior}.
  We say a type family $Y : X \to \tpv$ is behavioral when $Y(x)$ is behavioral for all $x : X$, and we say a map $f : Y \to X$ is behavioral when $\fib{f}{x} \isdef \sum_{y : Y} f(x) = y$ is behavioral.
\end{definition}

We may unambiguously use the same notation for a dependent variant of the behavioral modality, as well: given a type family $X : \beh \to \tpv$, we write $\Op X$ for $\prod_{\b : \beh} X(\b)$.
Additionally, we write $\eqOp{x}{x'}$ as a shorthand for $\Op(x = x')$.

\begin{definition}\label{def:closed-modality}
  The \emph{algorithmic modality} $\Cl X$ marks a type as behaviorally irrelevant: crucially, we have that $\Op \Cl X \iso \unit$.
  It is defined as the pushout of the behavioral equivalence $\pi_1 : X \times \beh \to X$ along the map $\pi_2 : X \times \beh \to \beh$, sometimes written $\Cl X \isdef X \lor \beh$:
%
  \begin{center}
    \begin{minipage}{0.5\linewidth}
      %
      \[\begin{tikzcd} {X \times \beh} & \beh \\
        X & {\Cl X}
        \arrow["{\pi_1}", from=1-1, to=2-1]
        \arrow["{\pi_2}", from=1-1, to=1-2]
        \arrow["{\starCl}", from=1-2, to=2-2]
        \arrow["{\etaCl}", from=2-1, to=2-2]
        \arrow["\lrcorner"{anchor=center, pos=0.125, rotate=180}, draw=none, from=2-2, to=1-1]
      \end{tikzcd}\]
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
      \iblock{
        \mhang{\kw{data}~\Cl~(X : \tpv) : \tpv~\kw{where}}{
          \mrow{\Label{\etaCl} : X \to \Cl X}
          \mrow{\Label{\starCl} : \{\b : \beh\} \to \Cl X}
          \mrow{\Label{\_} : (x : X)~\{\b : \beh\} \to \Label{\etaCl} x = \Label{\starCl}}
        }
      }
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
      %
    \end{minipage}
  \end{center}
%
  For convenience, we make the argument to the constructor $\starCl$ of type $\beh$ implicit, indicated with braces.
  The quotient case induced by the pushout must be respected by users of this modality: when casing on data of type $\Cl X$, both the $\etaCl$ and $\starCl$ cases must agree (behaviorally, because $\starCl$ may only be constructed assuming $\beh$ holds).
  We say a type $X$ is \emph{algorithmic} when $\Cl X \iso X$,%
  \footnote{In other work this notion has been referred to as closed-modal/$\Cl$-modal~\cite{rijke-shulman-spitters>2020}, $\Op$-connected~\cite{rijke-shulman-spitters>2020}, $\beh$-sealed~\cite{sterling-harper>2021-metalanguage-multi-phase-modularity,sterling-harper>2022,sterling>2022-logical-relations}, and (purely) intensional~\cite{niu-sterling-grodin-harper>2022,grodin-niu-sterling-harper>2024} types.}
  and we call an inhabitant of an algorithmic type an \emph{algorithm}.
  We say a type family $Y : X \to \tpv$ is algorithmic when $Y(x)$ is algorithmic for all $x : X$, and we say a map $f : Y \to X$ is algorithmic when $\fib{f}{-}$ is algorithmic.
\end{definition}

\begin{lemma}\label{lem:algorithmic}
  Algorithmic data can be characterized in terms of their behavior:
  \begin{enumerate}
    \item a type $X$ is algorithmic exactly when $\Op X$ is contractible \cite[Example 1.31]{rijke-shulman-spitters>2020}, and
    \item a map $f : Y \to X$ is algorithmic exactly when $\Op f : \Op Y \to \Op X$ is an equivalence \cite[Lemma 1.35 and Theorem 3.1]{rijke-shulman-spitters>2020}.
  \end{enumerate}
\end{lemma}

Algorithmic types will be a central notion in this work, describing classes of algorithms that all share a single behavior.
%
%
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
%
Although an algorithmic type may have many inhabitants, they must all implement the same behavior, rendering the type behaviorally trivial.
For an algorithmic type $X$, we have that $\Op X$ is contractible; we refer to center of contraction $x_0 : \Op X$ as the \emph{behavior} of $X$, because all algorithms of type $X$ collapse to $x_0$ under the aegis of the behavioral phase.


\subsubsection{Noninterference and modularity}
These modalities admit the statement and proof of a \emph{noninterference theorem}, which states that the algorithmic content of an implementation does not impact the behavior of its clients.
This ensures that implementations may be freely substituted for one another without changing client behavior, even though algorithmic-level details about the client (such as cost) may be impacted.
%
%
%
%
%
%
%

%
%
%
%
%
\begin{theorem}[Noninterference \citep{niu-sterling-grodin-harper>2022}]\label{thm:noninterference}
  Let $X$ be an algorithmic type, and let $Y$ be an arbitrary type.
  Then, the function space $X \to Y$ is behaviorally equivalent to $Y$.
  %
\end{theorem}
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
The essence of this theorem is that behaviorally, $x_0$ is the unique input of type $X$ (up to equivalence).
This means that given a program of type $Y$ using an algorithm of type $X$, we may choose \emph{any} convenient implementation when verifying behavioral correctness.
\begin{corollary}[Modularity]\label{cor:modularity}
  Let $X$ be an algorithmic type, and let $Y$ be an arbitrary type.
  Then, for all $f : X \to Y$ and $x, x' : X$, we have that behaviorally, $f(x) = f(x')$.
\end{corollary}
In other words: for an implementation $f$ of $Y$ depending on an algorithmic type $X$, we may freely swap any $x : X$ for any $x' : X$ and guarantee identical behavior.

\begin{remark}[Security]
  Modularity and the behavioral phase may be viewed through the lens of security, where the behavioral phase corresponds to a public, low-security environment and the default algorithmic phase corresponds to a private, high-security environment~\citep{sterling-harper>2022}.
  By default, we operate in the private environment, capable of writing secret implementation details pertaining to cost and clever implementation.
  When we switch to the public environment, though, implementation details (including cost) are redacted.
  It is in this sense that the behavioral phase guarantees a notion of abstraction and modularity: private data is guaranteed to be redacted in the public phase and may therefore be swapped with any other private data at will with no impact.
\end{remark}

\subsubsection{Fracture and gluing}
Importantly, every type consists of a behavioral component, an algorithmic component, and a function mapping the latter to the former, understood in this work as an abstraction function.
\begin{theorem}[Fracture and Gluing \citep{rijke-shulman-spitters>2020}]\label{thm:fracture}
  Let $\tpv$ be the universe of (value) types, and let $\BEH{\tpv}$ and $\ALGO{\tpv}$ be the universes of behavioral and algorithmic types, respectively.
  There is an equivalence
  \[ \tpv = \sum_{\BEH{X} : \BEH{\tpv}} \sum_{\ALGO{X} : \ALGO{\tpv}} \ALGO{X} \to \Cl \BEH{X} \]
  between types $X : \tpv$ and their fracturing
  %
  into a behavioral type $\BEH{X}$, an algorithmic type $\ALGO{X}$, and an abstraction function $\alpha : \ALGO{X} \to \Cl \BEH{X}$.
\end{theorem}
\begin{proof}[Proof Sketch]
  We give an isomorphism explicitly.
  In the forward direction, \emph{fracture} the type $X$ by sending it to the triplet $(\Op X, \Cl X, \Cl \etaOp_X)$.
  In the reverse direction, \emph{glue} the parts $(\BEH{X}, \ALGO{X}, \alpha)$ by sending them to the following pullback, which we denote $\Glue{\BEH{X}}{\ALGO{X}}{\alpha}$:
  %
  \begin{center}
    \begin{minipage}{0.5\linewidth}
      \[\begin{tikzcd} \Glue{\BEH{X}}{\ALGO{X}}{\alpha} & \ALGO{X} \\
        \BEH{X} & {\Cl \BEH{X}}
        \arrow[from=1-1, to=2-1]
        \arrow[from=1-1, to=1-2]
        \arrow["{\alpha}", from=1-2, to=2-2]
        \arrow["{\etaCl_{\BEH{X}}}", from=2-1, to=2-2]
        \arrow["\lrcorner"{anchor=center, pos=0.125}, draw=none, from=1-1, to=2-2]
      \end{tikzcd}\]
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
      \[
        \Glue{\BEH{X}}{\ALGO{X}}{\alpha} \isdef \sum_{\BEH{x} : \BEH{X}} \sum_{\ALGO{x} : \ALGO{X}} \etaCl_{\BEH{X}} \BEH{x} = \alpha \ALGO{x}
      \]
    \end{minipage}
  \end{center}
  The round-trip condition on $\tpv$ says that every type $X : \tpv$ can be recovered by the following pullback of $\Op X$ and $\Cl X$:
  \begin{center}
    \begin{minipage}{0.5\linewidth}
      \[\begin{tikzcd} X & \Cl X \\
        \Op X & {\Cl \Op X}
        \arrow["{\etaOp_X}", from=1-1, to=2-1]
        \arrow["{\etaCl_X}", from=1-1, to=1-2]
        \arrow["{\Cl \etaOp_X}", from=1-2, to=2-2]
        \arrow["{\etaCl_{\Op X}}", from=2-1, to=2-2]
        \arrow["\lrcorner"{anchor=center, pos=0.125}, draw=none, from=1-1, to=2-2]
      \end{tikzcd}\]
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
      \[
        X = \sum_{\BEH{x} : \Op X} \sum_{\ALGO{x} : \Cl X} \etaCl_{\Op X} \BEH{x} = \Cl \etaOp_X \ALGO{x}
      \]
    \end{minipage}
  \end{center}
  The other round-trip condition ensures that $\Op \Glue{\BEH{X}}{\ALGO{X}}{\alpha} = \BEH{X}$ and $\Cl \Glue{\BEH{X}}{\ALGO{X}}{\alpha} = \ALGO{X}$.
  %
  %
\end{proof}

%
%
%
%
%
%
%
%
%
%
%
%
%

\subsubsection{Semantics}\label{sec:semantics}

We recall three important semantic models of \calf{}, differing centrally in their interpretation of the behavioral phase proposition, $\beh$.

\begin{model}[Behavioral]\label{mod:true}
  We may interpret $\beh$ as the true proposition.
  Because the assumption that programs exist only for their behavior is true, programs collapse to their behavioral or mathematical interpretations.
  In this setting $\Op X = X$, $\Cl X = 1$, and $\Glue{\BEH{X}}{\ALGO{X}}{\alpha} = \BEH{X}$.
\end{model}

\begin{model}[Algorithmic]\label{mod:false}
  We may interpret $\beh$ as the false proposition.
  Because the assumption that programs exist only for their behavior is false, all behavioral assumptions are erased, leaving behind the standard algorithmic implementation.
  In this setting $\Op X = 1$, $\Cl X = X$, and $\Glue{\BEH{X}}{\ALGO{X}}{\alpha} = \ALGO{X}$.
\end{model}

\begin{model}[Presheaf]\label{mod:psh}
  \calf{} can be given a Kripke semantics in the Sierpinski topos, \ie presheaves on the ``walking arrow'' category $\mathbbm{2} \isdef \{ \circ \to \bullet \}$~\cite[\S 5]{niu-sterling-grodin-harper>2022}.
  Each type $X$ is interpreted as a presheaf
  %
  $\interp{X}$, where $\ALGO{\interp{X}}$ is the algorithmic component and $\BEH{\interp{X}}$ is the behavioral component.
  The induced map $\ALGO{\interp{X}} \to \BEH{\interp{X}}$ can be thought of as an abstraction function, converting the private, algorithmic representation $\ALGO{\interp{X}}$ to the public, behavioral representation $\BEH{\interp{X}}$.
  For example:
  \begin{align*}
    \interp{X} &\isdef \Presheaf{\ALGO{\interp{X}}}{\BEH{\interp{X}}} &
    \interp{\nat} &\isdef \Presheaf[\text{id}]{\nat}{\nat} &
    \interp{\beh} &\isdef \Yo(\circ) = \Presheaf{0}{1}
  \end{align*}
  Standard base types, such as $\nat$, are interpreted as constant presheaves, with identical algorithmic and behavioral components and the identity function between them.
  The behavioral phase $\beh$ is defined as the Yoneda embedding of $\circ : \mathbbm{2}$, with an empty algorithmic component and a trivial behavioral component, combining \cref{mod:true,mod:false}.
  The modalities are interpreted as follows:
  \begin{align*}
    \interp{\Op X} &= \interp{\beh \to X} = \Presheaf[\text{id}]{\BEH{\interp{X}}}{\BEH{\interp{X}}} &
    \interp{\Cl X} &= \interp{X \lor \beh} = \Presheaf{\ALGO{\interp{X}}}{1}
  \end{align*}
  Notice that a type $X$ is behavioral when it is interpreted as a constant presheaf with $\ALGO{\interp{X}} = \BEH{\interp{X}}$ and algorithmic when it has $\BEH{\interp{X}} = 1$.
  In other words a type is behavioral when its intrinsic abstraction function is an equivalence, and a type is algorithmic when its intrinsic abstraction function is a unique map into $1$ that fully erases information.
  Gluing can be viewed as synthetically constructing a presheaf,
  \[ \interp{\Glue{\BEH{X}}{\ALGO{X}}{\alpha}} = \Presheaf[\interp{\alpha}_\bullet]{\ALGO{\interp{\ALGO{X}}}}{\ALGO{\interp{\BEH{X}}}}, \]
  where $\interp{\alpha} : \interp{\ALGO{X}} \to \interp{\Cl \BEH{X}}$ is a map of presheaves.
  In this sense every type is interpreted as an abstraction function, describing (the algorithmic parts of) types $\ALGO{X}$ and $\BEH{X}$ with an associated abstraction function to erase private details.
%
%
%
%
\end{model}

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%


\subsection{Cost as an effect}
In \calf{} cost is treated abstractly as an effect: we write $\mstep{c}{a}$ for a print-like effect that records $c : \costty$ units of abstract cost before running the computation $a : A$, where $\costty$ is a value type representing cost equipped with a monoid structure $(0, +)$.%
\footnote{We alter the notation $\mathsf{step}^c(-)$ from previous developments in \calf{}, emphasizing that $c$ is counting an abstract notion of cost, not the number of evaluation steps.}
The cost effect is governed by the following laws, using the monoid operations associated with cost algebra $\costty$.
\begin{axiom}
  The cost effect respects the monoid $(\costty, 0, +)$:
  \begin{subequations}
    \begin{align}
    \mstep{0}{a} &= a \label{eq:zero}\\
    \mstep{c_1}{\mstep{c_2}{a}} &= \mstep{c_1 + c_2}{a} \label{eq:plus}
  \end{align}
  \end{subequations}
\end{axiom}
%

In \calf{} it is crucial that the cost algebra $\costty$ be algorithmic: this allows the cost effect to be omitted in the behavioral phase, supporting reasoning about correctness without involving their cost.
\begin{axiom}\label{axiom:cost-algo}
  The cost algebra $\costty$ is algorithmic.%
\end{axiom}

\begin{theorem}
  If $\beh$ holds, then for all $c : \costty$, we have $\mstep{c}{e} = e$.
\end{theorem}
\begin{proof}
  Suppose $\beh$ holds, and let $c : \costty$ be arbitrary.
  Then, because $\costty$ is algorithmic, it is contractible.
  Therefore, all elements of $\costty$ are equal, so $c =_\costty 0$.
  The result follows by \cref{eq:zero}.
  %
  %
  %
  %
  %
\end{proof}

\begin{remark}
  Although the presence of cost amplifies the importance of certain issues in this paper, the techniques developed here for modular verification of algorithms and data structures stand freely without cost annotations, as well.
  In particular note that the trivial monoid is a valid cost model, as $\costty \isdef 1$ is algorithmic.
\end{remark}

In this paper, as in \calf{}~\citep{niu-sterling-grodin-harper>2022}, we choose to define $\costty \isdef \Cl \nat$ for the purpose of our examples.
%
%
%
For convenience, we avoid $\etaCl$ when constructing costs, and we avoid the use of $\starCl$ in favor of $0$.

\subsection{Contributions}\label{sec:contributions}

In this paper we identify algorithmic types as a novel source of semantic modularity suitable for the compositional verification of behavior, elevating the concept of algorithmicity from merely a tool for cost erasure to a more general programmer-facing construct for guaranteeing the client-facing redaction of choices made for the purpose of efficiency.
We demonstrate sources of algorithmic types that specify common algorithms and data structures, using the fracture/gluing property and behavioral quotients to mark algorithmic details for erasure in the behavioral phase, guaranteeing that algorithms and data structures may be swapped out interchangeably without affecting behavior.
%
This perspective lends itself to a simple and precise consolidation of many concepts about algorithms and data structures, including benign effects, abstraction functions, relational parametricity, views, and smart constructors.

\paragraph{Synopsis}

This paper is organized as follows.
In \cref{sec:algorithms} we consider the specification of sorting algorithms to justify the claim that algorithmic types are a sensible notion for the specification of algorithmic problems, and we consider subtleties that arise with uniqueness of outputs and modularity.
In \cref{sec:data-structures} we expand the story to data structures and abstract data types, considering an algorithmic type specifying persistent queues and implementing the representation type as a synthetic abstraction function via gluing.
In \cref{sec:free} we present an ergonomic approach to specifying synthetic abstraction functions implicitly using behavioral quotients to redact efficiency-only aspects of representation types when verifying behavior of client code.
Finally, in \cref{sec:conclusion} we summarize results, connect to related work, and suggest directions for future development.
 %
\section{Algorithmic types as behavioral specifications}\label{sec:algorithms}

To specify an algorithmic problem, it is typical to make precise the intended behavior that the corresponding algorithms must implement.
Algorithms may then implement the given behavior with various cost characteristics.
This notion is made precise via algorithmic types: although an algorithmic type may have many inhabitants, it must behaviorally be a singleton, contracting down to the single guaranteed behavior required by the specification.

\subsection{Constructing algorithmic types}\label{sec:algorithms:constructing}

The canonical strategy for constructing an algorithmic type out of an arbitrary type $X$ consists of providing a behavior $x_0 : \Op X$ and then considering the subtype of $X$ consisting of all $x : X$ that behaviorally match $x_0$, which we write as $\SPEC{X}{x_0(\b)}$%
\footnote{We use a notation inspired by extension types~\citep{riehl-shulman>2017,sterling-harper>2021}. However, we use typal equality, because the proof that an algorithm matches its behavioral reference need not be definitional.}:
%
%
\[ \SPEC{X}{x_0(\b)} \isdef \sum_{x : X} \eqOp{x}{x_0(\b)} \]
This type is always algorithmic, with behavior
%
\[ \lambda (\b : \beh).\ (x_0(\b), \lambda (\b : \beh).\ \eqrefl) : \Op \SPEC{X}{x_0(\b)}; \]
the proof is a minor phase-sensitive adaptation of a standard argument from homotopy type theory~\cite[Theorem 10.1.14]{rijke>2022}.
In fact any algorithmic type can be put in this form: if $Y$ is algorithmic with behavior $y_0$, then $Y \iso \SPEC{Y}{y_0}$.

\begin{example}\label{ex:sort-bad}
  To classify all sorting algorithms, we may use the algorithmic type
  \[ \SPEC{\U{\listty{\nat} \rightharpoonup \F{\listty{\nat}}}}{\Impl{isort}}, \]
  where an element is a function $f : \U{\listty{\nat} \rightharpoonup \F{\listty{\nat}}}$ equipped with a proof that its behavior matches insertion sort, $\eqOp{f}{\Impl{isort}}$.
  %
\end{example}

Although this technique does accurately describe all algorithmic types, it can obfuscate the intended verification strategy.
For example, to show that merge sort or randomized quick sort is a valid sorting algorithm (\ie, inhabits the type given in \cref{ex:sort-bad}), one has to prove that $\eqOp{\Impl{msort}}{\Impl{isort}}$ or $\eqOp{\Impl{qsort}}{\Impl{isort}}$.
Although this is true, the proof itself is structured around the idea that $\Impl{isort}$, $\Impl{msort}$, and $\Impl{qsort}$ are all valid sorting algorithms on $\listty{\nat}$, and all such sorting algorithms are equivalent, as verified by \citet{niu-sterling-grodin-harper>2022}.
Taking this perspective, we can give a more ergonomic version of the algorithmic type of \cref{ex:sort-bad}.

\begin{example}\label{ex:sort-ergonomic}
  Let $\Name{IsSorted}(l)$ be a propositional type family over $\listty{\nat}$ that is inhabited exactly when list $l$ is sorted, and
  let $\Name{IsPerm}(l, l')$ be a propositional type family over $\listty{\nat} \times \listty{\nat}$ that is inhabited exactly when list $l$ is a permutation of list $l'$.%
  \footnote{In some definitions, such as the Agda standard library~\citep{agda-standard-library>2024}, these type families may not be immediately propositional. In that case, one can propositionally truncate~\cite[\S 14]{rijke>2022} to obtain propositionality.}
  For every list $l$, there exists a unique list $l'$ such that the types $\Name{IsSorted}(l')$ and $\Name{IsPerm}(l, l')$ are inhabited%
  \footnote{The proof of this fact is a sorting \emph{function}, without cost annotations, serving as the center of contraction.};
  therefore, the type
  \[ \textstyle \Name{SortedPerm}(l) \isdef \sum_{l' : \listty{\nat}} \Name{IsSorted}(l') \times \Name{IsPerm}(l,
  l') \]
  is contractible (and therefore algorithmic) for all $l : \listty{\nat}$.

  Absent of any restrictions on the effects available, the type $\U{\F{\Name{SortedPerm}(l)}}$ need \emph{not} be algorithmic; for example, if errors are available from the monad $\U{\F{-}}$, an inhabitant of this type could either return or error.
  However, the type
  \[ \Benign \Name{SortedPerm}(l) \isdef \SPEC{\U{\F{\Name{SortedPerm}(l)}}}{\ret{x_0(\b)}} \]
  is algorithmic, where $x_0 : \Op(\Name{SortedPerm}(l))$ is the behavior of $\Name{SortedPerm}(l)$.
  Behaviorally, an inhabitant computation $e : \U{\F{\Name{SortedPerm}(l)}}$ is restricted to be $\ret{x_0(\b)}$, returning a value; even though $e$ may use monadic effects, such as cost (in insertion sort and merge sort) and nondeterminism/randomization (in quick sort~\cite{grodin-niu-sterling-harper>2024}), the effects must be \emph{benign}, trivializing in the behavioral phase.
  %
  %
  %
  %
  %

  Abstracting over the list $l : \listty{\nat}$ to be sorted, we get that the type
  \[ \textstyle \Name{Sort} \isdef \prod_{l : \listty{\nat}} \Benign \Name{SortedPerm}(l) \]
  is algorithmic, describing all sorting algorithms.
  This type $\Name{Sort}$ is equivalent to the algorithmic type of \cref{ex:sort-bad}; however, although $\Name{Sort}$ is also equipped with a behavior (of type $\Op(\Name{Sort})$) based on the proof of algorithmicity, this fact is not explicit in the type itself, which streamlines the implementation of sorting algorithms of this type $\Name{Sort}$.
  %
  %
  %
  %
  %
  %
\end{example}

\begin{remark}
  When verifying programs in a dependent type theory, one typically faces the issue of not knowing how much needs to be proved.
  For example, in the case of sorting algorithms, domain-specific knowledge suggests that one should prove that the output list is sorted and a permutation of the input list.
  However, how can one justify that both properties are required?
  Because if either requirement is omitted, the resulting type fails to be algorithmic!
  The proposal of algorithmic types in this work provides a general theoretical foundation for making such guarantees: \emph{one knows that an algorithm specification is precise enough when its type is algorithmic}.
\end{remark}

The principles used in \cref{ex:sort-ergonomic} are instances of more general techniques that allow us to specify an algorithmic problem via a property that its results should satisfy uniquely.
First, we elaborate on the $\Benign$ construction.

\begin{definition}
  Let $X$ be an algorithmic type with behavior $x_0 : \Op X$.
  We write
  \[ \Benign X \isdef \SPEC{\U{\F{X}}}{\ret{x_0(\_)}} \]
  for the type of computations of type $\U{\F{X}}$ that behaviorally return.
  This operator preserves algorithmicity, sending an algorithmic type $X$ to an algorithmic type $\Benign X$.
  Moreover, $\Benign$ forms a monad on the universe of algorithmic types, which we refer to as the \emph{benign effect monad} (relative to the monad $\U{\F{-}}$).
  %
\end{definition}

The concept of benign effects slots in smoothly with the perspective that the behavioral phase erases private details: in the benign effect monad, while effects may be used for implementation purposes, a client must not observe the effects behaviorally.

For an algorithmic problem that takes inputs of type $X$, the valid output can be described as an algorithmic type family $Y(x)$, for each $x : X$.
Then, we may use dependent products and the benign effect monad to encode an algorithmic problem as an algorithmic type, abstracting \cref{ex:sort-ergonomic}.

\begin{theorem}\label{thm:pi-algorithmic}
  Let $X$ be an arbitrary type, and let $Y : X \to \tpv$ be a family of types indexed by $X$ such that each $Y(x)$ is algorithmic\footnote{In practice $Y(x)$ will often be contractible, not merely algorithmic.}.
  Then, the type
  $\prod_{x : X} Y(x)$
  is algorithmic.
\end{theorem}
\begin{proof}
  Follows from dependent products preserving contractability \cite[Lemma 3.11.6]{univalentfoundations>2013}.
  %
\end{proof}

Combining \cref{thm:pi-algorithmic} with the benign effect monad preserving algorithmicity, we recover \cref{ex:sort-ergonomic}, where $X \isdef \listty{\nat}$ and $Y(x) \isdef \Benign \Name{SortedPerm}(x)$.
Variations of $X$ and $Y$ give other common algorithmic problem shapes.

\begin{example}
  Let $P : X \to \tpv$ be a family of decidable propositions: every $P(x)$ is a proposition, and for every $x : X$, either $P(x)$ or $\lnot P(x)$.
  Then, letting
  \[ Y(x) \isdef \Benign(P(x) + \lnot P(x)), \]
  we have that $\prod_{x : X} Y(x)$ is the type of decision procedures for $P$.
  Behaviorally, there is a single inhabitant of this type that states whether $P(x)$ or $\lnot P(x)$ holds.
  In general, though, algorithms of type $\prod_{x : X} Y(x)$ can have various cost characteristics.
\end{example}

\begin{example}
  Let $X \isdef \nelistty{\nat}$ be the type of nonempty lists of natural numbers, and let $\elemty{x}$ be the type of inhabitants of $x$.
  Defining
  \[ \textstyle Y(x) \isdef \Benign \sum_{n : \elemty{x}} \prod_{n' : \elemty{x}} n \le_\nat n', \]
  we have that $\prod_{x : X} Y(x)$ is the type of algorithms that find the minimum number contained in a nonempty list.
  %
  Behaviorally, there is a single inhabitant of this type, although multiple algorithms may implement this type; for example, an optimized algorithm could exit early returning $0$ if it is ever found in the list.
\end{example}

Overall, this development hinges on the idea that $Y(x)$ itself is algorithmic; in other words, there is (behaviorally) a unique answer that can be expected from every algorithm implementation.
Sometimes, this is not the case, though: multiple solutions to a problem could exist.
Just as we use the algorithmic modality to quotient away information in the behavioral phase, we can use other behavioral quotients to ensure algorithmicity in the case that multiple solutions are possible.

\subsection{Disambiguating specifications using behavioral quotients}\label{sec:algorithithms:quotient}

Sometimes, an algorithm may produce an output that is not, a priori, uniquely determined by its input.
An algorithm may be allowed to produce one of many valid solutions; for example, in an arbitrary comparison-based sort, stable and unstable sorting algorithms differ on how they treat comparison-isomorphic elements.
At first glance, this seems to trivialize the entire subject of algorithmic types: is it not desirable to have many possible answers?
However, this fundamentally breaks modularity (\cref{cor:modularity}): if multiple behaviors are allowed, one cannot freely swap out algorithms.
For example, if client code may view the results of stable and unstable sorting algorithms differently, it could have different behavior depending on the stability.
To avoid this issue, we may use behavioral quotients to explicitly identify distinct behaviors.

\begin{example}\label{ex:sort-general}
  In \cref{ex:sort-ergonomic} we showed that the type of algorithms that sort a list of natural numbers is algorithmic.
  How can we generalize this result to sorting algorithms for an arbitrary element type $X$?
  In the implementation of sorting algorithms it is essential that the preorder on elements of type $X$ be total.
  However, under only these conditions, it is not true that a sorted permutation of a list exists uniquely.
  For example, if $X \isdef \nat \times \stringty$ where comparison is performed at the first component only, then both $[(3, \texttt{"a"}), (3, \texttt{"b"})]$ and $[(3, \texttt{"b"}), (3, \texttt{"a"})]$ are sorted permutations of $[(3, \texttt{"a"}), (3, \texttt{"b"})]$.
  To recover algorithmicity, we must alter the types involved such that any comparison-isomorphic permutations are considered equal.
%
  \begin{figure}
    \begin{subfigure}{0.5\textwidth}
      \iblock{
        \mhang{\kw{data}~ X/\cong : \tpv~\kw{where}}{
          \mrow{\Label{\eta} : X \to X/\cong}
          \mrow{\Label{\_} : \prod_{x,x' : X} x \cong_X x' \to \eqOp{\Label{\eta} x}{\Label{\eta} x'}}
        }
      }
      \caption{Behavioral quotient by preorder isomorphism.}\label{fig:antisym1}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
      \iblock{
        \mhang{\kw{data}~ \trunc{X}_\beh : \tpv~\kw{where}}{
          \mrow{\Label{\eta} : X \to \trunc{X}_\beh}
          \mrow{\Label{\_} : \prod_{x, x' : X} \eqOp{\Label{\eta} x}{\Label{\eta} x'}}
        }
      }
      \caption{Behavioral truncation.}\label{fig:antisym2}
    \end{subfigure}
%
    \caption{Behavioral quotients used to behaviorally ignore stability of sorting.}
    \Description{Purely textual code figure.}
  \end{figure}
  Two approaches to accomplish this are given as follows:
  \begin{enumerate}
    \item
      We may ask that the ordering relation on element type $X$ is \emph{behaviorally} antisymmetric.
      Say that a comparison relation $\le_X$ is antisymmetric when the type
      \[ \textstyle \Name{Antisymmetric}(\le_X) \isdef \prod_{x, x' : X} x \cong_X x' \to x = x' \]
      is inhabited, where $x \cong_X x' \isdef (x \le_X x') \times (x' \le_X x)$.
      If $\le_X$ is behaviorally antisymmetric, then the type $\prod_{l : \listty{X}} \Benign{\Name{SortedPerm}(l)}$ is algorithmic.
%
      Because the comparison relation $\le_\nat$ is antisymmetric (and thus behaviorally antisymmetric), this scenario directly generalizes that of \cref{ex:sort-ergonomic}.
      If the ordering relation on $X$ is not behaviorally antisymmetric, though---such as for $X \isdef \nat \times \stringty$ with comparison of numbers only---we may behaviorally quotient $X$ to identify comparison-isomorphic elements in the behavioral phase.
      This new type $X/\cong$, shown in \cref{fig:antisym1}, consists of a quotient of $X$ by the equivalence relation $\beh \times {\cong}$.
      In \cref{mod:true} this is simply a quotient as usual, and in \cref{mod:false}, $X/\cong$ is equivalent to $X$ because the quotient is vacuous.
      Now, although $(3, \texttt{"a"})$ and $(3, \texttt{"b"})$ are distinct, the injections $\Label{\eta}(3, \texttt{"a"})$ and $\Label{\eta}(3, \texttt{"b"})$ are equal at type $X/\cong$.

    \item
      Alternatively, we may leave the element type unmodified and instead behaviorally propositionally truncate the type of sorted permutations, using the behavioral truncation given in \cref{fig:antisym2}.
      In \cref{mod:true} this is simply propositional truncation $\trunc{X}$, and in \cref{mod:false}, $\trunc{X}_\beh$ is equivalent to $X$ because the quotient is vacuous.
      Using this truncation, the type $$\prod_{l : \listty{X}} \Benign{\trunc{\Name{SortedPerm}(l)}_\beh}$$ is algorithmic, because differing sorted permutations are behaviorally identified.
  \end{enumerate}
  Notice that in either case, programs using the result of a sorting algorithm must have identical behavior on identified sorted permutations.
  Although operating on one permutation may have differing cost compared to another, the quotients ensure that the same behavior is always encountered given comparison-equivalent permutations.
\end{example}

Sometimes, it is discussed whether a sorting algorithm is \emph{stable},
preserving the original relative ordering of comparison-isomorphic elements. The
perspective of \cref{ex:sort-general} suggests that stability of sorting
algorithms is an algorithmic property, possibly affecting efficiency but never
affecting behavioral correctness. Saying that a sorting algorithm is (un)stable is akin to
proving a cost bound: algorithmically, this may matter, but behaviorally, there
is still only one sorting function.

\begin{remark}
  If stability is desired for correctness, one could strengthen the requirements imposed by the type in exchange for avoiding the behavioral quotients.
  For example,
  %
  one could use a stable sorting algorithm as a specification implementation, such as
  \[ \SPEC{\U{\listty{X} \rightharpoonup \F{\listty{X}}}}{\Impl{isort}} \]
  adapted from \cref{ex:sort-bad}.
  This algorithmic type describes a different class of algorithms, the ``stable sorting algorithms'', as opposed to the ``sorting algorithms'' described in \cref{ex:sort-general}.
  When the comparison ordering $\le_X$ is behaviorally antisymmetric, these notions coincide.
\end{remark}

Behavioral quotients may be used in the specification of many other algorithms.
For example, algorithms that find extremal solutions commonly refer to the extreme only up to some heuristic (such as the shortest path using path length, or a maximal spanning tree using tree weight); then, a behavioral quotient can ensure that the behavior of downstream code does not depend on the representative solution.

%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%

%
%
%
%

%
%
%
%
%


%
%
%
%
%
%

%
%
%

%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%

%
%
%
%
%
%
%
%
%

%


\subsection{Compositional verification via modularity}\label{sec:algorithms:modularity}

By noninterference (\cref{thm:noninterference}) and modularity (\cref{cor:modularity}), the behavioral verification of code downstream of an algorithm only depends on the unique behavior mandated by the algorithm; therefore, any algorithm implementation may be selected for convenience.

\begin{example}
  Consider the following piece of downstream code, where $\Impl{minimum}$ finds the least element of its input list:
%
  \iblock{
    \mrow{\Impl{downstream} : \U{\Name{Sort} \pto \listty{\nat} \pto \listty{\nat}}}
    \mrow{\Impl{downstream}~\Impl{sort}~l \isdef \Impl{sort}~(\consex{\Impl{minimum}~l}{l})}
  }
%
  We may wish to prove some facts about the behavior of $\Impl{downstream}$ on various inputs. For example, we may wish to show that for all $\Impl{sort}$ and $l$, \[ \eqOp{\Impl{downstream}~\Impl{sort}~l}{\consex{\Impl{minimum}~l}{\Impl{sort}~l}}. \]
  One proof technique is to argue in terms of the definition of being a sorted permutation of $\consex{\Impl{minimum}~l}{l}$, which all elements of type $\Name{Sort}$ are obliged to produce.
  More cleverly, though, we may simply pick a sorting algorithm that makes this theorem easy to prove, such as (in this case) insertion sort.
  To prove the general claim, it suffices to show that \[ \eqOp{\Impl{downstream}~\Impl{isort}~l}{\consex{\Impl{minimum}~l}{\Impl{isort}~l}}, \] for all $l$, which follows straightforwardly from the definition of insertion sort.
\end{example}

%
%
%

%

%

%

%

%

%
%
%
%
%

%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%

%


%
%

%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%

%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%

%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%

%
%
%

%


%
%
%
%
%
%
%
%
%
%
%
%

%

%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%

%
 %
\section{Abstract data types, data structures, and gluing}\label{sec:data-structures}

Using the behavioral phase, we may classify a type equipped with operations that restricts to a known behavior from within the phase, expressing the notion of an \emph{abstract data type}.
The informal definition of an abstract data type is well-known:
\begin{quote}
  In computer science an \emph{abstract data type (ADT)} is a mathematical model for data types, defined by its behavior (semantics) from the point of view of a user of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations.~\cite{wikipedia>abstract-data-type}
\end{quote}
%
To describe an abstract data type, it is essential to describe the behavior a client can expect from its data structure implementations, which can be reified as a type-level requirement using the behavioral phase.
For example, consider the following ``signature'' $\Name{PreQueue}$:
%
%
\[ \Name{PreQueue} \isdef \sum_{X : \tpv} (\Label{empty} : X) \times (\Label{enqueue} : \U{X \pto \nat \pto \F{X}}) \times (\Label{dequeue} : \U{X \pto \F{\nat \times X}}) \]
%
%
A reader might intuit from the included labels that this interface describes an abstract data type that contains natural numbers: a value type $X$ equipped with an empty instance, an operation to add a natural number to an instance, and an operation to remove a natural number. %
Which abstract data type is being described, though---stacks, queues, sets, priority queues, or something else?

\subsection{Gluing along abstraction functions}\label{sec:data-structures:gluing}

To make precise which of these choices the interface $\Name{PreQueue}$ is meant to classify, we may restrict to inhabitants of this type that have a mandated behavior $q_0 : \Op \Name{PreQueue}$ as in \cref{sec:algorithms:constructing}, creating an algorithmic type.
For example, to describe queues, we might choose $q_0$ to be a cost-free implementation of a queue based on lists:
%
\[ \Name{Queue} \isdef \SPEC{\Name{PreQueue}}{(\listty{\nat}, \nilex, (\lambda l.\ \lambda n.\ \ret{\catlist{l}{\singex{n}}}), \Impl{uncons})} \]
By restricting the behavior of the given operations to match the intended behavior of a queue, this algorithmic type $\Name{Queue}$ exactly represents the queue abstract data type.
Via the structure identity principle (\cref{eq:eq-sigma}), an element of this type consists of a quadruple
%
%
%
%
%
%
%
%
%
%
%
%
%
%
\begin{align*}
  (X, p) &: \SPEC{\tpv}{\listty{\nat}} \\
  \Label{empty} &: \SPEC{X}[p]{\nilex} \\
  \Label{enqueue} &: \SPEC{\U{X \pto \nat \pto \F{X}}}[p]{\lambda l.\ \lambda n.\ \ret{\catlist{l}{\singex{n}}}} \\
  \Label{dequeue} &: \SPEC{\U{X \pto \F{\nat \times X}}}[p]{\Impl{uncons}}
\end{align*}
where we write $\SPEC{X}[p]{x_0(\b)} \isdef \sum_{x : X}\Op(p_*(x) = x_0(\b))$ to classify all $x : X$ that behaviorally match $x_0$ up to transportation across an equivalence $p$.
%
%
%
%
%
%
%
%
%
%
Although the behavior of $X$ is fixed to be $\listty{\nat}$, the algorithmic part can be chosen freely so long as it coheres.

Classically, to give a representation type $\ALGO{X}$ modeled by $\listty{\nat}$, the programmer is to give a meta-theoretic \emph{abstraction function}, $\alpha : \ALGO{X} \to \listty{\nat}$, that gives the behavioral semantics of an element of $\ALGO{X}$ as a list.
\begin{quote}
  The first requirement for the proof [of behavioral correctness] is to define the relationship between the abstract space in which the abstract program is written, and the space of the concrete representation.
  This can be accomplished by giving a function [$\alpha$] which maps the concrete variables into the abstract object which they represent\dots~
  Note that in this and in many other cases [$\alpha$] will be a many-one function.
  Thus there is no unique concrete value representing any abstract one.
  \citep{hoare>1972}
\end{quote}
In this phase-separated setting such abstraction functions become first-class notions, fused into the very definition of the representation type by gluing.
To choose a type $X$ with $\eqOp{X}{\listty{\nat}}$, \ie $\Op X = \Op (\listty{\nat})$, we have by the fracture property (\cref{thm:fracture}) that it suffices to give an algorithmic type $\ALGO{X} : \tpv_{\Cl}$ and a map $\alpha : \ALGO{X} \to \Cl(\Op(\listty{\nat}))$ and glue them with $\Op(\listty{\nat})$.

\begin{example}[Batched Queue]\label{ex:batched-queue}
  To implement functional queues with efficient amortized cost, a pair of lists may be used: incoming data is enqueued to the ``inbox'' list, and outgoing data is usually dequeued from the ``outbox'' list, unless it is empty, in which case the ``inbox'' data is moved to the ``outbox''~\citep{hood-melville>1981,burton>1982,gries>1989,okasaki>1999}.
  In order to implement a queue in this way, we use gluing, selecting an algorithmic representation type $\ALGO{X}$ and an abstraction function $\alpha : \ALGO{X} \to \Cl(\Op(\listty{\nat}))$:
  \begin{align*}
    \ALGO{X} &\isdef \Cl (\listty{\nat} \times \listty{\nat}) &
    %
    %
    \alpha &\isdef \Cl (\Impl{revAppend}\mathbin{;}\etaOp) %
  \end{align*}
  where $\Impl{revAppend}~(l_1, l_2) = \catlist{l_2}{\rev{l_1}}$.
  Encoded within the type $\Glue{\Op(\listty{\nat})}{\ALGO{X}}{\alpha}$ itself is the idea that every pair of lists can be transformed to its abstract single-list representation by appending the reversed inbox list to the outbox.
  Using this gluing as the representation type, we define $\Impl{batchedQueue} : \Name{Queue}$ in \cref{fig:batched-queue}.
  \begin{figure}
%
    \iblock{
      \mrow{\Impl{batchedQueue} : \Name{Queue}}
      \mrow{\Impl{batchedQueue}.X \isdef \Glue{\Op(\listty{\nat})}{\Cl (\listty{\nat} \times \listty{\nat})}{\Cl (\Impl{revAppend}\mathbin{;}\etaOp)}}
      \mrow{\Impl{batchedQueue}\proj{empty} \isdef (\etaOp \nilex, \etaCl(\nilex, \nilex))}
      \mrow{\Impl{batchedQueue}\proj{enqueue}~(\BEH{x},\ALGO{x})~n \isdef {\ret{(\lambda (\b : \beh).\ \catlist{\BEH{x}(\b)}{\singex{n}}), \Cl(\lambda (l_1, l_2).\ (\consex{n}{l_1}, l_2))(\ALGO{x})}}}
      \mrow{\Impl{batchedQueue}\proj{dequeue}~(\BEH{x},\etaCl(l_1, \consex{n}{ns})) \isdef \ret{n, (\lambda (\b : \beh).\ \Impl{tail}(\BEH{x}(\b))), \etaCl(l_1, ns)}}
      \mhang{\Impl{batchedQueue}\proj{dequeue}~(\BEH{x},\etaCl(l_1, \nilex))~\kw{with}~\mstep{\len{l_1}}{\Impl{reverse}~l_1}}{
        \mrow{\dots \mid \nilex \isdef \ret{0, \etaOp \nilex, \etaCl(\nilex, \nilex)}}
        \mrow{\dots \mid \consex{n}{ns} \isdef \ret{n, (\lambda (\b : \beh).\ \Impl{tail}(\BEH{x}(\b))), \etaCl(\nilex, ns)}}
      }
      \mhang{\Impl{batchedQueue}\proj{dequeue}~(\BEH{x},\starCl)~\kw{with}~\Impl{uncons}(\BEH{x}(\b))}{
        \mrow{\dots \mid (n,l) \isdef \ret{n, \etaOp l, \starCl}}
      }
    }
%
    \caption{The definition of a batched queue, using copattern matching notation~\cite{abel-pientka-thibodeau-setzer>2013}.}\label{fig:batched-queue}
    \Description{Purely textual code figure.}
  \end{figure}

  The implementation of $\Label{empty}$ pairs a behavioral empty list and an algorithmic pair of empty lists; the implementation of $\Label{enqueue}$ incorporates number $n$ into both the behavioral list $\BEH{x} : \Op(\listty{\nat})$ and the algorithmic pair of lists $\ALGO{x} : \Cl (\listty{\nat} \times \listty{\nat})$; and the implementation of $\Label{dequeue}$ implements batched queue dequeue when $\ALGO{x} = \etaCl (l_1, l_2)$ and implements the required behavior when $\ALGO{x} = \starCl$.
  Within this code, some important proofs are omitted for readability:
  \begin{enumerate}
    \item
      Throughout the code, each glued pair $(\BEH{x}, \ALGO{x}) : \Op(\listty{\nat}) \times \Cl (\listty{\nat} \times \listty{\nat})$ comes equipped with a proof that the components cohere according to $\alpha$.
    \item
      The cases $\etaCl$ and $\starCl$ must (behaviorally) agree, by the definition of the algorithmic modality.
    \item
      This definition must come with a proof that each component matches the mandated behavioral specification, $q_0$.
      The type matches by the gluing construction (\cref{thm:fracture}), and the operations must be shown to match.
  \end{enumerate}
  The fact that these definitions behaviorally restrict to $q_0$ is crucial for implementing the algorithmic type $\Name{Queue}$: when algorithmic content (cost annotations and the $\ALGO{x}$ component of $(\BEH{x},\ALGO{x})$ pairs) is erased in the behavioral phase, we recover the specification queue, $q_0$, which is the unique behavior of all queues.
\end{example}

\begin{remark}[Abstraction Function]
  The function $\alpha : \ALGO{X} \to \Cl(\Op(\listty{\nat}))$ being glued along is a linguistic reification of the venerable notion of an \emph{abstraction function}~\citep{hoare>1972}, taking a concrete data representation $\ALGO{X}$ to its representative list.
  Using the fracture and gluing theorem (\cref{thm:fracture}), we observe that the phase distinction equips every type with an ``abstract'' component $\BEH{X}$, a ``concrete'' component $\ALGO{X}$, and an abstraction function.
  Entering the behavioral phase causes all abstraction functions to activate implicitly, leaving behind only ``abstract'' components and forgetting ``concrete'' implementation details.
  %
  This is emphasized through the various semantics of glued type $X$:
  \begin{enumerate}
    \item
      In \cref{mod:true} the semantics is simply $\listty{\nat}$, retaining the behavioral requirement for the implementation type although obliterating the pair-of-lists split.
    \item
      In \cref{mod:false} the semantics recovers the usual functional implementation of batched queues, because the single-list representation is now hidden under an impossible assumption.
    \item
      In \cref{mod:psh} the semantics maintains both the ``concrete'' batched and ``abstract'' single-list representations, as well as the abstraction function $\Impl{revAppend}$, all within type $X$:
      \[ \interp{X} \isdef \interp{\Glue{\Op(\listty{\nat})}{\Cl(\listty{\nat} \times \listty{\nat})}{\alpha}} = \Presheaf[\Impl{revAppend}]{\listty{\nat} \times \listty{\nat}}{\listty{\nat}} \]
  \end{enumerate}
  Even the cost model $\costty$ has both components: because $\costty$ is algorithmic by \cref{axiom:cost-algo}, we have that the ``abstract'' part of $\costty$ is simply trivial.
  The behavioral phase distinction provides a unifying syntax capable of being compiled to mathematical behavior, efficient algorithms, or both side-by-side.
\end{remark}

\begin{remark}[Synthetic Parametricity]\label{rem:relational-parametricity}
  In their presentation of batched queues \citet[\S 4.1]{sterling-harper>2021} similarly provide a conjoined implementation of a list queue (here, $q_0$) alongside a batched queue (here, $\Impl{batchedQueue}$) connected by a (functional) relation, $\Impl{revApp}$.
  Using a pair of symmetric (``left'' and ``right'') phases, either the list queue or the batched queue may be isolated by entering the appropriate phase.
  Instead, we emphasize here the functional nature of the relation (given as $\alpha$): we only allow a coercion of our conjoined implementation to the privileged specification $q_0$, chosen as the canonical meaning of ``queue'', via the behavioral phase.
  %
  We recover a theorem analogous to their representation independence result \cite[Theorem 4.1]{sterling-harper>2021} via noninterference (\cref{thm:noninterference}): for all result types $R$ and functions $f : \Name{Queue} \to R$, we have that $\eqOp{f(q_0(\b))}{f(\Impl{batchedQueue})}$.
\end{remark}

\begin{remark}[Relational Correspondence]
  If two representation types implement the same abstract data type, they can be given a many-to-many heterogeneous relation as is traditional in parametricity arguments~\citep{mitchell>1986}.
  %
  %
  %
  %
  %
  %
  For any types $X_1, X_2$ equipped with proofs $p_i : \eqOp{X_i}{\listty{\nat}}$, we can define a relation $R$ as the behavioral pullback of $p_1$ and $p_2$:
  \begin{center}
    \begin{minipage}{0.5\linewidth}
%
\[\begin{tikzcd}[column sep=tiny, row sep=scriptsize]
  & R \\
  {X_1} && {X_2} \\
  {\Op X_1} && {\Op X_2} \\
  & {\Op(\listty{\nat})}
  \arrow[from=1-2, to=2-1]
  \arrow[from=1-2, to=2-3]
  \arrow["\lrcorner"{anchor=center, pos=0.125, rotate=-45}, draw=none, from=1-2, to=4-2]
  \arrow["{\etaOp_{X_1}}"', from=2-1, to=3-1]
  \arrow["{\etaOp_{X_2}}", from=2-3, to=3-3]
  \arrow["{p_1}"', r,-,double equal sign distance,double, from=3-1, to=4-2]
  \arrow["{p_2}", r,-,double equal sign distance,double, from=3-3, to=4-2]
\end{tikzcd}\]
  \end{minipage}%
  \begin{minipage}{0.5\linewidth}
    \[ R \isdef \sum_{x_1 : X_1} \sum_{x_2 : X_2} \eqOp[\listty{\nat}]{{p_1}_*(x_1)}{{p_2}_*(x_2)} \]
  \end{minipage}
  \end{center}
  In other words, $x_1 : X_1$ and $x_2 : X_2$ are related exactly when their behaviors as lists match.
  Note that this type $R$ itself satisfies $\eqOp{R}{\listty{\nat}}$.
  Then, queue operations on $X_1$ and $X_2$ induce a queue implementation $r : \Name{Queue}$ with $r.X = R$, recovering an analytic analogue of the synthetic parametricity structures of \citet{sterling-harper>2021} in our synthetic behavioral setting.
\end{remark}

Generalizing this approach beyond queues, we may think of an abstract data type as a behaviorally-fixed type equipped with some behaviorally-fixed operations.
To construct an implementation type, we may always use gluing as a canonical technique, because by \cref{thm:fracture}, every type $X$ is constructed via gluing (up to equivalence).


\subsection{Compositional verification of behavior}

It has long been understood that the behavior of code dependent on abstract data types should only depend on the behavior guaranteed by the ADT.
\begin{quote}
  If the data representation is proved correct, the correctness of the final concrete program depends only on the correctness of the original abstract program.~\cite{hoare>1972}
\end{quote}
\begin{quote}
  %
  %
  When a programmer makes use of an abstract data object, he is concerned only with the behavior which that object exhibits but not with any details of how that behavior is achieved by means of an implementation.~\cite{liskov-zilles>1974}
\end{quote}
We now capitalize on this principle to verify client programs of the queue abstract data type.

\begin{example}
  Consider the following program demonstrating a simple usage pattern for a queue, enqueueing the number $3$ to an empty queue and immediately dequeueing:
%
  \iblock{
    \mrow{\Impl{demo} : \U{\Name{Queue} \pto \F{\nat}}}
    \mrow{\Impl{demo}~q \isdef \bindex{q\proj{enqueue}~(q\proj{empty})~3}{x} q\proj{dequeue}~x}
    %
    %
    %
    %
    %
    %
    %
    %
  }
%
  To verify the behavior of $\Impl{demo}$, we show that $\eqOp{\Impl{demo}~q}{\ret{3}}$ for all queue implementations $q : \Name{Queue}$.
  As in \cref{sec:algorithms:modularity}, we may choose an arbitrary representative implementation, such as $\Impl{batchedQueue}$, without loss of generality.
  The behavioral equivalence between $\Impl{demo}(\Impl{batchedQueue})$ and $\ret{3}$ holds judgmentally, so the theorem holds.
\end{example}

\begin{figure}
%
  \begin{multicols}{2}
    \iblock{
      \mrow{\Impl{fromList} : \U{\prod_{q : \Name{Queue}} \listty{\nat} \pto \F{q.X}}}
      \mrow{\Impl{fromList}~q~\nilex \isdef \ret{q\proj{empty}}}
      \mhang{\Impl{fromList}~q~(\consex{n}{ns}) \isdef}{
        \mrow{\bindex{\Impl{fromList}~q~ns}{queue}}
        \mrow{q\proj{enqueue}~n~queue}
      }
    }
    \columnbreak
    \iblock{
      \mrow{\Impl{toList} : \U{\prod_{q : \Name{Queue}} \nat \pto q.X \pto \F{\listty{\nat}}}}
      \mrow{\Impl{toList}~q~\zero~x \isdef \ret{\nilex}}
      \mhang{\Impl{toList}~q~(\suc{k})~x \isdef}{
        \mrow{\bindex{q\proj{dequeue}~x}{n, x'}}
        \mrow{\bindex{\Impl{toList}~q~k~x'}{ns}}
        \mrow{\ret{\consex{n}{ns}}}
      }
    }
  \end{multicols}

  \begin{multicols}{2}
    \iblock{
      \mrow{\Impl{qreverse} : \U{\Name{Queue} \pto \listty{\nat} \pto \F{\listty{\nat}}}}
      \mhang{\Impl{qreverse}~q~l \isdef}{
        \mrow{\bindex{\Impl{fromList}~q~l}{queue}}
        \mrow{\Impl{toList}~q~\len{l}~queue}
      }
    }
    \columnbreak
    \iblock{
      \mrow{\Impl{reverse} : \U{\listty{\nat} \pto \F{\listty{\nat}}}}
      \mrow{\Impl{reverse}~\nilex \isdef \ret{\nilex}}
      \mhang{\Impl{reverse}~(\consex{n}{ns}) \isdef}{
        \mrow{\bindex{\Impl{reverse}~ns}{ns'}}
        \mrow{\ret{\catlist{ns'}{\singex{n}}}}}
    }
  \end{multicols}
%
  \caption{List reverse implemented using a queue, $\Impl{qreverse}$, and a direct list reversal function, $\Impl{reverse}$.}\label{fig:queue-rev}
  \Description{Purely textual code figure.}
\end{figure}

\begin{example}
  Another simple example usage of queues is to reverse a list by enqueueing its elements and dequeueing them in reverse order, implemented in $\Impl{qreverse}$ in \cref{fig:queue-rev}.
  We may verify that the behavior of this $\Impl{qreverse}$ function matches the usual list reverse specification, $\Impl{reverse}$: we show that $\eqOp{\Impl{qreverse}~q}{\Impl{reverse}}$ for all queue implementations $q : \Name{Queue}$.
  Under the behavioral phase, we know by construction that $q$ is equivalent to the specification queue, $q_0(\b)$; in other words, $\eqOp{q}{q_0(\b)}$.
  %
  %
  %
  %
  %
  %
  Swapping the queue usages in $\Impl{fromList}$ and $\Impl{toList}$ for the queue specification $q_0(\b)$, we can see that $\Impl{fromList}$ is exactly the $\Impl{reverse}$ function, and $\Impl{toList}$ is exactly the identity function on lists. Thus, the behavior of $\Impl{qreverse}$ is equivalent to $\Impl{reverse}$.
  Although it is possible to verify this fact about $\Impl{batchedQueue}$ directly, the proof is more involved; using the algorithmicity of the $\Name{Queue}$ type allows us to choose a convenient implementation for verification of this fact, such as the list representation of queues, $q_0(\b)$.
  %
\end{example}

%

%
 %
\section{Behavioral properties and data structure quotients}\label{sec:free}

Many common abstract data types classify free/inductive algebraic structures.
For example, finite ordered sequences are classified by the free monoid, finite multisets are classified by the free commutative monoid, and finite sets are classified by the free semilattice.
In this section using finite ordered sequences as our primary example, we explore how to form an algorithmic type that classifies data structures implementing a free algebraic structure, and we use behavioral quotients to implicitly imbue implementations with abstraction functions.

\subsection{Behavioral properties}
Behaviorally, it is well understood that the free monoid classifies finite ordered sequences of data, henceforth referred to as \emph{sequences}~\cite{blelloch>1992}.
Free monoids are unique up to behavioral equivalence: mathematically speaking, lists are the only free monoid.
Algorithmically, though, there are many ways to implement data structures modeling the free monoid, all with different cost profiles: arrays, (``linked'') lists, finite functions, trees, and various balanced trees, to name a few.
Each implementation consists of a type $A$ equipped with a ``raw monoid'' structure (including the capability for effects):
\[ \Name{RawMonoid} \isdef \sum_{A : \tpc} (\Label{empty} : \U{A}) \times (\Label{append} : \U{A \otimes A \lolli A}) \]
To be considered a monoid, these operations must satisfy some additional properties, identity and associativity, rendered in the presence of effects as follows:
%
\iblock{
  \mrow{\Name{LeftIdentity}(\Label{emp}, \Label{app}) \isdef \prod_{a : \U{A}} \Label{app}(\Label{emp}, a) = a}
  \mrow{\Name{RightIdentity}(\Label{emp}, \Label{app}) \isdef \prod_{a : \U{A}} \Label{app}(a, \Label{emp}) = a}
  \mrow{\Name{Associative}(\Label{app}) \isdef \prod_{a_1,a_2,a_3 : A} \Label{app}(\Label{app}(a_1, a_2), a_3) = \Label{app}(a_1, \Label{app}(a_2, a_3))}
}
%
As in the Agda standard library\cite{agda-standard-library>2024}, we package these definitions as follows:
%
\iblock{
  \mrow{\Name{Identity}(\Label{emp}, \Label{app}) \isdef \Name{LeftIdentity}(\Label{emp}, \Label{app}) \times \Name{RightIdentity}(\Label{emp}, \Label{app})}
  \mrow{\Name{IsMonoid}(\Label{emp}, \Label{app}) \isdef \Name{Associative}(\Label{app}) \times \Name{Identity}(\Label{emp}, \Label{app})}
}
%
In the presence of cost, though, implementations of $\Label{empty}$ and $\Label{append}$ only satisfy these properties behaviorally.

\begin{example}
  Lists with a cost model considering recursive calls form a raw monoid:
%
  \iblock{
    \mrow{\Impl{listRawMonoid} : \Name{RawMonoid}}
    \mrow{\Impl{listRawMonoid}.A \isdef \F{\listty{\nat}}}
    \mrow{\Impl{listRawMonoid}\proj{empty} \isdef \ret{\nilex}}
    \mrow{\Impl{listRawMonoid}\proj{append}~(\ret{l_1}, \ret{l_2}) \isdef \mstep{\len{l_1}}{\ret{\catlist{l_1}{l_2}}}}
  }
%
  However, this raw monoid does not satisfy the axioms for a monoid when cost is under consideration.
  Although the $\Label{append}$ function does have $\Label{empty}$ as a left identity,
  \[ \Impl{listRawMonoid}\proj{append}~(\ret{\nilex}, \ret{l}) = \mstep{0}{\ret{\catlist{\nilex}{l}}} = \ret{\catlist{\nilex}{l}} = \ret{l}, \]
  it only \emph{behaviorally} has $\Label{empty}$ as a right identity for non-empty $l$,
  \[ \Impl{listRawMonoid}\proj{append}~(\ret{l}, \ret{\nilex}) = \eqOp{\mstep{\len{l}}{\ret{\catlist{\nilex}{l}}}}{\ret{\catlist{\nilex}{l}}} = \ret{l}, \]
  %
  since the left side costs $\len{l}$ and the right side costs zero.
  Associativity also holds only behaviorally.
\end{example}

%
\NewDocumentCommand{\OMonoid}{}{\Name{Monoid}^{\circ}}
\NewDocumentCommand{\OMonoidOn}{m}{\Name{Monoid}^{\circ}\Name{On}~{#1}}
%

Since the monoid properties can only be expected to hold behaviorally, we work not with monoids, but instead with \emph{behavioral monoids}:
\[ \OMonoid \isdef \sum_{(A, \Label{empty}, \Label{append}) : \Name{RawMonoid}} \Op(\Name{IsMonoid}(\Label{empty}, \Label{append})) \]
In this definition a behavioral monoid consists of a raw monoid equipped with a proof that behaviorally, the raw monoid operations indeed form a monoid.
Note that behaviorally, a behavioral monoid is just a monoid: entering the behavioral phase recovers the usual notion of a monoid.

Now, to develop sequences, we further equip a behavioral monoid with a generator, serving to create a singleton sequence, for an element type $E : \tpv$:
\[ \OMonoidOn{E} \isdef \sum_{M : \OMonoid} (\Label{singleton} : \U{E \pto M.A}) \]
For example, we can implement a behavioral monoid on $\nat$ that performs addition as shown in \cref{fig:add-monoid}, even when the addition operation is annotated with cost such that it only satisfies the identity laws in the behavioral phase.
\begin{figure}
%
  \iblock{
    \mrow{\Impl{addMonoid} : \OMonoidOn{\nat}}
    \mrow{\Impl{addMonoid}.A \isdef \F{\nat}}
    \mrow{\Impl{addMonoid}\proj{empty} \isdef \ret{0}}
    \mrow{\Impl{addMonoid}\proj{append}~(\ret{n_1}, \ret{n_2}) \isdef \mstep{1}{\ret{n_1 + n_2}}}
    \mrow{\Impl{addMonoid}\proj{singleton}~n \isdef \ret{n}}
  }
%
  \caption{Behavioral monoid implementing addition of natural numbers, instrumented with a cost of $1$ per addition operation. The behavioral $\Name{IsMonoid}$ proof is omitted for brevity.}\label{fig:add-monoid}
  \Description{Purely textual code figure.}
\end{figure}
%
%
%
%
%

%
\NewDocumentCommand{\PreSequence}{m}{\Name{PreSequence}~{#1}}
\NewDocumentCommand{\Sequence}{m}{\Name{Sequence}~{#1}}
%

To describe ordered sequences on $E$, we additionally ask for a $\Label{mapreduce}$ function for each other behavioral monoid on $E$, the recursor sending a sequence of type $M.A$ to the carrier of another behavioral monoid, $M'.A$:
\[ \PreSequence{E} \isdef \sum_{M : \OMonoidOn{E}} \left(\Label{mapreduce} : \prod_{M' : \OMonoidOn{E}} \U{M.A \lolli M'.A}\right) \]

%

\begin{example}
  We may define implement $\PreSequence{E}$ using the list type as a representative implementation, as shown in \cref{fig:list-preseq}.
  %
  %
  \begin{figure}
%
    \iblock{
      \mrow{\Impl{listPreSequence}_E : \PreSequence{E}}
      \mrow{\Impl{listPreSequence}_E.A \isdef \F{\listty{E}}}
      \mrow{\Impl{listPreSequence}_E\proj{empty} \isdef \ret{\nilex}}
      \mrow{\Impl{listPreSequence}_E\proj{append}~(\ret{l_1}, \ret{l_2}) \isdef \mstep{\len{l_1}}{\ret{\catlist{l_1}{l_2}}}}
      \mrow{\Impl{listPreSequence}_E\proj{singleton}~e \isdef \ret{\singex{e}}}
      \mrow{\Impl{listPreSequence}_E\proj{mapreduce}~M' \isdef \Impl{foldr}~(M'\proj{empty})~(\lambda e~a.\ M'\proj{append}~(M'\proj{singleton}~e, a))}
    }
%
    \caption{Implementation of $\PreSequence{E}$ using the list type as the representation type.}\label{fig:list-preseq}
    \Description{Purely textual code figure.}
  \end{figure}
  To implement $\Label{mapreduce}$, we use the structure of $M'$ to combine the list elements.
\end{example}

As with the type $\Name{PreQueue}$ used in the queue example of \cref{sec:data-structures}, there are many possible implementations of $\PreSequence{E}$.
%
%
To adapt $\PreSequence{E}$ into an algorithmic type, we must restrict the behavior of implementations to ensure that the monoid operations and $\Label{mapreduce}$ are universal.
One viable strategy would be to require behavioral coherence with $\Impl{listPreSequence}_E$:
\[ \Sequence{E} \isdef \SPEC{\PreSequence{E}}{\Impl{listPreSequence}_E} \]
%
%
However, just as the ``unbiased'' definition of $\Name{Sort}$ from \cref{ex:sort-ergonomic} was more ergonomic than the ``$\Impl{isort}$-biased'' definition from \cref{ex:sort-bad}, we may use the universality of the free monoid to provide an equivalent unbiased definition of $\Sequence{E}$ more ergonomic for verification.

\subsection{Phased universal properties}\label{sec:phased-universal-property}

To state the universality of the free monoid, we will ask that $\Label{mapreduce}$ be some form of homomorphism.
However, when cost is considered, $\Label{mapreduce}$ need not preserve the $\OMonoidOn{E}$ structure.
%
Thus, we will ask that $\Label{mapreduce}$ only \emph{behaviorally} preserve structure.

%
%

%

\begin{definition}
  Let $M, M' : \OMonoidOn{E}$.
  %
  A \emph{behavioral homomorphism} from $M$ to $M'$ consists of a function $a : M.A \lolli M'.A$ that behaviorally preserves the operations: %
  \begin{align*}
    \eqOp*{a (M\proj{empty})}{M'\proj{empty}} \\
    \eqOp*{a \circ M\proj{append}}{M'\proj{append} \circ (a \otimes a)} \\
    \eqOp*{a \circ M\proj{singleton}}{M'\proj{singleton}}
  \end{align*}
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  We write the type of behavioral homomorphisms as $\Hom[\Op]{M}{M'}$.
  %
  %
  %
\end{definition}

Using behavioral homomorphisms, we can define the algorithmic type of sequences to be the behaviorally-initial $\OMonoidOn{E}$:
\[ \Sequence{E} \isdef \sum_{M : \OMonoidOn{E}} \prod_{M' : \OMonoidOn{E}} \sum_{\alpha : \Hom[\Op]{M}{M'}} \prod_{\alpha' : \Hom[\Op]{M}{M'}} \Op(\alpha = \alpha'). \]
In other words a sequence consists of $M : \OMonoidOn{E}$ with a representation type and empty, append, and singleton constructors, alongside a $\Label{mapreduce}$ function (taking $M'$) whose universal property is guaranteed by the behavioral uniqueness and preservation of the monoid structure.
In the behavioral phase this type restricts to the usual mathematical definition of an initial object of type $\OMonoidOn{E}$, which must be unique; this causes the type $\Sequence{E}$ to be algorithmic.

\begin{example}
  Paired with a proof that $\Label{mapreduce}$ is behaviorally the unique homomorphism from $M$ to $M'$, the data $\Impl{listPreSequence}_E$ comprises an implementation $\Impl{listSequence}_E : \Sequence{E}$.
\end{example}

Without loss of generality, then, we may view $\etaOp(\Impl{listSequence}_E)$ as the behavior of $\Sequence{E}$.

%
%
%
%
%


%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%


\subsection{Behavioral quotients as representation types}\label{sec:free:behavioral-quotient}

In \cref{sec:data-structures:gluing} we use gluing to construct a type that is behaviorally equivalent to the given specification.
Although this approach is technically always applicable by \cref{thm:fracture}, storing both representations side-by-side is not particularly ergonomic: in the operations provided by an implementation, we must duplicate inline the behavioral operations (using lists) and show that our implementation coheres.
Especially when working with an ``unbiased'' universal construction, such as the behaviorally-free monoid, it is often more straightforward to verify the correctness of an implementation on its own terms.

\begin{remark}
  A similar issue of ergonomics occurs in phase distinctions for module systems~\cite{harper-mitchell-moggi>1989}: it is inconvenient to ``physically'' separate types and terms in modules, referred to as a \emph{phase separation}.
  Instead, it is preferable to intermix types and terms and isolate the static type components, using a \emph{phase distinction} as in the module calculus of \citet{sterling-harper>2021}.
\end{remark}

We now present an alternative approach to remove this redundancy: using behavioral quotients (as in \cref{sec:algorithithms:quotient}), we may manually collapse our representation type to the specification when inside the phase, blending the behavioral reference into the representation type by specifying with modalities and quotients what data to behaviorally erase.
Moreover, this collapsing can occur locally, only involving a particular pattern of constructors rather than a recursive definition.

\begin{example}\label{ex:seq-tree-quotient}
  Sequences may be implemented as trees, causing the constructors $\Label{empty}$, $\Label{append}$, and $\Label{singleton}$ to incur zero cost.
  We construct a behaviorally quotiented type of binary trees that collapses to lists under the phase.
  To accomplish this, we behaviorally quotient by identity and associativity, as shown in \cref{fig:tree}.
  \begin{figure}
%
    \iblock{
      \mhang{\kw{data}~\treety{(E : \tpv)} : \tpv~\kw{where}}{
        \mrow{\Label{empty} : \treety{E}}
        \mrow{\Label{leaf} : E \to \treety{E}}
        \mrow{\Label{node} : \treety{E} \to \treety{E} \to \treety{E}}
        \mrow{\Label{id}^\Label{l} : \prod_{t : \treety{E}} \eqOp{\Label{node}~t~\Label{empty}}{t}}
        \mrow{\Label{id}^\Label{r} : \prod_{t : \treety{E}} \eqOp{\Label{node}~\Label{empty}~t}{t}}
        \mrow{\Label{assoc} : \prod_{t_1,t_2,t_3 : \treety{E}} \eqOp{\Label{node}~(\Label{node}~t_1~t_2)~t_3}{\Label{node}~t_1~(\Label{node}~t_2~t_3)}}
      }
    }
%
    \caption{Type representing binary trees behaviorally quotiented by the monoid laws.}\label{fig:tree}
    \Description{Purely textual code figure.}
  \end{figure}

  The behavioral phase is intended to erase details only included for efficiency.
  Here, we erase the tree shape in which the elements are stored within the behavioral phase, leaving over only the elements in their given order.
  Now, when implementing an operation that cases on a tree of type $\treety{E}$, we must verify that the code behaviorally respects removal of $\Label{empty}$ constructors and tree rotations; this rules out functions that behaviorally reveal information about the chosen tree representation of a sequence, even though the choice of representation may algorithmically have an impact on the (cost of the) result.
  For example, by noninterference (\cref{thm:noninterference}), it is impossible to write a function $\treety{E} \to \nat$ that behaviorally computes the height of the input tree.
  It is important that the quotient only applies in the behavioral phase: if the tree quotient applied more generally, we would lose the ability to write most algorithms, as the cost annotations on an algorithm need not respect the quotients.

  Implementing $\Sequence{E}$, the type component is chosen to be as $\F{\treety{E}}$.
  This greatly simplifies the implementation: rather than managing a list and a tree side-by-side and ensuring the coherence of operations with in-order traversal explicitly, as gluing would require, we simply operate on trees.
  The list representation implicitly reveals itself in the behavioral phase due to the quotient cases, which locally and unobtrusively ensures coherence with in-order traversal.
  We show the implementation in \cref{fig:tree-sequence}, omitting proofs as usual.
  \begin{figure}
%
    \iblock{
      \mrow{\Impl{treeSequence}_E : \Sequence{E}}
      \mrow{\Impl{treeSequence}_E.A \isdef \F{\treety{E}}}
      \mrow{\Impl{treeSequence}_E\proj{empty} \isdef \ret{\Label{empty}}}
      \mrow{\Impl{treeSequence}_E\proj{append}~(\ret{t_1}, \ret{t_2}) \isdef \ret{\Label{node}(t_1, t_2)}}
      \mrow{\Impl{treeSequence}_E\proj{singleton}~e \isdef \ret{\Label{leaf}(e)}}
      \mrow{\Impl{treeSequence}_E\proj{mapreduce}~M'~(\ret{\Label{empty}}) \isdef M'\proj{empty}}
      \mrow{\Impl{treeSequence}_E\proj{mapreduce}~M'~(\ret{\Label{leaf}~e}) \isdef M'\proj{singleton}~e}
      \mrow{\Impl{treeSequence}_E\proj{mapreduce}~M'~(\ret{\Label{node}(t_1, t_2)}) \isdef M'\proj{append}~(\Impl{treeSequence}_E\proj{mapreduce}~M'~(\ret{t_1}), \Impl{treeSequence}_E\proj{mapreduce}~M'~(\ret{t_2}))}
    }
%
    \caption{Implementation of sequences using the binary tree type of \cref{fig:tree}.}\label{fig:tree-sequence}
    \Description{Purely textual code figure.}
  \end{figure}
  The proof that $\Label{mapreduce}$ respects the behavioral quotient cases follows from the assumption that $M'$ is a behavioral monoid.
  %
  %
  %
  %
  %
  %
  %
\end{example}

\begin{remark}
  In \cref{mod:psh}, the type $\treety{E}$ may be interpreted as the presheaf
  \[ \Presheaf[\Impl{inOrder}]{\Type{BinaryTree}~E}{\listty{E}}, \]
  where $\Type{BinaryTree}~E$ is the usual type of binary trees with elements of type $E$ at the leaves and the abstraction function $\Impl{inOrder}$ is the in-order traversal function.
  Notice that this function was never given explicitly in the syntax, as $\treety{E}$ was not constructed syntactically via gluing!
  However, it appears semantically due to the behavioral quotient laws: as empty trees may be removed and nodes may be freely associated (without loss of generality, to the right), the behavior of every tree is equivalent to a right-spine, which is simply a list.
  The use of behavioral quotients here, as opposed to gluing, streamlines programming with $\treety{E}$: functions implemented on this type only need to respect the behavioral quotient laws, without need for a duplicated program in the syntax and a proof of coherence by in-order traversal.
\end{remark}

\begin{remark}[Views]\label{rem:views}
  From the perspective of \citet{wadler>1987}, trees can be seen as a \emph{view} of lists that have improved efficiency~\cite{sleep-holmstrom>1982}.
  Functions $\Impl{in}$ and $\Impl{out}$ are given to convert between the representations.
  It is remarked that the correct notion of equality must be carefully selected in order for these functions to be inverses:
  \begin{quote}
    The correctness of the view depends on the equivalence between the various ways of representing a join list; otherwise, the $\Impl{in}$ and $\Impl{out}$ functions would not be inverses.~\citep{wadler>1987}
  \end{quote}
  In our cost-aware setting we first observe that if the conversion functions $\Impl{in}$ and $\Impl{out}$ incur cost, they will not generally be inverses, as the round-trip would incur nonzero cost.
  Moreover, when considering efficiency as a first-class notion, it is clear that trees and lists should \emph{not} always be equivalent: an algorithm on a list may have differing efficiencies depending on the chosen associativity of its tree representative!
  The behavioral quotient recovers the appropriate notion of equivalence, identifying trees containing the same data to make $\treety{E}$ and $\listty{E}$ behaviorally equivalent.
  %
  %
  Here, the role of $\Impl{in}$ is played by $\etaOp : \treety{E} \to \Op(\treety{E}) = \Op(\listty{E})$, converting a tree to a list by implicitly forgetting the tree structure under the influence of the phase.
  The inverse, $\Impl{out}$, is immediate in the behavioral phase, since $\etaOp$ is an algorithmic map (\ie, a behavioral equivalence).
  %
  %
\end{remark}

\begin{example}\label{ex:seq-rbt-quotient}
  To improve efficiency of common operations implemented via $\Label{mapreduce}$, a sequence may be implemented using a tree data structure equipped with some additional data to main approximate balance, such as a red-black tree \cite{guibas-sedgewick>1978,okasaki>1999}.%
  \footnote{Commonly, red-black trees store data at the $\Label{red}$ and $\Label{black}$ nodes, used to implement efficient binary search. However, we choose to store data at leaves, simplifying our development involving monoids.}
  We may adapt the previous example to encode the red-black invariants in a tree, taking care to erase behaviorally-irrelevant information.

  %
  Following \citet{weirich>2014}, we may define an indexed inductive type to enforce the red-black invariants, with indices for tree color and black-height.
  However, with indices of type $\colorty$ and $\nat$, naively grafting on the associativity and identity laws of \cref{ex:seq-tree-quotient} would not even well-typed: since red-black trees must be approximately balanced, performing arbitrary tree rotations need not lead to another invariant-satisfying red-black tree!
  To evade the red-black invariants, the key maneuver is the placement of the color and black-height invariants under the algorithmic modality: that way, in the behavioral phase, we are no longer obliged to maintain the red-black invariants.
  Then, to avoid the term-level distinction between $\Label{black}$ and $\Label{red}$ nodes---which is only maintained for algorithmic efficiency purposes, anyway---we behaviorally identify both colors of nodes, with the constructor $\Label{recolor}$.
  Finally, we may import the quotients of \cref{ex:seq-tree-quotient}, using $\Label{black}$ as the default node color, without loss of generality since red nodes may be behaviorally recolored.
  We show this quotient inductive type in \cref{fig:rbt}.
  \begin{figure}
%
    \iblock{
      \mhang{\kw{data}~\irbtty{(c : \Cl\colorty)}{(n : \Cl\nat)}{(E : \tpv)} : \tpv~\kw{where}}{
        \mrow{\Label{empty} : \irbtty{(\etaCl \black)}{(\etaCl \zero)}{E}}
        \mrow{\Label{leaf} : E \to \irbtty{(\etaCl \black)}{(\etaCl \zero)}{E}}
        \mrow{\Label{red} : \irbtty{(\etaCl \black)}{n}{E} \to \irbtty{(\etaCl \black)}{n}{E} \to \irbtty{(\etaCl \red)}{n}{E}}
        \mrow{\Label{black} : \irbtty{c_1}{n}{E} \to \irbtty{c_2}{n}{E} \to \irbtty{(\etaCl \black)}{((\Cl\suc*{})~n)}{E}}
        \mrow{\Label{recolor} : \beh \to \prod_{t_1, t_2 : \irbtty{\starCl}{\starCl}{E}} \Label{red}~t_1~t_2 = \Label{black}~t_1~t_2}
        \mrow{\Label{id}^\Label{l} : \beh \to \prod_{t : \irbtty{\starCl}{\starCl}{E}} \Label{black}~t~\Label{empty} = t}
        \mrow{\Label{id}^\Label{r} : \beh \to \prod_{t : \irbtty{\starCl}{\starCl}{E}} \Label{black}~\Label{empty}~t = t}
        \mrow{\Label{assoc} : \beh \to \prod_{t_1,t_2,t_3 : \irbtty{\starCl}{\starCl}{E}} \Label{black}~(\Label{black}~t_1~t_2)~t_3 = \Label{black}~t_1~(\Label{black}~t_2~t_3)}
      }
      \mrow{}
      \mrow{\rbtty{E} \isdef \sum_{c : \Cl\colorty} \sum_{n : \Cl\nat} \irbtty{c}{n}{E}}
    }
%
    \caption{Type representing invariant-preserving red-black trees, instrumented with the algorithmic modality and quotients to behaviorally annihilate red-black coloring and tree shape.}\label{fig:rbt}
    \Description{Purely textual code figure.}
  \end{figure}

  Beyond $\treety{E}$, we must now verify that code behaviorally respects recoloring.
  For example, by noninterference (\cref{thm:noninterference}), it is impossible to write a function $\rbtty{E} \to \colorty$ that behaviorally computes the color of a given red-black tree.
  The $\Sequence{E}$ implementation is a straightforward adaptation of \cref{ex:seq-tree-quotient} to account for node coloring, sketched in \cref{fig:rbt-sequence}.
  \begin{figure}
%
    \iblock{
      \mrow{\Impl{rbtSequence}_E : \Sequence{E}}
      \mrow{\Impl{rbtSequence}_E.A \isdef \F{\rbtty{E}}}
      \mrow{\Impl{rbtSequence}_E\proj{empty} \isdef \ret{\etaCl \black, \etaCl \zero, \Label{empty}}}
      \mrow{\Impl{rbtSequence}_E\proj{append} \isdef \Impl{join}}
      \mrow{\Impl{rbtSequence}_E\proj{singleton}~e \isdef \ret{\etaCl \black, \etaCl \zero, \Label{leaf}~e}}
      \mrow{\Impl{rbtSequence}_E\proj{mapreduce} \isdef \dots}
    }
%
    \caption{Representative cases of the implementation of sequences using the red-black tree type of \cref{fig:rbt}, adapting the implementation of \cref{fig:tree-sequence} to balanced trees.}\label{fig:rbt-sequence}
    \Description{Purely textual code figure.}
  \end{figure}
  The subroutine used to implement the $\Label{append}$ operation,
  \[ \Impl{join} : \F{\rbtty{E}} \otimes \F{\rbtty{E}} \lolli \F{\rbtty{E}}, \]
  combines two red-black trees in an order-preserving and invariant-maintaining manner~\citep{blelloch-ferizovic-sun>2016,blelloch-ferizovic-sun>2022} (verified in \calf{} by \citet{li-grodin-harper>2023}).
  Importantly, $\Impl{join}$ respects the given behavioral quotients, as it only performs rotations and recolorings to produce a balanced tree.
\end{example}

\begin{remark}[Smart Constructors]\label{rem:smart-constructor}
  For the verification of $\Impl{join}$, the essential lemma is that
  \[ \eqOp[\irbtty{\starCl}{\starCl}{E}]{\Impl{join}(\ret{\starCl, \starCl, t_1}, \ret{\starCl, \starCl, t_2})}{\ret{\Label{black}~t_1~t_2}}. \]
  In other words: behaviorally, $\Impl{join}$ is just the $\Label{black}$ constructor.
  For this reason, we justify the terminology that $\Impl{join}$ is a \emph{smart constructor}, informally defined to be a constructor that performs some additional computation for the sake of efficiency only.
  We may treat this observation as a formal definition: a \emph{smart constructor} is a computation behaviorally equivalent to a constructor.
\end{remark}

\begin{remark}\label{rem:semantics-quotient}
  Since the invariants and quotients are both relative to the behavioral phase, we may extract different results using the various semantics.
  For example,
  \begin{enumerate}
    \item
      in \cref{mod:true} the indices are erased, and the quotients always apply, recovering the mathematical free monoid (equivalent to $\listty{E}$); and
    \item
      in \cref{mod:false} the algorithmic modality on the indices disappears, and the quotient equations are vacuous, recovering the standard red-black tree type and algorithms.
  \end{enumerate}
  The phase mediates between these semantics: code must respect the possibility of collapsing to lists under the phase, but this may uniformly be deleted in the semantics to recover the true code.
\end{remark}

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%

%

%

%


\subsection{Behavior refinements}

%
%
%

%
%
%
%
%
%

Although the elimination form for sequences provides the facility to implement any algorithm, there is no guarantee that the implementation will be efficient.
We may refine the type $\Sequence{E}$ with extra data, exporting additional operations with known behavior but lower cost, using the fact that algorithmic types are closed under dependent sum~\citep[Example 1.8]{rijke-shulman-spitters>2020}.

\begin{lemma}
  If $X : \tpv$ and $Y : X \to \tpv$ are algorithmic, then $\sum_{x : X} Y(x)$ is algorithmic.
\end{lemma}

Letting $X \isdef \Sequence{E}$, we may define algorithmic type families $Y$ that equip a sequence with additional data.

\begin{example}
  Using any $M : \Sequence{E}$, computing the length of a given sequence can be done using $\Label{mapreduce}$:
  \[ \Impl{length} \isdef M\proj{mapreduce}~(\F{\nat}, \ret{0}, \Impl{add}, \Impl{const}(\ret{1})) \]
  However, for many implementations of the sequence abstraction, this operation will take linear time.
  We may refine sequences with an additional primitive operation that must behaviorally cohere with the above implementation:
  \[ \Name{SequenceExt}(E) \isdef \sum_{M : \Sequence{E}} (\Label{length} : \SPEC{M.A \lolli \F{\nat}}{\Impl{length}}) \]
  Even though this $\Label{length}$ function must behaviorally cohere with $\Impl{length}$ (and could always be implemented as exactly $\Impl{length}$), it may also be implemented using a more efficient method, such as storing the length alongside the sequence for constant-time computation.
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
\end{example}

This strategy of exporting behaviorally-redundant information in an abstract data type is pervasive, as the algorithms able to be implemented via the elimination form are rarely the most efficient.
For example, the queue abstract data type can be thought of as a refinement of lists with optimized operations for appending elements to the end and removing elements from the beginning, and priority queues can be thought of as refining finite multisets with an optimized operation for removing the least element according to some ordering.

%


%


%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%

%
%

%
%
%
%
%
%
%
%

%
%
%
%
%
%
%

%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%

%

%
%
%
%

%
%
%
%
%
%
%
%
%

%
%
%
%
%

%

%


  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %
  %

%


%

%

%
 %
%
\section{Conclusion}\label{sec:conclusion}

In this paper we have shown how a synthetic phase distinction explains the key foundations for modularity of algorithms and data structures in dependent type theory.
While previous developments in \calf{} heavily emphasize the behavioral (\ie, open) modality, we bring algorithmic (\ie, closed-modal) types and the related fracture theorem to the forefront for the verification of algorithms and data structures.
Furthermore, we emphasize the importance of noninterference not just for guaranteed separation of cost and behavior, but for separation of all private algorithmic concerns, of which cost is a paradigmatic example.

\subsection{Related work}

We now characterize the relationship between our development and prior work, beyond the connections that have been made throughout the text.

\subsubsection{Synthetic phase distinctions}
This work is fundamentally built upon the general framework for modalities in homotopy type theory developed by \citet{rijke-shulman-spitters>2020}, making particular use of the open and closed modalities associated with the proposition $\beh$, and set in the world of synthetic phase distinctions, pioneered by \citet{sterling-harper>2021}.
\citet{sterling-harper>2022} also apply the techniques of synthetic phase distinctions to the domain of security and information flow, which broadly aligns with the viewpoint that algorithmic data is private and behavioral data is public.

Recent work by \citet{gratzer-sterling-angiuli-coquand-birkedal>2022} on abstraction in dependent type theory makes use of phases to selectively reveal the implementation of definitions; within the phase for a particular definition, the corresponding code is revealed.
This technique makes use of extension types~\citep{riehl-shulman>2017}, similar to the type we write $\SPEC{X}{x_0(\b)}$ but equipped with a judgmental rather than typal equality.
The judgmental equality ensures a degree of faithfulness to the true source code that our story intentionally avoids: although a private implementation should match its public specification, the proof of this fact is rarely judgmental.

As regards the connections to cost analysis and \calf{}, the principal reference is~\citet{niu-sterling-grodin-harper>2022} on which the cost-oriented discussions in the present paper is based.
Therein are provided a comprehensive comparison to related work on formalized cost analysis, all of which applies as well to the present setting.


\subsubsection{Ghost code}
Our use of phases broadly parallels the technique of \emph{ghost code}, where functional, specification-level ghost code is maintained alongside (typically more efficient) ``regular'' code.
%
%
%
Prior accounts of ghost code have described noninterference of ghost code with regular code, erasing ghost code to extract the efficient regular code~\citep{filliatre-gondelman-paskevich>2016}.
Although our presentation supports the extraction of algorithmic code as an external notion, achieved by giving a semantics where $\beh$ is the false proposition as described in \cref{mod:false}, the directionality of our phase is dual: internally, we allow erasure of regular (algorithmic) code, leaving behind only behavior.
This ensures our opposite variety of noninterference, of regular code with ghost code (\cref{thm:noninterference}), which appears here as the essence of modular verification.
%

\subsubsection{Representation independence and univalence}
\citet{angiuli-cavallo-mortberg-zeuner>2021} tell a similar story for abstract data types and representation types in a univalent setting.
For example, in their presentation of batched queues, the pair-of-lists type is quotiented by equivalence under $\Impl{revAppend}$, leading to a type equivalent to the $\listty{\nat}$~\citep[\S 4.2]{angiuli-cavallo-mortberg-zeuner>2021}; this is similar to the behavioral quotients we considered in \cref{sec:free:behavioral-quotient}, but implementing the queue example of \cref{sec:data-structures}.
Furthermore, they also discuss truncating a cost counter with the writer monad, propositionally truncating the cost model to identify differing costs \citep[Example 2.1]{angiuli-cavallo-mortberg-zeuner>2021}.
These quotients are precisely what occurs in our development here under the behavioral phase (or in \cref{mod:true} where $\beh$ is true), so we may think of their work as taking place in the behavioral phase, after all algorithmic details have already been redacted.
Thus, our story is pleasingly compatible: to recover the ability to extract code prior to redaction, we simply condition the quotients on the behavioral phase.

\subsubsection{Realignment and strict glue type}
One role of univalence in this work is strictly equating the glue type $\Glue{\BEH{X}}{\ALGO{X}}{\alpha}$ to its behavioral component $\BEH{X}$ under the behavioral phase, so that the internal representation of an abstract data type can be related with its specifications as in \cref{sec:data-structures:gluing}. A similar result can be achieved in a non-univalent setting by considering the \emph{realignment/strictification axiom} \cite{birkedal-bizjak-clouston-grathwohl-spitters-vezzosi>2016,orton-pitts>2016,sterling>2022-logical-relations,sterling>thesis} that turns a partial isomorphism under a proposition into a strict equality. Then a \emph{strict glue type} \cite{sterling-harper>2022,yang>thesis} can be defined by realigning the $\Sigma$ type as we have in $\Glue{\BEH{X}}{\ALGO{X}}{\alpha}$.

%
%

\subsubsection{Verification of data structures using abstraction functions}
This work is far from the first to verify data structures using abstraction functions; for example, \citet{nipkow>2024} has developed an extensive suite of data structures in Isabelle with verifications based on abstraction functions.
Our development with the behavioral phase can be viewed as a synthetic place in which to reconstruct such analytic arguments: because every type contains an abstraction function, the language provides the capability to uniformly apply all the abstraction functions simultaneously, working in a phase where all data is abstract.

\subsubsection{Algebraic specification}
In the discipline of algebraic specification abstract data types are specified via equational properties on operations~\citep{sannella-tarlecki>2012}.
In general, it is not required that all operations are uniquely defined by the equations.
However, this strategy is often too conservative: unless the properties exported are complete with respect to the implementation behavior, there will be theorems that the client wishes to prove that are not consequences of the exported properties, violating the principle of modularity (\cref{cor:modularity}).
Moreover, from the perspective of the implementer, it will be possible to provide an ``incorrect'' implementation if the requirements are not strict enough.
These issues are only exacerbated in the presence of complex language features, such as effects and higher-order functions.
To constitute an algorithmic type, an algebraic specification must be behaviorally fully constrained.


\subsection{Future work}

Using the behavioral phase for modularity forces the programmer to carefully construct specifications that are algorithmic, and to carefully redact implementations such that the specification is met.
This process distills the essence of each algorithm and data structure, explicitly isolating the choices being made for efficiency, as exemplified in our presentation of red-black trees (\cref{ex:seq-rbt-quotient}).
As a general next step, we hope to verify additional algorithms and data structures in this style, as well.

\subsubsection{Approximation algorithms}
The foundational assumption surrounding the use of algorithmic types for specification is that a unique behavioral specification is known for the problem at hand.
In many cases this is true; however, some cases have more relaxed notions of correctness, such as approximation algorithms, algorithms with probabilistic correctness guarantees, or algorithms with numerical error tolerances.
Inspired by the work of \citet[\S 4.3.2]{atkey>2024} on bounding correctness, we hope to provide a synthetic account of approximation algorithms, generalizing the theory presented here about behavioral singletons to behaviorally \emph{bounded} types.

\subsubsection{Cost refinements for abstract data types}
In this work we primarily treat cost as a private, algorithmic notion, briefly considering the refinement of specifications for algorithms with cost considerations.
We anticipate that this story can be expanded further, providing interfaces for abstract data types that incorporate cost for a compositional story about the verification of cost and behavior.
The \decalf{}~\citep{grodin-niu-sterling-harper>2024} type theory adds a judgmental notion of inequality to \calf{} that compares cost; based on the work of \citet{grodin-harper>2024}, which uses (lax) homomorphisms to bound the amortized cost of a data structure, we anticipate that the simple, cost-only notion of inequality provided by \decalf{} can be generalized to describe homomorphisms, inspired by recent developments in simplicial type theory~\citep{riehl-shulman>2017,gratzer-weinberger-buchholtz>2024,gratzer-weinberger-buchholtz>2025}.
 
\section*{Data Availability Statement}
Building on the work of \citet{niu-sterling-grodin-harper>2022} and \citet{li-grodin-harper>2023}, the definitions and examples presented have been partially mechanized in the Cubical Agda proof assistant~\citep{norell>2009}.
%


\begin{acks}
  The authors wish to thank Zachary Battleman, Yue Niu, and Jonathan Sterling for fruitful adjacent collaboration that broadly inspired to this research.
  %
  This material is based upon work supported by the United States Air Force Office of Scientific Research under grant number FA9550-21-0009 (Tristan Nguyen, program manager) and the National Science Foundation under grant number CCF-1901381. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the AFOSR or NSF.
\end{acks}

%
%
%
%

%
\bibliographystyle{ACM-Reference-Format}
\bibliography{main,manual}
%

%
%

\end{document}
