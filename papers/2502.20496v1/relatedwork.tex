\section{Related work}
We now characterize the relationship between our development and prior work, beyond the connections that have been made throughout the text.

\subsubsection{Synthetic phase distinctions}
This work is fundamentally built upon the general framework for modalities in homotopy type theory developed by \citet{rijke-shulman-spitters>2020}, making particular use of the open and closed modalities associated with the proposition $\beh$, and set in the world of synthetic phase distinctions, pioneered by \citet{sterling-harper>2021}.
\citet{sterling-harper>2022} also apply the techniques of synthetic phase distinctions to the domain of security and information flow, which broadly aligns with the viewpoint that algorithmic data is private and behavioral data is public.

Recent work by \citet{gratzer-sterling-angiuli-coquand-birkedal>2022} on abstraction in dependent type theory makes use of phases to selectively reveal the implementation of definitions; within the phase for a particular definition, the corresponding code is revealed.
This technique makes use of extension types~\citep{riehl-shulman>2017}, similar to the type we write $\SPEC{X}{x_0(\b)}$ but equipped with a judgmental rather than typal equality.
The judgmental equality ensures a degree of faithfulness to the true source code that our story intentionally avoids: although a private implementation should match its public specification, the proof of this fact is rarely judgmental.

As regards the connections to cost analysis and \calf{}, the principal reference is~\citet{niu-sterling-grodin-harper>2022} on which the cost-oriented discussions in the present paper is based.
Therein are provided a comprehensive comparison to related work on formalized cost analysis, all of which applies as well to the present setting.


\subsubsection{Ghost code}
Our use of phases broadly parallels the technique of \emph{ghost code}, where functional, specification-level ghost code is maintained alongside (typically more efficient) ``regular'' code.
%
%
%
Prior accounts of ghost code have described noninterference of ghost code with regular code, erasing ghost code to extract the efficient regular code~\citep{filliatre-gondelman-paskevich>2016}.
Although our presentation supports the extraction of algorithmic code as an external notion, achieved by giving a semantics where $\beh$ is the false proposition as described in \cref{mod:false}, the directionality of our phase is dual: internally, we allow erasure of regular (algorithmic) code, leaving behind only behavior.
This ensures our opposite variety of noninterference, of regular code with ghost code (\cref{thm:noninterference}), which appears here as the essence of modular verification.
%

\subsubsection{Representation independence and univalence}
\citet{angiuli-cavallo-mortberg-zeuner>2021} tell a similar story for abstract data types and representation types in a univalent setting.
For example, in their presentation of batched queues, the pair-of-lists type is quotiented by equivalence under $\Impl{revAppend}$, leading to a type equivalent to the $\listty{\nat}$~\citep[\S 4.2]{angiuli-cavallo-mortberg-zeuner>2021}; this is similar to the behavioral quotients we considered in \cref{sec:free:behavioral-quotient}, but implementing the queue example of \cref{sec:data-structures}.
Furthermore, they also discuss truncating a cost counter with the writer monad, propositionally truncating the cost model to identify differing costs \citep[Example 2.1]{angiuli-cavallo-mortberg-zeuner>2021}.
These quotients are precisely what occurs in our development here under the behavioral phase (or in \cref{mod:true} where $\beh$ is true), so we may think of their work as taking place in the behavioral phase, after all algorithmic details have already been redacted.
Thus, our story is pleasingly compatible: to recover the ability to extract code prior to redaction, we simply condition the quotients on the behavioral phase.

\subsubsection{Realignment and strict glue type}
One role of univalence in this work is strictly equating the glue type $\Glue{\BEH{X}}{\ALGO{X}}{\alpha}$ to its behavioral component $\BEH{X}$ under the behavioral phase, so that the internal representation of an abstract data type can be related with its specifications as in \cref{sec:data-structures:gluing}. A similar result can be achieved in a non-univalent setting by considering the \emph{realignment/strictification axiom} \cite{birkedal-bizjak-clouston-grathwohl-spitters-vezzosi>2016,orton-pitts>2016,sterling>2022-logical-relations,sterling>thesis} that turns a partial isomorphism under a proposition into a strict equality. Then a \emph{strict glue type} \cite{sterling-harper>2022,yang>thesis} can be defined by realigning the $\Sigma$ type as we have in $\Glue{\BEH{X}}{\ALGO{X}}{\alpha}$.

%
%

\subsubsection{Verification of data structures using abstraction functions}
This work is far from the first to verify data structures using abstraction functions; for example, \citet{nipkow>2024} has developed an extensive suite of data structures in Isabelle with verifications based on abstraction functions.
Our development with the behavioral phase can be viewed as a synthetic place in which to reconstruct such analytic arguments: because every type contains an abstraction function, the language provides the capability to uniformly apply all the abstraction functions simultaneously, working in a phase where all data is abstract.

\subsubsection{Algebraic specification}
In the discipline of algebraic specification abstract data types are specified via equational properties on operations~\citep{sannella-tarlecki>2012}.
In general, it is not required that all operations are uniquely defined by the equations.
However, this strategy is often too conservative: unless the properties exported are complete with respect to the implementation behavior, there will be theorems that the client wishes to prove that are not consequences of the exported properties, violating the principle of modularity (\cref{cor:modularity}).
Moreover, from the perspective of the implementer, it will be possible to provide an ``incorrect'' implementation if the requirements are not strict enough.
These issues are only exacerbated in the presence of complex language features, such as effects and higher-order functions.
To constitute an algorithmic type, an algebraic specification must be behaviorally fully constrained.