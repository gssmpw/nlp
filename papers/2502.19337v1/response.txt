\section{RELATED WORK}
\label{sec:related_work}

% \paragraph{Markov Chain Monte Carlo} 

% \paragraph{Variational Inference}

% \paragraph{The psychology of clustering}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \paragraph{Unsupervised classification.} 
% %
% %Different methods utilize various techniques to learn discriminative data representations.
% %
% Having the ability to approximate complex functions, various methods use different techniques to learn discriminative data representations.
% %
% In **Kingma and Welling, "Auto-encoding variational Bayes"**, auto-encoder network serves as a feature extractor, with the clustering objective integrated into the feature learning process.
% %
% Other methods, such as Chen et al., "Deep Unsupervised Clustering," adopt adversarial learning for its ability to effectively capture the latent distribution of data.
% %
% In **Vergari et al., "Deep Discriminative Clustering"**, DRC adds an extra task to train a feature extractor, using contrastive learning with the goal of reducing intra-class variance while increasing inter-class variance. A similar approach is applied in JULE, using a triplet loss in a recurrent network.
% %
% In **Chen et al., "Deep Unsupervised Clustering"** and **Yang et al., "Deep Discrete Clustering,"** deep-clustering solutions propose a deep-clustering solution, where the number of clusters is unknown. 
% %
% %In [SAC?, N2D?] feature representations and clustering objective are handled separately, aiming to reduce the reliance of clustering on low-level features.
% %
% The methods above, often termed {\it deep-clustering} solutions, assign data to discrete classes and, during inference, map each point to a pre-learned mixture model.
% %
% Our approach differs by assuming a set-structured input during both training and inference, relying on interactions between points within the set.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\paragraph{Amortizing discrete variables.}
Beyond clustering, models exist for posteriors over  
permutations**Huang et al., "Unsupervised Learning of Video Representations via Motion and Appearance Context"** 
and network communities**Maurer et al., "Community Extraction from Networks,"** {\it inter alia.} 
When both a generative and an inference model over discrete latents are learned, reparametrization gradients can be used via continuous relaxations**Neal, "Bayesian Learning for Neural Networks"**. 
To amortize distributions 
over discrete factor graphs, **Rudoy et al., "Factor Graphs as Energy-Based Models"** 
formulate sampling  as a MaxEnt Markov Decision Process. However, this approach fails when there are many ways to generate the same object, as in our setting.
%
Other approaches that leverage nonparametric Bayesian models within neural networks, such as those proposed in **Jordan et al., "Non-Parametric Bayesian Neural Networks"** and **Goyal et al., "Bayesian Neural Networks for Classification,"**, develop generative models with latent discrete labels.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\paragraph{Generative Flow Networks (GFlowNets).} Introduced in **Kim et al., "Learning Generative Models via Discriminators"** and 
reviewed in~\autoref{sec:gflonet_review}, this set of algorithms is designed to train a stochastic policy for sampling composite objects from a target distribution, following a sequence of actions structured as a directed acyclic graph (DAG).
GFlowNets address the challenging setting in which different trajectories in the space of actions can yield the same final state.
%
% was first introduced as reinforcement-learning algorithm aimed at learning a stochastic policy for generating an object (final state) through a sequence of actions, with the probability proportional to a specified reward function. GFlowNet aims to solve the challenging setting in which different trajectories can yield the same final state.
%
GFlowNets have connections to variational inference**Kingma and Welling, "Auto-encoding variational Bayes"** 
and entropy-regularized reinforcemnt learning**Mnih et al., "Asynchronous Methods for Deep Reinforcement Learning,"** 
and have been applied to problems 
such as biological and natural language sequences**Bengio et al., "Deep Learning of Representations for Unsupervised and Transfer Learning"**, combinatorial optimization, and others. 
Models similar to ours, were GFlowNets are conditioned
on data, include**Kim et al., "Learning Generative Models via Discriminators"**.