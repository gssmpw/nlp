
\section{AVERAGE SCORE VS. GREEDY DECODING}
\label{sec:average_score}

In this section, we evaluate GFNCP using the average-score approach, where metrics are derived from multiple assignment samples, and compare it to the greedy-decoding approach introduced in the paper.
%
In the average-score approach, for each input set sampled from the test data, we generate 
assignment predictions by selecting the next assignment at each step in the sequence through sampling, instead of choosing the most probable assignment. Next, we compute the NMI/ARI metrics based on the top-100 assignments, sorted according to their predicted probabilities. We utilize the same models trained and evaluated in the Experiment section of the paper on Mixture of Gaussians (MoG), MNIST, and ImageNet-50/100/200 (IN50/IN100/IN200) datasets, maintaining the same test set size for consistency. Results are presented in~\autoref{tab:rebuttal_R3}. We observe that GFNCP is still equal or better than NCP across all datasets, and that greedy decoding yields slightly better results in most cases.

\subimport{../tables/}{rebuttal_top_100_avg_score_R3}