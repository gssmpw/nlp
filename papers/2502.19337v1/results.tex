

\section{EXPERIMENTS}

\subimport{./figures/}{fmnist_generated_clustering}

% -------------------------------------------------
%                  General Comments
% -------------------------------------------------

We present an extensive evaluation of GFNCP on several datasets,
covering synthetic and toy data in \autoref{subsec:toy_data}, and real-world data in \autoref{subsec:real_data}.
%
We compare GFNCP with other notable existing approaches, including Set Transformer (ST)~\citep{lee2019set}, DAC~\citep{DAC} and NCP~\citep{pakman2020}. 
%
We demonstrate that GFNCP outperforms existing methods in clustering performance and maintains invariance to input data order, supported by both quantitative and qualitative evidence.
%
% In \autoref{subsec:toy_data} we analyze GFNCP's clustering performance and data-permutation invariance on synthetic and toy data. In \autoref{subsec:real_data} we continue evaluating GFNCP on real-data (embedded ImageNet~\citep{Russakovsky:IJCV:2015:imagenet})
% % using arbitrary number of clusters. 
% %
% We compare GFNCP with other notable existing approaches, including Set Transformer (ST)~\citep{lee2019set}, DAC~\citep{DAC} and NCP~\citep{pakman2020}. 
% %
% We demonstrate that GFNCP is invariant to the order of input data, supported by both quantitative and qualitative results. 
%
In all of our experiments we report the average values on three runs, selecting the best model based on the lowest loss value.

\subsection{Set-structured input generation}\label{subsec:input_set_generation}

Recall that our method can be trained in an unsupervised manner (\autoref{seq:self_sup}). 
In all our experiments, we generate the training-data distribution $p_{\text{data}}(\bc,\bx)$ by following~\autoref{eq:gen1} and utilizing a Chinese Restaurant Process (CRP)~\citep{pitman_csp} for clustering mixtures, where each cluster comprises a sampled data point.
Specifically, we adhere to the following steps: (1) the data size $N$ is either fixed or sampled,  and 
a clustering mixture $\bc$ is drawn using the CRP; (2) for self-supervision, instance discrimination is applied: 
data for each cluster contains a random data point from the dataset plus its augmentations to match the cluster size.  
For the test data, we follow the same procedure, except that in step (2), we use the original data points instead of augmentations.
%
See~\autoref{sec:data_generation} for details. 
% Further details on data generation and CRP parameters are available in~\autoref{sec:data_generation}.

% -------------------------------------------------
%                Invariance Metrics
% -------------------------------------------------


\subsection{Data-order invariance metrics}\label{subsec:inv_metrics}

% To evaluate the gap between our model and NCP, we introduce two quantitative metrics for evaluating data-permutation invariance.
%To assess the discrepancy between our model and NCP, we define two quantitative indicators to assess data-permutation invariance.
% \indent \textbf{Marginal Consistency (MC).} This metric measures the marginal-consistency loss (\autoref{eqn:mc_loss}) based on the marginal probabilities at test time.
% \indent \textbf{Standard Deviation over Permutation Probabilities (SDPP).} For this metric, we conduct an experiment where we generate the model's output probabilities given 500 different permutations of the same dataset. We then compute the standard deviation (SD) of the resulting probabilities and normalize it by dividing by the mean (M) probability, to eliminate scaling bias in method comparisons.
%
% The SDPP metric is defined as follows:
%         \begin{equation}
%             \text{SDPP} = \mathbb{E}_{p(N)p(\bx)} \left[ \frac{SD ( \{ p(\bc_{\pi} | \bx_{\pi}) \}_{\pi \in \rho})}{M ( \{ p(\bc_{\pi} | \bx_{\pi}) \}_{\pi \in \rho})} \right]
%             \label{eq:inv_metric}
%         \end{equation}
% where $\rho$ is a set of 500 random permutations. 
% Lower values of the MC and SDPP metrics indicate greater consistency of the model. Note that ST and DAC are excluded from this comparison since they do not produce marginal probabilities for clustering assignments.
To compare GFNCP with NCP, we introduce two metrics. (i)
\textbf{Marginal Consistency (MC):} the average of the marginal-consistency loss (\autoref{eqn:mc_loss}) 
over test pairs $(\bc,\bx) \sim p_{\text{data}}(\bc,\bx)$. 
%\indent 
(ii) \textbf{Standard Deviation over Permutation Probabilities (SDPP):} 
Given a pair $(\bc,\bx) \sim p_{\text{data}}(\bc,\bx)$, we evaluate the probabilities (\autoref{eq:prob_trajectory}) for 500 different permutations $(\bc_{\rho},\bx_{\rho})$; we then compute the standard deviation~(SD) of these probabilities and divide by their mean (M), to eliminate scaling bias.
%
The SDPP metric for $(\bc,\bx)$ is 
        \begin{equation}
            \text{SDPP}(\bc,\bx) =  
            \frac{SD ( \{p(\bc_{\rho} | \bx_{\rho})\}_{\rho \in S^N} ) }
            {M ( \{p(\bc_{\rho} | \bx_{\rho})\}_{\rho \in S^N} ) }
            \label{eq:inv_metric} \,.
        \end{equation}
% and the SDPP metric for the model is 
%         \begin{equation}
%           \text{SDPP} =\mathbb{E}_{p_{data}(\bc,\bx)}[\text{SDPP}(\bc,\bx)]  
%             \label{eq:inv_metric}
%         \end{equation}
Lower MC and SDPP metrics indicate greater consistency of the model. Note that ST and DAC are excluded from this comparison since they do not produce probabilities for clustering assignments.




% -------------------------------------------------
%                  Toy data
% -------------------------------------------------
\subimport{./figures/}{perms_GFNCP_vs_NCP_mnist}
\subimport{./tables/}{clustering_stats_toy_data_fixed_k}
\subimport{./tables/}{clustering_stats_toy_data_unlim_k}
\subsection{Toy data}\label{subsec:toy_data}

We first demonstrate GFNCP's performance 
on a two-dimensional Gaussian-Mixture-Model (MoG), MNIST and Fashion-MNIST (FMNIST)~\citep{xiao:2017:FMNIST} datasets, using either fixed or arbitrary number of clusters $K$.
%
For data generation we follow the procedure in \autoref{subsec:input_set_generation}.
% During training, we create input sets by randomly sampling $N$ data points 
%from the training dataset, 
% based on the CRP mixture. 
We use $N\sim (100,1000)$ for set size, and a batch size of $64$. For the fixed-clusters experiment we condition the CRP prior on $K=6$.
%
As the ST method is mainly designed for embedded images, we utilize a data encoder (similar to the one used in our architecture) for these experiments, to enhance its performance.
%
We evaluate the models on $10,000$ input sets drawn from the test data for MNIST and FMNIST, and on $3,000$ newly-generated input sets for MoG, where each set is of size $N=300$. 
%
We report NMI and ARI metrics \citep{fahad:2014:NMI_ARI} for clustering evaluation.
%
For NCP and GFNCP, these metrics are calculated on assignments
generated via greedy decoding, where each assignment~$c_n$ 
in the sequence is selected according to the highest forward probability~\autoref{eq:forward_clustering}. 
%
See \autoref{sec:data_gen_and_experimental_setup} for more details on the experimental setup and data generation.
%
We also evaluate GFNCP using the average-score approach, where metrics are derived from multiple assignment samples (see \autoref{sec:average_score} for more details).

\autoref{tab:clustering_stats_toy_data_fixed_k} and \autoref{tab:clustering_stats_toy_data_unlim_k} present results for fixed and varying number of clusters, respectively.
%
GFNCP consistently outperforms existing methods on different datasets and settings. We observe that DAC's performance deteriorates when the data mixture is less balanced, a factor influenced by the CRP hyper-parameter.
%
Note that ST is excluded from \autoref{tab:clustering_stats_toy_data_unlim_k} because it is not designed for varying~$K$.
%
In \autoref{fig:fmnist_generated_clustering} we illustrate the top-three most probable clustering generated by GFNCP, highlighting its capability to leverage point interactions in assignment predictions.
%
In \autoref{fig:perms_GFNCP_vs_NCP_mnist} we showcase GFNCP's invariance to input-data order, \eg, when the digit `8' (highlighted in orange) appears earlier in the data sequence, NCP generates an additional cluster for the thicker `8' instances, whereas GFNCP produces consistent results.
%
The gap in order invariance is also shown in \autoref{fig:invariance_ecdf_mnist}, where we present the histogram and empirical CDF (ECDF) of the SDPP metric for both GFNCP and NCP on MNIST.
%
% Alongside the aforementioned experiments, we utilize a well-known set of tests known as Geweke's Tests~\citep{geweke2004getting} in the Appendix to demonstrate that GFNCP can effectively approximate the prior distribution $p(c_{1:N})$. 
% In the Appendix, we use a popular family of tests called Geweke's Tests~\citep{geweke2004getting}, and show that GFNCP can approximate the prior distribution $p(c_{1:N})$. 
%In addition, in \autoref{subsec:geweke_test} we show that GFNCP can approximate the prior distribution, by using a popular family of tests called Geweke's test.




% -------------------------------------------------
%                  Real-world data
% -------------------------------------------------

\subimport{./tables/}{clustering_stats_IN_50_100_200}

\subsection{Real-world data}\label{subsec:real_data}
We evaluate GFNCP's clustering performance on images sampled from ImageNet-50/100/200, which are subsets of 50/100/200 classes from ImageNet ~\citep{Russakovsky:IJCV:2015:imagenet}, using arbitrary $K$.
%
Since the models we consider assume that the cluster parameters,
$\mu_k$ (\autoref{eq:gen1}), have been integrated out, it is natural to explore 
their ability to generalize to unseen cluster classes.  
We thus sample training sets from half of the classes, and use the other half to form the test sets.
%
% To study the generalization of our method for unseen examples, training sets are sampled from half of the classes, while the other half is used to form the test sets, ensuring there is no overlap between the training and test classes.
%
Each image is represented by a 384-dim vector obtained from DINO~\citep{caron:DINO:2021}. 
% 
Similar to the toy-data experiments, we follow the procedure in \autoref{subsec:input_set_generation} for data generation. %, with the same input-set sizes.
%
In \autoref{tab:clustering_stats_IN_50_100_200} we show a significant advantage to GFNCP. We report NMI, ARI and MC metrics, computed on the results over 2500 test sets.
% 
In \autoref{fig:invariance_ecdf_IN50_IN200} we present the histogram and ECDF of the SDPP metric for GFNCP and NCP.
%
More information on the experimental setup can be found in \autoref{sec:data_gen_and_experimental_setup}.

%\subsection{Geweke’s Tests}\label{subsec:geweke_test}

\subimport{./figures/}{invariance_ecdf_IN50_IN200}


In addition to the mentioned experiments, we evaluate GFNCP in an ``online mode". Unlike the primary mode, where the forward transition relies on the full dataset $x_{1:N}$, the model here sequentially predicts assignments for new data points based only on prior points and their cluster assignments, without access to future data. More details about this experiment are available in~\autoref{sec:online_mode}.








