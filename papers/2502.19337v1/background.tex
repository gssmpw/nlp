
\section{BACKGROUND}
\subsection{Generative  models of clusters} 
Consider  $N$ data points $\mathbf{ x} = \{x_i\}$, 
and assume they were generated through a probabilistic clustering model of the form
\begin{align}
\nn
\alpha_1, \alpha_2 &\sim p(\alpha_1, \alpha_2)
\\
\nn 
N &\sim p(N)
\\
c_1 \ldots c_N &\sim p(c_{1:N}|\alpha_1) 
\quad c_i \in \{ 1 \ldots K \}
\label{eq:gen1}
\\
\mu_1 \ldots \mu_K|c_{1:N} &\sim 
p(\mu_{1:K}  |\alpha_2) 
\nn
\\
x_i &\sim p(x_i|\mu_{c_{i}}) \quad i=1 \ldots N.
\nn
\end{align}
%The generative model introduces discrete random variables~$c_i$ denoting the index of the cluster that data point~$x_i$ is assigned to,
% and note that $K$, the number of clusters, can itself be a random variable. 
%
The generative model introduces discrete random variables~$c_i$, representing the cluster index for each data point~$x_i$. Note that $K$, the number of clusters,
can itself be a random variable. 
%
Here $\alpha_1, \alpha_2$ are hyperparameters and~$\mu_k$ denotes a parameter vector controlling the distribution of the $k$-th cluster (e.g.,~$\mu_k$ could include both the mean and covariance of a Gaussian-mixture component). 
We also assume that the priors $p(c_{1:N}|\alpha_1)$ and 
$p(\mu_{1:K}|\alpha_2)$ are exchangeable,
\eqan 
\nn
p(c_{1:N}|\alpha_1) &=& 
p(c_{\rho_1}\ldots c_{\rho_N}|\alpha_1)\,,
\\
p(\mu_{1:K} |\alpha_2) &=& 
p(\mu_{\xi_1} \ldots \mu_{\xi_K}|\alpha_2)\,,
\label{eq:exch_pior}
\enan
where $\{ \rho_i \}_{i=1}^N$ and $\{ \xi_k \}_{k=1}^K$ are arbitrary permutations over $N$ and $K$ 
indices, respectively. 


% \begin{figure*}[t!]
% 	\begin{center}
% 		\fbox{		
% 		\includegraphics[width=.85\textwidth]{figures/Gks2.pdf}}
% 	\end{center}
% 	\caption{{\bf Encoding cluster labels.} 
% After assigning labels 
% $c_{1:6}$ to $K=2$ clusters, each of the three possible $c_7$
% labels  (for the circled point~$x_7$) gives
% an encoding  $G_k$ for the set $x_{1:7}$.  
% Each $G_k$ is the encoding $G_{c_{1:6}}$ obtained when 
% point $x_n$ joins cluster $k$. 
% The vector~$U= U_{n+1}$ encodes the four gray unlabeled points (Best in color).
% 	} 
% 	\label{fig:Gks}	
% \end{figure*}
Given data points $x_{1:N}$, the central object we aim to model 
is the posterior $p(c_{1:N}|x_{1:N})$. 
Of particular interest for us are two properties: 
% posterior Note in  As in many distributions over highly structured domains,  
%  typically respect  certain symmetries~\citep{kallenberg2005probabilistic}.
% \paragraph{Labeling Invariance}
% It should not matter which label we use to designate each cluster: 
% \eqan 
% p(c_{1:N} |x_{1:N} ) = 
% p(\xi_{c_{1}} \ldots \xi_{c_N}|x_{1:N}) \,.
% \label{eq:label_sym}
% \enan 
\begin{itemize}
    \item {\bf Conditional exchangeability:}
probabilities should not 
depend on the order of the data: 
% As follows from (\ref{eq:gen1}) and (\ref{eq:exch_pior}), we have
\begin{equation}
p(c_{1:N} |x_{1:N}) = 
p(c_{\rho_1}\ldots c_{\rho_N}|x_{\rho_1} \ldots x_{\rho_N} )\,.
\label{eq:exchange}   
\end{equation}

\item {\bf Marginal consistency:}
by definition, the following relationship holds between marginals
(for $n=1 \ldots N-1$): 
\eqan 
p(c_{1:n}| x_{1:N}  )  = 
 \sum_{c_{n+1}} p(c_{1:n}, c_{n+1}| x_{1:N} ) \,. 
 \label{eq:marginal_consistency1}
\enan 
\end{itemize}



\subsection{The Neural Clustering Processes}
\label{sec:amortizing}
The standard approach to draw samples from the posterior $p(c_{1:N}|x_{1:N})$, MCMC, has two major limitations. First, convergence can be slow and hard to assess. Second, MCMC requires an explicit expression for the generative model $p(x_i|\mu_{c_i})$. 
A common way out of the latter problem is to assume that $p(x_i|\mu_{c_i})$ follows a Gaussian
(perhaps after some data pre-processing, \eg, 
as proposed in~\cite{Chang:NIPS:2013:ParallelSamplerDP}),
%~\citep{dinari:2022:sampling,ronen:2022:DeepDPM}, 
a choice that is not justified in general. 

%To overcome  the above limitations, neural amortized models have been proposed recently that yield (approximate) 
To address these limitations, recent advancements have introduced neural amortized models that can generate (approximate)
i.i.d.~samples from $p(c_{1:N}|x_{1:N})$, 
without requiring an explicit generative model $p(x_i|\mu_{c_i})$. 
The Neural Clustering Process~(NCP)~\citep{pakman2020},
is a model for~$p(c_{1:N}|x_{1:N})$
that approximates the marginal posteriors \begin{align}
p(c_{1:n}| x_{1:N}  )=
\!\!\! \sum_{c_{(n+1):N}} 
\!\!\! 
p(c_{1:N}| x_{1:N} ) \,,
 %\quad n=1 \ldots N\!-\!1
 \label{eq:posterior_marginals}
\end{align} 
for $n=1 \ldots N-1$, 
using an energy-based model,
\begin{equation}
p_{\theta}(c_{1:n}| x_{1:N}  ) = 
  \frac{e^{-E_n[c_{1:n}, x_{1:N}]}}{Z_n[x_{1:N}]} \,,
\label{eq:NCP_marginals}
\end{equation}
where $Z_n[x_{1:N}]$ is a normalization constant
and $\theta$ are the parameters of the energy 
function~$E_n$. Note that under the  generative model~(\autoref{eq:gen1}),
the marginal posteriors~(\autoref{eq:posterior_marginals})
depend on all the  data points   $x_{1:N}$, 
not just on $x_{1:n}$.
Using the approximate marginals (\autoref{eq:NCP_marginals}),
posterior samples are obtained by fixing a data order and  sequentially sampling from  each factor in the approximate expansion:
\eqan 
p_{\theta}(\bc |\bx) 
\simeq   p(c_1| \bx ) p_{\theta}(c_2|c_1,\bx ) \ldots p_{\theta}(c_N|c_{1:N-1}, \bx)\,,
\label{joint}
\enan
given by:  
\begin{align}
p(c_1=1| \bx ) &= 1
\label{eq:first_assgn}
\\
p_{\theta}(c_n|c_{1:n-1}, \bx) 
&= \frac{  p_{\theta}(c_{1:n} |\bx)}
{  \sum_{c_n'=1}^{K+1}  p_{\theta}(c_1 \ldots c_n'| \bx)},
\label{eq:conditional}
\\
&= \frac{  e^{-E_n[c_{1:n}, x_{1:N}]} }
{  \sum_{c_n'=1}^{K+1}  
e^{-E_n[c_1 \ldots c_n', x_{1:N}]}}.
\label{eq:conditional2}
\end{align}
Note that the first assignment (\autoref{eq:first_assgn}) is deterministic. The NCP setup assumes $K$ unique values in $c_{1:n-1}$,
so~$c_n$ can take $K+1$ values, i.e., $x_n$ can join any existing cluster or form its own new cluster. 
%
Interestingly, the normalization constant from \autoref{eq:NCP_marginals} cancels out in the conditionals (Eq. \ref{eq:conditional}-\ref{eq:conditional2}). This allowed the authors of~\cite{pakman2020} to train the model via maximum likelihood,  
\begin{align}
    \theta = \argmax_{\theta} \mathbb{E}_{ p_{\text{data}}(\bc, \bx)} [\log p_{\theta}(\bc |\bx) ]    \,,
\end{align}
without contrastive divergence~\citep{hinton2002training}. 
A major limitation of the NCP model, however, is that 
although \autoref{eq:conditional} assumes 
the validity of \autoref{eq:marginal_consistency1}, the latter is not enforced 
in the architecture or the loss. 

\paragraph{Architecture of the energy function.} The NCP energy function $E_n[c_{1:n}, x_{1:N}]$ in \autoref{eq:NCP_marginals}
is the scalar output of 
a network that respects the following symmetries of the marginal posteriors $p(c_{1:n}| x_{1:N})$ in \autoref{eq:posterior_marginals}: 
% The general problem of constructing such invariant encodings was discussed recently in \citep{deep_sets}; to adapt this approach to our context, we consider three distinct permutation symmetries:
\newlist{myitemize}{itemize}{3}
\setlist[myitemize,1]{label=\textbullet,leftmargin=0.2in}
\begin{myitemize}

	\item Permutations {\bf within a cluster}	
 are preserved by encoding the data points in each cluster as: 
	\eqan
	H_k= \sum_{i : c_{i}=k} h(x_i)  %\qquad k = 1\ldots K\,,
	\quad h:\mathbb{R}^{d_x} \rightarrow \mathbb{R}^{d_h}
	\label{Hk}
	\enan 
	% which is clearly invariant under permutations of $x_i$'s in the same cluster. 

 \item Permutations {\bf  between clusters}
	%	\\
	% (\ref{eq:posterior_marginals}) is invariant under permutations of the cluster labels.
 are preserved, using the cluster invariants~$H_k$,  by 
 %in terms of the , 
	\eqan 
	G_{c_{1:n}}= \sum_{k =1}^K g(H_k) ,
	\quad 
	g:\mathbb{R}^{d_h} \rightarrow \mathbb{R}^{d_g}.
	\label{G_def}
	\enan 			

	\item Permutations of the {\bf  unassigned data points} are preserved  by 
	\eqan 
	U_{n+1} = \sum_{i=n+1}^{N}  u(x_i) \,,
		\qquad 
	u:\mathbb{R}^{d_x} \rightarrow \mathbb{R}^{d_u}.
	\label{Q}
	\enan 		
	\end{myitemize} 

The functions $h,g,u$ are neural networks.  
$G$ and~$U$ provide distributed, 
symmetry-invariant representations of the assigned and unassigned data points, respectively, for any~$N$ and $K$.  
Encodings of this form 
yield arbitrarily accurate approximations 
of (partially) symmetric 
functions~\citep{deep_sets,gui2021pine}.
Using the $G,U$ encodings, 
the NCP model represents the energy functions in \autoref{eq:NCP_marginals} as 
\eqan 
E_n[c_{1:n}, x_{1:N}] = f(G_{c_{1:n}},U_{n+1}) \,,
\label{eq:unnormalized_marginal}
\enan 
where $	f:\mathbb{R}^{d_g + d_u} \rightarrow \mathbb{R}$ is a neural network.













\subsection{Generative Flow Networks} 
\label{sec:gflonet_review}
\begin{figure*}[t!]
	\begin{center}
		\fbox{		
\includegraphics[width=.77\textwidth]{figures/dag5.pdf}}
	\end{center}
	\caption{{\bf Clustering via sequential decisions}. 
 Directed Acyclical Graph (DAG) of sequential
 assignment of cluster labels  for a dataset of size $N=3$. The first action samples uniformly an order $\rho$ for the data points.  Each terminal state, corresponding to a fully clustered dataset, receives $N!$ incoming edges, corresponding to all possible orders of the data. 
	} 
	\label{fig:dag}	
\end{figure*}

GFlowNets \citep{bengio2021flow,bengio2023gflownet}
are a family of  models that amortize the 
cost of sampling over complex discrete objects. 
Assume we are given 
a directed acyclic graph (DAG) $(\mathcal{S}, \mathcal{A})$
where $\mathcal{S}$ is a finite set of vertices {\it (states)} and  $\mathcal{A} \subset \mathcal{S} \times \mathcal{S}$ is a
set of directed edges {\it (actions)}, and there is a unique initial state $s_0$ from which every other state is reachable. 

The composite objects of interest are represented by 
{\it terminal states} $\mathcal{Z} \subseteq \mathcal{S}$ without outgoing edges. Such objects can be constructed by following a trajectory 
$\tau = (s_0 \rightarrow s_1 \rightarrow \ldots
\rightarrow z)$, where $z \in \mathcal{Z}$. 
Denoting by $\mathcal{T}$ the set of trajectories, 
\cite{bengio2023gflownet} define a {\it trajectory flow} $F:\mathcal{T} \rightarrow \mathbb{R}^+$ as an unnormalized probability mass associated 
to trajectory~$\tau$. 
The {\it edge flow} is defined as  
$ F(s \rightarrow s') = \sum_{\tau: s \rightarrow s' \in \tau } F(\tau)$
and the {\it state flow} as 
$ F(s) = \sum_{\tau: s \in \tau } F(\tau)$. 

%

Markovian GFlowNets treat the generation of a sample 
in $\mathcal{Z}$ 
as a Markov sequential decision problem. 
Samples from $\mathcal{Z}$ 
are obtained by starting from $s_0$ and 
sampling successive actions using a {\it forward policy}, 
which represents a distribution over the children of $s \in \mathcal{S} \backslash  \mathcal{Z}$ given~by 
\begin{align}
P_F(s'|s) = \frac{F(s \rightarrow s')}
{\sum_{s''} F(s \rightarrow s'') } \,,
\label{eq:forward}
\end{align}
until a terminal state is reached.  
% A {\it consistent flow} satisfies $\forall s \in \mathcal{S}$ the flow matching equations
% \begin{align}
%     \sum_{s' \in \text{ Parent}(s) } \!\!\!\!\!\! F( s' \rightarrow s)  = 
%     \!\!\!\!\!\!
%     \sum_{s'' \in \text{ Children}(s) } \!\!\!\!\!\! F(s \rightarrow s'').
% \label{eq:flow_match}
% \end{align}
% The goal of training a GFlowNet is to find a policy such that 
% the probability of reaching a terminal state $z \in \mathcal{Z}$ is proportional to a specified or learned {\it reward} function $R(z):\mathcal{Z} \rightarrow \mathbb{R}^+$, i.e., 
% \begin{align}
%     R(z) \varpropto  \sum_{z \in \tau } F(\tau) \,.
%     \label{eq:R_GFN}
% \end{align}
% As shown in~\cite{bengio2021flow}, this occurs 
% when using the policy of \autoref{eq:forward} in a consistent flow whose terminal states satisfy $F(z)\varpropto R(z)$. Given a parameterized edge flow, the Flow Matching loss~\citep{bengio2021flow} imposes  
% equation \autoref{eq:flow_match} in log space. 
% Recent  works also use other losses such as the Detailed Balance~\citep{bengio2023gflownet} or Trajectory Balance~\citep{malkin2022trajectory}, which exploit backward policies  over the parents of a state $s$. But in our case (see below) non-terminal states have a single parent. 
The goal of training a GFlowNet is to find a policy such that 
the probability of reaching a terminal state $z \in \mathcal{Z}$ is proportional to a specified or learned {\it reward} function $R(z) \in \mathbb{R}^+$, i.e., 
\begin{align}
    R(z) \varpropto  \sum_{\tau: z \in \tau } F(\tau) \,.
    \label{eq:R_GFN}
\end{align}
As shown in~\cite{bengio2021flow}, this occurs 
when using a policy of the form \autoref{eq:forward} obtained from edge flows 
satisfying the flow matching equations
\begin{align}
    \sum_{s' \in \text{ Parent}(s) } \!\!\!\!\!\! F( s' \rightarrow s)  = 
    \!\!\!\!\!\!
    \sum_{s'' \in \text{ Children}(s) } \!\!\!\!\!\! F(s \rightarrow s'')\,,
\label{eq:flow_match}
\end{align}
and whose terminal states satisfy $F(z)\varpropto R(z)$. Given a parameterized edge flow, the Flow Matching loss~\citep{bengio2021flow} imposes  
equation \autoref{eq:flow_match} in log space. 
Recent  works use other losses such as Detailed Balance~\citep{bengio2023gflownet}, Trajectory Balance~\citep{malkin2022trajectory}
or SubTB($\lambda$)~\citep{madan2023learning}, 
which exploit backward policies  over the parents of a state $s$. 
% But in our case (see below) non-terminal states have a single parent. 




% A GFlowNet is structurally equivalent to a Markov Reward Process~\citep{ronald1971dynamic}, i.e., 
% a Markov Decision Process with deterministic dynamics, and has close connections with entropy-regularized reinforcement learning~\citep{tiapkin2024generative}. 