\section{Related Works}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
\subsection{Evolution of AI-generated Images}
%-------------------------------------------------------------------------------
The rapid advancement of generative models has significantly improved the quality and diversity of AI-generated images.
Early approaches, such as Variational Autoencoders (VAEs)____, focused on learning latent representations of data distributions. 
Generative Adversarial Networks (GANs)____, through their adversarial training framework, enabled high-fidelity image generation, with subsequent models like BigGAN____ and StyleGAN____ further enhancing controllability and realism.
Recently, diffusion models ____ have emerged as a powerful alternative to GANs, achieving state-of-the-art results in image generation. These models gradually denoise a random distribution to generate highly detailed and diverse images____.
Additionally, autoregressive models such as DALLÂ·E____, along with diffusion-based models like Stable Diffusion 1.4____, GLIDE____, and ADM____, have further pushed the boundaries by enabling highly realistic text-to-image generation. These models have significantly broadened the applicability of AI-generated images across a variety of domains, including creative content generation, artistic design, and virtual reality ____.

However, the increasing realism of AI-generated images has raised concerns about their potential misuse, such as creating deepfakes or spreading misinformation. This has motivated research into robust detection techniques capable of generalizing across diverse generative models, as the subtle artifacts of generated images make them increasingly difficult to distinguish from real ones.

%-------------------------------------------------------------------------------
\subsection{Detection of AI-generated Images}
%-------------------------------------------------------------------------------
The detection of AI-generated images has become a critical research area due to the potential misuse of generative technologies____. 
Early methods focused on identifying GAN-specific artifacts, such as pixel-level inconsistencies, using handcrafted features or traditional classifiers____. While effective for low-quality or early-generation fake images, these approaches struggled to generalize to more advanced models. With the rise of deep learning, Convolutional Neural Networks (CNNs) have been widely adopted for their ability to automatically learn discriminative features____. For example, Wang et al.____ find that pre-trained CNNs on ProGAN-generated images can generalize to other GAN-based images, benefiting from large-scale training on diverse LSUN____ object categories.

However, as generative models such as diffusion models and text-to-image models have gained traction, new challenges have emerged for detection tasks____. Unlike GANs, which often introduce visible artifacts, diffusion models produce highly realistic images with minimal visual discrepancies____. Zhu et al.____ highlight that classifiers trained solely on GAN-based images struggle to generalize to diffusion-based generated images, as the two types of synthetic images exhibit distinct fingerprints.
To address this, Wang et al.____ proposed the Diffusion Reconstruction Error (DIRE), which leverages the insight that real images cannot be accurately reconstructed by diffusion models. While effective for diffusion-generated images, DIRE fails to generalize to text-to-image generation models, as demonstrated by Sha et al. in ZeroFake____. ZeroFake____ improves upon DIRE by exploiting the differential response of fake and real images to the adversary prompts during the inversion and reconstruction process, showing superior performance in detecting fake images generated by text-to-image models. While ZeroFake does not require retraining, its adversarial prompt and reconstruction process are computationally expensive. Moreover, its reliance on case-specific thresholds (e.g., fake image detection and fake artwork detection), further limiting its practicality in open-world scenarios.

In summary, existing detection methods face significant challenges in generalizing to unseen generative models____. As the landscape of generative models continues to diversify, there is a growing need for a universal detection method that can detect fake images generated by any model, even when only a single generative model is used during training. 

\begin{figure*}[t!]
  \centering
  \includegraphics[width=0.98\linewidth]{./figure/framework1.pdf}
  \caption{ The overall framework of our PAD. It consists of two key steps: (1) aligning test images with known fake distributions, and (2) generating pseudo-fake samples for further classification using deep KNN distances and a threshold-based criterion.}
\label{fig: framework}
\end{figure*}
%-------------------------------------------------------------------------------