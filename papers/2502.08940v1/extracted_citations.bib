@inproceedings{allen-zhu2023towards,
title={Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning},
author={Zeyuan Allen-Zhu and Yuanzhi Li},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}

@inproceedings{allen2022feature,
  title={Feature purification: How adversarial training performs robust deep learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  booktitle={2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={977--988},
  year={2022},
  organization={IEEE}
}

@article{bishop1995training,
  title={Training with noise is equivalent to Tikhonov regularization},
  author={Bishop, Chris M},
  journal={Neural computation},
  volume={7},
  number={1},
  pages={108--116},
  year={1995},
  publisher={MIT Press}
}

@article{carratino2022mixup,
  title={On mixup regularization},
  author={Carratino, Luigi and Ciss{\'e}, Moustapha and Jenatton, Rodolphe and Vert, Jean-Philippe},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={325},
  pages={1--31},
  year={2022}
}

@article{chen2020group,
  title={A group-theoretic framework for data augmentation},
  author={Chen, Shuxiao and Dobriban, Edgar and Lee, Jane H},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={245},
  pages={1--71},
  year={2020}
}

@article{chen2024does,
  title={Why does sharpness-aware minimization generalize better than SGD?},
  author={Chen, Zixiang and Zhang, Junkai and Kou, Yiwen and Chen, Xiangning and Hsieh, Cho-Jui and Gu, Quanquan},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{chidambaram2023provably,
  title={Provably learning diverse features in multi-view data with midpoint mixup},
  author={Chidambaram, Muthu and Wang, Xiang and Wu, Chenwei and Ge, Rong},
  booktitle={International Conference on Machine Learning},
  pages={5563--5599},
  year={2023},
  organization={PMLR}
}

@inproceedings{dao2019kernel,
  title={A kernel theory of modern data augmentation},
  author={Dao, Tri and Gu, Albert and Ratner, Alexander and Smith, Virginia and De Sa, Chris and R{\'e}, Christopher},
  booktitle={International conference on machine learning},
  pages={1528--1537},
  year={2019},
  organization={PMLR}
}

@article{hanin2021data,
  title={How data augmentation affects optimization for linear regression},
  author={Hanin, Boris and Sun, Yi},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8095--8105},
  year={2021}
}

@inproceedings{huang2023understanding,
  title={Understanding convergence and generalization in federated learning through feature learning theory},
  author={Huang, Wei and Shi, Ye and Cai, Zhongyi and Suzuki, Taiji},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{jelassi2022towards,
  title={Towards understanding how momentum improves generalization in deep learning},
  author={Jelassi, Samy and Li, Yuanzhi},
  booktitle={International Conference on Machine Learning},
  pages={9965--10040},
  year={2022},
  organization={PMLR}
}

@article{oh2024provable,
  title={Provable benefit of cutout and cutmix for feature learning},
  author={Oh, Junsoo and Yun, Chulhee},
  journal={arXiv preprint arXiv:2410.23672},
  year={2024}
}

@article{park2022unified,
  title={A unified analysis of mixed sample data augmentation: A loss function perspective},
  author={Park, Chanwoo and Yun, Sangdoo and Chun, Sanghyuk},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={35504--35518},
  year={2022}
}

@inproceedings{rajput2019does,
  title={Does data augmentation lead to positive margin?},
  author={Rajput, Shashank and Feng, Zhili and Charles, Zachary and Loh, Po-Ling and Papailiopoulos, Dimitris},
  booktitle={International Conference on Machine Learning},
  pages={5321--5330},
  year={2019},
  organization={PMLR}
}

@inproceedings{shen2022data,
  title={Data augmentation as feature manipulation},
  author={Shen, Ruoqi and Bubeck, S{\'e}bastien and Gunasekar, Suriya},
  booktitle={International conference on machine learning},
  pages={19773--19808},
  year={2022},
  organization={PMLR}
}

@inproceedings{wen2021toward,
  title={Toward understanding the feature learning process of self-supervised contrastive learning},
  author={Wen, Zixin and Li, Yuanzhi},
  booktitle={International Conference on Machine Learning},
  pages={11112--11122},
  year={2021},
  organization={PMLR}
}

@article{wen2022mechanism,
  title={The mechanism of prediction head in non-contrastive self-supervised learning},
  author={Wen, Zixin and Li, Yuanzhi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24794--24809},
  year={2022}
}

@article{zhang2020does,
  title={How does mixup help with robustness and generalization?},
  author={Zhang, Linjun and Deng, Zhun and Kawaguchi, Kenji and Ghorbani, Amirata and Zou, James},
  journal={arXiv preprint arXiv:2010.04819},
  year={2020}
}

@inproceedings{zou2023benefits,
  title={The benefits of mixup for feature learning},
  author={Zou, Difan and Cao, Yuan and Li, Yuanzhi and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={43423--43479},
  year={2023},
  organization={PMLR}
}

