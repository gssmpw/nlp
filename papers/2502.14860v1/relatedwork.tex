\section{Related Work}
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/mediq_medqa.pdf}\vspace{-3mm}
    \caption{3B Model performance on the interactive MediQ-MedQA task. Models aligned with \methodname are more robust to out-of-distribution data.}
    \label{fig:results:medqa}\vspace{-3mm}
\end{figure}

\paragraph{Clinical Reasoning in LLMs. }

LLMs have the potential to significantly transform medicine by enhancing personalized care and accessibility \citep{shanmugam2024generative}. 
Models trained with medical data contain rich medical knowledge \citep{singhal2025toward,lewis-etal-2020-pretrained,chen2023meditron,labrak2024biomistral,singhal2023large,brin2023comparing}, but are limited in instruction-following and multi-hop reasoning \cite{hager2024evaluation, arroyo2024openclinicalllmssensitive,nov2023putting,zhang2014understanding}.
These models excel in static, medical QA benchmarks \citep{jin2020disease,pal2022medmcqa},
but recent work has moved away from the static single-turn paradigm and highlight \emph{proactive question-asking} as a key capability to reliable and effective clinical reasoning \citep{li2024mediq, hu2024uncertainty}. Our work furthers this direction by providing an evaluation benchmark with real data and the first method to train specialized question-asking models.


Our proposed method relies on synthetic counterfactual data generation \citep{mishra2024llm, ding2024data, park-etal-2024-valuescope} and fine-grained alignment. 
Inspired by prior work on multi-objcetive RLHF \citep{zhou2023beyond,wu2023fine}, we extend PPO \citep{ouyang2022training,christiano2017deep} and DPO \citep{rafailov2023direct} to align models with attribute-specific datasets, and uniquely compare different integration points of the fine-grained preference signals \citep{rame2024rewarded,chronopoulou2023adaptersoup,wang2024interpretable}.