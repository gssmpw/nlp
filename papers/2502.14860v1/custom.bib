@article{ball2015improving,
  title={Improving diagnosis in health care},
  author={Ball, John R and Miller, Bryan T and Balogh, Erin P},
  year={2015},
  publisher={National Academies Press}
}

@article{kurtz1996calgary,
  title={The Calgary—Cambridge Referenced Observation Guides: an aid to defining the curriculum and organizing the teaching in communication training programmes},
  author={Kurtz, Suzanne M and Silverman, Jonathan D},
  journal={Medical education},
  volume={30},
  number={2},
  pages={83--89},
  year={1996},
  publisher={Wiley Online Library}
}

@inproceedings{li2024mediq,
  title={MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive Clinical Reasoning},
  author={Li, Shuyue Stella and Balachandran, Vidhisha and Feng, Shangbin and Ilgen, Jonathan S and Pierson, Emma and Koh, Pang Wei and Tsvetkov, Yulia},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{zhang2024modeling,
  title={Modeling future conversation turns to teach llms to ask clarifying questions},
  author={Zhang, Michael JQ and Knox, W Bradley and Choi, Eunsol},
  journal={arXiv preprint arXiv:2410.13788},
  year={2024}
}

@article{richardson1995well,
  title={The well-built clinical question: a key to evidence-based decisions.},
  author={Richardson, W Scott and Wilson, Mark C and Nishikawa, Jim and Hayward, Robert S},
  journal={ACP journal club},
  volume={123},
  number={3},
  pages={A12--3},
  year={1995}
}
@book{silverman2016skills,
  title={Skills for communicating with patients},
  author={Silverman, Jonathan and Kurtz, Suzanne and Draper, Juliet},
  year={2016},
  publisher={crc press}
}
@article{heritage2010questioning,
  title={Questioning in medicine},
  author={Heritage, John},
  journal={Why do you ask},
  pages={42--68},
  year={2010}
}
@misc{hall1995doctors,
  title={Doctors talking with patients—patients talking with doctors: improving communication in medical visits},
  author={Hall, JA and Roter, DL and Junghans, Barbara},
  year={1995},
  publisher={Taylor \& Francis}
}
@article{west1984routine,
  title={Routine complications: Troubles with talk between doctors and patients},
  author={West, Candace},
  year={1984}
}
@article{stivers2007questioning,
  title={Questioning children: Interactional evidence of implicit bias in medical interviews},
  author={Stivers, Tanya and Majid, Asifa},
  journal={Social Psychology Quarterly},
  volume={70},
  number={4},
  pages={424--441},
  year={2007},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
@article{ong1995doctor,
  title={Doctor-patient communication: a review of the literature},
  author={Ong, Lucille ML and De Haes, Johanna CJM and Hoos, Alaysia M and Lammes, Frits B},
  journal={Social science \& medicine},
  volume={40},
  number={7},
  pages={903--918},
  year={1995},
  publisher={Elsevier}
}

@inproceedings{kaufmann2023challenges,
  title={On the Challenges and Practices of Reinforcement Learning from Real Human Feedback},
  author={Kaufmann, Timo and Ball, Sarah and Beck, Jacob and H{\"u}llermeier, Eyke and Kreuter, Frauke},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={276--294},
  year={2023},
  organization={Springer}
}

@misc{alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  month = {5},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@misc{dubois2023alpacafarm,
  title={AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback}, 
  author={Yann Dubois and Xuechen Li and Rohan Taori and Tianyi Zhang and Ishaan Gulrajani and Jimmy Ba and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
  year={2023},
  eprint={2305.14387},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@article{johri2025evaluation,
  title={An evaluation framework for clinical use of large language models in patient interaction tasks},
  author={Johri, Shreya and Jeong, Jaehwan and Tran, Benjamin A and Schlessinger, Daniel I and Wongvibulsin, Shannon and Barnes, Leandra A and Zhou, Hong-Yu and Cai, Zhuo Ran and Van Allen, Eliezer M and Kim, David and others},
  journal={Nature Medicine},
  pages={1--10},
  year={2025},
  publisher={Nature Publishing Group US New York}
}

@book{heritage2006communication,
  title     = {Communication in Medical Care: Interactions between Primary Care Physicians and Patients},
  editor    = {Heritage, John and Maynard, Douglas W.},
  publisher = {Cambridge University Press},
  address   = {Cambridge, UK},
  year      = {2006}
}

@article{roterHall1987,
  title   = {Studies of doctor-patient interaction},
  author  = {Roter, Debra L. and Hall, Judith A.},
  journal = {Annual Review of Public Health},
  volume  = {8},
  pages   = {163--180},
  year    = {1987},
  doi     = {10.1146/annurev.pu.08.050187.001115}
}

@article{chouinard2007,
  title   = {Children’s Questions: A Mechanism for Cognitive Development},
  author  = {Chouinard, Michelle M.},
  journal = {Monographs of the Society for Research in Child Development},
  volume  = {72},
  number  = {1},
  pages   = {1--112},
  year    = {2007},
  doi     = {10.1111/j.1540-5834.2007.00412.x}
}

@article{freed1994form,
  title   = {The Form and Function of Questions in Informal Dyadic Conversation},
  author  = {Freed, Alice F.},
  journal = {Journal of Pragmatics},
  volume  = {21},
  number  = {6},
  pages   = {621--644},
  year    = {1994},
  doi     = {10.1016/0378-2166(94)90100-7}
}

@book{searle1969speech,
  title     = {Speech Acts: An Essay in the Philosophy of Language},
  author    = {Searle, John R.},
  publisher = {Cambridge University Press},
  address   = {Cambridge, UK},
  year      = {1969}
}

@article{jin2021disease,
  title={What disease does this patient have? a large-scale open domain question answering dataset from medical exams},
  author={Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},
  journal={Applied Sciences},
  volume={11},
  number={14},
  pages={6421},
  year={2021},
  publisher={MDPI}
}

@article{ram1991theory,
  title={A theory of questions and question asking},
  author={Ram, Ashwin},
  journal={Journal of the Learning Sciences},
  volume={1},
  number={3-4},
  pages={273--318},
  year={1991},
  publisher={Taylor \& Francis}
}

@article{ruggeri2015children,
  title={Children adapt their questions to achieve efficient search},
  author={Ruggeri, Azzurra and Lombrozo, Tania},
  journal={Cognition},
  volume={143},
  pages={203--216},
  year={2015},
  publisher={Elsevier}
}

@incollection{levinson2012interrogative,
  title={Interrogative intimations: On a possible social economics of interrogatives},
  author={Levinson, Stephen C},
  booktitle={Questions: Formal, functional and interactional perspectives},
  pages={11--32},
  year={2012},
  publisher={Cambridge University Press}
}

@article{keil2008discerning,
  title={Discerning the division of cognitive labor: An emerging understanding of how knowledge is clustered in other minds},
  author={Keil, Frank C and Stein, Courtney and Webb, Lisa and Billings, Van Dyke and Rozenblit, Leonid},
  journal={Cognitive science},
  volume={32},
  number={2},
  pages={259--300},
  year={2008},
  publisher={Wiley Online Library}
}

@article{ronfard2018question,
  title={Question-asking in childhood: A review of the literature and a framework for understanding its development},
  author={Ronfard, Samuel and Zambrana, Imac M and Hermansen, Tone K and Kelemen, Deborah},
  journal={Developmental Review},
  volume={49},
  pages={101--120},
  year={2018},
  publisher={Elsevier}
}

@article{gopnik2012reconstructing,
  title={Reconstructing constructivism: causal models, Bayesian learning mechanisms, and the theory theory.},
  author={Gopnik, Alison and Wellman, Henry M},
  journal={Psychological bulletin},
  volume={138},
  number={6},
  pages={1085},
  year={2012},
  publisher={American Psychological Association}
}

@article{hu2024openrlhf,
  title={OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework},
  author={Jian Hu and Xibin Wu and Zilin Zhu and Xianyu and Weixun Wang and Dehao Zhang and Yu Cao},
  journal={arXiv preprint arXiv:2405.11143},
  year={2024}
}

@article{rodriguez2024leveraging,
  title={Leveraging large language models to foster equity in healthcare},
  author={Rodriguez, Jorge A and Alsentzer, Emily and Bates, David W},
  journal={Journal of the American Medical Informatics Association},
  pages={ocae055},
  year={2024},
  publisher={Oxford University Press}
}

@article{moor2023foundation,
  title={Foundation models for generalist medical artificial intelligence},
  author={Moor, Michael and Banerjee, Oishi and Abad, Zahra Shakeri Hossein and Krumholz, Harlan M and Leskovec, Jure and Topol, Eric J and Rajpurkar, Pranav},
  journal={Nature},
  volume={616},
  number={7956},
  pages={259--265},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{thirunavukarasu2023large,
  title={Large language models in medicine},
  author={Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
  journal={Nature medicine},
  volume={29},
  number={8},
  pages={1930--1940},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@article{singhal2025toward,
  title={Toward expert-level medical question answering with large language models},
  author={Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Amin, Mohamed and Hou, Le and Clark, Kevin and Pfohl, Stephen R and Cole-Lewis, Heather and others},
  journal={Nature Medicine},
  pages={1--8},
  year={2025},
  publisher={Nature Publishing Group US New York}
}

@article{singhal2023large,
  title={Large language models encode clinical knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={172--180},
  year={2023},
  publisher={Nature Publishing Group}
}

@article{xie2024preliminary,
  title={A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?},
  author={Xie, Yunfei and Wu, Juncheng and Tu, Haoqin and Yang, Siwei and Zhao, Bingchen and Zong, Yongshuo and Jin, Qiao and Xie, Cihang and Zhou, Yuyin},
  journal={arXiv preprint arXiv:2409.15277},
  year={2024}
}

@article{jeong2024limited,
  title={The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models},
  author={Jeong, Daniel P and Mani, Pranav and Garg, Saurabh and Lipton, Zachary C and Oberst, Michael},
  journal={arXiv preprint arXiv:2411.08870},
  year={2024}
}

@article{brin2023comparing,
  title={Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments},
  author={Brin, Dana and Sorin, Vera and Vaid, Akhil and Soroush, Ali and Glicksberg, Benjamin S and Charney, Alexander W and Nadkarni, Girish and Klang, Eyal},
  journal={Scientific Reports},
  volume={13},
  number={1},
  pages={16492},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{labrak2024biomistral,
  title={Biomistral: A collection of open-source pretrained large language models for medical domains},
  author={Labrak, Yanis and Bazoge, Adrien and Morin, Emmanuel and Gourraud, Pierre-Antoine and Rouvier, Mickael and Dufour, Richard},
  journal={arXiv preprint arXiv:2402.10373},
  year={2024}
}

@article{toma2023clinical,
  title={Clinical camel: An open expert-level medical language model with dialogue-based knowledge encoding},
  author={Toma, Augustin and Lawler, Patrick R and Ba, Jimmy and Krishnan, Rahul G and Rubin, Barry B and Wang, Bo},
  journal={arXiv preprint arXiv:2305.12031},
  year={2023}
}

@article{chen2023meditron,
  title={Meditron-70b: Scaling medical pretraining for large language models},
  author={Chen, Zeming and Cano, Alejandro Hern{\'a}ndez and Romanou, Angelika and Bonnet, Antoine and Matoba, Kyle and Salvi, Francesco and Pagliardini, Matteo and Fan, Simin and K{\"o}pf, Andreas and Mohtashami, Amirkeivan and others},
  journal={arXiv preprint arXiv:2311.16079},
  year={2023}
}

@article{zhou2023survey,
  title={A survey of large language models in medicine: Progress, application, and challenge},
  author={Zhou, Hongjian and Liu, Fenglin and Gu, Boyang and Zou, Xinyu and Huang, Jinfa and Wu, Jinge and Li, Yiru and Chen, Sam S and Zhou, Peilin and Liu, Junling and others},
  journal={arXiv preprint arXiv:2311.05112},
  year={2023}
}

@article{jin2020disease,
  title={What disease does this patient have},
  author={Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},
  journal={A Large-scale Open Domain Question Answering Dataset from Medical Exams. arXiv [cs. CL]},
  year={2020}
}

@article{august2023paper,
  title={Paper plain: Making medical research papers approachable to healthcare consumers with natural language processing},
  author={August, Tal and Wang, Lucy Lu and Bragg, Jonathan and Hearst, Marti A and Head, Andrew and Lo, Kyle},
  journal={ACM Transactions on Computer-Human Interaction},
  volume={30},
  number={5},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@article{nov2023putting,
  title={Putting ChatGPT’s medical advice to the (Turing) test: survey study},
  author={Nov, Oded and Singh, Nina and Mann, Devin},
  journal={JMIR Medical Education},
  volume={9},
  pages={e46939},
  year={2023},
  publisher={JMIR Publications Toronto, Canada}
}

@inproceedings{zhang2014understanding,
  title={Understanding user intents in online health forums},
  author={Zhang, Thomas and Cho, Jason HD and Zhai, Chengxiang},
  booktitle={Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
  pages={220--229},
  year={2014}
}

@inproceedings{shaikh2024grounding,
  title={Grounding Gaps in Language Model Generations},
  author={Shaikh, Omar and Gligori{\'c}, Kristina and Khetan, Ashna and Gerstgrasser, Matthias and Yang, Diyi and Jurafsky, Dan},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={6279--6296},
  year={2024}
}

@article{wu2023fine,
  title={Fine-grained human feedback gives better rewards for language model training},
  author={Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={59008--59033},
  year={2023}
}

@article{rame2024rewarded,
  title={Rewarded soups: towards pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards},
  author={Rame, Alexandre and Couairon, Guillaume and Dancette, Corentin and Gaya, Jean-Baptiste and Shukor, Mustafa and Soulier, Laure and Cord, Matthieu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shi2024decoding,
  title={Decoding-time language model alignment with multiple objectives},
  author={Shi, Ruizhe and Chen, Yifang and Hu, Yushi and Liu, Alisa and Hajishirzi, Hannaneh and Smith, Noah A and Du, Simon S},
  journal={arXiv preprint arXiv:2406.18853},
  year={2024}
}

@article{hu2024uncertainty,
  title={Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models},
  author={Hu, Zhiyuan and Liu, Chumin and Feng, Xidong and Zhao, Yilun and Ng, See-Kiong and Luu, Anh Tuan and He, Junxian and Koh, Pang Wei and Hooi, Bryan},
  journal={arXiv preprint arXiv:2402.03271},
  year={2024}
}

@article{andukuri2024star,
  title={Star-gate: Teaching language models to ask clarifying questions},
  author={Andukuri, Chinmaya and Fr{\"a}nken, Jan-Philipp and Gerstenberg, Tobias and Goodman, Noah D},
  journal={arXiv preprint arXiv:2403.19154},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={53728--53741},
  year={2023}
}

@article{zhou2023beyond,
  title={Beyond one-preference-for-all: Multi-objective direct preference optimization},
  author={Zhou, Zhanhui and Liu, Jie and Yang, Chao and Shao, Jing and Liu, Yu and Yue, Xiangyu and Ouyang, Wanli and Qiao, Yu},
  journal={arXiv preprint arXiv:2310.03708},
  year={2023}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{chronopoulou2023adaptersoup,
  title={Adaptersoup: Weight averaging to improve generalization of pretrained language models},
  author={Chronopoulou, Alexandra and Peters, Matthew E and Fraser, Alexander and Dodge, Jesse},
  journal={arXiv preprint arXiv:2302.07027},
  year={2023}
}

@article{rame2024warm,
  title={Warm: On the benefits of weight averaged reward models},
  author={Ram{\'e}, Alexandre and Vieillard, Nino and Hussenot, L{\'e}onard and Dadashi, Robert and Cideron, Geoffrey and Bachem, Olivier and Ferret, Johan},
  journal={arXiv preprint arXiv:2401.12187},
  year={2024}
}

@article{jang2023personalized,
  title={Personalized soups: Personalized large language model alignment via post-hoc parameter merging},
  author={Jang, Joel and Kim, Seungone and Lin, Bill Yuchen and Wang, Yizhong and Hessel, Jack and Zettlemoyer, Luke and Hajishirzi, Hannaneh and Choi, Yejin and Ammanabrolu, Prithviraj},
  journal={arXiv preprint arXiv:2310.11564},
  year={2023}
}

@article{kim2024evaluating,
  title={Evaluating Language Models as Synthetic Data Generators},
  author={Kim, Seungone and Suk, Juyoung and Yue, Xiang and Viswanathan, Vijay and Lee, Seongyun and Wang, Yizhong and Gashteovski, Kiril and Lawrence, Carolin and Welleck, Sean and Neubig, Graham},
  journal={arXiv preprint arXiv:2412.03679},
  year={2024}
}

@article{long2024llms,
  title={On llms-driven synthetic data generation, curation, and evaluation: A survey},
  author={Long, Lin and Wang, Rui and Xiao, Ruixuan and Zhao, Junbo and Ding, Xiao and Chen, Gang and Wang, Haobo},
  journal={arXiv preprint arXiv:2406.15126},
  year={2024}
}

@inproceedings{xu2024wizardlm,
  title={WizardLM: Empowering large pre-trained language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Lin, Qingwei and Jiang, Daxin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{murtaza2023synthetic,
  title={Synthetic data generation: State of the art in health care domain},
  author={Murtaza, Hajra and Ahmed, Musharif and Khan, Naurin Farooq and Murtaza, Ghulam and Zafar, Saad and Bano, Ambreen},
  journal={Computer Science Review},
  volume={48},
  pages={100546},
  year={2023},
  publisher={Elsevier}
}

@article{fansi2022ddxplus,
  title={Ddxplus: A new dataset for automatic medical diagnosis},
  author={Fansi Tchango, Arsene and Goel, Rishab and Wen, Zhi and Martel, Julien and Ghosn, Joumana},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={31306--31318},
  year={2022}
}

@inproceedings{oh2024use,
  title={How to use Language Models for Synthetic Text Generation in Cerebrovascular Disease-specific Medical Reports},
  author={Oh, Byoung-Doo and Kim, Gi-Youn and Kim, Chulho and Kim, Yu-Seop},
  booktitle={Proceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024)},
  pages={10--17},
  year={2024}
}

@article{mishra2024synfac,
  title={SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization},
  author={Mishra, Prakamya and Yao, Zonghai and Vashisht, Parth and Ouyang, Feiyun and Wang, Beining and Mody, Vidhi Dhaval and Yu, Hong},
  journal={arXiv preprint arXiv:2402.13919},
  year={2024}
}

@article{yao2024mcqg,
  title={MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback},
  author={Yao, Zonghai and Parashar, Aditya and Zhou, Huixue and Jang, Won Seok and Ouyang, Feiyun and Yang, Zhichao and Yu, Hong},
  journal={arXiv preprint arXiv:2410.13191},
  year={2024}
}

@inproceedings{wang-etal-2024-notechat,
    title = "{N}ote{C}hat: A Dataset of Synthetic Patient-Physician Conversations Conditioned on Clinical Notes",
    author = "Wang, Junda  and
      Yao, Zonghai  and
      Yang, Zhichao  and
      Zhou, Huixue  and
      Li, Rumeng  and
      Wang, Xun  and
      Xu, Yucheng  and
      Yu, Hong",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.901/",
    doi = "10.18653/v1/2024.findings-acl.901",
    pages = "15183--15201",
    abstract = "We introduce NoteChat, a novel cooperative multi-agent framework leveraging Large Language Models (LLMs) to generate patient-physician dialogues. NoteChat embodies the principle that an ensemble of role-specific LLMs, through structured role-play and strategic prompting, can perform their assigned roles more effectively. The synergy among these role-playing LLMs results in a cohesive and efficient dialogue generation. Evaluation on MTS-dialogue, a benchmark dataset for patient-physician dialogues-note pairs, shows that models trained with the augmented synthetic patient-physician dialogues by NoteChat outperforms other state-of-the-art models for generating clinical notes. Our comprehensive automatic and human evaluation demonstrates that NoteChat substantially surpasses state-of-the-art models like ChatGPT and GPT-4 up to 22.78{\%} by domain experts in generating superior synthetic patient-physician dialogues based on clinical notes. NoteChat has the potential to engage patients directly and help clinical documentation, a leading cause of physician burnout."
}


@article{wang2024helpsteer2,
  title={HelpSteer2: Open-source dataset for training top-performing reward models},
  author={Wang, Zhilin and Dong, Yi and Delalleau, Olivier and Zeng, Jiaqi and Shen, Gerald and Egert, Daniel and Zhang, Jimmy J and Sreedhar, Makesh Narsimhan and Kuchaiev, Oleksii},
  journal={arXiv preprint arXiv:2406.08673},
  year={2024}
}


@InProceedings{pal2022medmcqa,
  title = 	 {MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},
  author =       {Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle = 	 {Proceedings of the Conference on Health, Inference, and Learning},
  pages = 	 {248--260},
  year = 	 {2022},
  editor = 	 {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
  volume = 	 {174},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07--08 Apr},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v174/pal22a/pal22a.pdf},
  url = 	 {https://proceedings.mlr.press/v174/pal22a.html},
  abstract = 	 {This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions. More than 194k high-quality AIIMS &amp; NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity. Each sample contains a question, correct answer(s), and other options which requires a deeper language understanding as it tests the 10+ reasoning abilities of a model across a wide range of medical subjects &amp; topics. A detailed explanation of the solution, along with the above information, is provided in this study.}
}

@misc{jin2019pubmedqadatasetbiomedicalresearch,
      title={PubMedQA: A Dataset for Biomedical Research Question Answering}, 
      author={Qiao Jin and Bhuwan Dhingra and Zhengping Liu and William W. Cohen and Xinghua Lu},
      year={2019},
      eprint={1909.06146},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1909.06146}, 
}

@misc{kanithi2024mediccomprehensiveframeworkevaluating,
      title={MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications}, 
      author={Praveen K Kanithi and Clément Christophe and Marco AF Pimentel and Tathagata Raha and Nada Saadi and Hamza Javed and Svetlana Maslenkova and Nasir Hayat and Ronnie Rajan and Shadab Khan},
      year={2024},
      eprint={2409.07314},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.07314}, 
}

@inproceedings{rawat-etal-2024-diversitymedqa,
    title = "{D}iversity{M}ed{QA}: A Benchmark for Assessing Demographic Biases in Medical Diagnosis using Large Language Models",
    author = "Rawat, Rajat  and
      McBride, Hudson  and
      Ghosh, Rajarshi  and
      Nirmal, Dhiyaan  and
      Moon, Jong  and
      Alamuri, Dhruv  and
      O'Brien, Sean  and
      Zhu, Kevin",
    editor = "Dementieva, Daryna  and
      Ignat, Oana  and
      Jin, Zhijing  and
      Mihalcea, Rada  and
      Piatti, Giorgio  and
      Tetreault, Joel  and
      Wilson, Steven  and
      Zhao, Jieyu",
    booktitle = "Proceedings of the Third Workshop on NLP for Positive Impact",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.nlp4pi-1.29/",
    doi = "10.18653/v1/2024.nlp4pi-1.29",
    pages = "334--348",
    abstract = "As large language models (LLMs) gain traction in healthcare, concerns about their susceptibility to demographic biases are growing. We introduce DiversityMedQA, a novel benchmark designed to assess LLM responses to medical queries across diverse patient demographics, such as gender and ethnicity. By perturbing questions from the MedQA dataset, which comprises of medical board exam questions, we created a benchmark that captures the nuanced differences in medical diagnosis across varying patient profiles. To ensure that our perturbations did not alter the clinical outcomes, we implemented a filtering strategy to validate each perturbation, so that any performance discrepancies would be indicative of bias. Our findings reveal notable discrepancies in model performance when tested against these demographic variations. By releasing DiversityMedQA, we provide a resource for evaluating and mitigating demographic bias in LLM medical diagnoses."
}

@inproceedings{zheng2023llmasajudge,
 author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and Zhang, Hao and Gonzalez, Joseph E and Stoica, Ion},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {46595--46623},
 publisher = {Curran Associates, Inc.},
 title = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf},
 volume = {36},
 year = {2023}
}

@misc{yao2025mcqgsrefinemultiplechoicequestion,
      title={MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback}, 
      author={Zonghai Yao and Aditya Parashar and Huixue Zhou and Won Seok Jang and Feiyun Ouyang and Zhichao Yang and Hong Yu},
      year={2025},
      eprint={2410.13191},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.13191}, 
}


@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@article{rencic2011twelve,
  title={Twelve tips for teaching expertise in clinical reasoning},
  author={Rencic, Joseph},
  journal={Medical teacher},
  volume={33},
  number={11},
  pages={887--892},
  year={2011},
  publisher={Taylor \& Francis}
}

@misc{zhu2025askpatientspatienceenabling,
      title={Ask Patients with Patience: Enabling LLMs for Human-Centric Medical Dialogue with Grounded Reasoning}, 
      author={Jiayuan Zhu and Junde Wu},
      year={2025},
      eprint={2502.07143},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.07143}, 
}

@article{hager2024evaluation,
  title={Evaluation and mitigation of the limitations of large language models in clinical decision-making},
  author={Hager, Paul and Jungmann, Friederike and Holland, Robbie and Bhagat, Kunal and Hubrecht, Inga and Knauer, Manuel and Vielhauer, Jakob and Makowski, Marcus and Braren, Rickmer and Kaissis, Georgios and others},
  journal={Nature medicine},
  volume={30},
  number={9},
  pages={2613--2622},
  year={2024},
  publisher={Nature Publishing Group US New York}
}

@misc{arroyo2024openclinicalllmssensitive,
      title={Open (Clinical) LLMs are Sensitive to Instruction Phrasings}, 
      author={Alberto Mario Ceballos Arroyo and Monica Munnangi and Jiuding Sun and Karen Y. C. Zhang and Denis Jered McInerney and Byron C. Wallace and Silvio Amir},
      year={2024},
      eprint={2407.09429},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.09429}, 
}

@inproceedings{mishra2024llm,
  title={LLM-Guided Counterfactual Data Generation for Fairer AI},
  author={Mishra, Ashish and Nayak, Gyanaranjan and Bhattacharya, Suparna and Kumar, Tarun and Shah, Arpit and Foltin, Martin},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={1538--1545},
  year={2024}
}

@inproceedings{ding2024data,
  title={Data augmentation using llms: Data perspectives, learning paradigms and challenges},
  author={Ding, Bosheng and Qin, Chengwei and Zhao, Ruochen and Luo, Tianze and Li, Xinze and Chen, Guizhen and Xia, Wenhan and Hu, Junjie and Tuan, Luu Anh and Joty, Shafiq},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={1679--1705},
  year={2024}
}

@inproceedings{park-etal-2024-valuescope,
    title = "{V}alue{S}cope: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions",
    author = "Park, Chan Young  and
      Li, Shuyue Stella  and
      Jung, Hayoung  and
      Volkova, Svitlana  and
      Mitra, Tanu  and
      Jurgens, David  and
      Tsvetkov, Yulia",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.972/",
    doi = "10.18653/v1/2024.findings-emnlp.972",
    pages = "16659--16695",
    abstract = "This study introduces ValueScope, a framework leveraging language models to quantify social norms and values within online communities, grounded in social science perspectives on normative structures. We employ ValueScope to dissect and analyze linguistic and stylistic expressions across 13 Reddit communities categorized under gender, politics, science, and finance. Our analysis provides a quantitative foundation confirming that even closely related communities exhibit remarkably diverse norms. This diversity supports existing theories and adds a new dimension to understanding community interactions. ValueScope not only delineates differences in social norms but also effectively tracks their evolution and the influence of significant external events like the U.S. presidential elections and the emergence of new sub-communities. The framework thus highlights the pivotal role of social norms in shaping online interactions, presenting a substantial advance in both the theory and application of social norm studies in digital spaces."
}

@article{shanmugam2024generative,
  title={Generative ai in medicine},
  author={Shanmugam, Divya and Agrawal, Monica and Movva, Rajiv and Chen, Irene Y and Ghassemi, Marzyeh and Pierson, Emma},
  journal={arXiv preprint arXiv:2412.10337},
  year={2024}
}

@inproceedings{fung-etal-2024-agenda,
    title = "Agenda-Driven Question Generation: A Case Study in the Courtroom Domain",
    author = "Fung, Yi  and
      Kumar, Anoop  and
      Galstyan, Aram  and
      Ji, Heng  and
      Natarajan, Prem",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.49/",
    pages = "572--583",
    abstract = "This paper introduces a novel problem of automated question generation for courtroom examinations, CourtQG. While question generation has been studied in domains such as educational testing and product description, CourtQG poses several unique challenges owing to its non-cooperative and agenda-driven nature. Specifically, not only the generated questions need to be relevant to the case and underlying context, they also have to achieve certain objectives such as challenging the opponent`s arguments and/or revealing potential inconsistencies in their answers. We propose to leverage large language models (LLM) for CourtQG by fine-tuning them on two auxiliary tasks, agenda explanation (i.e., uncovering the underlying intents) and question type prediction. We additionally propose cold-start generation of questions from background documents without relying on examination history. We construct a dataset to evaluate our proposed method and show that it generates better questions according to standard metrics when compared to several baselines."
}

@inproceedings{deng2024towards,
  title={Towards human-centered proactive conversational agents},
  author={Deng, Yang and Liao, Lizi and Zheng, Zhonghua and Yang, Grace Hui and Chua, Tat-Seng},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={807--818},
  year={2024}
}

@article{ellis2000evidence,
  title={An evidence-based medicine curriculum for medical students: the art of asking focused clinical questions},
  author={Ellis, PETER and Green, MICHAEL and Kernan, WALTER},
  journal={Academic Medicine},
  volume={75},
  number={5},
  pages={528},
  year={2000},
  publisher={LWW}
}

@article{allen2023asking,
  title={Asking Patient Focused Clinical Questions},
  author={Allen, Carla M},
  journal={Evidence-Based Practice for Clinical and Diagnostic Professionals},
  year={2023},
  publisher={University of Missouri}
}

@inproceedings{proffit2013evidence,
  title={Evidence and clinical decisions: asking the right questions to obtain clinically useful answers},
  author={Proffit, William R},
  booktitle={Seminars in orthodontics},
  volume={19},
  number={3},
  pages={130--136},
  year={2013},
  organization={Elsevier}
}

@article{wang2024interpretable,
  title={Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts},
  author={Wang, Haoxiang and Xiong, Wei and Xie, Tengyang and Zhao, Han and Zhang, Tong},
  journal={arXiv preprint arXiv:2406.12845},
  year={2024}
}

@misc{yang2025mixdatamergemodels,
      title={Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging}, 
      author={Jinluan Yang and Dingnan Jin and Anke Tang and Li Shen and Didi Zhu and Zhengyu Chen and Daixin Wang and Qing Cui and Zhiqiang Zhang and Jun Zhou and Fei Wu and Kun Kuang},
      year={2025},
      eprint={2502.06876},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.06876}, 
}

@article{lambert2024t,
  title={T$\backslash$" ulu 3: Pushing frontiers in open language model post-training},
  author={Lambert, Nathan and Morrison, Jacob and Pyatkin, Valentina and Huang, Shengyi and Ivison, Hamish and Brahman, Faeze and Miranda, Lester James V and Liu, Alisa and Dziri, Nouha and Lyu, Shane and others},
  journal={arXiv preprint arXiv:2411.15124},
  year={2024}
}

@article{wang2023far,
  title={How far can camels go? exploring the state of instruction tuning on open resources},
  author={Wang, Yizhong and Ivison, Hamish and Dasigi, Pradeep and Hessel, Jack and Khot, Tushar and Chandu, Khyathi and Wadden, David and MacMillan, Kelsey and Smith, Noah A and Beltagy, Iz and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={74764--74786},
  year={2023}
}

@article{wongpakaran2013gwets,
  author    = {Wongpakaran, Nahathai and Wongpakaran, Tinakon and Wedding, Danny and others},
  title     = {A comparison of Cohen’s Kappa and Gwet’s AC1 when calculating inter-rater reliability coefficients: a study conducted with personality disorder samples},
  journal   = {BMC Medical Research Methodology},
  volume    = {13},
  pages     = {61},
  year      = {2013},
  doi       = {10.1186/1471-2288-13-61},
  url       = {https://doi.org/10.1186/1471-2288-13-61}
}

@misc{ramesh2024evaluatingdifferentiallyprivatesynthetic,
      title={Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains}, 
      author={Krithika Ramesh and Nupoor Gandhi and Pulkit Madaan and Lisa Bauer and Charith Peris and Anjalie Field},
      year={2024},
      eprint={2410.08327},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.08327}, 
}

@misc{mireshghallah2023privacypreservingdomainadaptationsemantic,
      title={Privacy-Preserving Domain Adaptation of Semantic Parsers}, 
      author={Fatemehsadat Mireshghallah and Yu Su and Tatsunori Hashimoto and Jason Eisner and Richard Shin},
      year={2023},
      eprint={2212.10520},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.10520}, 
}

@inproceedings{ding2022whose,
author = {Wang, Ding and Prabhat, Shantanu and Sambasivan, Nithya},
title = {Whose AI Dream? In search of the aspiration in data annotation.},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502121},
doi = {10.1145/3491102.3502121},
abstract = {Data is fundamental to AI/ML models. This paper investigates the work practices concerning data annotation as performed in the industry, in India. Previous human-centred investigations have largely focused on annotators’ subjectivity, bias and efficiency. We present a wider perspective of the data annotation: following a grounded approach, we conducted three sets of interviews with 25 annotators, 10 industry experts and 12 ML/AI practitioners. Our results show that the work of annotators is dictated by the interests, priorities and values of others above their station. More than technical, we contend that data annotation is a systematic exercise of power through organizational structure and practice. We propose a set of implications for how we can cultivate and encourage better practice to balance the tension between the need for high quality data at low cost and the annotators’ aspiration for well-being, career perspective, and active participation in building the AI dream.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {582},
numpages = {16},
keywords = {AI labour, data annotation, future of work, qualitative study},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@misc{zhang2024divergingpreferencesannotatorsdisagree,
      title={Diverging Preferences: When do Annotators Disagree and do Models Know?}, 
      author={Michael JQ Zhang and Zhilin Wang and Jena D. Hwang and Yi Dong and Olivier Delalleau and Yejin Choi and Eunsol Choi and Xiang Ren and Valentina Pyatkin},
      year={2024},
      eprint={2410.14632},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.14632}, 
}

@misc{wang2024healthqunveilingquestioningcapabilities,
      title={HealthQ: Unveiling Questioning Capabilities of LLM Chains in Healthcare Conversations}, 
      author={Ziyu Wang and Hao Li and Di Huang and Amir M. Rahmani},
      year={2024},
      eprint={2409.19487},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.19487}, 
}

@inproceedings{xin2024false,
  title={A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage},
  author={Xin, Rui and Mireshghallah, Niloofar and Li, Shuyue Stella and Duan, Michael and Kim, Hyunwoo and Choi, Yejin and Tsvetkov, Yulia and Oh, Sewoong and Koh, Pang Wei},
  booktitle={Neurips Safe Generative AI Workshop 2024}
}