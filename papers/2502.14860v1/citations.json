[
  {
    "index": 0,
    "papers": [
      {
        "key": "shanmugam2024generative",
        "author": "Shanmugam, Divya and Agrawal, Monica and Movva, Rajiv and Chen, Irene Y and Ghassemi, Marzyeh and Pierson, Emma",
        "title": "Generative ai in medicine"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "singhal2025toward",
        "author": "Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Amin, Mohamed and Hou, Le and Clark, Kevin and Pfohl, Stephen R and Cole-Lewis, Heather and others",
        "title": "Toward expert-level medical question answering with large language models"
      },
      {
        "key": "lewis-etal-2020-pretrained",
        "author": "Lewis, Patrick  and\nOtt, Myle  and\nDu, Jingfei  and\nStoyanov, Veselin",
        "title": "Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art"
      },
      {
        "key": "chen2023meditron",
        "author": "Chen, Zeming and Cano, Alejandro Hern{\\'a}ndez and Romanou, Angelika and Bonnet, Antoine and Matoba, Kyle and Salvi, Francesco and Pagliardini, Matteo and Fan, Simin and K{\\\"o}pf, Andreas and Mohtashami, Amirkeivan and others",
        "title": "Meditron-70b: Scaling medical pretraining for large language models"
      },
      {
        "key": "labrak2024biomistral",
        "author": "Labrak, Yanis and Bazoge, Adrien and Morin, Emmanuel and Gourraud, Pierre-Antoine and Rouvier, Mickael and Dufour, Richard",
        "title": "Biomistral: A collection of open-source pretrained large language models for medical domains"
      },
      {
        "key": "singhal2023large",
        "author": "Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others",
        "title": "Large language models encode clinical knowledge"
      },
      {
        "key": "brin2023comparing",
        "author": "Brin, Dana and Sorin, Vera and Vaid, Akhil and Soroush, Ali and Glicksberg, Benjamin S and Charney, Alexander W and Nadkarni, Girish and Klang, Eyal",
        "title": "Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "hager2024evaluation",
        "author": "Hager, Paul and Jungmann, Friederike and Holland, Robbie and Bhagat, Kunal and Hubrecht, Inga and Knauer, Manuel and Vielhauer, Jakob and Makowski, Marcus and Braren, Rickmer and Kaissis, Georgios and others",
        "title": "Evaluation and mitigation of the limitations of large language models in clinical decision-making"
      },
      {
        "key": "arroyo2024openclinicalllmssensitive",
        "author": "Alberto Mario Ceballos Arroyo and Monica Munnangi and Jiuding Sun and Karen Y. C. Zhang and Denis Jered McInerney and Byron C. Wallace and Silvio Amir",
        "title": "Open (Clinical) LLMs are Sensitive to Instruction Phrasings"
      },
      {
        "key": "nov2023putting",
        "author": "Nov, Oded and Singh, Nina and Mann, Devin",
        "title": "Putting ChatGPT\u2019s medical advice to the (Turing) test: survey study"
      },
      {
        "key": "zhang2014understanding",
        "author": "Zhang, Thomas and Cho, Jason HD and Zhai, Chengxiang",
        "title": "Understanding user intents in online health forums"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "jin2020disease",
        "author": "Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter",
        "title": "What disease does this patient have"
      },
      {
        "key": "pal2022medmcqa",
        "author": "Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan",
        "title": "MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "li2024mediq",
        "author": "Li, Shuyue Stella and Balachandran, Vidhisha and Feng, Shangbin and Ilgen, Jonathan S and Pierson, Emma and Koh, Pang Wei and Tsvetkov, Yulia",
        "title": "MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive Clinical Reasoning"
      },
      {
        "key": "hu2024uncertainty",
        "author": "Hu, Zhiyuan and Liu, Chumin and Feng, Xidong and Zhao, Yilun and Ng, See-Kiong and Luu, Anh Tuan and He, Junxian and Koh, Pang Wei and Hooi, Bryan",
        "title": "Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "mishra2024llm",
        "author": "Mishra, Ashish and Nayak, Gyanaranjan and Bhattacharya, Suparna and Kumar, Tarun and Shah, Arpit and Foltin, Martin",
        "title": "LLM-Guided Counterfactual Data Generation for Fairer AI"
      },
      {
        "key": "ding2024data",
        "author": "Ding, Bosheng and Qin, Chengwei and Zhao, Ruochen and Luo, Tianze and Li, Xinze and Chen, Guizhen and Xia, Wenhan and Hu, Junjie and Tuan, Luu Anh and Joty, Shafiq",
        "title": "Data augmentation using llms: Data perspectives, learning paradigms and challenges"
      },
      {
        "key": "park-etal-2024-valuescope",
        "author": "Park, Chan Young  and\nLi, Shuyue Stella  and\nJung, Hayoung  and\nVolkova, Svitlana  and\nMitra, Tanu  and\nJurgens, David  and\nTsvetkov, Yulia",
        "title": "{V}alue{S}cope: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "zhou2023beyond",
        "author": "Zhou, Zhanhui and Liu, Jie and Yang, Chao and Shao, Jing and Liu, Yu and Yue, Xiangyu and Ouyang, Wanli and Qiao, Yu",
        "title": "Beyond one-preference-for-all: Multi-objective direct preference optimization"
      },
      {
        "key": "wu2023fine",
        "author": "Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh",
        "title": "Fine-grained human feedback gives better rewards for language model training"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "christiano2017deep",
        "author": "Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario",
        "title": "Deep reinforcement learning from human preferences"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "rafailov2023direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "rame2024rewarded",
        "author": "Rame, Alexandre and Couairon, Guillaume and Dancette, Corentin and Gaya, Jean-Baptiste and Shukor, Mustafa and Soulier, Laure and Cord, Matthieu",
        "title": "Rewarded soups: towards pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards"
      },
      {
        "key": "chronopoulou2023adaptersoup",
        "author": "Chronopoulou, Alexandra and Peters, Matthew E and Fraser, Alexander and Dodge, Jesse",
        "title": "Adaptersoup: Weight averaging to improve generalization of pretrained language models"
      },
      {
        "key": "wang2024interpretable",
        "author": "Wang, Haoxiang and Xiong, Wei and Xie, Tengyang and Zhao, Han and Zhang, Tong",
        "title": "Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts"
      }
    ]
  }
]