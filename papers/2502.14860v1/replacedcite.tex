\section{Related Work}
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/mediq_medqa.pdf}\vspace{-3mm}
    \caption{3B Model performance on the interactive MediQ-MedQA task. Models aligned with \methodname are more robust to out-of-distribution data.}
    \label{fig:results:medqa}\vspace{-3mm}
\end{figure}

\paragraph{Clinical Reasoning in LLMs. }

LLMs have the potential to significantly transform medicine by enhancing personalized care and accessibility ____. 
Models trained with medical data contain rich medical knowledge ____, but are limited in instruction-following and multi-hop reasoning ____.
These models excel in static, medical QA benchmarks ____,
but recent work has moved away from the static single-turn paradigm and highlight \emph{proactive question-asking} as a key capability to reliable and effective clinical reasoning ____. Our work furthers this direction by providing an evaluation benchmark with real data and the first method to train specialized question-asking models.


Our proposed method relies on synthetic counterfactual data generation ____ and fine-grained alignment. 
Inspired by prior work on multi-objcetive RLHF ____, we extend PPO ____ and DPO ____ to align models with attribute-specific datasets, and uniquely compare different integration points of the fine-grained preference signals ____.