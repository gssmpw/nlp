\section{Conclusion}
In this paper, we introduce the Lighting Controllable Video Diffusion model (LCVD) for high-fidelity, relightable portrait animation. By distinguishing between intrinsic and extrinsic facial features, our approach effectively preserves identity and appearance while enabling precise control over lighting and pose. We propose a novel framework that leverages reference and shading adapters to construct feature subspaces and incorporates multi-condition classifier-free guidance to fine-tune the lighting effects. Our extensive experimental results demonstrate that LCVD outperforms existing methods, providing significant improvements in lighting realism, image quality, and video consistency. 