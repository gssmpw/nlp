
% % \documentclass{article} % For LaTeX2e
% \documentclass[11pt, letterpaper, shortlabels]{archer}
% \usepackage{times}
% \usepackage{enumitem}
% \usepackage{comment}
% \usepackage{etoolbox}
% \usepackage{ifthen}
% \usepackage{mathrsfs}
% \usepackage{upquote}
% \usepackage{caption}
% \usepackage{subcaption}
% \usepackage{algorithm}
% \usepackage{algpseudocode}
% \usepackage{arydshln}
% \usepackage{longtable}
% \usepackage{hyperref}
% \usepackage{url}
% \usepackage{graphicx}
% \usepackage{booktabs}
% \usepackage{adjustbox}
% \usepackage{amsmath}
% \usepackage{dsfont}
% \usepackage{multirow}
% \usepackage{mdframed}
% \usepackage{xcolor}
% \usepackage{blindtext}
% \usepackage{setspace}
% \usepackage{xcolor,colortbl}
% \definecolor{Gray}{gray}{0.90}
% \definecolor{LightCyan}{rgb}{0.88,1,1}
% % \newcommand{\yifei}[1]{{\textcolor{blue}{[Yifei: #1]}}}
% % \newcommand{\qianlan}[1]{{\textcolor{green}{[Qianlan: #1]}}}
% \usepackage{multirow}
% \newcommand{\ourmethod}{Proposer-Agent-Evaluator }
% \newcommand{\ourmethodnospace}{Proposer-Agent-Evaluator}
% \newcommand{\ouracronym}{PAE }
% \newcommand{\ouracronymnospace}{PAE}
% \usepackage{wrapfig}

% % \newcommand{\kl}[1]{\comment{Kaixiang's comment: #1}}
% % Add comments
% \newcommand{\showcomments}{yes}
% \newcommand\kaixiang[1]{
% \ifthenelse{\equal{\showcomments}{yes}}{{\color{cyan} Kaixiang: #1}}{\ignorespaces}
% }

% \newcommand\yifei[1]{
% \ifthenelse{\equal{\showcomments}{yes}}{{\color{blue} yifei: #1}}{\ignorespaces}
% }

% \newcommand\qianlan[1]{
% \ifthenelse{\equal{\showcomments}{yes}}{{\color{blue} qianlan: #1}}{\ignorespaces}
% }
% \newcommand\erran[1]{
% \ifthenelse{\equal{\showcomments}{yes}}{{\color{blue} erran: #1}}{\ignorespaces}
% }
% \usepackage{listings}

% % Optional math commands from https://github.com/goodfeli/dlbook_notation.
% \input{math_commands.tex}
% % \linespread{0.94}


% \title{\ourmethodnospace~(\ouracronymnospace): \\Autonomous Skill Discovery For Foundation Model Internet Agents}
% %%SL.8.31: The current title is pithy, which is great, but it doesn't index very precisely into a particular topic -- i.e., readers who are interested in VLMs for example might not realize it has anything to do with VLMs and might not click on it in arxiv. Maybe we can make the title stand out better and have it index better into the main topics of the paper that are likely to be of interest to readers? --> How is the new one?
% %%SL.9.21: AgentDiscover sounds pretty generic to me, won't be very memorable. It's OK to just go with an acronym method name, or else something that is more likely to stand out uniquely to the reader. The rest of the title seems ok, but do we really need to emphasize "Internet Agents"? That sounds really limiting, vs. agents more generally. ---> AT LEAST include internet agents for submission? the web agent is actually is pretty big and growing community

% \usepackage[all]{hypcap}

% \usepackage[authoryear, round]{natbib}
% % \bibliographystyle{plainnat}

% \usepackage{hyperref}[citecolor=magenta,linkcolor=magenta]

% \hypersetup{
%     colorlinks = true,
%     citecolor = {magenta},
% }


% % Authors must not appear in the submitted version. They should be hidden
% % as long as the \iclrfinalcopy macro remains commented out below.
% % Non-anonymous submissions will be rejected without review.

% \author{
% }

% % The \author macro works with any number of authors. There are two commands
% % used to separate the names and addresses of multiple authors: \And and \AND.
% %
% % Using \And between authors leaves it to \LaTeX{} to determine where to break
% % the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% % puts 3 of 4 authors names on the first line, and the last on the second
% % line, try using \AND instead of \And bexwore the third author name.

% \newcommand{\fix}{\marginpar{FIX}}
% \newcommand{\new}{\marginpar{NEW}}

% %\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
% \begin{document}


% \maketitle



% \documentclass{article} % For LaTeX2e
\documentclass[11pt, letterpaper, shortlabels]{archer}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
% \input{math_commands.tex}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{pgf}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{xcolor}         % Extended colors
\usepackage{color}         % Color extended names
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{resizegather}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}
\usepackage{color-edits}
\addauthor{yifei}{blue}
% \linespread{.98}
\title{\ourmethodnospace~(\ouracronymnospace): \\Digi-Q}


% % Attempt to make hyperref and algorithmic work together better:
% \newcommand{\theHalgorithm}{\arabic{algorithm}}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{algorithm}
% \usepackage{algorithmic}
% \usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\ifx\assumption\undefined
\newtheorem{assumption}{Assumption}
\fi

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \theoremstyle{plain}
% \theoremstyle{definition}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
% \newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}
\usepackage{wrapfig}
\captionsetup[figure]{font=small,skip=0pt}
\setlength{\belowcaptionskip}{0pt}


% ##########################################

% ##########################################

% ##########################################

% ##########################################

% ##########################################
% \documentclass{article} % For LaTeX2e
% \documentclass[11pt]{berkeley}

% \usepackage[preprint]{neurips_2023}

\newcommand{\yifei}[1]{{\textcolor{blue}{[Yifei: #1]}}}
\newcommand{\jack}[1]{{\textcolor{blue}{[Jack: #1]}}}
\newcommand{\qianlan}[1]{{\textcolor{green}{[Qianlan: #1]}}}
\usepackage{multirow}
\newcommand{\ourmethod}{Digi-Q}
\newcommand{\ourmethodnospace}{Proposer-Agent-Evaluator}
\newcommand{\ouracronym}{PAE }
\newcommand{\ouracronymnospace}{PAE}
\newcommand{\argmax}{\arg \max}

\usepackage[all]{hypcap}

\usepackage[authoryear, round]{natbib}
% \bibliographystyle{plainnat}

\usepackage{hyperref}[citecolor=magenta,linkcolor=magenta]

\hypersetup{
    colorlinks = true,
    citecolor = {magenta},
}

\usepackage{graphicx}
\usepackage{booktabs} % for professional tables
\usepackage{float}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{nicefrac}
\usepackage{dsfont}
\usepackage{enumitem}
% \usepackage{minted}
\usepackage{float}
% \usepackage{times}
\usepackage{enumitem}
\usepackage{comment}
\usepackage{etoolbox}
\usepackage{ifthen}
\usepackage{mathrsfs}
\usepackage{upquote}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{arydshln}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{multirow}
\usepackage{mdframed}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{setspace}
\usepackage{xcolor,colortbl}
\definecolor{Gray}{gray}{0.90}
\definecolor{LightCyan}{rgb}{0.88,1,1}
% \newcommand{\yifei}[1]{{\textcolor{blue}{[Yifei: #1]}}}
% \newcommand{\qianlan}[1]{{\textcolor{green}{[Qianlan: #1]}}}
\usepackage{multirow}
\usepackage{wrapfig}

\setlength\parindent{0pt}
% \setminted[python]{frame=lines, breaklines, framesep=2mm, fontsize=\footnotesize, numbersep=5pt}


% \usepackage[authoryear, sort&compress, round]{natbib}
\usepackage{xspace}
\usepackage[capitalize,noabbrev]{cleveref}
\bibliographystyle{plainnat}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{lipsum}
\usepackage{listings}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bbm}

\usepackage{algpseudocode}
\usepackage{setspace}

\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{microtype}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
basicstyle=\ttfamily\footnotesize,
language=Python,
morekeywords={self, clip, exp, mse_loss, uniform_sample, concatenate, logsumexp},              % Add keywords here
keywordstyle=\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=single,                         % Any extra options here
showstringspaces=false
}}

% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

\DeclareRobustCommand{\StartCrate}{%
  \begingroup\normalfont
  \raisebox{-0.3ex}{\smash{\includegraphics[height=2.0\fontcharht\font`\B]{figures/icon.png}}}%
  \endgroup
}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

\newcommand{\Dcal}{\mathcal{D}}
\newcommand{\EE}{\mathbb{E}}

% % \input{defs.tex}
% % \input{}

\makeatletter
\def\mathcolor#1#{\@mathcolor{#1}}
\def\@mathcolor#1#2#3{%
  \protect\leavevmode
  \begingroup
    \color#1{#2}#3%
  \endgroup
}
\makeatother

% \usepackage[textsize=tiny]{todonotes}
% \setlength{\parskip}{3pt}

% \usepackage[skins,theorems]{tcolorbox}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % from Tengyang

% tweaking cleveref
\Crefformat{equation}{#2Eq.\;(#1)#3}

\Crefformat{figure}{#2Figure #1#3}
\Crefformat{assumption}{#2Assumption #1#3}
\Crefname{assumption}{Assumption}{Assumptions}

% Fix hyperref in section titles.
\usepackage{crossreftools}
\pdfstringdefDisableCommands{%
    \let\Cref\crtCref
    \let\cref\crtcref
}
\newcommand{\creftitle}[1]{\crtcref{#1}}

\usepackage{dsfont}
\usepackage{nicefrac}

\author[1,2\textbf{*}]{Hao Bai}
\author[1\textbf{*}]{Yifei Zhou}
\author[3]{Li Erran Li}
\author[1]{Sergey Levine}
\author[4]{Aviral Kumar}

\affil[*]{Equal contributions}
\affil[1]{UC Berkeley}
\affil[2]{UIUC}
\affil[3]{Amazon}
\affil[4]{Carnegie Mellon University}

\correspondingauthor{haob2@illinois.edu, yifei\_zhou@berkeley.edu.\\ This work was done entirely at UC Berkeley and CMU.}

% \author{Hao Bai$^{1,2}$\thanks{Equal contribution, listed in alphabetical order; work done at UC Berkeley. E-mails: haob2@illinois.edu, yifei\_zhou@berkeley.edu,  aviralku@andrew.cmu.edu. Project page: \url{https://digirl-agent.github.io/}. Code available at \url{https://github.com/DigiRL-agent/digirl}.}  
% \: Yifei Zhou$^{1*}$ 
% \AND 
% \: Li Erran Li$^{3}$ 
% \: Sergey Levine$^{1}$ 
% \: Aviral Kumar$^{4, 5}$ 
% \AND \normalfont 
% $^{1}$UC Berkeley
% \: $^{2}$UIUC
% \: $^{3}$Amazon
% \: $^{4}$CMU
% \: $^{5}$Google DeepMind}

% \author{Author List}

\title{\StartCrate{} Digi-Q: Learning VLM Q-Value Functions for Training Device-Control Agents}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\begin{abstract}
\textbf{Abstract:} While a number of existing approaches for building foundation model agents rely on prompting or fine-tuning with human demonstrations, it is not sufficient in dynamic environments (e.g., mobile device control). On-policy reinforcement learning (RL) should address these limitations, but collecting actual rollouts in an environment is often undesirable in truly open-ended agentic problems such as mobile device control or interacting with humans, where each unit of interaction is associated with a cost. In such scenarios, a method for policy learning that can utilize off-policy experience by learning a trained action-value function is much more effective. In this paper, we develop an approach, called \ourmethod{}, to train VLM-based action-value Q-functions which are then used to extract the agent policy. We study our approach in the mobile device control setting. \ourmethod{} trains the Q-function using offline temporal-difference (TD) learning, on top of frozen, intermediate-layer features of a VLM. Compared to fine-tuning the whole VLM, this approach saves us compute and enhances scalability.
To make the VLM features amenable for representing the Q-function, we need to employ an initial phase of fine-tuning to amplify coverage over actionable information needed for value function. Once trained, we use this Q-function via a Best-of-N policy extraction operator that imitates the best action out of multiple candidate actions from the current policy as ranked by the value function, enabling policy improvement without environment interaction. \ourmethod{} outperforms several prior methods on user-scale device control tasks in Android-in-the-Wild, attaining 21.2\% improvement over prior best-performing method. In some cases, our Digi-Q approach already matches state-of-the-art RL methods that require interaction. The project is open-sourced at \url{https://github.com/DigiRL-agent/digiq}
\end{abstract}

\begin{document}

\maketitle

 \input{sections/1_introduction}
 \input{sections/2_related_works}
 \input{sections/3_method}
 \input{sections/4_experiments}
 \input{sections/5_conclusion}
 \input{sections/ack}

% \newpage
% \section*{Reproducibility Statement}
% To facilitate reproducibility of our work, we will open-source the model checkpoints and training infrastructure. We have included a discussion of our choices of hyperparameters in all experiments in~\Cref{app:hyperparams} and the prompts that we used for the autonomous evaluator in~\Cref{app:vlm-prompts}. We will also release the data that we use to train our model and the environment configuration (e.g. emulator device specifications).

% \section*{Ethics Statement}
% We develop methods that enable device control agent to operate on a fully-functioning Android device in an open-ended way. It is possible that irresponsible deployment of such device control agents can result in privacy leaks and vulnerability to malicious attacks (e.g. when the agent clicks on some malicious website links). While the development of a device control agent can significantly benefit productivity and increase accessibility, it is important that proper precautionary mechanisms should be in place to prevent such risks.


% The dataset to be released will include browsing on the Internet, so it will include a snapshot of the Internet when the data is collected. However, as we don't provide any personal information to the agent, privacy will not leak. Cautions should be paid, though, if the user decides to train an agent with personal information authenticated to the learning environment, which will likely result in a privacy leak.

% It's also important not to train the agent on task sets or datasets with harmful intentions. Training agents on these tasks/data is likely to make the agent intentionally leak privacy, go to harmful websites, or jailbreak (i.e. the agent becomes a chatbot that's malicious to the user).

\bibliography{neurips2024}
% \bibliographystyle{neurips2024}

\newpage

\appendix
\onecolumn
\part*{Appendices}

\input{sections/app_algorithm_box}
\input{sections/app_exp_details}
\input{sections/app_qualitative_examples}
\input{sections/app_prompts}
\input{sections/app_hyperparameters}

\end{document}
