\section{Related Works}
\label{sec:rw}
The problem of data publication has become a major research topic in recent years. The naive solution would be to inject noise into each cell of the ____ tensor, but this would cause too much perturbation, making the published data inaccurate. 
To provide a better alternative, many methods have been developed to publish and query high-dimensional data under DP. We present here the state-of-the-art on this problem.\medskip

\noindent{\bf Partitioning approaches.} 
Rather than perturbing data points, ____ proposed algorithms that partition data into bins. In ____, they focused on data partitioning based on minimal \textit{aggregation error}, and then applied the \textit{Laplace mechanism} to add noise to the mean value of each bin. Their solution is only effective in low-dimensional/small-domain data, due to the complexity of finding the best partitioning. 
Other solutions have proposed a recursive domain decomposition algorithm that uses the quadtree strategy to divide the tensor into smaller blocks ____. 
Partitioning continues until a convergence condition is satisfied. After convergence, blocks will only keep a representative value of the cells, such as the mean (similar to ____), and perturb this value to ensure DP. 
One of the main challenges with partitioning is defining a limit or depth, denoted as $h$, to manage the budget distribution. Some solutions ____ use heuristics to determine an appropriate value for $h$, while ____ bypasses this constraint altogether, as it can hinder performance and introduce inaccuracies. We will address this challenge more in details in Section \ref{sec:ps}.

% One of the main challenges with partitioning is define a limit or depth $h$ in order to manage the budget distribution. Some solutions ____, use a heuristic to determine an $h$, meanwhile ____ bypassed this strong constraint as it may hinder the performances and introduce inaccuracies.
HDPView ____ can be considered an improvement over ____. Instead of using quadtree partitioning, HDPView introduces a data-dependent partitioning strategy, which enhances the quality of the resulting DP view by reducing both the \textit{Aggregation Error (AE)} and DP noise. However, this data-dependent strategy is still constrained by the depth parameter $h$ (after which it becomes totally random). While the convergence of ____ is independent of $h$, the partitioning strategy itself is limited by $h$, which reintroduces the issue in part of their solution.

% HDPView ____ can be considered as an improvement of ____. Instead of using quadtree partitioning, they introduced a data-dependent partitioning strategy. Thus, the quality of the created DP view is improved in terms of the \textit{aggregation error} and the DP noise. But, this data-dependent strategy is constrained by the depth $h$. Which means that even if the convergence of ____ is independent of $h$, their partitioning strategy is, thus re-introduced the issue in part of their solution.
\medskip

\noindent{\bf Workload-based approaches.} 
Some solutions aim to release only a part of the data delimited by a predefined set of queries, also called \textit{Workload}. In ____, they introduced a matrix mechanism (MM) that creates queries and outputs optimized for a given workload. The work in ____ presents an extension to ____ by adapting and optimizing the matrix mechanism to high-dimensional data (HDMM). 
In addition, HDMM improves ____, which also falls into this category of solutions. 
The main issues with these techniques are: (1) workload dependency, and (2) matrix operations can be computationally costly.
PrivateSQL ____ provides a framework that calculates the sensitivity of relational data based on its schema and relationships. It then creates a multidimensional view of these data using methods such as ____.
% Another solution in this class is ____, which uses random sampling to create a synopsis of the original data and accompany it with a dedicated perturbation table to inject noise to each query. This solution is considered as a data publishing solution, beacuse it pertubs the data and no further budget is needed for the queries. But, it differs than the previosly introduced solution in a sense that the generated data remains at the server in order to manage the perturbation of the queries (can be considred as hybrid publishing/online query answering). Consequently, ____ is relevent to our work but not quite comparable.
Another solution in this class is ____, which uses random sampling to create a synopsis of the original data and complements it with a dedicated perturbation table to inject noise into each query. This approach is considered a data publishing solution because it perturbs the data upfront, and no further budget is required for individual queries. However, it differs from the previously introduced solutions in that the generated data remains on the server to handle query perturbation, making it a hybrid between data publishing and online query answering. As a result, ____ is relevant to our work but not directly comparable.
\medskip

\noindent{\bf Private generative models.} 
Another direction of research in this area is the use of generative models to create synthetic, private versions of the data that can then be published.  
In ____, the authors trained a Bayesian network under DP guarantees, while others ____ used marginal tables to learn the distribution of the original data.
Given the impressive performance of deep generative models in many research areas, ____ proposed models that preserve DP while synthesizing data. 
These models, such as ____ (which uses a Generative Adversarial Network, GAN), outperform ____ only on some classification tasks, but ____ outperforms GAN-based methods on private tabular data. 
The limitations of these approaches are, in general, as follows: (1) The models are not specifically tailored to tensor data structures and OLAP tasks, which is a major drawback compared to partitioning and workload-dependent approaches, and (2) Generative models are very complex and resource-intensive for large-scale data. In scenarios where data is frequently updated, this computational cost becomes very significant.\medskip

In our work, we focus on \textbf{workload-independent partitioning-based approaches}. 
More specifically, we address the \textbf{limitations and inefficiencies} of existing methods such as ____ which we will present in more detail in Section \ref{sec:ps}. 
We propose a new partitioning algorithm \texttt{RIPOST}, which creates a better quality view in terms of \textbf{accuracy} while ensuring \textbf{data privacy and utility}.


%We propose a new partitioning algorithm called \texttt{RIPOST} (p\textbf{R}ivate v\textbf{I}ew by two-\textbf{P}hase decomp\textbf{O}sition for multidimen\textbf{S}ional da\textbf{T}a), which creates a better quality view in terms of \textbf{accuracy} while ensuring \textbf{data privacy and utility}.