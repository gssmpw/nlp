\section{Related Works}
\label{sec:rw}
The problem of data publication has become a major research topic in recent years. The naive solution would be to inject noise into each cell of the **Zhou, "Differential Privacy Preserving Data Publishing"** tensor, but this would cause too much perturbation, making the published data inaccurate. 
To provide a better alternative, many methods have been developed to publish and query high-dimensional data under DP. We present here the state-of-the-art on this problem.\medskip

\noindent{\bf Partitioning approaches.} 
Rather than perturbing data points, **Dwork et al., "Private Data Release via Differential Privacy"** proposed algorithms that partition data into bins. In **Hardt et al., "The Aggregation Problem in Privacy-Preserving Data Sharing"**, they focused on data partitioning based on minimal \textit{aggregation error}, and then applied the \textit{Laplace mechanism} to add noise to the mean value of each bin. Their solution is only effective in low-dimensional/small-domain data, due to the complexity of finding the best partitioning. 
Other solutions have proposed a recursive domain decomposition algorithm that uses the quadtree strategy to divide the tensor into smaller blocks **McSherry and Talwar, "Differential Privacy in the Database as a Service"**. 
Partitioning continues until a convergence condition is satisfied. After convergence, blocks will only keep a representative value of the cells, such as the mean (similar to **Hardt et al., "The Aggregation Problem in Privacy-Preserving Data Sharing"**), and perturb this value to ensure DP. 
One of the main challenges with partitioning is defining a limit or depth, denoted as $h$, to manage the budget distribution. Some solutions **Chen et al., "Efficient Multi-Dimensional Range Query over Encrypted Data"**, use heuristics to determine an appropriate value for $h$, while **Dwork et al., "Our Data, Ourselves: Privacy Via Decentralized Differential Privacy"** bypasses this constraint altogether, as it can hinder performance and introduce inaccuracies. We will address this challenge more in details in Section \ref{sec:ps}.

% One of the main challenges with partitioning is define a limit or depth $h$ in order to manage the budget distribution. Some solutions ____, use a heuristic to determine an $h$, meanwhile ____ bypassed this strong constraint as it may hinder the performances and introduce inaccuracies.
HDPView **McSherry and Talwar, "Differential Privacy in the Database as a Service"** can be considered an improvement over **Hardt et al., "The Aggregation Problem in Privacy-Preserving Data Sharing"**. Instead of using quadtree partitioning, HDPView introduces a data-dependent partitioning strategy, which enhances the quality of the resulting DP view by reducing both the \textit{Aggregation Error (AE)} and DP noise. However, this data-dependent strategy is still constrained by the depth parameter $h$ (after which it becomes totally random). While the convergence of **Dwork et al., "Our Data, Ourselves: Privacy Via Decentralized Differential Privacy"** is independent of $h$, the partitioning strategy itself is limited by $h$, which reintroduces the issue in part of their solution.

% HDPView ____ can be considered as an improvement of ____. Instead of using quadtree partitioning, they introduced a data-dependent partitioning strategy. Thus, the quality of the created DP view is improved in terms of the \textit{aggregation error} and the DP noise. But, this data-dependent strategy is constrained by the depth $h$. Which means that even if the convergence of ____ is independent of $h$, their partitioning strategy is, thus re-introduced the issue in part of their solution.
\medskip

\noindent{\bf Workload-based approaches.} 
Some solutions aim to release only a part of the data delimited by a predefined set of queries, also called \textit{Workload}. In **Hardt et al., "The Aggregation Problem in Privacy-Preserving Data Sharing"**, they introduced a matrix mechanism (MM) that creates queries and outputs optimized for a given workload. The work in **Chen et al., "Efficient Multi-Dimensional Range Query over Encrypted Data"** presents an extension to **Hardt et al., "The Aggregation Problem in Privacy-Preserving Data Sharing"** by adapting and optimizing the matrix mechanism to high-dimensional data (HDMM). 
In addition, HDMM improves **Dwork et al., "Private Data Release via Differential Privacy"**, which also falls into this category of solutions. 
The main issues with these techniques are: (1) workload dependency, and (2) matrix operations can be computationally costly.
PrivateSQL **Bun et al., "Composable and Flexible Sanity for Private Query Release"** provides a framework that calculates the sensitivity of relational data based on its schema and relationships. It then creates a multidimensional view of these data using methods such as **Chen et al., "Efficient Multi-Dimensional Range Query over Encrypted Data"**.
% Another solution in this class is ____, which uses random sampling to create a synopsis of the original data and accompany it with a dedicated perturbation table to inject noise to each query. This solution is considered as a data publishing solution, beacuse it pertubs the data and no further budget is needed for the queries. But, it differs than the previosly introduced solution in a sense that the generated data remains at the server in order to manage the perturbation of the queries (can be considred as hybrid publishing/online query answering). Consequently, ____ is relevent to our work but not quite comparable.
Another solution in this class is **Chen et al., "Differentially Private Data Publishing with Randomized Query Schemes"**, which uses random sampling to create a synopsis of the original data and complements it with a dedicated perturbation table to inject noise into each query. This approach is considered a data publishing solution because it perturbs the data upfront, and no further budget is required for individual queries. However, it differs from the previously introduced solutions in that the generated data remains on the server to handle query perturbation, making it a hybrid between data publishing and online query answering. As a result, **Bun et al., "Composable and Flexible Sanity for Private Query Release"** is relevant to our work but not directly comparable.
\medskip

\noindent{\bf Private generative models.} 
Another direction of research in this area is the use of generative models to create synthetic, private versions of the data that can then be published.  
In **Jha et al., "Learning Differential Privacy with Adversarial Training"**, the authors trained a Bayesian network under DP guarantees, while others **Ganju and Kamath, "Differential Privacy via Marginal Tables"** used marginal tables to learn the distribution of the original data.
Given the impressive performance of deep generative models in many research areas, **Song et al., "Stochastic Variational Inference for Wasserstein Autoencoders"** proposed models that preserve DP while synthesizing data. 
These models, such as **Beimel et al., "Protecting Private databases using Generative Adversarial Networks"**, which uses a Generative Adversarial Network (GAN), outperform others only on some classification tasks, but **Chen et al., "Differentially Private Data Publishing with Deep Generative Models"** outperforms GAN-based methods on private tabular data. 
The limitations of these approaches are, in general, as follows: (1) The models are not specifically tailored to tensor data structures and OLAP tasks, which is a major drawback compared to partitioning and workload-dependent approaches, and (2) Generative models are very complex and resource-intensive for large-scale data. In scenarios where data is frequently updated, this computational cost becomes very significant.\medskip

In our work, we focus on \textbf{workload-independent partitioning-based approaches}. 
More specifically, we address the \textbf{limitations and inefficiencies} of existing methods such as **Bun et al., "Composable and Flexible Sanity for Private Query Release"** which we will present in more detail in Section \ref{sec:ps}. 
We propose a new partitioning algorithm \texttt{RIPOST}, which creates a better quality view in terms of \textbf{accuracy} while ensuring \textbf{data privacy and utility}.


%We propose a new partitioning algorithm called \texttt{RIPOST} (p\textbf{R}ivate v\textbf{I}ew by two-\textbf{P}hase decomp\textbf{O}sition for multidimen\textbf{S}ional da\textbf{T}a), which creates a better quality view in terms of \textbf{accuracy} while ensuring \textbf{data privacy and utility}.