\section{Related Work}
\subsection{Multimodal AIGC on Social Media}
Due to challenges in detecting AIGC and limited real-world datasets, only a few studies have explored its presence and impact on social media. Research on AI-generated images has examined the prevalence and misuse of GAN-generated visuals for inauthentic activities \cite{yang2024characteristics}, the role of synthetic content like political memes in shaping discourse during elections \cite{chang2024generative,minici2024uncovering}, and the broader influence of AIGC on platform dynamics, including content creation and consumption patterns \cite{wei2024understanding}. In contrast, studies on AI-generated text are scarce, with one notable work investigating its prevalence among coordinated and organic users across platforms \cite{cinus2024exposing}.

Despite these contributions, two significant gaps remain in the literature. First, many studies are limited in their detection of AIGC, either focusing on a narrow range of models, such as GAN \cite{yang2024characteristics,ricker2024ai}, or relying on explicit hashtags to identify labeled content \cite{wei2024understanding}, which excludes unlabeled AIGC, including potentially harmful or misleading content. Additionally, manual identification approaches \cite{chang2024generative}, while useful, are neither scalable nor consistently accurate. These limitations prevent a comprehensive understanding of the full landscape of AIGC on social media. Second, existing research largely fails to adopt a multimodal perspective, which is critical given the differences between text and image modalities in emotional resonance \cite{li2020picture}, accessibility, and their potential to mislead audiences \cite{barari2021political,sundar2021seeing} and retain memories \cite{kirkpatrick1894experimental}. As multimodal AIGC, including text, image, audio, and video, increasingly circulates online, examining multiple modalities is essential to fully capture its scope and implications. To address these gaps, this work adopts a multimodal approach to analyze AIGC on social media platforms, aiming to provide a comprehensive view of its prevalence and explore differences in user sharing behaviors across modalities.

\subsection{Superspreaders of Online Information}
Superspreaders, also referred to as supersharers, are users who disproportionately contribute to the spread of specific types of content on social media, such as low-credibility or fake news. They play a unique role in shaping online information ecosystems by generating content that garners substantial reach and engagement. Studies have consistently found that a small fraction of superspreaders accounts for the majority of misinformation shared online \cite{nogara2022disinformation,deverna2024identifying}. For instance, during the 2016 U.S. Presidential Election, just 0.1\% of Twitter users were responsible for nearly 80\% of fake news shared, with similar patterns observed during the 2020 Election \cite{grinberg2019fake, baribi2024supersharers, guess2018selective}.  Superspreaders are typically identified using various metrics, such as k-core decomposition to assess centrality within the network, the sum of nearest neighbors' degrees to evaluate local influence, and the h-index to measure the volume and reach of their shared content \cite{pei2014searching, deverna2024identifying}. Superspreaders are not limited to bots or automated accounts but frequently include politically active individuals and pundits with large followings \cite{guess2019less, baribi2024supersharers}. Recent work has also shown that $\mathbb{X}$'s recommendation algorithm amplifies superspreaders like political commentators and partisan influencers \cite{ye2024auditing}. 

While most studies have focused on superspreaders of misinformation, the rise of generative AI introduces new complexities and raises open questions. AIGC is often multimodal, blending text and visuals, which may enhance its appeal and spreadability \cite{cao2023comprehensive}. Additionally, AIGC's potential to mimic diverse styles and create content at scale raises concerns about its integration into existing misinformation networks \cite{ferrara2024genai}. Superspreaders of AIGC may exploit these affordances and automation capabilities to amplify their influence further. This study, therefore, builds on prior work by investigating AIGC superspreaders during the 2024 U.S. Presidential Election.