\def\year{2022}\relax
%File: formatting-instructions-latex-2022.tex
%release 2022.1
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai22}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{cite}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{todonotes}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{soul}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{balance}
\usepackage{array}
\usepackage{amsmath}
\usepackage{xspace}
\usepackage{xcolor}
\usepackage{float}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{amssymb}
\newcommand{\answerYes}[1]{\textcolor{blue}{#1}} 
\newcommand{\answerNo}[1]{\textcolor{teal}{#1}} 
\newcommand{\answerNA}[1]{\textcolor{gray}{#1}} 
\newcommand{\answerTODO}[1]{\textcolor{red}{#1}}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
%\nocopyright
%
% PDF Info Is REQUIRED.
% For /Title, write your title in Mixed Case.
% Don't use accents or commands. Retain the parentheses.
% For /Author, add all authors within the parentheses,
% separated by commas. No accents, special characters
% or commands are allowed.
% Keep the /TemplateVersion tag as is

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai22.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using, and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash

\title{Prevalence, Sharing Patterns, and Spreaders of Multimodal AI-Generated Content on $\mathbb{X}$ during the 2024 U.S. Presidential Election}

\author{
    %Authors
    % All authors must be in the same font size and format.
    Zhiyi Chen\equalcontrib,
    Jinyi Ye\equalcontrib,
    Emilio Ferrara,
    Luca Luceri
}
\affiliations{
    %Afiliations
    University of Southern California, Information Sciences Institute \\
    zchen346@usc.edu,
    jinyiy@usc.edu,
    emiliofe@usc.edu,
    ll\_774@usc.edu
    % Information Sciences Institute\\
    % 4676 Admiralty Way \#1001\\
    % Marina Del Rey, California 90292
}

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name,\textsuperscript{\rm 1}
    Second Author Name, \textsuperscript{\rm 2}
    Third Author Name \textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1} Affiliation 1\\
    \textsuperscript{\rm 2} Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi

\begin{document}

\maketitle

\begin{abstract}
While concerns about the risks of AI-generated content (AIGC) to the integrity of social media discussions have been raised, little is known about its scale and the actors responsible for its dissemination online. In this work, we identify and characterize the prevalence, sharing patterns, and spreaders of AIGC in different modalities, including images and texts. Analyzing a large-scale dataset from $\mathbb{X}$ related to the 2024 U.S. Presidential Election, we find that approximately 12\% of images and 1.4\% of texts are deemed AI-generated. Notably, roughly 3\% of text spreaders and 10\% of image spreaders account for 80\% of the AI-generated content within their respective modalities. Superspreaders of AIGC are more likely to be $\mathbb{X}$ Premium subscribers with a right-leaning orientation and exhibit automated behavior. Additionally, AI image spreaders have a higher proportion of AI-generated content in their profiles compared to AI text spreaders. This study serves as a very first step toward understanding the role generative AI plays in shaping online socio-political environments and offers implications for platform governance.
% last sentence can be refined
% only image superspreaders are more right-leaning
\end{abstract}


\section{Introduction}
Generative artificial intelligence (AI) technologies are increasingly mediating our online interactions on social media. From content moderation bots \cite{jhaver2019human} and synthetic personas \cite{ferrara2024risks} to AI-generated news and tweets \cite{kreps2022all}, AI is assisting, augmenting, or even replacing human contributions \cite{sundar2022rethinking}, creating a ``synthetic reality'' where human and AI actors coexist in our digital environment \cite{ferrara2024genai}. The advancements and proliferation of generative AI applications like ChatGPT, DALL·E, and Midjourney have amplified both the quantity and quality of AI-generated content (AIGC) online, while intensifying concerns about information credibility and authenticity \cite{lee2020authenticity}, model bias \cite{liang2021towards}, social trust \cite{epstein2023art}, and potential nefarious activity \cite{minici2024uncovering}. Although prior work has examined the impact of AIGC on human perceptions and behavior in the social media domain (e.g., \citet{jakesch2019ai,du2023effect}), most of these studies are conducted in experimental settings, and relatively little attention has been given to the actual sharing behaviors of AIGC in real-world scenarios.
% , such as social media networks.
% AI-Generated Content (AIGC)

In critical contexts like democratic processes, concerns about AIGC on social media focus primarily on its negative impact on the integrity of online information. Research warns against the threat of deepfakes \cite{campbell2022preparing}, coordinated information campaigns \cite{luceri2024unmasking}, and offensive speech targeting opposing viewpoints or vulnerable populations \cite{shaw2023social}. However, we know little about the scale, scope, and influence of AI-generated content online. Besides, research in misinformation consistently shows that a small fraction of individuals---also known as superspreaders---are responsible for the majority of questionable information shared on social media \cite{deverna2024identifying,nogara2022disinformation,baribi2024supersharers}. Moreover, individuals who frequently share low-credibility content often post more toxic language and are more political in nature \cite{deverna2024identifying}. While AIGC clearly represents a new form of inauthentic content, it is still unknown whether superspreaders of AI-generated content display similar characteristics to misinformation superspreaders, yet, to the best of our knowledge, no prior work has examined this prolific group of users.


% It is arguable that superspreaders of AI-generated content might display similar characteristics, yet, to the best of our knowledge, no prior work has examined this emerging group of users.
% Flow of this paragraph can be improved

In this study, we utilize a comprehensive dataset collected during the 2024 U.S. Presidential Election period on $\mathbb{X}$ (formerly Twitter) to investigate and characterize the behavior of users sharing AI-generated content over the three months leading up to the election. We focus on disentangling
AIGC based on its modality, thus differentiating between
text and image generated by AI, given the increasing attention on the effects of multimodal generative AI on human
behavior \cite{yan2024promises}. Our analysis begins by addressing fundamental questions about the prevalence of AIGC and identifying the users responsible for its dissemination. To this end, we use GPT-4o to detect AI-generated images and a fine-tuned RoBERTa model to distinguish AI-generated text. Through this process, we identify 303 superspreaders across two modality groups, employing established metrics of online influence \cite{deverna2024identifying}. Finally, we characterize the behaviors of these superspreaders, focusing on their levels of automation and toxicity. This work addresses the following research questions (RQs):
% AIGC: define twice

% \begin{itemize}
%     \item \textbf{RQ1:} \textit{What is the prevalence and concentration of AIGC on $\mathbb{X}$? Do we observe consistent inequalities in user sharing behaviors across distinct modalities?}
%     \item \textbf{RQ2:} \textit{What are the characteristics of AIGC superspreaders?}
%     \item \textbf{RQ3:} \textit{What are the sharing behaviors of AIGC superspreaders across different modalities?}
% \end{itemize}

\begin{itemize}
    \item \textbf{RQ1:} \textit{What is the prevalence and concentration of AIGC on $\mathbb{X}$? Do we observe consistent inequalities in sharing patterns across distinct AIGC modalities?}
    \item \textbf{RQ2:} \textit{What are the characteristics and sharing behaviors of AIGC superspreaders across different modalities?}
\end{itemize}

% \begin{quote}
%     \textbf{RQ1:} What is the prevalence and concentration of AI-generated contents on $\mathbb{X}$? \\
%     \textbf{RQ2:} Who are the superspreaders? \\
%     \textbf{RQ3:} What are the sharing behaviors of superspreaders? \\
% \end{quote}

\subsubsection{Contributions of This Work.}

This study serves as an initial step toward understanding how generative AI technologies shape social media dynamics in political discussions. 
As one of the first investigations using real-world data to assess the prevalence of AIGC on social media, we reveal that approximately 12\% of images and 1.4\% of texts within the online discourse on $\mathbb{X}$ related to the 2024 U.S. Presidential Election are AI-generated. Notably, a small fraction of users dominate AIGC dissemination---about 3\% of text spreaders and 10\% of image spreaders account for 80\% of content in their respective modalities. We identify and characterize the behaviors of AIGC superspreaders, noting that they are more likely to have a right-leaning political orientation, subscribe to $\mathbb{X}$ Premium, and exhibit stronger bot-like behaviors. Furthermore, we analyze differences in sharing patterns across AIGC modalities, finding that users spreading AI-generated images have a higher proportion of AIGC within their timelines compared to those sharing AI-generated text. We hope our findings pave the way for further research on the role of AIGC in social media, offering valuable insights for platform governance, policy-making, and public awareness of generative AI’s growing impact on online sociopolitical landscapes.
% toxicity results to be discussed

\section{Related Work}

\subsection{Multimodal AIGC on Social Media}
Due to challenges in detecting AIGC and limited real-world datasets, only a few studies have explored its presence and impact on social media. Research on AI-generated images has examined the prevalence and misuse of GAN-generated visuals for inauthentic activities \cite{yang2024characteristics}, the role of synthetic content like political memes in shaping discourse during elections \cite{chang2024generative,minici2024uncovering}, and the broader influence of AIGC on platform dynamics, including content creation and consumption patterns \cite{wei2024understanding}. In contrast, studies on AI-generated text are scarce, with one notable work investigating its prevalence among coordinated and organic users across platforms \cite{cinus2024exposing}.

Despite these contributions, two significant gaps remain in the literature. First, many studies are limited in their detection of AIGC, either focusing on a narrow range of models, such as GAN \cite{yang2024characteristics,ricker2024ai}, or relying on explicit hashtags to identify labeled content \cite{wei2024understanding}, which excludes unlabeled AIGC, including potentially harmful or misleading content. Additionally, manual identification approaches \cite{chang2024generative}, while useful, are neither scalable nor consistently accurate. These limitations prevent a comprehensive understanding of the full landscape of AIGC on social media. Second, existing research largely fails to adopt a multimodal perspective, which is critical given the differences between text and image modalities in emotional resonance \cite{li2020picture}, accessibility, and their potential to mislead audiences \cite{barari2021political,sundar2021seeing} and retain memories \cite{kirkpatrick1894experimental}. As multimodal AIGC, including text, image, audio, and video, increasingly circulates online, examining multiple modalities is essential to fully capture its scope and implications. To address these gaps, this work adopts a multimodal approach to analyze AIGC on social media platforms, aiming to provide a comprehensive view of its prevalence and explore differences in user sharing behaviors across modalities.

\subsection{Superspreaders of Online Information}
Superspreaders, also referred to as supersharers, are users who disproportionately contribute to the spread of specific types of content on social media, such as low-credibility or fake news. They play a unique role in shaping online information ecosystems by generating content that garners substantial reach and engagement. Studies have consistently found that a small fraction of superspreaders accounts for the majority of misinformation shared online \cite{nogara2022disinformation,deverna2024identifying}. For instance, during the 2016 U.S. Presidential Election, just 0.1\% of Twitter users were responsible for nearly 80\% of fake news shared, with similar patterns observed during the 2020 Election \cite{grinberg2019fake, baribi2024supersharers, guess2018selective}.  Superspreaders are typically identified using various metrics, such as k-core decomposition to assess centrality within the network, the sum of nearest neighbors' degrees to evaluate local influence, and the h-index to measure the volume and reach of their shared content \cite{pei2014searching, deverna2024identifying}. Superspreaders are not limited to bots or automated accounts but frequently include politically active individuals and pundits with large followings \cite{guess2019less, baribi2024supersharers}. Recent work has also shown that $\mathbb{X}$'s recommendation algorithm amplifies superspreaders like political commentators and partisan influencers \cite{ye2024auditing}. 

While most studies have focused on superspreaders of misinformation, the rise of generative AI introduces new complexities and raises open questions. AIGC is often multimodal, blending text and visuals, which may enhance its appeal and spreadability \cite{cao2023comprehensive}. Additionally, AIGC's potential to mimic diverse styles and create content at scale raises concerns about its integration into existing misinformation networks \cite{ferrara2024genai}. Superspreaders of AIGC may exploit these affordances and automation capabilities to amplify their influence further. This study, therefore, builds on prior work by investigating AIGC superspreaders during the 2024 U.S. Presidential Election.

\section{Methodology}
\subsection{Data Collection and Curation}
We leverage an existing dataset of tweets related to the 2024
U.S. \textsc{ELECTION} \cite{balasubramanian2024public}. The dataset was generated by querying targeted keywords related to political figures, events, and emerging issues of the Presidential Election to query data effectively. In this study, we analyze data spanning a three-month period leading up to the election, from July 1, 2024, to September 30, 2024. The resulting dataset includes 24.7M tweets and 2.5M images shared by 3.1M users. 

Since our analysis focuses on characterizing the behaviors of users who shared AI-generated content during the observed period, we first extract and count these AI content sharers. To facilitate comparisons between the two modalities, we classify users into two groups: text and image, and apply the filtering process separately while adhering to the same criteria. Specifically, users who shared at least one AI-generated text are referred to as \textit{AI text sharers}, while those who shared at least one AI-generated image are denoted as \textit{AI image sharers} (details on the detection of AIGC can be found in the \textit{AI-Generated Content Detection} section). This yields approximately 170K AI text sharers and 88K AI image sharers. 

Next, to address RQ2, we apply a filtering process to identify a subset of target users. To ensure that each user has sufficient data points to analyze their sharing behavior and received engagement, two criteria are applied. The first criterion sets a minimum threshold for the total number of tweets a user has posted during the observed time period. For AI text sharers, users with fewer than five tweets containing text are excluded. Similarly, for AI image sharers, users who have posted fewer than five tweets with at least one image in each are excluded from the analysis. The second criterion requires that among all tweets a user has shared, at least one must have received at least one retweet, i.e., \textit{h}-index $>$ 0 (details on the calculation of \textit{h}-index are provided in the \textit{Identifying AIGC Superspreaders} section). These criteria collectively ensure a robust and meaningful dataset for evaluating user activity and influence. After this filtering step, we retrieve a subset of \textit{target users} consisting of 17,584 AI text sharers and 12,898 AI image sharers. Table~\ref{tab:text_image_summary} provides the basic statistics of the dataset. 
% ai-image sharers filtered out because of invalid responses

\begin{table}[t!]
\centering
\caption{Basic statistics of the dataset}
\begin{tabular}{l|c|c}
\toprule
\textbf{Modality} & \textbf{Text} & \textbf{Image} \\
\midrule
\# of tweets    & 24,746,761  & 1,896,292      \\
\# of users     & 3,108,782   & 414,541  \\
\# of AIGC sharers  & 170,980     & 88,045   \\
\# of target users  & 17,584      & 12,898   \\
\bottomrule
\end{tabular}
\label{tab:text_image_summary}
\end{table}
% Add more details here?

%Table \ref{tab:election_dataset} provides detailed statistics on the number of tweets and users.

% We define users who have shared at least one tweet with text as text sharers and those who have shared at least one image as image sharers. 

% \begin{table}[t!]
% \centering
% \begin{tabular}{c c}
% \toprule
% \textbf{} & 2024 \textsc{Election} Subset \\ 
% \midrule
% \# of tweets        & 24,746,761 \\
% \# of images\footnote{A tweet can contain multiple images.}        & 2,462,132  \\
% \# of users        & 3,108,782  \\
% % All image sharers & 414,541    \\
% \bottomrule
% \end{tabular}
% \caption{Statistics of the 2024 \textsc{Election} dataset subset.}
% \label{tab:election_dataset}
% \end{table}

\subsection{AI-Generated Content Detection}
With the rise of AI-generated content on platforms like $\mathbb{X}$, detection has become a significant challenge. Traditional deep learning models often struggle to distinguish AI-generated images~\cite{borji2022good}, but recent advancements show that large language models (LLMs) like GPT-4o, paired with well-crafted prompts, offer robust multimodal performance~\cite{chen2023gpt,chang2024generative,brin2024assessing}. Accordingly, we employ GPT-4o for image detection in this study.
For AI-generated texts, LLMs often underperform in zero-shot settings~\cite{bhattacharjee2024fighting}. To address this, we follow prior successful approaches~\cite{dmonte2024classifying,cinus2024exposing} by curating a dataset of AI-generated and human-written texts and fine-tuning a RoBERTa model for enhanced accuracy. This method ensures reliable detection across diverse sources.

\subsubsection{AI-Generated Text Detection.}

To detect AI-generated texts on $\mathbb{X}$, we build on the method introduced in \citet{dmonte2024classifying}, which uses a fine-tuned RoBERTa model trained on 8,000 election-related claims written by humans and three open-source LLMs: Llama, Falcon, and Mistral. However, we enhance this dataset as it does not account for texts generated by other widely-used generative AI models, such as GPT, Claude, and Gemini. To address this limitation, we construct a new dataset comprising tweets generated by four models: GPT-4o, Claude 3 Sonnet, Gemini 1.5, and Llama 3 8B, alongside human-written tweets. Human-written tweets are randomly sampled from a dataset related to the 2020 U.S. Election \cite{chen2022election2020}, which predates the widespread adoption of LLMs like ChatGPT. For each human-written tweet, we generate an AI counterpart using the following prompt to ensure similar topic and language distributions \cite{cinus2024exposing}:

\begin{quote}
\textit{This is a tweet related to the 2020 U.S. election: \{tweet\}. Based on the topic of the given tweet, write a new tweet, mimicking the language styles used by Twitter users.} 
\end{quote}

Table \ref{tab:label_distribution} presents the number of instances for each label in the training and test datasets. We performed binary classification to distinguish between human- and AI-generated tweets. The RoBERTa model was fine-tuned using the AdamW optimizer with a learning rate of 1e-5, trained for 3 epochs on the training data, and evaluated on the test dataset. The model achieved a 0.96 F1-score on the validation set, demonstrating strong performance in distinguishing AI-generated texts from human-written ones. Training code and dataset can be found in URL\footnote{\url{https://github.com/angelayejinyi/AI_political_tweet_classifier}}.

\begin{table*}[t!]
\centering
\caption{Label distribution of instances in the training and test datasets}
\begin{tabular}{c|c|c|c|c|c|c}
\toprule
\multirow{2}{*}{\textbf{Dataset}} & \multicolumn{4}{c|}{\textbf{AI}} & \multirow{2}{*}{\textbf{Human}} & \multirow{2}{*}{\textbf{Total}} \\ 
\cmidrule(lr){2-5}
 & GPT & Llama & Claude & Gemini &  &  \\ 
\midrule
Train & 4,000 & 4,000 & 1,796 & 2,204 & 12,000 & 24,000 \\
Test & 1,000 & 1,000 & 449 & 551 & 3,000 & 6,000 \\
\bottomrule
\end{tabular}
\label{tab:label_distribution}
\end{table*}

\subsubsection{AI-Generated Image Detection.}

We leverage GPT-4o to differentiate AI-generated images from non-AI-generated ones. To evaluate its performance, we follow the approach of \citet{epstein2023online}, constructing a validation set of 1,200 AI-generated images and 1,200 non-AI-generated images. The non-AI-generated subset is randomly sampled from the LAION-400M dataset \cite{schuhmann2021laion}, while the AI-generated subset includes 400 images from the TwitterGAN dataset \cite{yang2024characteristics}, 400 DALL·E-generated images crawled from the subreddit r/dalle\footnote{Subreddit r/dalle: \url{https://www.reddit.com/r/dalle/}}, and 400 Midjourney-generated images crawled from its official website\footnote{Midjourney Explore: \url{https://www.midjourney.com/explore/}}.
% add footnotes linking to the websites

We extract image URLs from the metadata of tweets in our dataset and craft the following prompt:
\begin{quote}
\textit{Is this an AI-generated image? Answer in one word: ``yes'' or ``no''.}
\end{quote}
The prompt, along with the image URL, is provided to GPT-4o, with the temperature fixed at 0 to minimize variability. Among the 2,400 images in the validation set, GPT-4o successfully respond to 2,367 images but failed to process 33 due to issues such as sensitive content. The model achieved an F1-score of 0.96, demonstrating high accuracy in detecting AI-generated images.

We then apply GPT-4o detection to our 2024 U.S. Election dataset, using the OpenAI BatchAPI\footnote{OpenAI BatchAPI: \url{https://platform.openai.com/docs/guides/batch}} to optimize computational time and cost. The model's responses for each image are categorized as: (i) valid responses (``yes'' or ``no''), (ii) failure to download the image due to content moderation, or (iii) inability to respond, likely due to sensitive content, with messages like, ``Sorry, I cannot answer this.'' Valid responses correspond to category (i), while categories (ii) and (iii) are classified as invalid. Of the 2,462,132 images processed, approximately 90.5\% receive valid responses. Subsequent analyses focus on the remaining images and users.

% train-test split, model parameters, training epochs, GPU (add to appendix)
% need to suppliment the number of AI-generated texts and non-AI-generated texts in the training set; the overall performance after expanding the dataset (in detail and brief); do we add non-AI tweets into the training set?

% \subsection{Selecting Target Users}
% We perform additional filtering to identify a subset of target users. A user must meet three criteria to be considered a target user. First, the user must have shared at least one tweet containing AI-generated content, whether it is AI-generated text or an image. To facilitate comparisons between the two modalities, we classify users into two groups—text and image—and apply the filtering process separately but following the same criteria. Specifically, users who have shared at least one tweet which contain AI-generated text are defined as AI-text sharers, while those who have shared at least one AI-generated image are defined as AI-image sharers. After this initial filtering step, approximately 170K AI-text sharers and 88K AI-image sharers remain.

% These filtered AI-text and AI-image sharers constitute the target users when addressing questions related to prevalence and concentration. However, to answer RQ2 and RQ3, we apply two additional filtering criteria, outlined as follows.

% The second criterion sets a minimum threshold for the total number of tweets a user has posted within the observed time period. For AI-text sharers, users who have sent fewer than five tweets containing text are excluded. Similarly, for AI-image sharers, users who have posted fewer than five tweets, each containing at least one image, are excluded from the analysis. This step ensures that users with insufficient data points are excluded, as their sharing behavior cannot be meaningfully analyzed.

% The third criterion filters out users whose \textit{h}-index is 0. An \textit{h}-index of 0 indicates that the user has not contributed any tweets containing AI-generated content that meet the threshold of influence (i.e., being retweeted with a minimum number of times). Including such users would dilute the analysis by incorporating accounts that are inactive or lack meaningful engagement in the dissemination of AI-generated content.

% After applying these three filtering steps, 17,584 AI-text sharers and 12,898 AI-image sharers remain. Table~\ref{tab:user_filtering} presents an overview of the number of target users meeting the specified criteria.

% \begin{table}[t!]
% \centering
% \caption{Summary of users filtered through different steps.}
% \begin{tabular}{lcc}
% \toprule
% \textbf{\# of Users}              & \textbf{Text} & \textbf{Image} \\ 
% \midrule
% All users                         & 3,108,782     & 379,025        \\ 
% Users after the 1\textsuperscript{st} step & 170,980       & 88,045         \\ 
% Users after the 2\textsuperscript{nd} step & 113,839       & 30,654         \\ 
% Users after the 3\textsuperscript{rd} step & 17,584        & 12,898         \\ 
% \bottomrule
% \end{tabular}
% \label{tab:user_filtering}
% \end{table}


% \subsection{Quantifying Inequality}

% \subsubsection{Gini Coefficient}
% To quantify the level of inequality in users' sharing of AI-generated content—specifically, whether a large volume of AI-generated content is concentrated among a small number of accounts—we use the Gini coefficient, a widely adopted metric for measuring inequality \cite{bartley2023evaluating}. The Gini coefficient ranges from 0 to 1, where 0 indicates perfect equality (i.e., all users share an equal amount of AI-generated content), and 1 represents maximum inequality, where a very small number of users account for the majority of shared AI-generated content. In the current study, the Gini coefficient $G$ is calculates as:
% \[
% G = \frac{\sum_{i=1}^n \sum_{j=1}^n \left| E_i - E_j \right|}{2n^2 \bar{E}},
% \]
% where, for AI-text sharers, $E_i$ and $E_j$ represent the number of tweets which contain AI-generated text shared by users $i$ and $j$, respectively. $\bar{E}$ represents the average number of such tweets across all AI-text sharers, and $n$ denotes the total number of AI-text sharers. Similarly, when analyzing AI-image sharers, $E_i$ and $E_j$ denote the total number of tweets shared by users $i$ and $j$,  where each tweet contains at least one AI-generated image. $\bar{E}$ is the average number of such tweets among all AI-image sharers, and $n$ represents the total number of AI-image sharers. A higher Gini coefficient indicates that a disproportionate amount of AI-generated content is shared by a small subset of accounts, while a lower coefficient suggests a more equitable distribution among users.
% % do we need to discuss text and image separately?


\subsection{Identifying Superspreaders of AIGC}
% \subsubsection{\textit{h}-index}
Superspreaders are typically identified using influence metrics, including k-core centrality, the sum of nearest neighbors' degrees, and the engagement driven by their original content
\cite{pei2014searching,deverna2024identifying}. 
Here, we adopt the \textit{h}-index, originally designed to measure scholarly impact \cite{hirsch2005index}, and later adapted for identifying superspreaders of low-credibility content on $\mathbb{X}$ \cite{deverna2024identifying}. In our scenario, the $h$-index for a user $i$ is defined as the maximum value of $h$ such that user $i$ posted at least $h$ tweets containing AIGC, each retweeted at least $h$ times. This metric captures both the volume of AI-generated content shared and the engagement received by each post. A superspreader must meet both criteria: a high number of tweets containing AI-generated content and a significant volume of received retweets. This ensures that superspreaders are identified based on both their activity and the broader impact of their AI-generated content on the platform.
% do we need to mention top 1\% users here?

\subsection{Characterizing AIGC Superspreaders}

We characterize superspreaders of AI-generated content based on three key metrics: The \textit{AI score} quantifies the proportion of AI-generated content in a user's posts. The \textit{bot score} evaluates the probability of an account being automated based on its historical tweet activity. Finally, the \textit{language toxicity} metric evaluates the degree of toxicity present in a user's shared content.

\subsubsection{AI Score.}
To quantify the proportion of AI-generated content in a user's tweets, we introduce a new metric called the \textit{AI score}, defined as:
\[
r_i = \frac{A_i}{T_i},
\]
where $A_i$ is the number of tweets containing AI-generated text (for AI text sharers) or at least one AI-generated image (for AI image sharers), and $T_i$ is the total number of tweets or tweets containing an image shared by the user $i$ during the observation period. This metric captures the dominance of AIGC in a user's shared posts, with higher AI scores indicating a greater reliance on AIGC, whether in text or image. We compute the Pearson correlation coefficient between the AI scores of users who share both AI-generated images and texts, yielding a value of 0.20 ($p < .001$), indicating a weak positive relationship. This suggests that AI text and image sharers exhibit distinct behaviors, with few users actively sharing both types of content.

\subsubsection{Bot Score.}
We use the bot score metric to assess the likelihood of an account being automated. Bot scores are calculated using the widely adopted tool Botometer \cite{ferrara2016rise}, which evaluates various account features, such as tweet content, network interactions, and posting behavior. A machine learning model then assigns a score ranging from 0 to 1, where higher scores indicate a greater likelihood of automation. Notably, Botometer relies on the Twitter V1 API \cite{yang2020scalable} to retrieve historical account data. Since this API was discontinued in 2023, we can only retrieve bot scores for accounts created prior to May 2023.

\subsubsection{Language Toxicity.}
To examine the prevalence of toxic language among target users, we draw from the Google Jigsaw Perspective API \cite{lees2022new}, a machine learning tool designed to identify and manage harmful or abusive content on online platforms. The API assigns a toxicity score to each tweet, ranging from 0 to 1, with higher scores indicating a greater likelihood of rude or harmful language. This analysis focuses exclusively on English-language tweets. To calculate a user's overall toxicity level, we average the toxicity scores of all the tweets they have posted.
% do we need to say how many we have filtered out after 2023.5?

\section{Results}

\subsection{RQ1: Prevalence and Concentration of AIGC}
Investigating the prevalence of AI-generated content involves two key questions. On the one hand, we aim to reveal the proportion of AI-generated texts versus images on $\mathbb{X}$. On the other hand, we seek to determine the proportion of users sharing AI-generated texts versus images. The former analysis focuses on the number of tweets and images, while the latter emphasizes the activity distribution among users.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{images/prevalence_V2.png} % Image file name
    \caption{Daily proportions of AI-generated texts and images relative to all tweets and images} % Image caption
    \label{prevalence} % Label for cross-referencing
\end{figure*}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.9\linewidth]{images/supersharers_V3.png} % Image file name
    \caption{Cumulative percentage of total AI-generated texts and images shared by text and image spreaders} % Image caption
    \label{inequality} % Label for cross-referencing
\end{figure}

% Figure~\ref{prevalence} illustrates that the proportion of AI-generated texts remains consistently low, ranging from 1.18\% in September to 1.49\% in August, with minor fluctuations over the three months. In contrast, the proportion of AI-generated images is significantly higher, peaking at 13.72\% in August, followed by 12.74\% in September and 11.48\% in July. 
Overall, approximately 1.37\% of the tweets related to the 2024 U.S. Election on $\mathbb{X}$ contain AI-generated text, whereas 12.33\% of images are AI-generated. This indicates that AI-generated images are nearly ten times more prevalent than AI-generated texts, highlighting the greater prominence of visual AI-generated content on $\mathbb{X}$. Figure \ref{prevalence} highlights the daily proportions of AI-generated texts and images relative to all tweets and images, respectively. AI-generated images consistently show a significantly higher prevalence compared to AI-generated texts, with a daily mean of 12.25\% for images and 1.06\% for texts. The proportion of AI-generated texts remains stable over time with minimal fluctuations, while AI-generated images show greater variability, including notable spikes and dips, reflecting episodic surges in usage. This highlights the dominance of images over texts in prevalence and suggests more dynamic sharing behavior for images. Additionally, the low Pearson correlation coefficient (0.07, $p = .55$) indicates that the sharing activities of the two modalities are largely independent and follow distinct patterns. This finding is consistent with the earlier observation that the correlation between the AI scores of users who share both AI-generated images and texts is also relatively low. This further underscores the distinct patterns of AI-generated content sharing within the two modality groups.

In terms of users sharing AIGC, among the 3,108,782 users who shared at least one tweet containing text, only 5.5\% are AI text sharers. In contrast, 23.23\% of the 379,025 users who shared at least one image are AI image sharers. The substantially higher proportion of users sharing AI-generated images suggests that these visuals may have a broader appeal compared to AI-generated text.

We next compare the distributions of text sharers and image sharers. As shown in Figure \ref{inequality}, approximately 3\% of text sharers are responsible for 80\% of the total AI-generated texts shared, while 10\% of image sharers account for 80\% of the total AI-generated images shared. This suggests that AI-generated content is highly concentrated among a small subset of users in both modalities, with AI text production being significantly more concentrated than AI image production.

% The Gini coefficient for AI-text sharers is 0.45, while for AI-image sharers it is 0.58, indicating a moderate to high level of inequality in both groups~\cite{ye2024auditing}. Notably, the higher Gini coefficient among AI-image sharers suggests a more unequal distribution compared to AI-text sharers.


\begin{table}[t!]
\centering
\caption{Number of users across four groups categorized by impact and modality}
\begin{tabular}{c|c|cc}
\toprule
\multicolumn{2}{c}{} & \multicolumn{2}{c}{\textbf{Modality}} \\ 
\cmidrule(lr){3-4}
\multicolumn{2}{c}{} & Text & Image \\ 
\midrule
\multirow{2}{*}{\textbf{Impact}} & Superspreader & 175 & 128 \\
 & Non-Superspreader & 17,409 & 12,770 \\
\bottomrule
\end{tabular}
\label{tab:superspreader}
\end{table}

\subsubsection{Summary.} We present three key findings regarding the prevalence and concentration of AI-generated content. First, AI-generated images are significantly more prevalent than AI-generated texts, accounting for over 10\% of all images. Additionally, more than 20\% of users have shared at least one AI-generated image. Second, the sharing patterns of AI-generated text and images exhibit minimal correlation, suggesting distinct user sharing behaviors across modalities. Third, AIGC dissemination is highly concentrated: 3\% of text sharers account for 80\% of AI-generated texts, while 10\% of image sharers contribute 80\% of AI-generated images. Notably, AI text production is even more concentrated than AI image production.

\subsection{RQ2: AIGC Superspreader Characterization}
% do we need to present examples of profiles or hashtags statistics?
Given the inequalities presented above, in this section, we identify and characterize superspreaders among users sharing AI-generated texts and images. Using the \textit{h}-index, calculated for both text and image groups, we refer to the top 1\% of the accounts with the highest \textit{h}-index in each group as \textit{superspreaders}. This yields 175 superspreaders in the text group and 128 in the image group.

We first look into the political leanings of these superspreaders and their account verification statuses. To further analyze their content sharing behavior, we categorize users into four groups: superspreaders of AI-generated images, non-superspreaders of AI-generated images, superspreaders of AI-generated texts, and non-superspreaders of AI-generated texts, as detailed in Table \ref{tab:superspreader}. We evaluate their sharing behaviors using three metrics---AI score, bot score, and toxicity score---as outlined in the Methods section. Group-wise comparisons are conducted using the Mann-Whitney U test, with significant differences reported using \textit{p}-values where applicable.

\subsubsection{Political Affiliation.} 
One way to characterize these AIGC superspreaders is by examining their political affiliation. To achieve this, two authors manually inspect the 303 accounts. The annotation process is conducted in two steps. First, the annotators assess whether the user’s profile description indicates a clear political affiliation. Second, if an affiliation is present, they determine whether the user supports a
specific political party. After the initial round of annotations, the two encoders agree on 289 accounts (95.4\% of superspreaders, Krippendorff’s $\alpha$ = 0.90). For the remaining disagreements, a third annotator is involved, and the disagreements are resolved through a majority vote among the three annotators.

Figure \ref{stance} summarizes the annotation results. Among the 128 superspreaders in the image group, 88 have clear political affiliations, with 64 identified as right-leaning and 24 as left-leaning, while 40 users show no clear affiliation. In the text group, 10 of the 175 superspreaders have had their accounts suspended. Of the remaining 165 users, 151 exhibit clear political affiliations, with 77 identified as right-leaning and 74 as left-leaning.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{images/stance_2.png} % Image file name
    \caption{Political affiliations of AIGC superspreaders} % Image caption
    \label{stance} % Label for cross-referencing
\end{figure}

% From these results, three key findings emerge. First, a larger proportion of superspreaders are right-wing in both the image and text groups. Second, superspreaders of AI-generated images have a higher proportion of accounts without established political affiliations. Third, the difference in proportions between right-wing and left-wing superspreaders is more pronounced in the image group, while it is less noticeable in the text group.
Four key findings emerge from these results. First, superspreaders in the image group are predominantly right-leaning, with a significantly larger right-to-left ratio compared to the text group. Second, the text group shows a near balance between right- and left-leaning superspreaders, with a slight right-leaning majority. Third, a higher proportion of image superspreaders lack clear political affiliations compared to the text group. Lastly, account suspensions occur exclusively among AI text superspreaders.
% text: equal distribution; image: more right-leaning

\subsubsection{Premium Account Status.} 
Another perspective to describe superspreaders is to examine the proportion of \textit{$\mathbb{X}$ Premium subscribers}\footnote{$\mathbb{X}$ Premium: \url{https://help.x.com/en/managing-your-account/about-x-verified-accounts}}. $\mathbb{X}$ Premium subscribers (users with a blue check mark) gain additional features, such as tweet editing, longer posts, enhanced analytics, and priority in replies and searches. As shown in Figure~\ref{verified}, superspreaders consistently have a higher proportion of premium accounts than non-superspreaders across both modalities. Note that proportions are calculated considering users within each group.
Notably, superspreaders of AI-generated images have the highest proportion (82.8\%) and non-superspreaders of AI-generated texts have the lowest (34.5\%). This shows that premium accounts are more prevalent among superspreaders, particularly within the image group.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{images/blue_account_V2.png} % Image file name
    \caption{$\mathbb{X}$ Premium account proportion by modality and user impact. Proportions are calculated for each user group} % Image caption
    \label{verified} % Label for cross-referencing
\end{figure}

% \subsection{RQ3: Sharing Behaviors of Superspreaders}

% \begin{figure}[t!]
%     \centering
%     \includegraphics[width=0.5\textwidth]{images/categorize.png} % Image file name
%     \caption{User Categorization.} % Image caption
%     \label{categorize} % Label for cross-referencing
% \end{figure}
% switch into a table


\subsubsection{AI Score.} 
The AI score represents the proportion of AI-generated content shared by a user. Figure \ref{ai} shows the AI scores for the four user groups. Results show that AIGC superspreaders have significantly higher AI scores than non-superspreaders in both the image and text groups ($p < .001$), indicating greater involvement in sharing AI-generated content. This outcome is expected but not guaranteed, as hyper-active accounts do not always garner high engagement \cite{luceri2021down}.
AI image sharers consistently have higher AI scores than AI text sharers ($p < .001$), regardless of their impact, i.e., superspreader or non-superspreader users. AI scores in the image group exhibit a broader range, while scores for AI-text sharers are more concentrated between 0 and 0.2. The broader range of AI scores in the image group highlights greater variability in how users adopt and share AI-generated images, indicating a wider diversity of behaviors among AI image sharers. Moreover, the fat-tailed distribution among superspreaders, particularly in the image group, highlights the prevalence of a relevant fraction of users with high AI scores exhibiting extreme AIGC-sharing behaviors. 
% to be noted: fat tails for superspreaders, especially for AIG images

% To summarize, our analysis highlights three major findings: (1) Superspreaders are significantly more engaged in sharing AI-generated content compared to non-superspreaders. (2) AI-image sharers have a larger proportion of AI-generated content in their overall shares than AI-text sharers. (3) The broader range of AI scores in the image group underscores greater heterogeneity in the extent to which users adopt and share AI-generated images, suggesting a wider variety of behaviors among AI-image sharers.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/ai_score_V2.png} % Image file name
    \caption{Comparison of AI scores across four user groups} % Image caption
    \label{ai} % Label for cross-referencing
\end{figure}

\subsubsection{Bot Score.} 
Although the analysis using Botometer is limited to accounts created prior to the discontinuation of the Twitter API, a significant portion of our user base was successfully evaluated,  indicating that the majority of the accounts analyzed are not newly created. In particular, we assess 99 (77.3\%) superspreaders of AI-generated images, 10,415 (81.6\%) non-superspreaders of AI-generated images, 146 (83.4\%) superspreaders of AI-generated texts, and 14,871 (85.4\%) non-superspreaders of AI-generated texts.
% , following the exclusion of .

Figure \ref{bot} presents the bot scores across these four user groups. First, we can observe that superspreaders are significantly more likely to exhibit automated behavior than non-superspreaders in both the image and text groups ($p < .001$). Second, non-superspreaders of images are more likely to be automated than non-superspreaders of texts ($p < .001$), while no significant difference is observed between superspreaders of AI-generated images and texts. Third, the distribution of superspreaders is distinctly bimodal, particularly within the image group, with prominent peaks around 0.2 and 0.6, suggesting a conspicuous number of automated accounts employed in the diffusion of AIGC, especially images. Note that a high bot score (e.g., larger than 0.5) is indicative of bot-like behavior \cite{luceri2019evolution}.
%bimodal
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/bot_V2.png} % Image file name
    \caption{Comparison of bot scores across four user groups} % Image caption
    \label{bot} % Label for cross-referencing
\end{figure}

% \subsubsection{AI Score} This indicator represents the proportion of AI-generated content shared by a user. A higher AI score indicates that AI-generated content constitutes a larger proportion of all content that a user has shared. We calculate AI scores for four groups of users, and the results are shown in Figure~\ref{ai}.

% \begin{figure}[t!]
%     \centering
%     \includegraphics[width=0.5\textwidth]{images/ai.png} % Image file name
%     \caption{Comparison of AI scores across four groups.} % Image caption
%     \label{ai} % Label for cross-referencing
% \end{figure}

% According to Figure~\ref{ai}, we observe three interesting patterns. First, 
% %when fixing the independent variable as modality and comparing AI scores between superspreaders and non-superspreaders, 
% both AI text and image superspreaders exhibit significantly higher AI scores than non-superspreaders ($p < .001$), indicating that superspreaders are more actively involved in sharing AI-generated content compared to non-superspreaders. Second, when fixing the independent variable as influence and comparing AI scores across the two modalities, AI-image sharers have higher AI scores than AI-text sharers, regardless of whether they are superspreaders or not ($p < .001$). Another noteworthy aspect is that AI scores in the image group span a broader range compared to the text group. In contrast, AI scores for AI-text sharers are more concentrated in the range of 0 to 0.2.

% To summarize, our analysis highlights three major findings: (1) Superspreaders are significantly more engaged in sharing AI-generated content compared to non-superspreaders. (2) AI-image sharers have a larger proportion of AI-generated content in their overall shares than AI-text sharers. (3) The broader range of AI scores in the image group underscores greater heterogeneity in the extent to which users adopt and share AI-generated images, suggesting a wider variety of behaviors among AI-image sharers.

\subsubsection{Language Toxicity.} 
For toxicity detection, only English-language tweets are analyzed, leading to the exclusion of 171 non-superspreaders of AI-generated images and 61 non-superspreaders of AI-generated texts. A Mann-Whitney U test reveals a significant difference in toxicity scores solely between superspreaders and non-superspreaders of AI-generated texts, with non-superspreaders exhibiting higher toxicity levels ($p < .001$). No significant differences are found in toxicity scores across the other comparisons.

%Figure~\ref{toxic} illustrates the toxicity scores across the four groups.
% \begin{figure}[t!]
%     \centering
%     \includegraphics[width=0.5\textwidth]{images/toxic.png} % Image file name
%     \caption{Comparison of toxicity scores across four groups.} % Image caption
%     \label{toxic} % Label for cross-referencing
% \end{figure}

\subsubsection{Summary.} Among the AIGC superspreaders, a higher proportion of AI-image superspreaders align with conservative views, while AI-text superspreaders show a more balanced political distribution. Premium accounts are more prevalent among superspreaders, especially in the image group. When characterizing the behaviors of AIGC superspreaders, three key findings emerge: (i) AIGC superspreaders tend to share a higher proportion of AI-generated content in their profiles compared to non-superspreaders; (ii) AI image sharers demonstrate greater heterogeneity in their sharing activity of AIGC, with a significant portion of users exhibiting extreme sharing behaviors; (iii) AIGC superspreaders are more bot-like compared to non-superspreaders.
% heterogenity can be mentioned

\section{Discussion and Conclusions}
This study, grounded in the analysis of over 24.7 million tweets and 2.5 million images, investigates the prevalence and concentration of AI-generated content (AIGC) and provides an in-depth characterization of AIGC superspreaders. Four key insights emerge from our research.

\subsubsection{Finding 1: AI-generated images are more prevalent than AI-generated texts.}
Our analysis reveals that AI-generated images are ten times more prevalent than texts in the 2024 U.S. Election discussion on $\mathbb{X}$. Influencers may prefer visual content due to its ability to convey complex messages instantly and evoke stronger emotional responses \cite{li2020picture}. Furthermore, generative AI has significantly lowered the barriers to creating and sharing customized content, such as political memes \cite{chang2024generative}. While this trend highlights the increasing presence of AIGC across two modalities on social media, it also raises concerns about its potential harm. Research demonstrated that humans often struggle to distinguish AI-generated images from authentic ones \cite{lu2024seeing}, creating opportunities for misuse and weaponization of generative AI technologies, such as attacking political figures \cite{chang2024generative}, fabricating events, and disseminating misinformation \cite{kreps2022all}. 
%potentially influencing public perception and trust in democratic processes. 
These risks underscore the need for robust detection mechanisms and informed strategies to mitigate the negative impacts of AI-generated images and safeguard democratic processes.

\subsubsection{Finding 2: AIGC sharing is highly unequal and concentrated.}
The sharing of AIGC is highly skewed, with approximately 3\% of text sharers responsible for 80\% of all AI-generated texts and 10\% of image sharers accounting for 80\% of all AI-generated images. This highlights the outsized role of a small group of users in generating AIGC on social media. Interestingly, similar patterns have been observed in misinformation sharing, where a small fraction of users disproportionately spreads low-credibility content \cite{grinberg2019fake,baribi2024supersharers,deverna2024identifying,nogara2022disinformation}. For instance, \citet{grinberg2019fake} shows that 0.1\% of users share roughly 80\% of fake news. 
However, AIGC sharing appears less skewed, suggesting a broader base of users is involved in its dissemination, potentially exposing a larger audience to such content. 
These findings highlight the need for further research into the dynamics of AIGC diffusion to gain deeper insights into its reach, engagement, and influence relative to misinformation.
% These findings underline the need for further research into the dynamics of AIGC diffusion, including the role of \textit{superconsumers} (a small proportion of highly active users who account for a disproportionate share of consumption), to better understand its reach, engagement, and influence compared to misinformation.

% These findings provide important insights for future research on the dynamics of AIGC dissemination and its potential impact on social media ecosystems. By studying \textit{superconsumers} of AIGC (a small proportion of the overall user base but account for a disproportionately large share of consumption), researchers can further explore how AIGC differs from misinformation in terms of reach, engagement, and influence.

\subsubsection{Finding 3: AIGC superspreaders are more likely to be bots.}
Our results show that AIGC superspreaders have significantly higher bot scores compared to non-superspreaders, indicating that they are more likely to be automated accounts. This aligns with prior studies showing that bots play a crucial role in diffusing low-credibility content \cite{shao2018spread}, highlighting similarities between the dissemination patterns of AIGC and misinformation.
% wherein automated accounts play a crucial role in amplifying the reach and visibility of such material. 
% These patterns point to the systematic nature of AIGC diffusion, potentially driven by coordinated efforts to manipulate public perception, shape discourse, or advance specific agendas. 
% Automated accounts appear central to amplifying AIGC's reach, potentially driven by coordinated efforts to influence public discourse or advance specific agendas.
However, an intriguing discrepancy also emerges. Unlike \citet{shao2018spread}, which reported a single peak in the bot score distribution around 0.2, we discover that the distribution of bot scores among AIGC superspreaders is distinctly bimodal, particularly for image content, with two peaks at around 0.2 and 0.6. This might surface the potential coordinated activity of a subset of bots specifically targeting the dissemination of visual AIGC.
% , which implies potentially deceptive or harmful behaviors. 
Therefore, future research could look into the strategies, motivations, and coordinated actions underlying bot-driven AIGC diffusion.
% This suggests the presence of a conspicuous subset of bots specifically employed in the dissemination of AIGC, potentially reflecting their heightened role in visual content generation and diffusion. 

% These findings underscore the urgency of implementing robust detection and mitigation strategies to address the influence of automated accounts in the dissemination of AIGC. Given their ability to operate at scale and reach targeted audiences, these bots pose a significant risk of spreading misleading or harmful AI-generated content, particularly in high-stakes contexts like elections. Furthermore, understanding both the consistencies and discrepancies between AIGC and low-credibility content dissemination provides critical insights into the evolving role of bots in shaping the information ecosystem. This also lays the groundwork for future research to investigate the unique characteristics, motivations, and broader implications of bot-driven AIGC diffusion, including coordinated actions with human actors. 

\subsubsection{Finding 4: AI image sharers exhibit greater heterogeneity in AIGC sharing.}
Our analysis reveals a broader range of AI scores among users sharing AI-generated images, suggesting greater variability in how users adopt and share this content. The diversity of AI scores reflects a wider spectrum of behaviors among AI image sharers, ranging from sporadic use to highly frequent generation of AI-generated visuals. Notably, the distribution of AI scores among AI image sharers, particularly superspreaders, displays a ``fat tail,'' indicating the presence of a small yet substantial fraction of users who engage in extreme sharing behaviors. These outliers play a disproportionate role in sharing and driving engagement with their AI-generated images on social media, compared to the majority of users who share AIGC at a more moderate pace.
% while most users are moderately involved in sharing AIGCa small subset of superspreaders contributes significantly to its dissemination, potentially shaping online narratives and public discourse.
% This finding not only highlights the importance of studying outlier behaviors in the context of AIGC but also raises critical questions about the underlying motivations and strategies driving such extreme sharing patterns. Future research could delve deeper into the profiles, intentions, and impacts of these outliers to better understand their role in the broader ecosystem of AI-generated content dissemination.

\subsubsection{Limitations and Future Work}
We acknowledge several limitations in our research, which will guide future research. First, our data collection spans only three months, from July to September, excluding the critical period of Election Day. Future studies could incorporate Election Day into the analysis to explore variations in user behavior before and after this pivotal event. 
%Second, as the dataset is based on an advanced search algorithm, it predominantly comprises original tweets rather than retweets. Differentiating between users who generate AIGC and those who consistently amplify it through retweets could provide valuable insights into their distinct behaviors and roles. 
Second, while this study focuses on analyzing individual superspreaders, future research could investigate the collective behaviors of coordinated superspreaders, offering a broader understanding of their networked activity and impact on vulnerable population. Third, our research centers on characterizing superspreaders of AIGC. Expanding this scope to examine the effects on audiences, such as user engagement, emotional arousal, or behavioral changes, would be a promising direction. Lastly, this study is situated within the political context of $\mathbb{X}$; future research could extend and compare these findings to other platforms and different high-stakes scenarios, such as public health crises or misinformation campaigns.

\subsubsection{Ethical Statement}
This study investigates the behaviors of superspreaders of AI-generated content on social media, aiming to inform platform governance and public awareness. To mitigate potential societal harms, we anonymized all user data and avoided releasing granular user-level findings that could be exploited to enhance malicious content dissemination. We acknowledge the potential misuse of our findings, such as stigmatizing specific users or enabling more effective content manipulation, and have taken steps to ensure responsible data handling, access control, and reproducibility while adhering to ethical research standards.


% \section{Acknowledgments}
% Anonymized
% Work supported in part by DARPA (contract \#HR001121C0169) and the NSF (award \#2331722).

\bibliography{reference}


% \newpage
% \section{Appendix}
% a detailed validation results of image detection
% a detailed validation results of text detection

\end{document}
