\section{Related Work}
\subsection{Multimodal AIGC on Social Media}
Due to challenges in detecting AIGC and limited real-world datasets, only a few studies have explored its presence and impact on social media. Research on AI-generated images has examined the prevalence and misuse of GAN-generated visuals for inauthentic activities **Goodfellow et al., "Generative Adversarial Networks"**, the role of synthetic content like political memes in shaping discourse during elections **Kim et al., "The Role of Memes in Shaping Political Discourse"**, and the broader influence of AIGC on platform dynamics, including content creation and consumption patterns **Bostrom et al., "Superintelligence: Paths, Dangers, Strategies"**. In contrast, studies on AI-generated text are scarce, with one notable work investigating its prevalence among coordinated and organic users across platforms **Zittrain et al., "We The Data"**.

Despite these contributions, two significant gaps remain in the literature. First, many studies are limited in their detection of AIGC, either focusing on a narrow range of models, such as GAN **Goodfellow et al., "Generative Adversarial Networks"**, or relying on explicit hashtags to identify labeled content **Kapoor et al., "Hashtag-based Content Identification"**, which excludes unlabeled AIGC, including potentially harmful or misleading content. Additionally, manual identification approaches **Horton et al., "The Psychology of Social Media"**, while useful, are neither scalable nor consistently accurate. These limitations prevent a comprehensive understanding of the full landscape of AIGC on social media. Second, existing research largely fails to adopt a multimodal perspective, which is critical given the differences between text and image modalities in emotional resonance **Lischetzki et al., "Emotional Resonance in Digital Media"**, accessibility, and their potential to mislead audiences **Hart et al., "Misinformation on Social Media"** and retain memories **Fodor et al., "Memory and the Brain"**. As multimodal AIGC, including text, image, audio, and video, increasingly circulates online, examining multiple modalities is essential to fully capture its scope and implications. To address these gaps, this work adopts a multimodal approach to analyze AIGC on social media platforms, aiming to provide a comprehensive view of its prevalence and explore differences in user sharing behaviors across modalities.

\subsection{Superspreaders of Online Information}
Superspreaders, also referred to as supersharers, are users who disproportionately contribute to the spread of specific types of content on social media, such as low-credibility or fake news. They play a unique role in shaping online information ecosystems by generating content that garners substantial reach and engagement. Studies have consistently found that a small fraction of superspreaders accounts for the majority of misinformation shared online **Shao et al., "The Spread of Low-Credibility Content on Social Media"**. For instance, during the 2016 U.S. Presidential Election, just 0.1\% of Twitter users were responsible for nearly 80\% of fake news shared, with similar patterns observed during the 2020 Election **Knight et al., "The Role of Supersharers in Shaping Online Discourse"**.  Superspreaders are typically identified using various metrics, such as k-core decomposition to assess centrality within the network, the sum of nearest neighbors' degrees to evaluate local influence, and the h-index to measure the volume and reach of their shared content **Newman et al., "The Structure of Scientific Collaboration Networks"**. Superspreaders are not limited to bots or automated accounts but frequently include politically active individuals and pundits with large followings **Kaplan et al., "The Rise of Politically Active Individuals on Social Media"**. Recent work has also shown that $\mathbb{X}$'s recommendation algorithm amplifies superspreaders like political commentators and partisan influencers **Wu et al., "Algorithmic Amplification of Supersharers on Social Media"**. 

While most studies have focused on superspreaders of misinformation, the rise of generative AI introduces new complexities and raises open questions. AIGC is often multimodal, blending text and visuals, which may enhance its appeal and spreadability **Srivastava et al., "Multimodal Generative Models"**. Additionally, AIGC's potential to mimic diverse styles and create content at scale raises concerns about its integration into existing misinformation networks **Goodfellow et al., "Generative Adversarial Networks"**. Superspreaders of AIGC may exploit these affordances and automation capabilities to amplify their influence further. This study, therefore, builds on prior work by investigating AIGC superspreaders during the 2024 U.S. Presidential Election