\section{Related Work}
This section reviews studies on visualization recommendations and support for exploratory data analysis (EDA) in notebooks.

\subsection{Visualization Recommendation}
Visualization recommendation aims to generate charts with effective visual designs and data insights based on user inputs like a data table and optional analysis requirements. Existing methods can be categorized into rule-based~\cite{seedb, compassql, voyager, apt}, learning-based~\cite{vizml, data2vis, kg4vis}, and hybrid~\cite{deepeye, deepeye2,draco} approaches. Rule-based methods rely on established visualization principles, such as CompassQL, which enumerates design constraints to suggest optimal charts. Learning-based methods~\cite{vizml, data2vis, kg4vis, vislearning, table2charts} generate visualizations end-to-end, while hybrid methods combine visualization knowledge with machine learning models. For instance, Draco~\cite{draco} uses answer set programming to apply visualization rules, and DeepEye~\cite{deepeye, deepeye2} employs ranking models to select the most compelling charts from a vast design space. Recent studies~\cite{calliope, erato, datashot, dashbot, multivision, dminer, composition, pi2} focus on generating multi-view visualizations to support complex data analysis, typically from static tables. In contrast, the chart recommendations in this study initiate the analysis of dynamic EDA flows.

In computational notebooks, LUX~\cite{lee2021lux} enables users to trigger visualization recommendations with a single line of code specifying intents. Building on LUX, Solars~\cite{epperson2022leveraging} extends recommendations by considering the history of data analysis. However, these methods only recommend charts for individual tables without tracking data changes across the EDA process. Additional support is needed to connect data insights across different cells, especially when cells are executed out of order.



\subsection{Support for Exploratory Data Analysis}
Researchers have developed tools to enhance the efficiency of EDA, with a basic requirement being quick data understanding. Pandas Profiling, for instance, provides a detailed overview of data features, including missing values, distributions, and correlations through histograms and heatmaps. While static reports offer a good starting point, EDA involves evolving data, making changes hard to perceive. To address this, Datamation~\cite{datamation} and DataParticles~\cite{dataparticles} use animations to represent data changes visually. DataPilot~\cite{datapilot} learns from users' previous analyses to recommend relevant data subsets.

Users are also interested in cell dependencies when programming. Dataflow Notebook~\cite{dataflow} tracks code cell dependencies, while Fork It~\cite{forkit} supports forking and backtracking to explore alternatives. Verdant~\cite{verdant} helps users identify past analysis choices, and Head et al.\cite{messnotebook} developed an extension to clean messy code in notebooks. Recognizing that EDA is often collaborative, some researchers employ multiverse analysis\cite{multiverse, multiverseworkflow} to understand workflows, uncertainties, and flaws across different analysts. Other research focuses on aiding analysts in reusing existing code during EDA. McNutt et al.\cite{notebookaidesign} explore AI copilot design guidelines for notebooks, while NB Search\cite{nbsearch} and EDAssistant~\cite{edassistant} use semantic modeling to search for useful notebooks in code repositories.

Related work has focused on modeling data iterations during exploration. Somnus~\cite{somnus} and Comantics~\cite{comantics} parse scripts to reveal relationships between tables, but detailed data changes remain hard to track. DITL~\cite{ditl} addresses this by visualizing differences between table versions, while AutoProfiler~\cite{autoprofiler} tracks changes in variables, providing real-time data updates. These tools offer a lightweight, intuitive view of data changes, aiding further exploration. However, they lack the ability to present comprehensive dependencies between tables, making them less suitable for notebooks with many cells. Users still struggle to trace previous data states after executing multiple cells. To overcome these limitations, we propose \system{}, which keeps users aware of the overall data flow while providing detailed insights through visualization recommendations.