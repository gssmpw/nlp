\section{\system{} Construction}
\label{sec:method}

This section describes the construction of \system{}.

\subsection{Overview}

To effectively monitor the evolution of data tables throughout the EDA process, \system{} is built around three modules: flow parsing, chart recommendation, and chart tracing. 

\textbf{Flow Parsing.}
Data flow parsing aims to recognize the data tables and the relationships between them, which are important for the tracing.
With each cell execution, we identify the input tables, output tables, transformation operations, and the data columns involved in each line of scripts. 
By linking this input-operation-output triplet, we construct a dynamic graph of intermediate data tables and their relationships. 
Each data table is a node, and the transformation between them is the link. 
This ongoing parsing process offers an evolving view of the data flow.

\textbf{Chart Recommendation.}
Chart recommendation aims to identify charts that reflect data changes and insights at specific tables, serving as an entry point for understanding the EDA flow. To effectively grasp the state of data tables, we need representations that highlight the most important features, typically the key columns users focus on. In common data analysis workflows, users create visualizations with these key columns to verify transformations or guide further analysis. To streamline this process, \system{} automatically recommends charts that capture the transformations and key features of intermediate data tables after each cell execution, allowing users to quickly assess table states without manually creating visualizations.


\textbf{Chart Tracing.}
Chart tracing allows users to explore visually consistent charts throughout the entire data flow. Starting with a recommended chart for a specific table, this mechanism enables tracing both backward and forward through the EDA process using the same chart. Since these charts represent the states of key columns, tracing them reveals how these columns evolve over time. \system{} adapts the chart encodings to match the transformations of the associated data tables, ensuring that visual representations remain coherent and insightful. This approach helps users observe and understand significant changes in key column features throughout the analysis.

The following subsections explain the implementation of each module.

\subsection{Flow Parsing}
We first extract and construct data flow from notebooks, which drives our subsequent chart recommendation and tracing.
The flow of data transformation is a complex process involving a large number of operations on the levels of data tables or data items.
Moreover, there are customized functions defined by users to handle different corner cases.
Accurately parsing data transformations and semantic relationships between data tables in notebooks is extremely difficult, and it is still a frontier research topic in the area of databases and software engineering.

In this study, we primarily focused on detecting data tables in Pandas, one of the most popular EDA libraries. 
We followed the pipeline in Comantics~\cite{comantics}, a state-of-the-art data transformation inference method, to detect data transformation functions and their semantic relationship from the scripts.
Specifically, we first parse each line of scripts and extract the names of input and output tables, the names of functions, and the parameters.
The function names are then forwarded into a detection module to classify the transformation types summarized from existing studies~\cite{proactive, tablescraps}.
Then, we classify each line of the script into one transformation type without the support for chaining operations comprising multiple steps.
Moreover, we also extended Comantics to parsing of chaining operations with multiple transformations.

In computational notebooks, it is common to call a function without assignment, and the notebooks will show the outputs by default.
Such patterns also demonstrate the need to investigate the data.
Therefore, we parsed the call and stored the intermediate data table in the data flow.
In this study, the implementation of data flow extraction is based on Pandas.
To be clear, the terms data tables and nodes in the following text will also be referred to as data frames.

After the parsing, we obtain all the intermediate data tables and their data inter-related transformations.
The data flow in a computational notebook can be represented as a graph of nodes and edges. 
Each node represents a data table at a specific point in time, and each edge represents a relationship or transformation between two data tables. Importantly, a node corresponds to a snapshot of a variable's state, not the variable itself, because a variable can change throughout the analysis. For example, in the code \code{df = df + 1}, the variable \code{df} is represented by two nodes: one before the addition and one after.
We mark each node distinctly by the variable name, the executed cell id and its script line id. 


\subsection{Chart Recommendation}

After each cell execution, \system{} recommends appropriate charts for the executed cell to display the states of the variables in the cell. 
The challenge lies in recommending charts that effectively capture the key characteristics of the data state. 
In this study, the recommendation is achieved through a querying and a ranking phase.
Specifically, given a data table, we first query the table with a list of rules and generate a large number of charts.
Second, we rank the generated charts by a list of criteria. 

The querying phase involves generating charts based on transformation operations and data facts.
Previous work, such as LUX~\cite{lee2021lux}, defines a search space from which charts are recommended based on detected data facts in data tables. 
Solas~\cite{epperson2022leveraging} further employs the provenance of data transformations and columns mentioned for the recommendation.
\system{} employs a similar approach with two main factors to consider: the transformations applied to the data and the data facts contained in the data table. 

\textbf{Transformation Operations.}
Analysts frequently apply data transformations during EDA to shape their data tables for subsequent analysis. The recommended charts should reflect how these transformations impact the data. 

Previous studies~\cite{tablescraps, comantics, proactive} have presented different data transformation taxonomies. 
Specifically, Xiong et al.~\cite{comantics} introduced a comprehensive set of 30 categorized transformation operations.
Building upon this foundation, our categorization of important operations is predicated on whether the operation alters the data distribution of specific columns. 
This approach helps us identify 12 target operations (\autoref{tab:rules}). 
These operations change or create columns of the data tables. 
We develop rules to visualize these columns with appropriate charts. 
For example, the \code{replace} operation usually applies on a column and changes the distribution of the values.
We visualize the changes of the column values using a bar chart with the referred column as x, and the count of records as y. 
Taking the transformation of filling \code{NA} values as another example, showing the distribution of the transformed column using a histogram would be useful.
After the articulation with the potential operations, we obtain a list of rules that can generate charts to show the data changes of the target tables. 

\textbf{Data Facts.} 
We consider three types of data facts: distribution, correlation, and trend, and visualize these data facts with appropriate chart types (\autoref{tab:rules}). 
For distribution visualization, we derive histograms that show the data distribution of a specific column or the value distribution of a specific column aggregated by another.
For correlation visualization, we visualize the column pairs using scatterplots.
For trend visualization, we show the trend of a column by a temporal column using a line chart.
With the aforementioned charts, we generate additional charts by enhancing the charts using categorical columns with color encoding.


\begin{table*}
  \caption{Chart Recommendation Rules}
  \small
  \label{tab:rules}
  \begin{tabular}{p{1.5cm}p{4.8cm}p{1.8cm}p{5.5cm}}
    \toprule
    Factors&Description&Chart Type& Factor Values\\
    \midrule
    Transformation Operations & The chart is suitable for showing specific column value changes after the operation. & histogram, bar, line, heatmap& mutate, filter, aggregate, sort, fill, replace, unfold, extract, deduplicate, fold, separate, merge\\
    \midrule
    Data Facts & The chart is suitable for showing the data facts of specific columns. & histogram, line, scatter&distribution, trend, correlation\\
  \bottomrule
\end{tabular}
\end{table*}

\textbf{Chart Ranking.} 
\label{sec:ranking}
With the two factors above, we can generate a large number of charts for the data tables. 
Each chart is tagged with the reason for its generation (e.g., data fact of correlation or a kind of transformation).

Specifically, a single chart may be searched for multiple times. 
For example, a histogram might represent both a data transformation and a distribution fact. 
Such charts are identified when searched again and are tagged with multiple recommendation reasons. 
The final list of recommended charts is then ranked based on these tags and their encodings.
The ranking criteria, prioritized from highest to lowest, are:
\begin{itemize}[leftmargin=*]
\item Relevance to Data Transformations. Charts that reflect recent data transformations are prioritized, as they provide crucial insights into the changes.
\item Recency of Transformations. More recent transformations are given higher priority over older ones.
\item Relation to Data Distributions. Charts that represent data distributions are ranked higher, as these are commonly used for profiling and guiding further analysis.
\item Inclusion of Operated Columns. Charts that involve columns directly affected by transformations are prioritized. This includes columns that have undergone changes such as renaming, duplication, or selection.
\item Number of Tags. Charts with multiple tags are ranked higher, indicating they are relevant for several reasons.
\item Correlation Score for Scatterplots. Scatterplots with higher correlation scores are ranked higher, reflecting their importance in showing relationships between variables.
\end{itemize}

\subsection{Consistent Chart Tracing}

\system{} enables users to monitor the evolution of data states by selecting recommended charts to trace across the data flow. 
Users can choose any recommended chart under any executed cell for tracing. 
Once a chart is selected, \system{} applies the same chart types and encodings across all intermediate data tables in the flow, allowing users to observe how specific charts evolve as the data progresses.

However, due to the flexibility of data transformations, chart encodings may not always be applicable to all data tables, particularly when columns are added or deleted. 
For instance, if a new column \code{B} is created by mutating an existing column \code{A}, tracing a histogram of \code{B} backward would be impossible before the mutation, as column \code{B} did not exist. Similarly, when columns are added, backward tracing can become problematic, as the added columns can not be found in the previous data tables. 
In contrast, deleting columns would influence the forward tracing, and adding and deleting columns together would influence both. 

To address these issues, \system{} strives to maintain the tracing relationship as consistently as possible. 
If a traced chart's encoding becomes inapplicable at a certain data table, the system automatically detects the input-output relationships of the transformation and attempts to substitute the traced column with its corresponding input or output column. 
For example, if the user specifies tracing the histogram of column \code{B}, and the data flow involves creating column \code{B} from mutating column \code{A} from \code{node\_1} to \code{node\_2}, \system{} substitute the histogram of column \code{B} with the histogram of column \code{A} at \code{node\_1}. 

\system{} identifies transformation operations that may add or delete columns using the categorization from Xiong et al.~\cite{comantics}. Of the 30 transformation types, 15 have the potential to cause issues related to column addition or deletion. \system{} recognizes these operations and adjusts the tracing process accordingly, ensuring the consistent tracing of data evolution.