\section{Introduction}
Exploratory Data Analysis (EDA) is important for data workers to uncover patterns, test hypotheses, and ensure data quality before formal modeling~\cite{wongsuphasawat2019goalsEDA, behrens1997principlesEDA}. 
EDA is iterative and decision-driven, requiring data workers to frequently revisit previous states of data tables—often shown through visualizations or printed outputs—to inform and make decisions on further exploration.  
Computational notebooks, such as Jupyter Notebooks and R Markdown, are the most widely used tools for EDA~\cite{tukey1977exploratory}, as they allow for immediate feedback by executing code cell by cell, making them particularly well-suited for this iterative process.

However, these notebooks lack sufficient support for tracking the states of data tables over time. 
Data workers usually write code to monitor these states, typically through visualizations, which is time-consuming~\cite{2016dataprofile}. 
Prior research has sought to address this issue by recommending visualizations based on the latest cell's data patterns and user operations~\cite{lee2021lux, b2} or providing continuous displays of data distributions and summary statistics~\cite{autoprofiler}. 
Other works focus on visualizing changes before and after cell execution~\cite{datamation}. 
However, these approaches are limited to individual cells or localized changes, neglecting the broader context of the entire EDA process.
As EDA progresses and the code lengthens, multiple data tables exist in different states at various points, making it easy to lose track of the overall data flow. 
A global trace of these transformations is essential for understanding the full sequence of data changes. 
Existing tools require users to scroll or switch views back and forth to monitor global states, making the process cumbersome and disrupting workflow efficiency. 
This constant navigation also forces users to track each state mentally, further adding to the cognitive burden.

In this study, we introduce \system{}, a notebook library that tracks and visualizes the states of intermediate data tables throughout the entire EDA process. We propose treating charts as ``sight glasses'' for the data, allowing users to understand how data tables evolve by observing changes in the charts. This concept presents two key challenges that need to be addressed.

\textbf{Scalable tracking of the entire EDA flow.}
In a computational notebook, a single data transformation cell can produce multiple intermediate tables, making it challenging to track them all. The flexible execution of cells often results in messy, interrelated table relationships, complicating the visualization of these tables in a clear layout. To manage this, it's essential to hide less important tables and allow users to focus on those of interest.
To address this challenge, \system{} uses a code parsing method to extract and index intermediate tables along with their relationships. We then develop a graph-based visualization, where each table is represented as a node, allowing users to observe the entire EDA flow. The graph is organized in a stepped layout to reflect the execution order of cells, with user-friendly interactions to hide unnecessary nodes.

\textbf{Effective slicing the complex data space.} 
Charts that visualize specific columns offer a window into the data, revealing distributions and patterns. However, with numerous columns in a data table, the range of possible chart designs can be overwhelming. Chart recommendation~\cite{saket2018heuristics} helps narrow this range to the most insightful options. Yet, most existing methods~\cite{lee2021lux, epperson2022leveraging} focus on relationships within a single table's columns, often neglecting cross-table relationships crucial in EDA.
To conduct effective EDA, charts must maintain visual consistency across tables while highlighting their differences. To achieve this, we recommend charts that account for visual encodings and their relationship to changes in data distribution and table structure. \system{} ensures visual consistency across nodes when tracking the EDA flow with the recommended charts.


\system{} was evaluated through a series of user studies.
The studies demonstrate that \system{} can effectively recommend charts that reflect the analysis intents and summarize the whole EDA process.
The library also facilitates awareness of global data states while investigating detailed data insights with intuitive visualizations.
User feedback also reflects that our method can inform the data analysis progress and convey critical insights in the data tables.
We summarize the feedback and discuss the lessons learned to inspire future studies on EDA with computational notebooks.
The contribution of this study includes:
\begin{itemize}[leftmargin=*]
    \item a \textbf{EDA framework} using flow parsing, chart recommendation, and flow tracing to recover the whole EDA flow efficiently; 
    \item a \textbf{notebook library} provides code-free support for creating visualizations with convenient interactions for data state tracing;
    \item \textbf{user studies} evaluating the effectiveness of \system{} on both identifying code anomalies and understanding an existing script.
    \item \textbf{take-away messages} concluded from comparative user studies and user feedback on designing user-friendly EDA support tools.
\end{itemize}






