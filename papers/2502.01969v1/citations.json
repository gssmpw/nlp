[
  {
    "index": 0,
    "papers": [
      {
        "key": "devlin2018bert",
        "author": "Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova",
        "title": "{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}"
      },
      {
        "key": "lu2019vilbert",
        "author": "Jiasen Lu and Dhruv Batra and Devi Parikh and Stefan Lee",
        "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"
      },
      {
        "key": "chen2019uniter",
        "author": "Yen-Chun Chen and Linjie Li and Licheng Yu and Ahmed El Kholy and Faisal Ahmed and Zhe Gan and Yu Cheng and Jingjing Liu",
        "title": "UNITER: Learning Universal Image-Text Representations"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "bai2023qwen",
        "author": "Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and others",
        "title": "Qwen Technical Report"
      },
      {
        "key": "brown2020language",
        "author": "Tom Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared D. Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and others",
        "title": "Language Models are Few-Shot Learners"
      },
      {
        "key": "gilardi2023chatgpt",
        "author": "Fabrizio Gilardi and Meysam Alizadeh and Ma{\\\"e}l Kubli",
        "title": "ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks"
      },
      {
        "key": "raffel2020exploring",
        "author": "Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu",
        "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "key": "taori2023stanford",
        "author": "Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto",
        "title": "Stanford Alpaca: An Instruction-Following LLaMA Model"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "lu2019vilbert",
        "author": "Jiasen Lu and Dhruv Batra and Devi Parikh and Stefan Lee",
        "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "tan2019lxmert",
        "author": "Hao Tan and Mohit Bansal",
        "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "radford2021clip",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "jia2021scaling",
        "author": "Chao Jia and Yinfei Yang and Ye Xia and Yi-Ting Chen and Zarana Parekh and Hieu Pham and Quoc Le and Yun-Hsuan Sung and Zhen Li and Tom Duerig",
        "title": "Scaling Up Visual and Vision-Language Representation Learning with Noisy Text Supervision"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liu2024visual",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "dai2024instructblip",
        "author": "Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale N. Fung and Steven Hoi",
        "title": "InstructBLIP: Towards General-Purpose Vision-Language Models with Instruction Tuning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "chen2023shikra",
        "author": "Keqin Chen and Zhao Zhang and Weili Zeng and Richong Zhang and Feng Zhu and Rui Zhao",
        "title": "Shikra: Unleashing Multimodal LLM\u2019s Referential Dialogue Magic"
      },
      {
        "key": "you2023ferret",
        "author": "Haoxuan You and Haotian Zhang and Zhe Gan and Xianzhi Du and Bowen Zhang and Zirui Wang and Liangliang Cao and Shih-Fu Chang and Yinfei Yang",
        "title": "Ferret: Refer and Ground Anything Anywhere at Any Granularity"
      },
      {
        "key": "zhang2023gpt4roi",
        "author": "Shilong Zhang and Peize Sun and Shoufa Chen and Min Xiao and Wenqi Shao and Wenwei Zhang and Kai Chen and Ping Luo",
        "title": "GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "alayrac2022flamingo",
        "author": "Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katherine Millican and Malcolm Reynolds and others",
        "title": "Flamingo: A Visual Language Model for Few-Shot Learning"
      },
      {
        "key": "awadalla2023openflamingo",
        "author": "Anas Awadalla and Irena Gao and Josh Gardner and Jack Hessel and Yusuf Hanafy and Wanrong Zhu and Kalyani Marathe and Yonatan Bitton and Samir Gadre and Shiori Sagawa and others",
        "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "peng2023kosmos",
        "author": "Zhiliang Peng and Wenhui Wang and Li Dong and Yaru Hao and Shaohan Huang and Shuming Ma and Furu Wei",
        "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World"
      },
      {
        "key": "zhang2023prompt",
        "author": "Yuechen Zhang and Shengju Qian and Bohao Peng and Shu Liu and Jiaya Jia",
        "title": "Prompt Highlighter: Interactive Control for Multi-Modal LLMs"
      },
      {
        "key": "chen2023llava",
        "author": "Wei-Ge Chen and Irina Spiridonova and Jianwei Yang and Jianfeng Gao and Chunyuan Li",
        "title": "LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "cui2023holistic",
        "author": "Chenhang Cui and Yiyang Zhou and Xinyu Yang and Shirley Wu and Linjun Zhang and James Zou and Huaxiu Yao",
        "title": "Holistic Analysis of Hallucination in GPT-4V (ision): Bias and Interference Challenges"
      },
      {
        "key": "liu2024survey",
        "author": "Hanchao Liu and Wenyuan Xue and Yifei Chen and Dapeng Chen and Xiutian Zhao and Ke Wang and Liping Hou and Rongjun Li and Wei Peng",
        "title": "A Survey on Hallucination in Large Vision-Language Models"
      },
      {
        "key": "guan2023hallusionbench",
        "author": "Tianrui Guan and Fuxiao Liu and Xiyang Wu and Ruiqi Xian and Zongxia Li and Xiaoyu Liu and Xijun Wang and Lichang Chen and Furong Huang and Yaser Yacoob and others",
        "title": "HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination \\& Visual Illusion in Large Vision-Language Models"
      },
      {
        "key": "li2023evaluating",
        "author": "Yifan Li and Yifan Du and Kun Zhou and Jinpeng Wang and Wayne Xin Zhao and Ji-Rong Wen",
        "title": "Evaluating Object Hallucination in Large Vision-Language Models"
      },
      {
        "key": "wang2024mementos",
        "author": "Xiyao Wang and Yuhang Zhou and Xiaoyu Liu and Hongjin Lu and Yuancheng Xu and Feihong He and Jaehong Yoon and Taixi Lu and Gedas Bertasius and Mohit Bansal and others",
        "title": "MEMENTOS: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences"
      },
      {
        "key": "nie2024mmrel",
        "author": "Jiahao Nie and Gongjie Zhang and Wenbin An and Yap-Peng Tan and Alex C. Kot and Shijian Lu",
        "title": "MMREL: A Relation Understanding Dataset and Benchmark in the MLLM Era"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "shukang2023woodpecker",
        "author": "Shukang Yin and Chaoyou Fu and Sirui Zhao and Tong Xu and Hao Wang and Dianbo Sui and Yunhang Shen and Ke Li and Xing Sun and Enhong Chen",
        "title": "Woodpecker: Hallucination Correction for Multimodal Large Language Models"
      },
      {
        "key": "zhou2024object",
        "author": "Yiyang Zhou and Chenhang Cui and Jaehong Yoon and Linjun Zhang and Zhun Deng and Chelsea Finn and Mohit Bansal and Huaxiu Yao",
        "title": "Analyzing and Mitigating Object Hallucination in Large Vision-Language Models"
      },
      {
        "key": "lee2023volcano",
        "author": "Seongyun Lee and Sue Hyun Park and Yongrae Jo and Minjoon Seo",
        "title": "Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liu2024mitigating",
        "author": "Fuxiao Liu and Kevin Lin and Linjie Li and Jianfeng Wang and Yaser Yacoob and Lijuan Wang",
        "title": "Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"
      },
      {
        "key": "yu2024hallucidoctor",
        "author": "Yu, Q. and Li, J. and Wei, L. and Pang, L. and Ye, W. and Qin, B. and Zhuang, Y.",
        "title": "HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data"
      },
      {
        "key": "sun2023aligning",
        "author": "Zhiqing Sun and Sheng Shen and Shengcao Cao and Haotian Liu and Chunyuan Li and Yikang Shen and Chuang Gan and LiangYan Gui and Yu-Xiong Wang and Yiming Yang and others",
        "title": "Aligning Large Multimodal Models with Factually Augmented RLHF"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "sicong2023vcd",
        "author": "Sicong Leng and Hang Zhang and Guanzheng Chen and Xin Li and Shijian Lu and Chunyan Miao and Lidong Bing",
        "title": "Mitigating object hallucinations in large vision-language models through visual contrastive decoding"
      },
      {
        "key": "huo2024sid",
        "author": "Fangzhou Huo and Wenjie Xu and Zhiqi Zhang and Hao Wang and Zhi Chen and Peilin Zhao",
        "title": "Self-introspective decoding: Alleviating hallucinations for large vision-language models"
      },
      {
        "key": "qidong2023opera",
        "author": "Qidong Huang and Xiaoyi Dong and Pan Zhang and Bin Wang and Conghui He and Jiaqi Wang and Dahua Lin and Weiming Zhang and Nenghai Yu",
        "title": "Opera: Alleviating hallucination in multi-modal large language models via over-trust penalty and retrospection-allocation"
      }
    ]
  }
]