\section{Introduction}
\label{sec:intro}

\begin{figure}
    \centering
        \includegraphics[width=0.95\linewidth]{pics/drop_cnt_4.png}
        \caption{The main subject and the regions with more details are \textit{brushed} for more steps than other regions in \ourmethod{}. Each block represents a patchified latent token.}
        \label{fig:drop_cnt_map}
\end{figure}

% \begin{figure*}
%     \centering
%     \includegraphics[width=\linewidth]{pics/showcase.pdf}
    
%     \caption{(a)(b) Accelerating Lumina-Next-T2I and Stable Diffusion 3, with 30 and 28 steps separately. (c)(d) Multiple configurations of RAS outperform rectified flow in both image qualities and text-following. RAS-X stands for RAS with X sampling steps in total. (e) RAS achieves comparable human-evaluation results with the default model configuration while achieving around 1.6x speedup.}
%     \label{fig:teaser}
% \end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{minipage}{0.58\textwidth}
        % 左侧的两个子图
        \begin{subfigure}{\linewidth}
            \includegraphics[width=\linewidth]{pics/lumina_case.png}
            \caption{Lumina-Next-T2I ~~~~~~~~~~~~~~~~~~~~~~}
        \end{subfigure}
        \vfill
        \begin{subfigure}{\linewidth}
            \includegraphics[width=\linewidth]{pics/sd3_case.png}
            \caption{Stable Diffusion 3 ~~~~~~~~~~~~~~~~~~~~~~}
        \end{subfigure}
    \end{minipage}
    \hspace{0.01\textwidth}
    \begin{minipage}{0.35\textwidth}
        % 右侧的三个子图
        \begin{subfigure}{\linewidth}
            \includegraphics[width=\linewidth]{pics/lumina_fid.png}
            \caption{Lumina-Next-T2I FID RAS VS Rectified Flow}
        \end{subfigure}
        \vfill
        \begin{subfigure}{\linewidth}
            \includegraphics[width=\linewidth]{pics/lumina_clip.png}
            \caption{Lumina-Next-T2I CLIP Score RAS VS Rectified Flow}
        \end{subfigure}
        \vfill
        \begin{subfigure}{\linewidth}
            \includegraphics[width=\linewidth]{pics/human_eval.png}
            \caption{Default VS RAS (1.625x throughput for Stable Diffusion 3 and 1.561x for Lumina-Next-T2I) Human Evaluation}
        \end{subfigure}
    \end{minipage}

    \caption{(a)(b) Accelerating Lumina-Next-T2I and Stable Diffusion 3, with 30 and 28 steps separately. (c)(d) Multiple configurations of RAS outperform rectified flow in both image qualities and text-following. RAS-X stands for RAS with X sampling steps in total. (e) RAS achieves comparable human-evaluation results with the default model configuration while achieving around 1.6x speedup.}
    \label{fig:teaser}
\end{figure*}

% \begin{figure*}[bp]
%     \centering
%     % First row with two subfigures aligned using minipage
%     \begin{minipage}[t]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{pics/drop_overview.png}
%         \caption{Overview of \ourmethod{} design. Only the fast-update regions of each step are passed to the model.}
%         \label{fig:drop_overview}
%     \end{minipage}
%     \hfill
%     \begin{minipage}[t]{0.65\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{pics/dropcnt.png}
%         \caption{The main subject and the areas with more details are "brushed" for more steps in \ourmethod{}. Each block represents the patchified latent token.}
%         \label{fig:drop_cnt_map}
%     \end{minipage}
    
%     \vspace{-1em} % Add vertical space between the rows

%     % Second row with two subfigures aligned at the top
%     \begin{minipage}[t]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{pics/coefficient.png}
%         \caption{NDCG \cite{dcg, wang2013theoreticalanalysisndcgtype} for each pair of adjacent sampling steps, marking the similarities in the ranking of focused tokens ranging from 0 to 1.}
%         \label{fig:ndcg}
%     \end{minipage}
%     \hfill
%     \begin{minipage}[t]{0.65\textwidth}
%         \centering
%         % \raisebox{0.55cm}
%         % { % Adjust vertical offset to align the center
%             \includegraphics[width=\linewidth]{pics/similarity_short.png}
%         % }
%         \caption{Standardized predicted noise of each step. DiT model focuses on certain regions during each step and the change in focus is continuous across steps.}
%         \label{fig:latents}
%     \end{minipage}

%     % \caption{\ourmethod{} Overview}
%     \label{fig:main}
% \end{figure*}






% \begin{figure}[hbt] 
%     \centering 
%     \includegraphics[width=0.45\textwidth]{pics/coefficient.png} 
%     \caption{High degree of NDCG between adjacent sample steps.} 
%     \label{Fig.coefficient}
% \end{figure}


% Recently, diffusion models \cite{Ho2020diffusion, Prafulla2024diffusionbeats, Yang2019Generative, Jascha2015deep} have shown impressive abilities in multiple downstream tasks, among which Diffusion Transformer \cite{William2023DiT}(DiT)-based models have shown extraordinary abilities in vision generation tasks\cite{chen2023pixartalphafasttrainingdiffusion, chen2024pixartsigmaweaktostrongtrainingdiffusion, gao2024luminat2xtransformingtextmodality, opensora, ma2024lattelatentdiffusiontransformer, esser2024scalingrectifiedflowtransformers}. DiT inference is time-consuming because we need to repeatedly denoise the original noise sample with the DiT model.
Diffusion models (DMs) \cite{Ho2020diffusion, Prafulla2024diffusionbeats, Yang2019Generative, Jascha2015deep} have proven to be highly effective probabilistic generative models, producing high-quality data across various domains. Applications of DMs include image synthesis \cite{rombach2022high, dhariwal2021diffusion}, image super-resolution \cite{li2022srdiff, yue2024resshift, gao2023implicit}, image-to-image translation \cite{wang2022pretraining, saharia2022palette, li2023bbdm}, image editing \cite{kawar2023imagic, zhang2023sine}, inpainting \cite{lugmayr2022repaint}, video synthesis \cite{blattmann2023align, esser2023structure}, text-to-3D generation \cite{poole2022dreamfusion}, and even planning tasks \cite{janner2022planning}. However, generating samples with DMs involves solving a generative Stochastic or Ordinary Differential Equation (SDE/ODE) \cite{protter2005stochastic, hartman2002ordinary} in reverse time, which requires multiple sequential forward passes through a large neural network. This sequential processing limits their real-time applicability.

Considerable work has been dedicated to accelerating the sampling process in DMs by reducing the number of sampling steps. Approaches include training-based methods such as progressive distillation \cite{salimansprogressive}, consistency models \cite{song2023consistency}, and rectified flow \cite{liu2022flow, albergo2022building, lipman2022flow}, and training-free methods such as DPM-solver \cite{lu2022dpm}, AYS \cite{sabouralign}, DeepCache \cite{xu2018deepcache}, and Delta-DiT \cite{chen2024delta}. These methods, however, uniformly process all regions of an image during sampling, irrespective of the specific needs of different regions. Each sampling step in these methods treats every area of the image equally, predicting the noise for each region at the current time step before proceeding to the next. Intuitively, however, the complexity of different regions within an image varies: intricate foreground elements may require more sampling steps for clarity, while repetitive backgrounds could benefit from more aggressive compression of sampling steps without significant loss of quality. This suggests a potential for a more flexible sampling approach that can dynamically adjust the sampling ratio across different regions, enabling faster, yet high-quality diffusion process.

This concept is a natural progression in the evolution of DMs. From DDPM \cite{Ho2020diffusion} to Stable Diffusion XL \cite{podell2023sdxlimprovinglatentdiffusion}, diffusion models have predominantly relied on U-Nets, whose convolutional structures \cite{ronneberger2015u} necessitate uniform treatment of all image regions due to fixed square inputs. However, with the advent of DiTs \cite{William2023DiT} and the increasing exploration of fully transformer-based architectures \cite{vaswani2017attention}, the research focus has shifted towards architectures that can accommodate flexible token inputs. DiTs allow any number of tokens to be processed flexibly, opening up new possibilities. This shift has inspired us to design a new sampling approach capable of assigning different sampling steps to different regions within an image.

To further explore the feasibility of this idea, we visualized several diffusion process outputs at varying sampling steps (Figure \ref{fig:latents}). We observed two key phenomena: (1) the regions of focus in adjacent steps exhibit considerable continuity during the later stages of diffusion, and (2) in each sampling step, the model tends to focus on specific semantically meaningful areas within the image. This pattern is akin to the process of an artist completing a painting in 1000 steps on a blank canvas, where each step involves a different brush stroke that selectively refines certain areas. This observation suggests that in each adjacent step, the "brushes" used by the diffusion model are similar, and hence, the areas they refine remain consistent. Thus, areas that the model momentarily ignores could potentially be excluded from the computationally intensive DiT processing, allowing the model to focus more on regions of immediate interest.

To validate this hypothesis, we conducted an experiment where we identified the ranking of tokens at each diffusion step using the metric of output noise we introduced, representing regions of primary focus for the model. By calculating the similarity of token rankings using NDCG (Figure \ref{fig:ndcg}), we found a high degree of continuity in the areas of focus between adjacent steps. This continuity motivated us to design a sampling approach that assigns different sampling ratios to different regions based on their attention continuity.


\begin{figure*}[htbp]
    \centering
        % \raisebox{0.55cm}
        % { % Adjust vertical offset to align the center
            \includegraphics[width=\linewidth]{pics/similarity.png}
        % }
        \caption{Visualization of predicted noise of each step. DiT model focuses on certain regions during each step and the change in focus is continuous across steps.}
        \label{fig:latents}
\end{figure*}

As is shown in Figure \ref{fig:drop_overview}, our method leverages the output noise from the previous step to identify the model's primary focus for the current step (fast-update regions), allowing only these regions to proceed through DiT for denoising. Conversely, for regions of less interest (slow-update regions), we reuse the previous step's noise output directly. This approach enables regional variability in sampling steps: areas of interest are updated with higher ratio, while others retain the previous noise output, thus reducing computation. After each local update, the updated regions' predicted noise values change, forming the noise map for sampling in the current step, which also serves as the selection criterion for the next fast-update regions. This operation restricts the tokens processed by DiT to those in the model's current area of focus, enhancing image refinement efficiency.

\begin{figure}[htbp]
    % First row with two subfigures aligned using minipage
    \centering
        \includegraphics[width=\linewidth]{pics/coefficient.png}
        \caption{NDCG \cite{dcg, wang2013theoreticalanalysisndcgtype} for each pair of adjacent sampling steps is high throughout the diffusion process, marking the similarities in the ranking of focused tokens ranging from 0 to 1. }
        \label{fig:ndcg}
\end{figure}

For each input \( X_t \), we select a fast-update rate to determine the regions needing updates in each step, while regions in the slow-update regime retain the previous noise output, which, combined with the updated fast-region noise, forms \( X_{t-1} \) for the next step. To maintain global consistency, we keep features from slow-update regions as reference keys and values for subsequent steps. Although the fast-region selection is dynamic and recalculated after each update to prioritize significant areas, we periodically reset the inference for all regions to mitigate cumulative errors.

In summary, we propose \ourmethod{}, the first diffusion sampling strategy that allows for regional variability in sampling ratios. Compared to spatially uniform samplers, this flexibility enables our approach to allocate DiT's processing power to the model's current areas of interest, significantly improving generation quality within the same inference budget. As shown in Figure \ref{fig:teaser} (c)(d), our method achieves substantial reductions in inference cost with minimal FID increase, while outperforming the uniform sample baseline in terms of FVD within equivalent inference times. Figure \ref{fig:teaser} (a)(b) also demonstrates that with models like Lumina-Next-T2I \cite{gao2024luminat2xtransformingtextmodality} and Stable Diffusion 3 \cite{esser2024sd3}, our method's fast-region noise updating yields over twice the acceleration with negligible image quality loss. A user study comparing our method to uniform sampling across various generated cases further shows that our method maintains comparable generation quality at 1.6x the acceleration rate.





\begin{figure}[htbp]
    % First row with two subfigures aligned using minipage
        \centering
        \includegraphics[width=0.8\linewidth]{pics/drop_overview.png}
        \caption{Overview of \ourmethod{} design. Only current fast-update regions of each step are passed to the model.}
        \label{fig:drop_overview}
\end{figure}



% Graph 2, introducing existing t2i speedup methods and explain why they cannot be used in SOTA DiT models.

% Graph 3, introducing what we observe (the patterns in the softmax attn score and the similarity between diffusion steps) and what our methods are.
% \subsection{Observation and motivation}

% Based on observations of inter-step similarities and the distribution of differences in the diffusion process (a figure for analysis would be needed):
% 1. The regions where the model eDiTs at each step are continuous across steps but spatially sparse.
% 2. By leveraging patterns from previous steps, we can effectively identify the focus regions for the current step.
% 3. This allows for a lossless reduction in the input tokens for DiT since transformer allows dynamic input length.

% In conclusion, the contribution of this paper can be summarized below:
% \begin{itemize}
%     \item We observe the inter-step similarities and the distribution of differences in the diffusion process and found that the patterns from the previous step can be utilized in following timesteps.
%     \item Based on the insights, we propose a novel Token Skip strategy, which can largely improve the throughput of the generation process while bringing little harm to the accuracy without any fine-tuning required.
%     \item We propose an efficient end-to-end implementation of the novel algorithm
%     \item Through experiments, we evaluate the effectiveness of XXX and prove that xxxx.
% \end{itemize}