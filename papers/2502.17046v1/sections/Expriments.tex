\section{Experiments}
\label{sec:exp}
This section presents the experimental setup used to evaluate our proposed MA2RL and compare it against baselines. We conduct various multi-agent tasks to answer the following questions: (\textbf{Q1}) Can MA2RL effectively utilize global information and facilitate learning efficiency in complex multi-agent tasks and multi-task problems? (Section ~\ref{subsec:multi-task}) (\textbf{Q2}) Are masked autoencoders generalizable learners for MARL? And can the reduction of partial observability impact enhance the generalization and transferability of models?? (Section ~\ref{subsec:generalization})(\textbf{Q3}) How can we better leverage the latent representation of all masked entity-observations to enhance MA2RL's performance? (Section ~\ref{subsec:ablation})
\subsection{Experimental Setup}
\label{sec:exp_setup}
To evaluate the effectiveness of MA2RL, we conduct experiments with different scenarios and settings on two classical partially observed environments: StarCraft Multi-Agent Challenge (SMAC)~\cite{samvelyan2019starcraft} and MPE~\cite{lowe2017multi}. In SMAC and MPE, the policy network controls agents to perform decentralized actions. Thus, partial observability, to some extent, hinders the performance and generalization of the policy network. Our approach not only focuses on asymptotic performance in single-task settings but also on multi-task settings, as well as zero-shot generalization and transferability.

\textbf{Baselines:}We compare MA2RL with DT2GS~\cite{Decompose_Tian}, UPDeT~\cite{hu2021updet} and ASN\cite{wang2019action}. MAPPO~\cite{yu2022surprising} is added to the asymptotic performance experiment in single-task settings. DT2GS is chosen because it is the SOTA method and possesses sound zero-shot generalization capability across tasks by maintaining consistent yet scalable semantics. It is also used in the attentive action decoder in MA2RL. UPDeT develops a multi-agent framework based on the transformer block to adapt to tasks with varying observation/state/action spaces. ASN considers the semantic difference of actions and forms a foundation of generalizable models in MARL. Similar to the settings in DT2GS~\cite{Decompose_Tian}, our experiments use "ASN\_G" to denote the generalizable ASN. The criteria for choosing baselines depend on whether they can be applied across tasks in MARL or state-of-the-art methods.

\textbf{Architecture, Hyperparameters, and Infrastructure}:We implement MA2RL based on the codebase of MAPPO and DT2GS. The hyperparameters for MA2RL and baselines are presented in Table ~\ref{network_hyper} and Table ~\ref{algorithm_hyper}. With the model hyperparameters and training configurations above, a single job of MA2RL tasks up to 6 hours training on most of the SMAC maps, on a single machine of AMD EPYC 7742 CPU@2.25GHz with 64 CPU cores and eight RTX 3090 GPU. In practice, we use cluster with similar hardware to launch multiple jobs in parallel.
\begin{table*}[!ht]
    \centering
    \caption{Network hyperparameters used for MA2RL and baselines}
    \begin{tabular}{ccc}
    \hline
        \textbf{Hyperparameters} & \textbf{Value} & \textbf{Algorithms} \\ \hline
        hidden layer dimension of Encoder & 8 & MA2RL, DT2GS \\ 
        MLP's hidden layer dimension  & 64 & MA2RL, DT2GS, UPDeT, ASN\_G, MAPPO \\ 
        attention's hidden layer dimension & 64 & MA2RL, DT2GS, UPDeT, ASN\_G \\ 
        attention heads & 3 & MA2RL, DT2GS, UPDeT, ASN\_G \\ 
        number of subtasks/skills & 4 & MA2RL, DT2GS \\ \hline
    \end{tabular}
    \label{network_hyper}
\end{table*}

\begin{table*}[!ht]
    \centering
    \caption{Algorithm hyperparameters used for MA2RL and baselines}
    \begin{tabular}{cccccc}
    \hline
        \textbf{Hyperparameters} & \textbf{Value} & \textbf{Hyperparameters} & \textbf{Value} & \textbf{Hyperparameters} & \textbf{Value} \\ \hline
        optimizer & Adam & huber delta & 10 & use orthogonal & True \\ 
        learning rate & 0.0005 & clip param & 0.2 & clip param & 0.2 \\ 
        rollout threads & 24 & gae lambda & 0.95 & value\_loss\_coef & 1 \\ 
        num mini batch & 8 & use gae & True & gamma & 0.99 \\ 
        use valuenorm & True & gain & 0.01 & gae\_lambda & 0.95 \\ \hline
    \end{tabular}
    \label{algorithm_hyper}
\end{table*}



\subsection{Performance on single-task and multi-task settings}
\label{subsec:multi-task}
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/Images/generalization.pdf}
    \caption{The zero-shot generalization capability of MA2RL and its baselines, including DT2GS, UPDeT, ASN\_G, was compared across various source and target tasks. The evaluation was conducted on 6 zero-shot settings and the horizontal axis represent the source task $\rightarrow$ the target task, where (a) 2s3z$\rightarrow$3s5z, (b) 3s\_vs\_4z$\rightarrow$3s\_vs\_5z, (c) 3s5z$\rightarrow$3s5z\_vs\_3s6z , (d) 8m\_vs\_9m$\rightarrow$5m\_vs\_6m, (e) 10m\_vs\_11m$\rightarrow$8m\_vs\_9m, (f) 5m\_vs\_6m$\rightarrow$10m\_vs\_11m}.
\label{fig:generalization}
\end{figure*}
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/Images/generalization_ablation.pdf}
    \caption{The zero-shot generalization capability of MA2RL and ablations.}
\label{fig:generalization_ablation}
\end{figure*}


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/Images/transfer.pdf}
    \caption{The transferability of MA2RL and its baselines, including DT2GS, UPDeT, ASN\_G, was compared across various source and target tasks.}
\label{fig:transfer}
\end{figure*}
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{Figures/Images/ablation.pdf}
    \caption{Ablation studies. MA2RL\_w/o\_De, it only removes the usage of latent representation of all masked entity-observation in attentive action decoder and MA2RL\_w/o\_Re, it is not reuse the VAE decoder in the attentive action decoder.}.
\label{fig:ablation}
\end{figure*}

\begin{table*}[ht]
    \centering
    \caption{The table shows a comparison of zero-shot generalization capability between baselines in MPE. "3->2" indicates that the source task is set by 3 agents and 3 landmarks, while the target task is 2 agents and 2 landmarks.}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{source/target} & \textbf{MA2RL} & \textbf{DT2GS} & \textbf{UPDeT} & \textbf{ASN\_G} \\ 
        \hline
        3>2 & \textbf{-110.10 $\pm$ 4.61} & -113.06 $\pm$ 4.06 & -113.74 $\pm$ 3.35 & -157.55 $\pm$ 11.37 \\ 
        3>4 & \textbf{-273.96 $\pm$ 3.18} & -283.28 $\pm$ 7.35 & -288.11 $\pm$ 7.11 & -339.91 $\pm$ 8.75 \\ 
        3>5 & \textbf{-374.37 $\pm$ 5.83} & -377.99 $\pm$ 7.47 & -381.72 $\pm$ 8.34 & -485.12 $\pm$ 33.23 \\ 
        3>6 & \textbf{-477.23 $\pm$ 1.33} & -483.68 $\pm$ 8.53 & -488.97 $\pm$ 11.20 & -572.85 $\pm$ 11.64 \\ 
        \hline
    \end{tabular}
    \label{mpe_zeroshot1}
\end{table*}

\begin{table*}[t]
    \centering
    \caption{The figure shows a comparison of zero-shot generalization capability between baselines in MPE. "4->2" indicates that the source task is set by 4 agents and 4 landmarks, while the target task is 2 agents and 2 landmarks.}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{source/target} & \textbf{MA2RL} & \textbf{DT2GS} & \textbf{UPDeT} & \textbf{ASN\_G} \\ 
        \hline
        4>2 & -111.27 $\pm$ 1.49 & \textbf{-111.07 $\pm$ 3.17} & -111.43 $\pm$ 4.25 & -117.15 $\pm$ 3.35 \\ 
        4>3 & \textbf{-185.78 $\pm$ 1.73} & -190.55 $\pm$ 4.69 & -192.18 $\pm$ 6.72 & -214.54 $\pm$ 9.71 \\ 
        4>5 & \textbf{-363.2 $\pm$ 2.76} & -368.46 $\pm$ 5.46 & -373.69 $\pm$ 8.73 & -431.35 $\pm$ 7.26 \\ 
        4>6 & \textbf{-468.67 $\pm$ 5.04} & -473.96 $\pm$ 7.85 & -479.84 $\pm$ 7.85 & -570.85 $\pm$ 18.52 \\ 
        \hline
    \end{tabular}
    \label{mpe_zeroshot2}
\end{table*}
Asymptotic performance and sample efficiency are the most fundamental evaluation metrics for a model. Therefore, we first evaluate MA2RL and the baselines on hard and superhard maps in SMAC. As shown in Fig.\ref{fig:single_task}, MA2RL obtains the best performance on most of the maps, particularly in hard and superhard maps such as 5m\_vs\_6m, 6h\_vs\_8z, 3s5z\_vs\_3s6z, 3s\_vs\_5z. It is worth noting that MA2RL outperforms all the baselines by the largest margin on the above-mentioned maps, which have numerous entities and suffer severely from partial observations. The results indicate that MA2RL can effectively model and infer information about masked entities through MAE. While DT2GS improves asymptotic performance and generalization capability through scalable semantics, the learning of semantics suffers severely from partial observations. MA2RL shows a faster increasing trend in win rate, which may be attributed to its inference regarding global states. Additionally, MA2RL exhibits lower variance in learning curves, indicating that modeling the masked entities can mitigate the impact of partial observability and enhance training stability.To further evaluate the proposed method in cooperative multi-agent settings, We conducted asymptotic performance experiments on Spread in MPE. As pepicted in Fig.~\ref{fig:asymptotic_mpe}, MA2RL outperforms all the baselines, whose curves rise earliest and fastest.

MA2RL decomposes observations into entity observations and applies MAE from the perspective of entities, naturally forming a cross-task generalizable model structure. Subsequently, we apply MA2RL in multi-task settings to further demonstrate the generalization and representation capability across tasks. We conduct two multi-task settings with different distributions of difficulty: \textit{stalker\_zealot}-series tasks (easy, easy, superhard) and \textit{marine}-series tasks (hard, hard, hard). In each multi-task setting, the policy interacts synchronously with multiple tasks and updates the policy using a mixed experience replay buffer. As shown in Fig.~\ref{fig:multi_task}, MA2RL exhibits the fastest convergence and highest win rate among the compared methods (DT2GS, UPDeT, ASN\_G). DT2GS and UPDeT closely follow MA2RL in asymptotic performance. ASN\_G fails to win in the hard multi-task setting. Similarly, in the single-task setting, MA2RL displays a lower variance across random seeds.

\subsection{Masked Autoencoders are generalizable Zero-shot \& Few shot learners}
\label{subsec:generalization}
Improving zero-shot generalization capability is the fundamental motivation behind our design. MA2RL employs MAE from the perspective of entities, aiming to alleviate the degradation of generalization caused by partial observability in MAS. We evaluate the generalization capability of MA2RL and the baselines in six different settings, each of which includes a target task that is either more difficult or equally difficult compared to the source task. Fig.~\ref{fig:generalization} shows that MA2RL outperforms all baselines in terms of zero-shot capability, especially in settings with uncertainty resulting from partial observability (e.g. 2s3z$\rightarrow$3s5z, 8m\_vs\_9m$\rightarrow$5m\_vs\_6m). These indicate that MA2RL's applying MAE from the entity perspective can effectively address the challenges of partial observation and varying observation/state/action spaces in MARL, thus effectively improving generalization. We also conducted zero-shot experiments on Spread in MPE and the results of the zero-shot experiments are presented in Table ~\ref{mpe_zeroshot1} and Table ~\ref{mpe_zeroshot2}. In the Table ~\ref{mpe_zeroshot1} and ~\ref{mpe_zeroshot2}, "4>2" in the column of "source/target" indicates that the source task is set by 4 agents and 4 landmarks, while the target task is set by 2 agents and 2 landmarks.

In conclusion, MA2RL is a generalizable zero-shot learner that can successfully transfer the ability to infer masked entity-observations to new tasks without requiring fine-tuning. Additionally, Fig.~\ref{fig:transfer} demonstrates that MA2RL has more transferabilty than baselines regarding asymptotic  performance and time to threshold.

\subsection{Ablations}
\label{subsec:ablation}
We carry out ablation studies to investigate how to leverage better the latent representation of all masked entity observations and access MAE's contributions in MARL. We compare MA2RL against four ablations:(1) \textit{MA2RL\_w/o\_De}, which excludes the utilization of the latent representation of all masked entity-observations in the attentive action decoder. (2) \textit{MA2RL\_w/o\_Re}, which does not reuse the VAE decoder in the attentive action decoder. (3) \textit{DT2GS}, which removes all components related to MAE. In these ablations, all other structural models are kept consistent strictly with the full MA2RL. Fig.~\ref{fig:ablation} shows ablation results on four representative maps. The results demonstrate that the design of reusing decoder in VAE and MAE are essential for MA2RL's capability. Specifically,  MA2RL\_w/o\_De slightly improves performance compared to DT2GS, confirming that MAE in MA2RL facilitates better assignment of individual skills to tackle complex tasks. Significantly, MA2RL\_w/o\_Re exhibits severe performance degradation compared to MA2RL, indicating that the reuse of the VAE decoder can effectively leverage the mapping relationship between latent space and observation space. The reuse of the VAE decoder effectively connects the two components.

To further verify the role of each module in MA2RL for policy generalization, we add zero-shot experiments in the ablation studies, as illustrated in Fig.~\ref{fig:generalization_ablation}. The results demonstrate the effectiveness of different components in MA2RL from both the aspects of generalization and asymptotic performance:
\begin{itemize}
    \item generalization: MA2RL significantly outperforms DT2GS by a large marin, demonstrating the excellent generalization of MA2RL. The comparison between MA2RL and MA2RL\_w/o\_De shows that using the inferred mask information can learn skill semantics with stronger generalization.
    \item asymptotic performance: MA2RL does not introduce additional hyperparameters. All parameter settings are consistent with the baselines, thus the designed MAE can improve the asymptotic performance to some extent. Additionally, MA2RL can greatly enhance generalization without damaging the asymptotic performance, and even improve the asymptotic performance in some difficult tasks (e.g. 5m\_vs\_6m, 6h\_vs\_8z).
\end{itemize}

