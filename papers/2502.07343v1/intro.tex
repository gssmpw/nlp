% \vspace*{-0.2cm}
\section{Introduction}
\label{sec:intro}
Nearest Neighbor Search (NNS) in high-dimensional Euclidean space has been a fundamental component of many applications, including {\cheng databases~\cite{milvus2021, pan2024vector}}, information retrieval~\cite{ANNForIR, ANNForDPR}, data mining~\cite{ANNForDM}, recommendation systems~\cite{ANNForRS}, and generative artificial intelligence (GAI)~\cite{zhao2024retrievalaugmented}. However, due to the curse of dimensionality~\cite{curse1, curse2}, existing NNS methods~\cite{Jagadishidistance2005} often fail to meet practical efficiency requirements. To address this, Approximate Nearest Neighbor Search (ANNS) has been proposed, %and extensively studied~[xx]
%which aims to find approximate nearest neighbors, 
trading off some accuracy for significantly improved efficiency~\cite{li2020improving}.
%
%To address the ANNS problem, various %approximate nearest neighbors search 
%techniques have been proposed, such as tree-based methods~[xx], hashing-based methods~[xx], quantization-based methods~[xx], and graph-based methods~[xx].

Over the past decades, various ANNS techniques have been proposed~\cite{arora2018hdindex, BeygelzimerKL06Covertree, RamS19kdtree,wangSurveyLearningHash2018, hash2014survey, jegouProductQuantizationNearest2011, gongIterativeQuantizationProcrustean2013, DBLP:journals/pami/GeHK014,gao2024rabitq,wang2021comprehensive}, such as tree-based methods~\cite{arora2018hdindex, BeygelzimerKL06Covertree, RamS19kdtree}, hashing-based methods~\cite{wangSurveyLearningHash2018, hash2014survey}, quantization-based methods~\cite{jegouProductQuantizationNearest2011, gongIterativeQuantizationProcrustean2013, DBLP:journals/pami/GeHK014,gao2024rabitq}, and graph-based methods~\cite{wang2021comprehensive,fu2019fast,DBLP:journals/pami/FuWC22,DBLP:journals/is/MalkovPLK14,DBLP:conf/cvpr/HarwoodD16,malkovEfficientRobustApproximate2020}. %According to experimental evaluations~[xx]
Among them, graph-based methods provide superior performance compared to other methods~\cite{wang2021comprehensive,liApproximateNearestNeighbor2020}. %Given a database $D$, %with $N$ objects, 
%Graph-based %algorithms 
These methods construct a graph %$G(V, E)$ 
to index the dataset%$D$
, where each node %in $V$ 
corresponds to an object in dataset %$D$ 
and two nodes are associated with an edge if their distance satisfies some proximity property. %During the query phase
At query time, a greedy search algorithm~\cite{fu2019fast,malkovEfficientRobustApproximate2020,wang2021comprehensive} is used to find approximate nearest neighbors. %in the graph. 
%Existing 
Most state-of-the-art graph-based ANNS indexes are constructed by approximating
%based on 
the Relative Neighborhood Graph (RNG)~\cite{rng}. Its pruning strategy effectively removes some redundant edges based on edge length (distance between nodes), thereby achieving a better accuracy-efficiency tradeoff, as verified in~\cite{wang2021comprehensive} ({%\cheng 
details will be presented} in Section~\ref{sec:graph-anns}). 


In recent years, researchers {%\cheng 
started to explore various} variants of ANNS queries~\cite{pan2024vector}, in order to handle more complex real-world scenarios. 
{%\cheng 
In particular, \cite{milvus2021} studies the multi-vector query, where each object is described by multiple vectors, and the similarity score is computed by aggregating %the
each individual vector's similarity score.% for each vector.
} %\ziqi
{For instance, intelligent video surveillance systems employ different vectors to represent the front face, side face, and posture of each individual recorded by the camera~\cite{baltruvsaitis2018multimodal}, which will subsequently be used for person identification.}
% For instance, on online shopping platforms, products may have tags in addition to descriptions, such as shipment (free shipping or not) and target audience (men, women, or children).\ziqi{ To address this, \cite{wei2020analyticdbv} introduces a hybrid ANNS query with attribute filtering, to retrieve similar vectors that satisfy boolean predicates over their attributes.} %In this case, product descriptions and query keywords can be transformed into vectors, while tags serve as filtering attributes. 
% {\cheng Another example} is {\cheng that in} social networks, such as Instagram and Pinterest, 
% % where 
% many posts contain textual and visual information, and users search {\cheng them} using both {\cheng their} images and keywords (in particular, their corresponding learned embeddings/vectors). 


% To handle this case, \cite{milvus2021} proposed a multi-vector query, where each object is described by multiple vectors, and the similarity score is computed via the aggregate scores of each vector's similarity.

In this {%\cheng 
paper}, we investigate the Hybrid Vector Query (\hvq), which {%\cheng 
is one kind of} multi-vector query, {%\cheng 
where each object involves} two vectors. {%\cheng 
Specifically,} an \hvq aims to retrieve the approximate nearest neighbors according to the weighted sum of the distances {%\cheng 
based on the two} vectors, where {%\cheng 
the distance between %two 
vectors captures the dissimilarity between them and} a %user-given 
query-specific parameter $\alpha$ determines the weight of each vector's distance (as to be formulated in Section~\ref{sec:preliminary}). {%\cheng 
\hvq has many applications given the} ubiquity of bimodal data in real-life scenarios, such as image-text data~\cite{salvador2017learning,OpenImagesLocNarr,sharma2018conceptual}, spatio-textual data~\cite{chenLocationKeywordbasedQuerying2021}, and video-text data~\cite{miech19howto100m,baltruvsaitis2018multimodal}.
% affords \hvq a wide range of practical applications~\cite{baltruvsaitis2018multimodal, salvador2017learning,chenLocationKeywordbasedQuerying2021}. 
In the case of geo-textual objects, one feature vector is derived from the object's textual description using language processing techniques, such as BERT~\cite{devlin2018bert}, while the other feature vector represents its two-dimensional geographical coordinates. 
{\cheng A \hvq query can be issued} by a user {\cheng looking} for a `Japanese sushi restaurant' %that is located 
{\cheng near his/her} position, with the parameter $\alpha$ capturing the query’s preference over the trade-off between geographical proximity and semantic similarity. 
%{\cheng where the parameter $\alpha$ can be used to capture the user’s preference over} the trade-off between geographical proximity and semantic similarity. %\ziqi{When search keywords are very detailed, higher weight can be given to semantic similarity. Conversely, if a user frequently visits nearby geo-textual objects after searching, greater weight can be assigned to geographic proximity for personalized searches.} 
% \pasq{In this case, the system would dynamically adjust the parameter $alpha$, depending on the granularity level of the keywords in the current query, and on the historical preference of the user for nearby locations.} 
% In this case, it is advisable to dynamically adjust the parameter $\alpha$ {\cheng to serve users with different preferences.}
\revision{%\annotation{R2O4}
For example, machine learning techniques are used to learn a query-dependent weight $\alpha$ for a query~\cite{liu2023}, thereby better capturing the query’s preference.} 
% based on the granularity level of the keywords in the query and the user's historical preference for nearby points of interest. 
\revision{Another example is in the intelligent video surveillance scenario~ %is provided by
\cite{milvus2021}, where each person can be represented by a face vector and a posture vector. This approach can enhance the accuracy of person recognition, where the weight of each vector could be different depending on the quality of each vector, such as the resolution of the image.}

% {%\cheng 
% Another example} is {%\cheng 
% that in} social networks such as Instagram and Pinterest, 
% % where 
% many posts contain textual and visual information, and users search {%\cheng 
% them} using both %{\cheng their} 
% images and keywords (in particular, their corresponding learned embeddings/vectors). %\ziqi{The weight of each vector can depend on the quality of each feature. For example, when a search uses a particularly blurry image, a lower weight can be assigned to image similarity. This can be achieved by machine learning algorithms.}
% % \pasq{The weight of each vector would be automatically adjusted based on the quality of each feature, such as the resolution of the image, and the uniqueness of the searched keywords.}
% The weight of each vector 
% % would be automatically adjusted based 
% {\cheng could be different depending}
% on the quality of each feature, such as the resolution of the image, and the uniqueness of the searched keywords.


% \ziqi{}In the scenario of speaker identification~\cite{wu2005multi, baltruvsaitis2018multimodal}, where each person is profiled using a visual feature vector and an audio feature vector, identification can be enhanced by considering the similarity of both vectors. The quality of each feature determines the weight of its respective vector. 




% {\color{red} As users might dynamically specify different $\alpha$ values based on their needs and scenarios, the \hvq needs to find approximate nearest neighbors based on both the query vectors and the query $\alpha$, which distinguishes it from traditional ANNS queries.}

% \ziqi{In fact, what we aim to solve is designing an ANNS index for the hybrid vector query problem. Existing ANNS indexes are developed for the single vector query scenario. Simply applying them to \hvq problem faces significant performance degradation.}

% \pasq{What problem are you trying to address? What you wrote above is clear and simple, but it doesn't look like there is a problem}



% However, few studies have attempted to apply them to the \hvq problem. %However, the time complexity of constructing an exact RNG is $O(N^3)$. Therefore, many ANNS indexes have been developed to approximate the RNG.

% Despite extensive studies on graph-based ANNS indexes~[xx], few studies have attempted to apply them to the \hvq problem. % research on the \hvq problem remains limited. 
\noindent\textbf{{%\cheng 
Existing methods and limitations.}} 
% {\cheng Few studies have been devoted to the \hvq problem.}
% {\cheng Only [xx] introduces} two simple methods 
% for the \hvq problem 
% by modifying existing ANNS indexes, \ziqi{which can be} integrate %them 
% with graph-based indexes for handling \hvq. %\ziqi{Specifically, }{\cheng One of them} constructs a hybrid ANNS index by setting $\alpha = 0.5$ during the indexing phase. In the query phase, it performs a search on the hybrid index. 
{%\cheng 
Two methods~\cite{milvus2021} have been proposed for the \hvq problem.} 
%\ziqi
{Specifically, {%\cheng 
the first one} constructs {%\cheng 
an ANNS index based on the weighted distance with $\alpha = 0.5$.}}
% by using the distance between two objects when $\alpha=0.5$ as their measure of distance. 
In the query phase, it {%\cheng 
simply uses this index (which is built with $\alpha = 0.5$) for handling queries (which can have arbitrary values of $\alpha$).}
{%\cheng 
The second one} constructs separate ANNS indexes, {%\cheng 
one} for each modality. During the query phase, it performs {\cheng search} on each index, retrieves similar objects in each modality, and then re-ranks {%\cheng 
all retrieved objects} to obtain the approximate nearest neighbors. 
{%\cheng 
Graph-based ANNS indexes can be %used in 
integrated with these two methods given their superior performance over other {\cheng types of ANNS index}. %(\ziqi{as to be detailed in Section~\ref{sec:motivations}}).
}\revision{%\annotation{R1O1}
Additionally, when one of the feature vectors represents geographical coordinates, \hvq 
%becomes 
%equivalent to 
can function as 
the semantic-aware spatial keyword query~\cite{qianSemanticawareTopkSpatial2018}. 
%Although some methods exist for this problem
The previous work on semantic-aware spatial keyword query~\cite{chenS2RtreePivotbasedIndexing2020,qianSemanticawareTopkSpatial2018, DBLP:conf/edbt/TheodoropoulosN24} has encountered significant efficiency challenges, largely due to the curse of dimensionality of high-dimensional semantic vectors~\cite{curse1,curse2} (as to be detailed in Section~\ref{sec:related})}.

% The above solutions share a common idea: 
{%\cheng 
The two methods~\cite{milvus2021} 
%mentioned above 
both adopt the strategy of using a fixed}
$\alpha$ value (e.g., 0 or 0.5) during the index construction phase to build the index. \textbf{This is because existing %graph-based 
ANNS indexes are constructed under the assumption that the distances between objects are certain and pre-determined%pre-determined and static
.} %\ziqi
{For instance, graph-based ANNS indexes select neighbors for each node based on the edge lengths (the distances between objects), which assumes that the edge lengths are certain and pre-determined.}
% Therefore, $\alpha$ has to be fixed 
{%\cheng 
Using a fixed $\alpha$ value} during the indexing phase {%\cheng 
would help} ensure that %\ziqi
{the distances between objects} %edge lengths
remain constant, %\ziqi
{thereby maintaining the proximity property in the ANNS indexes for the given $\alpha$ value.} %satisfy the proximity property for the given $\alpha$ value.} 
However, 
% when users dynamically adjust the query's $\alpha$ value, 
{%\cheng 
different queries can %users
have different $\alpha$ values %for the query
}
based on their needs and scenarios, the 
%edge {\cheng lengths (
distances between objects %) 
would change %} 
as well, making the proximity property %of the edges 
of the %graph 
ANNS index ineffective and leading to severe performance degradation (as to be shown in Section~\ref{sec:motivations}).

 
\noindent\textbf{Challenges.} In this {%\cheng 
paper}, we aim to develop a graph-based ANNS index that is capable of maintaining high performance for \hvq with varying 
% query 
$\alpha$ values. %{%\cheng 
%Next, we (1) elaborate on the challenges of achieving this goal and (2) present our new method by explaining how it solves the challenges.} 
The key lies in how to construct a graph-based ANNS index that is capable of handling varying $\alpha$ values, which presents three challenges: \textbf{(1) How to compute the candidate neighbor set for each node.} Existing graph-based ANNS indexes typically acquire hundreds of approximate nearest neighbors for each node as the candidate neighbor set, avoiding considering all nodes in the dataset and thereby improving construction efficiency. However, as $\alpha$ changes, the {\cheng distances between objects would change}, and the approximate nearest neighbors of each node may vary significantly. Therefore, it becomes challenging to compute a candidate set for each node that comprises the approximate nearest neighbors {\cheng for} varying $\alpha$ values. \textbf{(2) How to determine edges from the candidate set.} A key idea of existing state-of-the-art graph-based ANNS indexes is to use the pruning strategy of Relative Neighborhood Graph (RNG)
%'s pruning strategy 
to prune some redundant candidate edges based on the edge lengths, thereby determining the final edges from the candidate set. According to the experimental evaluation~\cite{wang2021comprehensive}, this pruning strategy can significantly improve search performance. % at query time
However, for the \hvq problem, the $\alpha$ value
%may 
varies at query time, making the edge lengths dynamic, and the RNG pruning strategy does not work. A straightforward solution is to fix an  $\alpha$ value to prune edges during the index construction phase. However, as the query $\alpha$ varies, the RNG's property becomes ineffective, thereby leading to significant performance degradation (as to be shown in Section~\ref{sec:motivations}). How to design a new edge pruning strategy that can maintain the RNG's property under varying $\alpha$ values is an open problem.
\textbf{(3)~How to select the seed for the graph index in the \hvq problem.}
%Additionally, 
According to~\cite{fu2019fast}, the start node (seed) of the graph impacts {%\cheng 
the search path length, which reflects} the search efficiency. To reduce the search path length, \cite{fu2019fast} proposes {%\cheng 
to use} the graph's approximate center as the seed. However, the center can vary significantly with different $\alpha$ values. 
An intuitive solution is to {%\cheng 
use} multiple approximate centers for different $\alpha$ values, but this {%\cheng 
would degrade the} search efficiency 
{\cheng since some of the start nodes may not be good one for a particular $\alpha$ value.}
% due to the multiple start nodes. 



% \textbf{The first challenge lies in the designing of the graph.} \ziqi{As stated above, existing ANNS indexes are constructed based on the assumption that the distances between objects remain static, and graph-based ANNS indexes are no exception.} These indexes face significant performance degradation when the value of $\alpha$ changes. Constructing {\cheng a specific} graph-based ANNS {\cheng index} for {\cheng each possible} value of 
% $\alpha$ is unfeasible {\cheng because the number of possible $\alpha$ values is an infinity}. Designing a graph that can maintain the proximity property of edges for a dynamically changing $\alpha$ parameter, thereby ensuring high performance across different values, remains an open problem. \textbf{A second challenge lies in the construction of the graph.} The time complexity of constructing an exact RNG is $O(N^3)$. Therefore, existing techniques~\cite{fu2019fast,malkovEfficientRobustApproximate2020} typically acquire hundreds of approximate nearest neighbors for each node as its edge candidate set and then select the final edges from the set, to approximate the RNG. With a varying $\alpha$ parameter, the approximate nearest neighbors of each node may change significantly, making it challenging to acquire the candidate set for each node. Additionally, according to~\cite{fu2019fast}, the start node (seed) of the graph impacts {\cheng the search path length, which reflects} the search efficiency. To reduce the search path length, \cite{fu2019fast} proposes {\cheng to use} the graph's approximate center as the seed. However, the center can vary significantly with different $\alpha$ values. An intuitive solution is to {\cheng use} multiple approximate centers for different $\alpha$, but this {\cheng would degrade the} search efficiency. It is another open challenge to select the seed for the \hvq problem.


\noindent\textbf{Our method.} 
%To address the first challenge, we develop a Greedy Pareto frontier search algorithm (GPS algorithm) to compute the candidate neighbor set for each node. We find that finding the nearest neighbor of a given node at any $\alpha$ value is equivalent to solving the problem of minimizing the hybrid distance function at that $\alpha$ value. Since $\alpha$ can be any arbitrary value in $[0,1]$, finding solutions for each possible $\alpha$ value becomes unfeasible. 
In the first challenge, since $\alpha$ can be any arbitrary value in $[0,1]$, finding the nearest neighbor of a given node for each possible $\alpha$ value becomes unfeasible.
To address this, we propose to treat the problem as a multi-objective optimization problem, where the distance of each individual vector is considered as an objective function. Then, we %can 
use the Pareto frontier~\cite{ma2020efficient} %as %the solution, serving 
as the candidate set, ensuring that the nearest neighbor is always within the Pareto frontier for varying $\alpha$. However, in our context, finding the exact Pareto frontier for each node is expensive. To address this, we propose the Greedy Pareto Frontier Search (GPS) algorithm. 
%
%The GPS algorithm searches over a partially built graph, as we built the graph index by incrementally inserting nodes, similar to previous studies~\cite{malkovEfficientRobustApproximate2020,DBLP:journals/is/MalkovPLK14}. It assumes that a neighbor's neighbor is more likely to be a neighbor. 
By iteratively exploring the neighbor of neighbor and searching for Pareto frontiers within the small set, GPS efficiently finds high-quality approximate Pareto frontiers.

%, which assumes that the neighbor of a neighbor is more likely to be a neighbor. It iteratively explores the neighbors of neighbors and searches for Pareto frontiers within a small set, thereby efficiently finding high-quality approximate Pareto frontiers.


To handle the second challenge, we propose a novel dynamic edge pruning strategy. This strategy aims to maintain the property of the RNG for pruning 
at varying $\alpha$ values, as this property is essential for enhancing the search performance~\cite{wang2021comprehensive}. 
To achieve this, 
%we take $\alpha$ into account the pruning strategy of the RNG. Then 
we find that some edges {\cheng would} be pruned at certain $\alpha$ values based on the pruning strategy of RNG, while at other $\alpha$ values, they {\cheng would} be preserved. This motivates us to come up with the idea of assigning each edge {\cheng a range called \emph{active range}}, covering the 
% suitable 
$\alpha$ values for that edge, within which it {\cheng would} not be pruned by the RNG's property. During the query phase, the edge is activated only if the query's specific $\alpha$ falls within its active range; otherwise, the edge {\cheng would} be ignored. This strategy ensures that for each query $\alpha$ value, the graph can dynamically prune edges based on the RNG's property, so the remaining graph formed by the activated edges satisfies the RNG's property, thereby ensuring high performance.


% To address the first challenge, we propose a novel Dynamic Relative Neighborhood Graph (D-RNG). %To ensure that the graph 
% D-RNG aims to preserve the proximity property of edges for varying $\alpha$ values. %, D-RNG maintains edges suitable for different values in a single graph. 
% A straightforward solution is to maintain edges suitable for different values in a single graph. However, as edges suitable for different $\alpha$ values vary, maintaining all these edges within one graph {\cheng would result in a very dense} graph, 
% % which reduces efficiency if all edges are navigated 
% {\cheng affecting the search efficiency}
% at query time. To address this, we propose {\cheng to assign a range called \emph{active range}} to each edge, {\cheng covering} the suitable $\alpha$ values for that edge. During the query phase, the edge is activated only if the query's specific $\alpha$ falls within the active range; otherwise, the edge will be ignored. %we propose to assign an active range to each edge, so that the edge is activated only if the query's $\alpha$ value, specified by the user, falls into the active range; alternatively, the edge will be ignored during the query phase. 
% \ziqi{{\cheng Specifically}, we take $\alpha$ into account in the pruning strategy of the RNG
% % . Consequently, we find that edges may be pruned at certain $\alpha$ values due to the pruning strategy of RNG, while at other $\alpha$ values, they may be preserved. Therefore, according to the pruning strategy of the RNG, we assign an active range to each edge, ensuring that 
% {\cheng such that} for each $\alpha$ value, the remaining graph formed by the edges that are not ignored %with active ranges intersecting $\alpha$ 
% satisfies the property of the RNG, thereby ensuring high performance.}


% To handle the second challenge, we propose {\cheng to consider} the distances of two vectors as two objective functions and then {\cheng to use} the Pareto frontiers~[xx] of each node as the edge candidate set. %The Pareto frontier
% It ensures that for a varying $\alpha$, the nearest neighbor is always within the Pareto frontier, thereby guaranteeing that only the objects satisfying the proximity property for different $\alpha$ values are selected as candidates. 
% % However, using existing techniques to 
% {\cheng Since finding} the exact Pareto frontier for each point is very time-consuming, {\cheng e.g., it has a time} complexity of $O(N^2\log(N))$,
% % {\cheng Motivated by} this, 
% we develop a greedy Pareto Frontier Search algorithm, called the GPS algorithm. Following existing studies~[xx], we construct the graph by continuously inserting nodes. {\cheng Specifically, we use the} GPS algorithm {\cheng to search} on a partially built graph, continually exploring the neighbors of newly inserted nodes and maintaining approximate Pareto frontiers. 
% % The process terminates 
% {\cheng We stop the process}
% when no new nodes are added to the maintained approximate Pareto frontier. 
% To reduce the search path, we propose a new edge seed acquisition method that uses the nodes farthest from the graph's center as the seed. The edge seed is capable of adaptively locating the nearest seed node to the query as the start node, while implicitly abandoning other start nodes, thereby ensuring search efficiency. 

To tackle the issue of choosing appropriate seeds for the graph index, we propose a new edge seed method. This method uses nodes that are farthest from the center under varying $\alpha$ values as seeds, i.e., edge seeds. Since edge seeds are far from each other, at query time, the greedy search will automatically start from the seed node closest to the query and ignore distant seeds, thus avoiding the efficiency problem caused by multiple start nodes.

Based on these proposed techniques, we develop a novel Dynamic Edge Navigation Graph (\method). During the index construction phase, \method constructs the index by 
%continuously 
inserting nodes one by one, similar to previous methods~\cite{malkovEfficientRobustApproximate2020,DBLP:journals/is/MalkovPLK14}. For each inserted node, \method performs the GPS algorithm over the partially built graph to obtain the candidate neighbor set. Then it applies the dynamic edge pruning strategy to determine the edges from the candidate set. Finally, it checks whether each newly inserted node can update the edge seed set. At query time, \method employs a variant of the greedy search algorithm, which dynamically skips some edges based on the query's $\alpha$ value and their active ranges.







% Compared to using multiple approximate centroids, edge seed ensures that they are far from each other. In greedy search, only edge nodes close to the query are activated, while others are ignored due to their large distance, thus avoiding the efficiency issue caused by multiple start nodes.



% \ziqi{Based on the two techniques proposed above, we propose a novel Dynamic Edge Navigation Graph (\method), which is a good approximation of the D-RNG. To the best of our knowledge, this is the first work that identifies the limitations of existing methods for the \hvq problem and attempt to resolve them.} 

The main contributions of this work are summarized as follows:

\begin{enumerate}[leftmargin=*,topsep=0pt]
\item We 
%first 
analyze 
%and present 
the limitation of existing methods for the \hvq problem (Section~\ref{sec:motivations}). Specifically, these methods perform well for certain query $\alpha$ values but face significant performance degradation when the {\cheng $\alpha$ value} varies. 
%This limitation arises because existing ANNS indexes are constructed under the assumption that the distances between objects are certain and pre-determined \(Section~\ref{sec:motivations}).
%To the best of our knowledge, 
This finding
%are new and 
has not been reported in previous literature. 


\item We propose a new graph-based ANNS index called \method to maintain high performance across varying {\cheng $\alpha$ values}. It comprises three technical contributions: (i) a greedy Pareto frontier search algorithm to compute a candidate neighbor set for each node, comprising the node’s approximate nearest neighbors for varying $\alpha$ values; (ii) a dynamic edge pruning strategy that dynamically prunes edges at query time to maintain the property of the Relative Neighborhood Graph; and (iii) an 
%novel 
edge seed method. To the best of our knowledge, this is the first ANNS index designed specifically for HVQ. %and our ANNS index is able to utilize the property of RNG for prunning.

%. Meanwhile, this is also the first study that utilizes the property of the RNG to enhance the search performance of the Hybrid Vector Query.


\item We conduct extensive experiments on real-world datasets, which demonstrate that (i) \method demonstrates the best performance compared to all baselines across different $\alpha$ settings; {\cheng and} (ii) \method maintains high performance across different $\alpha$ settings without significant degradation. 

\end{enumerate}

