\section{Related Work}
\paragraph{Ambiguity Resolution in NLP} Numerous studies have focused on ambiguity in natural language tasks using strategies like generating multiple answers **Li, "Addressing Ambiguity in Text Classification"** __**, asking clarification questions **Chen, "Clarification Questions for Ambiguous Sentences"** __**, and estimating uncertainty **Kumar, "Estimating Uncertainty in NLP Tasks"** ____. Similar to our work, **Zhu, "Iterative Prompting for Ambiguity Resolution"** use iterative prompting to refine and generate alternative interpretations in the context of question answering, while **Wang, "Ambiguous Question Detection and Resolution"** first detect ambiguous questions and then resolve them through clarification requests. 

 \paragraph{Ambiguity in Semantic Parsing} Ambiguity has been studied across semantic parsing tasks, from code generation **Liu, "Code Generation for Ambiguous Inputs"** to $\lambda$-calculus translation **Kim, "$\lambda$-Calculus Translation for Semantics"** __**,  and logical form prediction **Brown, "Logical Form Prediction for Ambiguity"** ____. In the domain of text-to-SQL parsing, recent work has emphasized the fact that benchmarks often overlook ambiguity by providing single interpretations **Smith, "Text-to-SQL Parsing with Single Interpretations"** ____. Existing approaches focus on detecting column ambiguity through counterfactual examples **Huang, "Counterfactual Examples for Column Ambiguity"** __**, special-purpose decoding **Lee, "Special-Purpose Decoding for Ambiguity"** ____, and resolving ambiguity through clarification questions **Tan, "Clarification Questions for Ambiguity Resolution"** ____. Our work uses explicit disambiguation before parsing and thus extends to different types of ambiguities, question styles, and database formats.

\paragraph{Intermediate Representations in Text-to-SQL} Intermediate representations are commonly used to bridge the gap between natural language and database queries. Several approaches decompose complex questions into a sequence of simpler operations expressed in natural language   **Cheng, "Decomposing Complex Questions for Text-to-SQL"** __**, modular execution plans **Jiang, "Modular Execution Plans for Text-to-SQL"** ____, or simplify the parsing task by augmenting questions with SQL keywords that mention necessary computation steps **Zhang, "SQL-Augmented Questions for Text-to-SQL Parsing"** ____. Building on this work, we also use intermediate representations to make implicit information explicit but focus on resolving ambiguity.

\paragraph{Learning to Correct LLM Outputs} More recently, various approaches have been proposed to correct systematic biases in LLM outputs. For example, **Rajani, "Model-Agnostic Correction for Systematic Biases"** propose a model-agnostic module that learns correctional residuals between preferred and dispreferred outputs. **Zhou, "Corrector Model for Iterative Review"** use a corrector model to iteratively review imperfect generations from a base model. 
Similarly,  critique generators can be developed using reinforcement learning  **Guo, "Reinforcement Learning for Critique Generation"**  or through fine-grained feedback **Wang, "Fine-Grained Feedback for Critique Generation"** ____. Such correction approaches are most effective when guided by external tools **Kang, "Guiding Correction Approaches with External Tools"** ____. We follow this paradigm using a specialized infilling model to correct systematic  LLM biases towards certain interpretations and validate our output through SQL execution.