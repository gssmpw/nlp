\section{Related Work}
\label{sec:RelatedWorks}

\paragraph{Code Generation Benchmarks}
In code generation tasks,
ambiguous user instructions hinder the evaluation of code
suggestions generated by the model. Since the cause of
ambiguity is missing details, clarifying questions become
neessary~\cite{mu2023clarifygptempoweringllmbasedcode}. Interactive, test-driven workflows mitigate this ambiguity by first generating test cases aligned with user expectations, which users validate before code generation~\cite{lahiri2023interactivecodegenerationtestdriven}. Extensions of this approach employ runtime techniques to generate, mutate, and rank candidate code suggestions and test cases based on user feedback~\cite{Fakhoury_2024_LLM_Code_Gen}. Although effective, these workflows can burden users, highlighting the need to minimize intervention to essential cases. 

\paragraph{Interactive ML Systems}
In task-oriented settings, ambiguity between generated outputs and user expectations remains a challenge. AmbigNLG addresses this by introducing a taxonomy of instruction ambiguities and applying targeted disambiguation based on the identified ambiguity type~\cite{ambignlp}. These ambiguities include unclear output lengths, mandatory keywords, and contextual nuances in instructions. NoisyToolBench~\cite{NoisyToolBench} offers a dataset for evaluating LLM tool use with ambiguous instructions, though it focuses on simpler tasks. Reinforcement learning frameworks like ReHAC balance user interaction by modeling optimal intervention points~\cite{feng2024largelanguagemodelbasedhumanagent}, but more effective strategies are needed for complex, multi-step workflows.

\paragraph{LLMs and Ambiguity}
The current state-of-the-art LLMs
are not inherently trained to handle ambiguity through
user interaction~\cite{zhang2024clamberbenchmarkidentifyingclarifying}, but, their instruction
tuning enables improved performance with prompt engineering~\cite{white2023prompt}. Ambiguity detection has been
tackled with uncertainty estimation to measure the utility
of seeking clarification~\cite{zhang2023clarifynecessaryresolvingambiguity, park2024claraclassifyingdisambiguatinguser}. Meanwhile, the quality of clarifying questions and
the resulting performance remain critical to overall success~\cite{learning-good-questions, clarifydelphi, kuhn2023clamselectiveclarificationambiguous}. Despite advances, state-of-the-art techniques such as few-shot prompting and Chain-of-Thought
reasoning offer limited relief in ambiguous scenarios~\cite{zhang2024clamberbenchmarkidentifyingclarifying}. Self-disambiguation uses the internal knowledge of a
model to reduce query ambiguity~\cite{keluskar2024llmsunderstandambiguitytext,sterner2022explaining,sumanathilaka2024llmsassistambiguityquantitative}. For example,
Alignment with Perceived Ambiguity (APA) employs self-
disambiguation to quantify perceived ambiguity using information gain, improving the modelâ€™s processing of such
inputs ~\cite{kim2024aligninglanguagemodelsexplicitly}. Although inference-only
methods are cost-effective, they are less robust than training-based approaches for handling ambiguity.
