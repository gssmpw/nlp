\section{Limitations}
\label{sec:Limitations}
Our study benefits from including both open-weight and proprietary models, as well as models from the same family with different parameterizations, enhancing the generalizability of the findings. However, certain design decisions may affect the experiments.

Ambiguity detection is limited to the first three turns, as LLMs struggle to interact meaningfully if they do not engage early. To assess question quality, we measure changes in the latent vector to capture the information gained, assuming equal importance for all new informationâ€”though models may prioritize different details in their solution. The resolve rates in the overall problem solving experiment reflect real-life conditions, where incorrect code is unacceptable, regardless of how close the generated patch is to the solution. However, data leakage could enable some models to make correct assumptions in underspecified settings, inflating resolve rates. Additionally, the user proxy may be more interactive than real-world users, as LLMs are tuned to be helpful. We address this by limiting the number of interaction turns and focusing interactions on the task with detailed system prompts.

