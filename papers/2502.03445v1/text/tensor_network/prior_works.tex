\subsection{Why: Co-processing Inefficiencies in Prior Works}\label{sec:prior_co_processing}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/prior_inefficiencies.pdf}
    \caption{A hypothetical $4$-subcircuit scenario to demonstrate the two sources of inefficiencies of prior works.
    Consider the case where $e_{1,2,3}$ are fixed and only $e_4$ permutes.}
    \label{fig:prior_inefficiencies}
\end{figure}
State-of-the-art circuit cutting techniques~\cite{tang2021cutqc} follow the reconstruction formula in Equation~\ref{eq:reconstruction}.
This formula iteratively cycles through each of the ${I, X, Y, Z}$ bases for the $|E|$ cut edges,
resulting in a total of $4^{|E|}$ summation terms.
Each summation term requires computing the tensor products across the $m$ subcircuits.
The calculation of these summation terms is embarrassingly parallel,
and allows for straightforward distribution across CPUs and GPUs~\cite{tang2021cutqc,tang2022cutting}.
However, simple parallelization only reduces the runtime linearly in a fundamentally exponential problem.

The previous method incurs excessive costs due to redundant computations.
Typically, an input benchmark is divided into more than two subcircuits,
and not all subcircuits are interconnected by the cuts.
Since the output of a subcircuit $p_j^{\{e|e\in E_j\}}$ only alters when at least one of its connecting cuts changes bases,
many intermediate results remain unchanged and could be reused.
However, the earlier approach overlooks this possibility and redundantly recalculates all subcircuit products from scratch for each iteration.

Figure~\ref{fig:prior_inefficiencies} visualizes an example to demonstrate the two sources of inefficiencies of the prior method.
Specifically, the reconstruction formula~\ref{eq:reconstruction} translates to:
\begin{align}
    P&=\sum_{\{e_{1,2,3,4}\}}\otimes_{j=1}^{m}p_j^{\{e|e\in E_j\}}\nonumber\\
    % &=\sum_{\{e_{1,2,3,4}\}}p_1^{e_1}\otimes p_2^{e_{1,2,3}}\otimes p_3^{e_{2,4}}\otimes p_4^{e_{3,4}}\nonumber\\
    &=\sum_{\{e_{1,2,3}\}}\sum_{\{e_4\}}p_1^{e_1}\otimes p_2^{e_{1,2,3}}\otimes p_3^{e_{2,4}}\otimes p_4^{e_{3,4}}\label{eq:prior_compute_example}
\end{align}
Consider the scenario described by Equation~\ref{eq:prior_compute_example} with fixed edge bases on $e_{1,2,3}$.
Firstly, the intermediate result $p_1^{e_1}\otimes p_2^{e_{1,2,3}}$ is utilized multiple times as the basis for $e_4$ changes.
The baseline method inefficiently recalculates the product from scratch for each $e_4$ permutation.
Secondly, the baseline method separately multiplies the same intermediate result, $p_1^{e_1}\otimes p_2^{e_{1,2,3}}$,
with four distinct $p_3^{e_{2,4}}\otimes p_4^{e_{3,4}}$ results corresponding to each possible state of $e_4$.
This method of repetitive and separate multiplications followed by summations,
is computationally inefficient and does not optimize the use of computing kernels.
A more efficient strategy involves using the distributive property of multiplication to restructure Equation~\ref{eq:prior_compute_example} as follows:
\begin{equation}
    \sum_{\{e_{1,2,3}\}}p_1^{e_1}\otimes p_2^{e_{1,2,3}}\otimes\sum_{\{e_4\}}p_3^{e_{2,4}}\otimes p_4^{e_{3,4}}
\end{equation}
By computing the summation of $p_3 \otimes p_4$ prior to its multiplication with $p_1 \otimes p_2$,
this method significantly reduces the number of multiplications required - from four to just one.
This strategic reordering simplifies the computational process by minimizing redundancy.