\subsection{Runtime}\label{sec:runtime_results}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/total.pdf}
    \caption{End-to-end wall clock runtimes.
    Each data point is the average of $3$ trials.
    The error bars represent the standard deviations.
    Experiments terminate benchmarks when the estimated tensor contraction runtime exceeds $10^3$ seconds.}
    \label{fig:total_runtime}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/total_estimation.pdf}
    \caption{End-to-end runtime estimations using Equation~\ref{eq:cut_objective} for the same experiments in Figure~\ref{fig:total_runtime}.
    The estimated runtimes closely match with experimental data.}
    \label{fig:total_runtime_estimation}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/supremacy_breakdown.pdf}
    \caption{The runtime breakdown for the $Supremacy$ benchmarks.}
    \label{fig:runtime_breakdown}
\end{figure}

Figure~\ref{fig:total_runtime} shows the end-to-end wall clock runtime of computing $1$ million states for various benchmarks.
Experiments limit each benchmark circuit to at most half the number of qubits and gates in the uncut benchmark.
Note that these subcircuit size limits are upper bounds used in searching for cuts,
rather than the max subcircuit size produced from cutting.
Figure~\ref{fig:quantum_area} shows the actual quantum area found from cutting for the same set of experiments.

Figure~\ref{fig:total_runtime_estimation} shows the end-to-end runtime estimations obtained from Equation~\ref{eq:cut_objective}.
The estimations predict the tensor network contraction times using the heuristics number of floating point operations obtained from tensor network compilation,
divided by the backend GPU FLOPs.
The cut searching and QPU runtime estimations are the same as Figure~\ref{fig:total_runtime}.
Hence, estimations using Equation~\ref{eq:cut_objective} tend to overestimate the actual wall clock runtime,
but accurately reflect the trends.

Figure~\ref{fig:runtime_breakdown} shows the wall clock and estimation runtime breakdown of the $Supremacy$ benchmarks.
The inaccuracy in the runtime predictions is from the estimated time to contract subcircuit tensor networks.
Equation~\ref{eq:classical_runtime} consistently overestimates the GPU runtime.
We conjecture that more accurate estimations further require a holistic profiling of tensor network contraction on specific backend GPUs.
In addition, our cut searching algorithm~\ref{alg:graph_growing} finds cut solutions that balance between the quantum and classical runtimes,
showcasing its ability to find sweet tradeoff points.
Despite the efficiency of the heuristics cut search algorithm,
cuts finding still takes a significant portion of the end-to-end runtimes.