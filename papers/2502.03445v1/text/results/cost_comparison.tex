\subsection{Exponential Classical Overhead Advantage}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/cost_ratio.pdf}
    \caption{Classical post-processing overhead comparison of CutQC over TensorQC
    for the same experiments in Figure~\ref{fig:total_runtime} on a $\log$ scale.
    Max ratios are clipped at $10^9$ for clarity.}
    \label{fig:cost_ratio}
\end{figure}

Figure~\ref{fig:cost_ratio} shows the classical co-processing overhead of CutQC~\cite{tang2021cutqc} over TensorQC.
Specifically, we compute the number of scalar multiplications for TensorQC's tensor network contraction using~\cite{gray2021hyper},
and that of CutQC's brute force reconstruction.
The cost ratios are clipped at \textit{one billion} times improvement for clarity,
but the actual overhead reductions can be over $10^{50}\times$.
The classical post-processing cost ratios clearly demonstrate a fundamental improvement over~\cite{tang2021cutqc}.

% It is noteworthy that despite the wide overhead reduction,
% $Regular$ and $Erdos$ benchmarks are still challenging to be cut.
% In fact, $Regular$ benchmarks exceed $10^3s$ classical co-processing runtime at $90$ qubits,
% and $Erdos$ at just $40$ qubits.
% Developing better tensor network contraction sequences
% and parallel tensor network contractions may make such hard benchmarks more scalable.