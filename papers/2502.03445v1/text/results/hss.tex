\subsection{HSS Data Efficiency}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/hss_p.pdf}
    \caption{Retaining $2^8$ binary states using HSS for increasing benchmark sizes.
    HSS captures almost all the dominating states for benchmarks with skewed outputs
    including $W\_State$ and $GHZ$.
    Within our expectation,
    HSS captures decreasing amplitudes for other benchmarks with distributed outputs as sizes increase.
    }
    \label{fig:hss_p}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/hss_ratio.pdf}
    \caption{
    HSS amplitude retention as a percentage of the max possible retention with $2^8$ states.
    $AQFT$ (overlaps with $GHZ$ in the figure) shows nearly $r_{P,HSS}=1$ as any sampling algorithm performs the same for a uniform distribution.
    }
    \label{fig:hss_ratio}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/hss_efficiency.pdf}
    \caption{HSS data efficiencies for various benchmarks.
    }
    \label{fig:hss_efficiency}
\end{figure}

Reconstructing more states yields greater amplitude information
but also results in higher computational demands.
We limit the number of HSS reconstruction states to be $2^8$ in this section.
Figure~\ref{fig:hss_p} shows $P_{HSS}$ for various benchmarks with increasing sizes.

$W\_State$ and $GHZ$ benchmarks exhibit skewed binary state output landscapes,
allowing the HSS protocol to identify significant binary states with a minimal number of reconstruction states.
Notably, the HSS protocol retains nearly $100\%$ probability amplitudes at $30$-qubit while only reconstructing fewer than one-part-per-million binary states.

Benchmarks with more evenly distributed amplitude landscapes naturally pose a greater challenge for amplitude retention.
For example, $Regular$ benchmarks produce outputs without any dominating states.
Within our expectation,
the HSS algorithm retains a lower $P_{HSS}$ compared to benchmarks with skewed outputs.

However,
the lower amplitude retention is due to the intrinsic distribution of the benchmarks themselves.
Figure~\ref{fig:hss_ratio} shows that HSS captures a significant portion of the max possible amplitude retention,
despite the decreasing amplitudes for $AQFT$ and $Regular$ benchmarks shown in Figure~\ref{fig:hss_p}.

$\eta_{HSS}$ in Figure~\ref{fig:hss_efficiency}
shows that HSS retains much more amplitude weights relative to the few binary states reconstructed.
For example, HSS retains more than $10^6\times$ amplitudes than the number of states picked for $30$-qubit benchmarks with skewed outputs.

The $Supremacy$ benchmarks exhibit the poorest HSS metrics.
Unlike the $AQFT$ benchmarks,
which are uniform and thus allow any sampling algorithm to perform equally,
$Supremacy$ benchmarks feature a more evenly distributed output landscape.
This distribution complicates the task of identifying significant states.
Theoretically, a sampling algorithm could achieve a perfect $r_{P,HSS}=1$ across any output landscape,
but the diverse distribution in $Supremacy$ benchmarks makes this a particularly challenging goal.