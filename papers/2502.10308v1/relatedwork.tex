\section{Prior work}
In this section, we include prior work with a focus on the central course allocation problem and on LLMs. For a more comprehensive discussion of prior work on PE and machine learning in mechanism design, please see \Cref{app:morepriorwork}.


\paragraph{The course allocation problem}
The course allocation problem is a combinatorial assignment problem, motivated by the real-world challenge of assigning courses in business schools, where students compete for limited seats to build their schedules.
\cite{budish2017course}.
Early methods for performing course assignments at business schools included a draft and a bidding-based mechanism~\cite{sonmez2010course,brams1979prisoners}; however, these created incentives for strategic manipulation and resulted in poor outcomes.
As a combinatorial assignment problem, course allocation is subject to several impossibility results ruling out mechanisms with simultaneous good properties: most notably, combinatorial assignment mechanisms that are ex-post Pareto efficient and strategyproof must be dictatorships~\cite{papai2001strategyproof,hatfield2009strategy}.

To escape this impossibility result, \citet{budish2011combinatorial} proposed a mechanism that satisfies slightly relaxed versions of each of these desiderata: \textit{approximate competitive equilibrium from equal incomes (A-CEEI)}.
At a high level, A-CEEI simulates a competitive equilibrium form equal incomes, but the market need not exactly clear, and students may have slightly different initial endowments of money.

\citet{budish2017course} introduced \textit{Course Match (CM)}, a practical instantiation of A-CEEI tailored to the course allocation problem.
In CM, students report their value for each course, as well as positive or negative pairwise interactions between courses (because the users make these reports via graphical user interface, this is called the ``GUI language'' or ``GUI'').
CM treats these reports as reliably reflecting student preferences, and uses them to heuristically search for an assignment of courses that constitutes an A-CEEI.
CM has been successfully adopted at many leading institutions such as the Wharton School at the University of Pennsylvania and Columbia Business School~\cite{Course,Coursea}.


\paragraph{Machine Learning-powered Course Match}
Prior to CM's adoption by Wharton, \citet{budish2021can} conducted a lab experiment comparing it againt the previously used mechanism, the Bidding Points Auction. Students were happier with their allocation under CM and perceived it as more fair, leading to CM's adoption in practice.
At the same time, \citet{budish2021can} found that students seemed to have trouble with CM's reporting language: 
they make limited use of its features, 
and they sometimes even appear to make outright errors.
Motivated by this problem, \citet{soumalias2024machine} incorporated \textit{machine learning (ML)} into the CM pipeline.
While they start with the same user interface, they also ask students to answer pairwise CQs, which are easier for students. 
These CQs, combined with the reports submitted in the GUI language, are used to train neural network models of student preferences, which guide both query generation and the final allocation process.

\paragraph{Language models as proxies for humans}
A growing body of research explores employing LLMs as proxies for human participants in social and economic studies. 
\citet{horton2023large} provided an early demonstration of this approach by studying how LLM agents, endowed with carefully elicited human preferences, could generate interview responses that closely mirrored those given by human subjects. Building on this work, \citet{park2024generative} investigated whether LLM-based proxies could replicate qualitative interview responses as accurately as real participants. They found that LLM proxies matched human responses with an 85\% accuracy, suggesting substantial potential for LLMs to substitute for
human participants in certain contexts.

Subsequent work expanded the scope of LLM agents to broader social and economic scenarios. For example, \citet{brand2023using} and \citet{manning2024automated} studied how these models perform in auctions, negotiations, and marketing environments, providing further evidence that LLMs can effectively mimic human decision-making. More recently, researchers have applied LLMs as autonomous pricing agents for companies \cite{fish2024algorithmic} and as synthetic participants in auction design \cite{zhuevidence}.



In concurrent work, \citet{Huang25Accelerated} explore the use of LLMs as proxies in combinatorial \textit{allocation} domains, in contrast to our focus on large-scale combinatorial assignment. This distinction introduces a different set of challenges, resulting in a different framework for PE.

\paragraph{Mechanism Design for LLMs.}
A related area pioneered by \citet{duetting2024mdforllms} is that of mechanism design for LLMs.
In this setting, agents---typically advertisers---compete to influence an LLM's reply to a user's query, aiming to better represent their interests.
\citet{soumalias2024truthful} introduce a truthful mechanism based on importance sampling that converges to the optimal distribution. 
\citet{mohammad2024rag} leverage retrieval-augmented generation to create an auction where a pre-generated ads are probabilistically retrieved for each discourse segment, according to both their bid and relevance. 
\citet{bergemann2024datadrivenmd} explore an extension of this problem in which agents possess both private types and signals.