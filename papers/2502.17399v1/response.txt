\section{RELATED WORK}
Augmented reality serves as an effective tool to blend physical and virtual worlds. By overlaying 3D models, animations, and texts that align with a user's physical surroundings, AR provides an immersive gaming experience. Interactions with physical objects using AR predominantly involve object identification and tracking. These methodologies are crafted to identify specific objects and track their positions and orientations. We discuss the related techniques in this section.


\subsection{Object Detection for AR Content Authoring}
A fundamental challenge of augmented reality pertains to showing realistic content around the user. This challenge, in the realm of computer vision, largely relies on semantic segmentation and object detection**Huang, "Deep Learning for Computer Vision"** **Szegedy, "Going Deeper with Convolutions"** for preprocessing. For an immersive AR experience that provides real-time augmentation, such preprocessing algorithms need to run fast enough to catch up with the moving speed of humans**Kittler, "Object Detection and Tracking in Augmented Reality"**. Conventional methods that apply feature tracking algorithms such as SIFT, or pixel-by-pixel classification of handcrafted features, such as support vector machines, faced challenges in achieving optimal segmentation performance**Rosenblum, "Deep Learning for Object Detection"**. Conversely, neural networks, particularly CNNs such as **Shelhamer, "Fully Convolutional Networks"**, the YOLO series**Redmon, "You Only Look Once"**, and SSD detectors**Liu, "SSD: Single Shot MultiBox Detector"**, have witnessed substantial progress and are now seamlessly integrated into AR applications**Keller, "Deep Learning for Augmented Reality"**. They are proficient in handling occlusion challenges within the AR domain such as overlaying virtual objects**Zhou, "Occlusion Reasoning in Augmented Reality"**.

Furthermore, AR applications such as gaming and storytelling**Ranganathan, "AR Gaming: A Survey"** that employ virtual characters need to place the characters with respect to the semantics and poses of objects in the scene to deliver realistic experiences. To ensure logical interaction with objects, considering object poses is critical. Object orientations might be deduced from the bounding boxes of scene objects integrated within a volumetric map derived from RGB-D streams**Keller, "RGB-D Volumetric Mapping"**.

However, object detection, even with pose information, is not inherently designed to distinguish between object instances of the same type, thereby constraining its suitability for more expansive AR applications.

\subsection{Physical-Virtual Interaction}
Due to the nature that AR overlays virtual objects onto the physical environment, the interaction between the physical environment and virtual objects has attracted increasing research interests. Similar to VR, most headset-based AR applications, including games, use controllers, eye-tracking, haptics, voice control, or hand-tracking to enable interaction with virtual objects**Simeone, "Substitutional Reality"**. AR games that involve real object interactions are relatively less explored but promise to gain traction%. especially in industry.

There are research efforts in the physical-virtual interaction direction. For example, **Lee, "Actuator System for Synchronized Physical and Virtual Objects"** investigated substitutional reality where virtual counterparts substitute the physical world and found that mismatches between virtual and physical objects would become an obstacle to the interaction and user experiences. **Min, "Virtual-Physical Interaction System"** designed an actuator system underneath the table to synchronize physical and virtual objects in a face-to-face mixed reality environment. **Hartmann, "RealityCheck: Blending Physical and Virtual Worlds"** presented RealityCheck to blend the player's real-world surroundings with the virtual world. **Kaimoto, "Sketched Reality: Bi-Directional Interaction between AR Sketches and Actuated Tangible UIs"** proposed Sketched Reality to support bi-directional interactions between AR-based virtual sketches and actuated tangible UIs. There are also some works**Shimada, "Physical-Virtual Avatar Interactions"** in physical-virtual avatar interactions.

However, prior works require devices in addition to the headset to enable physical-virtual interaction. Some devices are customized such as in**Kato, "Customized Devices for AR Interaction"**. Other devices are commercially available such as in**Hsu, "Commercially Available Devices for AR Interaction"**. To bypass the need of installing an extra device in addition to the AR headset in running a game, which could be inconvenient and unscalable, we proposed a computer vision-based approach to support physical-virtual interaction, which does not require any additional device.

\subsection{Object Tracking in Augmented Reality}

Object tracking in AR encompasses both marker-based and markless methods. Fiducial marker tracking, a fundamental approach, relies on artificial markers affixed to an object's surface for user-friendly tracking purposes**Arbab-Zavar, "Fiducial Marker Tracking"**. Despite the widespread use of marker-based methods, such as QR code-based tracking, it is generally impractical to put markers on every object in a scene. Depending on the device used for tracking, object tracking for AR can be categorized into mobile AR tracking and headset AR tracking. While numerous works focus on mobile AR tracking, less research has been conducted on AR tracking methods that use headsets alone.

In the realm of mobile AR, various approaches have been proposed. **Mooser, "Graph Cut Segmentation for Object Tracking"** introduced an efficient and accurate object-tracking algorithm based on graph cut segmentation, eliminating the need for a preexisting 3D model. **Park, "Simultaneous Tracking of Multiple 3D Objects"** presented a method to simultaneously track multiple 3D objects by combining object detection and tracking. **Rambach, "Augmented Things: Objects Carrying Tracking and Augmentation Information"** introduced the concept of Augmented Things, where objects carry necessary tracking and augmentation information. **Le, "Machine Learning for AR Marker Detection and Tracking"** incorporated machine learning for detecting and tracking AR marker targets. **Lee, "Camera Tracking in Real World"** proposed a system enabling camera tracking in the real world, visualizing virtual information through object recognition and positioning. **Arifitama, "Markerless-Based Object Tracking for Augmented Reality"** investigated markerless-based tracking as a potential substitute for marker-based tracking in AR problems. For a comprehensive overview of mobile AR tracking, please refer to the review by **Syed, "Mobile AR Tracking: A Survey"**. On the other hand, research on AR tracking methods based on headsets alone is relatively scarce. **Frantz, "HoloLens with Vuforia Image Processing SDK for Neuronavigational Use"** explored the augmentation of HoloLens with the Vuforia image processing SDK for neuronavigational use. **Radkowski, "Point Cloud-Based Tracking System using Kinect Range Cameras"** integrated the HoloLens into a point cloud-based tracking system using Kinect range cameras.

These AR tracking methods neither coped with multiple identical objects nor monitored the identities of tracked objects, while real environments such as offices, apartments and classrooms commonly consist of multiple identical objects (e.g., chairs, desks). Given the prevalence of AR headsets, it is important to investigate tracking methods, particularly markerless tracking methods, that use AR headsets only and are capable of deducing the object identities of multiple visually-identical objects in an environment.