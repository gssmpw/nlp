\section{RELATED WORK}
Augmented reality serves as an effective tool to blend physical and virtual worlds. By overlaying 3D models, animations, and texts that align with a user's physical surroundings, AR provides an immersive gaming experience. Interactions with physical objects using AR predominantly involve object identification and tracking. These methodologies are crafted to identify specific objects and track their positions and orientations. We discuss the related techniques in this section.


\subsection{Object Detection for AR Content Authoring}
A fundamental challenge of augmented reality pertains to showing realistic content around the user. This challenge, in the realm of computer vision, largely relies on semantic segmentation and object detection~\cite{lee2021all} for preprocessing. For an immersive AR experience that provides real-time augmentation, such preprocessing algorithms need to run fast enough to catch up with the moving speed of humans~\cite{ko2020novel}. Conventional methods that apply feature tracking algorithms such as SIFT, or pixel-by-pixel classification of handcrafted features, such as support vector machines, faced challenges in achieving optimal segmentation performance~\cite{lee2021all}. Conversely, neural networks, particularly CNNs such as FasterRCNN~\cite{ren2015faster}, the YOLO series~\cite{redmon2018yolov3,simony2018complex}, and SSD detectors~\cite{liu2016ssd}, have witnessed substantial progress and are now seamlessly integrated into AR applications~\cite{zhang2020slimmer, tanzi2021real}. They are proficient in handling occlusion challenges within the AR domain such as overlaying virtual objects~\cite{roxas2018occlusion}. 

Furthermore, AR applications such as gaming and storytelling~\cite{liang2021scene,arstory,locationAR,snippet} that employ virtual characters need to place the characters with respect to the semantics and poses of objects in the scene to deliver realistic experiences. To ensure logical interaction with objects, considering object poses is critical. Object orientations might be deduced from the bounding boxes of scene objects integrated within a volumetric map derived from RGB-D streams~\cite{tahara2020retargetable}. 

However, object detection, even with pose information, is not inherently designed to distinguish between object instances of the same type, thereby constraining its suitability for more expansive AR applications.

\subsection{Physical-Virtual Interaction}
Due to the nature that AR overlays virtual objects onto the physical environment, the interaction between the physical environment and virtual objects has attracted increasing research interests. Similar to VR, most headset-based AR applications, including games, use controllers, eye-tracking, haptics, voice control, or hand-tracking to enable interaction with virtual objects~\cite{balakrishnan2021interaction}. AR games that involve real object interactions are relatively less explored but promise to gain traction.%, especially in industry. 

There are research efforts in the physical-virtual interaction direction. For example, Simeone et al.~\cite{simeone2015substitutional} investigated substitutional reality where virtual counterparts substitute the physical world and found that mismatches between virtual and physical objects would become an obstacle to the interaction and user experiences. Lee et al.~\cite{lee2019mixed} designed an actuator system underneath the table to synchronize physical and virtual objects in a face-to-face mixed reality environment. Min et al.~\cite{min2018virtual} presented a Virtual-Physical Interaction System (VPIS) that provided a realistic product experience in mixed reality by enabling users to manipulate a physical tangible product model. Hu et al.~\cite{hu2020enhancing} proposed a prototype to let users directly interact with physical objects, which provided active reactions in AR interactions. Hartmann et al.~\cite{hartmann2019realitycheck} presented RealityCheck to blend the player's real-world surroundings with the virtual world. Kaimoto et al.~\cite{kaimoto2022sketched} proposed Sketched Reality to support bi-directional interactions between AR-based virtual sketches and actuated tangible UIs. There are also some works~\cite{nagendran2012continuum, kim2018improving} in physical-virtual avatar interactions.

However, prior works require devices in addition to the headset to enable physical-virtual interaction. Some devices are customized such as in~\cite{lee2019mixed, hu2020enhancing}. Other devices are commercially available such as in~\cite{min2018virtual, hartmann2019realitycheck, kaimoto2022sketched}. To bypass the need of installing an extra device in addition to the AR headset in running a game, which could be inconvenient and unscalable, we proposed a computer vision-based approach to support physical-virtual interaction, which does not require any additional device. Based on the deduced identities of the real objects, our approach fuses virtual content onto the real objects. 

\subsection{Object Tracking in Augmented Reality}

Object tracking in AR encompasses both marker-based and markless methods. Fiducial marker tracking, a fundamental approach, relies on artificial markers affixed to an object's surface for user-friendly tracking purposes~\cite{kato1999marker}. Despite the widespread use of marker-based methods, such as QR code-based tracking, it is generally impractical to put markers on every object in a scene. Depending on the device used for tracking, object tracking for AR can be categorized into mobile AR tracking and headset AR tracking. While numerous works focus on mobile AR tracking, less research has been conducted on AR tracking methods that use headsets alone.

In the realm of mobile AR, various approaches have been proposed. Mooser et al.~\cite{mooser2007real} introduced an efficient and accurate object-tracking algorithm based on graph cut segmentation, eliminating the need for a preexisting 3D model. Park et al.~\cite{park2008multiple} presented a method to simultaneously track multiple 3D objects by combining object detection and tracking. Rambach et al.~\cite{rambach2017poster} introduced the concept of Augmented Things, where objects carry necessary tracking and augmentation information. Le et al.~\cite{le2021augmented} incorporated machine learning for detecting and tracking AR marker targets. Lee et al.~\cite{lee2022study} proposed a system enabling camera tracking in the real world, visualizing virtual information through object recognition and positioning. Arifitama et al.~\cite{arifitama2021mobile} investigated markerless-based tracking as a potential substitute for marker-based tracking in AR problems. For a comprehensive overview of mobile AR tracking, please refer to the review by Syed et al.~\cite{syed2022depth}. On the other hand, research on AR tracking methods based on headsets alone is relatively scarce. Frantz et al.~\cite{frantz2018augmenting} explored the augmentation of HoloLens with the Vuforia image processing SDK for neuronavigational use. Radkowski et al.~\cite{radkowski2018hololens} integrated the HoloLens into a point cloud-based tracking system using Kinect range cameras.

These AR tracking methods neither coped with multiple identical objects nor monitored the identities of tracked objects, while real environments such as offices, apartments and classrooms commonly consist of multiple identical objects (e.g., chairs, desks). Given the prevalence of AR headsets, it is important to investigate tracking methods, particularly markerless tracking methods, that use AR headsets only and are capable of deducing the object identities of multiple visually-identical objects in an environment.