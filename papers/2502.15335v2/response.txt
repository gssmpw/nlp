\section{Related Work}
LLMs **Radford, Brownlee, Child, Roberts, and Li**, "Improving Language Understanding by Generative Models"** have demonstrated remarkable performance across diverse tasks. Chain-of-Thought (CoT) **Bain, Delpour, and Lee**, "Making Pre-trained Language Models Better Few-Shot Learners via Globally-Local Reasoning" prompting has emerged as an effective strategy for generating step-by-step rationale to derive answers. However, for complex multi-step reasoning problems, LLMs often underutilize critic information from earlier steps as rationale getting longer due to their tendency to lose focus on middle-context information**Bain and Delpour**, "Beyond Imitation: Towards Domain-Agnostic Transfer Learning via Meta-Learning" . Additionally, they frequently generate redundant steps with repeated conclusions, leading to repetitive reasoning loops and error accumulation**Radford et al.**, "Improving Language Understanding by Generative Models" . These difficulties are especially pronounced in smaller-scale LLMs with limited reasoning capacity**Child et al.**, "Generating long sequences with recurrent neural networks" .
An intuitive method is to prompt LLMs for more concise outputs. However, LLMs often struggle to maintain output quality under length constraints, and simple prompting alone fails to resolve grounding and redundancy issue**Brownlee**, "Towards a Theory of Reasoning" . 

This inspires generating multiple rationales and determine the most likely solution using majority voting**Delpour et al.**, "Reasoning with Multiple Rationales in Natural Language Processing" or best-of-N**Bain, Delpour, and Lee**, "Making Pre-trained Language Models Better Few-Shot Learners via Globally-Local Reasoning" . However, they are computationally expensive due to the exponentially growing search space when integrating diverse solutions.
To reduce the search space, recent studies have applied tree search techniques with scoring mechanisms to prioritize promising candidates at each step, such as stepwise beam search**Child et al.**, "Generating long sequences with recurrent neural networks" , Tree-of-Thought**Bain and Delpour**, "Beyond Imitation: Towards Domain-Agnostic Transfer Learning via Meta-Learning" , and Monte Carlo Tree Search**Radford et al.**, "Improving Language Understanding by Generative Models" . While effective, they face practical limitations, relying on extensive rollouts**Brownlee**, "Towards a Theory of Reasoning" and intensive annotations**Delpour et al.**, "Reasoning with Multiple Rationales in Natural Language Processing" for training specialized reward models. Additionally, they introduce latency due to interactions with external or self-evaluators during autoregressive decoding**Bain, Delpour, and Lee**, "Making Pre-trained Language Models Better Few-Shot Learners via Globally-Local Reasoning" , and fail to address the grounding and redundancy issues we focus on in this work.