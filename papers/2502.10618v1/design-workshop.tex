%\section{Probing Into Plan Design Process through Design Workshops}
\section{Exploring Opportunities to Support Plan Identification in a Design Workshop}
\label{sec:design-workshop}

% Isn't this about finding out how humans can interact with LLM-generated materials to design plans?

%% KC: feels like something is missing here that connects the findings of the interview study with the key characteristic of the tool: the LLM-generated candidate content. 

The challenges we identified in instructors' current plan identification process (Section~\ref{sec:challenges}) suggest that there are multiple opportunities to increase instructors' efficiency and ability to identify domain-specific plans. In this section, we describe arguments for three design characteristics that may improve the plan identification process.
%, as well as reasons why large language models (LLMs) can enable those characteristics. 
Then, we report on the findings of design workshops in which instructors used and provided feedback about design artifacts with these characteristics. To ensure that our findings were applicable to domain-specific plan identification, we worked with instructors who teach application-focused programming domains and tailored their experience to include plan identification in those areas.
%: web development using Django, web scraping via BeautifulSoup, and data processing with Pandas. 
Finally, we report a set of design goals for systems that support domain-specific programming plan identification. %that can support instructors to search, abstract, and describe programming plans with LLM-based support.


% To understand how our insights about challenges in the plan identification process (Section~\ref{sec:challenges}) can inform the design of tools for plan identification, we conducted design workshops with instructors who teach application-specific programming topics (web development using Django, web scraping via BeautifulSoup, and data processing with Pandas). This workshop involved a preliminary design artifact that utilizes the capabilities of large language models to assist instructors in designing plans.
% The key characteristics of this artifact were influenced by instructor practices in introductory programming.
% In the design workshops, we explored additional interactions that can support instructors refine candidate plans and improve the instructor-LLM collaboration.

% To understand how our insights generalize to application-specific domains, we conducted design workshops with instructors from such domains using a design artifact informed by instructor practices in introductory programming. 

\begin{figure*}[ht]
    \centering
    \Description{Illustration of three main characteristics of design artifacts. On left, a window annotated A shows a list of programs with short explanations on top. On top right, one of three clusters is shown to be selected, named `Summary Statistics'. On bottom right, an `Item Details' pane for the candidate plan obtained from cluster, annotated C, and the suggested potential values for plan components given on the right, annotated B.} 
    \includegraphics[width=0.8\linewidth]{img/characteristics-new.pdf}
    \caption{Illustrations of the three characteristics of the design artifacts, 
    proposed to support instructors' plan identification process by addressing the challenges from our formative study. 
    %as informed by the practices observed in Section \ref{sec:interview_results}. 
    (A) Instructors can view a vast library of generated programs that achieve a diverse set of tasks in the relevant programming application area to inspire their plan identification; (B) Instructors can compare similar code snippets and other plan components to assist their refinement of plans; and (C) Instructors can follow suggested fields that endorse the structure their final plans should follow.}
    \label{fig:baseline-prototype}
\end{figure*}

\subsection{Characteristics of the Design Artifacts}
\label{sec:design-artifact}

The three key characteristics (see Figure~\ref{fig:baseline-prototype}) of our design artifacts are inspired by the three challenges identified in our formative study. These characteristics support a multi-stage workflow that mirrors educators' current plan identification process: initial identification of a plan candidates, refinement of the plan's details, and, finally, creating a complete description of the plan. 
%a multi-stage key practices adopted by instructors who identify common patterns in code and design programming plans to teach these patterns. The artifact reflects these three practices using the enabled interactions.

\subsubsection*{(A) Support \textbf{Initial Plan Identification} with \textbf{Quick Exploration of Many Authentic Programs and Problems}} % LLM generated content (A)
The participants in our formative study emphasized the importance of exploring content that captures a diverse set of authentic goals and implementations when identifying programming plans. However, they also found this search process to be tedious and time-consuming (Section \ref{sec:challenges_practice}). The instructors we spoke to indicated looking across multiple code files or examining textbooks to perform a survey of the topic in which they were identifying plans. \textit{If that reference material was readily available in a single interface, it may make the plan identification process quicker and easier.}
To address this challenge, we provide a large set of programs that address a diverse set of use cases in the target domain to reduce the tedium faced by instructors as they browse reference material and the burden of finding appropriate reference material for a certain programming domain.
These programs are generated by a large language model (LLM), described in full detail in Section~\ref{sec:llm-pipeline}. %By presenting instructors, we lessen the burden of searching many sources for appropriate examples.  

\subsubsection*{(B) Support \textbf{Plan Refinement} with \textbf{Comparisons of Similar Content}} % Clustering / which shows related programs (B)

Making decisions about exactly how to explain a particular concept in a programming plan was another common challenge highlighted by our formative study (see Section~\ref{sec:challenges_abstraction}). In refining their plan, instructors considered both how easily a potential plan could be used by their students (usability) and how common that plan was in practice (commonality). 
%A key process outlined by our participants to mitigate this challenge was comparing programs to recognize similarities to design initial candidates. Our interviewees employed different approaches to creating these candidates, including exploring reference material and discussions. % and literature reviews. % (Section \ref{sec:process-candidates}).
% More -- commonality / usability.
\textit{If instructors could view and compare multiple pieces of programs related to their potential plan, as well as a variety of potential plan goals, they may be able to more quickly evaluate how common or usable their plan is.}
We bootstrap this practice by clustering similar program snippets from the example programs, using a combination of heuristics and code embeddings (described in full detail in Section~\ref{sec:clustering}).
%This supports instructors by reducing the search space of relevant programs, potentially lowering the mental load of plan identification.

\subsubsection*{(C) Support \textbf{Robust and Shareable Plan Descriptions} with \textbf{Structured Fields}}
%{Finalizing Plan Design} % Plan components template (C)
% Support Complete Plan Descriptions with Structured Fields
The final practice we focus from the plan identification process is refining initial candidates into the structure of programming plans. 
We found that, surprisingly, instructors did not agree on their preferred structure for a programming plan, presenting the potential challenge that plans identified by one instructor may not be usable by another (see Section~\ref{sec:challenges_robust_shareable}). We observed that plan identification requires iteration and refinement, and instructors have varied opinions on the components that they incorporate in their plans.
% is an iterative process that is finalized through refinement of candidate plans (Section \ref{sec:individual-design}). We also identified a set of components used by instructors in this refinement phase (Section \ref{sec:components}). 
\textit{If instructors were given a structured template, they may iterate on their plans faster and achieve a convenient format for sharing with others.} By defining plans with all of the programming plan components mentioned by instructors in our formative study, they could ensure that plans they identify can be readily used by another instructor. Moreover, constraining instructors to work in such a structure could also support other educators who want to identify plans but are new to the pedagogical idea, potentially expediting their work by clarifying what exactly they should be looking for.
Thus, our interface enables examining plans with all their components for refinement rather than just code and comments in a general-purpose text editor or IDE.


\subsection{Workshop Methodology}

%We conducted a design workshop to explore features that address the needs of instructors in using the LLM-generated constructively.
To understand whether the design characteristics described accelerate domain-specific programming plan identification, as well as to identify what interactions with a plan identification system are valued by instructors, we hosted a series of design workshops.
%To evaluate how our design artifact reflects and improves instructor practices, 
We invited seven instructors with expertise in a variety of application-focused programming domains to participate (see Table~\ref{tab:participants-design-workshop}).
%in different computing applications
These areas included data analysis with Pandas (four instructors), web development with Django (two instructors), and web scraping with BeautifulSoup (one instructor). We did not require prior plan identification experience from participants. 



%Instructors participated in a video-recorded 90-minute design session with a \$75 compensation for creating plans in the aforementioned topics. 

%To understand how design practices for plan identification from introductory programming can be employed to design plans in application-focused computing domains, 


 

%\textbf{Protocol.}
\subsubsection{Protocol.}
Each instructor completed a screen- and audio-recorded 90 minute session involving three plan identification tasks and an interview. Participants were compensated with a \$75 Amazon gift card. % The study was determined as NHSR by our institutional review board.
Before the tasks, participants received a brief overview of the definition of programming plans and their components, based on the findings of our formative study (see Section~\ref{sec:challenges_robust_shareable}). %Once participants indicated familiarity,
We told participants that they should create plans appropriate for students with some Python familiarity but no experience in the application-focused domain (i.e., Pandas, Django, or Beautifulsoup).
Then, participants proceeded to perform plan identification in their domain of expertise across three conditions.
%that each provided different types of support. 
In each condition, participants were asked to create up to five programming plans during a 15 minute window in a thinkaloud setting. 

%Canvas conditions were realized using Miro boards\footnote{https://miro.com}, and the prototype interface was deployed as a web application.% through our institution.

%We employed a three-step process where 
%Conditions provided an increasing amount of support, so that we could
Our goal was to observe (a) how instructors interacted with the three characteristics in a low-constraint environment akin to paper prototyping~\cite{Sefelin_PaperPrototyping_CHIEA-2003} (Conditions 1 and 2), and (b) how instructors interacted with our more highly-constrained prototype (Condition 3). Across these conditions, we hoped that instructors' actions and feedback might suggest useful interactions to best make use of our proposed characteristics, as well as information about whether our prototype supported plan identification as expected. 
%Each task introduced an additional characteristic of the design artifact,
%with the third step being a prototype interface enabling all three characteristics. 
\begin{itemize}
    \item Condition 1: a Miro board\footnote{https://miro.com} populated with 30 example programs from the domain and associated one-line explanations in natural language. In addition, 70 more example programs could be found in a linked Google Sheet. Instructors were asked to create their plans in boxes labeled with each of the plan components. \textit{(Characteristics A and C)},
    \item Condition 2: a Miro board populated with common code snippets from the example programs, clustered into groups by similarity and ranked by frequency. Suggested goals, names, and changeable areas were also listed with the code snippets. Instructors were asked to create their plans in boxes labeled with each of the plan components. \textit{(Characteristics B and C)}, % Add link to 
    \item Condition 3: a web application that supports navigation through the example programs from Condition 1, viewing of "suggested plans" that contained clustered code snippets and associated goals, names, and changeable areas from Condition 2, and a plan creation area where plans can be edited within the suggested fields. \textit{(Characteristics A, B, and C)}
\end{itemize}
Participants were informed that they were not required to use provided content and could access external sources at any time, including web searches, library documentation, their own code, or their teaching material.
%with access to generated example programs \textit{(A)}. In the next stage, they identified plans in a second setting using the clustered set of candidate plans \textit{(A and B)}. Lastly, the participants interacted with the prototype that incorporated reference content enabling baseline interactions (\textit{(A, B, and C)}, see Figure~\ref{fig:baseline-prototype}).
%They were also reminded to think aloud while working on the tasks. 
The sessions ended with a short interview, during which the participants were asked to rank all three conditions based on how instructor-friendly they were, make requests for potential new features, and describe their likelihood of using a similar interface to generate programming plans for their courses. 
%Their insights also helped us formulate a comparative analysis between existing tools and the designed interface.


\begin{table}
\caption{Demographics of the Instructor Participants in our Design Workshop.}
    \centering
    \footnotesize
    \label{tab:participants-design-workshop}
    \begin{tabular}{l|ccccc}
    \toprule
            & Domain & \shortstack{Teaching \\ Experience \\ in CS} & \shortstack{Teaching \\ Experience in \\ Domain} & \shortstack{Used \\ Plans in \\ Instruction?}
    \\\midrule
        W1 & Pandas & 16-20 & 1-5 & No \\
        W2 & Django & 6-10 & 1-5 & No \\
        W3 & Pandas & 6-10 & 1-5 & Yes \\
        W4 & BeautifulSoup & 6-10 & <1 & Yes \\
        W5 & Pandas & 1-5 & 1-5 & No \\
        W6 & Django & 16-20 & 1-5 & No \\
        W7 & Pandas & 6-10 & <1 & Yes \\
    %\\\bottomrule
    \end{tabular}%
\end{table}

% \begin{table}
% \caption{Demographics of the Instructor Participants in our Design Workshop.}
%     \centering
%     \label{tab:participants-design-workshop}
%     \begin{tabular}{l|cccc}
%     \toprule
% \multirow{2}{*}{Workshop} & \multirow{2}{*}{Domain} & \multicolumn{2}{c}{Experience Teaching} & \multirow{2}{*}{Used Plans } \\
%                           &                         & CS   & Domain                     & in Instruction? \\
%     \\\midrule
%         W1 & Pandas & 16-20 & 1-5 & No \\
%         W2 & Django & 6-10 & 1-5 & No \\
%         W3 & Pandas & 6-10 & 1-5 & Yes \\
%         W4 & BeautifulSoup & 6-10 & <1 & Yes \\
%         W5 & Pandas & 1-5 & 1-5 & No \\
%         W6 & Django & 16-20 & 1-5 & No \\
%         W7 & Pandas & 6-10 & <1 & Yes \\
%     %\\\bottomrule
%     \end{tabular}%
% \end{table}

\subsection{Findings}
\label{sec:design-workshop-findings}

\subsubsection{Condition 1: Interactions with Example Programs from the Application-Specific Domain.}
% Before starting the plan design process, m
Most participants reviewed the example programs and use cases before designing any plans. Interviewees indicated that they found the provided examples to be meaningful and authentic (``\textit{this idea of merging datasets is really really valuable}'', said W1). Participants found value in both the code and the associated natural language descriptions. W7 added that reading ``\textit{titles are probably more useful than the code}.'' Instructors used these examples as inspiration for ideas about the different concepts that they can build plans around.
%Some participants edited the given code to ``\textit{give a theme}'' (W1) to motivate students by specifying their plans in the same context (e.g., a set of data analysis tasks for Taylor Swift album sales). 
%We noted that almost all participants browsed the given references to consolidate ideas about plans and then started their design process.

%While some instructors identified plans that were closely related to certain example programs, others used the examples as only a starting point. 
W2 and W7 explicitly communicated that designing one plan inspired them with ideas for new plans, rather than sticking to a list of ideas they came up with at the beginning of the session. % of writing plans also motivated the examples they presented subsequently.

However, participants did not always find what they were looking for. W1 and W4 had particular ideas for designing their plans, but they could not find the implementation of those ideas in the reference materials, leading to time wasted in a fruitless search. While most participants were positive about the provided examples, some preferred to gather inspiration from their own teaching experience or an external resource. Specifically, W5 preferred to design plans using their own prior work (a course website with modules for Pandas), and W7 consulted the Pandas documentation for clarifications and ideas. 

In this condition, participants created plans with different structures from one another.
%The structure of the designed plans were also different from one another. 
Most notably, participants annotated changeable areas in different ways: highlighting parts of code using a different color or changing the text color (W1, W6), drawing rectangles or ellipses around parts of changeable code (W4, W7), or writing a natural language description of changeable parts (W1, W2, W3, W4, W5).

Nonetheless, the process of plan identification was not straightforward. Sometimes, in the given reference material, participants saw syntax that they were unfamiliar with. In this case, instructors performed web searches to clarify their understanding of the structures. For instance, W4 redirected to StackOverflow to find the difference between \textit{``\texttt{.text} and \texttt{.content}''} and clarified that \textit{``there's ..., not a substantive difference''}. W5 asked questions about the ``\textit{specificity}'' of plans, and W6 requested clarifications about the intended audience. In addition, participants found it challenging to understand the difference between the plan names and goals. W2 articulated that names might be less meaningful to students, even if instructors do get it.
% Mirroring the challenges that instructors in our formative study indicated with finding the correct granularity of plans, W4 added that ``\textit{if [a plan] needs too much tinkering, it may not be a pattern}.'' 
% \begin{quote}
%     A plan should be something you can pull out of your back pocket. (W4)
% \end{quote}
Despite the hurdles, instructors reacted positively to 
%the concept of programming plans after working in 
this condition, praising the existence of reference materials. They ranked this condition second highest among the three.

\subsubsection{Condition 2: Interactions with Clusters of Code Snippets and Suggested Plan Components.}
\label{sec:workshop-findings-condition2}
In contrast to condition A, participants often struggled to create plans with the reference material provided in condition B and found the experience ``\textit{overwhelming}'' (W1) or tedious because they had to navigate a large canvas (W4).
%They suggested that a list of reference content would allow easier navigation.
More importantly, participants expressed dislike of the content itself, which consisted of clusters of similar small code snippets as well as suggested goals, names, and changeable areas. Many participants preferred to include complete worked examples rather than code snippets in their final plans, with the idea that it would help students to avoid any need for \textit{``implied knowledge ''} (W1). Similarly, some instructors were concerned about the size of the snippets, finding them ``\textit{too fine-grained''} (W4). 
%, i.e., assuming that students are familiar with the context. 
W4 felt the suggested names of plans were ``\textit{too generic}'' and that many of the code snippets presented the same ideas repeatedly.
%Yet instructors did find some characteristics that supported their plan identification process. 
While in a few cases, instructors were able to find inspiration among the clusters of code snippets, this  condition received the lowest ranking by all but one participant.

\subsubsection{Condition 3: Prototype with Improved Navigation of Content.}

Participants found the
%interactions and the plan template useful
interactions in the prototype to be useful, and this condition was ranked the highest by most interviewees.  
While identical reference information as in earlier conditions was presented, the features of the prototype made it easier for instructors to navigate and use the given content. W4 indicated that the interactions for browsing candidate plans reduced the effort in reviewing many clusters in previous conditions. W2 and W7 appreciated the two-column view of example programs, where they could scan the list of natural language descriptions in one column  and click to review code on the other column if they find that use case interesting. W3 felt that the features of the prototype improved their efficiency over the earlier conditions:
% (``\textit{having the examples is half the battle}'', expressed W6)
\begin{quote}
    The Miro board itself doesn't really bring any value....
    %And then that's where the canvas here gets a 2 because I think 
    I better understand the ways where things like the use case palette and the library [in the prototype] could be used to quickly do the compositing. %\footnote{Participants rated each condition on a scale of 1 to 5, with 1 representing strongly positive, and 5 representing strongly negative opinions.}. 
\end{quote}

At the same time, participants requested ways to further reduce their search space, such as searching for important keywords (W2).
%Interestingly, we noted that participants very rarely wrote code from scratch while using our prototype. Most participants used the code from reference vmaterials and refined it to design their plans.
While the prototype addressed some concerns of instructors in the other conditions, our interviewees did request that some features of Miro boards be incorporated (e.g., highlighting code to emphasize changeable areas (W1)). When asked about additional features, almost all interviewees requested syntax highlighting on code examples and snippets, similar to the format of code editors.

W2, a Django instructor, found it challenging to represent plans in a single template as many Django programs are spread over multiple files. In such domains, visualizing connections between multiple plans could be helpful. 


% Exactly the same content, but 


\subsection{Design Goals}
\label{sec:design-goals}

% another option
Reflecting on our findings from this workshop, we formulate four design goals to inform the development of PLAID (or other systems) that assist instructors in designing programming plans with LLM-generated content.
% In this section, we describe four design goals summarizing our findings to inform the development of systems for assisting instructors in designing programming plans with LLM-generated content.

% many - number
% diverse - concepts covered?
% authentic - represent real-world practice
Mirroring the process of reviewing code from Section~\ref{sec:challenges_practice}, we observed that instructors valued the availability of many complete example programs for inspiration and brainstorming.
% as it helped them brainstorm ideas for designing plans. 
% While all participants were requested to design plans using our suggested plan components, we noted that instructors had different opinions about how they defined each component.
However, the ways in which instructors interacted with these examples varied based on their personal values. %, which affected how they used the example programs to design plans. 
Some instructors emphasized the importance of having contextualized examples in their plans to motivate students. 
Others focused on incorporating best practices or conventional techniques that 
% often come up in large projects and 
are important to remember. 
So, PLAID should be able to present instructors with \textbf{authentic} code examples that capture context and key functionality at the same time.
Some instructors also described multiple approaches to instantiate the same plan, emphasizing the different ways of achieving the same goal. 
%To enable instructors to highlight different solutions or find the ideal implementation,
PLAID should provide \textbf{diverse} examples to instructors to help them capture these different approaches.
In addition to having access to a corpus of programs, the content should be \textbf{displayed in a compact view} to enable instructors to easily navigate and search for key concepts.
% find what they are looking for.
% Thus, PLAID should present \textbf{many} examples to address the wide-ranging needs of instructors.

\begin{quote}
    \textbf{DG1: PLAID should inspire instructors by presenting many diverse and authentic examples in a compact view.}
    % as sources of inspiration for instructors.}
\end{quote}

% Viewing many examples is key to helping instructors create plans that represent best practices and industry standards. 
While instructors have expertise in their target domains, the dynamic nature of domain-specific libraries (e.g. Pandas) makes it hard for experts to keep up with up-to-date conventions and practices.
% the deprecations or updates to methods and functions. 
In our design workshop, when participants saw strange syntax, they used external resources like library documentation and web searches to understand unfamiliar code. 
% to review concepts and syntax.
So, PLAID should incorporate mechanisms that can help instructors \textbf{understand} unfamiliar programming paradigms. 
Moreover, most computing instructors write programs using code editors where they can frequently run code to review their implementations. So, PLAID should allow instructors to \textbf{view the output} of their programs to validate and refine their material.
% who use code editors for.

\begin{quote}
    \textbf{DG2: PLAID should assist instructors in mitigating uncertainties with example code.}
\end{quote}

\begin{figure*}[h]
        \Description{Three annotated screenshots, showing the buttons and menus explained in the text.}
        \includegraphics[width=\textwidth]{img/jane-workflow-new.png}
        \caption{Jane's Workflow Diagram. Jane (1) asks the system to suggest a plan; (2) edits the name and goal components of her plan, (3) marks the changeable areas in the plan, (4) browses the list of use case to find code that meets her goals, (5) selects the relevant part of the code from the full program and creates a plan from the selection, (6) switches to the full programs tab to search for specific pieces of code, (7) uses the search bar to search for keywords, and (8) groups plans with similar goals.}
        \label{fig:jane-workflow}
\end{figure*}

A key challenge indicated by instructors was the tiresome nature of combining reference content from many different sources to design plans. Exploring multiple sources was distracting, and navigating various platforms reduced their efficiency. Moreover, we saw that some instructors preferred to use the given material as an initial draft and refine it rather than write code from scratch. 
So, PLAID should support efficient interactions for editing reference material to \textbf{speed up} plan refinement. Participants indicated that it is challenging to abstract high-level ideas from multiple similar programs, so PLAID should \textbf{support abstraction} by allowing instructors to quickly combine content from a variety of sources.
% \textbf{interactions that can allow instructors to structure reference content to design plans with great efficiency.}

\begin{quote}
    % \textbf{DG3: PLAID should accelerate instructors in structuring reference content by providing efficient interactions for designing plans. PLAID should also facilitate abstracting high-level ideas from multiple code snippets. .}
    % \textbf{PLAID should accelerate instructor workflows with efficient interactions for designing plans and producing abstract summaries.}


    \textbf{DG3: PLAID should accelerate instructor workflows with efficient interactions for abstracting concepts and designing plans.}


    % \textbf{PLAID should accelerate abstracting concepts and using reference content for designing plans.}

    % \textbf{PLAID should accelerate abstracting concepts using reference content for designing plans.}
\end{quote}




To adopt plan-based pedagogies in courses, instructors need to make decisions about how to organize and present plans to students. 
In our design workshop,
% participants expressed uncertainties about how they would adopt plan-based pedagogy in their existing curricula.
we observed that participants attempted to document how they would use plans during instruction by clustering plan boxes on the canvas by theme. They also ordered plans in the sequence that students should learn about them.
% Moreover, they used the plan components to add explanations 
% as variants of a question for creating assessments and ordering plans in a hierarchy arranged by difficulty for organization on lecture modules.
So, PLAID should present instructors with ways of organizing content, as they \textbf{navigate their pedagogical concerns} about how students should be learning about plans.
% by helping them move towards organizing plans as they would present them to students.

\begin{quote}
    \textbf{DG4: PLAID should support instructors in organizing content to address pedagogical concerns.
    % about ways of adopting plan-based pedagogy in their curricula.
    } %Anticipating 
\end{quote}


% Using reference material effectively
% < Highlight code in full code and code pane in tab1 and make a plan
% < Add a button to add full program as a plan too

% Making sense of the content: % Viewing metainformation or contextual information about the content % Exploring code functionality and context
% < Code explanation plugin for strange syntax (GPT)
% < Code execution feature

% Getting inspiration from content / being able to find what you need to find: % Viewing many examples
% < Search in the use cases (and full progs)
% < Duplicating plans
% < Keyword search/embedding filter for potential values
% < Show use case button in solution (add highlighting)

% Organizing plans effectively
% Grouping plans into categories
% < Multiple selection of the boxes
% < Naming groups of boxes

