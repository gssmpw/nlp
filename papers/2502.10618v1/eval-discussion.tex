\section{Discussion}
% Our findings in Section~\ref{sec:} illustrate that PLAID can support ...

%% Potential discussion nugget:
% LLMs have frequently been used to generate new student-facing instructional materials. However, LLMs are much less commonly used to support instructors. 
% LLMs have been applied to some instructor-facing tasks, such as labeling multiple choice questions with their key concepts. 
%Arguably, instructors are particularly well-positioned to make use of LLM-generated content for their needs, as they have sufficient content knowledge to not be sidetracked by hallucinactions, and appropraite pedagogical knowledge to recognize when LLM-generated content is too technical or verbose.


% 
Computing education research is a leading subject area for applications of large language models (LLMs) in education, as LLMs capable of generating code at scale were made publicly available much earlier than general-purpose models like ChatGPT. 
% There have been many student-facing tools that utilize LLM-generated content, but few instructor-facing systems.
There have been many studies that designed student-facing tools around this technology~\cite{ferdowsiValidatingAIGeneratedCode2024,jinTeachAIHow2024,kazemitabaarCodeAidEvaluatingClassroom2024,logachevaEvaluatingContextuallyPersonalized2024,yangDebuggingAITutor2024,yanIvieLightweightAnchored2024}. 
However, a main limitation explored in these works is the untrustworthy nature of LLMs, which could generate hallucinated, incorrect responses or content that is not appropriate for learners.
Arguably, instructors are particularly well-positioned to incorporate LLMs in educational workflows, as they have sufficient content knowledge to detect hallucinations and appropriate pedagogical knowledge to recognize when LLM-generated content is too technical or verbose.
However, tools that use LLMs for supporting instructors have been less common, even though there have been some successful examples (e.g.,~\cite{choiVIVIDHumanAICollaborative2024a}).

% While some approaches seem to eliminate the role of the instructor, we find that LLMs can be well-suited to *support* instructors, resulting in a better outcome when LLMs and instructors interact.
% Thus, HCI researchers working on computing education have taken on the task of developing tools through a critical lens, utilizing this emerging technology without following a reductionist approach toward the valuable pedagogical expertise of instructors.

Our evaluation of PLAID confirms that LLMs can be used in the design of tools that support instructors, specifically by automating the tedious parts of instructors' workflows without undermining opportunities for them to apply their domain-specific and pedagogical expertise. 
% content knowledge or pedagogical knowledge.  
One ubiquitous observation from our user study that validates this argument is the 
% that supports this claim is the 
highly positive response to the LLM-generated reference material. 
All instructors valued having access to diverse and authentic examples because this accelerated an initial content collection process that would otherwise have been performed manually. 
% preparation work they would have to do otherwise.
By delegating this process to a large language model, instructors are able to focus on refining and iterating on the process of designing plans. 
% Even though the generated content wasn't appropraite for use with students, instructors could easily modify that ``first draft'' to meet their needs

Notably, instructors who attempted to use ChatGPT as an external resource in the baseline condition did not benefit as much as instructors using PLAID did, even though ChatGPT was used to generate the reference content for PLAID. %report as high a level of satisfaction as when they used PLAID.
Moreover, they found the interactions with ChatGPT to be tedious and the outputs to be verbose, even though their prompts were not so different from our queries to generate content passed into PLAID.
This highlights the importance of presenting LLM-generated content with appropriate interactions that reflect existing instructor practices. 
Thus, our findings suggest that human-in-the-loop approaches that equip instructors with preliminary content and facilitate refinement of that content are promising for the design of educational technology. 
% <The prompts that instructors used to query ChatGPT in the baseline condition were actually rather similar to the early stages of our content generation pipeline. However, our additional processing of the candidate content seemed to yield more benefits for instructors. ChatGPT's default includes comments on nearly every line -- this doesn't helpful for encouraging abstraction....  >

PLAID presents encouraging results for utilizing LLM-powered tools to promote best practices and theory-informed approaches for education. Most instructors with no experience in plan-focused pedagogies were interested in using programming plans for instruction after a relatively short exposure to the concept. By streamlining the opaque and tedious process of designing a programming plan, PLAID successfully sparked interest among these instructors for adopting plan-focused pedagogies. While PLAID presently supports four application-focused domains (Pandas, Pytorch, Django, and BeautifulSoup), our versatile pipeline and design of the interface are able to support instructors in identifying plans in any domain of interest. In a sense, `robots are here'~\cite{pratherRobotsAreHere2023} for the boring and repetitive work of gathering content and organizing it into broad categories for the first draft. This delegation of work empowers instructors to focus on building overarching narratives and refining content for learners,
% The incorporation of LLMs allowed instructors to focus on how designing plans can help students learn, 
instead of going through a repetitive and unclear process of searching for programs that capture common patterns. Utilizing LLMs to automate repetitive information-gathering tasks, allowing instructors to use their expertise on problems with higher impact, could be an important goal for designers working on similar tools.
% <In addition to scaffolding how instructors create educational content, examples were provided. Even though they were bad examples, they still set expectations.>
% <Robots are doing the boring work of gathering relevant content, organizing it into broad categories, and suggesting a first draft, leaving instructors more free to focus on refining the content for learners according to their expertise. >


%%%% IMPORTANT: PLAID can be applied to any domain, prompted to create generate examples in new domains
While most instructors saw value in programming plans, we noted that there were some logistic concerns about adopting plan-based pedagogies. Instructors who have been teaching a 

well-structured course for a long time expressed reluctance to go through the effort of a major redesign. The most positive responses came from graduate teaching assistants or instructors in the process of designing a course from scratch, who had the chance to incorporate programming plans into their courses in the first place. 
Researchers working on educational technologies for instructors should consider this hesitancy to adopt new approaches, and identify additional design considerations relevant to such instructors.







% purpose oriented tasks, goal-oriented language
% system can support broadening of plan based pedgagogy
% however newer instructors are more open to that adoption due to logistics
% \subsection{Does PLAID Work?}

% \subsection{Does PLAID make Plan Identification Easier?}

% \subsection{How does PLAID facilitate Efficient Plan Identification?}

%% How do instructors interact with LLMs?
%% Does it help with abstraction through purpose-first language / goal-oriented language. 
%% How/where to use these plans in instructionn
