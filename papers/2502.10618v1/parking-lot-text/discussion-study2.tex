\section{Discussion}

In this section, we address RQ2: \textit{How can LLMs (e.g. ChatGPT) support the identification of domain-specific plans?} 
%With the results of our mixed methods study, we are able to identify the strengths of supporting the plan identification process with LLMs while noting its shortcomings.

% Component generation
We found that our ChatGPT pipeline can reliably generate common domain-specific code. 
%It performs well on code generation tasks, i.e. generating the solution component of a plan, as evident from the 
Our quantitative and qualitative evaluation showed that generated plan solutions were almost entirely syntactically valid (see Section~\ref{sec:quant_accuracy} and Section~\ref{sec:qual_components}). 
In addition, the generated code is representative of actual practice (Section~\ref{sec:quant_commonality}), as shown by similarity to a reference set of plans validated by experts, and comparable similarity to Github files from the same domain (Section~\ref{sec:commonality}). Moreover, accounting from the similar number of distinct methods covered in the two datasets, we infer that ChatGPT can generate plans that capture a variety of use cases in the domain (Section~\ref{sec:quant_usability}). Furthermore, the complexity of the generated code appears to be similar to those generated by instructors with domain expertise, indicating that the generated examples can be appropriate for novices (Section~\ref{sec:quant_learners_appropriateness}). 
Overall, using LLMs for early phases in plan identification by generating common examples and recognizing candidates is a promising avenue.

However, our approach is not consistently able to describe the code appropriately for learners.
It especially falls short on code interpretation, namely, generating other components of a plan such as names and goals. A number of its generated responses were either overly general or overstating what the code achieved (see Section~\ref{sec:qual_components}). This might reflect the existing challenges for LLMs on in-context learning tasks, observed by prior work~\cite{llms_hard_incontext_learning}.
In addition, ChatGPT sometimes generated technical jargon in the names and goals (see~\ref{sec:qual_characteristics}), which makes those plan components unsatisfactory for novice learners. However, despite these pitfalls, the generated plan components were somewhat accurate, implying that they may be appropriate starting points for instructors to refine.

%These findings suggest the role that LLMs can best play in domain-specific plan identification: they can generate candidate plans, however, they lack the capability to create plans that fully meet instructors' desired characteristics. 

We present suggestive evidence that using LLMs to generate candidate plans as a part of a plan generation pipeline could reduce the tedium in the identification process by eliminating the need for instructors to view programs or perform a literature review (Section~\ref{sec:viewing-programs} and Section~\ref{sec:lit-review}) prior to creating plans. Instead, LLMs could provide instructors with candidate plans that they would modify for their learner audience to ensure that the explanatory components are accurate and reasonable. A promising direction for the design of an automated plan identification system is to foster collaboration between an LLM and instructors in order to scale domain-specific plan identification. 
%that allows the instructor to refine the generated candidate plans to meet their learner's goals. 

% ...support instructors through simulating a collaborative process, where the LLM presents initial candidates and the instructor can modify and refine the candidates for their learning goals

% components/ accuracy
% name and goal
    % it seems to perform well on code generation (both qual and quant) but not as well on interpretating what the code does (qual).
%     Evidence on generation: quant similarity to existing plans
%     Related evidence: changeable areas not accurate, goals needed work (from qual)
% solution
    % accurate
% changeable areas
    % accurate yet not quality worthy

    % appropriateness to learning goals - not a metric that can be translated for llms
    
% bigger picture
% can generate quality candidate plans but not the final plans
% needs instructor feedback

% Instructors are still needed in the loop to ensure that explanatory components are correct, and to . A reasonable number were partially correct. 


% Which part of the plan identification process can be automated with LLMs?

% LLMS have the potential to replace the example search and literature review part. + supporting the instructor in domain expertise (by having more variety)

%This section can answer RQ2: How can tools for explaining and generating code
%(e.g. ChatGPT) support the identification of domain-specific plans?


