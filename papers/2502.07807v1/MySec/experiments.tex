
\vspace{-3mm}
 
\section{Experiments}

\subsection{Experimental Setup}

\textbf{Dataset and Baselines.} In our experiments, we consider two datasets: CP-GuardBench and V2X-Sim \citep{liV2XSimMultiAgentCollaborative2022}. 
We designate CAV \#1 as the ego CAV and randomly select adversarial collaborators from the remaining CAVs. Additionally, we use ROBOSAC \citep{liUsAdversariallyRobust2023} and MADE \citep{zhaoMaliciousAgentDetection2024} as baselines, which are two state-of-the-art CP defense methods based on the hypothesize-and-verify paradigm.

\textbf{Attack Settings.} We assess different CP defense methods targeted at five attacks: PGD attack \citep{madry2018towards}, C\&W attack \citep{carlini2017evaluatingrobustnessneuralnetworks}, BIM attack \citep{kurakin2017adversarialexamplesphysicalworld}, FGSM attack \citep{goodfellow2015explainingharnessingadversarialexamples}, and GN attack. We set different perturbation sizes $\Delta \in \{0.1, 0.25, 0.5, 0.75, 1.0\}$. The number of malicious attackers varies in $\{0,1,2\}$ and all the attackers are randomly assigned from the collaborators, where 0 attacker indicates an upper-bound case. For PGD, BIM and C\&W attacks, the number of iteration steps is 15 and the step size is 0.1. 

\textbf{Implementation Details.} The CP-Guard+ system is implemented using PyTorch, and we utilize the object detector described in Section \ref{sec:data_generation}.
For each agent, the local LiDAR point cloud data is first encoded into $32\times 32$ bird's eye view (BEV) feature maps with 256 channels prior to communication. For our CP-Guard+, we use ResNet-50 \citep{heDeepResidualLearning2016} as the backbone, and the training is performed for 50 epochs with batch size 10 and learning rate $1\times 10^{-3}$.  Our experiments are conducted on a server with four RTX A5000 GPUs.
For mixed contrastive training, we utilize the output of the fully connected layers preceding the final output layer in the backbone to form a one-dimensional feature vector for each agent, the dimension of which is 2048.

\textbf{Evaluation Metrics.} We use a variety of metrics to evaluate the performance of our CP-Guard+ model. For malicious agent detection on our CP-GuardBench dataset, we consider Accuracy, True Positive Rate (TPR), False Positive Rate (FPR), Precision, and F1 Score. For CP defense on the V2X-Sim dataset, we use metrics including average precision (AP) at IoU=0.5 and IoU=0.7. Additionally, to assess the computation efficiency of different CP defense methods, we introduce the metric frames-per-second (FPS). The definition of the metrics are provided in Table \ref{tab:eval_metrics} in Appendix.









\subsection{Quantitative Results}

\textbf{Performance Evaluation of CP-Guard+.} 
We evaluated CP-Guard+ on the CP-GuardBench dataset using various attack methods and perturbation budgets ($\Delta$), as detailed in Table \ref{tab:quantitative_results_cpguardbench}. Metrics include Accuracy, True Positive Rate (TPR), False Positive Rate (FPR), Precision, and F1 Score. At $\Delta = 0.25$, CP-Guard+ achieved over 98\% accuracy for PGD, BIM, and C\&W attacks. FGSM and GN attacks showed lower accuracy, around 91.64\% and 90.95\%, due to their weaker impact unless perturbations are large. With $\Delta = 0.5$, the model maintained an average accuracy of 98.08\% and a TPR of 97.07\%. For $\Delta = 0.75$ and $\Delta = 1.0$, accuracy was 98.43\% and 98.53\%, respectively. The model consistently showed high TPR and low FPR, indicating robust detection of true positives and minimal false positives. Overall, CP-Guard+ demonstrated strong performance and resilience across various attacks and perturbation levels.

\begin{table}[t]
    \vspace{-2mm}
    \caption{\textbf{Generalization results of CP-Guard+.} Test perturbation budgets $\Delta=0.25$.
    }
    \vspace{1mm}
    \label{tab:generalization_results}
    \centering 
    \renewcommand\arraystretch{1}
    \resizebox{1\linewidth}{!}{
    % \small
    \begin{tabular}{c|ccccc}
        \toprule
        Held-out & Accuracy & TPR & FPR & Precision & F1 Score \\
        \midrule
        PGD & 99.93 & 100.00 & 0.09 & 99.66 & 99.83 \\
        BIM & 99.52 & 100.00 & 0.60 & 97.66 & 98.82 \\
        C\&W & 99.86 & 100.00 & 0.17 & 99.32 & 99.66 \\
        FGSM & 95.82 & 79.66 & 0.09 & 99.58 & 88.51 \\
        GN & 96.02 & 81.02 & 0.17 & 99.17 & 89.18 \\
        \midrule
        Average & 98.23 & 92.94 & 0.22 & 99.08 & 95.20 \\
        \midrule
        Upper-bound & 99.41 & 97.42 & 0.09 & 99.65 & 98.50 \\
        \bottomrule
    \end{tabular}
    }
    \vspace{-8mm}
\end{table}



\textbf{Performance Comparison with Other Defenses.} We compare CP-Guard+ with MADE \citep{zhaoMaliciousAgentDetection2024} and ROBOSAC \citep{liUsAdversariallyRobust2023} on the V2X-Sim dataset. Table \ref{tab:quantitative_results_v2xsim} shows that without defense, AP@0.5/0.7 significantly drops. CP-Guard+ consistently achieves the highest scores, even as the number of malicious agents or perturbation level increases. For $\Delta=0.25$ and $N_\text{mal}=1$, CP-Guard+ achieves 71.88\% AP@0.5 and 69.92\% AP@0.7, outperforming the no-defense case by over 186\% and 196\%, respectively. It also surpasses MADE and ROBOSAC by notable margins. At $\Delta=0.5$ and $N_\text{mal}=2$, CP-Guard+ maintains superior performance, confirming its robustness and superiority.






\textbf{FPS Comparison.} We compare the FPS performance of CP-Guard+ with MADE and ROBOSAC, as shown in Figure \ref{fig:cont_ablation}(a). The median FPS values for MADE, ROBOSAC, and CP-Guard+ are 56.86, 20.76, and 70.36, respectively. CP-Guard+ achieves a 23.74\% higher FPS than MADE and a 238.92\% increase over ROBOSAC, representing a significant improvement. These results highlight the high computational efficiency of our CP-Guard+.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{fig/cont_ablation2.png}
    \vspace{-9mm}
    \caption{\textbf{(a) FPS performance comparison} between CP-Guard+ with and other baselines. \textbf{(b) Cosine disctance} between the intermediate features of the malicious agent and the benign agent. 
    % \textbf{(c) Abalation study on the effectiveness of the mixed contrastive training}. `w/o' means the CP-Guard+ \textit{without the mixed contrastive training}. `w/' means the CP-Guard+ \textit{with the mixed contrastive training}. 
    }
    \label{fig:cont_ablation}
    \vspace{-5mm}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{fig/DCCLoss_ablation.png}
    \vspace{-9mm}
    \caption{\textbf{(a) Effectiveness of contrastive loss (CL).} `w/o' means \textit{without} CL. `w/' means \textit{with} CL.  \textbf{(b) Effectiveness of DCCLoss.} `w/o' means \textit{without} DCCLoss. `w/' means \textit{with} DCCLoss. \textbf{(c) Comparison of DCCLoss.}
    }
    \label{fig:dccloss_ablation}
    \vspace{-7mm}
\end{figure}

\textbf{Generalization of CP-Guard+.} To evaluate our method's generalization ability, we conducted experiments using a leave-one-out strategy. In this approach, we iteratively excluded one type of attack from the training set, trained the model on the remaining attacks, and then tested its performance on the held-out attack type. The experimental results are presented in Table \ref{tab:generalization_results}. From the table, we can see that our method achieves strong generalization ability on unseen attacks. Compared to the upper-bound case, our method experiences only a little decrease in overall performance. These findings underscore our method's robust capability to detect and handle unseen attack patterns. 

\vspace{-2mm}

\subsection{Ablation Study and Visualization}


\textbf{The Effectiveness of DCCLoss.} 
We assess the impact of DCCLoss on CP-Guard+ performance. Figure \ref{fig:dccloss_ablation} shows the effectiveness of DCCLoss and its superiority compared with contrastive loss (CL) \cite{chenSimpleFrameworkContrastive2020}. 
Figure \ref{fig:dccloss_ablation}(b) shows that this training significantly boosts performance, including Accuracy, TPR, Precision, and F1 score. Figure \ref{fig:dccloss_ablation}(c) shows the comparison results between DCCLoss and CL, which demonstrate that our DCCLoss outperforms CL and shows its effectiveness in malicious agent detection. In addition, 
Figure \ref{fig:cont_ablation}(b) illustrates that DCCLoss increases the cosine distance between negative pairs and decreases it between positive pairs, enhancing the model's ability to distinguish between malicious and benign agents.



% \vspace{-3mm}



\begin{figure}[t]
    % \vspace{-5mm}
    \centering
    % \fbox{\rule{0pt}{1.2in} \rule{1\linewidth}{0pt}}
    \includegraphics[width=1\linewidth]{fig/quailtitive_results2.png}
    \vspace{-10mm}
    \caption{\textbf{Visualization and Qualitative Results.} We visualize the results of the CP systems with and without defense by CP-Guard+. The \textcolor{red}{red} bounding boxes represent the predicted outcomes, while the \textcolor{green}{green} ones denote the ground truth.}
    \label{fig:qualitative_results}
    \vspace{-4mm} 
\end{figure}



\textbf{Visualization.} Figure \ref{fig:qualitative_results} visualizes the CP system's results with and without the CP-Guard+ defense mechanism. The top row shows that without defense, malicious agents cause numerous false positives, compromising system performance and security. The bottom row demonstrates that CP-Guard+ effectively detects and eliminates malicious agents, reducing false positives and increasing the true positive rate, confirming its effectiveness.

\vspace{-3mm}