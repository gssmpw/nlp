\section{Related Work}



\subsection{Collaborative Perception}
Collaborative Perception (CP) significantly extends the field-of-view (FoV) for individual agents, thereby enhancing the comprehensiveness and accuracy of perception outcomes \citep{hanCollaborativePerceptionAutonomous2023}. In CP systems, CAVs utilize various fusion methods tailored to distinct stages of data processing. Early fusion at the raw data level and late fusion at the output level often result in either high communication loads aor increased perceptual noise. Conversely, intermediate fusion, which involves the transmission of intermediate features among CAVs, achieves an optimal balance by minimizing communication overhead while maximizing perceptual accuracy.
Based on intermediate-level collaboration, recent progress in CP have addressed a wide array of challenges, including communication overhead \citep{fangPACPPriorityAwareCollaborative2024}, robustness \citep{10160546}, system heterogeneity \citep{lu2024an}, and domain generalization \citep{huFullsceneDomainGeneralization2023}. Robustness, in particular, has become a pivotal area of focus, tackling issues such as communication disruptions \citep{10457955}, pose noise correction \citep{10160546}, and system latency \citep{10.1007/978-3-031-19824-3_19}. Despite comprehensive research, the vulnerability of these systems to malicious attacks has not been adequately addressed. In this paper, we delve into the robustness of CP systems, specifically considering the impact of malicious agents, and proposes strategies to enhance system security and integrity.

\subsection{Adversarial Collaborative Perception}

Adversarial attacks on single-vehicle perception systems typically utilize methods such as GPS spoofing \citep{Li_2021_ICCV}, LiDAR spoofing \citep{279980}, and deploying physically realizable adversarial objects \citep{Tu_2020_CVPR}. However, in multi-vehicle collaborative perception, adversarial strategies differ markedly across collaboration stages.
For early-stage collaborative perception, Zhang \textit{et al.} \citep{zhangDataFabricationCollaborative2023} have identified attacks that involve object spoofing and removal, exploiting vulnerabilities through simulated object presence or absence and advanced reconstruction of LiDAR point clouds. Conversely, late-stage collaboration, which mainly involves sharing object locations \citep{9120490}, offers adversaries opportunities to manipulate these data points.
Attacks at the intermediate stage are more complex, typically requiring white-box access to perception models. Such access allows attackers to precisely manipulate system outputs, though these systems are generally less vulnerable to simple black-box strategies like ray-casting due to the protective nature of benign feature maps that diminish the impact of these attacks.
Pioneering work by Tu \textit{et al.} \citep{tuAdversarialAttacksMultiAgent2021} introduced untargeted adversarial attacks aimed at generating inaccurate detection bounding boxes by altering feature maps in intermediate-fusion systems. Building on this, Zhang \textit{et al.}\citep{zhangDataFabricationCollaborative2023} have enhanced these techniques by incorporating perturbation initialization and feature map masking, enabling more realistic and targeted attacks in real-time scenarios.
Our research focuses on identifying and mitigating adversarial threats within the intermediate-level collaborative perception framework to bolster system resilience against these sophisticated attacks.


\subsection{Defensive Collaborative Perception}

To enhance the resilience of intermediate-level CP against adversarial threats, contemporary research has primarily focused on the detection of malicious agents at the output level. Li \textit{et al.} \citep{liUsAdversariallyRobust2023} developed the Robust Collaborative Sampling Consensus (ROBOSAC) method that selects a random subset of collaborators for consensus verification. Additionally, Zhao \textit{et al.} \citep{zhaoMaliciousAgentDetection2024} innovated by introducing match loss and reconstruction loss as metrics to assess consensus between the ego CAV and its collaborators' perception results for the detection of malicious agents. Furthermore, Zhang \textit{et al.} \citep{zhangDataFabricationCollaborative2023} utilized occupancy maps to identify inconsistencies between the ego CAV and other collaborators.
However, these approaches predominantly adhere to a hypothesis-and-verify workflow, necessitating the generation of hypothetical perception outcomes and subsequent verification of their consistency with those of collaborators. This methodology is notably time-consuming and resource-intensive, hindering the system scalability. In this paper, we propose a novel approach that shifts the focus to detecting malicious agents at the feature level, thus circumventing the need to verify final perception results.



