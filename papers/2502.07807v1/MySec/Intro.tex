
\vspace{-10mm}
\section{Introduction}
\label{sec:intro}




 
% \begin{figure}[htbp]
%     % \vspace{-5mm}
%     \centering
%     %\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
%     \includegraphics[width=0.5\textwidth]{fig/Security_threats.png}
%     \caption{\textbf{Illustration of the threats of malicious agent in collaborative perception and our defense framework, CP-Guard+}. When there is no defense, malicious CAVs could easily send intricately crafted adversarial messages to the ego CAV, consequently misleading the CP system and resulting in false perception outputs. To counter this vulnerability, we propose CP-Guard+,  a tailored defense mechanism for CP that can effectively detect and neutralize malicious agents, thereby ensuring robust perception outcomes. \textcolor{blue}{{\bf TODO@Yihang: Redraw and rewrite the figure and the caption, respectively.}}}
%     \label{fig:security_threats}
%     % \vspace{-3mm} 
% \end{figure}


The development of collaborative perception (CP) has been driven by the increasing demand for accurate and reliable perception in autonomous driving systems \citep{chenCooperCooperativePerception2019,chenFcooperFeatureBased2019,liV2XSimMultiAgentCollaborative2022,huWhere2commCommunicationefficientCollaborative2024,huAdaptiveCommunicationsCollaborative2023,huFullSceneDomainGeneralization2024,fangPACPPriorityAwareCollaborative2024,xuOPV2VOpenBenchmark2022,huAgentsCoMergeLargeLanguage2024, hu2024cpguardmaliciousagentdetection, huCollaborativePerceptionConnected2024,tao2025gcpguardedcollaborativeperception,lin2024split,lin2024splitlora}. Single-agent perception systems, which rely solely on the onboard sensors of a single vehicle, are restricted by limited sensing range and occlusion. On the contrary, CP systems incorporate multiple connected and autonomous vehicles (CAVs) to collaboratively capture their surrounding environments. Specifically, CAVs in a CP system can be divided into two categories: the ego CAV and helping CAVs. The helping CAVs send complementary sensing information (most methods send intermediate features) to the ego CAV, and the ego CAV then leverages this complementary information to enhance its perception performance \citep{balkusSurveyCollaborativeMachine2022,hanCollaborativePerceptionAutonomous2023,huAgentsCoDriverLargeLanguage2024,wangV2VNetVehicletoVehicleCommunication2020a,10845862,fang2024pibprioritizedinformationbottleneck, tao2024directcpdirectedcollaborativeperception,fang2024ic3mincarmultimodalmultiobject,lin2024efficient,lin2024fedsn,lin2024adaptsfl}. For example, the ego CAV can detect occluded objects and extend the sensing range after fusing the received information.

\begin{figure*}[htbp]
    % \vspace{-5mm}
    \centering
    
    \begin{subfigure}[b]{0.48\linewidth}
        \includegraphics[width=\textwidth]{fig/Security_threats_v2.png}
        \caption{Threats in Collaborative Perception}
        \label{fig:security_threats}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
        % \fbox{\rule{0pt}{1.8in} \rule{1\linewidth}{0pt}}
        \includegraphics[width=\textwidth]{fig/comparison.png}
        \caption{Paradigm Comparison}
        \label{fig:idea_comparison}
    \end{subfigure}
    \vspace{-3mm}
    \caption{(a) \textbf{Illustration of the threats of malicious agent in collaborative perception}. Malicious CAVs could send intricately crafted adversarial messages to an ego CAV, which will mislead it to generate false positive perception outputs. (b) \textbf{Comparison between the proposed CP-Guard+ with the traditional hypothesize-and-verify malicious agent detection methods.} 
    Hypothesize-and-verify involves multiple rounds of malicious agent detection iterations at the output level and requires the generation of multiple hypothetical outputs for verification, incurring high computational overhead. In contrast, CP-Guard+ directly outputs robust CP results with intermediate feature-level detection, significantly reducing the computational overhead.}
    % \label{fig:idea_comparison}
    \vspace{-5mm} 
\end{figure*}

Despite many advantages of CP outlined above, it also has several crucial drawbacks. Compared to single-agent perception systems, CP is more vulnerable to security threats and easier attack since it requires receiving and fusing information from other CAVs, which expands the attack surface. In particular, malicious agents can directly send intermediate features with adversarial perturbations to fool the ego CAV or a man-in-the-middle who can capture the intermediate feature maps and manipulate them. Figure \ref{fig:security_threats} illustrates the vulnerability of CP to malicious agents. In addition, several attack methods have been designed to fool CP. For example, Tu \textit{et al.} \citep{tuAdversarialAttacksMultiAgent2021} developed a method to generate indistinguishable adversarial perturbations to attack the multi-agent communication in CP, which can severely degrade the perception performance \cite{lin2024hierarchical,lin2025leo,lin2023pushing}. 


The inability for the ego CAV to accurately detect and eliminate malicious agents from its collaboration network poses significant risks to CP, potentially resulting in compromised perception outcomes and catastrophic consequences. 
For instance, the ego CAV might misinterpret traffic light statuses or fail to detect objects ahead of the road, resulting in severe traffic accidents or even fatalities. Hence, it is crucial to develop a defense mechanism for CP that is resilient to attacks from malicious agents and capable of eliminating them from its collaboration network.



To address the security threats in CP, some previous works have investigated the defense mechanisms against malicious agents. For example, Li \textit{et al.} \citep{liUsAdversariallyRobust2023} leveraged random sample consensus (RANSAC) to sample a subset of collaborators and calculate the intersection of union (IoU) of the bounding boxes to verify whether there is any malicious agent among the collaboration network. Zhao \textit{et al.} \citep{zhaoMaliciousAgentDetection2024} designed a match loss and a reconstruction loss as statistics to measure the consensus between the ego CAV and the collaborators. 
% \textcolor{c2}{In addition, our previous work, CP-Guard, which is currently under review, defends against malicious agents by iteratively checking the anomaly of the collaborative segmentation results from different collaborators.}
However, these methods all follow a hypothesize-and-verify paradigm, which requires generating multiple hypothetical perception results and verifying the consistency between the ego CAV and the collaborators.
This approach is computation-intensive and time-consuming, which hinders its scalability, leading to the following question:
\begin{quote}
    % \vspace{-2mm}
    \centering
    \textit{Is it feasible to detect malicious agents directly at the feature level?}
    % \vspace{-2mm}
\end{quote}
As illustrated in Figure \ref{fig:idea_comparison}, the new paradigm shifts the focus to feature-level detection, eliminating the need to generate multiple hypothetical perception results. This direct approach can significantly reduce computational overhead, thereby enhancing the efficiency of malicious agent detection in CP systems.

Although this idea is concise and appealing, there are still some challenges in realizing it. Firstly, to detect malicious agents at the feature level, we need to train a deep neural network (DNN) model on a large-scale dataset to help it learn the features of benign and malicious agents. However, there is a lack of a benchmark dataset for feature-level malicious agent detection in CP systems. The existing datasets for CP, such as V2X-Sim \citep{liV2XSimMultiAgentCollaborative2022} and OPV2V \citep{xuOPV2VOpenBenchmark2022}, contain only benign agents and do not include malicious agents. 
Therefore, it is difficult to train a robust DNN model for malicious agent detection in CP systems without a well-annotated dataset. 
Secondly, in CP scenarios, the environments are highly dynamic and complex, making it unrealizable to directly use a classifier to categorize the received intermediate features for detecting malicious agents. This is because dynamic environments will cause a high false-positive rate (FPR). Additionally, adversarial perturbations are indistinguishable at the feature level, and the feature distributions of malicious agents and benign agents are highly similar. These factors make it difficult to train a robust model to distinguish malicious agents from benign agents.

To address the aforementioned challenges, we first generate a new dataset, CP-GuardBench, which is the first dataset for malicious agent detection in CP systems. Then, we propose CP-Guard+, a robust malicious agent detection method for CP systems.
CP-Guard+ can effectively detect malicious agents at the feature level without verifying the final perception results, significantly reducing computational overhead and improving defense efficiency. Moreover, we design a Dual-Centered Contrastive Loss (DCCLoss) to tackle indistinguishability issues at feature level and further enhance robustness. 

% In summary, the main contributions of this paper are as follows: 1) we investigate the malicious agent detection problem in CP systems and propose a brand new paradigm, feature-level malicious agent detection, 2) we construct CP-GuardBench, the first benchmark for malicious agent detection in CP systems, and 3) we propose CP-Guard+, a robust malicious agent detection method with high robustness and computational efficiency.

In summary, we investigate the malicious agent detection problem in CP systems and propose a new paradigm, namely, feature-level malicious agent detection. Additionally, we construct CP-GuardBench, the first benchmark for malicious agent detection in CP systems. Furthermore, we propose CP-Guard+, a robust malicious agent detection framework with high robustness and computational efficiency. Finally, we conduct extensive experiments on CP-GuardBench and V2X-Sim, and demonstrate the superiority of our CP-Guard+.
