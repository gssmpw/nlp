

\section{CP-GuardBench}




To facilitate feature-level malicious agent detection in CP systems, we propose to develop CP-GuardBench, the first benchmark for malicious agent detection in CP systems. It provides a comprehensive dataset for training and evaluating malicious agent detection methods. 
In this section, we will introduce the details of CP-GuardBench, including the automatic data generation and annotation pipeline in Section \ref{sec:data_generation}, and the data visualization and statistics in Section \ref{sec:data_statistics}.

\subsection{Automatic Data Generation and Annotation}
\label{sec:data_generation}

We build CP-GuardBench based on one of the most widely used datasets in the CP field, V2X-Sim \citep{liV2XSimMultiAgentCollaborative2022}, which is a comprehensive simulated multi-agent perception dataset for V2X-aided autonomous driving. 
In this section, we introduce the automatic data generation and annotation pipeline of CP-GuardBench. The pipeline is shown in Figure \ref{fig:data_generation}. It consists of three steps: 1) intermediate feature generation, 2) attack implementation, and 3) pair generation and saving. 

Specifically, we first train a robust LiDAR collaborative object detector, which consists of a convolutional backbone, a convolutional decoder, and a prediction head for classification and regression \citep{Luo_2018_CVPR}. As for the fusion method, we adopt the mean fusion method to fuse the intermediate features from different collaborators.
Subsequently, the backbone is retained for extracting intermediate features, which are then transmitted and utilized by an ego CAV as supplementary information. 


Secondly, the attacks are implemented and applied to the intermediate features. 
The detection head and decoder are then frozen to generate the attacked detection results and optimize the adversarial perturbations. 
As shown in Figure \ref{fig:data_generation}, several iterations are required to optimize the perturbations, and the loss function differs for different attack types.
In our CP-GuardBench, we consider five types of attacks, including Projected Gradient Descent (PGD) \citep{madry2018towards}, Carini \& Wagner (C\&W) attack \citep{carlini2017evaluatingrobustnessneuralnetworks}, Basic Iterative Method (BIM) \citep{kurakin2017adversarialexamplesphysicalworld}, Guassian Noise Perturbation (GN), and Fast Gradient Sign Method (FGSM) \citep{goodfellow2015explainingharnessingadversarialexamples}. The implementation details can be found in Appendix \ref{app:attack_details}.



In the generation of attack data, we randomly choose one of the attacks mentioned above and generate the corresponding attack data in each iteration.
Finally, the perturbed features will be annotated with the corresponding attack type and saved for later use. 
\vspace{-3mm}




\subsection{Data Visualization and Statistics}
\label{sec:data_statistics}
% \vspace{-2mm}





We visualize the samples of the generated data in Figures \ref{fig:data_statistics}(a), (b), (c), and (d). We observe that attacks are so stealthy that it is very hard to see the difference with the naked eye, which poses a great challenge to address the detection of malicious agents.



To construct CP-GuardBench, we randomly sample 9000 frames from V2X-Sim and generate 42200 feature-label pairs. The data is then split into training, validation, and test sets with a ratio of 8:1:1. 
The data statistics are shown in Figures \ref{fig:data_statistics}(e), (f), and (g). Figure \ref{fig:data_statistics}(e) illustrates the distribution of the number of collaborators, which is the number of agents that collaboratively perceive environments. 
The number of collaborators ranges from 3 to 6, with the most common scenario being 4 collaborators, accounting for 46.0\% of the total data. 5 and 6 collaborators are also common, accounting for 29.9\% and 19.5\% of the total data, respectively. 
Regarding the distribution of attack types, as depicted in Figure \ref{fig:data_statistics}(f), we observe that the attack types are evenly distributed, with each type accounting for approximately 20\% of the total data. This is due to the random selection of one attack type in each iteration. Figure \ref{fig:data_statistics}(g) illustrates the attack ratio, which represents the ratio of the number of attackers to the total number of agents in a collaboration network. The maximum attack ratio exceeds 0.3, the minimum is 0, and the average attack ratio is 0.18.

% \vspace{-3mm}

\begin{figure}[t]
    \centering
    % \includegraphics[width=0.5\linewidth]{}
    % \caption{Caption}
    % \label{fig:enter-label}
    % \fbox{\rule{0pt}{1in} \rule{0.9\linewidth}{0pt}}
    \includegraphics[width=1\linewidth]{fig/data_statistics2.png}
    \vspace{-8mm}
    \caption{\textbf{Visualization and Statistics of CP-GuardBench. (a), (b), (c)  and (d) are visualization}, which visualize the normal intermediate features and the adversarial examples perturbed by different malicious agents. We can see the adversarial examples are almost identical to the normal examples, which indicates the challenges in detecting malicious agents. \textbf{(e), (f), (g) and (h) are the statistics} of CP-GuardBench, including the number of collaborators, attack ratio and attack types.} 
    \label{fig:data_statistics}
    \vspace{-8mm} 
\end{figure}