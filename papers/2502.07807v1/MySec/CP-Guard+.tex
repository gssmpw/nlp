\vspace{-3mm}

\section{CP-Guard+}

In this section, we present our CP-Guard+, a tailored defense method for CP scenarios that effectively detects malicious agents. It consists of two techniques: 1) Residual Latent Feature Learning, which learns the residual features of benign and malicious agents, and 2) Dual Centered Contrastive Loss (DCCLoss), which clusters the representation of benign features into a compact space and ensures that the representation of malicious features is as distant from the benign space as possible.


\subsection{Residual Latent Feature Learning}
In CP scenarios, the dynamic environment causes noisy, non-stationary data distributions. Directly detecting malicious agents can be challenging due to this noise, as object detectors' feature maps often mix foreground and background information.

To tackle this challenge, we propose to learn residual latent features instead of directly learning the features of benign or malicious agents. By focusing on the differences between the collaborators' feature maps and the ego agent's feature maps, the model can better distinguish between benign and malicious agents. This mechanism is also inspired by the idea that the collaborators' intermediate feature maps will achieve a consensus rather than conflict with the ego CAV's intermediate feature maps.

Specifically, given the collaborators' intermediate feature maps $\{\mathbf{F}_{j\rightarrow i}\}_{j\neq i,\  j\in \mathcal{X}^N}$ and the ego CAV's intermediate feature maps $\mathbf{F}_i$, the residual feature is obtained as: $\mathbf{F}^\mathtt{res}_{j\rightarrow i}= \mathbf{F}_i - \mathbf{F}_{j\rightarrow i}.$ 

Then, we can leverage the residual latent features to detect malicious agents by modeling the detection problem as a binary classification task. A binary classifier $f_{\mathtt{cls}}(\mathbf{x}; \theta)$ is trained on the residual latent features to distinguish between benign (labeled 0) and malicious (labeled 1) agents. The model is optimized using the cross-entropy loss $\mathcal{L}_\mathtt{CE}$:
\begin{equation}
    \min_\theta \mathcal{L}_\mathtt{CE} (f_{\mathtt{cls}}(\mathbf{F}^\mathtt{res}_{j\rightarrow i}; \theta), y_{j\rightarrow i})
\end{equation}
where $y_{j\rightarrow i}$ is the ground truth label of residual feature $\mathbf{F}^\mathtt{res}_{j\rightarrow i}$.


% \begin{equation}
% \mathcal{L}_{\text{res}} = -\frac{1}{N} \sum_{i = 1}^{N} (y_i \log(p_i) + (1 - y_i) \log(1 - p_i)),
% \end{equation}

% where $N$ is the number of samples, $y_i$ is the ground truth label, $p_i$ is the predicted probability, and $\theta$ is the classifier's parameters that need to be optimized.


% \begin{table*}[t]
%     \caption{\textbf{Performance Evaluation of CP-Guard+ on CP-GuardBench.} We report the average accuracy, true positive rate (TPR), false positive rate (FPR), precision, and F1 score of CP-Guard+ on CP-GuardBench with different attack methods and perturbation budgets $\Delta = 0.25, 0.5, 0.75, 1.0$. }
%     \label{tab:quantitative_results_cpguardbench}
%     \centering 
    
%     \renewcommand\arraystretch{1.0}
%     \resizebox{1\linewidth}{!}{
%     \small
%     \begin{tabular}{p{1.2cm}|ccccc|ccccc}
%         \toprule

%         \multirow{2}{*}{ \textbf{Metrics} } & \multicolumn{5}{c|}{$\Delta = 0.10$} & \multicolumn{5}{c}{$\Delta = 0.25$} \\
        
%         & Accuracy $\uparrow$ & TPR $\downarrow$  & FPR $\downarrow$ & Precision $\uparrow$ & F1 Score $\uparrow$ & Accuracy $\uparrow$ & TPR $\uparrow$ & FPR $\downarrow$ & Precision $\uparrow$ & F1 Score $\uparrow$ \\ \midrule

%         PGD&98.77&100.00&1.54&94.19&97.01&98.83&100.00&1.46&94.52&97.18\\
%         BIM&98.90&100.00&1.37&94.81&97.33&98.90&100.00&1.37&94.79&97.32\\
%         C\&W &98.60&99.30&1.58&94.02&96.59&97.96&100.00&2.56&90.38&95.19\\
        
%         FGSM&91.64&64.41&1.46&91.79&75.70&97.53&93.22&1.37&94.50&93.86\\
%         GN &90.95&60.34&1.29&92.23&72.95&97.19&92.12&1.54&93.73&92.92\\ \midrule 
%         Average &95.78&84.81&1.44&93.43&87.93&98.08&97.07&1.66&93.45&95.29\\ \bottomrule\toprule

%         \multirow{2}{*}{ \textbf{Metrics} } & \multicolumn{5}{c|}{$\Delta = 0.50$} & \multicolumn{5}{c}{$\Delta = 0.75$} \\
        
%         & Accuracy $\uparrow$ & TPR $\uparrow$ & FPR $\downarrow$  & Precision $\uparrow$ & F1 Score $\uparrow$ & Accuracy $\uparrow$ & TPR $\uparrow$ & FPR $\downarrow$ & Precision $\uparrow$ & F1 Score $\uparrow$ \\ \midrule

       
%         PGD&98.83&100.00&1.46&94.55&97.20&98.60&100.00&1.75&93.50&96.64\\
%         BIM&98.90&100.00&1.37&94.81&97.33&98.66&100.00&1.67&93.73&96.76\\
%         C\&W &97.30&100.00&3.41&88.46&93.88&96.43&100.00&4.42&84.34&91.50\\
%         FGSM&98.63&98.63&1.37&94.75&96.66&98.83&100.00&1.46&94.48&97.16\\
%         GN &98.49&98.27&1.45&94.35&96.27&98.90&99.96&1.28&95.08&97.32\\ \midrule
%         Average &98.43&99.38&1.81&93.38&96.27&98.53&99.93&1.82&93.20&96.43\\ \bottomrule
%     \end{tabular}
%     }
%     \vspace{-5mm}
% \end{table*}

\begin{table*}[t]
    \caption{\textbf{Performance Evaluation of CP-Guard+ on CP-GuardBench.} We report the average accuracy, true positive rate (TPR), false positive rate (FPR), precision, and F1 score of CP-Guard+ on CP-GuardBench with different attack methods and perturbation budgets $\Delta = 0.10, 0.25, 0.5, 0.75$. }
    \label{tab:quantitative_results_cpguardbench}
    \centering 
    
    \renewcommand\arraystretch{1.0}
    \resizebox{1\linewidth}{!}{
    \small
    \begin{tabular}{p{1.2cm}|ccccc|ccccc}
        \toprule

        \multirow{2}{*}{ \textbf{Metrics} } & \multicolumn{5}{c|}{$\Delta = 0.10$} & \multicolumn{5}{c}{$\Delta = 0.25$} \\
        
        & Accuracy $\uparrow$ & TPR $\uparrow$  & FPR $\downarrow$ & Precision $\uparrow$ & F1 Score $\uparrow$ & Accuracy $\uparrow$ & TPR $\uparrow$ & FPR $\downarrow$ & Precision $\uparrow$ & F1 Score $\uparrow$ \\ \midrule

        PGD&99.79&98.97&0.00&100.00&99.48&99.93&100.00&0.09&99.66&99.83\\
        BIM&99.93&100.00&0.09&99.66&99.83&100.00&100.00&0.00&100.00&100.00\\
        C\&W &99.73&98.96&0.09&99.65&99.30&99.86&100.00&0.17&99.32&99.66\\
        
        FGSM&91.23&56.80&0.09&99.40&72.29&98.77&94.24&0.09&99.64&96.86\\
        GN &91.02&55.63&0.09&99.39&71.33&98.49&92.88&0.09&99.64&96.14\\ \midrule 
        Average &96.34&82.07&0.07&99.62&88.45&99.41&97.42&0.09&99.65&98.50\\ \bottomrule\toprule

        \multirow{2}{*}{ \textbf{Metrics} } & \multicolumn{5}{c|}{$\Delta = 0.50$} & \multicolumn{5}{c}{$\Delta = 0.75$} \\
        
        & Accuracy $\uparrow$ & TPR $\uparrow$ & FPR $\downarrow$  & Precision $\uparrow$ & F1 Score $\uparrow$ & Accuracy $\uparrow$ & TPR $\uparrow$ & FPR $\downarrow$ & Precision $\uparrow$ & F1 Score $\uparrow$ \\ \midrule

       
        PGD&99.86&100.00&0.17&99.32&99.66&99.86&100.00&0.17&99.33&99.66\\
        BIM&99.93&100.00&0.09&99.66&99.83&99.93&100.00&0.09&99.66&99.83\\
        C\&W &99.86&100.00&0.17&99.32&99.66&99.93&100.00&0.09&99.66&99.83\\
        FGSM&99.93&100.00&0.09&99.66&99.83&99.79&99.66&0.17&99.32&99.49\\
        GN &99.86&100.00&0.17&99.32&99.66&99.79&99.65&0.17&99.31&99.48\\ \midrule
        Average &99.89&100.00&0.14&99.46&99.73&99.86&99.86&0.14&99.46&99.66\\ \bottomrule
    \end{tabular}
    }
    \vspace{-5mm}
\end{table*}

\begin{table*}[t]
    \caption{\textbf{Comparative results of CP-Guard+ on the V2X-Sim Dataset.} We report the AP@0.5 and AP@0.7 with different perturbation budgets $\Delta$ and number of malicious agents $N_\text{mal}$. }
    \label{tab:quantitative_results_v2xsim}
    \centering 
    
    \renewcommand\arraystretch{0.9}
    \resizebox{1\linewidth}{!}{
    \small
    \begin{tabular}{c|c|cc|cc|cc|cc}
        \toprule
        % \multirow{2}{*}{ \textbf{Method} } & \multicolumn{8}{c}{ \textbf{IoU} } \\

        \multirow{2}{*}{ {\makecell{Attack\\Method}} }&\multirow{2}{*}{ {\makecell{Defense\\Method}} } & \multicolumn{2}{c|}{$\Delta = 0.25, N_\text{mal} = 1$ } & \multicolumn{2}{c|}{$\Delta = 0.5, N_\text{mal} = 1$} & \multicolumn{2}{c|}{$\Delta = 0.25, N_\text{mal} = 2$} & \multicolumn{2}{c}{$\Delta = 0.5, N_\text{mal} = 2$}\\
               && AP@0.5 & AP@0.7  & AP@0.5 & AP@0.7 & AP@0.5 & AP@0.7  & AP@0.5 & AP@0.7 \\
        \midrule
        \multirow{4}{*}{PGD } & No Defense & 29.73 & 28.47  & 11.35 & 11.17 & 12.69 & 12.42 & 1.69 & 1.65 \\
        & MADE & 64.63 & 45.22 & 64.81 & 44.89 & 62.45 & 43.49 & 63.04 & 43.77 \\
        & ROBOSAC & 62.13 & 42.90 & 63.67 & 43.79 & 59.01 & 40.03 & 59.97 & 40.44 \\
        & CP-Guard+ & \textbf{72.89} & \textbf{71.45} & \textbf{69.50} & \textbf{68.56} & \textbf{69.50} & \textbf{67.92} & \textbf{66.09} & \textbf{64.82} \\ 
        \midrule

        \multirow{4}{*}{C\&W } 
        & No Defense & 19.03 & 16.58 & 4.69 & 3.78 & 19.03 & 16.58 & 0.71 & 0.58 \\
        & MADE & 65.26 & 45.24 & \textbf{64.74} & 45.65 & 63.41 & 44.28  & \textbf{62.86} & 42.93 \\
        & ROBOSAC & 61.83 & 42.01 & 62.47 & 42.80 & 59.39 & 39.94  & 59.83 & 39.82 \\
        & CP-Guard+ & \textbf{69.41} & \textbf{66.86} & {60.64} & \textbf{55.41} & \textbf{64.17} & \textbf{61.73}  & {58.54} & \textbf{53.15} \\
        \midrule

        \multirow{4}{*}{BIM } 
        & No Defense & 26.69 & 25.71 & 10.05 & 9.89 & 11.59 & 11.38 & 1.37 & 1.33 \\ 
        & MADE & 66.11 & 45.94 & 65.51 & 45.47 &  64.36 & 43.89  & 63.56 & 44.09 \\ 
        & ROBOSAC & 62.69 & 43.80  & 63.78 & 43.66 & 59.10 & 39.74  & 59.29 & 39.89 \\ 
        & CP-Guard+ & \textbf{73.35} & \textbf{71.46} & \textbf{66.83} & \textbf{66.05} & \textbf{70.91} & \textbf{69.11}  & \textbf{66.30} & \textbf{64.62} \\ 
        \midrule

        \multirow{4}{*}{Average} 
        & No Defense & 25.15 & 23.59 & 8.70 & 8.28 & 14.44 & 13.46 & 1.27 & 1.19 \\ 
        & MADE & 65.33 & 45.47 & 65.02 & 45.34 & 63.41 & 43.89 & 63.15 & 43.60 \\ 
        & ROBOSAC & 62.21 & 42.90 & 63.31 & 43.42 & 59.37 & 39.90 & 59.70 & 40.05 \\ 
        & CP-Guard+ & \textbf{71.88} & \textbf{69.92} & \textbf{65.66} & \textbf{63.34} & \textbf{68.19} & \textbf{66.25} & \textbf{63.64} & \textbf{60.86}\\ 
        \midrule
        \multicolumn{2}{c|}{Upper-bound} & 79.94 & 78.40& 79.94 & 78.40 & 79.94 & 78.40 & 79.94 & 78.40 \\ 
        \bottomrule
    \end{tabular}
    }
    \vspace{-5mm}
\end{table*}


\subsection{Dual-Centered Contrastive Loss}

In practice, attackers can continuously design new attacks to manipulate the victim's intermediate feature maps. Therefore, we need a model that is resistant to unseen attacks, which means the model should cluster the representation of benign features into a more compact space and ensure that the representation of malicious features is as distant from the benign space as possible.

To tackle this challenge, we propose a Dual-Centered Contrastive Loss (DCCLoss), which is a contrastive learning-based objective function. It explicitly models the distribution relationship between benign and malicious features, enhancing the positive pairs (features of the same class) to their corresponding center closer, thereby enhancing the internal consistency of both benign and malicious features. Meanwhile, negative pairs (features from different classes) will be pushed away from each other's centers, ensuring maximal separation between benign and malicious features in the feature space. In this way, the robustness of the model against unseen attacks is improved.

% To achieve both feature compactness and separation simultaneously, we design a contrastive learning-based objective function. The core ideas of TCCLoss are clustering positive pairs (features of the same class) to their corresponding center closer, thereby enhancing the internal consistency of both benign and malicious features. Meanwhile, negative pairs (features from different classes) will be pushed away from each other's centers, ensuring maximal separation between benign and malicious features in the feature space.

Specifically, we first leverage the output of the penultimate fully connected layer $f_{\text{cls}}$ to obtain the one-dimensional vector $\{\mathcal{V}_i\}_{i=0,1,\ldots, N-1}$ of residual features $\{\mathbf{F}^\mathtt{res}_{j\rightarrow i}\}_{j\neq i,\  j\in \mathcal{X}^N}$. Then, we introduce two feature centers in DCCLoss: 
\begin{enumerate}
    \vspace{-3mm}
    \setlength{\itemsep}{0pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}
    % \item Global center ($\mathbf{c}_{\mathtt{glb}}$): Represents the overall distribution center of all features (both benign and malicious), capturing the global structure of the feature space. 
    % \vspace{-3mm}
    % \begin{equation}
    %     % \mathbf{c}_\mathtt{glb} = \frac{1}{N}\sum_{i=0}^{N} \frac{\mathcal{V}_i}{\|\mathcal{V}_i\|}
    %     \mathbf{c}_x = \frac{1}{N}\sum_{i=0}^{N}{\mathcal{V}_i}
    % \end{equation}
    % \vspace{-3mm}
    \item Benign feature center ($\mathbf{c}_{\mathtt{b}}$): represents the center of all benign features, ensuring a compact distribution of benign features.
    \item Malicious feature center ($\mathbf{c}_{\mathtt{mal}}$): represents the center of all malicious features, ensuring maximal separation between malicious and benign feature distributions.
    \vspace{-3mm}
    
    % \vspace{-3mm}
    % \item Malicious feature center ($\mathbf{c}_{\mathtt{mal}}$): Represents the center of all malicious features, ensuring maximal separation between malicious and benign feature distributions. Given the malicious vector set $\{\mathcal{V}_\mathtt{mal}\}$ and the number of malicious vectors $N_\mathtt{mal}$, the malicious feature center is computed as:
    % \vspace{-3mm}
    % \begin{equation}
    %     \mathbf{c}_\mathtt{mal} = \frac{1}{N_\mathtt{mal}}\sum_{\mathcal{V}_i\in \{\mathcal{V}_\mathtt{mal}\}}^{N_\mathtt{mal}} \mathcal{V}_i
    % \end{equation}
\end{enumerate}
The benign feature center $\mathbf{c}_\mathtt{b}$ and the malicious feature center $\mathbf{c}_\mathtt{mal}$ are computed by averaging the vectors of benign and malicious features, respectively:
\vspace{-2mm}
\begin{equation}
    \mathbf{c}_\mathtt{b} = \frac{1}{N_\mathtt{b}}\sum_{\mathcal{V}_i\in \{\mathcal{V}_\mathtt{b}\}}^{N_\mathtt{b}} \mathcal{V}_i, \quad  \mathbf{c}_\mathtt{mal} = \frac{1}{N_\mathtt{mal}}\sum_{\mathcal{V}_i\in \{\mathcal{V}_\mathtt{mal}\}}^{N_\mathtt{mal}} \mathcal{V}_i.
\end{equation}
where $N_\mathtt{b}$ and $N_\mathtt{mal}$ are the numbers of benign and malicious vectors, respectively, and $\mathcal{V}_\mathtt{b}$ and $\mathcal{V}_\mathtt{mal}$ are the sets of benign and malicious vectors, respectively.

Moreover, denote $(\mathcal{V}_m, \mathcal{V}_n)$ as a pair of features, which is a positive pair if they are from the same class (both benign or malicious) and a negative pair otherwise. We have the DCCLoss of one feature pair $\ell(\mathcal{V}_m, \mathcal{V}_n)$ as:
\begin{equation}
    \begin{aligned}
    &\ell\left(\mathcal{V}_m, \mathcal{V}_n\right)=-\log \\
    &\frac{\exp\left((\mathcal{V}_m-\mathbf{c}^{(m)})\odot  (\mathcal{V}_n-\mathbf{c}^{(n)})/\tau\right)}
        {\sum_{o=1, o\neq m}^{N} \mathbb{I}\cdot\exp\left((\mathcal{V}_m-\mathbf{c}^{(m)})\odot  (\mathcal{V}_o-\mathbf{c}^{(o)})/\tau\right)},\\
    & \text{where}\ \mathcal{V}_x - \mathbf{c}^{(x)}= 
    \left\{\begin{aligned}
        &\mathcal{V}_x - \mathbf{c}_\mathtt{b}, & \text{if } \mathcal{V}_x \in \{\mathcal{V}_\mathtt{b}\},\\ 
        &\mathcal{V}_x - \mathbf{c}_\mathtt{mal}, & \text{if } \mathcal{V}_x \in \{\mathcal{V}_\mathtt{mal}\},
    \end{aligned}\right.
    \end{aligned}
\end{equation}
where $\mathbb{I}(\mathcal{V}_m, \mathcal{V}_o)$ is an indicator function that returns one or zero for positive or negative pairs, respectively. $\tau$ is a temperature parameter and $\odot$ denotes the cosine similarity, where $\mathcal{V}_m\odot \mathcal{V}_n = \frac{\mathcal{V}_m^\top  \mathcal{V}_n}{\|\mathcal{V}_m\|\|\mathcal{V}_n\|}$.
The final DCCLoss is the average of $\ell$ of all positive pairs.
\begin{equation}
    \mathcal{L}_\mathtt{DCCLoss}= \sum_{m=1}^{N} \sum_{n=m+1}^{N} \frac{\left(1-\mathbb{I}(\mathcal{V}_m, \mathcal{V}_n)\right)\ell\left(\mathcal{V}_m, \mathcal{V}_n\right)}{C(N,2)},
    \label{eq:contrastive_loss}
\end{equation}
where $C(N,2)= \binom{N}{2}={N!}/({2!(N-2)!})$. 
During training, we use the combination of cross entropy loss and Eq. \ref{eq:contrastive_loss} to optimize the model:
\begin{equation}
    \mathcal{L} = \mathcal{L}_\mathtt{CE} + \alpha\cdot \mathcal{L}_\mathtt{DCCLoss}
    \label{eq:mixed_loss}
\end{equation}
where $\alpha$ is a hyperparameter to balance the two losses.

\textbf{Discussion of DCCLoss.} In so doing, the first term $\mathcal{L}_\mathtt{CE}$ quantifies the difference between the true distribution and the predicted distribution from the model, thereby penalizing the confidence in wrong predictions. The second term $\mathcal{L}_\mathtt{DCCLoss}$ contributes significantly to the learning process. Standard contrastive loss attempts to maximize the distance between negative pairs, which may cause the features of benign samples to gradually drift away from their center. However, DCCLoss calculates the distance using the feature center as a reference point, thus avoiding this issue. The optimization goal of DCCLoss is to maximize the angular distance between negative pairs to enhance feature discriminability while maintaining the compactness of benign sample features, keeping them as close to the feature center as possible. 
In other words, the introduction of dual-center modeling optimizes the distributional relationship between benign and malicious features, making them more separable and making the distributions of benign and malicious features more compact on its own, respectively. This helps resolve the distribution overlap problem and enhances the model's ability to detect unseen attacks.






