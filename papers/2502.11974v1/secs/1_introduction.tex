\section{Introduction} \label{sec:introduction}



\begin{figure*}[thp]
    \centering
    \includegraphics[width=1\linewidth]{figs/teaser.pdf}
    \vspace{-2.0em}
    \caption{
    \textbf{Left:} Diagrammatic overview of the general formulaic description of image inversion (\textbf{\uppercase\expandafter{\romannumeral1}}), as well as its instantiation in GAN (\textbf{\uppercase\expandafter{\romannumeral2}}) and Diffusion (\textbf{\uppercase\expandafter{\romannumeral3}}) frameworks. 
    \textbf{Right:} Works summarization on different frameworks in recent years. 
    Only the works from the past four years are listed. Due to the superior performance of diffusion models, the interest in GAN-based work has been declining annually. 
    }
    \vspace{-1.5em}
    \label{fig:teaser}
\end{figure*}


Image inversion refers to the task of mapping a given image back to the latent representation with a pre-trained generative model. This task holds significant importance in applications such as image editing, style transfer, image restoration, \textit{etc}~\cite{survey1,survey2}. Through inversion techniques, users can effectively leverage the rich semantic information of generative models to achieve efficient control and modification of real images, making it an increasingly independent and active research direction.

Early researches on image inversion began with the rise of GANs~\cite{iGAN}, focusing primarily on how to project images into the latent space of GANs to facilitate subsequent image editing and generation tasks. The advent of the StyleGAN series~\cite{StyleGAN,StyleGAN2} notably improved the accuracy and efficiency of image inversion techniques. However, these methods have certain limitations~\cite{e4e,PTI,SDIC}: encoder-based one-forward approaches still yield suboptimal results, while optimization-based methods are time-consuming and fail to meet the demands of general image editing and high-precision applications, such as portrait photography. 
In recent years, diffusion models have emerged as a new favorite in the field of generative models due to their powerful generative capabilities and stable training processes. From DDPM~\cite{DDPM}/DDIM~\cite{DDIM} to LDM~\cite{LDM}, open-source models like the Stable Diffusion series have significantly enhanced the controllability and effectiveness of image editing, leading to numerous excellent training-free and fine-tuning solutions~\cite{Negative-prompt,StyleID,FreeControl}. Recent breakthroughs, such as the DiT~\cite{DiT} framework and flow matching techniques, have provided new insights and methods for image inversion. The diverse development from GANs to diffusion models has also laid the foundation for high-fidelity image inversion tasks and controllable editing applications in complex scenarios.

This survey systematically reviews and summarizes the development trajectory of these technologies, abstractly defining the problem from a formulaic perspective, and delving into the principles and practical issues of different categories of methods. It comprehensively covers image inversion and related subfields, providing a thorough discussion.


\nibf{Scope.} 
This paper focuses on the two main frameworks for image inversion: GAN inversion and diffusion model inversion. For GAN inversion, we conduct a comprehensive analysis and comparison from three perspectives: Encoder-based Approaches, Latent Optimization Approaches, and Hybrid Approaches. For diffusion model inversion, we categorize the methods from a training perspective into Training-free Approaches, Fine-tuning Approaches, and Extra Trainable Module Approaches, discussing the advantages and disadvantages of each. Additionally, we analyze the latest technological trends, such as DiT-based inversion methods\cite{DiT4Edit}, and explore the applications of inversion techniques in images and broader fields like video\cite{Videoshop} and audio\cite{ZETA}. This survey primarily analyzes work post-2021 to ensure its relevance and forward-looking nature. Due to space constraints, only representative works are discussed, with comprehensive and up-to-date work continuously tracked on this \href{https://github.com/RyanChenYN/ImageInversion}{\textcolor{magenta}{project page}}.

\nibf{Discussion with Related Surveys.}
Compared to existing surveys, such as ~\cite{survey1} which focuses on early GAN-based approaches, and recent work ~\cite{survey2} which focuses on diffusion-based approaches, this survey integrates GAN inversion and diffusion model inversion into a unified framework for systematic comparison, filling a research gap in this field. It also extends the discussion of inversion to non-image applications, providing readers with a more comprehensive perspective.

\nibf{Contributions.}
Firstly, we provide a thorough review of the latest advancements in the field of image inversion, covering the key inversion techniques of the two main generative models (GANs and diffusion models). By systematically categorizing these methods, we reveal the intrinsic connections and technical differences, offering clear theoretical guidance for researchers. Secondly, we discuss the primary applications from an image-level perspective and related field advancements. Finally, we summarize the current challenges in the research and propose a series of potential future research directions, providing important references for further development in the field of image inversion.


