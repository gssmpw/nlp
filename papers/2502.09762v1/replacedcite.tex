\section{Related Work}
\label{appendix:rw}

\begin{table*}[!ht]
    \centering
    \caption{Comparison of \framework with related works. Grey rows represent  literature related to multi-drone pursuit, while pink rows highlight adaptive teaming studies from the machine learning field. ``AT w/o TM'' denotes adaptive teaming without teammate modelling, while ``AT w/ TM'' refers to adaptive teaming with teammate modelling.}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c|c|c|c|c}
        \toprule
        \multirow{2}{*}{\textbf{Related Work}} & \multicolumn{4}{c|}{\textbf{Problem Setting}}& \multicolumn{2}{c|}{\textbf{Task}} & \multicolumn{2}{c}{\textbf{Method}} \\
        \cline{2-9}
        & \textbf{\# Learner} & \textbf{\# Unseen} & \textbf{\# Evader} &\textbf{Action Space} & \textbf{Main Related Task} & \textbf{Real-world?} & \textbf{AT w/o TM?} & \textbf{AT w/ TM?} \\
        \midrule 
        \rowcolor{gray!10} 
        Voronoi Partitions____ & Multi & 0 & 1  & Continuous &  Pursuit–evasion Game & \No & \No & \No \\ 
        \cline{1-9}
        \rowcolor{gray!10} 
        Bio-pursuit____  & Multi & 0 & Multi & Continuous &  Prey–predator Game & \No & \No & \No \\
        \cline{1-9}
        \rowcolor{gray!10} 
        Uncertainty-pursuit____ & Multi & 0 & 1 & Continuous & Pursuit–evasion Game & \No & \No & \No \\ 
        \cline{1-9}
        \rowcolor{gray!10}
        M3DDPG____ & Multi & 0 & 1 & Continuous &  Prey–predator Game & \No & \No & \No \\ 
        \cline{1-9}
        \rowcolor{gray!10}
        Pursuit-TD3____ & Multi & 0 & 1 & Continuous &  \textbf{\textcolor{blue}{Multi-drone Pursuit}} & \Yes & \No & \No \\ 
        \cline{1-9}
        \rowcolor{gray!10} 
        DACOOP-A____ & Multi & 0 & 1 & Discrete &  \textbf{\textcolor{blue}{Multi-drone Pursuit}} & \Yes & \No & \No \\ 
        \cline{1-9}
        \rowcolor{gray!10} 
        GM-TD3____  & Multi & 0 & 1 & Continuous & Prey–predator Game & \No & \No & \No \\ 
        \cline{1-9}
        \rowcolor{gray!10} 
        DualCL____ & Multi & 0 & 1 & Continuous & \textbf{\textcolor{blue}{Multi-drone Pursuit}} & \No & \No & \No \\ 
        \cline{1-9}
        \rowcolor{gray!10}
        HOLA-Drone____  &  1 & Multi & Multi & Continuous & \textbf{\textcolor{blue}{Multi-drone Pursuit}} & \Yes & \Yes  & \No \\ 
        \midrule
        \rowcolor{pink!30} 
        Other-play____ & 1 & 1 & 0 &  Discrete & Lever Game; Hanabi &  \No & \Yes  & \No \\ 
        \cline{1-9}
        \rowcolor{pink!30} 
        Overcooked-AI ____ & 1 & 1 & 0 &  Discrete & Overcooked &  \No & \Yes  & \No \\ 
        \cline{1-9}
        \rowcolor{pink!30} 
        TrajDi____  & 1 & 1 & 0 &  Discrete & Overcooked &  \No & \Yes  & \No \\ 
        \cline{1-9}
        \rowcolor{pink!30} 
        MEP____  & 1 & 1 & 0 &  Discrete & Overcooked &  \No & \Yes  & \No \\ 
        \cline{1-9}
        \rowcolor{pink!30} 
        LIPO____  & 1 & 1 & 0 &  Discrete & Overcooked &  \No & \Yes  & \No \\ 
        \cline{1-9}
        \rowcolor{pink!30} 
        COLE____  & 1 & 1 & 0 &  Discrete & Overcooked &  \No & \Yes  & \No \\ 
        \cline{1-9}
        \rowcolor{pink!30} 
        ZSC-Eval____  & 1 & 1 & 0 &  Discrete & Overcooked &  \No & \Yes  & \No \\ 
        \cline{1-9}
       \rowcolor{pink!30}  
       PLASTIC____  &  1 & Multi & Multi & Discrete & Prey-predator Game &  \No & \No & \Yes \\ 
       \cline{1-9} 
        \rowcolor{pink!30} 
        AATeam____  & 1 & 1 & 2 &  Discrete & Half Field Offense &  \No & \No & \Yes  \\  
        \cline{1-9} 
        \rowcolor{pink!30} 
        LIAM____  &  1 & Multi & %\rowcolor{pink!30} 
        Multi & Discrete & LBF; Prey-predator Game  &  \No & \No & \Yes   \\ 
        \cline{1-9} 
       \rowcolor{pink!30}  
       GPL____  &  1 & Multi & Multi & Discrete & LBF; Wolfpack; FortAttack &  \No & \No & \Yes   \\ 
       \cline{1-9} 
       \rowcolor{pink!30}   
       CIAO____ &  1 & Multi & Multi & Discrete &LBF; Wolfpack &  \No & \No & \Yes \\ 
       \cline{1-9} 
       \rowcolor{pink!30}   
       NAHT____  & Multi & Multi & Multi & Discrete & StarCraft2 &  \No & \No & \Yes \\
         \midrule
         \rowcolor{orange!30} 
         Our ATMDP  & Multi & Multi & Multi & Continuous & \textbf{\textcolor{blue}{Multi-drone Pursuit}} &  \Yes & \Yes & \Yes \\
         \bottomrule
    \end{tabular}
    }
    \label{appendix:tab_rw}
\end{table*}

In this work, we provide a comprehensive review of related research on multi-drone pursuit and adaptive teaming in machine learning, with a detailed comparison presented in Table~\ref{tab:review}.

\textbf{Multi-agent pursuit-evasion. } 
Multi-agent pursuit-evasion is closely related to the multi-drone pursuit task. 
Most existing methods rely on pre-coordinated strategies specifically designed for particular pursuit-evasion scenarios.
Traditional approaches often rely on heuristic____ or optimisation-based strategies____. For example, ____ proposes a bio-inspired model that uses local interaction rules to enhance group chasing success in Prey–Predator Games. Similarly, the Voronoi partitions algorithm____ and the uncertainty-pursuit algorithm____ employ decentralised frameworks to optimise the evader’s Voronoi partition and reachable area, respectively.
In recent years, deep reinforcement learning (DRL) has been widely adopted for pre-coordinated multi-drone pursuit tasks. M3DDPG____ and GM-TD3____ extend standard DRL algorithms, such as TD3____ and DDPG____, specifically for multi-agent pursuit in simulated environments. Pursuit-TD3____ applies the TD3 algorithm to pursue a target with multiple homogeneous agents, validated through both simulations and real-world drone demonstrations. ____ introduces DACOOP-A, a cooperative pursuit algorithm that enhances reinforcement learning with artificial potential fields and attention mechanisms, validated in real-world drone systems. DualCL____ addresses multi-UAV pursuit-evasion in diverse environments and demonstrates zero-shot transfer capabilities to unseen scenarios, though only in simulation.
The most recent work, HOLA-Drone____, claims to be the first zero-shot coordination framework for multi-drone pursuit. However, it is limited to controlling a single learner, restricting its applicability to broader multi-agent settings. 


\textbf{Adaptive Teaming. }The adaptive teaming paradigm can be broadly categorised into two approaches: adaptive teaming without teammate modelling (AT w/o TM) and adaptive teaming with teammate modelling (AT w/ TM), which correspond to the zero-shot coordination (ZSC) and ad-hoc teamwork (AHT) problems in the machine learning community, respectively.
AT w/o TM focuses on enabling agents to coordinate with unseen teammates without explicitly modelling their behaviours. Other-Play____ introduces an approach that leverages symmetries in the environment to train robust coordination policies, applied to discrete-action tasks like the Lever Game and Hanabi. Similarly, methods such as Overcooked-AI____, TrajDi____, MEP____, LIPO____, and ZSC-Eval____ study collaborative behaviours in Overcooked, where agents learn generalisable coordination strategies with diverse unseen partners. While these approaches demonstrate promising results, they are limited to single-learner frameworks in simplified, discrete-action domains like Overcooked and Hanabi. They lack scalability to multi-agent settings, continuous action spaces, and the complexities of real-world applications.

AT w/ TM, on the other hand, explicitly models the behaviour of unseen teammates to facilitate effective collaboration. Early methods like PLASTIC____ reuse knowledge from previous teammates or expert input to adapt to new teammates efficiently. AaTeam____ introduces attention-based neural networks to dynamically process and respond to teammates’ behaviours in real-time.
More advanced approaches, such as LIAM____, employ encoder-decoder architectures to model teammates using local information from the controlled agent. GPL____ and CIAO____ leverage graph neural networks (GNNs) to address the challenges of dynamic team sizes in AHT. Extending this further, NAHT____ enables multiple learners to collaborate and interact with diverse unseen partners in N-agent scenarios.
Despite their progress, these methods remain confined to discrete action spaces and simulated benchmarks, limiting their applicability to real-world, continuous-action tasks. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/OPT.pdf}
    \caption{Overview of our proposed open-ended population training algorithm.}
    \label{fig:opt}
\end{figure}