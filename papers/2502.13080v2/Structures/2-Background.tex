\subsection{Gene Expression Classification with ML models}
Gene expression classification \cite{do2024enhancing,do2023ensemble,huynh2019novel} lies at the forefront of biomedical research, offering profound insights into the molecular mechanisms underlying various diseases. ML models have become indispensable in this domain, as they can uncover complex patterns within vast and high-dimensional gene expression datasets. However, these datasets often contain a plethora of features, many of which are redundant or irrelevant, potentially obscuring the most critical biological signals and leading to overfitting. Consequently, feature selection becomes imperative—it refines the dataset by isolating the most informative genes, thereby enhancing model accuracy, interpretability, and computational efficiency. By focusing solely on the pivotal biomarkers, this research is able to achieve more reliable predictive outcomes. In this paper, we investigate and evaluate the classification with various ML techniques. Namely, we experiment our selected features with ML algorithms, i.e., SVM \cite{vapnik1995support}, Random Forest \cite{breiman2001random}, XGB \cite{chen2015xgboost}, Gradient Boosting \cite{friedman2002stochastic}.

\begin{definition}[Classification]
Let \( D = (X, y) \) be a dataset where \( X \subseteq \mathbb{R}^n \) is the feature space and \( y \in \mathcal{Y} = \{1,2,\dots,k\} \) represents the class labels. A classifier is a function
\[
f: X \to \mathcal{Y},
\]
that assigns a predicted label \( \hat{y} = f(x) \) to each input \( x \in X \). The function \( f \) is learned from the labeled examples
\[
D = \{(x_i, y_i) \mid x_i \in X,\; y_i \in \mathcal{Y},\; i = 1, \dots, N\},
\]
by minimizing a loss function \( \ell: \mathcal{Y} \times \mathcal{Y} \to \mathbb{R}_{\ge 0} \) that quantifies the error between the predicted and true labels. Once trained, \( f \) is used to classify new, unseen inputs.
\end{definition}

% \begin{definition}[Classification Using Machine Learning]
% Let \( D_{\text{selected}} = (X_{\text{selected}}, y) \) be the dataset with features \( X_{\text{selected}} \subseteq X^* \) as determined by LIME. A classifier is a function 
% \[
% f: X_{\text{selected}} \to \mathcal{Y},
% \]
% that assigns a predicted label \( \hat{y} = f(x) \) to each input \( x \in X_{\text{selected}} \). The classifier is trained on the labeled examples
% \[
% D_{\text{selected}} = \{(x_i, y_i) \mid x_i \in X_{\text{selected}},\; y_i \in \mathcal{Y},\; i = 1, \dots, N\},
% \]
% by minimizing a loss function \( \ell: \mathcal{Y} \times \mathcal{Y} \to \mathbb{R}_{\ge 0} \) that measures the discrepancy between the predicted and true labels. The trained classifier is then used to predict the classes of new, unseen instances.
% \end{definition}


Feature selection is crucial before classification begins. Our study focuses on two techniques: Boruta and LIME. 
% Boruta is chosen for its robustness in identifying all relevant features in high-dimensional datasets, ensuring no important predictor is missed. LIME is used for its ability to provide interpretable, local explanations of model predictions, which is essential for evaluating feature importance. 
We now introduce Boruta and LIME in the following sections.

\subsection{Leveraging Boruta for Robust Feature Extraction}
Boruta \cite{kursa2010boruta,zhou2023diabetes} is a powerful wrapper-based feature selection algorithm designed to identify all truly relevant variables in a dataset. By comparing the importance of actual features with that of randomly generated ``shadow'' features, Boruta systematically filters out irrelevant variables while preserving essential predictors. This rigorous selection process is particularly valuable in high-dimensional applications, such as gene expression classification, where capturing meaningful signals is crucial. For clarity, we formally define Boruta as follows:
\begin{definition}[Boruta Feature Selection]
Let \( D = (X, y) \) be a dataset with features \( X = \{x_1, x_2, \dots, x_p\} \) and target \( y \). The Boruta algorithm identifies all relevant features in \( X \) as follows:
\begin{enumerate}
    \item \textbf{Shadow Feature Generation:} For each \( x_i \in X \), create a shadow feature \( x_i^{\text{shadow}} \) by randomly permuting its values, forming the set \( X^{\text{shadow}} \).
    \item \textbf{Importance Estimation:} Train a classifier (e.g., Random Forest) on the combined set \( X \cup X^{\text{shadow}} \) and compute the importance score \( I(z) \) for each \( z \).
    \item \textbf{Feature Comparison:} For each \( x_i \), define
    \[
    I^{\text{shadow}}_{\max} = \max_{z \in X^{\text{shadow}}} I(z).
    \]
    Then classify \( x_i \) as \emph{relevant} if \( I(x_i) \) is significantly greater than \( I^{\text{shadow}}_{\max} \), \emph{irrelevant} if significantly lower, or \emph{tentative} otherwise.
    \item \textbf{Iteration:} Remove irrelevant and tentative features and repeat until all features are decisively classified.
\end{enumerate}
The final selected subset \( X^* \subseteq X \) comprises all features deemed relevant.
\end{definition}

After applying the Boruta algorithm, we retain only the relevant features (confirmed) and excluded the tentative and irrelevant features (rejected). To further enhance the selection of features in \(X^*\), we employed the AI explanation technique outlined in the following section.

% \begin{definition}[Boruta Feature Selection]
% Given a dataset \( D = (X, y) \) with original features \( X = \{ x_1, x_2, \dots, x_p \} \), Boruta augments \( X \) by creating shadow features \( X^{\text{shadow}} = \{ x_1^{\text{shadow}}, \dots, x_p^{\text{shadow}} \} \) via random permutation. A model \( M \) (e.g., Random Forest) is then trained on \( X \cup X^{\text{shadow}} \) to compute importance scores \( I(z) \) for every feature \( z \). For each \( x_i \in X \), if \( I(x_i) \) is significantly greater than the maximum shadow importance \( I^{\text{shadow}}_{\max} = \max_{z \in X^{\text{shadow}}} I(z) \), then \( x_i \) is marked as relevant; otherwise, it is rejected or considered tentative. Iterating this process yields the final set of selected features \( X^* \subseteq X \).
% \end{definition}

\subsection{XAI for Feature Selection}
Explainable AI (XAI) \cite{dwivedi2023explainable,zacharias2022designing} represents a forefront of AI research, aiming to elucidate the decision-making processes of complex models. In the context of gene expression classification, where feature selection is pivotal to model performance and interpretability, our study leverages LIME—Local Interpretable Model-Agnostic Explanations—to demystify and select critical features. LIME approximates the behavior of a sophisticated, black-box model with a simpler, locally interpretable surrogate, thereby pinpointing the most influential predictors in the vicinity of a given instance. This approach enhances the transparency of the model's predictions and facilitates a more informed and rigorous feature selection process, ultimately contributing to both improved accuracy and trustworthiness of the classification system.  Now, we provide a formal definition of LIME as follows:

% \begin{definition}[LIME-based Feature Selection]
% Let \( D = (X, y) \) be a dataset and \( f: X \to \mathcal{Y} \) a trained black-box classifier, where \( X \subseteq \mathbb{R}^p \) and \( \mathcal{Y} = \{1,2,\dots,k\} \). For a given instance \( x \in X \), LIME constructs an interpretable surrogate model \( g \) from a simple model class \( G \) (typically linear), expressed as
% \[
% g(z) = w_0 + \sum_{j=1}^{p} w_j z_j.
% \]
% The surrogate \( g \) is fitted by minimizing the weighted loss
% \[
% \min_{g \in G} \sum_{z \in Z_x} \pi_x(z) \left( f(z) - g(z) \right)^2 + \Omega(g),
% \]
% where \( Z_x \) is a set of perturbed samples around \( x \), \( \pi_x(z) \) is a proximity measure between \( z \) and \( x \), and \( \Omega(g) \) is a regularization term enforcing simplicity. The absolute coefficients \( |w_j| \) quantify the local importance of each feature, thus guiding feature selection.
% \end{definition}
\begin{definition}[LIME-based Feature Selection]
Let \( D^* = (X^*, y) \) be the dataset resulting from Boruta, where \( X^* \subseteq \mathbb{R}^{p^*} \) is the set of relevant features. Given a trained black-box classifier \( f: X^* \to \mathcal{Y} \) and an instance \( x \in X^* \), LIME constructs an interpretable surrogate model \( g \in G \) (typically linear), expressed as
\[
g(z) = w_0 + \sum_{j=1}^{p^*} w_j z_j,
\]
by solving the optimization problem
\[
\min_{g \in G} \sum_{z \in Z_x} \pi_x(z) \left( f(z) - g(z) \right)^2 + \Omega(g),
\]
where \( Z_x \) is a set of perturbed samples in the neighborhood of \( x \), \( \pi_x(z) \) is a proximity measure, and \( \Omega(g) \) enforces simplicity. The absolute coefficients \( |w_j| \) indicate the local importance of each feature, enabling a further refined selection \( X_{\text{selected}} \subseteq X^* \) for classification.
\end{definition}


To clarify, our choice of LIME for feature selection arises from the critical question of determining the optimal number of features for the model. In this context, assessing the local importance of each vector proves to be the most effective strategy, leading us to introduce the BOLIMES algorithm. The following section will provide a comprehensive explanation of the BOLIMES algorithm and its application.

%--------------------




