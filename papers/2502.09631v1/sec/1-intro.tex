\section{Introduction}
Creating realistic and artistically expressive 3D volumetric smoke is a complex task in computer graphics, with applications in film productions. 
The nonlinearity of numerous physical factors within the fluid motion, described by the Navierâ€“Stokes equations~\cite{bridson2015fluid}, lead to the inherent turbulence and ever-changing patterns in smoke simulations. 
To assist artists in achieving creative smoke stylization, there is a need for an intuitive way to input style references and get stylization results quickly. 
It is challenging to preserve the \textbf{spatiotemporal} consistency of the stylized volumetric smoke: maintaining spatial and temporal consistency across multiview and consecutive frames, together with having a stylization that matches the style image and preserving an overall plausible fluid motion. 
Additionally, high-resolution smoke simulations require a lightweight rendering algorithm to manage memory efficiently during training.


\input{sec/table-related}


Existing work for volumetric smoke stylization with a given style image can be classified into two types, see \Cref{tab:baseline}. 
\textit{Optimization-based} volumetric Neural Style Transfer (NST) techniques model 3D fluid through either Eulerian~\cite{kim19c} or Lagrangian~\cite{kimlnst} framework, iteratively stylizing the smoke simulation with loss functions similar to image style transfer~\cite{gatys2016image}. 
While these methods achieve temporal coherence by introducing an inter-frame smoothing loss, their computation costs scale up excessively and become unpractical for multi-view optimizations~\cite{kanyuk2023singed}.  
Other approaches~\cite{guo2021volumetric, aurand2022efficient} train \textit{feed-forward} 3D convolutional neural networks (CNN), using the original volume and style image as input to directly output the stylized volume.
These methods can produce multi-view consistent stylization. 
However, as a consequence of using large neural networks with millions of parameters, the training time for density-only stylization may take up to 20 hours, and 70 hours for colored albedo volumes.
\Cref{tab:baseline} summarizes the characteristics of the two categories of methods. 

In this work, we provide a new perspective on volumetric stylization by synthesizing a 3D texture volume that is inherently dynamic and continuously aligns with input smoke motion.
We propose Volumetric Neural Cellular Automata (\MethodName{}), a novel method that efficiently achieves high spatiotemporal consistency for stylizing smoke simulation given a reference style image. 
Our approach is reminiscent of \textit{Solid Texture} methods for mesh texturing \cite{on-demand-solid-texture, kopf2007solid, solid_textures}, with the key distinction that our synthesized texture volume is dynamic and iteratively updated, matching the motion of the smoke simulation. 


\MethodName{} is parameterized by a small \textit{recurrent} neural network\footnote{VNCA update rule is applied over different timesteps to update cell states. The cell states in VNCA resemble the hidden state in RNNs and the VNCA update rule resembles the time-invariant neural network of RNNs. } and is fast to train.  
It is trained on a single frame of the density sequence, and yet it can generalize to unseen density frames during inference for stylization in \textit{real-time}. 
We utilize the inherent spontaneous moving patterns of NCA-generated textures and match the motion of the smoke simulation to create a visually plausible fluid stylization. 
Since our synthesized 3D texture volume is naturally dynamic, we do not need to explicitly model fluid advection, nor to apply interframe smoothing terms to enforce temporal coherence. 
These advantages, coupled with the strong generalization ability of our NCA model, allow us to achieve a speedup in training of over an order of magnitude while creating high-quality smoke stylization.
Moreover, we show that our method can be adapted to mesh stylization by utilizing a similar training strategy as Solid Texturing methods, achieving results on par with existing methods.   


 

\noindent To summarize, our contributions are as follows:
\begin{itemize}[leftmargin=*]
    \item We propose \MethodName{}, a novel method to stylize 3D smoke simulations in real-time. VNCA generalizes to the whole simulation sequence while trained on a single frame. 
    \item Our stylization for the 3D smoke simulation is spatiotemporally consistent w.r.t the input reference image. 
    \item \MethodName{} speeds up training by over an order of magnitude. 
    \item \MethodName{} synthesizes texture volumes for mesh stylization. 
\end{itemize}