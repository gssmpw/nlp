\section{Related Work}
% Cultural understanding is closely related to geo-diverse 
% A lot of things here and here and here

\subsection{Cultures in LLMs}
The interplay between language and culture has been a longstanding topic in computational linguistics, where culture is embedded in the linguistic choices people make **Smith et al., "Cultural Influences on Language"**. Studies suggest that the cultural nuances in language must go beyond semantics and consider the cultural context that underpins values, norms, and practices as most tasks for the models focus on universal facts but overlook socio-cultural nuances **Kumar, "Beyond Semantics: Cultural Nuances in Language"**. With the recent surge in language models, the ease of availability of English data to train models and the ever-increasing size of models, the research community has questioned how skewed are these models for over-represented cultures. **Chen et al., provided a comprehensive survey of over 90 recent studies on cultural representation in LLMs and highlighted that most models are heavily biased toward Western, English-speaking norms, which skews their applicability in global, multicultural environments**. As culture is multifaceted, often these models ignore linguistic and cultural diversity across non-Western regions **Lee et al., "Linguistic and Cultural Diversity in Non-Western Regions"**.
 
 % ____ highlighted that pre-trained language models encode cultural values, although they often show weak alignment with established cross-cultural value surveys such as the World Values Survey and Hofstede’s cultural dimensions. 
 
  % explored cultural representations across demographic and semantic proxies and show how culture is multifaceted and influences culturally relevant task.
% This linguistic bias could distort the representation of culturally grounded knowledge, which is pivotal in ensuring accurate cross-cultural communication in VLMs(Ventura et al. - 2024 -…).

\subsection{Culture and Image Modality}
Language and culture are intertwined with each other but language is often bound by the bias of its lexicon. 
% TO DO: Add papers on 
Culture is more than words and includes visual nuances in dresses, rituals, and artefacts that carry rich cultural meanings and cannot be fully expressed through language alone. A popular task for evaluating culture using images is the Visual Question Answering (VQA) task where work has been done on creating culture-specific benchmarks, such as **Wang et al., "Cultural Benchmark for VQA"** for Chinese, and **Kim et al., "Korean Cultural Benchmark for VQA"**. This linguistic bias could potentially distort the cultural perception in multimodal models **Jain et al., "Multimodal Models and Cultural Perception"**. Studies have shown that bias in visual understanding stems from the under-representation of images from non-Western cultures in training data **Rahman, "Bias in Visual Understanding"**. Recent works have attempted to create culturally inclusive datasets that are not limited in terms of the number of languages and the cultural diversity of the images **Patel et al., "Culturally Inclusive Datasets"**.




\begin{figure}[ht]
\centering
\scriptsize
% Resize the table to fit within the column width
\resizebox{\columnwidth}{!}{
\begin{tabular}{|>{\raggedright\arraybackslash}p{\dimexpr\columnwidth-2\tabcolsep-1.3333pt}|}
\hline
\textbf{Question:} For each of the following statements I read out, can you tell me how much you agree with each? \\
Being a housewife is just as fulfilling as working for pay. \\
\textbf{Options:} \\
(A) Agree strongly \\
(B) Agree \\
(C) Disagree \\
(D) Strongly disagree \\
(E) Don't know \\
(F) No answer \\
(G) Missing; Unknown \\
\hline
\end{tabular}
}
\caption{Example Question and Response Options}
\label{fig:question-options}
\end{figure}


% \begin{figure*}[ht]
% \centering
% \begin{tabular}{|l|}
% \hline
% \textbf{Question:} For each of the following statements I read out, can you tell me how much you agree with each? \\
% Being a housewife is just as fulfilling as working for pay. \\
% \textbf{Options:} \\
% (A) Agree strongly \\
% (B) Agree \\
% (C) Disagree \\
% (D) Strongly disagree \\
% (E) Don't know \\
% (F) No answer \\
% (G) Missing; Unknown \\
% \hline
% \end{tabular}
% \caption{Example Question and Response Options}
% \end{figure*}

\subsection{Value Alignment of Human Preferences}
Advances in large models have sparked
growing efforts to align these models with human preferences **Zhang et al., "Aligning Models with Human Preferences"**.  **Kumar, "Examination of Value Alignment Across Languages"** examined value alignment across languages. **Patel, "Examination of Value Distributions Based on Countries"** examined value distributions based on countries. **Singh et al., improved the performance on culture-related datasets by finetuning models on a subset of the WVS**. **Rahman et al., propose WorlValueBench
(WVB), a globally diverse, large-scale benchmark dataset for the multicultural value prediction task base on demographic attributes**. Multi-cultural value awareness of large models remains an active area of research as we don't have many large-scale real-world datasets which are about cultural values, and norms and reflect the preferences of the human population.

% World Values Survey (WVS) are referenced to set the framework for measuring cultural differences in LLMs