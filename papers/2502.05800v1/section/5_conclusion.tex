\section{Conclusion}
This paper introduces MicroViT, a novel lightweight Vision Transformer architecture optimized for edge devices, considering computational power and energy efficiency. By employing the Efficient Single Head Attention (ESHA) mechanism, MicroViT achieves a substantial reduction in computational complexity and energy consumption while maintaining competitive accuracy in vision tasks. Extensive experiments on the ImageNet-1K and COCO datasets demonstrate that MicroViT not only improves $3.6 \times$ throughput and inference speed but also surpasses several MobileViT models with 40\% efficiency and performance on edge devices. These results confirm that MicroViT is a promising solution for deploying Vision Transformers in resource-constrained environments. Future work will explore further optimizations and broader applications of this architecture in other edge computing tasks.
