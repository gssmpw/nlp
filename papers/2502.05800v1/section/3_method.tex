\section{Proposed Method}
The main idea of a novel MicroViT architecture for an efficient vision model is reducing the computational complexity and redundancy for processing the image features. The MicroViT model incorporates the Efficient Single Head Attention (ESHA) technique, which could generate low-redundancy feature maps with low complexity SA.

\subsection{Efficient Single Head Attention (ESHA)} 
ESHA combines local and global spatial operations within a single block for efficient token information extraction. Unlike the original SA, which employs linear or PWConv to form queries, keys, and values, ESHA uses kernel-based group convolution for local information acquisition. In SA, tokens undergo scaled dot operations to retrieve the global feature context. Specifically, if $X_i$ is the feature map from the patch embedding block, ESHA is projected into $Q\in \mathbb{R}^{H\times W\times C_{q}}$, $K\in \mathbb{R}^{H\times W\times C_{k}}$, $V\in \mathbb{R}^{H\times W\times C_{v}}$, and $U\in \mathbb{R}^{H\times W\times C_{u}}$ as query, key, value, and unaltered feature. In Equation \ref{eq:in_proj}, $W_{ip}$ represents a $3 \times 3$ convolution kernel with 32 groups to reduce computation.
\begin{align}
    Q, K, V, U &= Split(W_{ip}*X_i), 
    \label{eq:in_proj}
\end{align} 
The projected input will be spliced that corresponds to the channel as described in equation \ref{eq:in_proj}. The query and key dimensions $C_q$ and $C_k$ are set to 16 as the maximum. The channel numbers of value and un-touch $C_v$ and $C_u$ follow the channel ratio $r$ with $rC$ for v and $2(C-C_a)$ for un-touch channel as illustrated in Figure \ref{fig:MicroViT-Arch}. The optimal channel number ratio is set $r=0.215$ that has been discussed in \cite{yun2024shvit} in single head attention.
The global attention score $A\in \mathbb{R}^{H\times W\times rC_{i}}$ will be processed with the scaled dot product operation in the following Equation \ref{eq:att_dw}.
\begin{align}
    A &= V\cdot Softmax(Q^T\cdot K) 
    \label{eq:att_dw}
\end{align} 
For fast computation, the spatial or token length will be reduced in $K\in \mathbb{R}^{\frac{H}{SR}\times \frac{W}{SR}\times C_{k}}$ and $V\in \mathbb{R}^{\frac{H}{SR}\times \frac{W}{SR}\times C_{v}}$ using DWConv with $SR$ ratio. It will reduce the computation of the dot product with $SR^2$ reduction. Next, the convolution projection will ensure efficient propagation of the attention features with un-touch from the previous convolution feature as detailed in equation \ref{eq:esha_mixer}.
\begin{align}
    X_i' &= W_{op}*Cat(A,\sigma{U})
    \label{eq:esha_mixer}
\end{align} 
The $\sigma$ denotes the activation function, such as $GELU(.)$ as the commonly used. The $W_{op}$ is the weight of $1 \time 1$ convolution operation that will connect feature across the channel. 

\begin{table}[ht]
\begin{center}
\caption{All Variant MicroViT Model configurations. \#Blocks denotes number of blocks. ESHA Dim means the number channel of feature map.}
\begin{tabular}{ccccccc}
\hline
\multicolumn{1}{c|}{\multirow{2}{*}{Stage}} & \multicolumn{1}{c|}{\multirow{2}{*}{Size}} & \multicolumn{1}{c|}{\multirow{2}{*}{Layer}} & \multicolumn{3}{c}{MicroViT}  \\ 
\cline{4-6} 
\multicolumn{1}{l|}{}  & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{S1} & \multicolumn{1}{c|}{S2} & \multicolumn{1}{c}{S3}  \\ 
\hline
\multicolumn{1}{c|}{\multirow{3}{*}{1}} & \multicolumn{1}{l|}{\multirow{3}{*}{$\frac{H}{16}\times\frac{W}{16}$}} & \multicolumn{1}{l|}{\multirow{1}{*}{Stem}} & \multicolumn{3}{c}{[3x3 Conv S=2, GeLU]$\times$4} \\
\cline{3-6} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{DWConv ($C$)}  & \multicolumn{1}{c|}{ 128 } & \multicolumn{1}{c|}{ 128 } & \multicolumn{1}{c}{192}    \\
\cline{3-6} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\#Blocks} & \multicolumn{1}{c|}{2}  & \multicolumn{1}{c|}{2}  & \multicolumn{1}{c}{3} \\ 
\hline
\multicolumn{1}{c|}{\multirow{3}{*}{2}} & \multicolumn{1}{l|}{\multirow{3}{*}{$\frac{H}{32}\times\frac{W}{32}$}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Patch Embed\end{tabular}} & \multicolumn{3}{c}{3x3, Stride 2} \\
\cline{3-6} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{DWConv ($C$)} & \multicolumn{1}{c|}{256} & \multicolumn{1}{c|}{320} & \multicolumn{1}{c}{384}  \\ 
\cline{3-6}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\#Blocks} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{7} & \multicolumn{1}{c}{6} \\ 
\hline
\multicolumn{1}{c|}{\multirow{7}{*}{3}} & \multicolumn{1}{l|}{\multirow{7}{*}{$\frac{H}{64}\times\frac{W}{64}$}}  & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Patch Size\end{tabular}} & \multicolumn{3}{c}{3x3, Stride 2} \\ 
\cline{3-6} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{ESHA Dim} & \multicolumn{1}{c|}{320}  & \multicolumn{1}{c|}{448} & \multicolumn{1}{c}{512} \\ 
\multicolumn{1}{l|}{}  & \multicolumn{1}{l|}{}  & \multicolumn{1}{l|}{QK ($C_q, C_k$)} & \multicolumn{1}{c|}{16, 16}  & \multicolumn{1}{c|}{16, 16} &  \multicolumn{1}{c}{16, 16} \\ 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{ratio $r$}  & \multicolumn{1}{c|}{$1/4$} & \multicolumn{1}{c|}{$1/4$}  & \multicolumn{1}{c}{$1/4$}  \\
\multicolumn{1}{l|}{}  & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Group ($g$)} & \multicolumn{1}{c|}{32}  & \multicolumn{1}{c|}{32} &  \multicolumn{1}{c}{32} \\ 
\multicolumn{1}{l|}{}  & \multicolumn{1}{l|}{}  & \multicolumn{1}{l|}{SR} & \multicolumn{1}{c|}{2}  & \multicolumn{1}{c|}{2} &  \multicolumn{1}{c}{1} \\ 
\cline{3-6} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\#Blocks}  & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c}{6} \\ 
\hline
\multicolumn{3}{c|}{Classifier Head} & \multicolumn{3}{c}{Avg Pool, FC }\\ \hline
\end{tabular}
\label{tab:arch_variant}
\end{center}
\end{table}

\subsection{Overall Architechture}
MicroViT employed a three-stage pyramid structure, starting with a $16\times 16$ stem comprising four $3\times3$ convolutions to shrink features by a factor of 16. Adopting the MetaFormer \cite{yu2022metaformer} framework, it utilized two residual blocks for spatial mixing, followed by a residual Feed Forward Network (FFN) for channel mixing, as explained in Equation \ref{eq:encoder}.
\begin{align}
    X'_i &= X_i+\lambda_i \odot SpatialMixer(X_i)\\
    X''_i &= X'_i+\lambda_i \odot FFN(X'_i)
    \label{eq:encoder}
\end{align} 
where $X_i', X_i'' \in \mathbb{R}^{C_i \times H\times W } $. The FFN block contains a sequence of point-wise convolutions as a linear operation. It encompasses a singular activation function, which may be mathematically represented by the subsequent equation.
\begin{equation}
    FFN(X'_i)=(\sigma(Norm(X'_i)*W_{fc1}))*W_{fc2},
\end{equation}
 The $W_{fc1} \in \mathbb{R}^{C_i\times \alpha C_i}$ and $W_{fc2} \in \mathbb{R}^{\alpha C_i\times C_i}$ are learnable weights with $\alpha$ expansion ratio with a default of 2. The $\sigma$ denotes the $GELU(.)$ activation function.

The MicroViT model employs a sequence of separable convolutions and a residual FFN for patch embedding, offering reduction rates of 32 in stage-2 and 64 in stage-3, and uses a $3 \times 3$ patch embedding. In the early stages, DW convolution acts as spatial mixers to fulfill higher memory demands. The final stage utilizes the Efficient Single Head Attention (ESHA) mechanism as outlined in Table \ref{tab:arch_variant}. Batch Normalization (BN) is used to better integrate with adjacent convolutional layers and reduce reshaping, thus enhancing inference speed. The architecture uses global average pooling followed by a fully connected layer for feature extraction and classification.


