\section{Production Impact and Discussion}
\label{sec:discussion}
% \feng{instead of saying NDA thing, say something about the graph?like it shows some report metrics such as duration / type}\peter{@Wei, can mention what we have in the text here} 
\begin{figure*}
	\centering
    \includegraphics[width=0.8\textwidth]{figures/interface.pdf}
	\caption{An illustrative interface of \tool. Due to the NDA, we cannot show the actual interface of \tool. However, to better showcase \tool, we created an illustration of how the result may be presented. \tool's report shows the detected GUI lags, their corresponding types, start and end times (and the frames), duration, and severity.}
	\label{fig_interface}
\end{figure*}
Figure~\ref{fig_interface} provides an illustration of \tool's result presentation. Due to the NDA, we cannot show the actual user interface of \tool, but we hope to provide an illustrative example. \tool's report shows the detected GUI lags, their corresponding types, start and end times (and the frames), duration, and severity. The detection report is linked to the screencast and also shows the user interaction of the tests when recording the screencast. Once a user wants to investigate one specific GUI lag, \tool shows the recorded screencast and the corresponding frames that experience a lag. This process significantly facilitates the analysis. We received much positive feedback from practitioners after deploying \tool in production. Below, we discuss the feedback we received that we hope can inspire other practitioners and future research. 

\subsection{Effectiveness of \tool in Detecting User-Centric Issues}
\tool has been consistently operating online for a while. With each code update, we execute automated GUI tests on the mobile device and record the resulting screencasts, which are then analyzed by \tool. In our evaluation, \tool successfully identified critical instances of GUI lag, most of which have been validated by developers in follow-up assessments. This capability is invaluable in identifying user-experienced performance issues that conventional metrics, such as CPU or memory usage, often fail to capture. 
Unlike traditional metrics-based tools, \tool's focus on perceptible lag types (i.e., janky, long loading, and frozen frames) ensures that it captures issues aligned with what users actually notice during interactions. Developers have noted that this capability helps them address performance issues that conventional tools might overlook, particularly those that influence user perception and satisfaction. For instance, \tool has proven effective in highlighting minor yet impactful lags that occur during high-interaction events, such as tapping or scrolling, which can lead to noticeable disruptions if left unaddressed. This user-centric approach to performance monitoring has proven instrumental in helping teams prioritize fixes based on real-world impact, making \tool an essential tool for enhancing the responsiveness and fluidity of mobile applications.


\subsection{Usefulness of \tool}
\phead{\tool Enhances Debugging Efficiency.} 
\tool significantly enhances debugging efficiency by providing comprehensive information about detected lags, helping developers identify potential performance issues. \tool accurately indicates the locations and types of GUI lags within screencasts, user operations (e.g., tapping, swiping, scrolling), and specific test scenarios, offering insights into how these lags occur. By focusing on user-perceived lags, developers can better understand how these lags directly impact users. Additionally, prioritizing these lags allows developers to concentrate on the most critical user experience issues. 
As one practitioner stated, ``\textit{The comprehensive reports have drastically reduced our debugging time and helped us focus on the critical performance issues that matter most to our users.}''


\phead{\tool Enhances Continuous Performance Monitoring.}
\tool is vital in monitoring mobile app performance from the GUI perspective. By testing different versions of an application and examining the distribution of detected GUI lags, developers can identify performance degradation and evaluate whether user-centric performance has declined over time. Additionally, \toolâ€™s integration with Continuous Integration (CI) pipelines enables automated GUI performance monitoring with every build, helping teams catch regressions early in the development cycle. As one practitioner noted, ``\textit{\tool has become an integral part of our CI pipeline. Its reports allow us to quickly identify and address new performance lags introduced by recent changes, enabling us to deliver smoother experiences with each release.}''
\tool's regular reporting helps practitioners track performance trends, identify recurring issues, and proactively address potential bottlenecks before they affect users. 


\subsection{Flexibility of \tool}
\tool demonstrates strong adaptability in both \textit{GUI Testing} and \textit{Lag Detection}. It supports mobile screencasts recorded from various testing methods, whether through manual testing or automated GUI testing tools, ensuring compatibility with diverse testing practices.
Furthermore, \tool is highly adaptable across multiple platforms and GUI applications, including Android, iOS, and TV. Minimal adjustments, such as fine-tuning detection thresholds, are required for it to work effectively across platforms. Currently, we are working closely with practitioners to adapt \tool to other UI-centric testing on various platforms.  %As one practitioner mentioned, ``\textit{\tool has simplified our workflow by offering a unified solution for GUI lag detection on both Android and iOS.}'' 
%This versatility has encouraged practitioners in working on multi-platform applications to adopt the tool as a unified solution for monitoring GUI performance across different environments. 


%\subsection{Future Research and Improvements} The deployment of \tool has inspired practitioners to suggest further enhancements. Some have proposed integrating \tool with user feedback mechanisms to better align performance data with real-world user expectations.

