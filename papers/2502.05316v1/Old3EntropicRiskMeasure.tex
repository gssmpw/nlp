%\thejaswini{I am more-or-less done writing this now. Need to edit maybe}
The entropic risk measure is a measure of the perceived risk which depends on the risk aversion/inclination of the user through the exponential utility function. 

A \emph{risk parameter} of a player is expressed as a real value $\rho\in\Rb$, where a positive value of $\rho$ indicates a risk-averseness of a player and a negative value indicates risk-inclination of a player.

\begin{definition}[Entropic risk measure]
Given a random variable $X$, the entropic risk measure of the variable $X$, is defined as 
$$\re_{\beta,\rho}[X] = -\frac{1}{\rho} \log_\beta \left( \Eb \left[ \beta^{-\rho X}\right] \right).$$
When $X$ is clear from context, we write $\re_\rho$, or even $\re$, for $\re_{\beta,\rho}$.
\end{definition}

% We show that 
\begin{restatable}{theorem}{REisPEOE}\label{thm:RE=PEorOE}
    Let $X$ be any random variable ranging over $\Rb$, and let $\beta > 1$.
    Then:
    \begin{itemize}
        \item The limit risk entropy of $X$ when $\rho$ tends to $0$ exists, and equals the expectation:
        $$\lim_{\rho \to 0} \re_{\beta,\rho} [X] = \Eb[X].$$
        
        \item The limit risk entropy of $X$ when $\rho$ tends to $+\infty$ exists, and equals the pessimistic expectation:
        $$\lim_{\rho \to +\infty} \re_{\beta,\rho} [X] = \pexp[X].$$
        
        \item The limit risk entropy of player $i$ when $\rho$ tends to $-\infty$ exists, and equals the optimistic expectation:
        $$\lim_{\rho \to -\infty} \re_{\beta,\rho} [X] = \oexp[X].$$
    \end{itemize}
\end{restatable}
% \begin{theorem}
    
% \end{theorem}


\begin{definition}[$\beta\brho$-risk-sensitive equilibrium]
    Let $\Game_{\|v_0}$ be a game, and let $\brho \in (\Rb \setminus \{0\})^\Pi$ be a \emph{risk-sensitivity profile}.
    Then, the strategy profile $\bsigma$ is a \emph{$\beta\brho$-risk-sensitive equilibrium}, or \emph{$\beta\brho$-RSE} for short, if and only if for each player $i$, the strategy $\sigma_i$ is $\beta,\rho$-risk-optimal in the MDP $\MDProc(\bsigma_{-i})$.
\end{definition}


Note that for every $\beta, \beta'$ and every $\gamma$, we have $\re_{\beta\gamma} = \re_{\beta'\gamma'}$ where $\gamma' = \gamma \frac{\ln(\beta)}{\ln(\beta')}$.
Therefore, one could fix $\beta$ (for example, to $\beta = e$) and use only $\gamma$ as a parameter without loss of generality, from a semantic perspective; but the choice of $\beta$ can still have an influence on the computabilities and complexities of the problems we will be interested in.



For a given class $\Cc$ of games, we define the following problems:

\begin{definition}[Constrained existence problem for $(P, O)$-equilibria in the class $\Cc$]
    Given a game $\Game_{\|v_0} \in \Cc$, a partition $P, O$ of $\Pi$, and two payoff vectors $\bx, \by \in \Qb^\Pi$, does there exists a $(P, O)$-equilibrium $\bsigma$ in $\Game_{\|v_0}$ such that $x_i \leq \pexp_{\bsigma}[\mu_i] \leq y_i$ for every $i \in P$, and $x_i \leq \oexp_{\bsigma}[\mu_i] \leq y_i$ for every $i \in O$?
\end{definition}

\begin{definition}[Constrained existence problem for risk-sensitive-equilibria in the class $\Cc$]
    Given a game $\Game_{\|v_0} \in \Cc$, a basis $\beta > 1$, a risk-sensitivity vector $\bgamma \in \Qb^\Pi$, and two payoff vectors $\bx, \by \in \Qb^\Pi$, does there exists an RSE $\bsigma$ in $\Game_{\|v_0}$ such that $x_i \leq \re_{\beta\gamma\bsigma}[\mu_i] \leq y_i$ for every $i \in \Pi$?
\end{definition}

\begin{lemma}\label{lemma:RSEtoQSSG}
Given a quantitative simple stochastic game $\Game|_{v_0}$, 
where the risk-parameter $\rho = (\rho_1,\rho_2,\dots,\rho_{|\Pi|})$ is such that $\rho_i\in \Rb$, 
it can be converted into quantitative simple stochastic game $\Game'|_{v_0}$ on the same underlying graph, with set of players, probability function, such that every player has risk parameter $0$, and the terminal rewards for each player is modified  such that any $(\beta,\rho)$-RSE is a Nash equilibria in $\Game'|_{v_0}$
\end{lemma}
\begin{proof}
    Consider the simple stochastic game $\Game|_{v_0} = \tpl{V,E,\Pi,(V_i)_{i\in \Pi},\p ,\mu}$. We will define $\mu'$ such that $\Game'|_{v_0} = \tpl{V,E,\Pi,(V_i)_{i\in \Pi},\p ,\mu'}$ has a Nash equilibrium if and only if $\Game$ has a $(\beta,\gamma)$-RSE.

    For a terminal vertex, we simply define $\mu_i'(v) = -(\beta^{-\rho\mu_i(v)})$. Consider this function $\modifiedreward{\beta}{\rho}\colon x\mapsto -(\beta^{-\rho x})$ as the modified reward function.  This function is similar to the negative utility function defined in the work of Baier et al.,~\cite{BCMP24}, where they replace terminal rewards with the negative value of the above function in order to compute the winner in a two-player zero-sum game with risk-averse players. 
    
    Observe that for any random variable $X$, we have that 
    \begin{equation}\label{inequality:REvsExp}    
    \re_{\beta,\rho}\left[X\right] \geq r\text{ if and only if }\Eb\left[\modifiedreward{\beta}{\rho}(X)\right] \geq -\beta^{-\rho r}\end{equation}
    since $\re_{\beta,\rho}\left[X\right] = \frac{-1}{\rho}\log_\beta\tpl{\Eb[\beta^{-\rho X}]}$.
    
    Therefore, any Nash equilibria in  $\Game'|_{v_0}$ would imply that there is a strategy $\bsigma$ such that, for all players $i\in\Pi$, in the MDP induced by $\sigma_{-i}$,  the strategy  $\sigma_i$ of player $i$ is an optimal strategy. If for some strategy $\tau_i$ of player $i$, if the value in the Markov chain induced by any $\bsigma' = (\sigma_{-i}, \tau_i)$ then consider the probability distribution $\prob_{\bsigma'}$ over plays. Define a random variable $X'$ where the value of the play in $\Game'$ sampled according to the probability distribution $\prob_{\bsigma'}$. 
    Similarly, let the random variable $Y'$ be the value of a play in game $\Game'$ where the play is sampled according to the probability distribution $\prob_{\bsigma}$. Since $\bsigma$ is a Nash equilibrium, we have that  
     $\Eb\left[Y'\right]\geq \Eb\left[X'\right]$.
     Since the payoffs in $\Game'$ is just $\modifiedreward{\beta}{\rho}(\mu_i(v))$, this implies that $\Eb\left[\modifiedreward{\beta}{\rho}(Y)\right]\geq \Eb\left[\modifiedreward{\beta}{\rho}(X)\right]$, where 
     $X$ and $Y$ are random variables where $X$ and $Y$ are both the value of the play in the original game $\Game$, however the plays of $X$ are sampled where the probability distribution is $\prob_{\bsigma}$ and $\prob_{\bsigma'}$, respectively. 
     From the statement (\ref{inequality:REvsExp}), we have     
     \begin{align*}
         \Eb\left[\modifiedreward{\beta}{\rho}(Y)\right]\geq \Eb\left[\modifiedreward{\beta}{\rho}(X)\right]\text{ if and only if }\\\re_{\beta,\rho}[Y'] \geq -\frac{1}{\rho}\log_\beta\tpl{-\Eb\left[\modifiedreward{\beta}{\rho}(X)\right] } = \re_{\beta,\rho}[X']\\
         \text{ if and only if }\re_{\beta,\rho}[Y']\geq \re_{\beta,\rho}[X']
     \end{align*}
      Therefore the strategy  $\bsigma$ is at least as good as (any strategy where one player deviates) $\bsigma'$ for the player $i$ that deviates, when their rewards are the risk-entropy measure. Thus, this makes $\sigma$ an risk-sensitive equilibrium. %\theju{badly written, need to revise. Will do it tomorrow.}
\end{proof}
\begin{theorem}[Existence of RSE]\label{thm:existanceRSE}
    There is always a (pure) $(\beta,\rho)$-RSE over a simple stochastic game. 
\end{theorem}
\begin{proof}
We know from \cref{lemma:RSEtoQSSG} that there is a Nash equilibrium in a modified game if and only if there is an RSE in a given $(\beta,\rho)$-RSE game. Since a pure Nash equilibrium always exists in a stochastic multi-player games~\cite[Theorem 3.10]{Umm10} (A correction of an existing proof~\cite{CMJ04}), our desired result follows.  
\end{proof}
\begin{proposition}\label{proposition:Undecidable}
    The constrained existence problem for RSE where $\brho \in \Qb^{\Pi}$ is undecidable. Further, even when players are restricted to pure strategies, the problem remains undecidable
\end{proposition}
\begin{proof}
         The undecidability of the constrained existence problem follows from the work of Ummels and Wojtczak~\cite[Theorem 4.9]{UW11} where they show the undecidability of the constrained existence problem for Nash equilibria in the setting with 10 or more players. Since Nash equilibria is a specific instance of the setting of RSE iwhere the risk parameters $\brho$ is $0$ for each player, the undecidability of our setting follows. 
\end{proof}

The Square-root sum problem is a decision problem in numerical analysis that asks given a list of $n$ numbers and a value $t$, if the sum of the square root of these numbers is at most $t$.
It is an open problem to determine if $\SQRTSUM$ lies in the polynomial hierarchy.  

% \begin{lemma}\label{lemma:memorylessRSE}
%         The constrained existence problem for RSE when players are restricted to pure strategies for quantitative simple stochastic games is undecidable.
% \end{lemma}
% \begin{proof}
%\end{proof}
\begin{lemma}\label{lemma:memorylessRSE}
        The constrained existence problem for RSE when players are restricted to memoryless (but stochastic) strategies for quantitative simple stochastic games is \begin{itemize}
            \item in $\PSPACE$ if the risk-parameters for each player $\brho$ as well as the base $\beta$ is algebraic; 
            \item decidable---subject to Shanuel's conjecture---if the risk-parameters for each player $\brho$  is algebraic and the base of the exponent is the Euler's constant $\beta=e$.
            \end{itemize}
        The problem is at least $\NP$-hard as well as $\SQRTSUM$-hard.
\end{lemma}
\begin{proof}
     We remark that a lower bound of $\NP$-hardness and $\SQRTSUM$-hardness  follows from the work of Ummels and Wojtczak~\cite[Theorem 4.4,Theorem 4.6]{UW11}. % where they show $\NP$-hardness for the constrained existence problem for Nash equilibria in the setting with only two players. Since Nash equilibria is a specific instance of the setting of RSE, where the risk parameters of each player is $0$, the $\NP$-hardness follows. 
         For the upper bounds, we appeal to results for the existential theory of the reals, the set of all existential first-order sentences that hold in the ordered field of reals $(\Rb,+,\times,0,1,\leq)$. Our results also closely resemble the proof given by Ummels and Wojtczak~\cite[Theorem 4.5]{UW11}, however, we need to do slightly more work to encode the payoff expressed by the entropic risk measure.
         Therefore, if we allow for the base $\beta$ to be equal to the Eular's constant, then we can express the formula using the existential theory of reals with exponents is decidable, subject to Shanuel's conjecture~\cite{MW95}. We don't describe the details, but only remark that Shanuel's conjecture is a well-known conjecture in the field of transcendental number theory~\cite{Lan66}. 
         
         %Further, we need the results in Baier et al.,~\cite{BCMP24} to reason about computational related to checking if a strategy 

    First observe that the it is enough to verify if there is a memoryless Nash equilibrium in the modified game obtained where all the terminal rewards $\mu_i(v)$ are replaced instead with $-\tpl{\beta^{\rho\mu_i(v)}}$. This follows from \cref{lemma:RSEtoQSSG}. 

    Since the players are restricted to strategies that are memoryless, we give a non-deterministic algorithm that uses the solution to sentences in $\exists\Rb$ if the values of $\beta$ and $\rho$s can be expressed in $\Qb$. If $\beta = e$, then we write such existential first order formulas in $\exp\text{-}\exists\Rb$ (The existential theory of reals with an exponentiation). We use solutions to such solutions as a black-box,. For the rational case, since $\exists\Rb$ is contained in $\PSPACE$ and further $\NPSPACE = \PSPACE$, this gives us a $\PSPACE$ algorithm for the case where $\beta$ and $\rho$ are rationals. 
     
     For a game $\Game|_{v_0} = \tpl{V,E,\Pi,(v_i)_{i\in \Pi}, \p,\mu}$, where $\mu$ is a function from a terminal set of nodes $T$ to values in $\Qb$,\theju{terminal nodes def?} and constraints $\Bar{x}$ and $\Bar{y}$ for each of the $n$ players in $\Pi$, let $S$ be the support of the strategy guessed. 

         \subparagraph*{Writing values of terminals efficiently.}
        For each value $t = \mu_i(v)$, which requires $\ell$ bits to encode, we ensure that there is a formula that uses only polynomially many variables in $\ell$ to encode $\modifiedreward{\beta}{\rho}(t) = -\tpl{\beta}^{-\rho t}$. 

        We assume without loss of generality that $\beta$ is a natural number. If $\beta$ is rational instead, and is represented by a value $a/b$, then individually find $a_1  = a^{\rho t}$ and $b_1 = b^{\rho t}$, and just find $b_1/a_1$, which is just written in $\exists\Rb$ by stating that $\exists  t_r \;\exists a_1'\colon a_1'\times a_1  = 1\land t_r = a_1'\times b_1$.
        Now that we assume that $\beta$ is a rational number, we now deal with fixed finite exponentiation with rational values. Similarly, we can assume without loss of generality that $\rho t$ is a natural number. Indeed, any value $r^{a/b} = r^a\times t^{1/b}$ and $t^{1/b}$ can be written as $\exists y \colon y^b = t$.

        It suffices to show therefore that for two values $b,a$, both natural numbers, $b^a$ can be expressed in $\exists\Rb$ succinctly, using only a formula that has length that is not more a poly-log of $b$ or $a$. 
        Let $a = \sum_{i=0}^{\log_2{a}}a_i 2^i$, where $a_i\in\{0,1\}$ 
        The reasoning follows from the observations below. 
        \begin{itemize}
            \item $b^a = \prod_{i=1}^{\log_2{a}}\tpl{b^{a_i}b^{2^i}}$
            \item  $2^i$ can be expressed in a formula with at most $i+1$ many variables
            \item $b^{2^i}$ further requires at most $i$ many variables to express, because let  $b_i$ represent $b^{2^{i}}$, then $b^{2^{i+1}} = b^{2^i}\times b^{2^i}$.
            \item Finally, using a similar trick, $b$ itself can be represented using at most $\log_2{b}$-many variables. 
        \end{itemize}


    Since we can efficiently represent the variables used for the payoffs of the modified game, we now can write an equation assuming that all terminal rewards are available to us constants. We now specify the variables to be used in the first order formula that we will construct to indicate if the constrained existence problem is satisfied. This is done in three parts. Since we have guessed the support, we first ensure that in fact there are variables corresponding to the probability that only take positive values on the edges corresponding to the support set that we guessed.  
    Then, we write equations using variables that compute the values of the induced Markov chain from this strategies. Finally, we also find a the values corresponding to the MDP obtained for each player when playing against the strategies of all other players. Then we compare if the value of the MDP is at least as large as the underlying Markov chain, for each player to ensure that it is indeed an equilibrium. To write all of this in $\exists\Rb$, we introduce the following variables. 
     \begin{itemize}
         \item one variable  $p_{vw}$ for each pair of vertices $vw$, which corresponds to the probabilities corresponding to the strategy;
         \item a variable $r^i_v$ which corresponds to the risk-entropy of player $i$ from vertex $v$ if they followed the strategy defined by the probabilities above; 
         \item a variable $m^i_v$ which corresponds to the value of the value obtained by player $i$ if the game is treated as an MDP against other players.
     \end{itemize}
 
        
     \subparagraph*{Writing FO formula assuming we have access to values for terminals.}
    The following part of the proof is similar to the one found in Ummels and Wojtczak~\cite[Theorem 4.5]{UW11}, but we provide it to suit our setting, for the sake of completeness. 
    First, we have a formula that  $p_{vw}$ indeed describe a strategy. We further ensure that for stochastic vertices, the value $p_vw$ encodes exactly the value dictated by the probability function $\p$ by the stochastic node
    \begin{align*}
    \Phi_S(\Bar{p})\:= \bigwedge_{v,w\in V}p_{vw}\geq 0\land \bigwedge_{v,w\in V}1\leq p_{vw}
    \land \bigwedge_{i\in \Pi}\bigwedge_{v\in V_i} \tpl{\sum_{w\in E(v)}\p_{vw}=1}\land \\
    \bigwedge_{v\in V_?}p_{vw} =  \p(vw)\land \bigwedge_{vw\in S}p_{vw}> 0 
    \end{align*}
    For a fixed support $S$ of a strategy $\alpha$, it is possible to compute the terminals $T_S$ that have non-zero probability of being reached in the underlying Markov chain that is formed, and the vertices $V_S$ from which such terminals can be reached with non-zero probability. We assign value $\mu_i'(v)$ as the reward for the terminal vertices for player $i$, and the reward $1$ for all vertices that cannot reach any terminal with positive probability ($\modifiedreward{\beta}{\rho}(0) = 1$).
    \[\Omega_S^i(\Bar{p},\Bar{r^i})\:= \bigwedge_{v\in T_S} r^i =\mu_i'(v) \land
                 \bigwedge_{v\notin V_S} r^i_v = 1 \land
                 \bigwedge_{v\in V_S\setminus T_S} \tpl{z^i_w = \sum_{w\in E(v)}\tpl{ p_{vw} r^i_v}}
                 \]     
    Finally, for computing the values of the MDP, we construct a similar FO statement
    \[\Gamma_S^i(\Bar{p},\Bar{m^i}) \:= \bigwedge_{v\in T} m^i =\mu_i'(v) \land
                 \bigwedge_{v\in V_i\\w\in E(v)} m_v^i\geq m_w^i \land
                 \bigwedge_{v\notin V\setminus V_i} \tpl{m^i_w = \sum_{w\in E(v)}\tpl{ p_{vw} m^i_v}}\]
Finally our statement would be $$\exists \Bar{p}\:\exists\Bar{r}\:\exists\Bar{m}\colon \Phi(\Bar{p})\land \bigwedge_{i\in\Pi}\left(\tpl{x^i_{v_0}\leq r^i_{v_0}}\land \tpl{r^i_{v_0}\leq y^i_{v_0}}\land\Omega_S^i(\Bar{p},\Bar{r^i})\land \Gamma_S^i(\Bar{p},\Bar{m^i})\land m_{v_0}^i\leq r_{v_0}^i \right)$$
For rewards that are represented by algebraic numbers that also can be expressed succinctly via $\exists\Rb$, we observe that our above reduction extends naturally. 

\end{proof}\theju{to check if this doesn't hit really low values. Need to bound it}


\begin{lemma}\label{lemma:positionalRSE}
        The constrained existence problem for RSE when players are restricted to pure and positional strategies for quantitative simple stochastic games is  in $\PSPACE$ if the risk-parameters for each player $\brho$ as well as the base $\beta$ is algebraic. Further, the problem is $\NP$-hard.% as well as $\SQRTSUM$-hard.
\end{lemma}
\begin{proof}
    For the lower bounds, we just remark that the corresponding problem of constrained existence of Nash equilibria, when players are restricted to positional strategies is both $\NP$-hard~\cite[Theorem 4.4]{UW11}
    from the work of Ummels and Wojtczak. Since Nash equilibria is a specific instance of the setting of RSE, where the risk parameters of each player is $0$, the $\NP$-hardness for the more general case of RSE follows.
    For the upper bound, we simply observe that the same proof as the one for the upper bound of~\cref{lemma:memorylessRSE} can be adapted to this situation. 
\end{proof}
\section{Computing equilibria for values of risk}

From this point, we will therefore extend, by continuity the definition of $\RE_{\beta,\rho}$ for $\rho = 0$.


\begin{lemma}
    If $\rho \leq \rho'$, then $\re_{\beta,\rho} \geq \re_{\beta \rho'}$.
\end{lemma}

\begin{proof}
    This result was proved in a text book on risk theory~\cite{KGD08} in a slightly different context.

    Let $\rho, \rho' \in \Rb \setminus \{0\}$.
    Let us assume $0 < \rho < \rho'$.
    Then, the mapping $x \mapsto x^{\frac{\rho}{\rho'}}$ is concave, hence by Jensen's inequality we can write:
    $$\Eb\left[ \left(\beta^{-\rho'X}\right)^{\frac{\rho}{\rho'}} \right] \leq \left( \Eb\left[ \beta^{-\rho X} \right] \right)^{\frac{\rho}{\rho'}}.$$
    Then, by applying the mapping $-\frac{1}{\rho} \log_\beta$, we obtain:
    $$-\frac{1}{\rho} \log_\beta \Eb\left[ \left(\beta^{-\rho X}\right) \right] \geq -\frac{1}{\rho} \frac{\rho}{\rho'} \log_\beta \Eb\left[ \beta^{-\rho X} \right],$$
    i.e. $\re_\rho[X] \geq \re_{\rho'}[X]$.

    The case where $\rho$ and $\rho$ are negative is analogous, and the result can be generalized to $\Rb$ using the continuity in $0$.
\end{proof}

In an MDP $\MDProc$, a strategy $\sigma$ is \emph{$\beta,\rho$-risk-optimal} if and only if for every strategy $\sigma'$, we have $\Eb_{\sigma'}[\mu] \leq \Eb_\sigma[\mu]$.


\begin{definition}[Risk-sensitive Equilibria]
    Let $\Game_{\|v_0}$ be a game, and let $\brho \in (\Rb \setminus \{0\})^\Pi$ be a \emph{risk-sensitivity profile}.
    Then, the strategy profile $\bsigma$ is a \emph{$\beta\brho$-risk-sensitive equilibrium}, or \emph{$\beta\brho$-RSE} for short, if and only if for each player $i$, the strategy $\sigma_i$ is $\beta,\rho$-risk-optimal in the MDP $\MDProc(\bsigma_{-i})$.
\end{definition}