\section{Related Work}
\label{sec:relatedwork}

\subsection{Traditional rPPG measurement}
% \noindent\textbf{Traditional rPPG measurement.}\quad 
As the rPPG signal change is very subtle, it is difficult to directly achieve from videos. Some traditional methods such as CHROM \cite{de2013robust} and POS~\cite{wang2016algorithmic} adopted mathematical models to decompose the videos into rPPG-relevant parts and non-relevant parts. However, the environment of illumination conditions and motions and the individual skin conditions are complicated to be incorporated into mathematical models. Besides, the input video is 3-dimensional (3D) signals involving spatial and temporal information which adds difficulty in developing the mathematical models. The deep-learning methods, however, are capable of extracting the rPPG signal from complex environments and individual conditions. 

\subsection{rPPG deep learning methods}
% \noindent\textbf{rPPG deep learning methods.}\quad 
The primary deep learning methods for rPPG are focused on supervised methods \cite{dong2024realistic,du2023dual,yu2019remote1,yu2023physformer++} and self-supervised methods \cite{wang2022self,sun2022contrast,gideon2021way,speth2023non,liu2024rppg,park2022self}. Previous supervised methods \cite{niu2019rhythmnet} used neural networks to regress heart rate as a single value. However, the characteristics of rPPG signals as quasi-periodic waveforms were neglected and much useful information was not leveraged in training models. The recent supervised methods predict the rPPG signal to leverage characteristics of signals by adding constraints of time and frequency domains in terms of signal similarity \cite{niu2020video}, signal distribution \cite{yu2022physformer}, and power spectral density (PSD) distance~\cite{gideon2021way}.

For self-supervised studies, some research utilizes the temporal and spatial characteristics of facial videos to construct self-supervised loss.  A contrastive framework was proposed by Su and Li \cite{sun2022contrast}. The positive samples were obtained from the anchor sample's different facial areas and near temporal windows. The negative samples were selected from different individuals' face videos. However, there are possibilities that different individuals have similar PSD which will confuse the model to push the negative samples. Since the rPPG signal is quasi-periodic, many self-supervised methods are developed taking advantage of its frequency characteristics. Jeremy Speth et al.~\cite{speth2023non} proposed a non-contrastive unsupervised learning framework. The model was constrained by the bandlimits, variance, and sparsity of the power spectral of the rPPG signal. The proposed framework was valid under a stable and simple environment. The authors tested that the model was not converged with a noisy CelebV-HQ dataset \cite{zhu2022celebv}.

As the input of the rPPG learning is 3D video clips,  some research \cite{niu2019rhythmnet,niu2020video,das2021bvpnet} pre-process the input into 2D spatial-temporal maps to adopt the off-the-shelf 2D models by averaging the pixel values of several region of interest (ROI) areas to increase the robustness of the model.  While the other research uses end-to-end 3D neural networks~\cite{yu2019remote,yu2022physformer} without pre-processing the input facial clips. 

% 3D-CNN-based PhysNet~\cite{yu2019remote,yu2019STVEN} and transformer-based~\cite{yu2022physformer,shao2023tranphys} PhysFormer deep learning architectures have been developed to deal with the 3D input with satisfactory results on several public datasets. 
% \subsection{Semi-supervised rPPG learning}

\subsection{Semi-supervised rPPG learning for vision tasks}
% \noindent\textbf{Semi-supervised rPPG learning for vision tasks.}\quad 
Semi-supervised learning methods have been widely studied in image classification \cite{tarvainen2017mean}, object detection \cite{li2022rethinking}, semantic segmentation \cite{alonso2021semi}, and action recognition tasks \cite{jing2021videossl}. The major semi-supervised methods can be roughly divided into consistency regularization and pseudo-labeling \cite{he2023pseudo}. The consistency regularization assumes the model will have the same output under spatiotemporal similarity or data augmentation. While pseudo-labeling annotates pseudo-labels for the unlabeled data. However, the pseudo-labels may also underperform due to noises. FixMatch \cite{sohn2020fixmatch} is a traditional SSL method assuming the consistency between weekly augmented images and strongly augmented images. A fixed threshold is adopted on the predicted class probability to filter out high-quality unlabeled data for training. The drawback of FixMatch is that it assumes an equal threshold for all classes without considering the learning difficulties between different classes. To improve FixMatch, FlexMatch \cite{zhang2021flexmatch} was proposed by replacing the fixed threshold with a flexible threshold. This method will calculate a dynamic threshold for each class at each time step. Hasan et al.~\cite{hasan2023srppg} proposed a semi-supervised adversarial learning framework that utilized two temporal consistency properties. It assumes two partially overlapped video frame sequences shall contain the same PPG signals for the overlapped period. Besides, the downsampled video frames will correspond to the downsampled PPG signal. According to the authors' statistics, research on semi-supervised rPPG learning is not sufficient. This study aims to address that gap by exploring rPPG learning using semi-supervised methods.

% Although consistency strategy is helpful for the model training in terms of regularization. However, the supervision is weaker than pseudo labels.


\begin{figure*}[t]
\centering
\includegraphics[scale=0.6]{Figures/HR.png}
  \caption{\small{
  %\textcolor{red}
  An illustration of calculating heart rate from blood volume pulse signal (BVP): First, the BVP signal is converted into power spectral density (PSD) through Fast Fourier Transform; Next, the PSD is categorized into classes ranging from 0 to 140, which correspond to heart rates of 40 to 180  beat per minute (BPM); Finally, the heart rate is determined by reverse mapping the class.
  }
  }
\label{fig:bvp_to_classes}
\end{figure*}