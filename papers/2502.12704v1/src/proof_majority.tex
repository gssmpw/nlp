\section{Proof of \np-hardness for Majority Dynamics}
\label{sec:maj}


In this section, we adapt the statement of \Cref{thm:nphardness_bayes} to the Majority dynamics setting.

\begin{theorem}[ ]\label{thm:nphardness_maj}
	\netlearn{} with the majority vote rule $\mu = \mu^M$ is \np-hard.
\end{theorem}

The proof is again a reduction from \sat.
The main idea is identical to that of \Cref{thm:nphardness_bayes}, so we offer here only the main points and construction, with emphasis on differences from the proof of \Cref{thm:nphardness_bayes}.
We offer the full proof in \appmaj.

\subsection{Adapted Graph Construction}
\label{ssec:maj_graph}

Unfortunately, if we wanted to directly apply the previous construction, we would find that the worst-case satisfied ordering reaches a \emph{lower} learning rate than the best-case unsatisfied ordering (as discussed in \Cref{ssec:assignment_bayes}).
Then there is no $ \varepsilon $ which separates the learning rates corresponding to satisfied and unsatisfied assignments.
We thus adapt the construction from \Cref{ssec:graph}, modifying the clause gadget.
We keep the variable cell unchanged.

\variableCell*

Intuitively, we need to give the nodes in the clause gadgets more input, so they are better equipped to use the input from the ``on'' cells.
To achieve this, we add two dummy nodes to the clause gadget.

\begin{definition}[Clause gadget]
    Let $ C = j \lor k \lor \ell $ be a clause of a 3-CNF formula $ \varphi $, where $ j \neq k \neq \ell $ are some literals.
    Then the \emph{clause gadget} is $ \gadget C = \left( V_C, E_C \right) $, where \begin{enumerate}[ ]
    	\item $ V_C = \left\{ j,k,\ell, d^1, d^2 \right\} $,
    	\item $ E_C = \{ ( x,y ) \mid x,y \in \{ j,k,\ell \}, x \neq y \} \cup \{ ( d^i, x ) \mid i \in \{ 1,2 \} , x \in \{ j,k,\ell \} \} $.
    \end{enumerate}
\end{definition}

We now define the formula graph using the same definition, only with the new clause gadget.

\bayesianGraph*

See \Cref{fig:gphi} for an illustration of this construction for the simple formula $ \varphi = x \lor y \lor z $.
Note that we also use the ``on''/``off'' states of a variable/literal, as defined for the Bayesian proof (see \Cref{par:ordering_literals}).

\input{src/figures/maj_gadget}

Next, we compute the learning rates of the variable cell, and of the clause gadgets, depending on whether its literals are on or off.

\begin{lemma}[Majority Dynamics Cell LR] \label{lemma:maj_MD_cellLearningRate}
    Let $x \in \vars$.
    Let $ q = \frac 12 $, and $ p $ be given.
    Then \[
	\oclr (\cell x) = 2p + 3p^2 -2p^3.
    \]
\end{lemma}

\begin{lemma}[Majority Dynamics Gadget Learning Rate]\label{lemma:maj_100CLR} 
    Let $C$ be a clause.
    Suppose that $\sigma^*$ is an optimal learning rate.
    Then, in the gadget for $C$, $\sigma^*$ places the cells first, then the dummy nodes, and finally the three literal nodes.
    Further, \begin{enumerate}
        \item if one literal is on, then $\clr(\gadget C, \sigma^*) $ is
        \begin{align*}
                \pone \deq p &\left(2 + 2 p + 6 p^2 + 11 p^3 + 4 p^4 - 51 p^5 - 6 p^6  + 21 p^7 \right. \\
                               & \left. + 115 p^8 - 136 p^9 + 13 p^{10} + 36 p^{11} - 12 p^{12} \right).
            \end{align*}
        \item if one literal is on, then $\clr(\gadget C, \sigma^*)$ is \begin{align*}
                \ptwo \deq p & \left(12 p^8-54 p^7+76 p^6-14 p^5 \right. \\
                               & \left. -40 p^4+9 p^3+12 p^2+2 p+2\right).
            \end{align*}
        \item if one literal is on, then $\clr(\gadget C, \sigma^*) $ is \begin{align*}
                \pthree \deq p & \left(2 + 2 p + 3 p^2 + 14 p^3 + 22 p^4 - 66 p^5 - 69 p^6 + 310 p^7 \right.\\
                            & \left.- 688 p^8 + 710 p^9 + 756 p^{10} - 2581 p^{11} + 2304 p^{12} - 558 p^{13}\right.\\ 
                            & \left.- 372 p^{14} + 264 p^{15} - 48 p^{16} \right).
            \end{align*}
    \end{enumerate}
    Furthermore, for a clause $ D $ satisfied under $ \sigma^* $, it holds \[
	    \pthree \geq \clr(\gadget D, \sigma^*) \geq \pone \geq \pzero.
	\]
\end{lemma}

Finally, we can now determine the optimal ordering, compute its learning rate, and show that there is an $ \varepsilon $ such that the learning rate is above $ \varepsilon $ if and only if the induced ordering is satisfied.

\begin{lemma}[Optimal Ordering] \label{lemma:maj_bestOrder}
    Let $\mathcal{A}^*$ be a maximal assignment.  Let $p(M) < 1$ be a threshold probability determined by $M$, the number of clauses. Then for all $p \geq p(M)$, the decision ordering $\sigma^*$ which places all dummy nodes first, then all variable nodes respecting the partial ordering induced by $\mathcal{A}^*$, and finally all literal nodes in the clause gadgets, maximizes the network learning rate.
\end{lemma}

The proof of this Lemma is very similar that of \Cref{lemma:bayes_bestOrder}, and is included in \appmaj.

We now apply the same reasoning as in \Cref{sec:bayes_epsilon}.
If $ p = p(M) $, then the worst-case learning rate of a satisfying assignment is $\frac{N\pcell + M\pone}{3N + 5M},$ strictly higher than the best-case non-satisfying LR, $\frac{N\pcell + (M-1)\pthree + \pzero}{3N + 5M}$. We can thus define the threshold (mind the new number of vertices---$ G_\varphi $ now has 5 for each clause):
\begin{align*}
    \varepsilon = \frac{1}{2}\left(\frac{2N\pcell + M\pone + (M-1)\pthree + \pzero}{3N + 5M}\right).
\end{align*}
This concludes the proof.
