\section{Related Work}
\subsection{Learning-Based MRI Reconstruction}
Learning-based models promise improved performance and reliability over traditional methods in MRI reconstruction \cite{Hammernik2017}. Yet, realizing this promise requires copious amounts of training data including diverse samples, since learning-based models poorly represent rare features and pathologies in their training sets \cite{data_diff}. Unfortunately, curating broad training sets is unfeasible in many applications given the high costs of scanning and subject recruitment \cite{GuoTMI2021}. These costs bear the common practice of model training on limited datasets available locally in solitary imaging sites, and such single-site models can inevitably suffer from suboptimal generalization \cite{dalmaz2024one}. Numerous strategies have been devised over the years to alleviate the unwanted influences of dataset scarcity, including transfer learning \cite{Dar2017}, unpaired learning \cite{Quan2018c, oh2020}, semi-supervised learning \cite{yurt2022semi}, and self-supervised learning \cite{yaman2020, FengLiu2021}. However, these canonical strategies rely on centralized model training following aggregation of datasets in a central repository, which incurs significant privacy concerns and maintenance costs \cite{kaissis2020secure}.

\subsection{Federated Learning for MRI Reconstruction}
Federated learning (FL) has emerged as a privacy-preserving collaboration framework that distributes the costs of model training across healthcare institutions \cite{kaissis2020secure}. Abandoning explicit sharing of sensitive imaging data, FL promotes cross-site knowledge transfer via exchange of model weights instead. In conventional FL, this exchange is attained by first training copies of a global model on the local datasets available at individual sites, and then aggregating the local copies into the shared global model on a server \cite{WenqiLi2019}. Several recent MRI studies have successfully adopted this conventional FL framework to boost generalization performance of reconstruction models \cite{guo2021,elmas2022federated,feng2023tmi}. Further improvements in site-specific performance have also been sought by employing personalized FL strategies to cope with differences in the distribution of MRI datasets across sites, such as partial model aggregation \cite{feng2023tmi}, test-time adaptation \cite{elmas2022federated}, and feature map normalization \cite{dalmaz2024one}. 

Despite their apparent benefits, previous FL methods for MRI reconstruction constrain all participating sites to adopt a homogeneous model architecture, which serves as the foundation for aggregating model weights \cite{FedAvg}. Note, however, that imaging sites can have substantial differences in computational resources or in difficulty of reconstruction tasks dependent on the interaction between distribution of local MRI datasets and desired acceleration rates. In turn, these differences can drive individual sites to prefer distinct models for MRI reconstruction, as evident from the literature where model preferences range broadly from convolutional \cite{guo2021,GuoTMI2021,feng2023tmi} and transformer \cite{korkmaz2022unsupervised,MTrans,feng2023cvpr} backbones to physics-driven unrolled architectures \cite{MoDl,levac2023bio,wang2024fed,mambaroll}. As such, the rigid model-homogeneity requirement of conventional FL severely limits the flexibility of individual sites, forcing them to forgo architectures tailored to their specific needs. During multi-institutional collaborations, this restriction can hinder participation of sites with limited resources or compromise performance in sites with copious resources.

To enable collaborative training of heterogeneous models across sites, here we introduce FedGAT as the first model-agnostic FL method for MRI reconstruction. Unlike conventional FL that transfers knowledge by communicating weights of the reconstruction model, FedGAT leverages a unique approach that decouples the process of knowledge transfer across sites from the process of building site-specific reconstruction models, and that mediates knowledge transfer via a global generative prior for multi-site MR images. Note that previous FL methods in machine learning that build generative priors have commonly proposed adversarial priors that can suffer from poor training stability and image quality \cite{FedGAN,elmas2022federated}, and diffusion priors that can suffer from suboptimal convergence that can lead to residual image noise and prolonged run times \cite{FedDDA}. In contrast, here we introduce a novel prior based on generative autoregressive transformers that efficiently synthesizes MR images via autoregressive prediction of feature maps across growing spatial scales, under guidance from a site prompt to preserve site-specific characteristics in MR images. At each site, a site-specific reconstruction model is then locally trained on a hybrid dataset comprising both the local dataset and synthetic datasets from other sites generated via the global prior. These technical advances enable FedGAT to operate seamlessly in model-heterogeneous settings, overcoming a critical barrier towards privacy-preserving collaborations across diverse institutions.