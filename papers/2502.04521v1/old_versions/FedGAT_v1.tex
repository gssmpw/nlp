\documentclass[journal,twoside,web]{ieeecolor}
\usepackage{tmi2}
\usepackage{cite}
\usepackage{comment}
\usepackage{amsmath,amssymb,amsfonts,mathbbol}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{float}
\usepackage{adjustbox}
\usepackage{caption}
\usepackage{stfloats}
\usepackage[dvipsnames]{xcolor}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{longtable}
\usepackage{pifont} % Add this to the preamble
\usepackage{multirow}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\setlength{\floatsep}{2ex}
\setlength{\dblfloatsep}{2ex}
\setlength{\textfloatsep}{2ex}
\setlength{\dbltextfloatsep}{2ex}
\setlength{\intextsep}{2ex}
\def\baselinestretch{1.0}
\setlength{\textheight}{1.000\textheight}
\setlength{\headsep}{2ex}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\setlength{\abovedisplayshortskip}{3pt}
\setlength{\belowdisplayshortskip}{3pt}
\setlength{\parskip}{0mm plus1mm minus0mm}
\setlength\tabcolsep{3 pt}
\renewcommand{\arraystretch}{1.3}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={FedGAT},
}

\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output

\usepackage[font=small,justification=justified,belowskip=2pt,aboveskip=2pt]{caption}
\setlength{\skip\footins}{3pt}

\usepackage[math]{cellspace}
\cellspacetoplimit 2pt
\cellspacebottomlimit 1pt

\floatname{algorithm}{Algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\def\SPSB#1#2{\rlap{\textsuperscript{{#1}}}\SB{#2}}
\def\SP#1{\textsuperscript{#1}}
\def\SB#1{\textsubscript{#1}}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\markboth{}{Generative Autoregressive Transformers for Model-Agnostic Federated MRI Reconstruction}
\begin{document}
\title{Generative Autoregressive Transformers for Model-Agnostic Federated MRI Reconstruction}
\author{Valiyeh A. Nezhad, Gokberk Elmas, Bilal Kabas, Fuat Arslan, and Tolga \c{C}ukur$^*$, \IEEEmembership{Senior Member} \vspace{-1.2cm}
\\
\thanks{\\
This study was supported in part by a TUBA GEBIP 2015 fellowship, and a BAGEP 2017 fellowship (Corresponding author: Tolga Çukur).}
\thanks{V.A. Nezhad, G. Elmas, B. Kabas, F. Arslan, and T. Çukur are with the Department of Electrical and Electronics Engineering, and the National Magnetic Resonance Research Center, Bilkent University, Ankara, Turkey (e-mail: \{valiyeh.ansarian@, gokberk@ee., bilal.kabas@, fuat.arslan@, cukur@ee.\}bilkent.edu.tr).}
}

\maketitle

\begin{abstract}
Although learning-based models hold great promise for MRI reconstruction, single-site models built on limited local datasets often suffer from poor generalization. This challenge has spurred interest in collaborative model training on multi-site datasets via federated learning (FL)-- a privacy-preserving framework that aggregates model updates instead of sharing imaging data. Conventional FL builds a global model by aggregating locally trained model weights, inherently constraining all sites to a homogeneous model architecture. This rigid homogeneity requirement forces sites to forgo architectures tailored to their compute infrastructure and application-specific demands. Consequently, existing FL methods for MRI reconstruction fail to support model-heterogeneous settings, where individual sites are allowed to use distinct architectures. To overcome this fundamental limitation, here we introduce FedGAT, a novel model-agnostic FL technique based on generative autoregressive transformers. FedGAT decentralizes the training of a global image prior that captures the distribution of multi-site MRI data. For enhanced fidelity, we propose a novel site-prompted GAT prior that controllably synthesizes MR images from desired sites via autoregressive prediction across spatial scales. Each site then trains its local reconstruction model--using its preferred architecture--on a hybrid dataset comprising local data and GAT-generated synthetic data for other sites. Comprehensive experiments on multi-institutional datasets demonstrate that FedGAT supports flexible collaborations while enjoying superior generalization and site-specific performance compared to state-of-the-art FL baselines. 
\end{abstract}

\begin{IEEEkeywords}
MRI, reconstruction, federated learning, model agnostic, generative, autoregressive, transformer. 
\end{IEEEkeywords}


\bstctlcite{IEEEexample:BSTcontrol}

\section{Introduction}
\IEEEPARstart{M}{agnetic} Resonance Imaging (MRI) is an indispensable diagnostic modality due to its exceptional soft-tissue contrast. Yet, characteristically long scan times in MRI exams can disrupt clinical workflows and reduce patient comfort \cite{Lustig2007}. A mainstream approach to improve scan efficiency relies on reconstruction of MR images from undersampled acquisitions \cite{Zhao2015,haldar2016p}. Learning-based reconstruction models have shown particular promise in recovering high-quality images from undersampled k-space data \cite{Wang2016, Hammernik2017, Kwon2017, Dar2017, Han2018a, ADMM-CSNET, raki, Xiang2019}. Despite their potential, models trained on local datasets available at individual sites often struggle to represent rare tissue features and fail to generalize effectively across sites \cite{Schlemper2017, MoDl, Quan2018c, Yu2018c, KikiNet, Mardani2019b, Polakjointvvn2020, rgan, PatelRecon}. As such, the development of robust models remains hindered by the limited availability of diverse training datasets in solitary institutions due to economic costs and privacy concerns \cite{LiangSPM, chen2022review, wang2024review}. This limitation underscores the pressing need for collaborative approaches to build models on multi-site MRI data while preserving patient privacy \cite{kaissis2020secure, heckel_deep_2024}.

Federated learning (FL) is an emergent paradigm for collaborative model training in privacy-sensitive domains such as medical imaging \cite{WenqiLi2019, Rieke2020}. By exchanging model weights as opposed to raw imaging data, FL enables knowledge transfer among sites while alleviating potential privacy risks \cite{Li2020}. Recognizing the transformative potential of FL, several recent studies on MRI reconstruction have proposed FL methods for building models on multi-site datasets \cite{guo2021,elmas2022federated,feng2023tmi,wang2024fed,levac2023bio,yan2024jbhi}. A common theme among these studies is their adherence to the conventional FL framework based on a server-client topology \cite{Li2020}. In this framework, a globally shared model is selected via agreement across sites to serve as the foundation for knowledge transfer. Over multiple communication rounds, local model copies trained on local data available at each site are aggregated on the server to update the global model \cite{FedAvg}. The global model is eventually expected to possess knowledge on the multi-site data distributions and thereby improve generalization performance over single-site models trained exclusively on local data \cite{guo2021}. 

While the conventional FL framework has shown promise in MRI reconstruction, it imposes a strict requirement for all participating sites to adopt a homogeneous model architecture as the basis for aggregating model weights during training \cite{FedAvg}. However, MRI imaging sites often differ substantially in terms of their computational resources and the complexity of their reconstruction tasks, which are influenced by variations in local data distributions and desired acceleration rates. These differences frequently lead sites to favor distinct model architectures, including data-driven convolutional networks that can be preferred to attain high local precision under relatively low compute budgets \cite{guo2021,elmas2022federated}, transformers that can be preferred to boost sensitivity to long-range contextual features when high compute budgets are available \cite{feng2023cvpr,korkmaz2022unsupervised}, or physics-driven unrolled networks that can be preferred to boost model reliability when training sets are relatively scarce albeit moderate-to-high compute budgets are available \cite{levac2023bio,wang2024fed}. Consequently, the architectural constraints in conventional FL refrain sites from leveraging models optimized for their specific requirements. Lack of architectural freedom has important practical implications such as discouraging participation from resource-constrained sites, compromising performance at sites with access to more advanced resources, and ultimately stifling innovations in MRI reconstruction models. Therefore, enabling model-agnostic FL—where sites can collaborate without adhering to a homogeneous model architecture—remains an open challenge \cite{mittone2023model}. 

In this study, we introduce a novel FL technique based on generative autoregressive transformers (FedGAT), which to our knowledge is the first model-agnostic FL approach in the literature for MRI reconstruction. Unlike conventional FL methods, FedGAT supports model-heterogeneous settings by decoupling the process of cross-site knowledge transfer on data distributions, from the process of building reconstruction models (Fig. \ref{fig:FedGAT_gen}). It mediates knowledge transfer via a global generative prior designed for multi-site MRI data. To avoid the limitations of existing adversarial and diffusion priors, we propose a novel GAT prior that autoregressively synthesizes MR images by predicting feature maps across spatial scales, guided by a site prompt to preserve site-specific characteristics. Afterwards, site-specific reconstruction models are locally trained on a hybrid dataset, combining local data with synthetic data generated by the global prior. Comprehensive demonstrations on multi-site MRI datasets indicate that FedGAT functions effectively in model-heterogeneous settings, overcoming a significant challenge in enabling privacy-preserving collaborations across diverse institutions. Code to implement FedGAT is available at {\small{\url{https://github.com/icon-lab/FedGAT}}}.

\vspace{0.2cm}
\subsubsection*{\textbf{Contributions}} 
\begin{itemize} 
\item To the best of our knowledge, FedGAT is the first model-agnostic federated learning (FL) method for MRI reconstruction, enabling seamless collaboration among sites with heterogeneous model preferences. 
\item To support model-heterogeneous settings, FedGAT decouples decentralized training of a global generative prior on multi-site MRI data for cross-site knowledge transfer, from local training of site-specific reconstruction models on a combination of local and synthetic MRI data.
\item To improve fidelity of synthetic MRI data, FedGAT employs a novel prior based on generative autoregressive transformers, formulating image generation as a next-spatial-scale prediction task and enforcing control over the data distribution via a site-prompting mechanism. 
\item To strike a balance between generalization and site-specific performance, FedGAT leverages a training procedure where reconstruction models pre-trained on local data are fine-tuned on a hybrid dataset including synthetic data from other sites. 
\end{itemize}

\begin{figure*}[t]
\centering
\includegraphics[width=0.99\textwidth]{figures/figure1.png}
\captionsetup{justification=justified, width=\textwidth}
\caption{FedGAT devises a two-tier strategy to collaboratively train heterogeneous models for MRI reconstruction. \textbf{(a)} The first tier conducts decentralized training of a global prior \(\text{GAT}_{\theta_{\text{GAT}}}\) that captures the distribution of multi-site MRI data. The global prior is built on a novel generative autoregressive transformer that formulates image generation as a next-spatial-scale prediction task, and that employs a site prompt $\texttt{sp}$ for controllable generation data from desired sites. \textbf{(b)} The second tier conducts local training of site-specific reconstruction models $H^k_{{\phi}^k}$ ($k$: site index). To achieve an optimal balance between generalization and site-specific performance, training is performed on a hybrid dataset comprising local data from the given site and synthetic data from other sites.}
\label{fig:FedGAT_gen}
\vspace{-0.1cm}
\end{figure*}



\section{Related Work}

\subsection{Learning-Based MRI Reconstruction}
Learning-based models promise improved performance and reliability over traditional methods in MRI reconstruction \cite{Hammernik2017}. Yet, realizing this promise requires copious amounts of training data including diverse samples, since learning-based models poorly represent rare features and pathologies in their training sets \cite{data_diff}. Unfortunately, curating broad training sets is unfeasible in many applications given the high costs of scanning and subject recruitment \cite{GuoTMI2021}. These costs bear the common practice of training on limited datasets available locally in individual imaging sites, and such single-site models inevitably suffer from poor generalization \cite{dalmaz2024one}. Numerous strategies has been devised over the years to alleviate the unwanted influences of data scarcity, including transfer learning \cite{Dar2017}, unpaired learning \cite{Quan2018c, oh2020}, semi-supervised learning \cite{yurt2022semi}, and self-supervised learning \cite{yaman2020, FengLiu2021}. However, these canonical strategies rely on centralized model training following data aggregation in a central repository, which incurs significant privacy concerns and maintenance costs \cite{kaissis2020secure}.

\subsection{Federated Learning for MRI Reconstruction}
Federated learning (FL) has emerged as a privacy-preserving collaboration framework that distributes the costs of model training across healthcare institutions \cite{kaissis2020secure}. Abandoning explicit sharing of sensitive imaging data, FL promotes cross-site knowledge transfer via exchange of model parameters instead. In conventional FL, this exchange is attained by first training copies of a global model on local data at each site, and then aggregating the local copies into the shared global model on a server \cite{WenqiLi2019}. Several recent MRI studies have successfully adopted this conventional FL framework to boost generalization performance of reconstruction models \cite{guo2021,elmas2022federated,feng2023tmi}. Further improvements in site-specific performance have also been sought by employing personalized FL strategies to cope with cross-site data heterogeneity, such as partial model aggregation \cite{feng2023tmi}, test-time adaptation \cite{elmas2022federated}, and feature map normalization \cite{dalmaz2024one}. 

Despite their apparent benefits in MRI reconstruction, previous methods based on conventional FL constrain all participating sites to adopt a homogeneous model architecture, which serves as the foundation of knowledge transfer via aggregation of model weights \cite{FedAvg}. Note, however, that imaging sites can have substantial differences in computational resources or in difficulty of reconstruction tasks dependent on the interaction between local data distributions and desired acceleration rates. In turn, these differences can drive individual sites to prefer distinct models for MRI reconstruction, as evident from the literature where model preferences range broadly from data-driven convolutional \cite{guo2021,GuoTMI2021,feng2023tmi} and transformer \cite{korkmaz2022unsupervised,MTrans,feng2023cvpr} backbones to physics-driven unrolled architectures \cite{MoDl,levac2023bio,wang2024fed,mambaroll}. As such, the rigid model-homogeneity requirement of conventional FL severely limits the flexibility of individual sites, forcing them to forgo architectures tailored to their specific need. This lack of architectural freedom during multi-institutional collaborations can hinder participation of sites with limited resources or compromise performance in sites with copious resources.

To enable collaborative training of heterogeneous models across sites, here we introduce FedGAT as the first model-agnostic FL method for MRI reconstruction. Unlike conventional FL that transfers knowledge by communicating weights of the reconstruction model, FedGAT leverages a unique approach that decouples cross-site knowledge transfer from building of site-specific reconstruction models, and that mediates knowledge transfer via a global generative prior for multi-site MRI data. Note that previous FL methods in machine learning that build generative priors have commonly proposed adversarial priors that can suffer from poor training stability and sample diversity, and diffusion priors that can suffer from residual image noise and prolonged run times. In contrast, here we introduce a novel prior based on generative autoregressive transformers that synthesize MR images via next-spatial-scale prediction of feature maps under guidance from a site prompt. Reconstruction models are locally trained on a hybrid dataset comprising both local data and synthetic data from other sites generated via the global prior. These technical advances enable FedGAT to operate seamlessly in model-heterogeneous settings, overcoming a critical barrier towards privacy-preserving collaborations across diverse institutions. 





\section{Theory}

\subsection{Conventional FL for MRI Reconstruction}
In MRI, the image domain and measurement domain where k-space data are acquired are linked through an imaging operator $\mathcal{A}=\mathcal{M}\mathcal{F}\mathcal{C}$ ($\mathcal{M}$: sampling pattern, $\mathcal{F}$: Fourier transform, $\mathcal{C}$: coil sensitivities):
\begin{equation}
\label{eq:AXY}
\mathcal{A} x = y,
\end{equation}
where $x$ is the MR image and $y$ are acquired k-space data. For undersampled acquisitions, adequate solution of Eq.~\ref{eq:AXY} requires incorporation of a regularizing constraint $\mathcal{R}(\cdot)$ \cite{Lustig2007}:
\begin{equation}
\label{eq:regularized_recon}
\widehat{x} = \underset{x}{\operatorname{argmin}} \| y - \mathcal{A} x \|_{2}^{2} + \mathcal{R}(x).
\end{equation}
Over the recent years, learning-based methods have gained prominence that operationalize the solution of Eq. \ref{eq:regularized_recon} as a forward pass through a network model $\widehat{x}=H_{\phi}(\mathcal{A}^{\dagger}y)$ where $\mathcal{A}^{\dagger}$ is the Hermitian adjoint of $\mathcal{A}$ \cite{Hammernik2017}.

In the conventional FL framework, an MRI reconstruction model is collaboratively trained over $L$ rounds of communication between a server and participating sites \cite{WenqiLi2019,Rieke2020}. The server maintains a global reconstruction model $H_{\phi}$ parameterized by $\phi$, and sites retain local copies of this common architecture $\{H_{\phi^k}\}_{k=1}^K$ where $k$ is site index, $K$ is the number of sites. At the start of the $l$th communication round, all sites initialize their local copies with the parameters of the global model broadcast by the server, $\phi^k \gets \phi(l-1)$. At the $k$th site, the initialized local copy $H_{\phi^k}$ is then trained on the available local dataset $\mathcal{D}_{\text{loc}}^k$ to minimize a reconstruction loss:
\begin{equation}
\label{eq:fed_dnn_training}
\mathcal{L}^{k}_{\text{rec}}(\mathcal{D}_{\text{loc}}^k) = \mathbb{E}_{(x^{k}_{\text{i}}, y^{k}_{\text{i}}) \sim \mathcal{D}_{\text{loc}}^k} \left[ \| x^{k}_{\text{i}} - H_{\phi^k}(\mathcal{A}^{\dagger k}_{\text{i}} y^{k}_{\text{i}}) \|_2^2 \right],
\end{equation}
where $\mathbb{E}$ denotes expectation over the local dataset $\mathcal{D}_{\text{loc}}^k$, $i$ denotes the sample index within $\mathcal{D}_{\text{loc}}^k$, $x^{k}_{\text{i}}$ is the reference image corresponding to a fully-sampled acquisition, $y^{k}_{\text{i}}$ is the corresponding undersampled acquisition, and $\mathcal{A}^k_{\text{i}}$, $\mathcal{A}^{\dagger k}_{\text{i}}$ are the imaging operator and its adjoint, respectively. 

At the end of the given communication round, locally-trained model copies are aggregated on the server via  averaging of parameters to derive an updated global model \cite{FedAvg}:
\begin{equation}
    \phi(l) = \sum_{k=1}^{K} \alpha_k \phi^k,
\end{equation}
where $\alpha_k = \frac{N^k}{\sum_{z=1}^K N^z}$ is the weight for site $k$ ($N^k$: the number of training samples at site $k$, $\sum_{z=1}^K N^z$: the number of training samples across all sites). 

After a total of $L$ communication rounds, the resultant global model $H_{\phi^{*}}$ with $\phi^* := \phi(L)$ is employed at each site to reconstruct MR images. In particular, reconstruction for the \( j \)-th test subject at site $k$ is formulated as:
\begin{equation}
\hat{x}^{k}_{j} = H_{\phi^*}(\mathcal{A}^{\dagger k}_{j} y^{k}_{j}),
\end{equation}
where $\hat{x}^{k}_{j}$ is the reconstructed image, and $y^{k}_{j}$ are the respective undersampled k-space data. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Federated Generative Autoregressive Transformers}
FedGAT is a model-agnostic FL framework that enables collaborative training of heterogeneous model architectures across sites by leveraging a decoupled two-tier strategy. During the first tier that follows a server-client topology, a site-prompted global prior based on generative autoregressive transformers is decentrally trained so as to capture the distribution of multi-site MRI data (Fig. \ref{fig:FedGAT_gen}\textbf{a}). The FL server sends the trained global prior to individual sites at the end of the first tier. During the second tier, site-specific reconstruction models are locally trained at each site with the aid of this global GAT prior (Fig. \ref{fig:FedGAT_gen}\textbf{b}). In particular, reconstruction models pre-trained on local data are later fine-tuned on a hybrid dataset containing both local data and synthetic data from other sites generated via the prior. The architecture of the global GAT prior and training procedures for FedGAT are detailed in subsections below.

\subsubsection{\underline{Architecture of the Site-Prompted GAT Prior}}
FedGAT uses a global generative prior to capture the distribution of multi-site MRI data, such that synthetic MR images from individual sites can later be generated. Given the success of autoregressive models in computer vision tasks \cite{AutoRSurvey} and the unparalleled contextual sensitivity of transformers in MR image formation tasks \cite{dalmaz2021resvit,korkmaz2022unsupervised}, here we propose a novel GAT prior equipped with transformers to autoregressively generate multi-site MR images. Unlike traditional autoregressive models devised to predict the next-token given earlier tokens (i.e., pixels or small patches) in an image \cite{pixelcnnrecon}, the autoregressive process in GAT predicts next-scale feature maps given maps at earlier spatial scales as inspired by a recent autoregressive model for natural images \cite{VAR}. Yet, differently from \cite{VAR}, GAT introduces a novel site-prompting mechanism to ensure refined control over the sites that the synthetic MR images represent. 

Since transformer architectures process images as a sequence of tokens and suffer from quadratic complexity with respect to sequence length, using transformers on pixel-level tokens is computationally challenging \cite{vaswani2021scaling}. To mitigate computational burden, here we leverage autoregressive transformers to instead synthesize feature maps in a compact latent space, while mapping between the image domain and the latent space via a variational autoencoder \cite{VQVAE}, drawing inspiration from recent efforts in generative modeling \cite{LDM}. Thus, the GAT prior comprises a compound architecture comprising VAE encoder-decoder and autoregressive transformer modules. 

\textbf{\textit{VAE Encoder Module:}} Receiving a coil-combined complex MR image $\mathbf{x} \in \mathbb{R}^{h \times w \times 2}$, the VAE encoder aims to map its input onto discrete token maps $\mathbf{f}_1, \mathbf{f}_2, \dots, \mathbf{f}_S$ across $S$ spatial scales. To do this, it first extracts a continuous latent representation $\mathbf{z} \in \mathbb{R}^{h_S \times w_S \times c}$ ($h_S$, $w_S$ denoting spatial dimensions at the $S$th scale--the highest scale) via a set of convolutional layers. The token maps at each spatial scale are then extracted by spatial downsampling to attain dimensions of $h_s$, $w_s$ at the $s$th scale, followed by quantization based on a learnable codebook $\mathbf{B} \in \mathbb{R}^{V \times c}$ with vocabulary size $V$. 

To minimize redundancy and information losses across scales, here we adopt a hierarchical procedure for token map extraction that progresses from the lowest ($s$$\,=\,$$1$) to the highest ($s$$\,=\,$$S$) spatial scale \cite{VQGAN}. For this purpose, a residual continuous representation $\mathbf{r}_{s} \in \mathbb{R}^{h_S \times w_S \times c}$ is maintained, initialized as $\mathbf{r}_{1}=\mathbf{z}$ at $s$$\,=\,$$1$. At the $s$th scale, the residual continuous representation is used to derive $\mathbf{f}_s$ as follows:
\begin{equation}
\mathbf{f}_s = \underset{v \in \{1, \dots, V\}}{\mathrm{argmin}} \, \lVert \mathbf{B}_{(v\,;\,:)} - \text{Down}_s(\mathbf{r}_{s}) \rVert^2,
\end{equation}
where $\mathbf{f}_s \in [V]^{h_s \times w_s}$, $\text{Down}_s$ denotes spatial downsampling to the $s$th scale via interpolation, and quantization is attained by identifying the closest vector in the codebook that minimizes Euclidean distance. Afterwards, codebook vectors corresponding to $\mathbf{f}_s$ are retrieved and upsampled via interpolation to the $S$th scale, and used to update the residual representation:
\begin{equation}
\mathbf{r}_{s+1} = \mathbf{r}_{s} - \text{Conv}(\text{Up}_S(\text{Lookup}(\mathbf{B},\mathbf{f}_s))),
\end{equation}
where $\text{Lookup}$ is the retrieval function for codebook vectors given discrete token maps, $\text{Up}_S$ denotes spatial upsampling to the $S$th scale via interpolation, and $\text{Conv}$ denotes a convolutional layer. Note that, at the encoder output, the discrete token maps derived at individual spatial scales are pooled into an aggregate multi-scale token map:
\begin{equation}
\{\mathbf{f}_1, \mathbf{f}_2, \dots, \mathbf{f}_S\} = \mathrm{Enc}(\mathbf{x}),
\end{equation}
which serves as the foundational features for autoregressive modeling in subsequent stages. 

\textbf{\textit{VAE Decoder Module:}} The VAE decoder aims to map discrete multi-scale token maps $\{\mathbf{f}_1, \mathbf{f}_2, \dots, \mathbf{f}_S\}$ back on the corresponding MR image $\mathbf{x}$ from which they were derived. Paralleling the extraction procedure in the VAE encoder, the decoder employs a hierarchical procedure to reconstruct the image progressively from low-to-high spatial scales. In particular, a residual continuous representation is initialized as $\mathbf{r}_{0}=0 \in \mathbb{R}^{h_S \times w_S \times c}$. At the $s$th scale, codebook vectors corresponding to the discrete token map $\mathbf{f}_s$ are retrieved and upsampled, and used to update the residual representation: 
\begin{equation}
\mathbf{r}_{s} = \mathbf{r}_{s-1} + \text{Conv}(\text{Up}_S(\text{Lookup}(\mathbf{B},\mathbf{f}_s))).
\end{equation}
Following $S$ scales of processing, the continuous representation $\mathbf{r_S} \in \mathbb{R}^{h_S \times w_S \times c}$ at the highest scale is used to recover the original image via a set of convolutional layers: 
\begin{equation}
\hat{\mathbf{x}} = \text{Rec}(\mathbf{r}_S),
\end{equation}
where $\hat{\mathbf{x}} \in \mathbb{R}^{h \times w \times 2}$ denotes a reconstruction of the original input MR image. 

\begin{figure*}[t]
\centering
\includegraphics[width=0.95\textwidth]{figures/figure2.png}
\captionsetup{justification=justified, width=\textwidth}
\caption{\color{red}NOTATIONS sos instead of sp\color{black} 
To generate the token map $\mathbf{f}_s$ during the $s$-th autoregressive step (e.g., $\mathbf{f}_2$), the process begins with the previous token map $\mathbf{f}_{s-1}$. The most recent token map, $\mathbf{f}_{s-1}$, is reshaped into a 2D structure (e.g., $1 \times 1$ for $\mathbf{f}_1$), embedded into a 2D feature map, and upsampled to match the spatial dimensions of $\mathbf{f}_s$ (e.g., $2 \times 2$ for $\mathbf{f}_2$). The upsampled feature map is then projected into the hidden dimension of the GAT transformer. A 2D positional embedding is added, resulting in the input embedding $\mathbf{e}_s$. Finally, the transformer processes $\mathbf{e}_s$ alongside the previous tokens to generate $\mathbf{f}_s$ .
}
\label{fig:GAT_arch}
\vspace{-0.1cm}
\end{figure*}

\textit{\textbf{Autoregressive Transformer Module:}} 
With the multi-scale token maps captured by the VAE in place, the proposed GAT prior formulates image generation as an autoregressive process that involves predictions across spatial scales. In particular, the transformer module aims to predict the sequence of tokens $\mathbf{f}_s$ at the $s$th scale, given as input the sequence of tokens aggregated across lower scales $\mathbf{f}_{<s}$$\,:=\,$$\{\mathbf{f}_1,...,\mathbf{f}_{s-1}\} \in \mathbb{R}^{T_{s-1}}$ ($T_{s-1} = \sum_{e=1}^{s-1} h_e w_e$ denoting the number of tokens at lower scales) and a site prompt $\mathbf{sp}(k)$$\,:=\,$$\mathbb{I}(k) \in \mathbb{R}^{1 \times K}$ that denotes a one-hot indicator for site identity. The transformer module uses the site prompt to initialize a site token $\mathbf{st} \in \mathbb{R}^{1 \times d}$:
\begin{equation}
\mathbf{st} = \mathbf{sp} \cdot \mathbf{E}_{\text{site}},
\end{equation}
where $\mathbf{E}_{\text{site}} \in \mathbb{R}^{K \times d}$ is a learnable embedding matrix and $d$ is the embedding dimensionality. A hidden representation is then derived by pooling the site token with a learnable projection of $\mathbf{f}_{<s}$, and adding learnable position and scale encodings:
\begin{equation}
\label{eq:vithid}
\mathbf{h}_0 = [\mathbf{st};\,\, [\mathbf{f}_{<s};\, \mathbf{m}] \cdot \mathbf{E}_{\text{tok}}] + \mathbf{E}_{\text{pos}} + \mathbf{E}_{\text{sca}},
\end{equation}
where $\mathbf{h}_0 \in \mathbb{R}^{(1+T_S)\times d}$ is the hidden representation where $T_S = \sum_{e=1}^{S} h_e w_e$ is the number of tokens across all scales, $\mathbf{E}_{\text{tok}} \in \mathbb{R}^{T_S \times d}$ is the token projection matrix, $\mathbf{E}_{\text{pos}} \in \mathbb{R}^{(1+T_S) \times d}$ is the position encoding that captures the relative spatial locations of tokens, and $\mathbf{E}_{\text{sca}} \in \mathbb{R}^{(1+T_S) \times d}$ is the scale encoding that captures the relative spatial scales of tokens. In Eq. \ref{eq:vithid}, $\mathbf{m} := 0^{(T_S-T_{s-1}) \times d}$ is a zero matrix that masks tokens from spatial scales succeeding the $(s-1)$th scale to ensure causal progression from lower to higher scales. 

To predict $\mathbf{f}_s$, the initial hidden representation $\mathbf{h}_0$ is projected through $L$ transformer blocks, where each block follows the common transformer architecture comprising multi-head self-attention (MHSA) and multi-later perceptron (MLP) layers interleaved with layer normalization and residual connections \cite{vaswani2021scaling}. Yet, unlike normalization layers in conventional transformers, here we employ adaptive layer normalization (AdaLN) in order to induce site-specific processing of hidden representations \cite{adaln,pflsynth}. In particular, we propose to modulate the statistics of $\mathbf{h}$ via learnable functions of the site token $\mathbf{st}$:
\begin{equation}
\mathrm{AdaLN}(\mathbf{h}, \mathbf{st}) = \gamma(\mathbf{st}) \cdot \frac{\mathbf{h} - \mu(\mathbf{h})}{\sigma(\mathbf{h})} + \beta(\mathbf{st}),
\end{equation}
where $\mathbf{h}$ is the hidden representation, $\mu$ and $\sigma$ the spatial mean and standard deviation vectors for $\mathbf{h}$, and $\gamma, \beta \in \mathbb{R}^{d}$ are learnable mean and std. parameters dependent on $\mathbf{st}$. Accordingly, the projection through the $\ell$th transformer block ($\ell \in [1 \mbox{ } L]$) can be expressed as follows:
\begin{eqnarray}
\mathbf{h}^\prime_{\ell} &=& \mathbf{h}_{\ell-1} + \mathrm{MHSA}(\mathrm{AdaLN}(\mathbf{h}_{\ell-1}, \mathbf{st})),\\
\mathbf{h}_{\ell}&=& \mathbf{h}^\prime_{\ell} + \mathrm{MLP}(\mathrm{AdaLN}(\mathbf{h}^\prime_{\ell}, \mathbf{st})).
\end{eqnarray}

$\mathbf{MHSA}$ layers consist of $S$ separate self-attention heads:
\begin{equation}
\mathbf{MHSA}(\mathbf{h}) = [\mathbf{SA}_1(\mathbf{h}); \mathbf{SA}_2(\mathbf{h}); \dots; \mathbf{SA}_S(\mathbf{h})] \cdot \mathbf{U}_{\mathbf{MHSA}},
\end{equation}
where $\mathbf{SA}_s$ represents the $s$-th attention head, and $\mathbf{U}_{\mathbf{MHSA}}$ is the learnable projection matrix. Each self-attention head computes:
\begin{equation}
\mathbf{SA}(\mathbf{h}) = A \cdot \mathbf{v},
\end{equation}
where $\mathbf{v}$ represents the value vectors, and $A$ is the attention weight matrix, calculated as:
\begin{equation}
A_{i,j} = \text{softmax}\left(\frac{\mathbf{q}_i \cdot \mathbf{k}_j^\top}{\sqrt{N_D}}\right),
\end{equation}
where the queries $\mathbf{q}$ and keys $\mathbf{k}$ are normalized to unit vectors to ensure scale invariance for stabilizing training:
\begin{equation}
\mathbf{q}_i = \frac{\mathbf{T}_q \cdot \mathbf{h}_i}{\|\mathbf{T}_q \cdot \mathbf{h}_i\|}, \quad
\mathbf{k}_j = \frac{\mathbf{T}_k \cdot \mathbf{h}_j}{\|\mathbf{T}_k \cdot \mathbf{h}_j\|}.
\end{equation}

The values $\mathbf{v}$ are derived as:
\begin{equation}
\mathbf{v} = \mathbf{T}_v \cdot \mathbf{h},
\end{equation}
where $\mathbf{T}_q$, $\mathbf{T}_k$, and $\mathbf{T}_v \in \mathbb{R}^{N_D \times N_D}$ are learnable projection matrices.

At the final stage, a site-conditioned head refines the embeddings via $\mathbf{AdaLN}$ and projects them to the output space. The embeddings from the last transformer layer, \( \mathbf{h}_{\text{final}} \), are normalized and conditioned using the site-specific token \( \mathbf{sos} \):
\begin{equation}
\mathbf{h}_{\text{output}} = \mathbf{AdaLN}(\mathbf{h}_{L}) \cdot \left(\gamma(\mathbf{sos}) + 1\right) + \beta(\mathbf{sos}),
\end{equation}
where \( \gamma(\mathbf{sos}) \) and \( \beta(\mathbf{sos}) \) are learnable parameters derived from the site-specific token \( \mathbf{sos} \). 


\begin{algorithm}[t]
\small
\caption{Training of the GAT prior}\label{alg:fedGAT_training}
\KwInput {
    $\mathcal{D}=\{\mathcal{D}^1,...,\mathcal{D}^K\}$: local datasets from $K$ sites. \\
    GAT: global GAT prior with parameters $\theta_{\text{GAT}}$. \\
    \{$\text{GAT}^1,...,\text{GAT}^K$\}: local copies with $\{\theta_{\text{GAT}}^1,...,\theta_{\text{GAT}}^K\}$. \\
    $L$: number of communication rounds.\\ 
    $I$: number of local epochs. \\
}
\KwOutput{Trained global GAT prior with $\hat{\theta}_{\text{GAT}}$.} 
\vspace{0.1cm}
Initialize global prior with $\theta_{\text{GAT}}(0)$.\\
\For{$l = 1:L$}{
    \For{$k = 1:K$}{ 
        $\theta_{\text{GAT}}^k \gets \theta_{\text{GAT}}(l-1)$ {$\triangleright$ global prior onto local copy} \\
        \For{$i = 1:I$}{
            $\theta_{\text{GAT}}^k \gets \theta_{\text{GAT}}^k - \eta \nabla_{\theta_{\text{GAT}}^k} \mathcal{L}^k_{\text{GAT}}$ {$\triangleright$ local update} \\
        }
    }
    $\theta_{\text{GAT}}(l) \gets \sum_{k=1}^{K} \theta_{\text{GAT}}^k$ {$\triangleright$ server aggregation}\\
}
\Return ${\theta}^{*}_{\text{GAT}} := \theta_{\text{GAT}}(L)$
\end{algorithm}




\subsubsection{\underline{Two-Tier Training Procedure for FedGAT}} 
FedGAT employs FL to train a global MRI prior $\text{GAT}$ across multiple sites. Each site $k$ maintains a local copy of the model $\text{GAT}$, while a FL server coordinates the training over \( L \) communication rounds by aggregating model parameters (Alg. \ref{alg:fedGAT_training}). 

Initially, the global GAT model is randomly initialized. At the start of each communication round, the global model parameters are distributed to all sites to initialize the local models:
\begin{equation}
\theta^k_{\text{GAT}} \gets \theta_{\text{GAT}}, \quad \forall k \in \{1, 2, \ldots, K\}.
\end{equation}

Each site $k$ trains its local model $ \text{GAT}^k$ using its local dataset $ \mathcal{D}^k $ over $n_g$ epochs. In the training process site-specific information \texttt{sp} integrate into the token embedding sequence. This token helps adapt the generative process to the characteristics of the specific site. The image tokens $f_{\leq s}$ from previous scales are concatenated with the site-prompt token and fed into the transformer, enabling the model to condition its generation on both spatial context and site-specific attributes.

After completing the local training, each site $k$ sends its updated model parameters $ \theta^k_{\text{GAT}}$ to the FL server. The server aggregates these parameters into the global prior:
\begin{equation}
\theta_{\text{GAT}} = \sum_{k=1}^{K} \theta^k_{\text{GAT}}.
\end{equation}


Following the generative learning phase, FedGAT leverages its model-agnostic framework to train site-specific reconstruction models \( H^k_{\phi} \) for each site \( k \) (Alg. \ref{alg:site_specific_recon}). This server-free, model-agnostic topology enables each site to independently choose the most suitable reconstruction model architecture for its local data, promoting flexibility and adaptability to diverse data distributions. The objective of these models is to accurately reconstruct high-quality MR images \( \hat{x}^k \) from the undersampled k-space data \( y^k_{us} \) collected at each site.

The reconstruction process consists of two stages: initial training with within-site local data, followed by fine-tuning using a combination of local and cross-site synthetic data.

In the first stage, the reconstruction model \( H^k_{\phi} \) is trained using the local MRI data for \( n_r \) epochs to learn the site-specific characteristics:
\begin{equation}
\hat{\phi}^k := \arg \min_{\phi^k} \mathbb{E}_{p(x^k_{ref}, x^k_{us}, y^k_{us})} \left\{ \| x^k_{ref} - H^k_{\phi}(x^k_{us}, y^k_{us}) \|^2 \right\},
\end{equation}
where \( x^k_{ref} \) is the fully-sampled reference image, and \( x^k_{us} \) is the zero-filled reconstruction obtained by applying the inverse Fourier transform \( \mathcal{F}^{-1} \) to the undersampled k-space data \( y^k_{us} \). This phase ensures that the model captures patterns and structures specific to the local data.

In the second stage, each reconstruction model $H^k_{\phi}$ is fine-tuned using both local data and synthetic data generated by the global GAT model. The synthetic data $x^{k}_{syn}=\text{VAE}_S^{-1}(\hat{f}_S)$ is created using the site-prompt token $\texttt{sp}$.


Fine-tuning over $n_s$ epochs involves incorporating both data types to enhance generalization across sites:
\begin{align}
X_{ref} &= \{X^k_{ref} \cup X^k_{\text{syn}}\}, \\
X_{us} &= \{X^k_{us} \cup X^k_{\text{syn,us}}\}, \\
Y_{us} &= \{Y^k_{us} \cup Y^k_{\text{syn,us}}\},
\end{align}
where \( X_{ref} \), \( X_{us} \), and \( Y_{us} \) denote the combined sets of reference images, zero-filled reconstructions, and undersampled acquisitions, respectively.

The fine-tuning objective at site \( k \) becomes:
\begin{align}
\hat{\phi}^k := \arg \min_{\phi^k} & \; \mathbb{E}_{p(X_{ref}, X_{us}, Y_{us}[i])} \Bigg\{ \\
& \| X_{ref}[i] - H^k_{\phi}(X_{us}[i], Y_{us}[i]) \|^2 \Bigg\}.
\end{align}
By fine-tuning the reconstruction models with both local and synthetic data, each site achieves optimal reconstruction performance while preserving the flexibility to use a model architecture that best fits its data.
%\begin{equation}
%\hat{\phi}^k := \arg \min_{\phi^k} \mathbb{E}_{p(X_{ref}, X_{us}, Y_{us}[i])} \Bigg\{ 
%\| X_{ref}[i] - H^k_{\phi}(X_{us}[i], Y_{us}%[i]) \|^2 \Bigg\}.
%\end{equation}




\begin{algorithm}[t]\small
\caption{Training of reconstruction models}\label{alg:site_specific_recon}
\small
\KwInput{
    $\mathcal{D_{\text{\text{loc}}}}^k$: local data from site $k$.\\
    %$H^k$: site-specific reconstruction model with parameters $\phi^k$. \\
    $\text{GAT}$: global GAT prior with $\hat{\theta}_{\text{GAT}}$. \\
    $N_r$: number of pre-training epochs. \\
    $N_s$: number of fine-tuning epochs. \\
}
\KwOutput{
   $H^k_{{\phi}^k}$: reconstruction model at site $k$.
}

Initialize model with $\phi^k(0)$ at site $k$.\\
{$\triangleright$ pre-train on local data}\\
\For{$e = 1$ \textbf{to} $N_r$}{ 
    $\phi^k(e) \leftarrow \phi^k(e-1) - \eta \nabla_{\phi^k}\mathcal{L}^k_{\text{rec}}(\mathcal{D_{\text{\text{loc}}}}^k)$ 
}
{$\triangleright$ generate synthetic data}\\
\For{$j = 1$ \textbf{to} $K$}{
    $\mathcal{D_{\text{syn}}}^j =\text{GAT}(\texttt{sp}(j))$; \\
}
{$\triangleright$ fine-tune on local\&synthetic data}\\
\For{$e = (1+N_r)$ \textbf{to} $(N_s+N_r)$}{
    $\phi^k(e) \leftarrow \phi^k(e-1) - \eta \nabla_{\phi^k}\mathcal{L}^k_{\text{rec}}([\mathcal{D_{\text{\text{loc}}}}^k; \mbox{ } \mathcal{D_{\text{syn}}}^{1,..,k-1,k+1,..,K}])$ 
}
\Return{${\phi}^{k*}:={\phi}^k(N_s+N_r)$}
\end{algorithm}



\section{Methods}
\subsection{Implementation Details}
The proposed VAR prior embodies a VAE encoder that projected MRI images onto multi-scale, quantized token embeddings \cite{VQVAE}, a transformer decoder that autoregressively generated quantized token embeddings across scales by starting from a random embedding at the smallest spatial scale \cite{multi-scaletransformer}, and a VAE decoder that recollected images from quantized token embeddings at the largest scale. Here, $S$$\,=\,$10 spatial scales where an individual token was taken as a $p\times p$ patches, patch size varied as $p$$\,=\,$$\{16, 13, 10, 8, 6, 5, 4, 3, 2, 1\}$ from the smallest to the largest scale. The VAE encoder and decoder each had 5 stages, with the encoder using 10 residual blocks \cite{resnet} in total (2 per stage) and attention in stages 4-5, downsampling via stride-2 convolutions. The decoder used 13 residual blocks in total (2-3 per stage) with attention in stages 4-5, upsampling via transposed convolutions. A mid module with 2 residual blocks and attention mechanisms bridged the encoder and decoder, and a model pre-trained on natural images was adopted without further tuning\footnote{\url{https://github.com/FoundationVision/VAR}}. Embedding dimensionality of $D$$\,=\,$32, and channel dimensionality of $C_{\text{vae}}$$\,=\,$32 were used. A common codebook of size $V$$\,=\,$4096 was prescribed to ensure consistent quantization across scales.  Meanwhile, the transformer decoder, designed for autoregressive generation, was implemented with 16 sequential blocks, each consisting daptive layer normalization (AdaLN), multi-head self-
attention (MHSA) layers and two-layer multi-layer perceptron
(MLP) modules. In the learning objective, $\lambda = 0.0015$ was prescribed.


\subsection{Competing Methods}
FedGAT was comparatively demonstrated against a centralized benchmark along with non-federated (Single) and federated (FedAvg, FedProx, and FedDist) baselines. For fair comparison, all competing methods were implemented with the same learning rate, number of communication rounds and number of epochs. 

    {\textbf{Central}}: A non-FL benchmark for across-site reconstruction performance that pools MRI data across sites to centrally train a global reconstruction model \cite{kaissis2020secure}. 
    
    {\textbf{Single-Site}}: A non-FL benchmark that within-site reconstruction performance that trains site-specific reconstruction models on local data, independently across sites \cite{guo2021}. 
    
    {\textbf{FedAvg}}: An FL baseline that restricts all sites to use the same model architecture, and decentrally trains a global reconstruction model on multi-site MRI data \cite{FedAvg}. 
    
    {\textbf{FedProx}}: An FL baseline that uses a proximal term to cope with data heterogeneity \cite{fedprox}. To permit heterogeneous-model setups, each site maintained global and site-specific reconstruction models. On the server, copies of the global model locally trained at individual sites were aggregated. At individual sites, the aggregated global model was locally distilled onto the site-specific models . 
    
    {\textbf{FedDist}}: An FL baseline that transfers knowledge among sites via model distillation \cite{zhu2021data}. Each site maintained global and site-specific reconstruction models. On the server, site-specific models were distilled onto the global model using a public MRI data. At individual sites, the global model was distilled onto site-specific models using local MRI data. 

    {\textbf{FedGIMP}}: 

    {\textbf{FedDDA}}: 


\subsection{Modeling Procedures}
We considered several three-site FL setups to examine performance under model-heterogeneous and model-homogeneous settings. The reconstruction models trained in these setups included MoDL with varying numbers of cascades \cite{MoDl}, rGAN \cite{rgan}, and D5C5 \cite{Schlemper2017}. All sites were taken to use common imaging operators with matched acceleration rates and sampling densities.

\textit{\underline{Model-heterogeneous settings}}: Each site was allowed to train a distinct reconstruction model. The three sites trained (MoDL-5, rGAN, D5C5) in a first experiment, and they trained (MoDL-3, MoDL-5, MoDL-7) in a second experiment. Note that model-heterogeneous FL precluded use of FedAvg. 

\textit{\underline{Model-homogeneous settings}}: All participating sites were restricted to train MoDL-3 (i.e., 3 cascades) as their reconstruction model. Model-homogeneous FL permits use of FedAvg as an aggregation technique. 

All models were implemented using the PyTorch framework and executed on two RTX 4090 GPUs. Models were trained via the AdamW optimizer with $\beta_1 = 0.9$, $\beta_2 = 0.95$, and a weight decay of 0.05. Training lasted 700 epochs with a communication round at every epoch, and a learning rate of $10^{-4}$. Reconstruction performance was evaluated via peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) metrics. Fidelity of synthetic MR images was evaluated via Freschet's inception distance (FID) metric. Performance differences among competing methods were examined via non-parametric Wilcoxon signed-rank tests (p$<$0.05). 





%\begin{table}[t]
%\centering
%\caption{Performance of reconstruction models trained on synthetic images. Across-site generalization (i.e., when a local model is tested on separate sites) in terms of peak signal-to-noise ratio (PSNR, dB) and structural similarity (SSIM, \%). Results listed as mean\(\pm\)std across test subjects, at R=4x, 8x acceleration rates. 
%}
%\resizebox{0.3\textwidth}{!}
%{
%\begin{tabular}{|l l | Sc | Sc |Sc | Sc |}
% \hline
% & &\multicolumn{2}{Sc|}{\textbf{Within-site}} & \multicolumn{2}{Sc|}{\textbf{Across-site}} \\
% \hline
% & &{PSNR $\uparrow$} & {SSIM $\uparrow$} & {PSNR $\uparrow$}  &{SSIM $\uparrow$}  \\
% \hline
% \multirow{2}{*}{{GAN}}  &  4x & \textbf{40.63$\pm$2.80} &  \textbf{96.74$\pm$1.50 }& 39.37$\pm$3.01 & 95.95$\pm$1.97 \\
% & 8x & \textbf{35.58$\pm$2.81}
 %& \textbf{93.67$\pm$2.30}& 34.42$\pm$2.69 & %91.67$\pm$3.08\\
%\cline{1-6}
%\multirow{2}{*}{{DDPM}}&   4x & 39.46$\pm$2.79 & 96.26$\pm$1.54 & 38.96$\pm$2.92 &  94.62$\pm$2.25
 %\\
 %& 8x & 35.28$\pm$2.90 & 93.55$\pm$2.31 & 34.72$\pm$2.76 &92.67$\pm$2.56\\
%\cline{1-6}
%\multirow{2}{*}{{GAT}} &  4x & 40.32$\pm$2.88 & 96.54$\pm$1.51 & \textbf{40.17$\pm$2.83} & \textbf{96.49$\pm$1.65}\\
% & 8x & 34.77$\pm$2.93 & 93.32$\pm$2.38 &% \textbf{35.18$\pm$2.92} & \textbf{93.62$\pm$2.56}\\
% \hline
%\end{tabular}
%}
%\end{table}



\subsection{Datasets}
In single-coil experiments, multi-contrast coil-combined magnitude MR images from public BraTS \cite{BRATS}, fastMRI \cite{fastMRI} and MIDAS \cite{midas} datasets were analyzed. Each dataset was taken to correspond to a separate site. At each site, (training, validation, test) splits of (40, 5, 10) non-overlapping subjects were used, resulting in (840, 105, 210) cross-sectional images. Subjects were selected at random from the datasets. 

In multi-coil experiments, multi-contrast k-space data from public fastMRI-brain, fastMRI-knee \cite{fastMRI} and an in-house dataset were analyzed \cite{elmas2022federated}. Each dataset was taken to correspond to a separate site. At each site, (training, validation, test) splits of (36, 6, 8) non-overlapping subjects were used, resulting in (840, 105, 210) cross-sectional images. Subjects were selected at random from the datasets. Multi-coil data were compressed to 5 virtual coils \cite{Zhang2013}.  

Both actual and synthetic data were retrospectively undersampled using a variable-density (VD) pattern with acceleration factors R = 4x and 8x \cite{Lustig2007}. Models were trained on a mixture of multi-contrast MRI data without special procedures to handle separate contrasts. When necessary, actual and synthetic MR images were zero-padded to a consistent size to permit training of reconstruction models, albeit performance assessments were conducted in native image sizes by discarding the padded regions following reconstruction. 

\begin{table}[t]
\centering
\caption{A model-heterogeneous FL setting on single-coil data. For each site, Site $k$ (dataset-type) denotes the site index, the local dataset, and the type of reconstruction model. Metrics are listed as mean$\pm$std across the test set, for within-site (upper panel) and across-site (lower panel) reconstructions at R=4x-8x. Note that FedAvg is inapplicable.}
\resizebox{1.025\columnwidth}{!}
{
\begin{tabular}{| Sc | l l | Sc | Sc | Sc | Sc | Sc | Sc |}
 \hline
\multicolumn{3}{|Sc|}{\textbf{Within-site}} & \multicolumn{2}{Sc|}{Site 1 (BraTS-MoDL)} & \multicolumn{2}{Sc|}{Site 2 (fastMRI-rGAN)}& \multicolumn{2}{Sc|}{Site 3 (MIDAS-D5C5)}\\
 \cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{reconstruction}} &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$   \\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{non-FL}}}& \multirow{2}{*}{\underline{Single}}   & 
    4x &\textbf{48.06$\pm$3.33} & \textbf{99.72$\pm$0.11} & 35.83$\pm$2.51 & 90.64$\pm$3.87 & \textbf{29.04$\pm$1.84} &  \textbf{74.20$\pm$3.97}\\
& & 8x & \textbf{42.46$\pm$3.15} & \textbf{99.03$\pm$0.45} & 33.18$\pm$2.26  &  86.58$\pm$4.64
&\textbf{27.79$\pm$2.05 }&\textbf{76.77$\pm$4.08}\\
 \cline{2-9}
 & \multirow{2}{*}{Central}   & 
4x &46.12$\pm$2.55&99.46$\pm$0.20&38.90$\pm$2.70 &81.00$\pm$6.51& - & -\\
& & 8x  &42.16$\pm$2.72&98.65$\pm$0.58&36.22$\pm$2.94 &74.13$\pm$47.71& - & -\\
 \cline{1-9}
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}}& \multirow{2}{*}{FedProx}   & 
    4x & 44.42$\pm$3.76 & 99.34$\pm$0.28 & 32.88$\pm$3.22 & 87.95$\pm$4.41 & 27.62$\pm$1.90  & 59.62$\pm$4.93  \\
& & 8x & 40.06$\pm$3.23 & 98.23$\pm$0.77 & 30.78$\pm$2.73 & 83.45$\pm$5.51 & 27.48$\pm$1.93 & 61.23$\pm$4.32 \\
 \cline{2-9}
 & \multirow{2}{*}
  {FedDist}   &  4x & 44.68$\pm$3.72 & 99.40$\pm$0.24 &34.24$\pm$3.06 &88.48$\pm$4.13 & 28.95$\pm$1.92 &  60.19$\pm$5.07 \\
& & 8x & 40.32$\pm$3.22 & 98.29$\pm$0.75&  32.96$\pm$2.56 & \textbf{86.64$\pm$4.66}&  \textbf{27.79$\pm$2.07} & 62.22$\pm$5.25 \\
 \cline{2-9}
& \multirow{2}{*}{FedGIMP} & 
 4x & 47.61$\pm$2.86 &  99.63v0.15 & - & - & 28.68$\pm$1.90& 73.96$\pm$4.08\\
& & 8x  & 42.14$\pm$2.71 & 98.62$\pm$0.54 & - & - & 26.82$\pm$2.17 & 74.91$\pm$4.42
\\
 \cline{2-9}
 & \multirow{2}{*}{FedDDA} & 
 4x & 47.50$\pm$2.81 & 99.61$\pm$0.15 & - & - & 30.17$\pm$2.42 & 66.28$\pm$7.80\\
& & 8x  &  41.76$\pm$2.90 &  98.47$\pm$0.63 & - & - & 28.86$\pm$2.46 & 63.63$\pm$6.69\\
 \cline{2-9}
& \multirow{2}{*}{FedGAT}   & 
    4x & 47.63$\pm$2.65&99.64$\pm$0.14  & \textbf{35.89$\pm$2.50} &\textbf{90.69$\pm$3.86} & 28.83$\pm$1.97 & 74.19$\pm$4.07\\
& & 8x & 41.60$\pm$2.85&98.78$\pm$0.54 & \textbf{33.23$\pm$2.36} &{86.45$\pm$0.67} & 27.28$\pm$2.23& 73.22$\pm$4.25\\
 \hline
 \hline
 \multicolumn{3}{|Sc|}{\textbf{Across-site}} & \multicolumn{2}{Sc|}{Site 1 (BraTS-MoDL)} & \multicolumn{2}{Sc|}{Site 2 (fastMRI-rGAN)}& \multicolumn{2}{Sc|}{Site 3 (MIDAS-D5C5)}\\
 \cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{reconstruction}} &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$   \\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{non-FL}}}& \multirow{2}{*}{Single}     & 4x & 34.45$\pm$3.57 &  91.44$\pm$4.05  & 33.02$\pm$2.30 & 66.49$\pm$7.26 & 29.67$\pm$2.28 & 75.67$\pm$6.93 \\
& & 8x & 30.48$\pm$3.20 & 85.48$\pm$5.37 &30.08$\pm$2.20
& 59.14$\pm$6.78 &28.38$\pm$2.26 &73.64$\pm$6.55
 \\
 \cline{2-9}

 & \multirow{2}{*}{\underline{Central}}     
 &  4x & 36.48$\pm$2.89 & 94.78$\pm$1.91 & 33.53$\pm$2.31 & 82.93$\pm$4.07 & - & -\\
& & 8x  & 32.79$\pm$2.81 & 92.16$\pm$2.62 & 30.78$\pm$2.25 & 78.75$\pm$4.67 & - & -\\
 \cline{1-9}
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}}& \multirow{2}{*}{FedProx}   & 
    4x & 34.40$\pm$3.12& 93.12$\pm$3.00 & 33.14$\pm$2.61 & 71.59$\pm$6.74 &29.23$\pm$2.38 & 72.45$\pm$8.43 \\
& & 8x & 30.91$\pm$2.87 & 90.33$\pm$3.36 & 30.89$\pm$2.22 & 64.17$\pm$7.14 & 28.37$\pm$2.63 & 72.76$\pm$7.12 \\
 \cline{2-9}
 & \multirow{2}{*}{FedDist}   & 
    4x & 34.61$\pm$3.13 & 93.42$\pm$2.75 & 33.11$\pm$2.26 & 68.04$\pm$6.84 &30.03$\pm$2.41 & 71.80$\pm$7.84 \\
& & 8x & 31.12$\pm$2.83& 90.63$\pm$3.13
 & 30.47$\pm$2.20 & 61.79$\pm$7.06 & 29.05$\pm$2.57& 72.31$\pm$7.93 \\
 \cline{2-9}
 \cline{2-9}
 & \multirow{2}{*}{FedGIMP} & 
4x & 36.42$\pm$3.17 & 94.32$\pm$2.49 & - & - & 30.30$\pm$2.33 & 76.19$\pm$6.56\\
& & 8x  & 31.88$\pm$2.87 & 90.16$\pm$3.78 & - & - & 28.31$\pm$2.16 &  71.75$\pm$6.10\\
 \cline{2-9}
 & \multirow{2}{*}{FedDDA} & 
 4x & 36.19$\pm$3.13 & 94.41$\pm$2.24 & - & - & 28.59$\pm$2.07 & 7.92$\pm$5.11\\
& & 8x  & 31.79$\pm$2.86 & 90.75$\pm$3.07 & - & - &  27.73$\pm$2.13 & 79.13$\pm$5.12\\
 \cline{2-9}
{} & \multirow{2}{*}{FedGAT}   & 
    4x & \textbf{36.71$\pm$3.01} & \textbf{95.02$\pm$1.96} & \textbf{34.50$\pm$2.36} & \textbf{75.69$\pm$5.76} &\textbf{30.77$\pm$2.35} & \textbf{77.08$\pm$6.86}\\
& & 8x & \textbf{32.02$\pm$2.95} & \textbf{91.53$\pm$3.07} & \textbf{31.47$\pm$2.49} & \textbf{71.84$\pm$6.47} & \textbf{29.72$\pm$2.38}&\textbf{77.62$\pm$6.41} \\
\hline
\end{tabular}
}
\label{tab:Heterogeneous_single}
\end{table}

\begin{table}[t]
\centering
\caption{A model-heterogeneous FL setting on multi-coil data (f.knee denotes fastMRI-knee, f.brain denotes fastMRI-brain).}
\resizebox{1.025\columnwidth}{!}{
\begin{tabular}{| Sc | l l | Sc | Sc | Sc | Sc | Sc | Sc |}
 \hline
\multicolumn{3}{|Sc|}{\textbf{Within-site}} & \multicolumn{2}{Sc|}{{Site 1 (f.knee-MoDL)}} & \multicolumn{2}{Sc|}{{Site 2 (f.brain-rGAN)}}& \multicolumn{2}{Sc|}{{Site 3 (UMRAM-D5C5)}}\\
 \cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{reconstruction}} &PSNR$\uparrow$&SSIM$\uparrow$& PSNR$\uparrow$& SSIM$\uparrow$&PSNR$\uparrow$&SSIM$\uparrow$\\
 \hline
 \multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{non-FL}}}& \multirow{2}{*}{\underline{Single}}   & 
    4x & 33.48$\pm$2.35 & 93.21$\pm$1.54 & \textbf{36.97$\pm$3.07} &\textbf{97.32$\pm$1.17} &\textbf{31.81$\pm$1.73}
&\textbf{90.10$\pm$2.57}\\
& & 8x & 29.02$\pm$2.13 & 83.28$\pm$3.10 & \textbf{33.08$\pm$3.39}& \textbf{94.54$\pm$2.26}& \textbf{28.77$\pm$1.71}& \textbf{85.29$\pm$3.64}\\
 \cline{2-9}
& \multirow{2}{*}{Central}   & 
     4x & - & - & - & - & - & -\\
& & 8x  & - & - & - & - & - & -\\
 \cline{1-9}
\multirow{8}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}} & \multirow{2}{*}{FedProx}   & 
    4x & 32.79$\pm$2.19& 
    90.40$\pm$2.45 & 33.95$\pm$2.88 & 96.30$\pm$1.39 & 
   30.34$\pm$1.55  & 88.99$\pm$2.53\\
& & 8x & 27.70$\pm$2.33 &
78.94$\pm$4.57 &
28.80$\pm$2.82 & 90.60$\pm$3.14 & 27.05$\pm$1.72 & 83.94$\pm$3.40\\
 \cline{2-9}
 & \multirow{2}{*}{FedDist}   & 
    4x & 32.48$\pm$2.24&
    90.57$\pm$2.21 &
    34.07$\pm$2.83 & 96.36$\pm$1.36 & 30.10$\pm$1.61 & 88.73$\pm$2.52 \\
& & 8x & 26.99$\pm$2.47 &
78.49$\pm$4.51 & 29.08$\pm$3.15& 90.16$\pm$3.23 & 27.13$\pm$1.64 & 84.18$\pm$3.31 \\
 \cline{2-9}
 & \multirow{2}{*}{FedGIMP} & 
4x & - & - & - & - & - & -\\
& & 8x  & - & - & - & - & - & -\\
 \cline{2-9}

 & \multirow{2}{*}{FedDDA} & 
4x & - & - & - & - & - & -\\
& & 8x  & - & - & - & - & - & -\\
 \cline{2-9}
& \multirow{2}{*}{FedGAT}   & 
    4x & \textbf{33.50$\pm$2.35} & \textbf{93.23$\pm$1.54}  & 35.86$\pm$2.78 &  96.85$\pm$1.19 & 30.72$\pm$1.69 & 88.02$\pm$2.30 \\
& & 8x & \textbf{29.37$\pm$2.13} & \textbf{83.40$\pm$3.14} & 31.48$\pm$2.34
 & 92.89$\pm$2.38 & 27.65$\pm$1.89 &  82.26$\pm$3.53 \\
 \hline
 \hline
 \multicolumn{3}{|Sc|}{\textbf{Across-site}} & \multicolumn{2}{Sc|}{{Site 1 (f.knee-MoDL)}} & \multicolumn{2}{Sc|}{{Site 2 (f.brain-rGAN)}}& \multicolumn{2}{Sc|}{{Site 3 (UMRAM-D5C5)}}\\
 \cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{reconstruction}} &PSNR$\uparrow$&SSIM$\uparrow$& PSNR$\uparrow$& SSIM$\uparrow$&PSNR$\uparrow$&SSIM$\uparrow$\\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{non-FL}}} & \multirow{2}{*}{Single}   &     4x & 37.97$\pm$3.10 & 97.33$\pm$1.51 & 31.17$\pm$3.22 & 93.03$\pm$2.57 & 26.18$\pm$2.62 & 79.42$\pm$5.73 \\
& & 8x & 31.97$\pm$3.01 & 92.06$\pm$2.84 & 26.82$\pm$3.15 & 85.13$\pm$5.06 & 22.64$\pm$2.30 & 70.31$\pm$6.85 \\
 \cline{2-9}
  & \multirow{2}{*}{\underline{Central}}   &     
  4x & - & - & - & - & - & -\\
& & 8x  & - & - & - & - & - & -\\
 \cline{1-9}
\multirow{8}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}} & \multirow{2}{*}{FedProx}   & 
    4x & 38.03$\pm$2.99 &
    96.54$\pm$1.41
    & 32.30$\pm$2.93 & 92.69$\pm$1.76 &  26.68$\pm$2.55 & 81.09$\pm$5.31\\
& & 8x & 32.05$\pm$2.80 & 92.25$\pm$3.12 & 27.68$\pm$2.80 & 85.12$\pm$4.50 &
24.04$\pm$2.48& 70.60$\pm$6.94 \\
 \cline{2-9}
 & \multirow{2}{*}{FedDist}   & 
    4x & 37.77$\pm$3.07 &
    96.53$\pm$1.59 &32.62$\pm$2.94&
    92.69$\pm$1.69& 26.39$\pm$2.50 & 80.99$\pm$5.26\\
& & 8x &31.35$\pm$2.91 &
91.22$\pm$3.24&28.03$\pm$2.50&
84.44$\pm$4.68&23.99$\pm$2.43&70.13$\pm$6.61\\
 \cline{2-9}
 & \multirow{2}{*}{FedGIMP} & 
4x & - & - & - & - & - & -\\
& & 8x  & - & - & - & - & - & -\\
 \cline{2-9}
 
 & \multirow{2}{*}{FedDDA} & 
 4x & - & - & - & - & - & -\\
& & 8x  & - & - & - & - & - & -\\
 \cline{2-9}
{} & \multirow{2}{*}{FedGAT}   & 
    4x & \textbf{38.89$\pm$2.85}
 & \textbf{97.34$\pm$1.49} & \textbf{33.95$\pm$2.34} & \textbf{93.45$\pm$1.95} & \textbf{27.48$\pm$2.61} & \textbf{81.24$\pm$5.63}\\
& & 8x & \textbf{33.64$\pm$2.67} & \textbf{92.94$\pm$3.00} & \textbf{29.20$\pm$2.28} & \textbf{86.58$\pm$4.23} & \textbf{24.47$\pm$2.55} & \textbf{71.03$\pm$8.77}\\
\hline

\end{tabular}
}
\label{tab:Heterogeneous_multi}
\end{table}



\begin{table}[t]
\centering
\caption{MoDL 3-5-7 Single.}
\resizebox{1.025\columnwidth}{!}
{
\begin{tabular}{| Sc | l l | Sc | Sc | Sc | Sc | Sc | Sc |}
 \hline
\multicolumn{3}{|Sc|}{\textbf{Within-site}} & \multicolumn{2}{Sc|}{Site 1 (BraTS-MoDL-5)} & \multicolumn{2}{Sc|}{Site 2 (fastMRI-MoDL-3)} & \multicolumn{2}{Sc|}{Site 3 (MIDAS-MoDL-7)} \\
 \cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{Reconstruction}} & PSNR $\uparrow$   & SSIM $\uparrow$    & PSNR $\uparrow$   & SSIM $\uparrow$    & PSNR $\uparrow$  & SSIM $\uparrow$   \\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{Non-FL}}}& \multirow{2}{*}{\underline{Single}}     & 4x & 51.80$\pm$2.83 & 99.86$\pm$0.06 & 40.79$\pm$2.94 & 97.09$\pm$1.26 & 36.31$\pm$2.89 & 95.91$\pm$1.71 \\
& & 8x & 44.07$\pm$3.26 & 99.38$\pm$0.33 & 36.30$\pm$2.83 & 95.14$\pm$1.81 & 30.93$\pm$2.81 & 92.45$\pm$3.01 \\
 \cline{2-9}
 & \multirow{2}{*}{Central}     & 4x & 51.30$\pm$2.38 & 99.83$\pm$0.08 & 40.00$\pm$3.12 & 96.76$\pm$1.36 & 36.06$\pm$2.76 & 95.73$\pm$1.73 \\
& & 8x & 44.19$\pm$2.79 & 99.26$\pm$0.36 & 35.02$\pm$3.00 & 94.14$\pm$2.05 & 31.08$\pm$2.80 & 92.47$\pm$2.97 \\
 \cline{1-9}
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}}& \multirow{2}{*}{FedProx}   & 4x & 47.08$\pm$2.88 & 99.63$\pm$0.13 & 39.31$\pm$3.12 & 96.35$\pm$1.55 & 33.31$\pm$2.71 & 94.19$\pm$2.13 \\
& & 8x & 41.53$\pm$3.13 & 98.89$\pm$0.46 & 34.18$\pm$3.13 & 93.49$\pm$2.48 & 29.54$\pm$2.55 & 90.28$\pm$3.28 \\
 \cline{2-9}
 & \multirow{2}{*}{FedDist}   & 4x & 47.02$\pm$2.84 & 99.63$\pm$0.13 & 39.23$\pm$3.27 & 96.37$\pm$1.58 & 33.37$\pm$2.69 & 94.20$\pm$2.12 \\
& & 8x & 41.43$\pm$3.10 & 98.86$\pm$0.47 & 33.97$\pm$3.16 & 93.52$\pm$2.46 & 30.03$\pm$2.53 & 90.52$\pm$3.25 \\
 \cline{2-9}
& \multirow{2}{*}{FedGIMP}   & 4x & 49.70$\pm$2.60 & 99.78$\pm$0.08 & 40.36$\pm$3.09 & 97.00$\pm$1.34 & 36.26$\pm$2.68 & 95.64$\pm$1.74 \\
& & 8x & 43.81$\pm$2.79 & 99.20$\pm$0.40 & 35.55$\pm$3.12 & 94.59$\pm$2.12 & 30.51$\pm$2.76 & 91.93$\pm$3.06 \\
 \cline{2-9}
 & \multirow{2}{*}{FedDDA}   & 4x & 49.10$\pm$2.83 & 99.76$\pm$0.09 & 39.71$\pm$3.03 & 96.90$\pm$1.31 & 35.78$\pm$2.86 & 95.64$\pm$1.76 \\
& & 8x & 43.39$\pm$2.84 & 99.16$\pm$0.38 & 34.68$\pm$3.20 & 94.65$\pm$1.99 & 30.41$\pm$2.81 & 91.85$\pm$3.08 \\
 \cline{2-9}
 & \multirow{2}{*}{FedVAT}   & 4x & \textbf{50.42$\pm$2.44} & \textbf{99.81$\pm$0.08} & {40.01$\pm$3.20} & {96.78$\pm$1.35} & {35.33$\pm$2.90} & {95.57$\pm$1.72} \\
& & 8x & \textbf{43.43$\pm$2.85} & \textbf{99.25$\pm$0.35} & {35.50$\pm$2.91} & {94.54$\pm$2.10} & {30.04$\pm$2.87} & {91.92$\pm$3.10} \\
 \hline
  \hline
 \multicolumn{3}{|Sc|}{\textbf{Within-site}} & \multicolumn{2}{Sc|}{Site 1 (BraTS-MoDL-5)} & \multicolumn{2}{Sc|}{Site 2 (fastMRI-MoDL-3)} & \multicolumn{2}{Sc|}{Site 3 (MIDAS-MoDL-7)} \\
 \cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{Reconstruction}} & PSNR $\uparrow$   & SSIM $\uparrow$    & PSNR $\uparrow$   & SSIM $\uparrow$    & PSNR $\uparrow$  & SSIM $\uparrow$   \\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{Non-FL}}}& \multirow{2}{*}{Single}     & 4x & 34.21$\pm$4.48 & 90.92$\pm$4.36 & 39.25$\pm$6.94 & 95.83$\pm$4.14 & 45.38$\pm$5.04 & 98.28$\pm$1.77 \\
& & 8x & 30.79$\pm$4.08 & 87.83$\pm$5.52 & 34.46$\pm$6.48 & 92.76$\pm$5.57 & 38.99$\pm$4.18 & 97.09$\pm$2.44 \\
 \cline{2-9}
 & \multirow{2}{*}{\underline{Central}}     & 4x & 38.98$\pm$4.55 & 96.36$\pm$1.80 & 40.83$\pm$7.05 & 96.78$\pm$3.19 & 47.23$\pm$5.35 & 98.62$\pm$1.50 \\
& & 8x & 33.82$\pm$4.45 & 93.52$\pm$3.15 & 35.31$\pm$6.20 & 93.43$\pm$5.26 & 41.77$\pm$4.41 & 97.75$\pm$2.03\\
 \cline{1-9}
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}}& \multirow{2}{*}{FedProx}   & 4x & 36.36$\pm$2.96 & 95.21$\pm$1.92 & 39.33$\pm$2.66 & 96.23$\pm$1.74 & 43.44$\pm$3.03 & 98.09$\pm$1.04 \\
& & 8x & 31.94$\pm$2.87 & 92.09$\pm$2.86 & 34.91$\pm$2.80 & 93.72$\pm$2.48 & 37.86$\pm$3.15 & 96.31$\pm$1.75 \\
 \cline{2-9}
 & \multirow{2}{*}{FedDist}   & 4x & 
 36.28$\pm$2.92 & 95.24$\pm$1.87 & 39.55$\pm$2.75& 96.28$\pm$1.79 & 43.43$\pm$3.02 & 98.08$\pm$1.04\\
& & 8x & 31.91$\pm$2.85 & 92.16$\pm$2.81& 34.87$\pm$2.84 & 93.69$\pm$2.53 & 37.58$\pm$3.25 & 96.37$\pm$1.72\\
\cline{2-9}
& \multirow{2}{*}{FedGIMP}   & 4x & 37.63$\pm$4.60 & 95.61$\pm$2.34 & 39.37$\pm$6.64 & 95.52$\pm$4.45 & 44.56$\pm$4.56 & 98.28$\pm$1.91 \\
& & 8x  & 33.02$\pm$4.29 & 92.37$\pm$4.15 & 34.76$\pm$6.43 & 92.88$\pm$5.52 & 39.67$\pm$4.07 & 96.94$\pm$2.78\\
 \cline{2-9}
 & \multirow{2}{*}{FedDDA} & 4x & 37.44$\pm$4.21 & 95.59$\pm$2.36& 39.61$\pm$6.79 & 95.82$\pm$4.04 & 45.93$\pm$5.06& 98.23$\pm$2.17 \\
& & 8x  & 33.02$\pm$4.14 & 92.90$\pm$3.61 & 35.06$\pm$6.15 & 93.07$\pm$5.38 & 39.66$\pm$4.22 & 97.14$\pm$2.62 \\ 
 \cline{2-9}
 & \multirow{2}{*}{FedVAT}   & 4x & 38.07$\pm$4.48 & 96.09$\pm$1.93 & 40.32$\pm$7.04 & 96.33$\pm$3.66 & 46.68$\pm$5.21 &98.48\pm1.65\\
& & 8x  &33.35$\pm$4.23 & 93.16$\pm$3.37 &35.13$\pm$6.94& 93.64$\pm$5.43 & 40.65$\pm$4.37 & 97.42$\pm$2.31 \\

  \hline
\end{tabular}
}
\label{tab:MoDL3_5_7_single}
\end{table}



\begin{table}[t]
\centering
\caption{MoDL 3-5-7 Multicoil.}
\resizebox{1.025\columnwidth}{!}
{
\begin{tabular}{| Sc | l l | Sc | Sc | Sc | Sc | Sc | Sc |}
 \hline
\multicolumn{3}{|Sc|}{\textbf{Within-site}} & \multicolumn{2}{Sc|}{{Site 1 (f.knee-MoDL)}} & \multicolumn{2}{Sc|}{{Site 2 (f.brain-MoDL)}}& \multicolumn{2}{Sc|}{{Site 3 (UMRAM-MoDL)}}\\
\cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{Reconstruction}} & PSNR $\uparrow$   & SSIM $\uparrow$    & PSNR $\uparrow$   & SSIM $\uparrow$    & PSNR $\uparrow$  & SSIM $\uparrow$   \\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{Non-FL}}}& \multirow{2}{*}{\underline{Single}}   & 
    4x & - & - & - & - & - & - \\
& & 8x & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{Central}   & 
    4x & - & - & - & - & - & - \\
& & 8x & - & - & - & - & - & - \\
 \cline{1-9}
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}}& \multirow{2}{*}{FedProx}   & 
    4x & - & - & - & - & - & - \\
& & 8x & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{FedDist}   & 
    4x & - & - & - & - & - & - \\
& & 8x & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{FedGIMP} & 
4x & - & - & - & - & - & - \\
& & 8x  & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{FedDDPM} & 
 4x & - & - & - & - & - & - \\
& & 8x  & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{FedVAT} & 
 4x & - & - & - & - & - & - \\
& & 8x  & - & - & - & - & - & - \\
 \hline
 \hline
\multicolumn{3}{|Sc|}{\textbf{Within-site}} & \multicolumn{2}{Sc|}{{Site 1 (f.knee-MoDL)}} & \multicolumn{2}{Sc|}{{Site 2 (f.brain-MoDL)}}& \multicolumn{2}{Sc|}{{Site 3 (UMRAM-MoDL)}}\\
\cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{Reconstruction}} & PSNR $\uparrow$   & SSIM $\uparrow$    & PSNR $\uparrow$   & SSIM $\uparrow$    & PSNR $\uparrow$  & SSIM $\uparrow$   \\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{Non-FL}}}& \multirow{2}{*}{Single}     & 
4x & - & - & - & - & - & - \\
& & 8x & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{\underline{Central}}     & 
4x & - & - & - & - & - & - \\
& & 8x & - & - & - & - & - & - \\
 \cline{1-9}
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}}& \multirow{2}{*}{FedProx}   & 
    4x & - & - & - & - & - & - \\
& & 8x & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{FedDist}   & 
    4x & - & - & - & - & - & - \\
& & 8x & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{FedGIMP} & 
4x & - & - & - & - & - & - \\
& & 8x  & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{FedDDPM} & 
 4x & - & - & - & - & - & - \\
& & 8x  & - & - & - & - & - & - \\
 \cline{2-9}
 & \multirow{2}{*}{FedVAT} & 
 4x & - & - & - & - & - & - \\
& & 8x  & - & - & - & - & - & - \\
 \hline
\end{tabular}
}
\label{tab:MoDL3_5_7_multicoil}
\end{table}


\section{Results}

\subsection{Comparison Studies}
To demonstrate the utility of FedGAT for sustaining flexible collaborations to build MRI reconstruction models, we considered a three-site FL setup under model-heterogeneous settings, where each site used a different network architecture as the basis of its reconstruction model. FedGAT was compared against several state-of-the-art baselines including distillation-based methods (FedProx, FedDist), and synthetic-data methods (FedGIMP, FedDDA). Note that conventional FedAvg is not applicable in model-heterogeneous settings. On one hand, site-specific performance was evaluated by conducting within-site reconstructions, where the eventual reconstruction model available at a given site was deployed on the same site (i.e., model for Site $k$ tested on data from Site $k$). Single models trained locally at each site were considered as a performance benchmark for within-site reconstructions. On the other hand, generalization performance was evaluated by conducting across-site reconstructions, where the eventual reconstruction model available at a given site was deployed on remaining sites (i.e., model for Site $k$ tested on data from Site $l$ where $k \neq l$). Central models trained on the server using data aggregated across all sites were taken as a privacy-violating performance benchmark for across-site reconstruction.

Performance metrics for an FL setup based on single-coil MRI data are listed in Table \ref{tab:Heterogeneous_single}. In within-site reconstructions, FedGAT performs competitively with the single-site benchmark, while outperforming the centralized benchmark. Meanwhile, FedGAT achieves significantly higher performance than all FL baselines (p$<$0.05). On average, FedGAT offers improvements of \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedProx, \( 1.49 \, \text{dB} \) PSNR and \( 5.48\% \) SSIM over FedDist, \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedGIMP, and \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedDDA. In across-site reconstructions, FedGAT performs competitively with the centralized benchmark while outperforming the single-site benchmark. Meanwhile, FedGAT achieves significantly higher performance than all FL baselines (p$<$0.05). On average, FedGAT offers improvements of \( 1.74 \, \text{dB} \) PSNR and \( 3.54\% \) SSIM over FedProx, \( 1.41 \, \text{dB} \) PSNR and \( 4.84\% \) SSIM over FedDist, \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedGIMP, and \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedDDA. 

Performance metrics for an FL setup based on multi-coil MRI data are listed in Table \ref{tab:Heterogeneous_multi}. In within-site reconstructions, FedGAT performs competitively with the single-site benchmark, while outperforming the centralized benchmark. Meanwhile, FedGAT achieves significantly higher performance than all FL baselines (p$<$0.05). On average, FedGAT offers improvements of \( 1.00 \, \text{dB} \) PSNR and \( 0.80\% \) SSIM over FedProx, \( 1.14 \, \text{dB} \) PSNR and \( 0.81\% \) SSIM over FedDist, \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedGIMP, and \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedDDA. In across-site reconstructions, FedGAT performs competitively with the centralized benchmark while outperforming the single-site benchmark. Meanwhile, FedGAT achieves significantly higher performance than all FL baselines (p$<$0.05). On average, FedGAT offers improvements of \( 1.10\, \text{dB} \) PSNR and \( 0.57\% \) SSIM over FedProx, \( 1.18 \, \text{dB} \) PSNR and \( 0.61\% \) SSIM over FedDist, \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedGIMP, and \( 2.48 \, \text{dB} \) PSNR and \( 5.87\% \) SSIM over FedDDA.

Representative images reconstructed via the FL baselines in model-heterogeneous FL setups are depicted in Fig. \ref{fig:visualres}. Corroborating the quantitative assessments, FedGAT attains higher image quality compared to baselines, with sharper depiction of structural details, lower artifact and noise. Meanwhile, XX, YY shows blur, noise amplification, loss of detailed tissue structure etc. 


%Within-site 
%Single  -0.73 dB,   -0.84,
%FedProx        1.00 dB,    0.80, 
%FedDist     1.14 dB,      0.81,

%Across-site 
%Single  1.67 dB,     0.75,
%FedProx      1.10 dB,      0.57, 
%FedDist   1.18 dB,    0.61, 




\begin{figure*}[t]
\centering
\includegraphics[width=0.875\textwidth]{figures/figure4.png}
\captionsetup{justification=justified, width=\textwidth}
\caption{Representative reconstructions at R=8x from zero-filled Fourier method (Zero-filled), single-site models (Single), FL baselines (FedProx, FedDist, FedGIMP, FedDDA), and FedGAT, along with reference images. \textbf{(a)} Local BraTS model tested on fastMRI, (b) Local fastMRI model tested on MIDAS. Zoom-in windows are included to emphasize method differences.}
\label{fig:visualres}
\vspace{-0.1cm}
\end{figure*}


\subsection{Ablation Studies}
The primary aim of the current study is to enable collaborative training of generalizable reconstruction models with heterogeneous architectures across imaging sites. Towards this aim, FedGAT leverages a generative image prior to synthesize multi-site MRI data, and these synthetic data serve as a privacy-preserving means to transfer knowledge across sites. To assess the efficacy of this transfer approach, FedGAT was compared against a central benchmark where knowledge transfer is attained via actual data aggregation, and conventional FL where knowledge transfer is attained via model aggregation. These comparisons were performed in model-homogeneous settings to permit use of conventional FL, and to avoid unwanted interactions between model architecture and data distribution across sites. Performance metrics on single-coil MRI data are listed in Table \ref{tab:cen_fedvat_compare}. On average across tasks, we find that FedGAT offers improvements of 0.6dB PSNR, 0.2\% SSIM over Central, and XXdB PSNR, YY\% SSIM over FedAvg. These results indicate that the synthetic data approach in FedGAT offers generally competitive performance to knowledge transfer via sharing of actual data or model weights among sites. 

Next, we examined the importance of building a generative image prior via a autoregressive transformer model. To do this, FedGAT was compared against variants models that built priors based via adversarial (GAN) and diffusion models (DDPM). Fidelity of synthetic MR images generated by FedGAT and variants were assessed via FID as shown in Fig. \ref{fig:FID}a. Sample synthetic images are displayed in Fig. \ref{fig:compare_synth}. We find that FedGAT achieves the highest image fidelity, as manifested by its consistently lower FID scores than variants, and by its improved visual realism apparent in sample images. While GAN shows structural artifacts and suboptimal contrast and DDPM occasionally shows elevated noise levels, GAT achieves high image quality with lower artifacts and noise. We then assessed whether this improvement in synthetic image fidelity translates onto benefits in reconstruction performance. For this purpose, performance of reconstruction models trained on synthetic images from FedGAT and variants were compared as listed in Fig. \ref{fig:FID}b. We find that FedFAT yields notable higher performance than both GAN and DDPM variants. 



\begin{table}[t]
\centering
\caption{A model-homogeneous FL setting on single-coil data, where all sites adopted MoDL as the type of reconstruction model.}
\resizebox{1.025\columnwidth}{!}{
\begin{tabular}{| Sc | l l | Sc | Sc | Sc | Sc | Sc | Sc |}
 \hline
\multicolumn{3}{|Sc|}{\textbf{Within-site}} & \multicolumn{2}{Sc|}{Site 1 (BraTS)} & \multicolumn{2}{Sc|}{Site 2 (fastMRI)}& \multicolumn{2}{Sc|}{Site 3 (MIDAS)}\\
 \cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{reconstruction}} &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$   \\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{non-FL}}} & \multirow{2}{*}{\underline{Single}}   & 4x & \textbf{48.06$\pm$3.33} & \textbf{99.72$\pm$0.11} & \textbf{40.75$\pm$2.88} & \textbf{97.11$\pm$1.23} & \textbf{34.16$\pm$2.75} & \textbf{94.06$\pm$2.03} \\
& & 8x & \textbf{42.46$\pm$3.15} & \textbf{99.03$\pm$0.45} & \textbf{36.37$\pm$2.79} & \textbf{95.19$\pm$1.83} & \textbf{29.67$\pm$2.53} & \textbf{88.88$\pm$3.35} \\
 \cline{2-9}
 & \multirow{2}{*}{Central}   & 4x & 46.12$\pm$2.55 & 99.46$\pm$0.20 & 39.22$\pm$3.14 & 96.38$\pm$1.51 & \textbf{33.75$\pm$2.62} & 93.18$\pm$2.24 \\
& &8x & \textbf{42.16$\pm$2.72} & \textbf{98.65$\pm$0.58} & \textbf{35.75$\pm$3.07} & \textbf{94.84$\pm$1.94} & \textbf{29.83$\pm$2.53} & \textbf{89.47$\pm$3.16} \\
 \cline{1-9}
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}} & \multirow{2}{*}{FedAvg}  & 4x & 46.65$\pm$2.86 & 99.58$\pm$0.14 & 38.52$\pm$3.62 & 95.50$\pm$2.32 & 33.14$\pm$2.52 & 92.80$\pm$2.75 \\
& & 8x & 40.80$\pm$3.12 & 97.96$\pm$0.82 & 32.94$\pm$3.52 & 91.83$\pm$3.59 & 28.77$\pm$2.23 & 87.85$\pm$3.43 \\
 \cline{2-9}
& \multirow{2}{*}{FedGAT}   &4x &47.63$\pm$2.65&99.64$\pm$0.14&39.73$\pm$3.31& 96.46$\pm$1.56& 33.59$\pm$2.63 &93.53$\pm$2.10 \\
& & 8x &41.60$\pm$2.85&98.78$\pm$0.54& 34.58$\pm$3.36&94.14$\pm$2.33& 28.85$\pm$2.62 & 87.75$\pm$3.34\\
 \hline \hline
\multicolumn{3}{|Sc|}{\textbf{Across-site}} & \multicolumn{2}{Sc|}{Site 1 (BraTS)} & \multicolumn{2}{Sc|}{Site 2 (fastMRI)}& \multicolumn{2}{Sc|}{Site 3 (MIDAS)}\\
 \cline{4-9}
\multicolumn{3}{|Sc|}{\textbf{reconstruction}} &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$   \\
 \hline
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{non-FL}}}  & \multirow{2}{*}{Single}   & 4x & 34.45$\pm$3.57 &  91.44$\pm$4.05 &39.03$\pm$2.72& 95.85$\pm$1.90& 42.27$\pm$2.90 & 97.56$\pm$1.33 \\
& & 8x & 30.48$\pm$3.20 & 85.48$\pm$5.37& 34.79$\pm$2.63 & 92.94$\pm$2.57 & 36.74$\pm$2.93 & 94.91$\pm$2.07 \\
 \cline{2-9}
 & \multirow{2}{*}{\underline{Central}}   & 
4x & 36.48$\pm$2.89 & 94.78$\pm$1.91 & 39.94$\pm$2.59 & 96.32$\pm$1.59 & 42.67$\pm$2.86 & 97.92$\pm$1.08 \\
& & 
8x & \textbf{32.79$\pm$2.81} & \textbf{92.16$\pm$2.62} & \textbf{35.99$\pm$2.63} & \textbf{94.06$\pm$2.27} & \textbf{38.95$\pm$2.90} & \textbf{96.75$\pm$1.43} \\
 \cline{1-9}
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{FL methods}}} & \multirow{2}{*}{FedAvg} & 4x & 35.83$\pm$3.12 & 94.15$\pm$2.54 & 39.89$\pm$2.70 & 96.19$\pm$1.95 & 42.59$\pm$3.26 & 97.54$\pm$1.64 \\
& & 8x & 30.85$\pm$2.95 & 89.84$\pm$3.51 & 34.78$\pm$2.71 & 92.91$\pm$2.49 & 36.87$\pm$3.33 & 94.89$\pm$2.60 \\
 \cline{2-9}
{} & \multirow{2}{*}{FedGAT}   & 4x & \textbf{36.71$\pm$3.01} & \textbf{95.02$\pm$1.96} & \textbf{40.28$\pm$2.65} & \textbf{96.39$\pm$1.81} & \textbf{43.52$\pm$2.83} & \textbf{98.06$\pm$1.04} \\
& & 8x & \textbf{32.02$\pm$2.95} & \textbf{91.53$\pm$3.07} & \textbf{35.52$\pm$2.84} & \textbf{93.68$\pm$2.55} & \textbf{37.98$\pm$2.97} & \textbf{95.65$\pm$1.94} \\
\hline
\end{tabular}
}
\label{tab:Homogeneous}
\end{table}



\section{Discussion}
Here we introduced a model-agnostic FL technique for MRI reconstruction that supports model-heterogeneous settings by decoupling cross-site knowledge transfer from building of reconstruction models. In particular, FedGAT mediates knowledge transfer among sites by sharing a global GAT prior that uses autoregressive predictions across multiple spatial scales to generate synthetic MR images, and a site prompt for precise control over the data distribution. Previous FL studies aiming to build generative priors have predominantly adopted adversarial approaches that can suffer from poor image quality due to training instabilities \cite{rgan,Mardani2019b,ozbey2022unsupervised}, or diffusion approaches that can suffer from extensive inference times and residual image noise \cite{jalaln2021nips,korkmaz2023selfsupervised,chung2022media,gungor2023adaptive}. In comparison, the autoregressive nature of GAT offers improved image fidelity over adversarial and diffusion priors as indicated by our results. To curate a hybrid multi-site dataset, the shared GAT prior is employed at each site to efficiently generate high-fidelity synthetic MRI data from remaining sites. Afterwards, site-specific reconstruction models are locally trained on this hybrid dataset to improve generalization while enjoying total freedom in architecture selection. Therefore, the proposed method holds great promise for advancing the practicality and scalability of FL in multi-institutional MRI studies.



\begin{figure}[t] % Single-column figure for one side
\centering
\includegraphics[width=\columnwidth]{figures/figure5.png} % Adjust width as necessary for column size
\caption{\textbf{(a)} Fidelity of synthetic MR images generated via GAN, DDPM and GAT priors. Bar plots of Frechet inception distance (FID) show mean\(\pm\)std across the test set. \textbf{(b)} On average across sites, PSNR/SSIM of reconstruction models trained on synthetic images listed as mean$\pm$std across the test set. \color{blue}model-homogeneous MoDL-3}\color{black}
\label{fig:FID}
\end{figure}

\begin{figure}[t] % Single-column figure for one side
\centering
\includegraphics[width=0.9\columnwidth]{figures/figure6.png} % Adjust width as necessary for column size
\caption{Samples of synthetic MR images from GAN, DDPM and GAT priors, along with samples of local MR images at separate sites.}
\label{fig:compare_synth}
\end{figure}

The distribution of MRI data collected in separate sites inevitably reflects the variations in imaging protocols or scanners across sites \cite{li2021fedbn}. When straightforward averaging of model weights is used for aggregation, this distributional variability can compromise the sensitivity of the global model to site-specific image attributes in the conventional FL framework. Recent FL methods on MRI reconstruction have aimed at addressing this limitation via personalization strategies such as latent-space alignment \cite{guo2021}, partial network aggregation \cite{feng2023tmi}, test-time adaptation \cite{elmas2022federated}, or feature map normalization \cite{dalmaz2024one}. While these strategies allow a modest degree of model attuning to individual sites, a substantial portion of the global model must still be shared across sites to ensure adequate knowledge transfer. In contrast to existing FL methods that share reconstruction model weights, FedGAT transfers knowledge among sites by building a global generative prior that can later generate synthetic MRI data from desired sites. This stark difference enables FedGAT to operate seamlessly under demanding model-heterogeneous settings, where no component of reconstruction models are shared among sites. In turn, FedGAT can sustain a higher-degree of site specialization in reconstruction models than permitted by previous approaches. 

Devised to accurately capture an underlying data distribution, generative priors synthesize MR images depicting random anatomical structures that do not correspond to the precise anatomy of any actual subject \cite{jalaln2021nips,fdb}. In FedGAT, such synthetic MR images from separate sites are employed in training of site-specific reconstruction models to improve generalizability across sites. Our assessments based on FID scores indicate that the synthetic MR images generated by the GAT prior attain a level of quality and realism closely mimicking actual MR images. Furthermore, reconstruction models trained on these synthetic MR images yield high performance when independently evaluated on actual MRI acquisitions in the test sets. Still, in the absence of anatomical guidance, the stochastic nature of generative priors naturally induce a degree of susceptibility to artificial features in synthetic MR images \cite{SelfRDB}. Our observations indicate that the downstream reconstruction models trained on synthetic MR images in this study are no unduly influenced by undesirable hallucinations. When needed, hallucination might be alleviated by building reconstruction models equipped with physics-driven modules and learning objectives \cite{Knoll2019inverseGANs}, or building generative priors via architectures that offer enhanced capture of contextual relationships among tissue signals \cite{I2IMamba,denomamba}. It remains important future work to validate the proposed method and its anatomical fidelity on broader patient cohorts.

FL frameworks help mitigate patient privacy risks by exchanging model weights rather than actual MRI data across sites. Regardless, security concerns can still be present in the presence of adversaries that attempt to corrupt model updates, hence compromising the accuracy of reconstruction images \cite{kaissis2020secure}. In addition, third-party inference attacks on trained reconstruction models might be able to leak sensitive information regarding the training MRI data from model weights  \cite{kaissis2020secure}. These concerns might be alleviated by incorporating differential privacy objectives in training of generative priors \cite{FengICCV2021,FedDPGAN}. Future research is warranted to systematically evaluate the privacy-preserving capabilities of FedGAT.


\section{Conclusion}
Here, we introduced a novel federated learning technique that enables multiple sites with distinct architectural preferences to collaborate in building MRI reconstruction models. To support model-heterogeneous settings, FedGAT decouples a first tier to learn a global generative prior that captures the distribution of multi-site MRI data, from a second tier to build site-specific albeit generalizable reconstruction models by using synthetic data generative via the global prior. Our experiments clearly demonstrate that FedGAT achieves superior performance compared to state-of-the-art FL baselines in both within-site and across-site reconstructions. These findings indicate that FedGAT promotes effective knowledge transfer across sites while remaining agnostic to architectures of reconstruction models, hence overcoming a critical barrier in supporting flexible collaborations.  


\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,Papersv0}


\end{document}
