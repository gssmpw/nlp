\documentclass[journal,twoside,web]{ieeecolor}
\usepackage{tmi}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{float}
\usepackage{adjustbox}
\usepackage{caption}
\usepackage{stfloats}
\usepackage[dvipsnames]{xcolor}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{longtable}
\usepackage{multirow}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\setlength{\floatsep}{1ex}
\setlength{\dblfloatsep}{1ex}
\setlength{\textfloatsep}{1ex}
\setlength{\dbltextfloatsep}{1ex}
\setlength{\intextsep}{1ex}
\def\baselinestretch{1.0}
\setlength{\textheight}{1.000\textheight}
\setlength{\headsep}{2ex}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\setlength{\abovedisplayshortskip}{3pt}
\setlength{\belowdisplayshortskip}{3pt}
\setlength{\parskip}{0mm plus1mm minus0mm}
\setlength\tabcolsep{3 pt}
\renewcommand{\arraystretch}{1.25}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={FedGIMP},
}



%%%%%
%%% Coloring the comment as blue
%\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
%\SetCommentSty{mycommfont}



\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output
%%%%%
\usepackage[font=small,justification=justified,belowskip=2pt,aboveskip=2pt]{caption}
\setlength{\skip\footins}{3pt}

\usepackage[math]{cellspace}
\cellspacetoplimit 2pt
\cellspacebottomlimit 1pt


\floatname{algorithm}{Algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\def\SPSB#1#2{\rlap{\textsuperscript{{#1}}}\SB{#2}}
\def\SP#1{\textsuperscript{#1}}
\def\SB#1{\textsubscript{#1}}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\markboth{}{Federated Learning of Generative Image Priors}
\begin{document}
\title{Federated Learning of Generative Image Priors for MRI Reconstruction}
\author{Gokberk Elmas, Salman UH Dar, Yilmaz Korkmaz, Emir Ceyani, Burak Susam, Muzaffer Ozbey, \\  Salman Avestimehr, \IEEEmembership{Fellow}  and Tolga \c{C}ukur$^*$, \IEEEmembership{Senior Member} 
\\
\thanks{\\
This study was supported in part by a TUBA GEBIP 2015 fellowship, and a BAGEP 2017 fellowship (Corresponding author: Tolga Çukur).}
\thanks{G. Elmas, S. UH. Dar, Y. Korkmaz, M. Ozbey, B. Susam and T. Çukur are with the Department of Electrical and Electronics Engineering, and the National Magnetic Resonance Research Center, Bilkent University, Ankara, Turkey (e-mail: \{gokberk@ee, salman@ee, korkmaz@ee, muzaffer@ee, burak.susam@ug, cukur@ee\}.bilkent.edu.tr).}
\thanks{E. Ceyani and S. Avestimehr are with the Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA 90089 USA (e-mail: \{ceyani@, avestime@\}usc.edu).}
}

\maketitle


\begin{abstract}
Multi-institutional efforts can facilitate training of deep MRI reconstruction models, albeit privacy risks arise during cross-site sharing of imaging data. Federated learning (FL) has recently been introduced to address privacy concerns by enabling distributed training without transfer of imaging data. Existing FL methods employ conditional reconstruction models to map from undersampled to fully-sampled acquisitions via explicit knowledge of the accelerated imaging operator. Since conditional models generalize poorly across different acceleration rates or sampling densities, imaging operators must be fixed between training and testing, and they are typically matched across sites. To improve patient privacy, performance and flexibility in multi-site collaborations, here we introduce Federated learning of Generative IMage Priors (FedGIMP) for MRI reconstruction. FedGIMP leverages a two-stage approach: cross-site learning of a generative MRI prior, and prior adaptation following injection of the imaging operator. The global MRI prior is learned via an unconditional adversarial model that synthesizes high-quality MR images based on latent variables. A novel mapper subnetwork produces site-specific latents to maintain specificity in the prior. During inference, the prior is first combined with subject-specific imaging operators to enable reconstruction, and it is then adapted to individual cross-sections by minimizing a data-consistency loss. Comprehensive experiments on multi-institutional datasets clearly demonstrate enhanced performance of FedGIMP against both centralized and FL methods based on conditional models.

\end{abstract}

\begin{IEEEkeywords}
MRI, accelerated, reconstruction, generative, prior, federated learning, distributed, collaborative. 
\end{IEEEkeywords}


\bstctlcite{IEEEexample:BSTcontrol}

\section{Introduction}
\IEEEPARstart{M}{agnetic} Resonance Imaging (MRI) is a principal radiological modality owing to its non-invasiveness and exceptional soft-tissue contrast. Yet, an inevitable consequence of its low signal-to-noise ratio (SNR) efficiency is prolonged exams that hinder clinical use. Accelerated MRI methods based on undersampled acquisitions improve efficiency by recovering missing data via reconstruction algorithms that incorporate additional prior information \cite{Lustig2007,Zhao2015}. Deep learning models have been adopted for MRI reconstruction, given their strong ability to capture data-driven priors for inverse problems \cite{Wang2016,Hammernik2017,Kwon2017,Dar2017,Han2018a,ADMM-CSNET,raki,Xiang2019,wang2022}. Deep reconstruction models are typically trained to perform a conditional mapping from undersampled acquisitions to images that are consistent with respective fully-sampled acquisitions \cite{Schlemper2017,MoDl,Quan2018c,KikiNet,Mardani2019b,Polakjointvvn2020,rgan,FengNNLS2021,PatelRecon}. Since these models typically show poor generalization to features scarcely present in the training set, learning of generalizable models involves training on a large and diverse collection of MRI data \cite{LiangSPM}. Unfortunately, economic and labor costs along with patient privacy concerns can prohibit compilation of comprehensive datasets centralized at a single institution \cite{Kaissis2020}.

Aiming at this limitation, federated learning (FL) is a promising framework that facilitates multi-institutional collaborations via decentralized training of learning-based models \cite{WenqiLi2019,Sheller2019,Rieke2020,Roth2020,Li2020,Liu2021}. An FL server periodically collects locally-trained models from individual sites in order to obtain a shared global model across sites \cite{McMahan2017CommunicationEfficientLO,fl_opt_guide}. Following aggregation of local models, the global model is then broadcast back onto individual sites for continual training. This decentralized procedure allows a multi-site model to be collaboratively trained without sharing of local data, thereby mitigating privacy concerns \cite{Li2020FederatedLC}. A multi-site model can improve generalization over single-site models given the native diversity in multi-institutional data, which can substantially benefit sites with relatively limited or uniform training data. However, this comes at the potential expense of lower site-specific performance due to data heterogeneity across sites, lowering sensitivity to site-specific image features particularly for non-adaptive architectures that are vulnerable to domain shifts \cite{Knoll2019inverseGANs,Li2020}.

Characteristics of acquired data are governed by two extrinsic factors in the context of accelerated MRI. At primary level, the spatial distribution of tissue magnetization (i.e., the MR image distribution) is determined by the pulse sequence and the scanner \cite{LiangSPM}. At secondary level, the MR image distribution is further modulated by the accelerated imaging operator, which captures the influences of undersampling in k-space and reception by coil arrays \cite{fastmri}. As such, multi-site MRI data can show substantial heterogeneity in the MR image distribution (e.g., due to different sequences, scanners) or the imaging operator (e.g., due to different acceleration rates, sampling densities). In turn, multi-site models can suffer from performance losses under significant domain shifts across sites, or across the training and test sets \cite{KnollGeneralization,Liu2021}. 

Few recent studies on FL-based MRI reconstruction have considered domain shifts across sites. In \cite{guo2021}, adversarial alignment between source and target sites was proposed to improve similarity of latent-space representations in reconstruction models. In \cite{feng2021}, reconstruction models were split into a global encoder shared across sites, followed by local decoders trained separately at each site. Despite improved performance against across-site variability, both methods are based on conditional models that assume explicit knowledge of the imaging operator. Conditional models generalize poorly under changes to the imaging operator \cite{Zhu2018,Biswas2019}. In turn, matching acceleration rates and sampling densities must be prescribed between the training and test sets, and similar prescriptions are often utilized among sites \cite{guo2021}. This requirement can restrict flexibility in multi-institutional collaborations and necessitate model retraining under significant changes to the desired imaging operator \cite{KnollGeneralization}. 

Here, we introduce a novel FL method for MRI reconstruction, FedGIMP, to enhance patient privacy, performance and flexibility in multi-site collaborations. Unlike previous FL methods, we propose a two-stage reconstruction approach: cross-site training of a generative MRI prior that captures the MR image distribution (Fig. \ref{fig:fedgimp_main}), and prior adaptation following injection of the subject-specific imaging operator (Fig. \ref{fig:fedgimp_opt}). To improve generalization, we train a global MRI prior operationalized as an unconditional adversarial model that synthesizes high-quality MR images. Training images are derived from coil-combined, fully-sampled acquisitions to decouple the influence of the imaging operator from the prior. The statistics of feature maps across the synthesizer are controlled by latent variables produced by a mapper. To improve specificity, we propose a novel mapper that produces site-specific latents given a site index. During inference, the global MRI prior is combined with subject-specific imaging operators that can vary flexibly across sites and between the training and test sets. Reconstruction is then performed by adapting the MRI prior to enforce consistency between synthesized and acquired k-space data. This adaptation further boosts site specificity by increasing conformity of the multi-site model to the distribution of test data. Code for FedGIMP can be found at: {\small \url{https://github.com/icon-lab/FedGIMP}}. 

\vspace{0.5cm}
\subsubsection*{\textbf{Contributions}}
\begin{itemize}
    \item We introduce a novel FL method for MRI reconstruction that decentrally trains a generative MRI prior decoupled from the imaging operator to improve patient privacy and flexibility in multi-site collaborations.
    
    \item We operationalize the prior as an unconditional adversarial model with a cross-site-shared generator to capture site-general representations, albeit with site-specific latents to maintain specificity in synthesized MR images.
    
    \item We leverage prior adaptation to enhance specificity of the multi-site model and improve reliability against domain shifts across sites and across training and test sets.
\end{itemize}
 
 
\begin{figure*}[t]

\centering
\includegraphics[width=0.875\textwidth]{figure01.png}
\captionsetup{justification=justified, width=\linewidth}
\caption{FedGIMP performs federated learning of a generative image prior for MRI reconstruction. The prior is embodied as an unconditional adversarial model that synthesizes high-quality MR images given site-specific latent variables. Cross-site-shared generators of parameters $\theta_G$ are used along with site-specific discriminators of parameters $\theta_{D}^{1,..,K}$. In each communication round, sites perform local updates to $\theta_G$ to minimize a synthesis loss, and the server then aggregates updated models.
\vspace{-0.1cm}}
\label{fig:fedgimp_main}
\end{figure*}


\section{Related Work}

Deep MRI reconstruction is pervasively based on conditional models that directly map undersampled acquisitions to images consistent with fully-sampled acquisitions \cite{Hammernik2017}. These models are trained on large sets of paired input-output data under a specific accelerated imaging operator. Heavy data demand limits applicability since curating large datasets at a single site is challenging \cite{data_diff,GuoTMI2021}. To facilitate curation, unpaired \cite{Quan2018c,oh2020,lei2020}, self-supervised \cite{yaman2020,Huang2019self,Tamir2019,hu2021,FengLiu2021,wang2022b}, or transfer \cite{Dar2017,KnollGeneralization} learning strategies were proposed. However, these methods require centralized training following cross-site data transfer that raises patient privacy concerns \cite{Kaissis2020}. 

FL is a decentralized framework for multi-institutional collaborations that communicates model parameters instead of raw data \cite{Li2020FederatedLC}. FL distributes costs related to the formation and processing of datasets across sites, while mitigating concerns regarding the data privacy \cite{Kaissis2020}. FL methods have readily been demonstrated on imaging tasks such as segmentation and classification \cite{Sheller2019,WenqiLi2019,Roth2020}. A major consideration is the reliability against domain shifts in multi-site imaging data, collected with varying imaging protocols and scanners. Data harmonization was proposed to remove site-specific variations while emphasizing shared variability across sites \cite{karayumak2019,dewey2019,li2021fedbn}. Although harmonization can improve population-level analysis, it can discard patient-level information of diagnostic value. Episodic learning in frequency space was proposed to improve generalization to unseen test domains for segmentation \cite{Liu2021}. Adversarial alignment and network splitting methods were also proposed for classification \cite{Li2020,VAFL,park2021}. While promising results were reported, it is nontrivial to directly adopt image analysis models for MRI reconstruction that requires image formation from raw data.

Domain shifts in MRI reconstruction involve heterogeneity in the MR image distribution and in the imaging operator, which can elicit performance losses when heterogeneity is prominent across sites, or across the training-test sets \cite{KnollGeneralization}. Few recent FL studies on single-coil MRI reconstruction have considered domain shifts across sites. In \cite{guo2021}, cross-site-shared latent-space representations were obtained by adversarially aligning all sites to the targeted test site in each communication round. In \cite{feng2021}, a split reconstruction model with a global encoder and unshared decoder was used to maintain site-specific and site-general representations. While demonstrating remarkable results, these recent methods are based on conditional models that are explicitly informed on the imaging operator. This can limit reconstruction performance and necessitate model retraining under notable domain shifts in the imaging operator \cite{Zhu2018,Biswas2019}. As such, previous studies have prescribed matching acceleration rates and sampling densities between the training-test sets, and usually across sites. 

Here, we propose an FL method that learns a generative MRI prior, and reconstructs images via prior adaptation after combination with the subject-specific imaging operator. Separation of the MRI prior from the imaging operator has recently been considered for centralized reconstruction models trained on single-site data \cite{Konukoglu2019,Knoll2019inverseGANs,korkmaz2021unsupervised}, yet it has not been studied in the context of FL. To our knowledge, FedGIMP is the first FL method that decouples the MRI prior from the imaging operator to train decentralized reconstruction models on multi-site datasets, and the first FL method that reconstructs multi-coil MRI data. Furthermore, FedGIMP includes several unique design elements compared to previous centralized methods. In \cite{Konukoglu2019}, a non-adaptive MRI prior was proposed that was kept static during inference. In \cite{Knoll2019inverseGANs}, an adaptive MRI prior was proposed that did not include latents, so no latent optimization was performed during inference. In \cite{korkmaz2021unsupervised}, an adaptive MRI prior was proposed that included mapper-produced latents albeit no site index, and the mapper was removed from the prior to directly optimize latents during inference. Unlike previous methods, FedGIMP introduces a novel site-index in its adaptive MRI prior to maintain site specificity, and it updates the mapper to indirectly optimize latents. These unique aspects enable FedGIMP to offer improved performance for MRI reconstruction on heterogeneous datasets.



\section{Theory}

\subsection{Federated Learning of Conditional MRI Models}

Accelerated MRI entails reconstruction of an underlying MR image $m$ from undersampled k-space acquisitions $y$:
\begin{equation}
\label{eq:sampling}
A m = y,
\end{equation}
where $A$ is the imaging operator that includes the effects of coil sensitivities and partial Fourier transformation on acquired k-space. As Eq. \ref{eq:sampling} is underdetermined, additional prior information is incorporated to regularize the reconstruction:
\begin{equation}
\label{eq:regularized_recon}
\widehat{m}=\underset{m}{\operatorname{argmin}}\|y-A m \|_{2}^{2} + H(m),
\end{equation}
where $H(m)$ enforces the prior \cite{Lustig2007}. Deep models have recently become the predominant method for solving Eq. \ref{eq:regularized_recon} by training of data-driven priors on diverse datasets \cite{Hammernik2017}. 

In FL, training is performed via communication between multiple sites and a server \cite{Li2020FederatedLC}. The server retains a global model ($C_{\theta}$ with parameters $\theta$), whereas each site retains a local model of matching architecture ($C_{\theta}^k$ for site $k$, where $k \in \{1,..,K\}$). In each communication round, local models are initialized with the global model broadcast from the server, $\theta_C^k \gets \theta_C$, and updated to minimize a local reconstruction loss:
\begin{equation}
\label{eq:fed_dnn_training}
\mathcal{L}^{k}_{Rec}(\mathcal{D}^k,A^k_{tr};\theta^k)= \mathbb{E}_{(m^{k}_{tr},y^{k}_{tr})} \left[\|m^{k}_{tr} - C_{\theta^k}(A^{\dagger k}_{tr}y^{k}_{tr}) \|_{2} \right],
\end{equation}
where $\mathbb{E}$ denotes expectation, $\mathcal{D}^k$ are local training data comprising undersampled acquisitions ($y^k_{tr}$) and reference images obtained from fully-sampled acquisitions ($m^k_{tr}$), and $A^k_{tr}$, $A^{\dagger k}_{tr}$ are the imaging operator and its adjoint. $C$ is a conditional model with parameters $\theta^k$ that receives zero-filled Fourier reconstruction of $y^k_{tr}$. At the end of each round, updated local models are aggregated via federated averaging (FedAvg) \cite{McMahan2017CommunicationEfficientLO}:
\begin{equation}
\label{eq:fed_avg}
\theta =  \sum_{k=1}^{K} \alpha^k \theta^k,
\end{equation}
where $\alpha^k$ denotes the relative site weights. 

The trained global model ($C_{\theta^*}$) is then used for inference:
\begin{equation}
\label{eq:fed_ref}
\hat{m}_{k,s} =  C_{\theta^*}(A_{test}^{\dagger k}y^{k,s}_{test}),
\end{equation}
where $\hat{m}_{k,s}$ is the reconstruction and $y^{k,s}_{test}$ is the undersampled acquisition for the $s^{th}$ subject at the $k^{th}$ site, and $A_{test}^{\dagger k}$ is the adjoint imaging operator at site $k$. Since conditional models generalize poorly against heterogeneity in the imaging operator, $A_{tr}^k$ and $A_{test}^k$ are typically matched across training-test sets (i.e. across training and test subjects), and across sites. 


\begin{figure}[t]
\centering
\includegraphics[width=0.825\columnwidth]{figure02.png}
\captionsetup{justification=justified, width=\columnwidth}
\caption{FedGIMP's MRI prior is embodied as a generator that synthesizes a high-quality, coil-combined MR image ($\hat{m}$). To perform reconstruction, the trained generator is combined with the subject-specific imaging operator at a test site ($A_{test}$) and adapted to minimize a data-consistency loss on acquired k-space samples ($L_{DC}$). $L_{DC}$ is expressed by projecting $\hat{m}$ onto individual coils, undersampling multi-coil images in k-space (with the pattern $\Omega$), and comparing synthesized and acquired k-space samples. For each cross-section, inference optimization is conducted over the synthesizer and mapper parameters ($\theta_{S,M}$), normal variables ($z$) and noise ($n$).}
\label{fig:fedgimp_opt}

\end{figure}



\subsection{Federated Learning of Generative MRI Priors}

To improve flexibility in multi-site collaborations, we propose a novel FL method based on decentralized learning of generative MRI priors. A global MRI prior is trained using an unconditional adversarial model with shared generator and local discriminator networks (Fig. \ref{fig:fedgimp_main}). During inference, the prior is combined with subject-specific imaging operators and adapted to the reconstruction task (Fig. \ref{fig:fedgimp_opt}). The proposed architecture and learning procedures are described below.    


\subsubsection{Unconditional Adversarial Model}
FedGIMP employs an unconditional architecture to learn a generative prior for high-quality MR images. Training images are derived from coil-combined, fully-sampled acquisitions to obtain a prior that is agnostic to k-space undersampling and individual coil sensitivities. Here, we propose a style-generative model as inspired by the success of this model family in natural image synthesis \cite{StyleGAN1}. Our proposed model has a generator that synthesizes realistic MR images, wherein the statistics of feature maps at each stage are controlled via latent variables. These statistics are expected to be different across sites given the native heterogeneity of MR images collected in separate sites. Our model introduces a novel mapper with a site index to produce site-specific latent variables, thereby increasing specificity in synthesized feature maps. Finally, a discriminator differentiates between synthetic and actual MR images.


\textbf{Generator ($G$)}: The generator uses mapper ($M$) and synthesizer ($S$) subnetworks to transform low-dimensional random variables onto high-dimensional MR images. \underline{$M$} receives i.i.d. normal variables $z \in \mathbb{R}^{1\times J}$ concatenated with a one-hot encoding vector for site index $v\in \mathbb{R}^{1\times K}$. Given an input in $\mathbb{R}^{1\times (J+K)}$, it computes latent variables $w\in \mathbb{R}^{1\times J}$:
\begin{align}
w=M_{\theta_M}(z \oplus v),
\end{align}
where $\oplus$ denotes concatenation. At the $i^{th}$ layer of $M$ with $L_M$ layers, latent variables $z_i$ are mapped onto $z_{i+1}$ as:
\begin{align}
z_{i+1}=FC_{M,i}(z_{i}),
\end{align}
where $FC_{M,i}$ is a fully-connected layer with parameters $\theta_{M,i} \in \mathbb{R}^{(J+K)\times J} \mbox{ if }  i=1;\mathbb{R}^{J\times J} \mbox{ if } i\neq1$. Dimensionality is reduced from $J+K$ to $J$ in the first layer, and retained in remaining layers. Receiving $w$ from $M$, \underline{$S$} generates an MR image progressively across $L_S$ layers. In the $i^{th}$ layer, feature maps from the preceding layer ($X_{i}^0\in \mathbb{R}^{\frac{h_1}{2}\times \frac{h_2}{2} \times q}$) are two-fold upsampled. The upsampled maps ($X_{i}^1\in \mathbb{R}^{h_1\times h_2\times q}$) are then processed through a cascade of blocks: $Conv_S^1$ (convolution), $NI^1$ (noise injection), $AdaIN^1$ (adaptive instance normalization), $Conv_S^2$, $NI^2$, $AdaIN^2$. The first block extracts local features, $X_{i}^{2}=Conv_S^1(X_{i}^{1})$:
\begin{align}
X_{i}^{2} =\begin{bmatrix}
    \sum_{c} X_{i}^{1,c} \circledast \theta_{S,i}^{c,1} \\
     \vdots \\
     \sum_{c}  X_{i}^{1,c} \circledast \theta_{S,i}^{c,u} \\
\end{bmatrix},
\label{eq:convolution}
\end{align}
where $\theta_{S,i}^1\in \mathbb{R}^{j\times j \times q \times u}$ are convolution kernels, $u$ is the number of output feature channels, $c$ is the channel index, and $\circledast$ denotes convolution. In Eq. \ref{eq:convolution}, $X_{i}^{2}$ is a 3D tensor and matrix rows span the $3^{rd}$ dimension of $X_{i}^{2}$. Next, the noise-injection block introduces pixel-level intensity modulations in the feature maps. Recent computer vision studies have reported that introducing noise variables across the synthesizer improves details in synthetic natural images \cite{StyleGAN1}. Accordingly, scaled noise variables are added onto feature maps to control low-level structural details, $X_{i}^{3}=NI^1(X_{i}^{2})$:
\begin{align}
X_i^{3} =\begin{bmatrix}
    \varphi(X_i^{2,1} +\epsilon_i^{1,1} n_i^{1}\\
     \vdots \\
     \varphi(X_i^{2,u} +\epsilon_i^{1,u} n_i^{1})\\
\end{bmatrix},
\end{align}
where $n_i^{1} \in \mathbb{R}^{h_1\times h_2}$ is multiplied with the scalar $\epsilon_i^{1,c}$ and added onto the $c^{th}$ channel of $X_i^{2} \in \mathbb{R}^{h_1\times h_2\times u}$, $\varphi$ is an activation function. To control high-level style features, adaptive instance normalization modulates feature maps given intermediate latent variables, $X_{i}^{4}=AdaIN^1(X_{i}^{3},w)$ \cite{adain}:
\begin{align}
X_i^{4} = \gamma^1_i (w) \frac{(X_i^{3}-\mu (X_i^{3}))}{\sigma (X_i^{3})} + \beta^1_i (w),
\end{align}
where $\gamma^1_i \in \mathbb{R}^{u\times 1}$ and $\beta^1_i \in \mathbb{R}^{u\times 1}$ are learnable affine transformations of $w$ that control the scale and bias of each feature channel respectively. $\mu$ and $\sigma$ are mean and variance along the channel dimension of $X_i^{3}$. Note that the cascade of convolution, noise injection and adaptive instance normalization is repeated a second time to yield the mappings $X_{i}^{5}=Conv_S^2(X_{i}^{4})$, $X_{i}^{6}=NI^2(X_{i}^{5})$, $X_{i+1}^{0}=AdaIN^2(X_{i}^{6},w)$. The parameters of these repeat blocks are distinct from those in the initial blocks, except for tied intermediate latents input to $AdaIN^{1,2}$. Overall, the mapping through the generator is: 
\begin{align}
\hat{x}=G_{\theta_G}(z \oplus v) = S_{\theta_S}(M_{\theta_M}(z \oplus v)),
\end{align}
where $\hat{x}$ is the synthesized image, the generator parameters $\theta_G$=\{$\theta_M, \theta_S$\} include mapper and synthesizer parameters.



\begin{algorithm}[t]
\small
\caption{Training of FedGIMP}\label{alg:flgimp_training}

\KwInput { $\mathcal{D}=\{\mathcal{D}^1,...,\mathcal{D}^K\}$: datasets from $K$ sites. \\
$L$: number of communication rounds.\\ 
$I$: number of local epochs. \\
\{$G^1,...,G^K$\}: local generators with \{$\theta_G^1,...,\theta_G^K$\}. \\
\{$D^1,...,D^K$\}: local discriminators with \{$\theta_D^1,...,\theta_D^K$\}. \\
\{$\alpha^1,...,\alpha^K$\}: weighting coefficients of K sites. \\
$G$: global generator with $\theta_G$. \\
}

\KwOutput{$G$ trained global model of params. $\theta_{G}^*$.} 
\For{$l=1:L$}
{
    \For{$k=1:K$}
    {
        $\theta_G^k \gets \theta_G$ (receive global generator)\\
        \For{$i=1:I$}
        {
            $\theta^{k}_{G} \gets \theta^{k}_{G}- Opt(\nabla_{\theta_G^k}\mathcal{L}^k_{G})$ \\
            $\theta^{k}_{D} \gets \theta^{k}_{D}- Opt(\nabla_{\theta_D^k}\mathcal{L}^k_{D})$ \\
        }
    }
    $\theta_G^* \gets  \sum_{k=1}^{K} \alpha^k \theta_G^k$ (aggregate local generators)\\
}
\end{algorithm}

\textbf{Discriminator ($D$)}: The discriminator attempts to discriminate between actual or synthetic MR image inputs. $D$ contains $L_D-1$ layers cascading two-fold downsampling and convolution blocks ($Conv_D$), followed by a final fully-connected layer ($FC_D$). The overall mapping is:
\begin{align}
x_D=D_{\theta_D}(x),
\end{align}
where $x$ is an actual ($x_r$) or synthetic image ($\hat{x}$), $x_D\in \mathbb{R}^{1}$ is the output, and $D_{\theta_D}$ is parametrized by $\theta_D$.


\subsubsection{Training of the Global MRI Prior}
To learn a global MRI prior, FedGIMP performs federated training of the unconditional adversarial model (Alg. \ref{alg:flgimp_training}). The training lasts a total of $L$ communication rounds between the sites and the server. A shared generator ($G$) and $K$ local generator copies ($G^k$) are maintained. Meanwhile, $K$ local discriminators ($D^k$) are not exchanged to limit communication load and augment data privacy. In the first round, $G$ and $D^k$ are randomly initialized. At the start of each round, local generators are initialized with the global generator broadcast from the server, $\theta_G^k \gets \theta_G$. In each round, $I$ local epochs are performed to update local models. The local generator updates are calculated to minimize a non-saturated logistic adversarial loss ($L^{k}_{G}$):
\begin{equation}
\label{eq:fedgimp_synthesizer_loss}
L^{k}_{G}(\theta^{k}_G) = -\mathbb{E}_{p(z)}\left[\log(f(D^{k}(G^{k}_{\theta^{k}_G}(z\oplus v,n))\right],
\end{equation}
where $\mathbb{E}_{p(.)}$ is expectation with respect to probability distribution $p$. The local discriminator updates are calculated to also minimize a non-saturated logistic adversarial loss ($L^{k}_{D}$), along with a gradient penalty according to the learned distribution of actual MR images $p(x^k_r)$ \cite{StyleGAN1}:
\begin{align}
L^{k}_{D}(\mathcal{D}^k;\theta^{k}_D) = & -\mathbb{E}_{p(z)}\left[ \log(1 - f(D^{k}_{\theta^{k}_D}(G(z\oplus v,n)))\right]\notag \\ 
& - \mathbb{E}_{p(x^k_r)}\left[\log(f(D^{k}_{\theta^{k}_D}(x^k_r))\right] \notag \\  
& + \frac{\delta}{2} \mathbb{E}_{p(x^k_r)}\left[\left\|\nabla D^{k}_{\theta^{k}_D}(x^k_r)\right\|^{2}\right], \label{eq:fedgimp_discriminator_loss}
\end{align}
where $\mathcal{D}^k$ are training data from site $k$, i.e. coil-combined MR images derived from fully-sampled acquisitions ($x^k_r$). After $I$ iterations of updates according to Eqs. \ref{eq:fedgimp_synthesizer_loss} and \ref{eq:fedgimp_discriminator_loss}, local generators are sent to the server for aggregation \cite{McMahan2017CommunicationEfficientLO}:
\begin{align}
\label{eq:fedgimp_avg}
\theta_G =  \sum_{k=1}^{K} \alpha^k \theta_G^k 
\end{align}
Here, $\alpha^k$ is set to $\frac{N^k}{N}$, where $N$ is the total number of training samples across all sites and $N^k$ is the number of training samples at the $k^{th}$ site.



\begin{algorithm}[t]\small
\caption{Reconstruction}\label{alg:cap}

\KwInput { $y_{test}^{k,s}$: Undersampled data for $k^{th}$ site, $s^{th}$ subject.\\
$A_{test}^{k,s}$: subject-specific imaging operator for $y_{test}^{k,s}$.\\ 
$G=\{ M, S\}$: global generator with $\theta^*_G=\{ \theta^*_M, \theta^*_S\}$.\\
$v$: site index.\\
$z$: i.i.d normal variable.\\
$E$: number of iterations for inference.\\
}
\KwOutput {$\hat{m}_{k,s}$: reconstructed image.}
$\theta_S^{1} \gets \theta^*_S$, $\theta_M^{1} \gets \theta^*_M$, $z^{1} \gets z$ (initialize)\\
\For{$e=1:E$}
{
            $\theta^{e+1}_{S} \gets \theta^{e}_{S} - Opt(\nabla_{\theta_S^{e}}\mathcal{L}^{k,s}_{DC})$ \\
            $\theta^{e+1}_{M} \gets w^{e}-Opt(\nabla_{\theta^{e}_{M}}\mathcal{L}^{k,s}_{DC})$ \\
        $z^{e+1} \gets z^{e}-Opt(\nabla_{z^e}\mathcal{L}^{k,s}_{DC})$ \\ 
}
$\hat{m}_{k,s}=S_{\theta^{E}_{S}}(M_{\theta_M^E}(z^{E} \oplus v))$\\

\end{algorithm}



\subsubsection{Inference at a Test Site} FedGIMP trains an unconditional prior that randomly generates high-quality, coil-combined, synthetic MR images. Synthetic images do not carry information on coil sensitivities or k-space sampling patterns, and they lack anatomical correspondence to the actual subject. Thus, a dedicated inference procedure is required for reconstruction. Synthetic images define a constraint reflecting the learned image distribution, whereas the subject's undersampled acquisitions define an anatomical constraint in accordance with the imaging operator. The two constraints do not necessarily have an intersection (e.g., a prior trained on brain images used to reconstruct knee images). For reconstruction, FedGIMP adapts its prior to refine the associated constraint and intersect it with the anatomical constraint. This adaptation enforces the prior to generate an image whose undersampled k-space data matches acquired data.

During inference, FedGIMP first combines the trained MRI prior with the subject-specific imaging operator at a test site ($A^{k,s}_{test}$). To do this, the prior can be included in the optimization problem for various model-based reconstructions \cite{Uecker2014,ADMM-CSNET,raki,MoDl}. Here, we follow a straightforward approach where the prior is adapted to minimize a data-consistency loss between synthesized and acquired k-space data (Alg. \ref{alg:cap}):
\begin{align}
L^{k,s}_{DC}=\left\|A^{k,s}_{test}S_{\theta_S}(M_{\theta_M}(z \oplus v))-y^{k,s}_{test}\right\|_{2}
\label{eq:fedgimp_optimization}
\end{align} 
where $w = M_{\theta_M}(z \oplus v)$, and a gradient penalty is included with weight $\eta$ to prevent noise amplification \cite{aggarwal2021}. To compute Eq. \ref{eq:fedgimp_optimization}, FedGIMP estimates synthetic k-space data by projecting the synthetic image $S_{\theta_S}(w,n)$ through the imaging operator $A^{k,s}_{test} = \Omega^{k,s} \mathcal{F} B^{^{k,s}}$, which embodies multiplication with coil sensitivities ($B^{^{k,s}}$), Fourier transformation ($\mathcal{F}$), and undersampling with the prescribed sampling pattern ($\Omega^{k,s}$) \cite{korkmaz2021unsupervised}. Anatomical correspondence between synthetic and actual data is then achieved by minimizing $L^{k,s}_{DC}$. For each cross-section, the optimization is performed over $\theta_S$, $\theta_M$, $z$ and $n$. Given the trained global generator $G_{\theta^*_G}$, synthesizer and mapper parameters are initialized as $\theta_S^{1} \gets \theta^*_S$ and $\theta_M^{1} \gets \theta^*_M$, whereas instance-specific variables are randomly initialized as $z^{1} \gets z$ and $n^{1} \gets n$. Following a total of $E$ iterations, the adapted prior is used to compute the final reconstruction: 
\begin{align}
\hat{m}_{k,s}=S_{\theta^{E}_S}(M_{\theta_M^E}(z^E \oplus v),n^E)
\label{reconstruction}
\end{align} 
Thus, the synthetic image produced by the generator at the end of the optimization yields the final reconstructed image. Note that the values of $z^E$ and $n^E$ are not random but optimized.




\section{Methods}

\subsection{Architectural Details}
The unconditional adversarial model in FedGIMP used a mapper with 8 FC layers receiving a standard normal vector and a one-hot binary encoding vector of site index as inputs, while outputting 32 intermediate latent variables. A synthesizer with 8 layers was used, where each layer contained a bilinear upsampling block for 2-fold increase of feature map resolution, followed by two serial cascades of Conv, NI and AdaIN blocks. The first layer received a 4x4 map of learnable constant values, initialized with ones, as input. The learnable noise variable was randomly initialized from a standard normal distribution. A discriminator with 8 layers was used, each containing a bilinear downsampling block for 2-fold reduction in resolution, and a convolution block with 3x3 kernel size. Leaky ReLU activation functions were used. Two separate channels at the generator's output and the discriminator's input were used to represent real and imaginary parts of complex MR images. During training, images were zero-padded to match the resolution of the output layer if needed. During inference, synthesized images were centrally cropped based on the size of the acquisition matrix prior to calculation of data-consistency loss. The synthesizer and discriminator were trained non-progressively, with all layers intact. 


\subsection{Competing Methods}

FedGIMP was demonstrated against a traditional reconstruction (LORAKS), non-federated models (GAN\SB{cond}/GIMP), and federated conditional models (FL-MRCM, FedGAN, LG-Fed, FedMRI). Hyperparameter selection was performed based on validation performance. For each method, a single set of learning rate, number of epochs (non-federated), number of communication rounds and epochs (federated), and loss term weights were selected that yielded near-optimal performance across tasks. All models were trained via the Adam optimizer. A learning rate of 2x$10^{-3}$ and $\delta$=10 was selected for unconditional models; a learning rate of 2x$10^{-4}$ was selected for conditional models. Decay rate parameters for the optimizer were adopted from previous studies as $\beta_1$=0.0, $\beta_2$=0.99 for unconditional \cite{StyleGAN1}, and $\beta_1$=0.5, $\beta_2$=0.99 for conditional models \cite{rgan}. Training lasted 100 epochs for non-federated models, $L$=100 rounds and $I$=1 epochs for federated models. During inference, unconditional models enforced anatomical consistency to a test subject by minimizing a data-consistency loss. No notable improvement was observed in conditional models subjected to inference optimization based on data-consistency loss, so they used a strict data-consistency projection following a forward pass. Strict data consistency was enforced on all reconstructions prior to reporting. To ensure adherent implementation of competing methods, we utilized libraries from the public repositories shared by the originally proposing authors. Accordingly, we implemented LORAKS in Matlab\footnote{https://mr.usc.edu/download/LORAKS2}, conditional models in PyTorch\footnote{https://github.com/icon-lab/ProvoGAN}$^,$\footnote{https://github.com/guopengf/FL-MRCM}$^,$\footnote{https://github.com/chunmeifeng/FedMRI}. Unconditional models were implemented in TensorFlow to adopt libraries from a style-generative architecture for natural image synthesis\footnote{https://github.com/NVlabs/stylegan}. Models were executed on a system with four Nvidia RTX 3090s.


\underline{\textit{FedGIMP:}} The proposed model was trained to synthesize coil-combined MR images. The model output magnitude images for single-coil experiments, and complex images with real and imaginary components as separate channels for multi-coil experiments. Inference was performed via the Adam optimizer, with optimized parameters transferred across consecutive cross-sections in a volume to improve convergence \cite{korkmaz2021unsupervised}. A learning rate of $10^{-2}$, $\eta$=$10^{-4}$ and $E$=1200 iterations were selected via cross validation. Reconstruction performance improves for higher $E$, yet the benefits become marginal beyond a certain level. Thus, we exercised early stopping based on the L-curve criterion to maintain a favorable compromise between performance and inference time \cite{korkmaz2021unsupervised}. 

\underline{\textit{LORAKS:}} A traditional autocalibrated low-rank reconstruction was performed \cite{Haldar2016}. The k-space neighborhood radius and the rank of LORAKS matrix were selected as (2,6) for single-coil reconstruction and (2,30) for multi-coil reconstruction.

\underline{\textit{GAN\SB{cond}:}} A non-federated conditional model was trained to map zero-filled (ZF) reconstruction of undersampled acquisitions to reference images of fully-sampled acquisitions \cite{rgan}. Weights of (pixel-wise, adversarial, perceptual) losses were set as (100, 1, 100). Centralized training was performed following dataset aggregation across sites, albeit an unshared discriminator was used to process data coming from different sites as in FedGIMP. GAN\SB{cond} serves as a privacy-violating benchmark for conditional reconstruction.  

\underline{\textit{GIMP:}} A non-federated unconditional model was trained based on the architecture and loss functions in FedGIMP. Centralized training was performed, other training and inference procedures were identical to FedGIMP. GIMP serves as a privacy-violating benchmark for unconditional reconstruction.  

\underline{\textit{FL-MRCM:}} A federated conditional model was trained with adversarial alignment of latent representations across sites \cite{guo2021}. For fair comparison among FL methods, architecture and loss functions were adopted from GAN\SB{cond}. Latent representations from the residual backbone were passed through a convolution layer and provided to a domain-alignment network. Weights of (pixel-wise, adversarial, perceptual, reconstruction, domain-alignment) losses were set as (100, 1, 100, 0.5, 0.5).

\underline{\textit{FedGAN:}} A federated conditional model was trained with a shared encoder and decoder across sites \cite{FedGAN}. The architecture and loss functions followed GAN\SB{cond}. Weights of (pixel-wise, adversarial, perceptual) losses were set as (100, 1, 100).

\underline{\textit{LG-Fed:}} A federated conditional model was trained with site-specific encoders and a shared decoder \cite{liang2020think}. The architecture and losses followed GAN\SB{cond}. Weights of (pixel-wise, adversarial, perceptual) losses were set as (100, 1, 100). 

\underline{\textit{FedMRI:}} A federated conditional model was trained with a shared encoder and site-specific decoders \cite{feng2021}. The architecture and losses followed GAN\SB{cond}, albeit an added contrastive loss was included \cite{feng2021}. Weights of (pixel-wise, adversarial, perceptual, contrastive) losses were set as (100, 1, 100, 10).



\begin{table}[t]
\centering
\caption{Single-coil reconstruction performance with the imaging operator matched across sites, and across the training-test sets. Boldface indicates the top-performing FL method.}
\resizebox{0.5\textwidth}{!}
{
\begin{tabular}{| Sc | l l | Sc | Sc | Sc | Sc | Sc | Sc |}
 \hline
& & & \multicolumn{2}{Sc|}{IXI} & \multicolumn{2}{Sc|}{fastMRI}& \multicolumn{2}{Sc|}{BRATS}\\
 \hline
{} & &  &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$   \\
 \hline
\multirow{6}{*}{\rotatebox[origin=c]{90}{\textbf{Non-fed}}}& \multirow{2}{*}{LORAKS}   & 3x & 28.6$\pm$2.5 & 69.9$\pm$6.5 & 29.1$\pm$4.6 & 70.4$\pm$11.3 & 35.1$\pm$4.0 & 95.1$\pm$0.5 \\
& & 6x & 26.0$\pm$1.9 & 61.9$\pm$6.6 & 26.0$\pm$3.9 & 62.0$\pm$12.2 & 31.7$\pm$3.6 & 92.3$\pm$0.9\\
 \cline{2-9}
& \multirow{2}{*}{GAN\SB{cond}}   & 3x & 38.6$\pm$1.2 & 94.6$\pm$1.0 & 39.2$\pm$2.3 & 95.1$\pm$1.3 & 44.1$\pm$1.3 & 98.5$\pm$0.3\\
& & 6x & 35.1$\pm$1.1 & 91.2$\pm$1.5 & 35.8$\pm$2.2 & 91.9$\pm$2.0 & 40.3$\pm$1.3 & 97.1$\pm$0.5\\
 \cline{2-9}
& \multirow{2}{*}{GIMP}   & 3x & 42.2$\pm$1.4 & 98.2$\pm$0.5 & 40.6$\pm$2.2 & 97.1$\pm$1.0 & 50.6$\pm$1.9 & 99.7$\pm$0.1 \\
& & 6x & 37.6$\pm$1.3 & 96.4$\pm$1.0 & 36.6$\pm$2.3 & 94.5$\pm$1.6 & 45.4$\pm$1.7 & 99.2$\pm$0.2 \\
 \hline
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textbf{Fed}}} & \multirow{2}{*}{FL-MRCM}   & 3x & 38.1$\pm$1.2& 94.2$\pm$1.1 & 38.8$\pm$2.3 & 94.6$\pm$1.4 & 43.4$\pm$1.3 & 98.3$\pm$0.3\\
& & 6x & 34.7$\pm$1.2 & 90.8$\pm$1.6 & 35.3$\pm$2.3 & 90.9$\pm$2.2 & 39.6$\pm$1.3 & 96.8$\pm$0.6 \\
 \cline{2-9}
& \multirow{2}{*}{FedGAN}  &3x& 38.5$\pm$1.2 & 94.5$\pm$1.0 & 38.9$\pm$2.3 & 94.9$\pm$1.4 & 44.1$\pm$1.2 & 98.4$\pm$0.3\\
&  &  6x & 35.0$\pm$1.1 & 91.2$\pm$1.5 & 35.6$\pm$2.2 & 91.7$\pm$2.0 & 40.1$\pm$1.3 & 97.0$\pm$0.6\\
 \cline{2-9}
{} & \multirow{2}{*}{LG-Fed}   & 3x & 38.4$\pm$1.2 & 94.3$\pm$1.0 & 38.9$\pm$2.3 & 94.9$\pm$1.4 & 44.0$\pm$1.3 & 98.4$\pm$0.3\\
& & 6x & 34.8$\pm$1.0 & 90.6$\pm$1.4 & 35.6$\pm$2.3 & 91.6$\pm$2.0 & 40.1$\pm$1.3 & 97.1$\pm$0.6\\
  \cline{2-9}
& \multirow{2}{*}{FedMRI}  & 3x & 38.6$\pm$1.2 & 94.4$\pm$1.0 & 39.0$\pm$2.3 & 94.9$\pm$1.3 & 44.2$\pm$1.3 & 98.5$\pm$0.3  \\
& & 6x & 34.9$\pm$1.1 & 90.5$\pm$1.5 & 35.5$\pm$2.2 & 91.4$\pm$2.0 & 40.3$\pm$1.4 & 97.2$\pm$0.5\\
 \cline{2-9}

& \multirow{2}{*}{FedGIMP}   & 3x& \textbf{42.9$\pm$1.5} & \textbf{98.5$\pm$0.5} & \textbf{41.1$\pm$2.2} & \textbf{97.4$\pm$0.8} & \textbf{50.9$\pm$1.9} & \textbf{99.7$\pm$0.1}\\
& & 6x& \textbf{37.8$\pm$1.4} & \textbf{96.5$\pm$1.0} &	\textbf{36.9$\pm$2.2} & \textbf{94.8$\pm$1.4} & \textbf{45.4$\pm$1.7} & \textbf{99.2$\pm$0.2}\\
\hline
\end{tabular}
}
\label{tab:within_domain_sc}
\end{table}


\subsection{Experiments}

\subsubsection{Datasets}
FL experiments were conducted using an in-house dataset acquired at Bilkent University along with three public datasets (IXI {\small \url{http://brain-development.org/ixi-dataset/})}, fastMRI \cite{fastmri}, BRATS \cite{BRATS}). We describe the in-house imaging protocol below (see related references for public datasets). Acquisitions were retrospectively undersampled using variable- (VD) and uniform-density (UD) patterns at acceleration rates R= (3x, 6x) \cite{Lustig2007}. There was no subject overlap between training, validation, and test sets. Each FL site corresponded to a distinct dataset, and all examined FL setups had 3 sites. The training set in each site aggregated MR images across multiple different contrasts. Training samples were randomly drawn from this aggregated set, without any special procedures for handling different contrasts. While modeling each contrast separately could enhance performance, we reasoned that training on mixed contrasts is a more realistic scenario given the ubiquity of multi-contrast protocols in clinical practice \cite{KnollGeneralization}.

\underline{\textit{In-House:}} T\SB{1}-, T\SB{2}- and PD-weighted scans were performed in 10 subjects on a 3T Siemens Tim Trio scanner located at Bilkent University using a 32-channel coil. An MP-RAGE sequence was used for T\SB{1}-weighted scans with TE/TI/TR = 3.87/1100/2000 ms, 20$^o$ flip angle; and an FSE sequence was used for T\SB{2}-/PD-weighted scans
with TE$_{PD}$/TE$_{T2}$/TR = 12/118/1000 ms, 90$^o$ flip angle. All scans were performed with 192x256x176 mm$^3$ field-of-view and 1x1x2 mm$^3$ voxel size. Ethics approval was obtained from the local ethics committee, and all participants gave written-informed consent.


\begin{table}[t]
\centering
\caption{Single-coil reconstruction performance with the imaging operator mismatched across the training-test sets, $A \rightarrow B$ denotes the domain shift in R (upper panel) / sampling densities (lower panel).}
\resizebox{0.5\textwidth}{!}
{
\begin{tabular}{| Sc | l l |  Sc | Sc | Sc | Sc | Sc | Sc | }
\hline
\multicolumn{9}{|Sc|}{\textbf{Acceleration Rate} (6x$\rightarrow$3x or 3x$\rightarrow$6x)} \\
\hline
 & & & \multicolumn{2}{Sc|}{IXI} & \multicolumn{2}{Sc|}{fastMRI}& \multicolumn{2}{Sc|}{BRATS}\\
\hline
{} & &  &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$  \\
 \hline
\multirow{6}{*}{\rotatebox[origin=c]{90}{\textbf{Non-fed}}}& \multirow{2}{*}{LORAKS}   & 3x & 28.6$\pm$2.5 & 69.9$\pm$6.5 & 29.1$\pm$4.6 & 70.4$\pm$11.3 & 35.1$\pm$4.0 & 95.1$\pm$0.5 \\
& & 6x & 26.0$\pm$1.9 & 61.9$\pm$6.6 & 26.0$\pm$3.9 & 62.0$\pm$12.2 & 31.7$\pm$3.6 & 92.3$\pm$0.9\\
  \cline{2-9}
& \multirow{2}{*}{GAN\SB{cond}}   & 3x & 37.8$\pm$1.1 & 92.9$\pm$1.1 & 38.0$\pm$1.9 & 93.7$\pm$1.4 & 42.2$\pm$1.3 & 97.8$\pm$0.4\\
&& 6x & 33.5$\pm$1.2 & 89.6$\pm$1.7 & 34.3$\pm$2.4 & 90.2$\pm$2.4 & 39.3$\pm$1.4 & 96.9$\pm$0.6\\
 \cline{2-9}
& \multirow{2}{*}{GIMP}   & 3x & 42.2$\pm$1.4 & 98.2$\pm$0.5 & 40.6$\pm$2.2 & 97.1$\pm$1.0 & 50.6$\pm$1.9 & 99.7$\pm$0.1 \\
& & 6x & 37.6$\pm$1.3 & 96.4$\pm$1.0 & 36.6$\pm$2.3 & 94.5$\pm$1.6 & 45.4$\pm$1.7 & 99.2$\pm$0.2 \\
 \hline
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textbf{Fed}}}& \multirow{2}{*}{FL-MRCM}  & 3x & 37.4$\pm$1.1 & 92.6$\pm$1.2 & 37.3$\pm$2.0 & 92.8$\pm$1.7 & 40.7$\pm$1.4 & 96.9$\pm$0.7\\
 &&  6x & 33.1$\pm$1.3 & 88.5$\pm$2.1 & 33.9$\pm$2.4 & 89.1$\pm$2.6 & 38.6$\pm$1.3 & 96.4$\pm$0.7\\
 \cline{2-9}
 & \multirow{2}{*}{FedGAN}  &3x& 37.5$\pm$1.1 &	92.7$\pm$1.2 &	38.1$\pm$1.9 &	93.8$\pm$1.4 &	41.9$\pm$1.2 &	97.6$\pm$0.5\\
 &&  6x & 33.3$\pm$1.2	& 89.2$\pm$1.7 &	34.1$\pm$2.4 &	89.8$\pm$2.5	& 39.1$\pm$1.3	& 96.8$\pm$0.6\\
 \cline{2-9}
&\multirow{2}{*}{LG-Fed}   & 3x& 37.6$\pm$1.0 &	92.9$\pm$1.0 &	37.8$\pm$1.9 &	93.4$\pm$1.6 &	42.2$\pm$1.3 &	97.8$\pm$0.5\\ 
&& 6x & 33.9$\pm$1.2 &	89.9$\pm$1.5 &	34.3$\pm$2.3 &	90.2$\pm$2.3 &	39.6$\pm$1.3 &	97.0$\pm$0.6\\
 \cline{2-9}
&\multirow{2}{*}{FedMRI}  & 3x & 37.6$\pm$1.0 &	92.8$\pm$1.1 &	37.8$\pm$1.8 &	93.5$\pm$1.5 &	42.7$\pm$1.3 &	98.0$\pm$0.4\\
 &&   6x & 34.1$\pm$1.2 &	90.2$\pm$1.5 &	34.3$\pm$2.4 &	89.9$\pm$2.4 &	39.6$\pm$1.4 &	97.1$\pm$0.6\\
 \cline{2-9}

&\multirow{2}{*}{FedGIMP}   & 3x& \textbf{42.9$\pm$1.5} & \textbf{98.5$\pm$0.5} & \textbf{41.1$\pm$2.2} & \textbf{97.4$\pm$0.8} & \textbf{50.9$\pm$1.9} & \textbf{99.7$\pm$0.1}\\
& & 6x& \textbf{37.8$\pm$1.4} & \textbf{96.5$\pm$1.0} &	\textbf{36.9$\pm$2.2} & \textbf{94.8$\pm$1.4} & \textbf{45.4$\pm$1.7} & \textbf{99.2$\pm$0.2}\\
\hline
\multicolumn{9}{|Sc|}{\textbf{Sampling Density} (VD$\rightarrow$UD)} \\
\hline
& & & \multicolumn{2}{Sc|}{IXI} & \multicolumn{2}{Sc|}{fastMRI}& \multicolumn{2}{Sc|}{BRATS}\\

 \cline{2-9}
{} & &  &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$ \\
 \hline
\multirow{6}{*}{\rotatebox[origin=c]{90}{\textbf{Non-fed}}}&\multirow{2}{*}{LORAKS}   & 3x & 25.5$\pm$1.4 &	80.9$\pm$3.7 &	26.1$\pm$2.9 &	79.9$\pm$6.5 &	31.5$\pm$2.9 &	94.5$\pm$0.6\\
&& 6x & 21.7$\pm$0.8 &	67.4$\pm$4.5 &	21.2$\pm$1.7 &	63.9$\pm$7.1 &	24.7$\pm$2.4 &	85.6$\pm$1.4\\
 \cline{2-9}
&\multirow{2}{*}{GAN\SB{cond}}   & 3x & 30.3$\pm$1.0 &	89.5$\pm$1.5 &	31.0$\pm$2.8 &	88.7$\pm$3.2 &	37.0$\pm$1.4 &	96.1$\pm$0.7\\
&& 6x & 24.2$\pm$0.7 &	77.0$\pm$2.9 &	25.1$\pm$1.9 &	76.5$\pm$4.5 &	30.4$\pm$1.3 &	90.0$\pm$1.3\\
 \cline{2-9}
 & \multirow{2}{*}{GIMP}   & 3x & 35.3$\pm$1.6 & 95.7$\pm$1.1 & 35.1$\pm$2.3 & 93.8$\pm$1.6 & 47.0$\pm$2.1 & 99.5$\pm$0.2 \\
&& 6x & 26.8$\pm$0.9 &	84.0$\pm$2.4 &	28.1$\pm$2.6 &	82.3$\pm$3.9 &	33.4$\pm$1.4 &	93.6$\pm$1.0\\
 \hline
 \multirow{10}{*}{\rotatebox[origin=c]{90}{\textbf{Fed}}}&\multirow{2}{*}{FL-MRCM}   & 3x& 30.5$\pm$1.0 &	89.8$\pm$1.3 &	30.7$\pm$2.6 &	87.5$\pm$3.1 &	36.1$\pm$1.5 &	95.1$\pm$0.9\\
&& 6x & 23.9$\pm$0.6 &	74.8$\pm$2.5 &	24.5$\pm$1.6 &	73.4$\pm$3.9 &	29.4$\pm$1.3 &	86.8$\pm$1.7\\
  \cline{2-9}
 &\multirow{2}{*}{FedGAN}  & 3x& 30.2$\pm$1.0 &	89.3$\pm$1.5 &	31.0$\pm$2.7 &	89.0$\pm$3.1 &	37.1$\pm$1.4 &	96.2$\pm$0.7\\
&& 6x & 24.1$\pm$0.7 &	76.6$\pm$3.0 &	25.0$\pm$1.9 &	76.4$\pm$4.6 &	30.2$\pm$1.3 &	89.8$\pm$1.3\\
 \cline{2-9}
&\multirow{2}{*}{LG-Fed}   & 3x& 30.6$\pm$1.1 &	90.0$\pm$1.4 &	31.0$\pm$2.7 &	88.7$\pm$3.1 &	36.9$\pm$1.5 &	96.1$\pm$0.8\\
&& 6x & 24.2$\pm$0.7 &	77.4$\pm$2.9 &	25.1$\pm$1.9 &	76.5$\pm$4.7 &	30.2$\pm$1.3 &	89.9$\pm$1.4\\
 \cline{2-9}
&\multirow{2}{*}{FedMRI}  & 3x & 30.7$\pm$1.1 &	90.4$\pm$1.3 &	31.1$\pm$2.7 &	89.0$\pm$2.9 &	37.2$\pm$1.5 &	96.3$\pm$0.7\\
&& 6x & 24.3$\pm$0.7 &	77.8$\pm$2.6 &	25.0$\pm$1.8 &	76.1$\pm$4.4 &	30.4$\pm$1.3 &	90.3$\pm$1.3\\
 \cline{2-9}

&\multirow{2}{*}{FedGIMP}   & 3x& \textbf{35.1$\pm$1.4} & \textbf{95.4$\pm$1.0} & \textbf{35.3$\pm$2.4} & \textbf{94.2$\pm$1.7} & \textbf{47.4$\pm$2.2} & \textbf{99.6$\pm$0.2}\\
&& 6x& \textbf{26.6$\pm$1.0} & \textbf{83.9$\pm$2.5} & \textbf{28.0$\pm$2.5} & \textbf{82.3$\pm$4.0} & \textbf{33.4$\pm$1.4} & \textbf{93.4$\pm$1.0}\\
\hline
\end{tabular}
}
\label{tab:cross_domain_sc}
\end{table}



\subsubsection{Single-Coil Reconstruction} Experiments were performed on IXI, fastMRI, and BRATS. Coil-combined magnitude images in each dataset were treated as single-coil data, so their analyses omitted the channel dimension of coil arrays. T\SB{1}-, T\SB{2}-, PD-weighted acquisitions in IXI and BRATS, T\SB{1}c-, T\SB{2}-, FLAIR-weighted acquisitions in fastMRI were considered. For each dataset, multi-contrast acquisitions of (40,5,10) subjects were reserved as (training, validation, test) sets, with 21 cross-sections per contrast randomly selected in each subject. As such, the training, validation and test sets within each dataset (i.e., each site) contained (840,105,210) cross-sections.





\subsubsection{Multi-Coil Reconstruction} Experiments were performed on fastMRI brain, fastMRI knee, and In-House brain datasets, which all contained multi-coil k-space data. For fastMRI brain, T\SB{1}-, T\SB{2}-, FLAIR-weighted acquisitions from (36,6,9) subjects were reserved, with 8 cross-sections per contrast randomly selected in each subject. For fastMRI knee, PD-, PDFS-weighted acquisitions from (48,8,12) subjects were reserved, with 9 cross-sections per contrast. For In-House, T\SB{1}-, T\SB{2}-, PD-weighted acquisitions from (6,1,3) subjects were reserved, with 48 cross-sections per contrast in the training and validation sets, and with 24 cross-sections per contrast in the test set. As such, the training, validation and test sets within each dataset contained (864,144,216) cross-sections. Coil compression was performed onto 5 virtual coils \cite{Zhang2013}. Conditional models mapped multi-coil, complex ZF reconstructions of undersampled data to reference images derived from fully-sampled data. GIMP and FedGIMP synthesized complex coil-combined MR images during training \cite{Uecker2014}. The imaging operator was only injected during inference to enforce data consistency based on multi-coil k-space data. 

\subsection{Quantitative Assessments}
Reconstructed images were compared against Fourier reconstruction of fully-sampled acquisitions as reference. Peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) were measured, following normalization of images to [0 1]. Tables list mean and standard deviation of performance metrics across test subjects. Statistical significance of performance differences was assessed via Wilcoxon sign-rank tests.




\begin{figure*}[tp]
\begin{minipage}{0.2\textwidth}
\caption{Representative reconstructions of a T\SB{2}-weighted acquisition in IXI, a T\SB{1}c-weighted acquisition in fastMRI, and a T\SB{1}-weighted acquisition in BRATS datasets at R=3x based on uniform-density patterns. Results are shown for ZF, LORAKS, FL-MRCM, FedGAN, LG-Fed, FedMRI, and FedGIMP along with the reference images. Conditional models were trained on variable-density patterns at R=3x.}
\captionsetup{justification   = justified,singlelinecheck = false}
\label{fig:singlecoil}
\end{minipage}
\begin{minipage}{0.8\textwidth}
\centerline{\includegraphics[width=0.975\textwidth]{figure03.png}}
\end{minipage}\hfill
\end{figure*}


\section{Results}
\subsection{Single-Coil Reconstruction}

\subsubsection*{Domain shifts in the MR image distribution}
Multi-site datasets of multi-contrast MRI data contain intrinsic domain shifts in the image distribution within and across sites \cite{guo2021}. To assess the influence of these intrinsic shifts, we examined performance when the imaging operator was matched across sites and across the training-test sets (Table \ref{tab:within_domain_sc}). FedGIMP outperforms all competing methods (p$<$0.05), except on BRATS, R=6x where the privacy-violating benchmark GIMP performs similarly. On average across sites and R, FedGIMP yields 3.7dB PSNR, 3.0\% SSIM improvement over the second-best FL method, demonstrating the efficacy of FedGIMP against heterogeneity in the MR image distribution.     

\subsubsection*{Domain shifts in the imaging operator}
We then examined reconstruction performance under additional domain shifts due to the imaging operator. First, we considered homogeneous imaging operators across sites, while either acceleration rates (e.g., training at 3x, testing at 6x) or sampling densities (training with VD, testing with UD patterns) were mismatched across the training and test tests (Table \ref{tab:cross_domain_sc}). FedGIMP is the top performer among all methods (p$<$0.05), except for GIMP that performs similarly. Compared to the second-best FL method, FedGIMP offers 4.8dB PSNR, 4.0\% SSIM improvement under mismatched R, and 4.5dB PSNR, 4.8\% SSIM improvement under mismatched sampling density. Representative reconstructions under mismatched sampling density are shown in Fig. \ref{fig:singlecoil}. Federated conditional models and LORAKS yield prominent aliasing artifacts and blurring, whereas FedGIMP achieves high visual acuity and improved artifact suppression due to its enhanced generalization performance.  

Next, we considered heterogeneous imaging operators across sites for improved flexibility in collaborations. We separately examined performance when the heterogeneous operators were matched or mismatched between the training-test sets (Table \ref{tab:variable_A}). When the training-test operators match, FedGIMP achieves the highest performance among competing methods (p$<$0.05), except for GIMP that performs similarly, and in BRATS where LG-Fed performs slightly better and GAN\SB{cond}, FedGAN, FedMRI perform similarly. When the training-test operators mismatch, FedGIMP achieves the highest performance among competing methods (p$<$0.05), except GIMP that performs similarly. Compared to the second-best FL method, FedGIMP offers 1.3dB PSNR and 2.7\% SSIM improvement under matched operators, and 5.1dB PSNR, 3.0\% SSIM improvement under mismatched operators.  

%%%%%%
\begin{table}[]
\centering
\caption{Single-coil reconstruction performance with heterogeneous imaging operators across sites. The operators were either matched (upper panel) or mismatched (lower panel) across the training-test sets.}
\resizebox{0.5\textwidth}{!}
{
\begin{tabular}{| Sc|l  | Sc | Sc | Sc | Sc | Sc | Sc |  }
\hline
\multicolumn{8}{|Sc|}{\textbf{Matched across training-test sets}} \\
\hline
& &  \multicolumn{2}{Sc|}{IXI} & \multicolumn{2}{Sc|}{fastMRI}& \multicolumn{2}{Sc|}{BRATS}\\
& &  \multicolumn{2}{Sc|}{(9x, VD)} & \multicolumn{2}{Sc|}{(3x, VD)}& \multicolumn{2}{Sc|}{(6x, UD)}\\
\hline
{}  & & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$   \\
\hline
\multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{Non-fed}}}&\multirow{1}{*}{LORAKS}    & 25.0$\pm$1.6 & 58.8$\pm$6.5 & 29.1$\pm$4.6 & 70.4$\pm$11.3 & 24.7$\pm$2.4 & 85.6$\pm$1.4\\
 \cline{2-8}
&\multirow{1}{*}{GAN\SB{cond}}    & 33.4$\pm$1.1 & 88.8$\pm$1.7 & 39.0$\pm$2.2 & 94.9$\pm$1.3 & 33.0$\pm$1.2 & 93.2$\pm$1.0\\
 \cline{2-8}
&\multirow{1}{*}{GIMP}   & 35.5$\pm$1.3 & 95.0$\pm$1.3 & 40.6$\pm$2.2 & 97.1$\pm$1.0 & 33.4$\pm$1.4 & 93.6$\pm$1.0\\
\hline
\multirow{5}{*}{\rotatebox[origin=c]{90}{\textbf{Fed}}}&\multirow{1}{*}{FL-MRCM}    & 32.9$\pm$1.0 & 88.5$\pm$1.5 & 37.6$\pm$2.3 & 93.1$\pm$1.7 & 30.5$\pm$1.3 & 89.9$\pm$1.4\\
 \cline{2-8}
&\multirow{1}{*}{FedGAN}  & 33.0$\pm$1.0 & 88.4$\pm$1.5 & 38.0$\pm$1.9 & 93.5$\pm$1.5 & 32.5$\pm$1.2 & 92.9$\pm$0.9\\
 \cline{2-8}
&\multirow{1}{*}{LG-Fed}  & 33.4$\pm$1.0 & 88.8$\pm$1.6 & 38.9$\pm$2.3 & 94.9$\pm$1.4 & \textbf{33.9$\pm$1.3} & \textbf{94.2$\pm$0.9}\\
 \cline{2-8}
&\multirow{1}{*}{FedMRI}  & 33.4$\pm$1.0 & 88.7$\pm$1.5 & 38.9$\pm$2.2 & 94.8$\pm$1.3 & 33.0$\pm$1.2 & 93.2$\pm$1.0\\
 \cline{2-8}

&\multirow{1}{*}{FedGIMP}  & \textbf{35.6$\pm$1.4} & \textbf{95.2$\pm$1.4} & \textbf{41.1$\pm$2.2} & \textbf{97.4$\pm$0.8} & 33.4$\pm$1.4 & 93.4$\pm$1.0 \\
\hline
\multicolumn{8}{|Sc|}{\textbf{Mismatched across training-test sets}} \\
\hline
&&   \multicolumn{2}{Sc|}{IXI} & \multicolumn{2}{Sc|}{fastMRI}& \multicolumn{2}{Sc|}{BRATS}\\
&&   \multicolumn{2}{Sc|}{(9x, VD)$\rightarrow$(3x, UD)} & \multicolumn{2}{Sc|}{(3x, VD)$\rightarrow$(6x, UD)}& \multicolumn{2}{Sc|}{(6x, UD)$\rightarrow$(3x, VD)}\\
\hline
{}    &&PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$  & SSIM$\uparrow$   \\
\hline
\multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{Non-fed}}}&\multirow{1}{*}{LORAKS}    & 25.5$\pm$1.4 & 80.9$\pm$3.7 & 21.2$\pm$1.7 & 63.9$\pm$7.1 & 35.1$\pm$4.0 & 95.1$\pm$0.5\\
 \cline{2-8}
&\multirow{1}{*}{GAN\SB{cond}}   & 31.3$\pm$1.1 & 91.2$\pm$1.3 & 26.1$\pm$2.3 & 79.4$\pm$4.8 & 42.1$\pm$1.0 & 97.7$\pm$0.3 \\
 \cline{2-8}
&\multirow{1}{*}{GIMP}   &  35.3$\pm$1.6 & 95.7$\pm$1.1 & 28.1$\pm$2.6 & 82.3$\pm$3.9 & 50.6$\pm$1.9 & 99.7$\pm$0.1\\
\hline
\multirow{5}{*}{\rotatebox[origin=c]{90}{\textbf{Fed}}}&\multirow{1}{*}{FL-MRCM}   &  31.9$\pm$0.9 & 91.6$\pm$1.1 & 25.8$\pm$2.0 & 77.7$\pm$4.3 & 40.8$\pm$1.2 & 97.0$\pm$0.6\\
 \cline{2-8}
&\multirow{1}{*}{FedGAN}  & 32.3$\pm$1.0 & 92.5$\pm$1.1 & 25.9$\pm$2.1 & 79.3$\pm$4.5 & 40.6$\pm$1.3 & 96.7$\pm$0.7\\
 \cline{2-8}
&\multirow{1}{*}{LG-Fed}   & 31.5$\pm$1.0 & 91.1$\pm$1.2 & 24.9$\pm$1.9 & 75.8$\pm$4.8 & 38.0$\pm$1.0 & 94.6$\pm$0.8\\
 \cline{2-8}
&\multirow{1}{*}{FedMRI}  & 31.7$\pm$1.1 & 91.4$\pm$1.2 & 24.9$\pm$1.8 & 75.8$\pm$4.5 & 37.8$\pm$1.1 & 94.2$\pm$1.0\\
 \cline{2-8}
&\multirow{1}{*}{FedGIMP}   &  \textbf{35.1$\pm$1.4} & \textbf{95.4$\pm$1.0} & \textbf{28.0$\pm$2.5} & \textbf{82.3$\pm$4.0} & \textbf{50.9$\pm$1.9} & \textbf{99.7$\pm$0.1}\\
\hline
\end{tabular}
}
\label{tab:variable_A}
\end{table}


\begin{figure*}[tp]
\begin{minipage}{0.2\textwidth}
\caption{Representative reconstructions of a FLAIR acquisition of the brain in fastMRI, a fat suppressed PD-weighted acquisition of the knee in fastMRI, and a T\SB{1}-weighted acquisition of the brain in In-House datasets at R=6x. Results are shown for ZF, LORAKS, FL-MRCM, FedGAN, LG-Fed, FedMRI and FedGIMP along with the reference images. Conditional models were trained at R=3x.}
\label{fig:multicoil}
\captionsetup{justification   = justified,singlelinecheck = false}
\end{minipage}
\begin{minipage}{0.8\textwidth}
\centerline{\includegraphics[width=0.975\textwidth]{figure04.png}}
\end{minipage}\hfill
\end{figure*}


%%%%%%%%multi-coil
\begin{table}[h]
\centering
\caption{Multi-coil reconstruction performance with the imaging operator matched across sites, and the training-test sets.}
\resizebox{0.5\textwidth}{!}
{
\begin{tabular}{| Sc| l l |  Sc | Sc | Sc | Sc | Sc | Sc |  }
\hline
 & & & \multicolumn{2}{Sc|}{fastMRI brain} & \multicolumn{2}{Sc|}{fastMRI knee} & \multicolumn{2}{Sc|}{In-House brain}\\
\hline
{}  & & &PSNR $\uparrow$   & SSIM$\uparrow$ &PSNR $\uparrow$   & SSIM$\uparrow$   & PSNR $\uparrow$   & SSIM$\uparrow$   \\
 \hline
\multirow{6}{*}{\rotatebox[origin=c]{90}{\textbf{Non-fed}}}&\multirow{2}{*}{LORAKS}   & 3x & 36.1$\pm$0.9 & 89.6$\pm$1.1 & 33.0$\pm$1.4 & 79.0$\pm$2.3 & 51.1$\pm$1.0 & 99.3$\pm$0.1\\
& & 6x & 30.8$\pm$1.6 & 80.3$\pm$2.6 & 30.9$\pm$1.5 & 74.1$\pm$2.7 & 39.3$\pm$1.4 & 95.7$\pm$0.9\\
  \cline{2-9}
&\multirow{2}{*}{GAN\SB{cond}}   & 3x & 40.1$\pm$0.9 & 95.6$\pm$0.6 & 36.1$\pm$1.2 & 89.9$\pm$1.6 & 43.5$\pm$1.0 & 98.7$\pm$0.2\\
& & 6x & 36.3$\pm$0.9 & 91.9$\pm$0.9 & 33.2$\pm$1.1 & 83.1$\pm$2.4 & 38.8$\pm$0.9 & 96.9$\pm$0.5\\
 \cline{2-9}
&\multirow{2}{*}{GIMP}   & 3x & 47.5$\pm$0.9 & 98.8$\pm$0.2 & 43.6$\pm$1.2 & 97.5$\pm$0.4 & 52.4$\pm$1.1 & 99.6$\pm$0.1 \\
&& 6x & 40.8$\pm$0.9 & 95.7$\pm$0.5 & 38.0$\pm$1.3  & 91.6$\pm$1.3 & 43.9$\pm$1.0  & 98.5$\pm$0.2\\
\hline
\multirow{10}{*}{\rotatebox[origin=c]{90}{\textbf{Fed}}}&\multirow{2}{*}{FL-MRCM}   & 3x & 39.4$\pm$0.9 & 95.8$\pm$0.5 & 36.9$\pm$1.3 & 90.6$\pm$1.3 & 40.4$\pm$0.9 & 97.5$\pm$0.4\\
&& 6x & 35.9$\pm$0.8 & 92.2$\pm$0.8 & 33.8$\pm$1.2 & 82.1$\pm$2.4 & 36.0$\pm$0.8 & 95.0$\pm$0.7\\
 \cline{2-9}
&\multirow{2}{*}{FedGAN}  & 3x & 39.8$\pm$0.9 & 95.6$\pm$0.5 & 37.0$\pm$1.2 & 90.0$\pm$1.5 & 41.7$\pm$1.1 & 98.1$\pm$0.3 \\
 &&  6x & 35.9$\pm$0.8 & 92.1$\pm$0.9  & 34.0$\pm$1.2 & 82.7$\pm$2.5  & 36.7$\pm$0.9 & 95.7$\pm$0.7\\
 \cline{2-9}
&\multirow{2}{*}{LG-Fed}   & 3x& 39.8$\pm$0.8 & 95.7$\pm$0.5 & 36.6$\pm$1.2 & 89.5$\pm$1.6 & 42.8$\pm$0.9 & 98.5$\pm$0.2\\
&& 6x& 35.9$\pm$0.8 & 92.4$\pm$0.8 & 33.7$\pm$1.2 & 82.2$\pm$2.5 & 38.4$\pm$0.9 & 96.6$\pm$0.5\\
  \cline{2-9}
& \multirow{2}{*}{FedMRI}  &3x& 39.9$\pm$0.9 & 95.8$\pm$0.5 & 36.8$\pm$1.2 & 89.7$\pm$1.6 & 43.0$\pm$0.9 & 98.6$\pm$0.2 \\
 &&  6x& 36.1$\pm$0.9 & 92.4$\pm$0.8 & 33.7$\pm$1.2 & 81.7$\pm$2.6 & 38.0$\pm$0.9 & 96.6$\pm$0.5\\
 \cline{2-9}

&\multirow{2}{*}{FedGIMP}   & 3x& \textbf{47.2$\pm$0.9} &\textbf{98.7$\pm$0.2} & \textbf{43.3$\pm$1.2} &\textbf{97.4$\pm$0.4} & \textbf{52.8$\pm$1.2} &\textbf{99.6$\pm$0.1}\\
&& 6x& \textbf{40.7$\pm$0.9} &\textbf{95.7$\pm$0.5}& \textbf{37.9$\pm$1.3} &\textbf{91.5$\pm$1.4} & \textbf{44.0$\pm$1.0} &\textbf{98.5$\pm$0.2} \\
\hline
\end{tabular}
}
\label{tab:within_mc}
\end{table}



\subsection{Multi-Coil Reconstruction}


\subsubsection*{Domain shifts in the MR image distribution}
We first evaluated reconstruction performance when the imaging operator was matched across sites and training-test sets to assess intrinsic domain shifts due to the image distribution. Differing from single-coil experiments, multi-coil FL experiments were conducted on datasets containing two separate anatomies, i.e. the knee and the brain (Table \ref{tab:within_mc}). FedGIMP outperforms all competing methods (p$<$0.05), except GIMP that performs similarly. On average, FedGIMP achieves 6.3dB PSNR, 4.2\% SSIM improvement over the second-best FL method. These results corroborate the efficacy of FedGIMP in multi-coil settings, and its efficiency in coping with heterogeneity in the image distribution due to diverse anatomy.     



%%%%%%%%multi-coil
\begin{table}[t]
\centering
\caption{Multi-coil reconstruction performance with the imaging operator mismatched across training-test sets.}
\resizebox{0.5\textwidth}{!}
{
\begin{tabular}{| Sc| l l |  Sc | Sc | Sc | Sc | Sc | Sc |  }
\hline
& && \multicolumn{2}{Sc|}{fastMRI brain}& \multicolumn{2}{Sc|}{fastMRI knee} & \multicolumn{2}{Sc|}{In-House brain}\\

 \hline
{}  &&  &PSNR $\uparrow$   & SSIM$\uparrow$  &PSNR $\uparrow$   & SSIM$\uparrow$  & PSNR $\uparrow$   & SSIM$\uparrow$  \\
 \hline
 
\multirow{6}{*}{\rotatebox[origin=c]{90}{\textbf{Non-Fed}}}&\multirow{2}{*}{LORAKS} & 3x & 36.1$\pm$0.9 & 89.6$\pm$1.1 & 33.0$\pm$1.4 & 79.0$\pm$2.3 & 51.1$\pm$1.0 & 99.3$\pm$0.1\\
& & 6x & 30.8$\pm$1.6 & 80.3$\pm$2.6 & 30.9$\pm$1.5 & 74.1$\pm$2.7 & 39.3$\pm$1.4 & 95.7$\pm$0.9\\
  \cline{2-9}
&\multirow{2}{*}{GAN\SB{cond}}   & 3x& 39.0$\pm$0.8 & 95.1$\pm$0.5 & 35.8$\pm$1.1 & 89.5$\pm$1.5 & 41.5$\pm$0.9 & 98.4$\pm$0.2\\
&& 6x & 36.4$\pm$1.0 & 92.2$\pm$1.0 & 33.4$\pm$1.2 & 83.3$\pm$2.4 & 37.4$\pm$1.0 & 95.8$\pm$0.6\\
  \cline{2-9}
& \multirow{2}{*}{GIMP}   & 3x & 47.5$\pm$0.9 & 98.8$\pm$0.2 & 43.6$\pm$1.2 & 97.5$\pm$0.4 & 52.2$\pm$1.1 & 99.7$\pm$0.1 \\
&& 6x & 40.8$\pm$0.9 & 95.7$\pm$0.5 & 38.0$\pm$1.3  & 91.6$\pm$1.3 & 43.6$\pm$1.0  & 98.4$\pm$0.2\\
 \hline
 \multirow{10}{*}{\rotatebox[origin=c]{90}{\textbf{Fed}}}&\multirow{2}{*}{FL-MRCM}   & 3x & 37.7$\pm$0.8 & 94.8$\pm$0.8 & 35.8$\pm$1.2 & 88.5$\pm$2.3 & 37.9$\pm$0.8 & 96.0$\pm$0.7\\
&& 6x & 36.3$\pm$1.0 & 93.0$\pm$0.7 & 34.2$\pm$1.3 & 83.9$\pm$1.7 & 35.9$\pm$0.9 & 94.7$\pm$0.6\\
   \cline{2-9}
&\multirow{2}{*}{FedGAN}  & 3x & 38.4$\pm$0.8 & 95.0$\pm$0.5 & 36.1$\pm$1.2 & 88.7$\pm$1.7 & 39.7$\pm$0.9 & 97.7$\pm$0.4\\
&& 6x & 36.0$\pm$1.1 & 92.6$\pm$0.9 & 34.2$\pm$1.2 & 84.0$\pm$2.3 & 36.2$\pm$1.1 & 95.3$\pm$0.7\\
  \cline{2-9}
&\multirow{2}{*}{LG-Fed}   & 3x& 38.6$\pm$0.7 & 95.1$\pm$0.5 & 35.8$\pm$1.2 & 88.2$\pm$1.7 & 41.3$\pm$0.8 & 98.1$\pm$0.3\\
&& 6x& 36.2$\pm$1.0 & 92.8$\pm$0.9 & 34.0$\pm$1.2 & 83.5$\pm$2.4 & 37.4$\pm$1.1 & 96.1$\pm$0.6 \\
  \cline{2-9}
 &\multirow{2}{*}{FedMRI}  & 3x& 38.9$\pm$0.8 & 95.1$\pm$0.5 & 35.9$\pm$1.2 & 88.0$\pm$1.8 & 40.8$\pm$0.8 & 98.2$\pm$0.3\\
&& 6x& 36.2$\pm$1.0 & 92.8$\pm$0.9 & 34.1$\pm$1.2 & 83.3$\pm$2.4 & 37.6$\pm$1.0 & 95.9$\pm$0.6\\
  \cline{2-9}

&\multirow{2}{*}{FedGIMP}   & 3x& \textbf{47.2$\pm$0.9} &\textbf{98.7$\pm$0.2} & \textbf{43.3$\pm$1.2} &\textbf{97.4$\pm$0.4} & \textbf{52.8$\pm$1.2} &\textbf{99.6$\pm$0.1}\\
&& 6x& \textbf{40.7$\pm$0.9} &\textbf{95.7$\pm$0.5}& \textbf{37.9$\pm$1.3} &\textbf{91.5$\pm$1.4} & \textbf{44.0$\pm$1.0} &\textbf{98.5$\pm$0.2} \\
\hline
\end{tabular}
}
\label{tab:cross_mc}
\end{table}



\subsubsection*{Domain shifts in the imaging operator}
We also evaluated reconstruction performance under additional domain shifts due to mismatched imaging operators with different acceleration rates across the training-test sets (Table \ref{tab:cross_mc}). FedGIMP is the top performer among competing methods (p$<$0.05), except for GIMP that performs similarly. FedGIMP offers 6.9dB PSNR, 4.5\% SSIM improvement over the second-best FL method. Representative reconstructions are shown in Fig. \ref{fig:multicoil}. LORAKS suffers from noise amplification, and conditional models yield notable blur and artifacts. In contrast, FedGIMP achieves high visual acuity while mitigating noise amplification. 


 
\subsection{Heterogeneity of MRI Data}
FL of a multi-site model on homogeneous datasets would correspond to training on more samples from a common distribution, and model performance would solely reflect the influence of prolonged training. To rule out this nuisance explanation, we first measured the intra-site and inter-site heterogeneity of cross-sectional images in the training set. For intra-site heterogeneity, the image distributions were compared among individual subjects within a given site. For inter-site heterogeneity, the image distributions were compared among individual subjects from separate sites. Frechet inception distance (FID) was used to measure dissimilarity of distributions. As shown in Fig. \ref{fig:heterogeneity}, we find varying albeit notable levels of heterogeneity in each site. Importantly, inter-site heterogeneity is significantly higher than intra-site heterogeneity for all sites (p$<$0.05). The increase from intra-site to inter-site FID score is 9.2 for single-coil (a 94.1\% increase) and 5.0 for multi-coil (a 105.0\% increase) settings. We then examined the influence of this apparent heterogeneity on single-site models trained on local data from individual sites. Specifically, we assessed the loss incurred in single-site models due to domain shifts in the image distribution between training and test sites. To do this, we measured the  within-site and across-site reconstruction performances of GAN\SB{cond} and GIMP while the imaging operator was matched across sites and training-test sets. We find that across-site performance is lower than within-site performance for both models (p$<$0.05). On average, GAN\SB{cond} suffers from 1.9dB PSNR, 2.0\% SSIM loss in single-coil, and 2.5dB PSNR, 1.8\% SSIM loss in multi-coil reconstruction. In contrast, GIMP shows relatively lower 1.5dB PSNR, 0.6\% SSIM loss in single-coil, and 0.8dB PSNR, 0.2\% SSIM loss in multi-coil reconstruction. Taken together, these findings indicate that our results cannot be attributed to a lack of data heterogeneity across sites. Furthermore, the adaptive GIMP model shows higher reliability against data heterogeneity compared to the non-adaptive GAN\SB{cond} model.

% single-coil, within versus across
% PSNR = 1.90 dB GANcond, 1.54 dB GIMP --gokberk 1.9dB GANcond, 1.5dB GIMP
% SSIM = 1.97 % GANcond, 0.56 % GIMP --gokberk 2.0% GANcond, 0.6% GIMP

% multi-coil, within versus across
% PSNR = 2.5 dB GANcond, 0.82 dB GIMP --gokberk 2.5dB GANcond, 0.8dB GIMP
% SSIM = 1.8 % GANcond, 0.16 % GIMP --gokberk 1.8% GANcond, 0.2% GIMP






\subsection{Ablation Studies}
Several lines of ablation studies were conducted to demonstrate the individual design elements in FedGIMP. To assess the contribution of using an adaptive prior, we built a static-prior variant that optimized model inputs but kept model weights fixed as in \cite{Konukoglu2019}. To assess the federated training of the prior, we built an untrained variant where inference adaptation was performed on a randomly initialized generator. To assess the mapper, we built a mapper-ablated variant that only used a synthesizer as in \cite{Knoll2019inverseGANs}. To assess the site index, we built a site-index-ablated variant that used a mapper producing site-general latent variables. To assess the mapper adaptation to indirectly optimize latents, we built a static-mapper variant that directly optimized latents as in \cite{korkmaz2021unsupervised}. Table \ref{tab:ablation} demonstrates that FedGIMP outperforms all ablated variants consistently across sites. These results indicate the importance of prior adaptation, learning of a high-quality prior, inclusion of the mapper, inclusion of the site index, and indirect optimization of latents for improving MRI reconstruction performance. In particular, utilizing a site-index in the mapper achieves 1.1dB PSNR and 0.5\% SSIM improvement, and in theory the benefits of the site index should increase further for growing number of sites and data heterogeneity. 




\begin{figure}[t]
\centering
\includegraphics[width=1.0\columnwidth]{figure05.png}
\caption{Heterogeneity of MRI datasets were examined by measuring FID between respective image distributions, reported as mean$\pm$se (error bars) across subjects. Intra-site (blue) and inter-site (orange) heterogeneity is shown for each dataset examined for (a) single-coil, (b) multi-coil reconstruction.}
\label{fig:heterogeneity}
\end{figure}




Next, we evaluated the influence of the site index on practicality when a site joins or leaves training abruptly. Note that an additional site can join training by designating spare digits in the site-index vector, and an existing site can easily abstain from training given that its digit in the site-index vector is not reassigned to a different site. Thus, we examined FedGIMP's performance under scenarios where an initially held-out site joined the training halfway, and where an initially included site left the training halfway. In both scenarios, FedGIMP was compared against the site-index-ablated variant, and against the original model trained with all sites intact. Performance metrics are listed in Table \ref{tab:site-in-out}. FedGIMP with joining or abstaining sites outperforms the ablated variant by 1.2dB PSNR, 0.6\% SSIM on average; and it offers similar performance to the original FedGIMP trained with all sites intact. These results suggest that the site index does not limit practicality of model training, and it rather introduces a degree of reliability against joining or abstaining sites. 

Lastly, we examined the utility of local discriminators in FedGIMP. A primary benefit of unshared discriminators is theoretical improvements in privacy against inference attacks \cite{ganleaks}. Local discriminators also reduce communication load by 46.7\% for FedGIMP, given that the discriminator and generator have comparable complexity (23.0 versus 26.3 million parameters). Beyond these theoretical benefits, we assessed the influence of local discriminators on model performance. First, we inspected the training losses for the generator (unreported). The loss curves showed smooth behavior across training epochs, with no apparent signs of mode collapse \cite{StyleGAN1}. Second, we compared FedGIMP against a variant with shared discriminators across sites. Metrics in Table  \ref{tab:site-in-out} indicate on par performance with both models. These results suggest that there are no apparent performance drawbacks to using local discriminators.






%%%%%%%%%%%%%%%%Ablation 
%%%%%%%%multi-coil
\begin{table}[t]
\centering
\caption{Reconstruction performance of FedGIMP and ablated variants at R=3x, with matched imaging operators across sites.}
\resizebox{0.5\textwidth}{!}
{
\begin{tabular}{| l  |  Sc | Sc | Sc | Sc | Sc | Sc |  }
\hline
 &  \multicolumn{2}{Sc|}{IXI} & \multicolumn{2}{Sc|}{fastMRI} & \multicolumn{2}{Sc|}{BRATS}\\
\hline
{}    &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$   & PSNR $\uparrow$   & SSIM$\uparrow$ \\
 \hline

\multirow{1}{*}{Static Prior} &  29.5$\pm$0.7 &  71.5$\pm$2.4 &  30.5$\pm$1.9 &  74.9$\pm$4.8 &  34.5$\pm$1.2 &   88.0$\pm$1.9\\
\hline
\multirow{1}{*}{Untrained} & 34.7$\pm$1.0 & 88.6$\pm$1.9 & 35.4$\pm$2.0 & 90.3$\pm$2.4 & 38.7$\pm$1.4 & 95.4$\pm$1.1  \\
\hline
\multirow{1}{*}{No Mapper} & 40.1$\pm$1.2 & 97.0$\pm$0.7 & 38.8$\pm$2.0 & 95.7$\pm$1.2 & 47.2$\pm$1.8 & 
99.2$\pm$0.3  \\
\hline
\multirow{1}{*}{No Site-Index}   & 41.0$\pm$1.3 & 97.7$\pm$0.7 & 40.2$\pm$2.1 & 96.8$\pm$1.0 & 50.5$\pm$1.9 & 99.6$\pm$0.2 \\
\hline
\multirow{1}{*}{Static Mapper}   & 42.3$\pm$1.4 & 98.2$\pm$0.5 & 40.7$\pm$2.2 & 97.1$\pm$0.9 &  50.6$\pm$1.9 &  99.6$\pm$0.1 \\
\hline
\multirow{1}{*}{FedGIMP}   & \textbf{42.9$\pm$1.5} & \textbf{98.5$\pm$0.5} & \textbf{41.1$\pm$2.2} & \textbf{97.4$\pm$0.8} & \textbf{50.9$\pm$1.9} & \textbf{99.7$\pm$0.1}\\
\hline
\end{tabular}}
\label{tab:ablation}
\end{table}



\begin{table}[t]
\centering
\caption{Reconstruction performance at R=3x with matched imaging operators. Results listed for FedGIMP with all sites, a joining site (FedGIMP-join), and an abstaining site (FedGIMP-abs); for the site-index-ablated variant with a joining site (NSI-join) and an abstaining site (NSI-abs); and for a variant with shared discriminators. The joining and abstaining sites were taken as BRATS.}
\resizebox{0.5\textwidth}{!}
{
\begin{tabular}{| l  |  Sc | Sc | Sc | Sc | Sc | Sc |  }
\hline
 &  \multicolumn{2}{Sc|}{IXI} & \multicolumn{2}{Sc|}{fastMRI} & \multicolumn{2}{Sc|}{BRATS}\\
\hline
{}    &PSNR $\uparrow$   & SSIM$\uparrow$    & PSNR $\uparrow$   & SSIM$\uparrow$   & PSNR $\uparrow$   & SSIM$\uparrow$ \\
 \hline
\multirow{1}{*}{FedGIMP}   & 42.9$\pm$1.5 & 98.5$\pm$0.5 & 41.1$\pm$2.2 & 97.4$\pm$0.8 & 50.9$\pm$1.9 & 99.7$\pm$0.1\\
\hline
\multirow{1}{*}{FedGIMP-join} &  42.7$\pm$1.4 &  98.4$\pm$0.5 &  41.0$\pm$2.2 &  97.3$\pm$0.9 &  50.6$\pm$1.9 &   99.7$\pm$0.1\\
\hline
\multirow{1}{*}{FedGIMP-abs} & 43.0$\pm$1.6 & 98.5$\pm$0.5 & 41.0$\pm$2.3 & 97.3$\pm$0.9 & 50.9$\pm$2.0 & 99.7$\pm$0.1\\
\hline
\multirow{1}{*}{NSI-join} &  40.9$\pm$1.2 &  97.5$\pm$0.6 &  39.9$\pm$2.2 &  96.6$\pm$1.1 &  49.8$\pm$1.9 &   99.6$\pm$0.2\\
\hline
\multirow{1}{*}{NSI-abs} & 40.4$\pm$1.2 & 97.2$\pm$0.7 & 40.1$\pm$2.1 & 96.8$\pm$1.0 & 50.7$\pm$1.9 & 99.7$\pm$0.1\\
\hline

\multirow{1}{*}{Shared $D$} & 42.9$\pm$1.5 & 98.4$\pm$0.5 & 41.2$\pm$2.2 & 97.4$\pm$0.8 & 51.1$\pm$1.9 & 
99.7$\pm$0.1\\
\hline
\end{tabular}}
\label{tab:site-in-out}
\end{table}


\begin{table}[t]
\centering
\caption{Average inference time in secs per cross-section for single-coil and multi-coil reconstructions.}
\resizebox{0.30\textwidth}{!}
{
\begin{tabular}{| l | Sc | Sc | Sc |}
\hline
 & LORAKS & Non-adaptive & Adaptive \\
\hline
Single-coil & 2.40 & 0.034 & 20.30 \\
\hline
Multi-coil & 6.99 &  0.080 & 27.89 \\
\hline
\end{tabular}}
\label{tab:inference-times}
\end{table}

\subsection{Inference Times}
Inference times of competing methods are listed in Table \ref{tab:inference-times}. Matching architectures yield near identical inference time, so results are reported for LORAKS, non-adaptive models (GAN\SB{cond}, FL-MRCM, FedGAN, LG-Fed, FedMRI), and adaptive models (GIMP, FedGIMP). Inference time for adaptive models is high compared to non-adaptive models that use a single forward pass, and it is relatively more proximate to LORAKS. Yet, this computational load enables substantial benefits in reconstruction performance. For instance, FedGIMP achieves 10.4dB PSNR, 14.7\% SSIM improvement over LORAKS, and 6.0dB PSNR, 3.1\% SSIM improvement over the top-contending non-adaptive model across single- and multi-reconstruction tasks at R=3x with matched imaging operators across sites and training/test sets. Furthermore, FedGIMP enhances tissue depiction visually with lower artifacts and higher acuity than competing methods. Note also that FedGIMP’s performance increases across inference iterations, so the number of iterations can be adjusted to maximize performance per available compute time in specific applications. Thus, FedGIMP offers a flexible trade-off between reconstruction quality and compute time, which might facilitate practical use. 


\section{Discussion}
Multi-site imaging data collected under diverse protocols/devices can contain heterogeneity in the image distribution and the imaging operator across sites, as well as across the training-test sets \cite{li2021fedbn}. Recent studies have proposed latent-space alignment or split-network approaches based on conditional reconstruction models to address across-site heterogeneity \cite{guo2021,feng2021}. Yet, conditional models are susceptible to domain shifts in the imaging operator pertained to undersampled data \cite{korkmaz2021unsupervised}. In contrast, FedGIMP decouples the undersampling characteristics from the prior to improve reliability against heterogeneity in the imaging operator. Experiments on multi-site datasets demonstrate that FedGIMP yields superior performance against federated conditional models under various imaging scenarios with varying acceleration rates, sampling density across sites, and across the training-test sets. Therefore, FedGIMP can improve flexibility in multi-site collaborations by permitting heterogeneous protocols.   

A practical concern for MRI reconstruction is the computational cost of training and inference. Here, we primarily considered adversarial architectures for competing methods. Previous conditional methods additionally compute either a cross-site alignment loss on latent-space representations \cite{guo2021}, or a weighted-contrastive loss across sites based on local encoder weights \cite{feng2021}. Furthermore, while conditional models are retrained for each configuration of acceleration rate and sampling density, FedGIMP trains a single MRI prior to reconstruct with various different imaging operators. Thus, FedGIMP offers a simpler training procedure. During inference, conditional models offer fast processing in a single forward-pass, whereas FedGIMP uses an iterative prior adaptation that elevates computational burden. Still, FedGIMP's inference time is generally compatible with clinically-adopted implementations of traditional reconstruction methods, implying practical feasability \cite{Haldar2016,l1SPIRiT}. To improve efficiency in time-critical applications, prior adaptation across an MRI volume can be accelerated by parallel computation via distributing cross-sections across multiple GPUs.

GAN models are commonly trained to generate new image samples from low-dimensional random variables \cite{StyleGAN1}. While the stochasticity of generated images may be undesirable for reconstruction, previous studies have employed GAN-based methods to recover MRI images without notable hallucinations \cite{Quan2018c,Mardani2019b,Knoll2019inverseGANs,rgan,lei2020,oh2020}. To prevent artificial structures, these methods have incorporated data-consistency modules. Similarly in FedGIMP, the subject-specific prior adaptation based on data-consistency constrains the reconstruction by incorporating information regarding coil sensitivities, sampling patterns and measured k-space data from the actual subject. Under this control procedure, we have not encountered artificial structures based on our visual inspections, as also indicated by high performance metrics across various datasets. Multi-site data analyzed here for single- and multi-coil reconstructions generally contained a considerable number of subjects. While the In-House dataset had relatively fewer subjects, we analyzed it given the scarcity of public datasets providing multi-coil, multi-contrast MRI data. It remains important future work to systematically validate the proposed method and its anatomical fidelity on broader patient cohorts.

FL methods transfer model weights across sites instead of MRI data to lower privacy risks. Still, security concerns can arise from backdoor attacks where an adversary poisons training updates to corrupt models and elicits diagnostically-inaccurate reconstructions \cite{Kaissis2020}. Previously proposed non-adaptive models freezing model weights following training can be more sensitive to model corruption. In contrast, FedGIMP adapts its MRI prior to each test sample, so it can potentially alleviate corruption during inference \cite{aggarwal2021}. Learning-based models can also be vulnerable to inference attacks on models aiming to leak sensitive information about training data \cite{Kaissis2020}. Differential privacy between training and synthetic samples in adversarial models substantially improves for large and diverse training datasets as encountered in FL settings \cite{FengICCV2021}. Furthermore, FedGIMP uses a shared generator without direct access to data and unshared discriminators that are not communicated \cite{Han2020}. Nonetheless, resilience against inference attacks can be improved by adopting differential-privacy procedures \cite{FedDPGAN,ziller2021}. Future studies are warranted to systematically characterize the privacy-preserving abilities of FedGIMP, including the benefits of local discriminators.

Here we aggregated local models using the relatively common and simple FedAvg algorithm, which has been successfully employed in many previous FL studies \cite{McMahan2017CommunicationEfficientLO}. Model aggregation was performed via a weighted linear combination, where the weight for each site is taken as the ratio of the number of local training samples to the number of all training samples across sites. Performance improvements might be possible with data-driven combination based on model comparisons \cite{FedFomo} or neural networks \cite{pFedHL}. However, data-driven model combination typically involves storage and computation of additional models, and transfer of additional model updates. Future work is warranted to examine the comparative benefits of unlearned versus learned aggregation of local models in MRI reconstruction. 

FedGIMP trains an MRI prior over the distribution of high-quality MR images, uninformed regarding the reconstruction task. Several lines of development can be considered for improved performance. First, multi-supervised networks concurrently operating in image and k-space domains have recently been introduced for MRI reconstruction \cite{KikiNet,wang2022}. FedGIMP might also benefit from a hybrid of image and k-space MR priors. Second, self-supervised training of parallel networks based on contrastive learning has been proposed \cite{hu2021,wang2022b}. Contrastive learning strategies might alleviate the need for fully-sampled acquisitions for training the MRI prior in FedGIMP. In principle, the federated prior can be adapted for other inverse problems such as MRI super-resolution or synthesis. A simple approach would be to train task-specific models using a synthetic dataset generated via the MRI prior. Alternatively, the trained prior can serve as a non-adaptive plug-and-play regularizer in optimization problems \cite{Konukoglu2019}. To adapt the prior during inference, the imaging operator for the reconstruction task would have to be replaced with corresponding operators in target tasks. 


\section{Conclusion}
Here, we introduced a novel MRI reconstruction based on federated learning of a generative MRI prior and inference adaptation via injection of subject-specific imaging operators onto this prior. Benefits over state-of-the-art federated and traditional methods were demonstrated in multi-site MRI datasets. Improved generalization against domain shifts renders FedGIMP a promising candidate for multi-site collaborations in accelerated MRI. FedGIMP might also be used for physics-based reconstruction in other modalities such as CT, PET, or ultrasound by modifying its imaging operator. 



\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,Papers}


\end{document}

