\section{Conclusion}
We have highlighted the reasons of ERM training limitations in non-stationary drifting scenarios, which causes models to miss out on learning temporal invariant features. To this end,  we first have constructed environments with different time spans for the training set to reveal information about changes in the data distribution. Then, we have built on invariant learning theory and have proposed a targeted end-to-end training strategy for malware detectors that integrates dual alignment of feature representations and classifier gradients to ensure that empirical risk is minimized within environments, while facilitating consistent representation learning across environments. 
%Our approach can be seamlessly integrated into existing malware detectors. 
Evaluations on datasets with different drift levels and time spans have shown that our approach significantly improves the robustness of models against drift, with increasing F1 scores by up to 8.10\% (4.63\% on avg) and AUT(F1, 5 years) of up to 4.75\% (overall about 3\%), while reducing the FNR by up to 49.89\% (17.55\% on avg). We also believe our approach can play a pivotal role in reducing the retraining frequency in continual learning settings, providing a feasible strategy to reduce the operational cost and resource requirements for malware detection. We plan to explore this direction as future work.