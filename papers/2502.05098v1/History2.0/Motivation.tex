\section{Motivation}

In this section, we explain the reasons behind the vulnerability of learning-based malware detectors when facing concept drift from the perspective of the underlying features' properties. Then, we highlight the necessity of employing temporal invariant learning to enhance the robustness of malware detectors in drifting scenarios. 
% \lc{Note: I removed the reference to NN and phrased as learning-based approaches.}

\subsection{Experiment Settings}

We perform the following empirical analysis using the Transcendent dataset provided by Barbero et al.~\cite{transcending}, which is primarily used to study concept drift and related rejection strategies of the underlying abstaining classifiers in Android malware detection tasks, with samples obtained from AndroZoo~\cite{androzoo}. The dataset includes 10\% of malware, following recommendations of Pendlebury et al.~\cite{tesseract}, covering five years from 2014 to 2018. Due to the incomplete family labeling provided, all samples containing accurate family labels were selected here and the benign samples corresponding to the time interval were randomly extracted based on this ratio. Detailed information about the dataset is provided in Section~\ref{sec5:dataset}. 

We trained models for each experiment following the settings in DeepDrebin~\cite{deepdrebin}, i.e., neural networks with three fully connected layers of size 200.

\begin{figure*}
    \centering
    \setlength{\abovecaptionskip}{0.cm}
    \includegraphics[width=1.00\linewidth]{Fig/family_distribution.pdf}
    \caption{Data distribution in the input space of the top 5 most prevalent malware families in the training set}
    \label{fig:family_distribution}
\end{figure*}

\subsection{Invariance in Malware Evolution}
Malware families commonly evolve to circumvent new detection techniques and security measures, resulting in constant changes in their code implementations and API calls. However, we find that while their code implementations and specific calls are adapted in response to detection, their core malicious behaviors and logic tend to remain stable throughout their evolution.

\subsection{The Contribution of Features to Detectors}
 Let $r \in \mathcal{R}$ represent an application sample in raw data space, with $y \in \mathcal{Y} = \{0, 1\}$ indicating the corresponding labels, where 0 denotes goodware and 1 denotes malware. The input feature vector $x \in \mathcal{X}$ consists of features $\mathcal{F}$ extracted from $r$ according to certain rules. Since the problem of concept drift in malware detection occurs over time, we partition the input features to be learned on both spatial and temporal scales. 

 In the context of a specific temporal span, the features learned by the model can be categorized into discriminative and non-discriminative features. Discriminative features enhance the detection performance of the model by minimizing empirical risk, enabling it to distinguish between malware and benign applications accurately. The definition of discriminative features is as follows:

\begin{myDef}
\label{Discriminative}
Given a set of features $\mathcal{F}$ and a set of labels $\mathcal{Y}$, the discriminative feature subset $\mathcal{F}_d \subset \mathcal{F}$ satisfies:
\begin{equation}
\mathcal{F}_d=\arg \min _{\mathcal{F}^{\prime} \subset \mathcal{F}} R_{erm}\left(\mathcal{F}^{\prime}\right),
\end{equation}
\end{myDef}
where $R_{erm}(\mathcal{F}')$ represents the empirical risk based on the subset of features $\mathcal{F}'$, defined as:
\begin{equation}
R_{erm}\left(\mathcal{F}^{\prime}\right)=\mathbb{E}[\ell(f(x), y)]
\end{equation}
$\ell(f(x), y)$ is a loss function. By minimizing the empirical risk, $\mathcal{F}_d$ achieves the lowest overall prediction error on the given dataset.

On a temporal scale, as the distribution of input samples changes over time, the features learned by the model can be divided based on stability. We posit that, despite the potential emergence of new malware variants in the future, the semantic behaviors of malicious activities tend to exhibit similarities. These may be reflected in shared behavioral traits, code similarities, or common objectives distinguishing malicious software from benign applications. Therefore, when facing unknown distributions, it is reasonable to assume that some features are stable and shared. We refer to these characteristics as stable features and define them as follows:
\begin{myDef}
\label{Stable}
Given a set of features $\mathcal{F}$, a subset $\mathcal{F}_s \subset \mathcal{F}$ is defined as a set of stable features if every feature $\mathcal{F}^{\prime} \in \mathcal{F}_s$ demonstrates relatively consistent importance across various time points $t_1, t_2, \ldots, t_T$.
\end{myDef}

Based on the aforementioned definitions, we can naturally derive the conditions that an ideal malware detector should meet to robustly handle concept drift: the feature representation should include as many discriminative and stable feature abstractions as possible. This vision prompts us to explore the vulnerabilities of current malware detectors and their underlearning of these two types of features, helping us to identify the reasons behind the limited performance of detectors and propose potential solutions.

\subsection{Limitations of Malware Detectors}
\subsubsection{Failure due to learning discriminative but unstable features}
A high performance on the test set over the same temporal horizon suggests the model has learned discriminative features on the training set to distinguish between goodware and malware. Here we explore the relationship between the importance of discriminative features and the performance degradation of the malware detector over time from the perspective of feature attribution. Following the suggestions by Warnecke et al.~\cite{IG_explain} on white-box explanations in cybersecurity, we employ Integrated Gradients (IG)~\cite{IG}, a method from the domain of Explainable Artificial Intelligence (XAI), as our tool for assessing feature importance. This technique determines the features that most significantly influence individual predictions by computing the integral of the gradient changes along the path from the baseline (typically a neutral point like a vector of zeros) to the input sample. To ensure a robust assessment of feature importance, binary noise is introduced to each sample, and the contribution of different features to the output inference is averaged over five runs. We choose the malware family AIRPUSH as a use case as it has a sufficient sample size throughout the temporal period considered.
% \lc{What is the path from the baseline?}

We divide the dataset containing goodware and the AIRPUSH family into five periods from 2014 to 2018, with data each year split into training and testing sets in an 80/20 ratio. Subsequently, the corresponding detectors are trained separately for each period's training set and we assess the features importance in each malware detector. Each test set includes only the AIRPUSH malware family and benign samples from the corresponding temporal period. Figure~\ref{fig:heatmap} shows the normalized changes in features importance, highlighting the top-100 features the model trained on the year 2014 focuses on, and analyzing the degree of attention these features received in subsequent years. The results suggest that some discriminative features that are emphasized in the early years are gradually ignored in later training, whereas features that are not initially emphasized may become important later. The reliance on such discriminative but unstable transient features consequently means that the model does not generalize well to new samples that deviate from the training data over time. 
%This also motivates our interest in exploring the second question of whether the generalization failure problem can be mitigated if the model focuses on stable features.


\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{0.3cm}
    \includegraphics[width=1.00\linewidth]{Fig/F1_family.pdf}
    \caption{The performance of the detectors trained separately for the selected families in the testing year}
    \label{fig:f1_family}
\end{figure}

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{0.cm}
    \includegraphics[width=1.00\linewidth]{Fig/headtmap.pdf}
    \caption{Feature Importance of AIRPUSH Over Years}
    \label{fig:heatmap}
\end{figure}

% \vspace{-0.5em}
\subsubsection{Failure due to learning stable but non-discriminative features}
\label{discriminative features}
If we ignore the role representations have in capturing varying degrees of semantics~\cite{pei2024exploiting}, concept drift in malware detection tasks is mainly caused by the emergence of new malware families, which may exhibit new, previously unseen, behaviors, and the evolution of existing families, which may also realize existing behaviors in unforeseen ways that might be imprecisely captured by the underlying representations~\cite{pei2024exploiting}. Thus, for existing malware families exhibiting fewer variants over time, it is reasonable to assume the model learns more stable features because the input data space is less variable.

To validate this rationale, we first selected the five most popular malware families from the training set and plotted their distribution in the data space over time, as shown in Figure ~\ref{fig:family_distribution}, where different colors represent samples from different years. Families such as DOWGIN, REVMOB, and LEADBOLT maintain a high consistency with their data distributions from the training year (2014). Even though the popularity of these families decreases over time, their distributions are still a sample of the original ones.

Afterwards, we took samples from these five families from 2014, divided them into training and validation sets in a 80/20 split, including benign samples from the same period, and trained five detectors. Each year, these detectors were tested on datasets containing only their respective families and benign samples. We evaluate Precision and Recall of the malicious class and show them in Figure~\ref{fig:f1_family}. The results reveal that for REVMOB and LEADBOLT, almost all malware are successfully detected, i.e., their high Recall remains steady over subsequent years, suggesting the models learned stable features for these families. However, in contrast, the false positive rate increases substantially, and the discriminatory nature of these stable features for goodware and malware is in decline. This further suggests that focusing on stability only during training is also suboptimal, as it leads to a detector diverging from its original training goal.

\subsection{Learning Invariant Features}

Our preceding discussion has examined the limitations of malware detectors from the perspective of feature analysis, prompting us to recognize that if a detector is to remain robust in the face of concept drift, it must focus on both discriminability and stability. Learning discriminative features is relatively straightforward, as ERM training helps identify features most strongly correlated with the target variable, the challenge lies in finding the stable components within these discriminative features. This is consistent with the goal of invariant learning introduced in Section~\ref{invariant_learning}.

However, applying invariant learning methods is challenging. Its effectiveness presupposes firstly that the environment segmentation can maximize the unstable information that the model needs to forget~\cite{environment_label, env_label}. In malware detection, it is uncertain which application variants will trigger distributional changes. In addition, an invariant predictor cannot focus solely on stable features, but also needs to ensure that these features are well-fitted to the training data~\cite{yang2024invariant}, which requires the encoder to have a good feature learning capability to provide the invariant predictor with information that can be effectively used for discriminative and invariant learning. Thus, given arbitrary malware detectors, our scheme aims to further extend the learning capability of the encoder to provide more learnable information to the invariant predictor by relying only on the time-aware environment segmentation. Minimizing the invariant risk, in turn, filters out instability in the feature representation, thus further enhancing the generalization ability of the malware detector to the concept drift.

