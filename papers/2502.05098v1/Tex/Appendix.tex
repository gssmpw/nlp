\section{Dataset Description}
\label{dataset}

\subsection{Sample selection}
We construct a dataset spanning 2014 to 2023 using samples from the Androzoo\footnote{https://androzoo.uni.lu} platform, a comprehensive repository aggregating samples from sources such as Google Play, PlayDrone, VirusShare, and AppChina. Each sample's timestamp corresponds to its submission date on VirusTotal\footnote{https://www.virustotal.com}, representing the time it was discovered. The dataset includes a decade of benign and malicious samples, labeled based on VirusTotal analysis from Androzoo. Samples flagged by more than four vendors are classified as malicious. To track malware family evolution, we used Euphony~\cite{euphony} to extract family labels. The dataset comprises 193,978 benign apps and 23,302 malicious apps. To mitigate temporal and spatial biases, we applied the TESSERACT~\cite{tesseract} methodology. In our experiments, the training set consists solely of 2014 samples. The dataset's class distribution, shown in Table~\ref{dataset}, reflects real-world proportions of benign and malicious samples.

\subsection{Timestamp selection}
In Android malware, the dex date is often manipulated or invalid (e.g., many applications display 1980), and the upload date on Androzoo does not necessarily reflect the actual release date of the application. Aware of this issue, we choose to use the observation date of applications on malware detection platforms, such as the ``first submission date'' provided by VirusTotal, as a more reliable alternative. Due to API access limitations, we selected 10\% of newer samples from the dataset (where dex dates are even less reliable) to verify their first submission date on VirusTotal. Comparisons revealed that these dates closely align with the $vt\_scan\_date$ provided by Androzoo. For the full dataset, we therefore approximate the observation date using $vt\_scan\_date$, referred to as the ``application observation date'' in the manuscript. 

% To evaluate the effectiveness of our approach in the context of long-term malware evolution, we select Android APKs from the Androzoo\footnote{https://androzoo.uni.lu} platform, a comprehensive repository aggregating malicious samples from sources like Google Play, PlayDrone, VirusShare, and AppChina. The dataset spans 2014 to 2023, covering ten years of benign and malicious samples. Each sample was analyzed using VirusTotal\footnote{https://www.virustotal.com} and classified as malicious if flagged by more than four vendors. To track malware family evolution, we use Euphony~\cite{euphony} to extract family labels. The dataset includes 251,394 benign and 46,724 malicious applications across 639 families. We adhere to the methodology proposed by TESSERACT~\cite{tesseract} to eliminate potential temporal and spatial biases. The training set covers the year 2014 and the test set the remaining 9 years, from 2015 to 2021. Additionally, the training set is further split into proper training (80\%) and validation (20\%) across all the experimental settings.

\input{Table/Dataset_overall}

\section{Candidate Detectors}
\label{candidate}

Details of each candidate detector are as follows:

\textbf{Drebin}: Drebin~\cite{Arpdrebin} is a malware detector using binary feature vectors from nine data types (e.g., hardware, API calls, permissions) for linear classification. To align with our framework's focus on neural network architectures, we include its deep learning variant, DeepDrebin~\cite{Grossedeepdrebin}, which uses the same feature space but employs a three-layer deep neural network (DNN) for feature extraction and classification.

\textbf{Malscan}: Malscan~\cite{malscan} adopts a graph-based feature space, extracting sensitive API calls from APKs and combining four centrality measures (degree, Katz, proximity, and harmonic wave centralities) as features. We concatenate these features according to the optimal method detailed in the paper for detection tasks.

\textbf{BERTroid}: BERTroid~\cite{bertroid} leverages Android application permission strings, encoding them into dense representations with a BERT-based pre-trained model that captures contextual relationships among permissions. For this study, we use the pooled BERT output as the feature representation for malware detection.
    


\section{Baseline}
\label{baseline}
Details of each baseline are as follows:

\textbf{APIGraph}: APIGraph~\cite{apigraph} clusters APIs, exceptions, and permissions based on semantic similarities from official documentation, creating an API semantic relationship graph. Similar APIs are represented by a clustered index, forming a stable feature space. From the original method, we derive 2,000 clusters, replacing all features within the same cluster with the corresponding index. 

\textbf{Guided Retraining}: Guided Retraining~\cite{guide_retraining} improves malware detection by re-partitioning and retraining on challenging samples. Samples are categorized using the base model’s confusion matrix (TN, TP, FN, FP), and supervised contrastive learning extracts group-specific feature representations, enabling separate processing of easy and difficult samples during inference for better accuracy.

\textbf{T-stability}: T-stability~\cite{svm_ce} introduces t-stability, a metric for SVM models with the Drebin feature space, measuring feature instability via the slope of expected values over time. Then, the above unstable features are constrained to enhance robustness.

As APIGraph and T-stability are tailored to specific feature spaces-APIGraph focusing on API call methods and T-stability on manually selected Drebin~\cite{Arpdrebin} features—we use each scheme’s applicable feature space for experiments.



\section{Invariant Training Algorithm}
\label{inv_alg}


The proposed invariant training process is shown in Algorithm~\ref{alg1}. This learning framework consists of two phases: discriminative information amplification and unstable information suppression. In Stage 1, the model enhances its ability to learn discriminative features through empirical risk minimization (ERM). Specifically, in Line 6, the classification loss $\mathcal{L}^{e}_{CLS}$ is calculated for each environment to ensure correct class separation, and in Line 7, a multi-proxy contrastive (MPC) loss $\mathcal{L}^{e}_{MPC}$ is computed to improve the discriminative power among samples. The combined loss for ERM, including the classification and contrastive components, is computed in Line 9, and then the model is updated by backpropagation in Line 10. Stage 2 focuses on suppressing unstable information through invariant training. In Line 14, the optimizer is reset to remove the influence of previous training, while the model parameters from Stage 1 are retained in Line 15 to preserve the learned discriminative capabilities. Line 21 calculates the invariant gradient alignment (IGA) loss $\mathcal{L}_{IGA}$. Line 22 calculates overall classification loss for complete samples. The combined invariant risk minimization (IRM) loss is formed in Line 24, integrating the classification, contrastive, and alignment losses and updating the model in Line 25. This two-phase training process enables the model to learn discriminative and stable features, improving robustness and generalization in the face of distribution drift.

\input{Algorithm/Invariant_training}


