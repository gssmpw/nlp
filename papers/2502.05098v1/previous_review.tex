% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.0
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex apssamp.tex
%  2)  bibtex apssamp
%  3)  latex apssamp.tex
%  4)  latex apssamp.tex
%
%\documentclass[prb,showkeys,preprintnumbers,amsmath,amssymb, 11pt]{revtex4}
%\documentclass[preprint,showpacs,showkeys,preprintnumbers,amsmath,amssymb]{revtex4}

% Some other (several out of many) possibilities
%\documentclass[preprint,aps]{revtex4}
%\documentclass[aps, two column, amsmath,amssymb,floatfix]{revtex4}
%\documentclass[showkeys,showpacs,amsmath,amssymb,onecolumn,superscriptaddress,prl]{revtex4-1}% Physical Review B  
%\documentclass[aps,prl,reprint,showpacs,floatfix,superscriptaddress, onecolumn, 12pt]{revtex4-2}
\documentclass[aps,prl,reprint,showpacs,floatfix,superscriptaddress, onecolumn, 10pt]{scrartcl}

\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{color}
\usepackage{epsfig}
\usepackage{multirow}
\usepackage{mathrsfs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{epstopdf}
\usepackage{subfigure}
\usepackage{autobreak}
\usepackage[utf8]{inputenc}
\usepackage{tcolorbox}
\usepackage{parskip}
\usepackage{fancyvrb}
\usepackage{fvextra}

%Macros for mathematical notations

\newcommand{\V}[1]{\boldsymbol{#1}} %# vector
\newcommand{\M}[1]{\boldsymbol{#1}} %# matrix
\newcommand{\Set}[1]{\mathbb{#1}} %# set
\newcommand{\D}[1]{\Delta#1} %# \D{t} for time step size
\renewcommand{\d}[1]{\delta#1} %# \d{t} for small increment
\newcommand{\norm}[1]{\left\Vert #1\right\Vert } % norm
\newcommand{\abs}[1]{\left|#1\right|} %abs

\newcommand{\grad}{\M{\nabla}} %gradient
\newcommand{\av}[1]{\left\langle #1\right\rangle } %take average

\newcommand{\sM}[1]{\M{\mathcal{#1}}} %matrix in mathcal font
\newcommand{\dprime}{\prime\prime} % double prime
%\global\long\def\i{\iota}
%\renewcommand{\i}{\iota} %i for imaginary unit
%\renewcommand{\i}{\mathsf i} %i for imaginary unit
\newcommand{\follows}{\quad\Rightarrow\quad} %=>
\newcommand{\eqd}{\overset{d}{=}} %=^d
\newcommand{\spe}[1]{\mathscr{#1}}  %important quantities in mathscr font
\newcommand{\eps}{\epsilon}

\newcommand{\ar}[1]{{\color{blue}#1}} % for authors' response

\newtcolorbox{mybox}{colframe = gray!75!black}


\begin{document}
%\preprint{Preprint}

\title{Prior Reviews and Responses}
\author{}
% \date{}

\maketitle

\noindent Dear Reviewers,

We would like to extend our sincere gratitude for your valuable feedback and constructive suggestions on our submission, titled ``Learning Temporal Invariance in Android Malware Detectors''. Below is a summary of the initial review comments received for the previous version of this manuscript, submitted to the IEEE Symposium on Security and Privacy 2025 (Cycle 2).

In this current submission to the USENIX Security Symposium 2025 (Cycle 2), we have made substantial improvements and refinements, carefully addressing the comments raised in prior reviews. Specifically, we conducted multiple passes on the paper to ensure greater clarity, coherence, and relevance of each concept. We have also restructured several sections to better align with the key contributions of our work and incorporated additional experiments and analyses to further substantiate our claims.

In the following, we highlight responses to the main concerns raised by reviewers. We append the verbatim reviews at the end of this manuscript.

%\noindent \textbf{Comments mentioned by previous reviewers: }

\section*{Main feedback in prior reviews}

\begin{mybox}
1. Reviewers suggested considering the applicability of the proposed framework in complex scenarios where malware increasingly uses obfuscation, packing, and encryption to evade feature extraction.
\end{mybox}

TIF learns representations that identify stable (and discriminative) features on a given feature space provided as input; as such, it relies on the existence of some feature space (thus it depends on it) but does not require knowledge about how that feature space is constructed (thus it is agnostic to it). The ability of the underlying feature space to address advanced forms of obfuscation is thus orthogonal to our approach. 
%In other words, TIF is used as an enhancement of the provided feature space, rather than creating new features. 
The design motivation has been mentioned in Section 1 and Section 3.2.

\begin{mybox}
2. Reviewers expressed concerns about the framework's potential resilience to adversarial attacks.
\end{mybox}
Our work focuses on the natural distribution drift of malware, driven by the emergence of new families and modifications to existing ones. This is fundamentally different from adversarial attacks, which evade models through optimal perturbations, requiring distinct solutions for these two challenges. Our approach addresses the long-term challenges posed by natural malware drift, enhancing the robustness of detectors to malware evolution across arbitrary feature spaces, rather than targeting localized, short-term adversarial attacks. Adversarial attacks, as another form of drift, could be explored further in future work. We have claimed our threat model in Section 3.1.

\begin{mybox}
3. Reviewers expressed concerns about time-based environmental classification: the reliability of sample timestamps and the impact of drift factors.
\end{mybox}
For the first concern, we agree with the reviewers' concerns regarding the reliability of sample timestamps. In Android malware, the \verb+dex_date+ is often manipulated or invalid (e.g., many applications display 1980), and the upload date on AndroZoo does not necessarily reflect the actual release date of the application. Aware of this issue, we chose to use the observation date of applications on malware detection platforms, such as the \verb+first_submission_date+ provided by VirusTotal, as a more reliable alternative. Due to API access limitations, we selected 10\% of newer samples from the dataset (where \verb+dex_dates+ are even less reliable) to verify their \verb+first_submission_date+ on VirusTotal. Comparisons revealed that these dates closely align with the \verb+vt_scan_date+ provided by AndroZoo. For the full dataset, we therefore approximate the observation date using \verb+vt_scan_date+, referred to as the \emph{application observation date} in the manuscript. The design details are described in Appendix A.

For the second concern, the design of time-based environment partitioning specifically addresses the challenge of unknown and diverse drift causes. Since it is difficult to pinpoint the exact factors driving future drifts, such as target geographic locations or Android versions, relying on a single factor for partitioning risks overlooks other important contributors. Prior research~\cite{cade,tesseract,transcending,continuous} has highlighted temporal drift in malware, suggesting that regardless of the underlying causes, drift ultimately manifests as distributional changes over time. Therefore, we align with prior works, which rely on time-based partitioning as a practical approach to account for as many drift factors as possible.

\begin{mybox}
4. The reviewer suggests elaborating on the effectiveness of learning stable feature representations at a more detailed level, such as robustness to new and unseen families.
\end{mybox}
Due to variations in the popularity of malware families, some families present in the training set rarely appear in the testing phase~\cite{Drift_forensice} (Also shown in Figure 1 of our submission). For example, if a specific family dominates the training set and covers only a small number of time intervals in the test set, it is difficult for us to show that variants of that family in the test phase do challenge the robustness of the detector. This also makes it impossible to objectively argue for the effectiveness of the approach. Therefore, to avoid this bias, instead of focusing on individual families to evaluate the learning of stable representations, we chose to divide the evaluation into two scenarios. Specifically, in RQ2 of the experiments section, we evaluate the model's performance in more granular scenarios by dividing the test samples into closed-world and open-world settings. The closed-world test set contains only malware families seen during training, while the open-world test set includes entirely new families. Experiments in Section 5.2 (Table 2 and Figure 6) demonstrate TIF's consistent performance improvements and its ability to learn stable representations in both scenarios.


\begin{mybox}
5. The reviewer suggests comparing our scheme (TIF) with traditional ERM regularization methods to show the generalizability advantage of TIF over them.
\end{mybox}
We fully agree with this consideration and have compared our approach with three classic regularization methods (i.e., early stopping, dropout, and L2 regularization) in Section 6.2 of the manuscript. Experimental results demonstrate that our method significantly outperforms these regularization techniques. This is because ERM regularization methods primarily focus on generalizing to validation sets with minimal distribution shift from the training set, as ERM assumes independent and identically distributed (i.i.d.) datasets. However, natural drift introduces more pronounced distribution changes, posing challenges for traditional regularization methods.

\bibliographystyle{abbrv}
\bibliography{reference.bib}

\section*{Original Reviews from IEEE S\&P 2025 (Cycle 2)}

\input{SPreviews.txt}

\end{document}