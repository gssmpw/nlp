@article{abel2017agent,
 author = {Abel, David and Salvatier, John and Stuhlm{\"u}ller, Andreas and Evans, Owain},
 journal = {ArXiv preprint},
 title = {Agent-agnostic human-in-the-loop reinforcement learning},
 url = {https://arxiv.org/abs/1701.04079},
 volume = {abs/1701.04079},
 year = {2017}
}

@article{celemin2019interactive,
  title={An interactive framework for learning continuous actions policies based on corrective feedback},
  author={Celemin, Carlos and Ruiz-del-Solar, Javier},
  journal={Journal of Intelligent \& Robotic Systems},
  volume={95},
  number={1},
  pages={77--97},
  year={2019},
  publisher={Springer}
}

@inproceedings{christiano2017deep,
 author = {Paul F. Christiano and
Jan Leike and
Tom B. Brown and
Miljan Martic and
Shane Legg and
Dario Amodei},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/ChristianoLBMLA17.bib},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {4299--4307},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Deep Reinforcement Learning from Human Preferences},
 url = {https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html},
 year = {2017}
}

@article{dafoe2020open,
  title={Open problems in cooperative AI},
  author={Dafoe, Allan and Hughes, Edward and Bachrach, Yoram and Collins, Tantum and McKee, Kevin R and Leibo, Joel Z and Larson, Kate and Graepel, Thore},
  journal={arXiv preprint arXiv:2012.08630},
  year={2020}
}

@inproceedings{fu2018learning,
  title={Learning Robust Rewards with Adverserial Inverse Reinforcement Learning},
  author={Fu, Justin and Luo, Katie and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{guan2021widening,
 author = {Guan, Lin and Verma, Mudit and Guo, Sihang and Zhang, Ruohan and Kambhampati, Subbarao},
 journal = {Advances in Neural Information Processing Systems},
 title = {Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation},
 volume = {34},
 year = {2021}
}

@inproceedings{ho2016generative,
 author = {Jonathan Ho and
Stefano Ermon},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/HoE16.bib},
 booktitle = {Advances in Neural Information Processing Systems 29: Annual Conference
on Neural Information Processing Systems 2016, December 5-10, 2016,
Barcelona, Spain},
 editor = {Daniel D. Lee and
Masashi Sugiyama and
Ulrike von Luxburg and
Isabelle Guyon and
Roman Garnett},
 pages = {4565--4573},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Generative Adversarial Imitation Learning},
 url = {https://proceedings.neurips.cc/paper/2016/hash/cc7e2b878868cbae992d1fb743995d8f-Abstract.html},
 year = {2016}
}

@inproceedings{jonnavittula2021learning,
  title={Learning to Share Autonomy Across Repeated Interaction},
  author={Jonnavittula, Ananth and Losey, Dylan P},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1851--1858},
  year={2021},
  organization={IEEE}
}

@inproceedings{kelly2019hg,
 author = {Kelly, Michael and Sidrane, Chelsea and Driggs-Campbell, Katherine and Kochenderfer, Mykel J},
 booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
 organization = {IEEE},
 pages = {8077--8083},
 title = {Hg-dagger: Interactive imitation learning with human experts},
 year = {2019}
}

@inproceedings{knox2012reinforcement,
  title={Reinforcement learning from human reward: Discounting in episodic tasks},
  author={Knox, W Bradley and Stone, Peter},
  booktitle={2012 IEEE RO-MAN: The 21st IEEE international symposium on robot and human interactive communication},
  pages={878--885},
  year={2012},
  organization={IEEE}
}

@article{krakovna2020specification,
  title={Specification gaming: the flip side of AI ingenuity},
  author={Krakovna, Victoria and Uesato, Jonathan and Mikulik, Vladimir and Rahtz, Matthew and Everitt, Tom and Kumar, Ramana and Kenton, Zac and Leike, Jan and Legg, Shane},
  journal={DeepMind Blog},
  year={2020}
}

@article{lee2021pebble,
  title={Pebble: Feedback-efficient interactive reinforcement learning via relabeling experience and unsupervised pre-training},
  author={Lee, Kimin and Smith, Laura and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2106.05091},
  year={2021}
}

@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@inproceedings{li2021efficient,
 author = {Li, Quanyi and Peng, Zhenghao and Zhou, Bolei},
 booktitle = {International Conference on Learning Representations},
 title = {Efficient Learning of Safe Driving Policy via Human-AI Copilot Optimization},
 year = {2022}
}

@inproceedings{macglashan2017interactive,
  title={Interactive learning from policy-dependent human feedback},
  author={MacGlashan, James and Ho, Mark K and Loftin, Robert and Peng, Bei and Wang, Guan and Roberts, David L and Taylor, Matthew E and Littman, Michael L},
  booktitle={International conference on machine learning},
  pages={2285--2294},
  year={2017},
  organization={PMLR}
}

@inproceedings{mandel2017add,
 author = {Travis Mandel and
Yun{-}En Liu and
Emma Brunskill and
Zoran Popovic},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/aaai/MandelLBP17.bib},
 booktitle = {Proceedings of the Thirty-First {AAAI} Conference on Artificial Intelligence,
February 4-9, 2017, San Francisco, California, {USA}},
 editor = {Satinder P. Singh and
Shaul Markovitch},
 pages = {2322--2328},
 publisher = {{AAAI} Press},
 timestamp = {Mon, 06 Mar 2017 00:00:00 +0100},
 title = {Where to Add Actions in Human-in-the-Loop Reinforcement Learning},
 url = {http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/15031},
 year = {2017}
}

@article{mandlekar2020human,
 author = {Mandlekar, Ajay and Xu, Danfei and Mart{\'\i}n-Mart{\'\i}n, Roberto and Zhu, Yuke and Fei-Fei, Li and Savarese, Silvio},
 journal = {ArXiv preprint},
 title = {Human-in-the-Loop Imitation Learning using Remote Teleoperation},
 url = {https://arxiv.org/abs/2012.06733},
 volume = {abs/2012.06733},
 year = {2020}
}

@inproceedings{menda2019ensembledagger,
  title={Ensembledagger: A bayesian approach to safe imitation learning},
  author={Menda, Kunal and Driggs-Campbell, Katherine and Kochenderfer, Mykel J},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5041--5048},
  year={2019},
  organization={IEEE}
}

@article{najar2020interactively,
  title={Interactively shaping robot behaviour with unlabeled human instructions},
  author={Najar, Anis and Sigaud, Olivier and Chetouani, Mohamed},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={34},
  number={2},
  pages={1--35},
  year={2020},
  publisher={Springer}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@inproceedings{pakdamanian2021deeptake,
  title={Deeptake: Prediction of driver takeover behavior using multimodal data},
  author={Pakdamanian, Erfan and Sheng, Shili and Baee, Sonia and Heo, Seongkook and Kraus, Sarit and Feng, Lu},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2021}
}

@inproceedings{palan2019learning,
  title={Learning Reward Functions by Integrating Human Demonstrations and Preferences},
  author={Palan, Malayandi and Shevchuk, Gleb and Charles Landolfi, Nicholas and Sadigh, Dorsa},
  booktitle={Robotics: Science and Systems},
  year={2019}
}

@article{reddy2018shared,
 author = {Reddy, Siddharth and Dragan, Anca D and Levine, Sergey},
 journal = {Robotics: Science and Systems},
 title = {Shared autonomy via deep reinforcement learning},
 year = {2018}
}

@inproceedings{ross2010efficient,
 author = {Ross, St{\'e}phane and Bagnell, Drew},
 booktitle = {Proceedings of the thirteenth international conference on artificial intelligence and statistics},
 organization = {JMLR Workshop and Conference Proceedings},
 pages = {661--668},
 title = {Efficient reductions for imitation learning},
 year = {2010}
}

@book{russell2019human,
  title={Human compatible: Artificial intelligence and the problem of control},
  author={Russell, Stuart},
  year={2019},
  publisher={Penguin}
}

@article{sadigh2017active,
 author = {Sadigh, Dorsa and Dragan, Anca D and Sastry, Shankar and Seshia, Sanjit A},
 journal = {UC Berkeley},
 title = {Active preference-based learning of reward functions},
 year = {2017}
}

@inproceedings{saunders2018trial,
 author = {Saunders, William and Sastry, Girish and Stuhlmueller, Andreas and Evans, Owain},
 booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
 organization = {International Foundation for Autonomous Agents and Multiagent Systems},
 pages = {2067--2069},
 title = {Trial without error: Towards safe reinforcement learning via human intervention},
 year = {2018}
}

@inproceedings{spencer2020learning,
 author = {Spencer, Jonathan and Choudhury, Sanjiban and Barnes, Matthew and Schmittle, Matthew and Chiang, Mung and Ramadge, Peter and Srinivasa, Siddhartha},
 booktitle = {Robotics: Science and Systems (RSS)},
 title = {Learning from Interventions},
 year = {2020}
}

@article{wang2021apple,
  title={Apple: Adaptive planner parameter learning from evaluative feedback},
  author={Wang, Zizhao and Xiao, Xuesu and Warnell, Garrett and Stone, Peter},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={4},
  pages={7744--7749},
  year={2021},
  publisher={IEEE}
}

@inproceedings{wang2021appli,
  title={Appli: Adaptive planner parameter learning from interventions},
  author={Wang, Zizhao and Xiao, Xuesu and Liu, Bo and Warnell, Garrett and Stone, Peter},
  booktitle={2021 IEEE international conference on robotics and automation (ICRA)},
  pages={6079--6085},
  year={2021},
  organization={IEEE}
}

@inproceedings{warnell2018deep,
 author = {Garrett Warnell and
Nicholas R. Waytowich and
Vernon Lawhern and
Peter Stone},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/aaai/WarnellWLS18.bib},
 booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence,
(AAAI-18), the 30th innovative Applications of Artificial Intelligence
(IAAI-18), and the 8th {AAAI} Symposium on Educational Advances in
Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February
2-7, 2018},
 editor = {Sheila A. McIlraith and
Kilian Q. Weinberger},
 pages = {1545--1554},
 publisher = {{AAAI} Press},
 timestamp = {Mon, 22 Oct 2018 01:00:00 +0200},
 title = {Deep {TAMER:} Interactive Agent Shaping in High-Dimensional State
Spaces},
 url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16200},
 year = {2018}
}

@inproceedings{xu2022look,
  title={Look Before You Leap: Safe Model-Based Reinforcement Learning with Human Intervention},
  author={Xu, Yunkun and Liu, Zhenyu and Duan, Guifang and Zhu, Jiangcheng and Bai, Xiaolong and Tan, Jianrong},
  booktitle={Conference on Robot Learning},
  pages={332--341},
  year={2022},
  organization={PMLR}
}

@inproceedings{zhang2017query,
  title={Query-efficient imitation learning for end-to-end simulated driving},
  author={Zhang, Jiakai and Cho, Kyunghyun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  year={2017}
}

