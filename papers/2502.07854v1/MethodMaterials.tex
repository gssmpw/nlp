\section{Methodology}

For the downstream task of forecasting heat demand, we adopt and adapt a convolution-based network $F$   \cite{chatterjee2022heat} for which each input feature is represented in a Time-Frequency domain in the form of wavelet scalograms obtained through Continuous Wavelet Transform (CWT). During convolution, as different types of features such as demand and weather are concatenated to form a multi-channel input, the kernel learns the inter-dependency between each channel, however, there is a risk of features obscuring essential patterns. As a remedy, the architecture is modified to $F^{'}$ where the endogenous and exogenous features are embedded in two distinct branches, with a cross-attention block introduced after the convolutional layers, as illustrated in Figure \ref{Fig1:block_diagram}. However, this delays the model's ability to learn certain inter-dependencies across feature families early on, and the attention block compensates by dynamically focusing on and prioritizing the most relevant contexts from each branch during the merging process. With fewer and similar features, we only require a single convolution layer per branch to capture the essential patterns.


\begin{figure}[htbp]
\centering
% \includegraphics[width=1.0\linewidth]{images/CrossAttention_PositionalEncoding2.pdf}
\includegraphics[width=1.0\linewidth]{images/cross.pdf}

\caption{Wavelet-based forecasting network with cross attention between the primary demand features and the supporting exogenous features. $N_{c}$, $N_{w}$, and $N_{t}$ represent the number of consumption, weather and time based features.}
\label{Fig1:block_diagram}
\end{figure}



The endogenous features consist of historical consumption data, while the exogenous features include weather forecasts and time-based variables. Owing to the unidirectional influence of weather on demand patterns endogenous feature embedding is used as the query vector for the attention layer, while the exogenous features provide contextual support, enriching the representation of heat demand \cite{Shih2019},\cite{adiferra}. The attention layer is followed by a series of fully connected layers to generate the demand forecast. During feature selection, in addition to relevant features in their current form selected through correlational analysis, we also perform seasonal decomposition of the features, to obtain trend, seasonal, and residual components. Figure \ref{Fig2:SD} illustrates the decomposition of historical demand and observed maximum temperature. The temperature trend is selected as a feature due to its inverse influence on the trend of heat demand. However, the seasonal component of temperature is disregarded, while the seasonal component of demand is retained to reflect the DMA's daily or weekly patterns. Residual components are included as well, given there are identifiable patterns.


To forecast for heat demand \(\mathbf{y}(t) = [x_{t+1}, x_{t+2}, ..., x_{t+n}]\) at time $t$, where \(n=24\) represents the forecasting horizon, we discretize all temporal features with a winow of $h=24$ historical observations. These observations are then transformed using CWT to generate scalograms with dimensions of $ h \times s \times 1$, where $s=24$ represents the number of scales associated with the CWT. The scalograms are concatenated based on the family of the feature (demand or weather), forming the inputs to the model for predicting $y(t)$.

\begin{figure}[htbp]
\centering
\includegraphics[width=1.0\linewidth]{images/SD_Centrum.pdf}
\caption{Seasonal decomposition of demand data and maximum temperature sampled hourly for a specific DMA.}
\label{Fig2:SD}
\end{figure}



