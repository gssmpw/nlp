\section{Related Works}
The theoretical assumption of the GP bandit is twofold: Bayesian setting____ where the reward function follows GPs, and the frequentist setting, where the reward function lies in known RKHS____.
%
Although this paper concentrates on deriving the regret upper bound for the frequentist setting, our Lemma~\ref{lem:pvu_mvr} and Corollary~\ref{cor:pvu_mvr} are versatile and can be applied to the Bayesian setting.


% Usual GP bandit
Many GP bandit algorithms have been proposed in the frequentist setting____.
%
Although several existing methods____ achieve near-optimal regret upper bounds for the ordinary GP bandit setting as summarized in ____, we develop PE- and MVR-style algorithms due to their simplicity.
%
On the other hand, although these existing methods are near-optimal regarding the time horizons, the optimality regarding the RKHS norm of the reward function has not been shown as summarized in Tables~\ref{tab:cr_rkhs_compare}--\ref{tab:sr_eps_rkhs_compare}.


% noiseless GP bandit
The regret analyses are also conducted on the noiseless setting____.
%
Regarding the cumulative regret, we obtained a tighter upper bound for both SE and Mat\'ern kernels than existing results without the additional assumption for the reward function like Assumption~4.2 in ____.
%
Regarding the simple regret, ____ have shown that the random sampling-based algorithm achieves the known-best regret upper bound in terms of the expectation regarding the algorithm's randomness.
% 
Compared with this result, we show the regret upper bounds that always hold with the deterministic MVR-style algorithm.
%
In particular, the regret upper bound is tighter for the Mat\'ern kernel than that from ____.
%
Tables~\ref{tab:nl_cr_compare}--\ref{tab:nl_sr_compare} summarize the comparison.


% lower bound of GP bandit
Compared with the regret upper bound, the analysis for the regret lower bound is limited____.
%
From these results, we will confirm the optimality of the GP bandit algorithms in Sections~\ref{sec:nls} and \ref{sec:rkhs_od}.
%
In \secref{sec:nsv}, our regret lower bound for the non-stationary noise variance setting is directly obtained from the proofs of____.



% non-stationary noise variance (linear bandit)
The linear bandit with heteroscedastic noise, where the noise variance is non-stationary with respect to the time horizons, has been studied ____.
%
These studies aim to obtain the noise variance-dependent regret upper bound, characterized by the sum of noise variances.
%
To our knowledge, the kernelized extension of this setting has not been investigated.
%
Furthermore, as discussed in \secref{sec:nsv}, the direct extension from the linear bandit methods is not near-optimal.



% \begin{table*}[tb]
%     \centering
%     \begin{tabular}{c|c|c|c|c|l}
%          & Regret (SE) & \multicolumn{3}{|c|}{Regret (Mat\'ern)} & Remark \\ \hline
%          &  &  &  \\ \hline
%         GP-UCB & $O\rbr{\sqrt{T \ln^{d+1} T}}$ & $\tilde{O}\rbr{T^{\frac{\nu + d}{2\nu + d}}}$ & \\
%         Explore-then-Commit & N/A & $O\rbr{T^{\frac{d}{\nu + d}}}$ & \\
%         REDS & N/A & $\tilde{O}\rbr{T^{\frac{\nu + d}{2\nu + d}}}$ & \\
%         Kernel-AMM-UCB & $O\rbr{\ln^{d+1} T}$ & $\tilde{O}\rbr{T^{\frac{\nu d + d^2}{2\nu^2 + 2\nu d + d^2}}}$ & \\
%         Phased Elimination & $O(\ln T)$ & $\begin{cases}
%             \tilde{O}\rbr{T^{\frac{d - \nu}{d}}} & \\
%             \tilde{O}\rbr{\ln^{\alpha} T} & \\
%             \tilde{O}\rbr{\ln T} & 
%         \end{cases}$
%         & \\
%         Conjectured Lower Bound & N/A & &
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table*}

\begin{table*}[tb]
    \centering
    \caption{Comparison between existing noiseless algorithms' guarantees for cumulative regret and our result. 
    In all algorithms, the smoothness parameter of the Mat\'ern kernel is assumed to be $\nu > 1/2$.
    Furthermore, $d$, $\ell$, $\nu$, and $B$ are supposed to be $\Theta(1)$ here. ``Type'' column shows that the regret guarantee is  (D)eterministic or (P)robabilistic. Throughout this paper, the notation $\tilde{O}(\cdot)$ represents the order notation whose poly-logarithmic dependence is ignored.
    }
    \begin{tabular}{c|c|c|c|c|c|l}
    \multicolumn{1}{c|}{\multirow{2}{*}{Algorithm}} & \multicolumn{1}{|c|}{\multirow{2}{*}{Regret (SE)}} & \multicolumn{3}{|c|}{Regret (Mat\'ern)} & \multirow{2}{*}{Type} & \multirow{2}{*}{Remark} \\ \cline{3-5}
    \multicolumn{1}{c|}{}  & \multicolumn{1}{|c|}{}  & $\nu < d$  & $\nu = d$  & $\nu > d$ &  & \\ \hline \hline
     GP-UCB & \multirow{3}{*}{$O\rbr{\sqrt{T \ln^{d} T}}$} & \multicolumn{3}{|c|}{\multirow{3}{*}{$\tilde{O}\rbr{T^{\frac{\nu + d}{2\nu + d}}}$}} & \multirow{3}{*}{D} & \\ 
     ____ & & \multicolumn{3}{|c|}{} & & \\ 
     ____ & & \multicolumn{3}{|c|}{} & & \\ \hline
     Explore-then-Commit & \multirow{2}{*}{N/A} & \multicolumn{3}{|c|}{\multirow{2}{*}{$\tilde{O}\rbr{T^{\frac{d}{\nu + d}}}$}} & \multirow{2}{*}{P} & \\ 
     ____ &  & \multicolumn{3}{|c|}{} & & \\ \hline
         Kernel-AMM-UCB
      & \multirow{2}{*}{$O\rbr{\ln^{d+1} T}$} & \multicolumn{3}{|c|}{\multirow{2}{*}{$\tilde{O}\rbr{T^{\frac{\nu d + d^2}{2\nu^2 + 2\nu d + d^2}}}$}} & \multirow{2}{*}{D} & \\ 
      ____
      &  & \multicolumn{3}{|c|}{} & & \\ \hline
     REDS & \multirow{2}{*}{N/A} & \multirow{2}{*}{$\tilde{O}\rbr{T^{\frac{d - \nu}{d}}}$} & \multirow{2}{*}{$O\rbr{\ln^{\frac{5}{2}} T}$} & \multirow{2}{*}{$O\rbr{\ln^{\frac{3}{2}} T}$} & \multirow{2}{*}{P} & Assumption for \\
     ____ &  &  &  &  & & level-set is required. \\ \hline
     \textbf{PE} & \multirow{2}{*}{$O\rbr{\ln T}$} & \multirow{2}{*}{$\tilde{O}\rbr{T^{\frac{d - \nu}{d}}}$} & \multirow{2}{*}{$O\rbr{\ln^{2 +\alpha} T}$} & \multirow{2}{*}{$O\rbr{\ln T}$} & \multirow{2}{*}{D} & $\alpha > 0$ is an arbitrarily  \\ 
     \textbf{(our analysis)} & & & & &  & fixed constant. \\ \hline
     Conjectured Lower Bound & \multirow{2}{*}{N/A} & \multirow{2}{*}{$\Omega\rbr{T^{\frac{d - \nu}{d}}}$} & \multirow{2}{*}{$\Omega(\ln T)$} & \multirow{2}{*}{$\Omega(1)$} & \multirow{2}{*}{N/A} & \\
     ____ & & & & & & \\
    \end{tabular}
    \label{tab:nl_cr_compare}
\end{table*}