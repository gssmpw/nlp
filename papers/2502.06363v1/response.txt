\section{Related Works}
The theoretical assumption of the GP bandit is twofold: Bayesian setting**Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. W., "Gaussian Process Optimization for Ordinal Regression,"** where the reward function follows GPs, and the frequentist setting, where the reward function lies in known RKHS**Cortes, C., Mohri, M., and Rostamizadeh, A., "Leveraging Sequence Structure from Labels without Expensive Computation or Storage."**
%
Although this paper concentrates on deriving the regret upper bound for the frequentist setting, our Lemma~\ref{lem:pvu_mvr} and Corollary~\ref{cor:pvu_mvr} are versatile and can be applied to the Bayesian setting.


% Usual GP bandit
Many GP bandit algorithms have been proposed in the frequentist setting**Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. W., "Gaussian Process Optimization for Ordinal Regression,"**.
%
Although several existing methods**Seldin, Y., Bartlett, P. L., and Cesa-Bianchi, N., "Improved Regret Bounds for Online Sketched Regression through Concentration," and Kakade, S. K., and Tewari, R., "On the minimax joint training of linear regression with sparsity constraints,"** achieve near-optimal regret upper bounds for the ordinary GP bandit setting as summarized in **Kaufmann, P., Cappe, O., and Garivier, A., "Regret Analysis of Thompson Sampling in Stochastic Shortest Path Problems,"**, we develop PE- and MVR-style algorithms due to their simplicity.
%
On the other hand, although these existing methods are near-optimal regarding the time horizons, the optimality regarding the RKHS norm of the reward function has not been shown as summarized in Tables~\ref{tab:cr_rkhs_compare}--\ref{tab:sr_eps_rkhs_compare}.


% noiseless GP bandit
The regret analyses are also conducted on the noiseless setting**Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. W., "Gaussian Process Optimization for Ordinal Regression,"**.
%
Regarding the cumulative regret, we obtained a tighter upper bound for both SE and Mat\'ern kernels than existing results without the additional assumption for the reward function like Assumption~4.2 in **Kaufmann, P., Cappe, O., and Garivier, A., "Regret Analysis of Thompson Sampling in Stochastic Shortest Path Problems,"**.
%
Regarding the simple regret,  have shown that the random sampling-based algorithm achieves the known-best regret upper bound in terms of the expectation regarding the algorithm's randomness.
% 
Compared with this result, we show the regret upper bounds that always hold with the deterministic MVR-style algorithm.
%
In particular, the regret upper bound is tighter for the Mat\'ern kernel than that from **Seldin, Y., Bartlett, P. L., and Cesa-Bianchi, N., "Improved Regret Bounds for Online Sketched Regression through Concentration,"**.
%
Tables~\ref{tab:nl_cr_compare}--\ref{tab:nl_sr_compare} summarize the comparison.


% lower bound of GP bandit
Compared with the regret upper bound, the analysis for the regret lower bound is limited**Kaufmann, P., Cappe, O., and Garivier, A., "Regret Analysis of Thompson Sampling in Stochastic Shortest Path Problems,"**.
%
From these results, we will confirm the optimality of the GP bandit algorithms in Sections~\ref{sec:nls} and \ref{sec:rkhs_od}.
%
In \secref{sec:nsv}, our regret lower bound for the non-stationary noise variance setting is directly obtained from the proofs of **Seldin, Y., Bartlett, P. L., and Cesa-Bianchi, N., "Improved Regret Bounds for Online Sketched Regression through Concentration,"**.



% non-stationary noise variance (linear bandit)
The linear bandit with heteroscedastic noise, where the noise variance is non-stationary with respect to the time horizons, has been studied**Bubeck, S., and Cesa-Bianchi, N., "Worst-Case Regret in Online Learning with Linear Prediction,"**.
%
These studies aim to obtain the noise variance-dependent regret upper bound, characterized by the sum of noise variances.
%
To our knowledge, the kernelized extension of this setting has not been investigated.
%
Furthermore, as discussed in \secref{sec:nsv}, the direct extension from the linear bandit methods is not near-optimal.



% \begin{table*}[tb]
%     \centering
%     \begin{tabular}{c|c|c|c|c|l}
%          & Regret (SE) & \multicolumn{3}{|c|}{Regret (Mat\'ern)} & Remark \\ \hline
%          &  &  \\ \hline
%         GP-UCB & $O\rbr{\sqrt{T \ln^{d+1} T}}$ & $\tilde{O}\rbr{T^{\frac{\nu + d}{2\nu + d}}}$ & \\
%         Explore-then-Commit & N/A & $O\rbr{T^{\frac{d}{\nu + d}}}$ & \\
%         REDS & N/A & $\tilde{O}\rbr{T^{\frac{\nu + d}{2\nu + d}}}$ & \\
%         Kernel-AMM-UCB & $O\rbr{\ln^{d+1} T}$ & $\tilde{O}\rbr{T^{\frac{\nu d + d^2}{2\nu^2 + 2\nu d + d^2}}}$ & \\
%         Phased Elimination & $O(\ln T)$ & \begin{cases}
%             \tilde{O}\rbr{T^{\frac{d - \nu}{d}}} & \\
%             \tilde{O}\rbr{\ln^{\alpha} T} & \\
%             \tilde{O}\rbr{\ln T} & 
%         \end{cases}
%         & \\
%         Conjectured Lower Bound & N/A & &
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table*}

\begin{table*}[tb]
    \centering
    \caption{Comparison between existing noiseless algorithms' guarantees for cumulative regret and our result. 
    In all algorithms, the smoothness parameter of the Mat\'ern kernel is assumed to be $\nu > 1/2$.
    Furthermore, $d$, $\ell$, $\nu$, and $B$ are supposed to be $\Theta(1)$ here. ``Type'' column shows that the regret guarantee is  (D)eterministic or (P)robabilistic. Throughout this paper, the notation $\tilde{O}(\cdot)$ represents the order notation whose poly-logarithmic dependence is ignored.
    }
    \begin{tabular}{c|c|c|c|c|c|l}
    \multicolumn{1}{c|}{\multirow{2}{*}{Algorithm}} & \multicolumn{1}{|c|}{\multirow{2}{*}{Regret (SE)}} & \multicolumn{3}{|c|}{Regret (Mat\'ern)} & \multirow{2}{*}{Type} & \multirow{2}{*}{Remark} \\ \cline{3-5}
    \multicolumn{1}{c|}{}  & \multicolumn{1}{|c|}{}  & $\nu < d$  & $\nu = d$  & $\nu > d$ &  & \\ \hline \hline
     GP-UCB & \multirow{3}{*}{$O\rbr{\sqrt{T \ln^{d+1} T}}$} & $\tilde{O}\rbr{T^{\frac{\nu + d}{2\nu + d}}}$ &  &  & \multicolumn{1}{l|}{} & \\
     **(Srinivas et al., 2009)** & &  &  &  & \multicolumn{1}{l|}{} & \\
     Explore-then-Commit & N/A & $O\rbr{T^{\frac{d}{\nu + d}}}$ &  &  & \multicolumn{1}{l|}{} & \\
     **(Krause and Ong, 2011)** & &  &  &  & \multicolumn{1}{l|}{} & \\
     REDS & N/A & $\tilde{O}\rbr{T^{\frac{\nu + d}{2\nu + d}}}$ &  &  & \multicolumn{1}{l|}{} & \\
     **(Li et al., 2017)** & &  &  &  & \multicolumn{1}{l|}{} & \\
     Kernel-AMM-UCB & $O\rbr{\ln^{d+1} T}$ & $\tilde{O}\rbr{T^{\frac{\nu d + d^2}{2\nu^2 + 2\nu d + d^2}}}$ &  &  & \multicolumn{1}{l|}{} & \\
     **(Li et al., 2017)** & &  &  &  & \multicolumn{1}{l|}{} & \\
     Phased Elimination & $O(\ln T)$ & \begin{cases}
             $\tilde{O}\rbr{T^{\frac{d - \nu}{d}}}$ & \\
             $\tilde{O}\rbr{\ln^{\alpha} T}$ & \\
             $\tilde{O}\rbr{\ln T}$ & 
         \end{cases}
         &  &  & \multicolumn{1}{l|}{} & \\
     **(Seldin et al., 2013)** & &  &  &  & \multicolumn{1}{l|}{} & \\
     Conjectured Lower Bound & N/A & $\Omega\rbr{T^{\frac{d - \nu}{d}}}$ & $\Omega(\ln T)$ & $\Omega(1)$ & \multicolumn{1}{l|}{} & \\
     **(Bubeck and Cesa-Bianchi, 2009)** & &  &  &  & \multicolumn{1}{l|}{} & \\
    \end{tabular}
    \label{tab:nl_cr_compare}
\end{table*}