\section{Qualitative and quantitative evaluation}
\label{Sec: exp and results}

\paragraph{Experiment setup}
\textbf{(1) Datasets}: We use images from two large-scale datasets: \textbf{(i)} MS-COCO \citep{lin2014microsoft} composed of 328K real images and \textbf{(ii)} DiffusionDB \citep{wang2022diffusiondb} composed of 14 million high-quality AI-generated images. We randomly sample $2000$ images from each dataset---the typical scale for the robustness evaluation of watermark systems~\citep{an2024benchmarking}, resize them to $512 \times 512$, and generate images with different watermarks, respectively; \textbf{(2) Watermark methods}: We focus on $6$ representative and publicly available \emph{post-processing} watermark methods: DwtDctSVD, rivaGAN, SSL, TrustMark, RoSteALS, and StegaStamp, whose watermark patterns vary in the visibility level and Fourier spectrum; see \cref{Fig: watermark vis,Fig: watermark fourier vis} and \cref{tab: watermark quality intensity} for visual and quantitative comparisons, respectively. We also evaluate on the SOTA \emph{in-processing} TreeRing watermark, where $2000$ watermarked images are generated using \texttt{Gustavosta} stable diffusion prompts from HuggingFace \citep{huggingface2024gustavosta}; \textbf{(3) Evasion methods}: In addition to our DIP-based evasion method described in \cref{alg: DIP evasion}, \footnote{We use the default `skip' network in the original DIP repo: \url{https://github.com/DmitryUlyanov/deep-image-prior}.} we also consider the following classical digital editing methods: \textbf{(i)} brightness, \textbf{(ii)} contrast, \textbf{(iii)} Gaussian noise, \textbf{(iv)} JPEG compression, \textbf{(v)} bm3d denoising, and recent SOTA purification methods: \textbf{(vi)} DiffPure \citep{saberi2023robustness}, \textbf{(vii)} Diffuser and \textbf{(viii)} VAE regeneration \citep{jiang2023evading}\footnote{VAE regeneration using model from \cite{cheng2020learned}, which gives the best VAE performance as in \cite{jiang2023evading}.}.

\input{tex-table/Tab-watermark-pattern-quality}

\paragraph{Evaluation protocol}
As we argue in \cref{Sec: Intro} (see also \cite{an2024benchmarking}), evasion success and image quality are two essential dimensions of watermarking systems. Therefore, we report the \emph{best image quality} each evasion method can achieve while failing watermark detection. To find the ``optimal'' tradeoff image, we perform an exhaustive search over the allowable ranges of the hyperparameters for each evasion method and look for images with \textbf{(i)} watermark undetected and \textbf{(ii)} the highest PSNR value with respect to the watermarked image $I_{\mb w}$; see \cref{sec:query-effi} for justification on why $I_{\mb w}$ is used and \cref{App: hyperparam} for details about all hyperparameters. Finally, to quantify the quality of such images, we use three metrics: \textbf{(i)} PSNR, \textbf{(ii)} Structural Similarity Index Measure (SSIM) \citep{hore2010image} and \textbf{(iii)} $90 \%$ quantile of pixel-wise difference, all with respect to the clean image $I$. The quantile metric mainly serves as a supplement, as PSNR and SSIM focus on the average difference while it reflects the difference on the tail---watermark-induced distortion to an image may be highly localized and hence spatially sparse, which might not be captured by averaging metrics; see \cref{Fig: watermark vis,tab: watermark quality intensity} for a sense of the visual and quantitative distortions caused by different watermark methods. Since the TreeRing watermark lacks a notion of clean image, we use $I_{\mb w}$ as the reference in all evaluation experiments related to TreeRing watermark. 
% The detection threshold $\gamma=0.75$ is used for all watermark decoders.\footnote{The choice of $\gamma$ in practice is problem specific, e.g., depending on the requirement of true positive rate (TPR) and false positive rate (FPR). \cite{jiang2023evading} empirically showed that $BA(D(I), \mb w) \approx 0.5$ if $I$ is a unwatermarked image. Hence, our choice $\gamma=0.75$ is a reasonably good TPR/FPR tradeoff point, which can also form fair comparisons among all evasion methods considered.} 



% \input{tex-table/Tab-in-Watermark-Evasion}
\input{tex-table/Tab-gamma-ablation}
\input{tex-table/Tab-App-Watermark-Evasion}
\input{tex-table/Tab-TreeRing}

\paragraph{Experiment results} 
% We report in \cref{tab: quantitative evasion result} the quantitative results of the evasion performance for each method with the watermark detection threshold $\gamma = 0.75$. 
As mentioned in \cref{Sec: background}, the choice of $\gamma$ in the watermark decoder, as shown in \cref{Eq: detection bar}, is highly task-dependent. It determines the true positive rate (TPR) and the false positive rate (FPR) in watermark detection---TPR measures the fraction of watermarked images correctly detected, and FPR measures the fraction of clean images wrongly flagged as watermarked images. In general, the higher the $\gamma$ used in the decoder, the lower the true positive rate (TPR) and the false positive rate (FPR). A practically useful watermark decoder should have a TPR close to one and a FPR close to zero. On the other hand, the higher the $\gamma$, the higher the quality of the evasion image can achieve. To account for the effect of $\gamma$ in robustness evaluation, we report in \cref{tab: watermark evasion diff gamma} the evasion performance of different methods under different $\gamma$'s on COCO images, and \cref{tab: watermark evasion diff gamma DiffusionDB} on DiffusionDB images, together with the TPR/FPR achieved. %; see also \cref{Sec App: DiffusionDB} for the results on DiffusionDB images. 

From \cref{tab: watermark evasion diff gamma,tab: watermark evasion diff gamma DiffusionDB,tab: tree-ring evasion}, we observe that: \textbf{(1)} The effect of $\gamma$ on TPR/FPR values as well as image quality of different watermarks against the detection threshold agrees with our discussion above. This is true also for the TreeRing watermark, whose detection threshold is based on the $\ell_1$ distance, very different from those for other watermark methods; \textbf{(2)} The performance of watermark evasion shown by the column with $\gamma = 0.55$ in \cref{tab: watermark evasion diff gamma,tab: watermark evasion diff gamma DiffusionDB} is not quite meaningful---the very high FPR renders the decoder hardly useful in practice; \textbf{(3)} In other cases, there is no clear winner among all the evasion methods we evaluate. For example, our DIP-based evasion has the best performance on DwtDctSVD and rivaGAN, and is comparable to the best on SSL; DiffPure is the most effective evasion on TrustMark, RoSteALS and StegaStamp; TreeRing seems most vulnerable to JPEG compression. This highlights the need to include diverse sources of evasion methods for faithful robustness evaluation of watermarking systems, as we argue in \cref{sec:why-include-dip}. 

Moreover, comparing the results of our DIP-based evasion on different watermarks, we observe that evasion images for DwtDctSVD, rivaGAN, and SSL watermarks can achieve very high quality when $\gamma \ge 0.65$, with reasonable TPR/FPR values. This is well expected, as these watermarks mainly cause high-frequency distortions  (see \cref{Fig: watermark fourier vis}), and DIP-based evasion is good at separating high- and low-frequency components and thereby largely removing the watermark during iteration, as argued in \cref{sec:why-include-dip}. In contrast,  DIP-based evasion shows limited performance on RoSteALS and StegaStamp, as these watermark methods induce substantial mid- and low-frequency distortions, which DIP picks up in early stages so are hard to separate from the clean image content. DIP's mediocre performance on TrustMark is a bit surprising. One possible explanation is that TrustMark, in fact, induces mainly low-frequency distortions, which is downplayed in our visualization due to the $\log$ scale  as shown in \cref{Fig: watermark fourier vis}. 
 
% Note that although DwtDctSVD appears to incorporate a significant mid-frequency component, its watermark patterns are still predominantly concentrated in the high-frequency range. This is because DwtDctSVD encodes watermarks on the singular values of the SVD decomposition of the DCT-transformed HH (high-frequency) band of the DWT transform --- the tail (low-magnitude) singular values thus map to the very high-frequency component in the image content. 


% Another interesting observation is that our DIP-based evasion can evade DwtDctSVD with very high-quality images although the watermark induces mid-frequency distortions. The reasons can be two-fold: \textbf{(i)} DwtDctSVD is a manually designed watermark \hy{where each bit of the watermark message is encoded in one frequency band --- only destroying the message on the highest frequency bans is sufficient to evade the watermark detection.} \textbf{(ii)} the overall watermark magnitude is small ($\sim 38$ PSNR; see \cref{tab: watermark quality intensity}). 

% For DiffPure and Diffuser that rely on learned denoising, 

% As for DiffPure and Diffuser where learning-based denoising method is leveraged, their watermark evasion performance seems to be influenced by their `averaged denoising' training target --- when the watermark magnitude is small (DwtDctSvd, rivaGAN, SSL and TrustMark), the evasion image quality is good but not great; whereas the watermark magnitude is large (RoSteALS and StegaStamp), the evasion image quality is OK but not bad. 

% However, DIP can also evade DwtDctSVD with very high-quality images even if the watermarks contain mid-frequency components. The reasons can be two-fold: \textbf{(i)} DwtDctSVD is a manually designed watermark and proper decoding relies on faithful reconstruction of all frequency bands---only picking up information in the mid-frequency is not sufficient; \textbf{(ii)} the watermark intensity is small (see \cref{tab: watermark quality intensity}) and most image components can be reconstructed before the watermark can be decoded. Compared with other evasion methods under the same watermarks, DIP performs the best on DwtDctSVD and rivaGAN, while performing less competitively on SSL and stegaStamp than VAE and DiffPure. 

\input{tex-figure/Fig-Evasion-Vis-StegaStamp}
% \input{tex-figure/Fig-Evasion-Vis-rivaGAN}


% For evasion methods that leverage pretrained diffusion models (DiffPure and Diffuser), the gap of image quality across different watermarks is relatively small (e.g., much smaller compared to that of DIP). This may be credited to the pretraining stage of the diffusion models, where large-scale image datasets might have been used. Evasion images are regenerated on top of the learned image distribution, rather than the single watermarked image provided. As a result, for watermarks that have relatively high visibility (e.g., StegaStamp, RoSteALS), DiffPure can evade them with high-quality images. For example, as shown in \cref{Fig: watermark evasion vis stegaStamp}, DiffPure can evade StegaStamp images with much higher quality than other methods. However, the downside is that the evasion image quality can be lacking when the watermarks are already low in visibility (e.g., DwtDctSVD and rivaGAN). For example, as shown in \cref{Fig: watermark evasion vis rivaGAN}, while our DIP-based evasion can evade rivaGAN images without noticeable loss of quality from clean ones, an overly smoothing effect by DiffPure and noticeable artifacts introduced by Diffuser can still be observed. 

% \paragraph{Implications}
% With the results and the analysis above, we can conclude that there are \emph{no universal best evasion algorithms} for existing watermarking systems. DIP is the most effective evader for relatively invisible watermarks (e.g., DwtDctSVD, rivaGAN and SteganoGAN) so far and likely a general and effective evader for all watermarks that rely on high-frequency information. Its limited evasion ability for SSL and StegaStamp indicates that the use of low- and mid-frequency components is a likely necessary condition for watermarking systems to be reliable. Thus, we advocate explicit consideration of this factor in future design of watermarks. Moreover, although the result in \cref{tab: quantitative evasion result} shows that all existing learning-based watermarks can be evaded with reasonably high-quality images by at least one evasion technique, the future of learning-based watermarks is not all pessimistic: learning-based watermarks may not be reliable at protecting copyrights, but they can be promising in preventing misinformation abuse. This is due to the difference in the reliability requirement of the two applications. For copyright protection, it is reasonable to expect the watermark to stay detectable as long as the image content is recognizable even under severe corruptions---which may be too hard to achieve. However, to prevent misinformation abuse by generated images, it is sufficient to achieve one of the following two conditions to reduce damage: \textbf{(i)} the watermark patterns can be detected by human eyes, e.g., a translucent logo or unnatural perturbations such as StegaStamp in \cref{Fig: watermark vis,Fig: watermark evasion vis stegaStamp}, which may be sufficient to raise suspicion that the image is already manipulated or fake in the content already; \textbf{(ii)} the watermark can be detected by an algorithmic decoder. Although how to quantify the detectability for human eyes is still an open question, relatively visible watermarks such as StegaStamp can be promising in promoting responsible use of AI-generated contents.

