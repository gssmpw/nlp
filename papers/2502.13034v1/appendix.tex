\appendix

\section{Quantitative Analysis of Tasks}
\label{appendix:a}
For computing similarity scores, we used the image and text encoders of the \verb|ViT-B/32| version of the CLIP model. Obtained \textit{visual similarity} and \textit{textual consistency} scores are subtracted from $1.0$ for representing the tasks on the shared space in Figure~\ref{fig:shared_space}. For the \textit{Multi-image/Video Question Answering} task, we set \textit{textual consistency} value to $1.0$ due to the unavailability of datasets having multiple-sentences in the textual outputs.

\section{Models}
\label{appendix:b}
Table~\ref{tab:models} outlines the models we reviewed for each of the multi-image-to-text tasks in this work. To reflect the evolution of models, we considered both RNN-based approaches and the more contemporary Transformer-based architectures that obtained state-of-the-art results.

\begin{table}[h]
    \centering
\begin{tblr}{
    colspec = {X[c,h]X[c]X[c]X[c]},
    stretch = 0,
    rowsep = 5pt,
    hlines = {xkcdBlack, 0.5pt},
    vlines = {xkcdBlack, 0.25pt}
  }

    \includegraphics[width=\linewidth,height=2cm]{images/CC_ex.pdf} &
    \textit{\color{xkcdVividBlue}Change Captioning}, dataset: \color{xkcdOrange}Spot-the-diff\color{black}\newline\textbf{Caption:} The blue truck is no longer there. A car is approaching the parking lot from the right. \\

    \includegraphics[width=\linewidth,height=2cm]{images/VIDQA_ex.pdf} &
    \textit{\color{xkcdVividBlue}Video Question Answering}, dataset: \color{xkcdOrange}IntentQA \color{black}\cite{intentqa}, Question: Why did the man point to the screen when talking to the child?\newline\textbf{Answer:} Draw child's attention. \\

    \includegraphics[width=\linewidth,height=2cm]{images/VC_ex.pdf} &
    \textit{\color{xkcdVividBlue}Video Captioning}, dataset: \color{xkcdOrange}Charades\color{black}\newline\textbf{Caption:} The person is sitting at the dining room table wrapped in a blanket.  The person is eating cereal and drinking orange juice. \\

    \includegraphics[width=\linewidth,height=2cm]{images/MAAD_ex.pdf} &
    \textit{\color{xkcdVividBlue}Movie Auto Audio Description}, dataset: \color{xkcdOrange}MAD-v1\color{black}\newline\textbf{Story:} Sully adjusts his seat harness. A male passenger looks up from his magazine ... Sully sticks out an arm as the jet bellies down onto the river.\\

    \includegraphics[width=\linewidth,height=2cm]{images/VIST_ex.pdf} &
    \textit{\color{xkcdVividBlue}Visual Storytelling}, dataset: \color{xkcdOrange}VIST\color{black}\newline\textbf{Story:} A discus got stuck up on the roof. Why not try getting it down with a soccer ball? ... It didn't work so we tried ... are all stuck on the roof.

\end{tblr}
\caption{Examples for each of the multi-image-to-text tasks we consider in this work. }
\label{tab:review_tasks_examples}
\end{table}

\input{models-table}
