

In this section, we employ a distinct proof strategy than \citet{aaronson2019online} to obtain lower bounds on sequential fat-shattering dimension -- recall that he proved that $\text{sfat}_\delta (\mathcal{H}_n, \mathcal{X})=\Theta(\frac{n}{\delta^2})$. This allows us to extend those bounds naturally to various subsettings of the online quantum state learning problem,  characterized by a restricted hypothesis class $\mathcal{H}\subset\mathcal H_n$ and a constrained sample space $\mathcal X$. Such settings frequently arise in practical applications, where the focus is on characterizing specific subsets of quantum states. Furthermore, experimental constraints often limit the implementable set of measurement operations. We derive bounds on $\text{sfat} (\mathcal{H}, \mathcal{X})$ for several such practically relevant subsettings, leading up to the most general formulation of the learning problem. In addition, we extend the tightness of minimax regret in the non-realizable case $\mathcal{V}_T=\tilde \Theta(\sqrt{nT})$ \citep{aaronson2019online} to the realizable case.


In our approach, we explicitly construct an $\mathcal{X}$-valued complete binary tree $\mathbf{x}$ of depth $T(\delta, n)$ and prove that it is $\delta$-shattered by $\mathcal{H}$. That is we will define an explicit $[0,1]$-valued complete binary tree $\mathbf{v}$ of same depth $T(\delta, n)$, and a function $\boldsymbol \omega:\{\pm 1\}^{T-1}\rightarrow{\mathcal C}_n$ such that for all paths $\ \boldsymbol{\epsilon} \in \{\pm 1\}^{T-1}$,
\begin{equation}
     \forall t \in [T(\delta,n)] \ \ \epsilon_t [\operatorname{Tr}_{\boldsymbol \omega(\boldsymbol \epsilon)}(\mathbf{x}_t(\boldsymbol{\epsilon})) - \mathbf{v}_t (\boldsymbol{\epsilon})] \geq \frac{\delta}{2}.
\end{equation}
This directly implies that $\text{sfat}_\delta (\mathcal{H}, \mathcal{X}) = \Omega(T(\delta, n))$.
% While proving this, we will also provide lower bounds for several simplified settings, when we further restrict the quantum states studied, or the measurements that we are allowed to implement. Not only will this allow to slowly build up to the final proof, it will also show regret lower bounds for several interesting quantum state learning problems.

To set the stage for the following sections, we first establish a few notations: since we will frequently consider pure states, the quantum state $\boldsymbol\omega (\boldsymbol{\epsilon})$ will be denoted by its associated vector $\ket{\psi (\boldsymbol{\epsilon})}$, where $\boldsymbol\omega (\boldsymbol{\epsilon})=\ket{\psi(\boldsymbol{\epsilon})} \bra{\psi(\boldsymbol{\epsilon})}$. Furthermore, we define $N=2^n$  to be the dimension of the Hilbert space under consideration. Additionally, we will denote the pair of binary trees $(\mathbf{x}, \mathbf{v})$ by a single tree $\mathbf{T}$. We call $\mathbf{x}$ the $\mathcal{X}$-valued part of $\mathbf{T}$, and $\mathbf{v}$ the real-valued part of $\mathbf{T}$.

\subsection{Learning with respect to a single measurement}

We start with the learning problem of estimating the expectation value of an unknown $n$-qubit quantum state with respect to a fixed measurement operator $E$. This learning problem is key to practical tasks such as quantum state discrimination and hypothesis testing \citep{barnett2008quantumstatediscrimination, Bae_2015}.
Formally, we take $\mathcal{X}=\{E\}$ to be the sample space and keep $\mathcal{H}_n$ as the hypothesis class. As mentioned previously, we are focused on providing a lower bound on $\text{sfat}_\delta(\mathcal{H}_n, \mathcal{X})$, which could then be used to lower bound $\mathcal{V}_T$. We achieve this by constructing what we call the Halving tree $\mathbf{T}_h$, which has a constant $\mathcal X$-valued part, and a real-valued part as shown in \cref{fig:halving_tree}. Every halving tree $\mathbf{T}_h [i, T]=(\mathbf x,\mathbf v)$ will thus be entirely determined by its depth $T$ and the constant measurement $\vonneu i$. The name follows from the distinctive structure exhibited by the real part of the tree $\mathbf{T}_h [i, T]$, as shown in \cref{fig:halving_tree}. This construction will prove useful as a crucial building block for establishing the regret bounds in more general settings (see \cref{theo:vnh,thm:final,theo:final_pure}). 

\begin{figure}[h]
    \centering
    \begin{forest}
    for tree={
        math content, % Ensures math mode inside nodes
        align=center, % Center-aligns the text inside the nodes
        s sep=0.45mm, % Further reduce width between siblings
        l sep=0.6mm, % Further reduce height between levels
        inner sep=1mm, % Reduce padding inside nodes
    }
    [$\frac12$
        [$\frac14$
            [$\frac18$
                [$\vdots$
                    [$\frac1{2^T}$]
                    [$\frac3{2^T}$]
                ]
                [$\vdots$
                    [$\cdots$, no edge]]
            ]
            [$\frac38$
                [$\vdots$
                     [$\cdots$, no edge]]
                [$\vdots$
                    [$\cdots$, no edge]]
            ]
        ]
        [$\frac34$
            [$\frac58$
                [$\vdots$
                    [$\cdots$, no edge]]
                [$\vdots$
                     [$\cdots$, no edge]]
            ]
            [$\frac78$
                [$\vdots$
                    [$\cdots$, no edge]]
                [$\vdots$
                    [$\frac{2^T-3}{2^T}$]
                    [$\frac{2^T-1}{2^T}$]
                ]
            ]
        ]
    ]
    \end{forest}
    \caption{Real valued part of a $T$-depth halving tree $\mathbf{T}_h$, up to a constant multiplicative factor $\frac1N$.}
    \label{fig:halving_tree}
\end{figure}


\begin{theorem}\label{theo:single_meas}
   Let $E\in\mathrm{Herm}_{\mathbb{C}}(2^n), \operatorname{Spec}(E)\subset[0,1]$ be a fixed measurement, and $\mathcal{X}=\{E\}$ be the sample space.
    Let $\mathcal{H}_n=\{\operatorname{Tr}_\omega, \omega\in\mathcal C_n\}$ be the hypothesis class, where $\mathcal{C}_n$ is the set of all $n$-qubit quantum states. Then we have $\text{sfat}_\delta(\mathcal H_n, \mathcal{X})=\Omega(\log_2(\frac1\delta))$.
\end{theorem}

We prove this result in \cref{pf:single_meas}.

\begin{remark}
    Note that the lower bound on the fat-shattering dimension obtained above is independent of $n$, and therefore still holds if the hypothesis class is induced by 1-qubit pure states.
\end{remark}




\subsection{Learning uniform superposition states}
\label{sec:vn}


In the previous section, the focus was on learning the expectation value of a single measurement. We now shift our attention to a harder setting. Consider the sample space $\mathcal{X}$ consisting of the $N$ measurements corresponding to an orthogonal basis of $\mathcal C_n$. The hypothesis class will be induced by the uniform superpositions of basis states.
Such states play an important role in fundamental quantum algorithms \citep{365701, Shor_1997, Grover_1997}, and for quantum random number generators \citep{Mannalatha_2023}.
We now provide a lower bound to the sequential fat-shattering dimension for this specific setting. We accomplish this by constructing what we call the Von Neumann tree $\mathbf{T}_{vn}$.
The name follows from the fact that, while its real-valued part is constant, all nodes in the $\mathcal{X}$-valued part of $\mathbf{T}_{vn}$ are labeled by Von Neumann measurements as shown in \cref{fig:vn_tree}.
\begin{figure}[h]
    \centering
    \begin{forest}
    for tree={
        math content, % Ensures math mode inside nodes
        align=center, % Center-aligns the text inside the nodes
        s sep=0.45mm, %  Width
        l sep=6mm, % Height
        inner sep=1mm, % Increase the padding inside the nodes
    }
    [$\vonneu{0}$
        [$\vonneu{1}$
            [$\vdots$
                [$\vonneu{T-1}$]
                [$\cdots$]
            ]
            [$\vdots$
                [$\cdots$, no edge]]
        ]
        [$\vonneu{1}$
            [$\vdots$
                [$\cdots$, no edge]]
            [$\vdots$
                [$\cdots$]
                [$\vonneu{T-1}$]
            ]
        ]
    ]
    \end{forest}
    \caption{The $\mathcal{X}$-valued part of the Von Neumann tree $\mathbf{T}_{vn}$.}
    \label{fig:vn_tree}
\end{figure}


\begin{theorem}\label{theo:uniform}
    Let $(\vect {0},...,\vect{N-1})$ be an orthogonal basis of $\mathcal C_n$, where $\mathcal{C}_n$ is the set of all $n$-qubit quantum states. Denote the sample space as $\mathcal{X}=\{\vonneu{i},i\in\llbracket 0, N-1 \rrbracket\}$. Let $\mathcal{H}=\{\operatorname{Tr}_\omega,\omega=\frac1{\sqrt{\vert I\vert}}\sum_{i\in I}\vect i, I\subset\llbracket0,N-1\rrbracket\}$ be the hypothesis class. Then we have $\text{sfat}_\delta(\mathcal H, \mathcal{X})=\Omega(\min(\frac1\delta,2^n))$.

\end{theorem}

We prove this result in \cref{pf:uniform}.

\subsection{Learning general states using Von Neumann measurements}


Building on the setting established in the previous section, we consider the sample space $\mathcal{X}$ consisting of the $N$ measurements corresponding to an orthogonal basis of $\mathcal C_n$. The hypothesis class in the present setting is however induced by the set of all pure quantum states. The corresponding learning problem involves a learner estimating the expectation values of an unknown $n$-qubit quantum state with respect to $N$ measurement operators, where the hypothesis is chosen from the set of all $n$-qubit pure quantum states.
Related problems have been considered, for example, in \citet{zhao2023provablelearningquantumstates}.

We now provide a lower bound to the sequential fat-shattering dimension for this specific setting. We accomplish this by constructing what we call the Von Neumann Halving tree $\mathbf{T}_{vnh}$, which is constructed by combining $\mathbf{T}_h$ and $\mathbf{T}_{vn}$ as shown in \cref{fig:vn_halving_tree}. Our construction illustrates the utility of $\mathbf{T}_h$, demonstrating its effectiveness as a tool to multiply existing lower bounds by a factor of $n$.
\begin{figure}[h]
    \centering
    \begin{forest}
    for tree={
        math content, % Ensures math mode inside nodes
        align=center, % Center-aligns the text inside the nodes
        s sep=5mm, %  Width
        l sep=10mm, % Height
        % inner sep=5mm, % Increase the padding inside the nodes
    }
    [$\vonneu{0}$
        [$\vonneu{1}$, edge label={node[midway,left] {$\mathbf{T}_h [0, T]$}}
            [$\vdots$, edge label={node[midway,left] {$\mathbf{T}_h [1, T]$}}
                [$\vonneu{N-2}$, edge label={node[midway,left] {$\mathbf{T}_h [N-3, T]$}}
                    [, edge label={node[midway,left] {$\mathbf{T}_h [N-2, T]$}}]
                ]
            ]
        ]
    ]
    \end{forest}
    \caption{Von Neumann Halving Tree}
    \label{fig:vn_halving_tree}
\end{figure}
\begin{theorem}
\label{theo:vnh}
Let $(\vect {0},...,\vect{N-1})$ be an orthogonal basis of $\mathcal C_n$ and $\mathcal{X}=\{\vonneu{i},i\in\llbracket 0, N-1 \rrbracket\}$ be the sample space. Let $\mathcal{H}=\{\operatorname{Tr}_\omega, \omega \in \mathcal{C}_n, \operatorname{Tr}(\omega^2) = 1\}$ be the hypothesis class. Here $\mathcal{C}_n$ is the set of all $n$-qubit quantum states. Then,  for $\delta=2^{-\frac n\eta}$, we have $\text{sfat}_\delta(\mathcal H_n, \mathcal{X})=\Omega(\frac n{\delta^\eta}) \ \forall\eta<1$.


\end{theorem}

We prove this result in \cref{pf:vnh}.

\subsection{Tightness of sequential fat-shattering dimension of quantum states}
\label{sec:tightness_gen}

Having considered several restricted settings in the previous sections, we now turn to the most general formulation of the online quantum state learning problem. Formally, we define the sample space to be the space of all 2-outcome measurements $\mathcal{X}$, while the Hypothesis class is given as $\mathcal{H}_n$. Our objective is to derive a tight lower bound on $\text{sfat}_\delta (\mathcal{H}_n, \mathcal{X})$. To accomplish this, we will use the techniques developed in the previous sections. In addition, we will establish new results on completion of partial matrices, which are essential for our analysis. We start with the latter. 

Let us first introduce a few necessary definitions on partial matrices and their completions. A partial matrix is a matrix in which certain entries are specified while the other entries are free to be chosen. It is called partial symmetric if it is symmetric on the specified entries. And a completion of a partial matrix refers to a specific assignment of values to its unspecified entries. 



\begin{theorem}\label{lemma_completion}
    Any real partial symmetric matrix $\omega$ satisfying the following conditions
    \begin{enumerate}
        \item $w_{11}=\frac{1}{2}$, and $w_{ii}=\frac{1}{2(N-1)}$ $\forall i\in\llbracket2,N\rrbracket$,
        \item Elements are specified on the set $\{w_{1i}, w_{i1}\}$, where $i\in [N]$,
        % Only the following elements are specified: $\{w_{1j}, w_{i1}\}$.
        \item $\forall i\in\llbracket2,N\rrbracket,|w_{1i}|\leq\frac1{2\sqrt{N-1}}$,
    \end{enumerate}
can be completed to a density matrix.
\end{theorem}
We prove this result in \cref{pf:lemma_completion}.
\begin{figure}[h]
    \centering
    % \includegraphics[width=0.5\linewidth]{}
\[
% \text{part} (w_{12}, w_{13}, \cdots, w_{1N}) =
\begin{bmatrix}
\frac12 & w_{12} & \cdots & \cdots & w_{1N} \\
w_{12} & \frac1{2(N-1)} & ? & \cdots & ? \\
\vdots & ? & \frac1{2(N-1)} & \cdots & ? \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
w_{1N} & ? & ? & \cdots & \frac1{2(N-1)}
\end{bmatrix}
\]
\caption{General form of the partial matrix described in \cref{lemma_completion}. The interrogation marks denote the unspecified entries in the matrix.}
    \label{fig:part_matrix}
\end{figure}
Any partial matrix of the form shown in \cref{fig:part_matrix} shall be denoted as $\text{part} (w_{12}, w_{13}, \cdots, w_{1N})$.

We now derive the lower bound for $\text{sfat}_\delta (\mathcal{H}_n, \mathcal{X})$. The key idea is to construct a new tree analogous to the Von Neumann halving tree, with a crucial distinction that it accommodates more general measurements, extending beyond the $\vonneu i$ type measurements that have been considered thus far. Furthermore, given this tree, we apply \cref{lemma_completion} to ensure that all paths on the tree can be associated to a valid density matrix. We show that this allows us to obtain the quadratic dependence on $\frac{1}{\delta}$ in the lower bound of $\text{sfat}_\delta (\mathcal{H}_n, \mathcal{X})$, thus establishing the almost tightness.
\begin{theorem}\label{thm:final}
    Let $\mathcal{X} = \{E\in\mathrm{Herm}_{\mathbb{C}}(2^n), \operatorname{Spec}(E)\subset[0,1]\}$ be the sample space.
    Define $\mathcal{H}_n=\{\operatorname{Tr}_\omega, \omega\in\mathcal C_n\}$ as the hypothesis class, where $\mathcal{C}_n$ is the set of all $n$-qubit quantum states. Then, for $\delta=2^{-\frac n\eta}$, we have $\text{sfat}_\delta(\mathcal H_n, \mathcal{X})=\Omega(\frac n{\delta^\eta}), \forall\eta < 2$.
\end{theorem}
We prove this result in \cref{pf:final}.
\begin{remark}

    As mentioned in the beginning of this section, our method for lower bounding the sequential fat-shattering dimension differs from that employed in \citet{aaronson2007learnability}, and is adaptable to various restricted online quantum state learning settings. For cases involving further restrictions, whether on the sample space, the hypothesis class or the relationship between $\delta$ and $n$ (Recall that \citet{aaronson2007learnability} required $\delta\geq\sqrt{n2^{-(n-5)/35}/8}$) we conjecture that the techniques from \cref{proof:final} involving matrix completion would serve as a valuable foundation. 


\end{remark}

% \end{proof}
Building on this result, we proceed to establish the tightness of the minimax regret $\mathcal{V}_T$ with the $L_1$-loss. While the bound has already been shown to be tight in the non-realizable case \citep{arora2012multiplicative, aaronson2019online}, we extend the tightness result in the realizable setting.



\begin{corollary}
\label{cor:tight_reg_gen}
    Let $\mathcal{X} = \{E\in\mathrm{Herm}_{\mathbb{C}}(2^n), \operatorname{Spec}(E)\subset[0,1]\}$ be the sample space.
    Define $\mathcal{H}_n=\{\operatorname{Tr}_\omega, \omega\in\mathcal C_n\}$ as the hypothesis class, where $\mathcal{C}_n$ is the set of all $n$-qubit quantum states. Then we have $\mathcal{V}_T=\Omega(\sqrt{nT})$, assuming the loss function under consideration is the $L_1$-loss.
\end{corollary}
We prove this result in \cref{pf:cor}.
