Learning information from an unknown quantum state is a fundamental task in quantum physics. Given several perfect copies of an $N$-dimensional quantum state $\rho \in \{\mathrm{Herm}_{\mathbb{C}} (N)\mid \ \operatorname{Tr}(\rho) = 1, \ \rho \succeq 0\}$, quantum full state tomography seeks to reconstruct the complete matrix representation of $\rho$ via measurements. It has a wide range of practical applications, including tasks such as characterizing qubit states for superconducting circuits \citep{PhysRevLett.100.247001}, nitrogen-vacancy (NV) centers in diamond \citep{doi:10.1126/science.1189075}, and verifying successful quantum teleportation \citep{Bouwmeester_1997}. The ease of learning a quantum state is often characterized by the sample complexity, \textit{i.e.} the number of independent copies of the quantum state required for an accurate reconstruction. For a general density matrix $\rho$, the sample complexity scales as $\tilde{\Theta}(N^3)$ for incoherent measurements. However, if the state is known to be pure, the sample complexity can be improved to $\tilde{\Theta}(N)$ \citep{kueng2014lowrankmatrixrecovery, harrow16sampletomography, chen2023doesadaptivityhelpquantum} . Nevertheless, for $n$-qubit states, where $N = 2^n$, this scaling implies an exponential dependence on the number of qubits.


However, for many practical problems, such as certification of a quantum device \citep{Gross_2010, Flammia_2011, eisert2020quantumcertification} and property estimation for quantum chemistry \citep{Huang_2021, Wu2023overlappedgrouping, zhang2023composite, guo2024estimatingpropertiesquantumstate, Miller_2024}, only partial information about the quantum state is needed. To address such cases, quantum PAC learning, also known as pretty good tomography, was introduced by \citet{aaronson2007learnability}. In this framework, a fixed distribution $\mathcal{D}$ governs the selection of two-outcome measurements $E$, which are represented by $N\times N$ Hermitian matrices with eigenvalues in $[0,1]$. The learner then tries to output a hypothesis state $\omega$ for which $\operatorname{Tr} (E \rho) \approx \operatorname{Tr} (E \omega)$ with high probability. The number of measurements required to output this hypothesis state was shown to scale only linearly with the number of qubits $n$, yielding an exponential speed-up over full-state tomography. However, a key limitation of both these approaches is that they do not account for adversarial environments, where the set of realizable measurements may evolve over time.
 


This limitation can be circumvented by generalizing to the online learning setting \citep{aaronson2019online, chen2020practicaladaptivealgorithmsonline,Chen2024adaptive}, where learning a quantum state $\rho$ is posed as a $T$-round repeated two-player game. In each round $t \in [T]$, Nature -- also called the adversary -- chooses a measurement $E_t$ from the set of two-outcome measurements. The task of the learner is to predict the value $\mathrm{Tr}(E_t\rho)$ by selecting a hypothesis $\omega_t$ and computing $\mathrm{Tr}(E_t\omega_t)$ based on previous results. Thereafter, Nature returns the loss, a metric quantifying the difference between the prediction and the true value. The most adversarial scenario arises when the measurement at each round is chosen from the set of all two-outcome measurements without any constraints, \textit{i.e.}, it can be chosen adversarially and adaptively. It has been shown that in such cases, a learner can output a hypothesis state which incurs an additional $O(\sqrt{nT})$ loss compared to the best possible hypothesis state after $T$ rounds of the game \citep{aaronson2019online}. This measure of how much worse a learner performs compared to the best possible strategy in hindsight is called regret and serves as a fundamental measure of performance for any online learning problem.


Given the clear separation in sample complexity between pure and mixed state tomography \citep{kueng2014lowrankmatrixrecovery, harrow16sampletomography}, we ask the central question that this work aims to address:

\begin{center}
\textit{Is there any separation between online learning of pure and mixed quantum states?}
\end{center}


\noindent In this work, we show that the answer is \textbf{No} when comparing regrets with respect to the $L_1$ loss. We believe that this result is surprising. Indeed, not only is there a significant difference in sample complexities between learning pure and mixed states in the standard tomographic settings, but this distinction also holds in specific online learning scenarios. For instance, under bandit feedback with adaptive measurements, \citet{Lumbreras_2022, lumbreras2024learningpurequantumstates} shows that the regret for mixed states grows exponentially faster than for pure states.

Our proof is based on the analysis of the sequential fat-shattering dimension of those states. Informally, it can be seen as the minimum number of mistakes -- defined as errors exceeding a threshold $\delta$ -- that a learner must make before successfully learning a quantum state $\rho$ against a perfect adversary. It has been demonstrated that both upper and lower bounds on regret can be expressed in terms of this dimension \citet{rakhlin2015sequential}. Therefore, it suffices to study the bounds of the latter, for the specific cases of pure and mixed state learning, to address the question posed above. Prior work \citep{aaronson2019online} established tight bounds on the sequential fat-shattering dimension of general mixed states. In this work, we establish lower bounds on the sequential fat-shattering dimension -- and consequently on the regret -- of several subclasses of quantum states, the most important of which is the class of pure states. Our approach employs a distinct proof strategy, providing new insights and extending naturally to various subsettings of the online quantum state learning problem. As a result, we show that the regret for online learning of both pure and mixed quantum state scales as $\Theta(\sqrt{nT})$.

A key feature of the online learning setting considered here is the adversary's ability to select measurements in a completely unconstrained manner. As a result, this setting may effectively incur full state tomography, even in cases where only partial information about the state is needed.  We therefore introduce the concept of smoothness for online learning of quantum states. Smoothed analysis was first introduced in \citet{spielman2004} as a tool that allows for interpolation between the worst and the average case analysis. Later, \citet{Haghtalab2024} extended this concept to the online setting, where the degree of adversariality is quantified by a smoothness parameter $\sigma \in [0,1]$. The particular value $\sigma = 1$ corresponds to $\mathrm{i.i.d.}$ inputs, while the limit $\sigma \rightarrow 0$ corresponds to fully adversarial inputs. In this work, we establish an upper bound on regret for smooth online learning of quantum states, providing insights into the effect of adversariality on regret scaling.


\subsection{Structure of the paper}

We start with a formal description of online learning and its application towards quantum state learning in \cref{sec:preliminaries}. In particular, we focus on regret and sequential fat-shattering dimension as fundamental measures of performance for any online learning problem. In \cref{sec:sfat_intro}, we proceed to derive bounds on sequential fat-shattering dimension, and hence regret, for several subsettings of quantum state learning. We use the techniques developed in this section to prove our main result in \cref{sec:main}, where we show that online learning of pure states is as hard as mixed states. In \cref{sec:smooth}, we extend our analysis to a smooth version of online learning of quantum states and derive an upper bound on the associated regret. Finally, we conclude the paper in \cref{sec:concl}.
