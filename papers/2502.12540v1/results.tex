\section{Results}\label{sec:results}


\subsection{Cold Start Percentage}

Figures~\ref{fig:cold_start_1} and~\ref{fig:cold_start_2} illustrate the impact of the KiSS framework's partitioned warm pool architecture on cold start percentages under various configurations, including 90-10, 80-20, 70-30, 60-40, and 50-50 splits, compared to a baseline without partitioning. The 80-20 split consistently achieved the lowest cold start percentages, especially in memory-constrained edge environments (4–16 GB):
\begin{itemize}
    \item \textbf{4 GB memory:} Cold starts dropped from \textbf{62\% (baseline)} to \textbf{52\%}, a \textbf{16.2\% improvement}.
    \item \textbf{8 GB memory:} Cold starts decreased from \textbf{43\% to 18\%}, a \textbf{58\% reduction}.
    \item \textbf{10 GB memory:} Cold starts were reduced from \textbf{20\% to 8\%}, a \textbf{60\% improvement}.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[trim = 7 5 5 5, width=1\columnwidth]{All_Splits_Cold_Starts.pdf}
    \caption{Cold start percentages across different configurations.}
    \label{fig:cold_start_1}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{Cold_Starts_Baseline_vs_Modded_Overall.pdf}
    \caption{Comparison of the 80-20 split with the baseline configuration.}
    \label{fig:cold_start_2}
\end{figure}

Alternative splits showed varying degrees of performance. The 70-30 split, while close in performance, exhibited higher cold start percentages in low-memory settings (e.g., \textbf{42\% at 4 GB} vs. \textbf{38\% for 80-20}). The 90-10 split overly prioritized small containers, starving large containers of resources, while the 50-50 split failed to sufficiently prioritize small containers, resulting in significantly higher cold start percentages overall.

The scalability of the 80-20 split was particularly notable. In highly provisioned environments (>16 GB), cold start percentages for both the 80-20 and baseline configurations approached near-zero, showing diminishing returns in memory-abundant scenarios.

\subsection{Drop Percentage}

Figure~\ref{fig:drop_percentage} highlights the drop percentage, which measures the proportion of function invocations that cannot be serviced due to resource contention.
\begin{itemize}
    \item \textbf{2–3 GB memory:} KiSS showed slightly higher drop percentages than the baseline, with drops at \textbf{60\% vs. 58\%} for 2 GB and \textbf{51\% vs. 50\%} for 3 GB. This was attributed to the resource isolation introduced by partitioning in extremely low-memory settings.
    \item \textbf{4–8 GB memory:} Partitioning stabilized, and KiSS significantly reduced drops. At \textbf{6 GB}, drops decreased from \textbf{34\% (baseline)} to \textbf{27\%} (\textbf{21\% improvement}). At \textbf{8 GB}, drops fell from \textbf{23\% to 10\%}, reflecting a \textbf{56.5\% improvement}.
    \item \textbf{Beyond 8 GB:} Both configurations exhibited near-zero drop percentages, demonstrating the scalability of the KiSS framework in well-provisioned environments.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{Drops_Overall.pdf}
    \caption{Drop percentage across memory configurations.}
    \label{fig:drop_percentage}
\end{figure}


\subsection{Fairness Analysis}

Figures~\ref{fig:cold_start_small} through~\ref{fig:drop_large} assess fairness by comparing cold start percentages, drop percentages, and memory utilization for small (QoS) and large (QoSLarge) containers.

Figures~\ref{fig:cold_start_small} and~\ref{fig:cold_start_large} illustrate the following trends for cold start percentages:
    \begin{itemize}
        \item \textbf{Small Containers:} At \textbf{4 GB}, cold starts reduced from \textbf{63\% (baseline)} to \textbf{53\%}, a \textbf{16\% improvement}, and from \textbf{45\% to 18\%} at \textbf{8 GB}, a \textbf{60\% reduction}.
        \item \textbf{Large Containers:} At \textbf{4 GB}, cold starts dropped from \textbf{61\% to 54\%} (\textbf{11.5\% improvement}) and from \textbf{37\% to 20\%} at \textbf{8 GB} (\textbf{46\% improvement}).
    \end{itemize}
   

Figures~\ref{fig:drop_small} and~\ref{fig:drop_large} illustrate the following trends in drop percentages for small and large containers:
    
    \begin{itemize}
        \item \textbf{Small Containers:} Drops increased slightly at \textbf{4 GB} (\textbf{32\% to 33\%}) but improved significantly at \textbf{8 GB} (\textbf{15\% to 6\%}, a \textbf{60\% improvement}).
        \item \textbf{Large Containers:} Drops reduced from \textbf{85\% to 78\%} at \textbf{4 GB} (\textbf{8.2\% improvement}) and from \textbf{47\% to 24\%} at \textbf{8 GB} (\textbf{49\% improvement}).
    \end{itemize}
    

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{Cold_Starts_Baseline_vs_Modded_QoS.pdf}
    \caption{Cold start percentages for small containers.}
    \label{fig:cold_start_small}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{Cold_Starts_Baseline_vs_Modded_QoSlarge.pdf}
    \caption{Cold start percentages for large containers.}
    \label{fig:cold_start_large}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{DropsQoS.pdf}
    \caption{Drop percentages for small containers.}
    \label{fig:drop_small}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{DropsQoSlarge.pdf}
    \caption{Drop percentages for large containers.}
    \label{fig:drop_large}
\end{figure}


\subsection{Policy Independence}

The KiSS framework demonstrates robust independence from specific replacement policies, maintaining consistent performance across Least Recently Used (LRU), Greedy Dual (GD), and Frequency-Based (FREQ) policies. This flexibility makes KiSS adaptable to a variety of serverless environments, allowing it to optimize performance regardless of the resource management strategy in use. Figures~\ref{fig:policy_fairness_small}, \ref{fig:policy_overall}, and \ref{fig:policy_fairness_large} illustrate the framework’s consistent cold start percentage reduction for small, overall, and large containers, respectively.

\noindent\textbf{Small Containers Performance}  
Figure~\ref{fig:policy_fairness_small} shows the cold start percentages for small containers under the three replacement policies. Across the memory configurations, all policies exhibit similar trends. The cold start percentages reduce significantly as memory increases from 4 GB to 10 GB, with negligible differences between policies. In edge environments (4–8 GB memory), LRU slightly outperforms GD and FREQ, but the differences are marginal. This demonstrates KiSS’s ability to prioritize high-frequency small containers, regardless of the policy in use.

\noindent\textbf{Overall Performance}  
As shown in Figure~\ref{fig:policy_overall}, the overall cold start percentages for all containers (small and large) remain consistent across the three policies. LRU, GD, and FREQ exhibit overlapping performance trends, with cold start percentages converging to near-zero beyond 16 GB memory. In edge-specific memory ranges (4–8 GB), KiSS achieves significant cold start reductions under all policies when compared to baseline, emphasizing its independence from specific replacement strategies.

\noindent\textbf{Large Containers Performance}  
Figure~\ref{fig:policy_fairness_large} highlights the cold start percentages for large containers across the three replacement policies. In memory-constrained settings (4–6 GB), the differences between policies are slightly more pronounced, with GD and FREQ slightly underperforming compared to LRU. However, the differences diminish as memory scales, with all policies converging at near-zero cold start percentages beyond 16 GB. This shows that KiSS ensures adequate prioritization of low-frequency, high-memory functions, regardless of the policy used.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{Policies_for_Modded_QoS.pdf}
    \caption{Cold start percentages for small containers across LRU, GD, and FREQ policies.}
    \label{fig:policy_fairness_small}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[trim = 5 35 20 30, width=1\columnwidth]{Policies_for_Baseline_vs_Modded_Overall.pdf}
    \caption{Overall cold start percentages across LRU, GD, and FREQ policies.}
    \label{fig:policy_overall}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{Policies_for_Modded_QoS_Large.pdf}
    \caption{Cold start percentages for large containers across LRU, GD, and FREQ policies.}
    \label{fig:policy_fairness_large}
\end{figure}


\subsection{Stress Testing}
To evaluate the robustness of KiSS under high-demand conditions, we conducted a stress test using a two-hour unedited trace comprising 4--5 million invocations on a 10 GB memory pool.  
KiSS serviced 150,000 requests compared to 160,000 in the baseline, maintaining high throughput under extreme load. KiSS also improved the hit rate from 0.38\% in the baseline to 2.85\%, showcasing its ability to prioritize critical requests and reduce contention.

Our analysis showed that the increased hit rate under KiSS demonstrates its ability to manage resource contention effectively. Additionally, KiSS maintained robust performance during workload spikes, validating its scalability and adaptability.

