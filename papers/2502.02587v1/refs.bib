@InProceedings{C2,
  author = 	 "Jones, C.D. and Smith, A.B. and Roberts, E.F.",
  title =        "Paper Title",
  booktitle =    "Proceedings Title",
  organization = "IEEE",
  year = 	 "2003",
  volume = 	 "II",
  pages = 	 "803-806"
}

% chris
@misc{who2018,
    author = {{World Health Organization}},
    title = {Estimates},
    year = {2018},
    month = {Jul},
    publisher = {World Health Organization},
    journal = {World Health Organization},
    url = {https://www.who.int/deafness/estimates/en/#:~:text=there%20are%20466%20million%20persons,affected%20by%20disabling%20hearing%20loss},
    note = {Accessed: 2025-02-04}
}
    
@article{woll2001multilingualism,
  title={Multilingualism: The global approach to sign languages},
  author={Woll, Bencie and Sutton-Spence, Rachel and Elton, Frances},
  journal={The sociolinguistics of sign languages},
  volume={8},
  pages={32},
  year={2001},
  publisher={Cambridge University Press Cambridge}
}

 @misc{unitednations, 
 title={International Day of Sign Languages}, 
 url={https://www.un.org/en/observances/sign-languages-day}, 
 journal={United Nations}, 
 publisher={United Nations}
 } 
 
@misc{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{camgoz2018neural,
  title={Neural sign language translation},
  author={Camgoz, Necati Cihan and Hadfield, Simon and Koller, Oscar and Ney, Hermann and Bowden, Richard},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7784--7793},
  year={2018}
}

@inproceedings{hu2020sign,
  title={Sign Language Translation: a Deep Learning-based Approach},
  author={Hu, Xiaoying and Li, Xiaoming and Ji, Peng and Cao, Xiaochun},
  booktitle={2020 IEEE International Conference on Signal and Image Processing (ICSIP)},
  pages={131--136},
  year={2020},
  organization={IEEE},
  doi={10.1109/ICSIP50750.2020.9376157}
}

@article{li2022sign,
  title={Sign language recognition and translation network based on multi-view data},
  author={Li, Ronghui and Meng, Lu},
  journal={Applied Intelligence},
  volume={52},
  number={13},
  pages={14624--14638},
  year={2022},
  publisher={Springer}
}

@inproceedings{zhang2019sign,
  title={Sign language translation using multimodal recurrent neural networks with visual attention},
  author={Zhang, Zhaopeng and Liu, Huan and Yang, Yandong and Chen, Dongmei and Wang, Mu},
  booktitle={2019 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1368--1374},
  year={2019},
  organization={IEEE},
  doi={10.1109/ICRA.2019.8793686}
}

@misc{camgoz2020sign,
      title={Sign Language Transformers: Joint End-to-end Sign Language Recognition and Translation}, 
      author={Necati Cihan Camgoz and Oscar Koller and Simon Hadfield and Richard Bowden},
      year={2020},
      eprint={2003.13830},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yin2020better,
      title={Better Sign Language Translation with STMC-Transformer}, 
      author={Kayo Yin and Jesse Read},
      year={2020},
      eprint={2004.00588},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wu2016googles,
      title={Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation}, 
      author={Yonghui Wu and Mike Schuster and Zhifeng Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and Maxim Krikun and Yuan Cao and Qin Gao and Klaus Macherey and Jeff Klingner and Apurva Shah and Melvin Johnson and Xiaobing Liu and Łukasz Kaiser and Stephan Gouws and Yoshikiyo Kato and Taku Kudo and Hideto Kazawa and Keith Stevens and George Kurian and Nishant Patil and Wei Wang and Cliff Young and Jason Smith and Jason Riesa and Alex Rudnick and Oriol Vinyals and Greg Corrado and Macduff Hughes and Jeffrey Dean},
      year={2016},
      eprint={1609.08144},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{bai2018empirical,
      title={An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling}, 
      author={Shaojie Bai and J. Zico Kolter and Vladlen Koltun},
      year={2018},
      eprint={1803.01271},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gehring2017convolutional,
      title={Convolutional Sequence to Sequence Learning}, 
      author={Jonas Gehring and Michael Auli and David Grangier and Denis Yarats and Yann N. Dauphin},
      year={2017},
      eprint={1705.03122},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{https://doi.org/10.1049/cvi2.12037,
author = {Rodriguez, Jefferson and Martínez, Fabio},
title = {How important is motion in sign language translation?},
journal = {IET Computer Vision},
volume = {15},
number = {3},
pages = {224-234},
doi = {https://doi.org/10.1049/cvi2.12037},
url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/cvi2.12037},
eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cvi2.12037},
abstract = {Abstract More than 70 million people use at least one sign language (SL) as their main channel of communication. Nevertheless, the absence of effective mechanisms to translate massive information among sign, written and spoken languages is the main cause of a negligible inclusion of deaf people into society. Therefore, SL automatic recognition systems have widely proposed to support the characterisation of the sign structure. Today, natural and continuous SL recognition is an open research problem due to multiple spatio-temporal shape variations, challenging visual sign characterisation, as well as the non-linear correlation among signs to express a message. A compact sign is introduced to text architecture that explores motion as an alternative to support sign translation. Such characterisation results are robust to appearance variance with relative support to geometrical variations. The proposed representation focuses on the main spatio-temporal regions to each corresponding word. The proposed architecture was evaluated in a built SL data set (LSCDv1) dedicated to motion study and also in the state-of-the-art RWTH-Phoenix. From the LSCDv1 data set, the best configuration reports a BLEU-4 score of 63.04 in a testing set. Regarding RWTH-Phoenix, the proposed strategy achieved a BLEU-4 score in a test of 4.56, improving the results under similar reduced conditions.},
year = {2021}
}

@ARTICLE{9354538,  author={Zhou, Hao and Zhou, Wengang and Zhou, Yun and Li, Houqiang},  journal={IEEE Transactions on Multimedia},   title={Spatial-Temporal Multi-Cue Network for Sign Language Recognition and Translation},   year={2022},  volume={24},  number={},  pages={768-779},  doi={10.1109/TMM.2021.3059098}}

@inproceedings{wu2021rethinking,
  title={Rethinking and improving relative position encoding for vision transformer},
  author={Wu, Kan and Peng, Houwen and Chen, Minghao and Fu, Jianlong and Chao, Hongyang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10033--10041},
  year={2021}
}

@article{chu2021conditional,
  title={Conditional positional encodings for vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and Wang, Xinlong and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={arXiv preprint arXiv:2102.10882},
  year={2021}
}

@inproceedings{xu2021positional,
  title={Positional encoding as spatial inductive bias in gans},
  author={Xu, Rui and Wang, Xintao and Chen, Kai and Zhou, Bolei and Loy, Chen Change},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13569--13578},
  year={2021}
}

@article{zheng2021rethinking,
  title={Rethinking positional encoding},
  author={Zheng, Jianqiao and Ramasinghe, Sameera and Lucey, Simon},
  journal={arXiv preprint arXiv:2107.02561},
  year={2021}
}

@article{perniss2018mapping,
  title={Mapping language to the world: The role of iconicity in the sign language input},
  author={Perniss, Pamela and Lu, Jenny C and Morgan, Gary and Vigliocco, Gabriella},
  journal={Developmental Science},
  volume={21},
  number={2},
  pages={e12551},
  year={2018},
  publisher={Wiley Online Library}
}

@misc{zhang2019selfattention,
      title={Self-Attention Generative Adversarial Networks}, 
      author={Han Zhang and Ian Goodfellow and Dimitris Metaxas and Augustus Odena},
      year={2019},
      eprint={1805.08318},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}