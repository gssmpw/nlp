@ARTICLE{9354538,  author={Zhou, Hao and Zhou, Wengang and Zhou, Yun and Li, Houqiang},  journal={IEEE Transactions on Multimedia},   title={Spatial-Temporal Multi-Cue Network for Sign Language Recognition and Translation},   year={2022},  volume={24},  number={},  pages={768-779},  doi={10.1109/TMM.2021.3059098}}

@misc{camgoz2020sign,
      title={Sign Language Transformers: Joint End-to-end Sign Language Recognition and Translation}, 
      author={Necati Cihan Camgoz and Oscar Koller and Simon Hadfield and Richard Bowden},
      year={2020},
      eprint={2003.13830},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{https://doi.org/10.1049/cvi2.12037,
author = {Rodriguez, Jefferson and Mart√≠nez, Fabio},
title = {How important is motion in sign language translation?},
journal = {IET Computer Vision},
volume = {15},
number = {3},
pages = {224-234},
doi = {https://doi.org/10.1049/cvi2.12037},
url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/cvi2.12037},
eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cvi2.12037},
abstract = {Abstract More than 70 million people use at least one sign language (SL) as their main channel of communication. Nevertheless, the absence of effective mechanisms to translate massive information among sign, written and spoken languages is the main cause of a negligible inclusion of deaf people into society. Therefore, SL automatic recognition systems have widely proposed to support the characterisation of the sign structure. Today, natural and continuous SL recognition is an open research problem due to multiple spatio-temporal shape variations, challenging visual sign characterisation, as well as the non-linear correlation among signs to express a message. A compact sign is introduced to text architecture that explores motion as an alternative to support sign translation. Such characterisation results are robust to appearance variance with relative support to geometrical variations. The proposed representation focuses on the main spatio-temporal regions to each corresponding word. The proposed architecture was evaluated in a built SL data set (LSCDv1) dedicated to motion study and also in the state-of-the-art RWTH-Phoenix. From the LSCDv1 data set, the best configuration reports a BLEU-4 score of 63.04 in a testing set. Regarding RWTH-Phoenix, the proposed strategy achieved a BLEU-4 score in a test of 4.56, improving the results under similar reduced conditions.},
year = {2021}
}

@misc{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yin2020better,
      title={Better Sign Language Translation with STMC-Transformer}, 
      author={Kayo Yin and Jesse Read},
      year={2020},
      eprint={2004.00588},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

