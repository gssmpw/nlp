
\documentclass[preprint,5p,times,numbered]{elsarticle}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{algorithmic}
\usepackage[ruled]{algorithm2e}
\usepackage{pgfplots}
\pagestyle{empty} %page numbering at the middle bottom: plain
\usepackage{url}
\usepackage[font=normalsize]{caption}
% 设置标题左对齐，标签与表格内容左对齐
% \captionsetup[table]{
%   justification=raggedright, % 标题文本左对齐
%   labelsep=quad,             % 标签与标题的间距（适当调整）
%   singlelinecheck=off,       % 强制单行标题左对齐（否则可能自动居中）
%   skip=0pt,                  % 标题与表格的间距
%   margin=0pt                 % 标题左侧无缩进
% }

\def\x{{\mathbf x}}
\def\L{{\cal L}}
\def\et{{et al.}}
\def\ie{{i.e.}}
\def\eg{{e.g.}}

\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newtheorem{mydef}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{pf}{Proof}
\newtheorem{lemma}[theorem]{Lemma}

\begin{document}

\begin{frontmatter}

\title{RoadFed: A Multimodal \emph{Fed}erated Learning System for Improving \emph{Road} Safety}


\author[1]{Yachao~Yuan} %% Author name
\ead{chao910904@suda.edu.cn}
%% Author affiliation
\affiliation[1]{organization={School of Future Science and Engineering, Soochow University},%Department and Organization
            city={Suzhou},
            state={Jiangsu},
            country={China}}

\author[1]{Xingyu~Chen} 
\ead{2262404010@stu.suda.edu.cn}

% \author[2]{Thar Baker}
% \ead{t.shamsa@brighton.ac.uk}
% \affiliation[2]{organization={School of Architecture, Technology and Engineering, University of Brighton},
%             city={Brighton},
%             state={East Sussex},
%             country={United Kingdom}}

%% Abstract
\begin{abstract}
Internet of Things (IoTs) have been widely applied in Collaborative Intelligent Transportation Systems (C-ITS) for the prevention of road accidents. As one of the primary causes of road accidents in C-ITS, the efficient detection and early alarm of road hazards are of paramount importance. Given the importance, extensive research has explored this topic and obtained favorable results. However, most existing solutions only explore single-modality data, struggle with high computation and communication overhead, or suffer from the curse of high dimensionality in their privacy-preserving methodologies. To overcome these obstacles, in this paper, we introduce RoadFed, an innovative and private multimodal \emph{Fed}erated learning-based system tailored for intelligent \emph{Road} hazard detection and alarm. This framework encompasses an innovative Multimodal Road Hazard Detector, a communication-efficient federated learning approach, and a customized low-error-rate local differential privacy method crafted for high dimensional multimodal data. Experimental results reveal that the proposed RoadFed surpasses most existing systems in the self-gathered real-world and CrisisMMD public datasets. In particular, RoadFed achieves an accuracy of 96.42\% with a mere 0.0351 seconds of latency, and its communication cost is up to 1,000 times lower than existing systems in this field. It facilitates collaborative training with non-iid high dimensional multimodal real-world data across various data modalities on multiple edges while ensuring privacy preservation for road users.
\end{abstract}

%%Graphical abstract
%\begin{graphicalabstract}
%%\includegraphics[width=0.8\textwidth]{figures_journal//RoadFed.jpg}
%\end{graphicalabstract}

%Research highlights
%\onecolumn
%\begin{highlights}
%\item An edge-cloud FL system for secure, private traffic accident prevention in ITSs
%\item A multimodal detector using triplet loss for improved road hazard detection
%\item A communication-efficient FL scheme ensuring robust hazard detection on non-iid IoT data
%\item An advanced multimodal LDP algorithm reducing privacy errors while preserving detection accuracy
%\end{highlights}

%% Keywords
\begin{keyword}
Internet of Things (IoTs) \sep Intelligent Transportation Systems (ITSs) \sep Road hazard detection \sep Federated learning \sep Edge-cloud computing \sep Local differential privacy
\end{keyword}

\end{frontmatter}

\section{Introduction} \label{sec:Introduction}
Internet of Things (IoTs) has been widely applied in diverse sectors such as healthcare, autonomous vehicles, and Intelligent Transportation Systems (ITSs), bringing huge revolutions in people's lifestyles. In this context, various IoT devices collect massive amounts of data from the real-world environment, providing users with high-quality services through modern digital technologies. Traffic accident prevention in ITS has attracted significant attention in industry and academia. The massive traffic data collected by IoT devices in ITSs is broadly used for traffic problems, such as traffic accident prevention. 
Since 2010, the annual number of fatalities resulting from traffic accidents has seen a slight decline, reaching 1.19 million and imposing costs on governments equivalent to approximately 1\%-3\% of GDP, as noted in~\cite{world2023global}. One of the main contributing factors to these incidents is road hazards, which include issues such as damaged roads, fallen trees, and crashed vehicles. Fig. \ref{fi:dataExample} shows some example images and texts of road hazards. However, because of huge road networks, messy real-world backgrounds, and high intra-class differences, it is very challenging for road users to receive useful road hazard information. 

\begin{figure}
\vspace{-2mm}
\centering
\includegraphics[width=0.45\textwidth]{figures_journal/dataExample2.jpg}
\caption{Example images and texts of road hazards (from left to right, crashed vehicles, icy road, fallen tree, and damaged road), including dangerous type and location.}
\label{fi:dataExample}
\vspace{-4mm}
\end{figure}

Recent intelligent road hazard recognition frameworks like \cite{EcRD,FedRD} employ edge-cloud-based frameworks for fast road damage inspection by placing the detection models at edges. However, most of them only use single-modality data, while extensive data in other modalities from IoT devices, such as text, remains unexplored. Furthermore, most existing approaches like \cite{EcRD,FedRD} identify road hazards on a cloud or edge by a machine learning model trained with large annotated datasets. However, the gathering of large annotated datasets is laborious, and the model struggles to dynamically update its knowledge based on evolving data patterns.
% model cannot adaptively learn from changing data. 
Besides, the latency of cloud-based systems is usually high and might not be appropriate for immediate road hazard warning.

Federated Learning (FL)~\cite{mcmahan2017communication} allows different platforms to acquire a global model while maintaining training data locally on road users' devices, providing privacy and security to some extent. Many studies~\cite{FedRD,zhao2024community,saha2024federated} proposed various FL strategies to improve FedAvg's~\cite{mcmahan2017communication} performance in the application of road damage detection. 
Despite ongoing advancements, they still face several persistent challenges.
One issue is the heterogeneity of data produced by IoT devices across various systems (\eg, non-iid data), which complicates the process of deriving meaningful insights. Additionally, the significant communication overhead remains a critical limitation for the practical deployment of federated learning in real-world settings.

Besides, the massive data produced by IoT devices incorporates large amounts of sensitive information, such as location privacy and facial privacy, which can be exposed to the adversary due to frequent bidirectional communications among users, edges, and the cloud. FL mitigates the privacy issue to some extent; however,~\cite{geiping2020inverting} demonstrates that people can still recover private data directly from the shared gradient parameters in FL. Differential Privacy (DP)~\cite{dwork2014algorithmic} is a promising strategy to protect sensitive information while maintaining model performance. Previous research, \cite{FedRD,hao2019efficient,xiong2021privacy,saha2024federated}, preserves data privacy at road users' devices, however, most of them are not for ITSs or did not take privacy of multimodal data into consideration. Even though some existing work, like~\cite{FedRD}, preserves data privacy by using DP, the expected error of their methods is excessively high when handling high dimensional real-world data from IoT devices. 

To tackle these issues, \emph{RoadFed}: a multimodal \emph{Fed}erated learning system is developed in this paper for improving \emph{Road} safety.
It capitalizes on the recent achievements in federated learning, edge-cloud computing, and Local Differential Privacy (LDP) to provide distributed and privacy-preserving road condition monitoring and danger alarm. 
RoadFed notably minimizes latency by identifying road hazards at the edge servers. By integrating visual and textual data for model training, RoadFed achieves superior detection accuracy compared to previous methods. Additionally, it enables collaborative and efficient learning across multiple edges while ensuring that most data remain securely on users’ devices, enhancing privacy. Furthermore, the proposed Multimodal Local Differential Privacy algorithm offers an extra layer of data protection.
The \textbf{key contributions} of this paper are outlined below:
\begin{itemize}
    \item 
    An innovative edge-cloud computing-based Federated learning system, RoadFed, is introduced for secure and private traffic accident prevention in ITSs. RoadFed utilizes IoT devices to collect and process multimodal data efficiently, leveraging the latest developments in FL, edge-cloud computing, and LDP.
    \item A new Multimodal Road Hazard Detector, MRHD, has been created to improve the effectiveness of existing solutions that rely solely on vision-based data. MRHD capitalizes on the benefits of triplet loss to capture both intra-class and inter-class relationships, resulting in improved performance in detecting road hazards and outperforming previous multimodal models.
    \item A communication-efficient and effective Federated Multimodal Learning scheme, MFed, is developed for joint learning across different devices. MFed guarantees robust and precise detection of road hazards on non-iid data collected from IoT devices. It drastically reduces both computational and communication overhead compared to existing federated learning approaches and achieves effective convergence, even with such challenging datasets.
    \item An advanced Multimodal Local Differential Privacy algorithm, MLDP, has been introduced to safeguard private data while maintaining high road hazard detection performance. Unlike current DP-based methods, MLDP can process multimodality data and significantly mitigate privacy errors posed by the high dimensionality when using LDP.
\end{itemize}

The rest of the paper is summarized as follows. We review the related literature in Section \ref{sec:RelatedWork}. Section \ref{sec:FrameworkDesign} depicts our framework design, including its design goals, framework components, and operational workflow. In Section \ref{sec:Methodologies}, details of the proposed key methodologies are described, consisting of the Multimodal Road Hazard Detector (MRHD), Multimodal Federated Learning Scheme (MFed), and Multimodal Local Differential Privacy Algorithm (MLDP). Experimental results are illustrated in Section \ref{sec:Evaluation}, and Section \ref{sec:conclusion} concludes the paper. 

\section{Related Work} \label{sec:RelatedWork}
IoT offers promising opportunities to optimize decision-making and improve efficiency. As part of intelligent transportation, many road hazard recognition and alarm techniques using IoT are introduced. Besides, the recent innovations of FL enable collaborative learning. Moreover, different privacy-preservation techniques are utilized to protect privacy. The related literature is summarized as follows.

\textbf{road hazard detection and alarm techniques.}
Deep learning algorithms are used for the identification of road hazards in many existing studies~\cite{pauly2017deeper,Hoai2017,maeda2018road,EcRD,FedRD,zhao2024community,saha2024federated} and have achieved promising results. 
Similarly,~\cite{maeda2018road,FedRD,zhao2024community,saha2024federated} introduced CNN-based models for the classification of road hazards. Despite the success of deep learning models in processing visual data within cluttered real-world scenarios, current road damage detection systems primarily rely on visual input. For example,~\cite{wang2021assistant} used a deep learning algorithm to identify road obstacles, thus mitigating road hazards.
In~\cite{sulistyowati2021monitoring}, a threshold-edge-based algorithm was proposed to detect holes in roads and report them on Google Maps.

To our knowledge, no existing studies have explored the integration of multimodal data in this domain. In contrast, extensive research in other domains has demonstrated that leveraging data from various modalities can substantially enhance model performance~\cite{ofli2020analysis,gallo2018image,praneshexploring,abavisani2020multimodal}. A straightforward approach involves fusing features from different modalities to learn from the available data. 
\cite{lan2014multimedia} utilized early (combining embeddings of initial layers) and late fusion (integrating final decisions) to achieve superior accuracy. The authors of \cite{kelly2017mining} developed a classifier that is trained from both image and text data to monitor flooding incidents. 
Furthermore,~\cite{mouzannar2018damage} introduced a multimodal deep learning system capable of recognizing damage to the infrastructures using image and text data retrieved from social media messages. Additionally,~\cite{abavisani2020multimodal} introduced a multimodal model with a cross-attention module for the categorization of crisis events.
\cite{dar2025social} proposed a a novel multimodal attentive framework combining graph neural networks and social context features to enhance disaster content classification by capturing both aligned and contrary patterns in text and visual data.

\textbf{IoT-based federated learning methods.} 
The concept of FedAvg was presented in~\cite{konevcny2016federated} in 2016 as a technique for developing a unified model by averaging multiple local models while ensuring the training data remains on its respective local devices. Nonetheless, a major obstacle limiting the widespread adoption of FL within the IoTs is the high communication expenses tied to frequent model updates exchanged between clients (i.e., road users) and the aggregator during the training process. Research conducted by~\cite{sattler2019sparse} suggests that the communication burden of an individual road user can reach a petabyte when training models on large datasets. Various solutions have been put forward to handle this challenge, which can be classified into two categories: reducing the frequency of communication and applying model compression techniques.

Methods aimed at reducing communication frequency seek to reduce the number of model transmissions. In~\cite{mcmahan2017communication,konevcny2016federated}, each client refreshes its local model multiple times before transmitting it, rather than sending it after every iteration. Such strategies can considerably reduce both upload and download communication expenses. 
Conversely, compression techniques reduce communication costs by decreasing the model's size before transmission.
A prevalent method is quantization~\cite{alistarh2017qsgd}, which reduces the model size by mapping updates to a limited range of possible values. SignSGD, introduced by~\cite{bernstein2018signsgd}, is a quantization-based method that converts gradient updates into their binary sign, thereby significantly reducing the model size by 32 times while theoretically guaranteeing convergence on identically distributed data. Additionally, SignSGD conducts downstream data compression through majority voting to aggregate received binary updates. Other scholars have suggested stochastic gradient quantization techniques to reduce the size of upstream gradients without introducing bias, exemplified by quantized stochastic gradient descent (QSGD)~\cite{alistarh2017qsgd}, which successfully quantifies model gradients while maintaining models' convergence.

In practical cases, the data gathered by individual users typically does not have an identical distribution (non-iid). The challenge of modeling non-iid data poses significant difficulties for deep learning algorithms. As indicated in~\cite{zhao2018federated,saha2024federated}, models' performance when applying FL can decrease drastically (by more than 50\% ) when the models are trained on non-iid datasets. To tackle this issue,~\cite{zhao2018federated} introduced a method that generates a slim data pool shared between all edge servers for training while~\cite{saha2024federated} utilized FedAvg and showed that it has some potential of dealing with non-iid data. Although this method partially mitigates the non-iid problem, achieving an identically distributed data setup on user devices remains challenging because of the unknown data distributions among clients. An alternative approach involves directly learning from non-iid data~\cite{briggs2020federated,chen2020asynchronous,shoham2019overcoming,li2024iofl,li2024feature}.

The research in~\cite{briggs2020federated} introduced a revised federated learning framework that organizes clients into hierarchical clusters according to the similarities of the local models to the global one, demonstrating higher convergence speed in non-iid data compared to conventional approaches. In~\cite{chen2020asynchronous}, a method called Asynchronous Online FL tailored for non-iid environments was designed, where users continuously gather data, and their local models are trained on the collected data. This strategy learns the interrelations between different devices through regularization and feature learning. Additionally,~\cite{shoham2019overcoming} tackled the problem of catastrophic forgetting in FL by incorporating a penalty term into the model’s loss function, which incentivizes all local models to move toward a global optimum. Moreover, studies~\cite{chen2020asynchronous,li2019convergence} have established that variations in data distributions can obstruct the convergence of the model. Specifically, according to~\cite{li2019convergence}, for FedAvg to achieve convergence to the global optimum in the context of non-iid data, the learning rate must be progressively reduced.
\cite{li2024iofl} proposed an Intelligent-Optimization-Based Federated Learning (IOFL) framework, where the server directly searches for global model parameters using intelligent optimization algorithms, while clients only validate the model and return test accuracy. This approach fundamentally eliminates the impact of non-IID data on model performance. 
\cite{li2024feature} tackled Non-IID challenges in federated learning by generating privacy-preserving synthetic data that matches essential class-relevant features.


\begin{figure*}[t]
\vspace{-2mm}
\centering
\includegraphics[width=0.99\textwidth]{figures_journal/RoadFed.jpg}
\caption{An overview of the proposed RoadFed framework, including three key components (i.e., road users' devices, untrusted edges, and untrusted cloud.) and three key methodologies (i.e., MRHD, MFed, and MLDP).}
\label{fi:RoadFedFramework}
\vspace{-2mm}
\end{figure*}


\textbf{IoT-based privacy-preserving techniques:}
Numerous techniques have been put forward to safeguard privacy, including encryption methods, anonymization, and differential privacy. Encryption techniques are typically employed to thwart unauthorized access, data misusage, and model recovery attacks (i.e., deducing parameters of a model) originating from unreliable edges or cloud environments, as discussed in~\cite{li2020attribute} and~\cite{li2020privacy}. Nonetheless, the substantial computational and communication expenses associated with these techniques limit their practicality in real-life scenarios. The approach presented in~\cite{guan2019appa} enhances user privacy using pseudonyms and pseudonym certificates within fog computing. Similarly,~\cite{zhao2021anonymous} engaged a trusted third party that acts as an intermediary to ensure the anonymity of the user. However, studies such as~\cite{qian2017social} and~\cite{narayanan2008robust} demonstrated that merely removing or disguising user identity information might not effectively secure privacy, as deanonymization attacks can exploit existing knowledge to reconstruct this information.

In contrast to anonymization and encryption techniques, differential privacy~\cite{dwork2014algorithmic} offers robust privacy assurances that can simultaneously protect user data and model efficacy. LDP is a type of DP that safeguards user data directly from personal devices like smartphones and smartwatches. Consequently, LDP can maintain user privacy without relying on a trusted intermediary (such as unreliable edge or cloud servers). The randomized response method was applied to encode values in~\cite{kairouz2016discrete} and~\cite{wang2017locally} to facilitate local privacy protection. This strategy is straightforward to implement without incurring additional computation costs; however, it performs poorly with high dimensional data. The works of~\cite{fanti2016building} and~\cite{ren2018textsf} employed Expectation Maximization (EM) based methodologies, which allocate the privacy budget across the values of individual features for preserving the privacy of local users’ data, addressing both two-attribute and multi-attribute scenarios. EM-based methods can cause high variance because of the allocation of the privacy budget, making them less suitable for high dimensional datasets. The authors of~\cite{xia2020distributed} utilized transformation techniques to convert data into binary strings. The randomized response technique was then applied to generate these strings, with the nearest center being communicated differentially privately. 
% Although~\cite{xia2020distributed} managed to safeguard the grouping information of users, it is not optimal for high dimensional data and incurs additional costs for selecting cluster centers.
\cite{batool2024secure} introduced a two-layer federated learning framework with local differential privacy at the vehicle level ensures secure and privacy-preserving data sharing in VANETs without relying on trusted third parties.
\cite{li2025wf} enhances trajectory data utility under local differential privacy by adaptively allocating privacy budgets via water-filling theory and optimizing user segmentation through entropy-driven grouping.

To summarize, first, deep learning approaches have been extensively investigated for classifying road hazards, yielding promising outcomes. However, the majority rely solely on one modality (i.e., images or videos). Given the vast amounts of multimodal data generated daily, incorporating multimodal information could significantly enhance the performance of single-modality models. To our best knowledge, there is no existing research addressing multimodal learning for road hazard detection. Second, methods that reduce communication frequency in collaborative learning are both straightforward and effective in lowering communication costs; however, high expenses persist due to the large sizes of models. Last, there is currently no LDP solution capable of managing real-world data encompassing multiple modalities and attributes, which leads to considerable errors when handling high dimensional data. To address these challenges, this paper introduces a multimodal FL system aimed at road hazard detection and alerting with minimal data exchange while protecting privacy. 

\section{Framework Design} \label{sec:FrameworkDesign}
This section outlines the design objectives, integral parts, and overall working process of the proposed RoadFed framework.

\subsection{Design Objectives}
The development of RoadFed is guided by the following aims:
\begin{enumerate}
    \item [--] {\underline{Latency:} The designed system must be capable of detecting road hazards and releasing alarms to road users timely to prevent accidents. Therefore, it is essential to maintain low latency.}
    \item [--] {\underline{Accuracy:} A well-designed road hazard detection system should be able to accurately recognize road hazards as failing to detect hazards can have serious consequences for road users.}
    \item [--] {\underline{Robustness:} The performance of the developed system should remain stable across various environments, including differing weather and lighting conditions. Additionally, it should maintain high performance even when some edge servers operate with limited and non-iid data, which is frequently encountered in practical scenarios.}
    \item [--] {\underline{Coverage:} The designed framework should offer extensive coverage to offer users information about hazardous road conditions, facilitating the prevention of road accidents and the planning of safer routes.}
    \item [--] {\underline{Communication and computation overhead:} A good distributed road hazard detection system should have low communication and computation costs for being able to be applied in practical applications.}
    \item [--] {\underline{Privacy:} There is a considerable threat of privacy breaches from untrusted edge servers or clouds, especially during data transmission in open environments. Besides, extensive studies have proved that even only transferring model parameters rather than raw data, attackers can still recover the data utilized for training the model from model parameters, as studied by \cite{geiping2020inverting}. Hence, the designed framework must ensure the protection of user privacy, including personal identifiers and locations, as well as the confidentiality of sensitive information in collected data, such as pictures of person and car plates.}
\end{enumerate}


\subsection{Framework Elements}
The RoadFed framework consists of four essential components, as depicted in Fig.~\ref{fi:RoadFedFramework}.
\begin{enumerate}
    \item [--] {\underline{Devices:} 
    IoT devices, such as cameras, sensors, or smartphones, are employed to gather multimodal data (including images and text) and subsequently transfer this information to the adjacent edge server, for example, the Roadside Unit (RSU).}
    \item [--] {\underline{Edges:} Edge servers are tasked with receiving data from users and swiftly addressing any potential road hazards present in the data. Specifically, the Multimodal Road Hazard Detector (MRHD) is implemented on the edges for the detection of road hazards. The MRHD versions running on the edges and the cloud are referred to as the local and global models. As edges are considered unreliable in this context, it is critical to ensure that sensitive user data from IoT devices remains confidential. Additionally, no data is retained on edge servers, and prior local models are routinely erased to enhance data processing speed.}
    \item [--] {\underline{Cloud:} The cloud functions as an aggregator for FL, facilitating data processing and storage. The global model resides in the cloud server, representing an accumulation of the captured local models. The global map on the cloud server is generated by aggregating the local models and is displayed in real-time on a Google map. This information allows road users to receive timely alerts regarding road hazards and aids in optimizing travel routes. Furthermore, data related to road hazards (both images and text) is periodically sourced from the Internet to enhance model training. The cloud is also considered unreliable here. The information stored within can be utilized by road management authorities for rapid repairs and effective budget management.}
    \item [--] {\underline{MRHD:} The Multimodal Road Hazard Detector (MRHD) is a deep learning model designed to process both image and text data collected from IoT devices to identify various road hazards, such as significant road damage, collisions involving vehicles, icy conditions, and fallen trees obstructing pathways (refer to Section~\ref{subsec:MRHD}). MRHD is positioned on edge servers to enable prompt detection and alerts concerning road hazards.}
    \item [--] {\underline{MFed:} The proposed Multimodal Federated Learning scheme (MFed) enhances road hazard detection performance through collaborative learning between edges and the cloud server, as edges possess greater computational capabilities and are located more adjacent to users than the cloud server. Many existing federated learning strategies exhibit inefficiencies in communication, so the design of MFed is aimed at significantly reducing communication overhead while guaranteeing high model performance and ensuring fast convergence. Further details regarding MFed are described in Section~\ref{subsec:MFed}.}
    \item [--] {\underline{MLDP:} The developed Multimodal Local Differential Privacy algorithm (MLDP) (refer to Section~\ref{subsec:MLDP}) safeguards both user privacy (such as user identification) and the confidentiality of data collected on users’ devices (e.g., people's faces) before being uploaded to nearby edge servers. MLDP enhances existing local differential privacy algorithms by addressing high expected error rates in high dimensional real-world data. This approach is applied to users’ devices to ensure privacy before sending data to the nearest edge, creating a more secure and user-friendly framework.}
\end{enumerate}

\begin{figure*}
% \vspace{-2mm}
\centering
\includegraphics[width=0.68\textwidth]{figures_journal/MRDD_new.png}
\caption{The proposed Multimodal Road Hazard Detector utilizes a triplet loss to improve feature quality, i.e., enlarging inter-class features’ distances and shrinking intra-class features’ distances, for higher accuracy.
}
\label{fi:MRHD}
\vspace{-2mm}
\end{figure*}

\subsection{Operational Workflow}
As depicted in Fig.~\ref{fi:RoadFedFramework}, RoadFed is structured on a device-edge-cloud framework where IoT devices facilitate data gathering, an edge server is utilized to minimize response time (i.e., latency), and the cloud server is engaged for aggregation of model parameters. The introduced MRHD is placed at the edge servers for rapid response to road hazards. If a road hazard is identified, the edge server promptly transmits an alarm to road users to prevent road accidents. similar to~\cite{konevcny2016federated}, FL is employed to jointly enhance model training across a number of edges with the help of a cloud. This FL approach allows for effective model development without necessitating the transfer of data from the edges to the clouds, safeguarding data privacy against potentially untrustworthy clouds. In RoadFed, local models refer to those established at the edges, while the road hazard detector in the cloud server is referred to as the global model. The operational workflow of RoadFed consists of four key phases that continuously learn from edge data.

\begin{itemize}
\item \textbf{Stage 1:} Each road user gathers image or textual information regarding road hazards using smart IoT devices and subsequently transmits this data to the nearby edge server.
\item \textbf{Stage 2:} Edges assess road hazards within their communication vicinity utilizing the MRHD model (received from the cloud). Following this, they disseminate road hazard alarms to all road users within their coverage area. Edge servers initiate the training of their local models on their local datasets when the newly accumulated data surpasses a predetermined threshold (configured to 100 based on comprehensive testing). Subsequently, they transmit the updated local models' parameters to the cloud server.  
The local models on the edge servers that do not have sufficient new data will not be trained to minimize communication and computation costs.
\item \textbf{Stage 3:}
The cloud server integrates the local parameters obtained from the covered edges according to Eq.~\eqref{eq:Fed} and Eq. (2) to formulate a global model.
\begin{align}\label{eq:Fed}
\boldsymbol{\omega}^t &= \sum_{i=1}^{N} \frac{D_i}{D} \boldsymbol{\omega}_i^t, \\
D &= \sum_{i=1}^{N} D_i,
\end{align}
in which $\boldsymbol{\omega}^t$ signifies the weights of the global model at time $y$, and $\boldsymbol{\omega}_i^t$ indicates the weights of the $x$-th local model at time $y$. $D_i$ represents the size of the training dataset of the $x$-th edge, while $D$ is the size of the overall training dataset across all participating edge servers. Here, $N$ denotes the count of edges that have transmitted their local models to the cloud. Subsequently, the cloud sends the global model to all edges within its coverage.
\item \textbf{Stage 4:}
Edge servers update their local models' parameters using the global model's parameters received from the cloud server.
\end{itemize}
Stages 1 to 4 are reiterated in every $R$ communication round, and extensive experiments have shown that the global model converges rapidly when $R = 10$.

\section{Methodologies} \label{sec:Methodologies}
This section describes the details of the proposed Multimodal Road Hazard Detector (MRHD), Multimodal Federated Learning Scheme (MFed), and Multimodal Local Differential Privacy Algorithm (MLDP).
\subsection{Multimodal Road Hazard Detector} \label{subsec:MRHD}
The proposed Multimodal Road Hazard Detector (MRHD) identifies road hazards using either images or texts as inputs. MRHD operates without the need for paired image-text data, which enhances its practicality. The architecture of the proposed multimodal model encompasses two stages: the pre-training stage and the re-training and inference stage, as depicted in Fig.~\ref{fi:MRHD}.

During the pre-training stage, a multimodal model with a well-designed triplet loss function is developed to learn distinguishable feature representations through distance evaluations. The goal of this stage is to train both text and image feature extractors (i.e., $f_t$ (Bert+FC) and $f_i$ (MobileNetV2+FC)) so that they can differentiate between benign road conditions and various kinds of road hazards from text/image data, where FC denotes a fully connected layer. Cosine similarity is employed to evaluate the distances between embeddings.

A designed triplet loss is formulated in Eq.~\eqref{eq:combinedTripletLoss}, which measures the intra-class and inter-class relationships of different data modalities, where $\alpha$ represents a penalty factor that regulates the significance of the term. Through experimentation, we found that $\alpha=0.1$ yields optimal results. This is reasonable because textual data includes high-level information, whereas visual data consists primarily of low-level information, and if the text-only part is not penalized, the overall loss would be excessively high. The designed triplet loss comprises fundamental triplet losses for text-only Eq.~\eqref{eq:tripletLoss1}, text-image Eq.~\eqref{eq:tripletLoss2}, and image-text Eq.~\eqref{eq:tripletLoss3}. For the experiments, we set $c=0.2$ and $m=0$ across all trials.

\begin{equation} \label{eq:combinedTripletLoss}
    Loss = \alpha \cdot Loss(a_t, p_t, n_t) + Loss(a_t, p_i, n_i) + Loss(a_i, p_t, n_t), 
\end{equation}
\begin{equation} \label{eq:tripletLoss1}
    Loss(a_t, p_t, n_t) = max\{\cos(a_t, p_t) - \cos(a_t, n_t) + c, m\}, 
\end{equation}
\begin{equation} \label{eq:tripletLoss2}    
    Loss(a_t, p_i, n_i) = max\{\cos(a_t, p_i) - \cos(a_t, n_i) + c, m\},
\end{equation}
\begin{equation} \label{eq:tripletLoss3}    
    Loss(a_i, p_t, n_t) = max\{\cos(a_i, p_t) - \cos(a_i, n_t) + c, m\}.
\end{equation}

Training the model with the designed triplet loss function over a large number of triplets can be computationally intensive. 
Inspired by~\cite{joachims2009cutting,shaw2011learning}, we select the most violating negative data points within every batch. 
In particular, feature vectors of three triplets, namely $(a_t, p_t, n_i)$, $(a_t, p_t, n_t)$, and $(a_i, p_t, n_t)$ are chosen in every batch, ensuring that the most difficult negative sample is employed for training in every batch; here, $a$, $n$, and $p$ denote anchor, negative, and positive data points, respectively, while $t, it$ refer to text and image data modalities. A negative sample is selected if the cosine similarity among an anchor sample and its negative pair is smaller than the cosine similarity of it to any other negative samples within the batch.

In the second stage, the MRHD is built based on the pre-trained image and text feature extractors (i.e., $f_i$ and $f_t$) as well as a merging block $M$. 
The cross-entropy loss is utilized to optimize the detector.
This model is first fine-tuned on the road hazards dataset and subsequently applied for road hazard detection. The merging block $M$ consists of two FC layers and one ReLU layer, as depicted in Fig. \ref{fi:MRHD}.

\subsection{Multimodal Federated Learning Scheme} \label{subsec:MFed}
The Multimodal Federated Learning Scheme (MFed) is designed to obtain superior detection performance across various edge servers with minimal communication overhead while ensuring the convergence of the model on non-IID datasets. MFed is primarily composed of three components: adaptive learning rate (AdaLR) and dynamic quantization.

\subsubsection{Adaptive Learning Rate}
Although existing FL strategies~\cite{mcmahan2017communication,reisizadeh2020fedpaq,li2019convergence} have achieved promising results, there are still some open issues that need to be solved, for example, high convergence time, particularly with challenging non-iid data. To address this challenge, the learning rate (LR) in MFed is reduced according to Eq.~\eqref{eq:AdaLR} after each global round, following~\cite{li2019convergence}.
\begin{equation} \label{eq:AdaLR}
\gamma_r = \gamma_0 \cdot \delta^{\floor*{\frac{\nu}{\zeta}}},
\end{equation}
where $\gamma_0$ represents the initial LR, set to 0.1 for the experiments. $\delta$ is set to 0.5. $\zeta$ and $\nu$ denote step size and the last global round, while $\zeta$ is configured to 1. Reducing the learning rate is essential to ensure the global model's convergence when working on non-IID datasets~\cite{li2019convergence}. 

\subsubsection{Dynamic Quantization}
One main challenge of FL is the substantial bandwidth costs incurred from constant parameter communications between the cloud server and edge servers. In MFed, at time $y$, each participating edge communicates only the quantized parameter differences ${\Delta \omega}_i^t$ between the obtained global model $ \boldsymbol{\omega}^{t-1}$ at time $t-1$ and the newly trained local model $\boldsymbol{\omega}_{i}^t$ at time $y$ to the cloud server, rather than transmitting the entire local model $\boldsymbol{\omega}_{i}^t$. The Low-Precision Quantizer (LPQ)~\cite{alistarh2017qsgd}, specifically the QSGD method, is employed to compress these model differences, as it provides convergence guarantees along with strong practical performance. The trade-off between convergence time and communication overhead can be adjusted smoothly (i.e., on a per-iteration basis) using QSGD.

After the local models are trained and aggregated, or before the local or global models are sent, the dynamic quantization technique\footnote{https://pytorch.org/tutorials/recipes/recipes/dynamic\_quantization.html} is employed to further diminish the model size and improve its efficiency by simply converting float32 into int8 values.
Besides, due to the precise calculation of the signal range for each input, it can substantially reduce latency without compromising accuracy significantly \cite{Gholami2022ASO, DQ}.
The primary concept behind it is to adaptively decide the degree of compression, ensuring that the most critical information is preserved while keeping a low model size. The proposed MFed strategy is formally outlined in Algorithm~\ref{alg:MFed}.

\begin{algorithm}[t]
	\caption{MFed scheme}\label{alg:MFed}
	\SetKwInOut{Input}{Input}  
	\SetKwInOut{Output}{Output}
	\Input{Datasets at edge servers and the detector MRHD}
	\Output{Trained local models at edge servers}
	The cloud server initialize $\boldsymbol{\omega}^0$ and distributes it to the covered edges \\
	The cloud server sets the initial LR as $\gamma_0$ \\
	  { \For{each global communication round $R$}{
        \For{each E epochs}{
         \For{every edge $i \in \{1,2,\cdots,K\}$}
         {
         Each edge server replaces its local model $\boldsymbol{\omega}_{i}^t$ with the obtained global one $\boldsymbol{\omega}^{t-1}$ \\
         Each edge server trains its local model $\boldsymbol{\omega}_{i}^t$ on its newly acquired local data by performing:
         $\boldsymbol{\omega}_{i}^t \xleftarrow{} \boldsymbol{\omega}_{i}^{t-1} - \frac{\gamma_0}{R+1} \bigtriangledown l(\boldsymbol{\omega}_{i}^{t-1}, b_{i}^{t-1})$ \\
         Computes the weight difference by:
         ${\Delta \omega}_i^t = \boldsymbol{\omega}_{i}^t - \boldsymbol{\omega}^{t-1}$ \\
         Each edge server applies the dynamic quantization technique on the $Q({\Delta \omega}_i^t)$ \\
         Each edge server transmits $Q({\Delta \omega}_i^t)$ to the cloud server \\
         $R = R+1$ \\
         }}
        The cloud server waits until $K$ local models are gathered \\
        The cloud server integrates the local models by: $\boldsymbol{\omega}^t = \boldsymbol{\omega}^{t-1} + \frac{1}{K} \sum_{i=1}^{K} Q({\Delta \omega}_i^t)$ \\
        The cloud server applies the dynamic quantization method on the global model $\boldsymbol{\omega}^t$ \\
        The cloud server transmits the global weights $\boldsymbol{\omega}^t$ to the covered edges servers  \\
        }}
\end{algorithm}


\subsection{Multimodal Local Differential Privacy Algorithm} \label{subsec:MLDP}
The Multimodal Local Differential Privacy algorithm (MLDP) seeks to decrease any detrimental impact on MRHD's performance while effectively protecting private information. MLDP is designed following the Local Differential Privacy (LDP) proposed by \cite{kairouz2014extremal} that is implemented on IoT devices to alter data prior to transmission to potentially unreliable edge servers.

When a user collects a text $y$ or image $x$, the Laplace Mechanism is utilized to introduce perturbations, which is one standard distribution of $\epsilon$-LDP. Specifically, the perturbed text or image data $X$ can be denoted as follows:
\begin{equation} \label{eq:addNoise1}
    \forall j \in [d], X^*[j] = X[j] + Laplace(\frac{s_1(f)}{\epsilon}),
\end{equation}
where $Laplace(\frac{s_1(f)}{\epsilon})$ means a Laplace distribution with scale $\frac{2d}{\epsilon}$.
The error derived from perturbing the input samples using the LDP Algorithm is $O(\frac{d}{\epsilon})$, where $d$ is the dimension of the input data. It could be extremely high for high dimensional data.
To mitigate the problem, we intentionally decrease the dimension of the data before applying the LDP.

As stated by~\cite{achlioptas2001database}, mapping a vector into a randomly selected lower-dimensional subspace can still capture important characteristics. However, this method is limited to reducing dimensions by a factor of up to $\sqrt{d}$, which may still be substantial when $d$ is big. To address this limitation, the dimensionality is further reduced by mapping the input to a smaller subset, ensuring that important information is preserved. Specifically, text data is first encoded into numerical vectors. The dimensions of both image and text data are then reduced by multiplying by random matrices $Q_{c \times d}$ ($c < d$) and $R_{d \times e}$ ($e < d$), generated by the edges. Each element of $Q$ and $R$, namely, $Q[i][j]$ and $R[i][j]$, is denoted as follows:
\begin{equation} \label{eq:dimensionReduction}
    Q[i][j] =  R[i][j] = sign(x) \times \frac{1}{e},
\end{equation}
where $x$ is evenly selected from $U(-1, 1)$. $e$ represents the output's dimensionality. Consequently, the altered text is $T = Tanh(Q \times T)$ while the modified image is $I = Tanh(Q \times I \times R)$.

The concept of $\epsilon$-LDP is presented as follows, following~\cite{dwork2014algorithmic}:
\textbf{Definition 1} ($\epsilon-LDP$). \textit{A randomized function $f$ achieves  $\epsilon-LDP$ only if for any two inputs $x$ and $y$, where $\epsilon>0$, it holds that}
    \begin{equation}
        P[f(\chi)=\chi^*] \leq exp(\epsilon) \cdot P[f(\chi')=\chi^*], 
    \end{equation}
where $P[\cdot]$ means probability, and $\epsilon$ represents the privacy budget, which quantifies the level of noise introduced into the dataset. 
A lower $\epsilon$ means a higher amount of added noise, resulting in enhanced privacy but correspondingly reduced accuracy. 
Based on this definition, the edge servers that capture the altered data $\chi^*$ cannot confidently discover the true value of $\chi^*$ (governed by $\epsilon$), no matter the amount of knowledge the edge servers possess.

To ensure that the data is $\epsilon$-LDP private, a random noise sampled from the Laplace distribution $Laplace(\frac{s_1(f)}{\epsilon})$ is added to the data.
The sensitivity estimates the maximum difference in output that can occur due to noise addition while still preserving privacy. The $L1$-sensitivity is denoted as follows:
\begin{equation}
\label{eq:RoadFedupperBound}
    s_1(f)= max\{ \lVert f(\chi)-f(\chi') \rVert_{1} \},
    % s_1(f)= max\{ \lVert f(\chi)-f(\chi') \rVert_{1} \},
\end{equation}
where $\lVert.\rVert_{1}$ refers to the L1 norm.

In this context, $f$ complies with $\epsilon-LDP$.

\textit{Proof:} 
Let $x$ and $y$ represent two samples, each of dimensionality $d$, another independent data point be $x$ (also with dimension $d$), and $d$ random variables are from $Laplace(0, \frac{s_1(f)}{\epsilon})$. 
\begin{align}
    & \frac{Pr[(f(\chi)=\chi^*]}{Pr[(f(\chi')=\chi^*]}
     =\prod_{i=1}^d \frac{exp(-\frac{{\epsilon}|f(\chi)_i-\chi^*_i|}{s_1(f)})}{exp(-\frac{{\epsilon}|f(\chi')_i-\chi^*_i|}{s_1(f)})}, \nonumber \\
    &\quad=\prod_{i=1}^d exp(\frac{\epsilon(f(\chi')_i-\chi^*_i|-|f(\chi)_i-\chi^*_i|)}{s_1(f)}),  \nonumber \\ % \label{eq:lap01}
    & \quad\leq \prod_{i=1}^d
    exp(\frac{\epsilon|f(\chi)_i-f(\chi')_i|}{s_1(f)}), \nonumber \\
    &\quad=exp(\frac{\epsilon \lVert f(\chi)-f(\chi') \rVert_{1}}{s_1(f)}), \nonumber \\
    &\quad\leq exp(\epsilon).
\end{align}
Therefore,
\begin{equation} \label{eq:proveFinal}
Pr[f(\chi)=\chi^*] \leq exp(\epsilon) \cdot Pr[f(\chi')=\chi^*].
\end{equation}

Importantly, post-processing invariance is a fundamental property of differential privacy. All computations performed on the edges using data received from IoT devices remain within the bounds of $\epsilon-LDP$. The specifics of the MLDP approach are outlined in Algorithm~\ref{alm:MLDP}.
%
\begin{algorithm}
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \Input{High-dimensional multimodal data (i.e., text $y$ and image $x$) with dimension $d$, and privacy budget $\epsilon$}
    \Output{Privacy-preserved mutimodal data features (i.e., text feature $y^{\prime\prime}$ and image feature $x^{\prime\prime}$)}   
    Create random matrices $Q_{c \times d}$ and $R_{d \times e}$ where each element has an equal chance of being $1/e$ or $-1/e$ \\
    Cut down the dimension of $x$ or $y$ by \\
    $y^\prime_{c \times 1} = Tanh(Q_{c\times d} \times y_{d \times 1})$  \\
    $x^\prime_{c \times e} = Tanh(Q_{c\times d} \times x_{d \times d} \times R_{d \times e}) $  $\xleftarrow{}$ only if the dimension of the text is large \\
    \For {$j = 1, 2, \cdots, d$}
    {
    $y^{\prime\prime}[j] = y^\prime[j] + Laplace(\frac{s_1(f)}{\epsilon})$ \\
    $x^{\prime\prime}[j] = x^\prime[j] + Laplace(\frac{s_1(f)}{\epsilon})$ \\
    Return $ y^{\prime\prime}, x^{\prime\prime}$
    }
    \caption{MLDP}
    \label{alm:MLDP}
\end{algorithm}

\section{Evaluation} \label{sec:Evaluation}
\subsection{Experimental setup} 
Three budget-friendly smartphones, a laptop (64-bit Windows 10 with \SI{32}{GB} RAM), and a server (running Ubuntu 18.04, equipped with \SI{64}{GB} of RAM and \SI{2}{GTX} \SI{1080}{Ti} GPUs) are used to simulate IoT devices, the edge, and the cloud in the proposed RoadFed framework. 
The implementation is carried out using Python~3.8. Additionally, the versions of Torch and Cuda used are 1.6.0 and 10.1, respectively. The versions of opencv-python and TensorFlow are set to 4.4.0 and 2.7.0.

The data collected from IoT devices comprises labeled text and image data grouped into six categories, namely damaged roads, crashed vehicles, icy roads, fallen trees, and normal roads. There are 780 images and texts. Eighty percent of the dataset is allocated for model training, while the rest is utilized for testing. Prior to the training of the model, images are clipped into 256 $\times$ 256 for subsequent processing to reduce the training time. Similarly, the texts are tokenized at the word level. RoadFed is also assessed using the CrisisMMD dataset~\cite{alam2018crisismmd} to validate the efficacy of the designed models. Both the MNIST dataset and the collected datasets are employed to assess MFed and to draw comparisons with leading FL strategies.
Because that text data $y$ only has one dimension and it is relatively small (i.e., 32) for our dataset, the dimensionality of $y$ remains unchanged. 

We use metrics like Precision, Accuracy, Recall, F1-score, Communication Cost (CC), and Collaborative Learning (CL) to compare model performance.

\begin{table}[t]
  \caption{MRHD evaluation results (\%) on our dataset.}
  \vspace{-4mm}
  \label{tab:MRHDEvaluationResults_own}
    \center
    \setlength\tabcolsep{1.5pt}
  \begin{tabular}{cccccc}
    \toprule
% \begin{table}[t]
% 	% \vspace{-2mm}
% 	\begin{center}
% 		\caption{MRHD evaluation results (\%) on our dataset.} \label{tab:MRHDEvaluationResults_own}
% 		\begin{tabular}{llllll}
% 			\toprule
			 Model & Accuracy  &  Precision & Recall & F1-score  \\
			\midrule
% 			\multirow{2}{*}{} 
			 MobileNetV2~\cite{sandler2018mobilenetv2} & 83.33 & 82.45 & 83.25 & 82.84 \\
% 			& FastText~\cite{joulin2016fasttext}& 92.31 & 91.87 & 92.65 & 92.26  \\
			 Bert~\cite{devlin2018bert} & 95.10 & 96.30 & 94.94 & 95.62\\
			\midrule
			 \cite{ofli2020analysis}& 94.84 & 95.02 & 95.00 & 94.01 \\
			 \cite{gallo2018image}& 95.32 & 71.43 & 95.94 & 81.89 \\
		\cite{choi2019embracenet}& 86.54 & 88.71 & 87.87 & 88.29  \\	
		\cite{praneshexploring} & 85.90 & 85.97 & 85.54 & 85.75 \\
		\cite{abavisani2020multimodal} & 98.08 & 98.17 & 98.08 & 98.12 \\
            \textbf{MRHD-noPretrain (ours)} &  97.79  & 97.96 & 97.79  & 97.87  \\
			\textbf{MRHD (ours)} & \textbf{99.14} & \textbf{99.15} & \textbf{99.14} & \textbf{99.14} \\
% 			\bottomrule
% 		\end{tabular}
% 		% {\\ Acc: Accuracy; P: Precision; R: Recall; F1: F1-score}
% 	\end{center}
% 	% \vspace{-2mm}
% \end{table}
  \bottomrule
\end{tabular}
\vspace{-1mm}
\end{table}
%
\begin{table}[t]
  \caption{MRHD evaluation results (\%) on the CrisisMMD dataset.}
  \vspace{-4mm}
  \label{tab:MRHDEvaluationResults_CrisisMMD}
    \center
    \setlength\tabcolsep{1.5pt}
  \begin{tabular}{cccccccc}
    \toprule
% \begin{table}[t]
% 	% \vspace{-2mm}
% 	\begin{center}
% 		\caption{MRHD evaluation results (\%) on the CrisisMMD dataset.} \label{tab:MRHDEvaluationResults_CrisisMMD}
% 		\begin{tabular}{cccccc}
% 			\toprule
	         Model & Accuracy  &  Precision & Recall & F1-score  \\
			\midrule
% 			\multirow{2}{*}{Unimodal} 
			MobileNetV2~\cite{sandler2018mobilenetv2} & 85.32  &  83.39 &  85.32 & 84.34 \\
% 			& FastText~\cite{joulin2016fasttext} & 78.71 & 75.97 & 78.71 & 76.41 \\
			Bert~\cite{devlin2018bert}& 88.47  & 87.90  & 88.47  & 88.18   \\
			\midrule
			\cite{ofli2020analysis}& 87.14  & 86.74  & 87.14  & 86.94  \\
			\cite{gallo2018image}& 84.92  &83.58  & 84.92  & 84.23   \\ 
			\cite{choi2019embracenet}& 86.92 & 84.62  & 86.92  & 85.75   \\	
			\cite{praneshexploring} &  85.81  & 84.78  &  85.81  &  85.29   \\
			\cite{abavisani2020multimodal} & 91.78 & 90.23  & 91.78 &  90.99  \\
			\textbf{MRHD-noPretrain (ours)} & 86.93 & 87.97  & 86.83 & 87.40  \\
			\textbf{MRHD (ours)} &  \textbf{92.00} &  \textbf{91.05} &  \textbf{92.00} & \textbf{91.52}  \\
% 			\bottomrule
% 		\end{tabular}
% 	\end{center}
% 	% \vspace{-4mm}
% \end{table}
  \bottomrule
\end{tabular}
\vspace{-1mm}
\end{table}

\begin{figure*}
    \vspace{-2mm}
    \centering
    \includegraphics[width=1.0\textwidth]{figures_journal/FedML_results.png}
    \caption{Performance comparison of MFed on both the road danger dataset and the MNIST public dataset (MFed-Q refers to MFed without using model quantization).}
    \label{fig:FL_performance}
    \vspace{-4mm}
\end{figure*}

\subsection{MRHD Results and Evaluation} \label{subsec:MRHDResultsandEvaluation}
Tables I and II show that multimodal models outperform most single-modality methods in both our datasets and the CrisisMMD datasets.
Notably, the accuracy of MRHD exceeds that of unimodal approaches by as much as 4\% on our dataset. Compared to the leading multimodal benchmarks~\cite{ofli2020analysis,gallo2018image,choi2019embracenet,praneshexploring,abavisani2020multimodal}, the introduced MRHD model obtains the highest accuracy on the collected dataset, reaching 99\%. This figure is 4\%, 4\%, 12\%, 13\%, and 1\% higher than the corresponding multimodal benchmarks~\cite{ofli2020analysis},~\cite{gallo2018image}, \cite{choi2019embracenet},~\cite{praneshexploring}, and~\cite{abavisani2020multimodal}. Additionally, when the weights from the pre-trained model are not utilized, the accuracy of the model on the road danger dataset decreases by approximately 2\%. This underscores that the model effectively learns the inter- and intra-class distinctions by implementing the introduced novel triplet loss function. Evaluation results of the model on the CrisisMMD dataset demonstrate that 
the introduced multimodal models surpass all state-of-the-art benchmarks by nearly 7\% in accuracy. MRHD’s performance improves by 6\% compared to the model without pre-training on the CrisisMMD dataset when employing the proposed triplet loss function. The comparison of MRHD against existing approaches on both datasets proves the effectiveness of MRHD.

\subsection{MFed Results and Evaluation}
The findings illustrated in Fig.~\ref{fig:FL_performance} reveal that the accuracy of MFed significantly surpasses the baselines on our road danger dataset and the MNIST public datasets. MFed converges in just 6 global communication rounds, which is 88\% faster than FedAvg and FedPAQ on the road danger dataset. Besides accuracy, the communication cost of MFed on the collected dataset is also analyzed. The results presented in Fig.~\ref{fig:FL_performance} demonstrate that the communication overhead of MFed is significantly lower than that of the existing methods. Specifically, MFed incurs a communication cost of only \SI{0.62}{MB} on the road danger dataset, which is around 270 times less than that of the existing approaches. AdaLR converges in approximately 15 global communication rounds, which is 150\% longer than for MFed but 70\% shorter than both FedAvg and FedPAQ. To validate the effectiveness of MFed, experiments are also conducted on the MNIST dataset. The corresponding results are shown in Fig.~\ref{fig:FL_performance}(b) and Fig.~\ref{fig:FL_performance}(d). 

\subsection{MLDP Results and Evaluation}
The influence of the privacy budget $\epsilon$ of MLDP on the detection performance of RoadFed has been evaluated, with findings presented in Fig.~\ref{fi:MLDPResults}. For a given privacy budget $\epsilon$, an allocation of $\epsilon/d^2$ is assigned to each element of every image with a dimension of $d \times d$ (prior to dimension reduction), while each text attribute with dimension $d$ receives $\epsilon/d$ as the privacy budget. The expected error, expressed as $O(\frac{d}{\epsilon})$, becomes significant when the dimension $d$ is large. 
It diminishes by 99.9\% (i.e., from $I_{256 \times 256}$ to $I_{1 \times 64}$) after using the proposed dimension reduction technique in MLDP.

As depicted in Fig.~\ref{fi:MLDPResults}, the road danger detection model's accuracy remains below 90\% when $\epsilon$ is under 0.2, subsequently increasing rapidly as $\epsilon$ rises from 0.001 to 0.8. Specifically, compared to the detection accuracy at $\epsilon=0.001$, the accuracy of RoadFed with $\epsilon=0.8$ increases by 12.43\%. Additionally, the accuracy of the model when $\epsilon = 0.8$ is approximately 5\% and 1\% higher than that of when $\epsilon=0.4$ and $\epsilon=0.6$, respectively. There is minimal variation in RoadFed's detection accuracy when transitioning from $\epsilon = 0.8$ to $\epsilon = 0.1$. Hence, $\epsilon=0.8$ is chosen as the privacy level to strike a favorable balance between the detection performance of the local model and the privacy of the data.
%
\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.68\linewidth]{figures_journal/map.png}
    \caption{Detection Result Display, where the red and green markers refer to road areas with and without road hazards. One can click the red markers to see details about the road hazards, including the type of road hazards and a timestamp.}
    \label{fig:display}
\end{figure*}

\begin{figure}[!ht]
	% \vspace{-2mm}
	\centering
	\scalebox{.9}{\input{figures_journal/PrivacyBudget}}
	\caption{The effect of $\epsilon$ in MLDP. $\epsilon = 0.8$ is selected as a trade-off between road hazard detection accuracy and data privacy preservation.} \label{fi:MLDPResults}
	% \vspace{-4mm}
\end{figure}

\subsection{RoadFed Framework Results and Evaluation}
RoadFed is evaluated against one cloud-based framework, namely CloudRD~\cite{li2024yolox}, and three edge-based frameworks: EcRD \cite{EcRD}, EdgeRD~\cite{saha2024federated}, and FedRD~\cite{FedRD}. Edge-based solutions exhibit significantly lower latency compared to cloud-based approaches, as edge servers are more adjacent to IoT devices (i.e., road users) than the cloud server. The performance metrics assessed include F1-score, accuracy, communication cost, and latency (with and without collaborative learning) for various frameworks, as detailed in Table~\ref{tab:RoadFedEvaluationResults}. According to Table~\ref{tab:RoadFedEvaluationResults}, RoadFed has around 
10\%, 5\%, 18\%, and 6\% improvements in F1-score compared to CloudRD, EcRD, EdgeRD, and FedRD.
Additionally, it attains roughly 10\%, 4\%, 17\%, and 5\% higher accuracy than CloudRD, EcRD, EdgeRD, and FedRD. RoadFed has 27.78\% and 98.43\% faster latency than EdgeRD and CloudRD.
RoadFed maintains a 5\% higher F1-score than EcRD, despite that RoadFed has a longer latency than EcRD. Unlike the other frameworks, both RoadFed and FedRD facilitate joint learning between the edge servers and the cloud server, enhancing privacy while reducing communication costs. RoadFed’s communication costs are about 100 and 1000 times cheaper than those of EcRD and FedRD, respectively.
%

\begin{table}[t]
  \caption{RoadFed evaluation results.}
  \vspace{-4mm}
  \label{tab:RoadFedEvaluationResults}
    \center
    \setlength\tabcolsep{1.5pt}
  \begin{tabular}{cccccc}
    \toprule
% \begin{table*}[t]
%   \caption{RoadFed evaluation results.} % 标题直接使用默认格式
%   \label{tab:RoadFedEvaluationResults}
%   \centering % 使用 \centering 保持模板默认间距
  % \begin{tabular}{cccccc}
  %   \toprule
    Framework & Accuracy & F1-score & Latency (\si{\second}) & CL & CC (\si{\mega\byte}) \\ 
    \midrule
    CloudRD~\cite{li2024yolox} & 87.90 & 87.66 & 2.49 & No & -- \\
    EdgeRD~\cite{saha2024federated} & 82.13 & 82.10 & 0.054 & No & -- \\
    EcRD~\cite{EcRD} & 92.51 & 92.05 & 0.003 & No & 292.97 \\
    FedRD~\cite{FedRD} & 91.64 & 91.25 & 0.0326 & Yes & 1003.34 \\
    \midrule
    RoadFed (our) & 96.42 & 96.61 & 0.0351 & Yes & 3.64 \\
%     \bottomrule
%   \end{tabular}
% \end{table*}
  \bottomrule
\end{tabular}
\vspace{-1mm}
\end{table}

% \begin{table}[t]
%   \caption{RoadFed evaluation results.}
%   \vspace{-4mm}
%   \label{tab:RoadFedEvaluationResults}
%     \center
%     \setlength\tabcolsep{1.5pt}
%   \begin{tabular}{cccccccc}
%     \toprule
% % \begin{table*} \caption{RoadFed evaluation results .} \label{tab:RoadFedEvaluationResults}
% % 		% \vspace{-2mm}
% % 	\begin{center}
% % 		\begin{tabular}{llllll}
% % 			\toprule
% 			Framework & Accuracy & F1-score  & Latency (s) & CL & CC (MB)\\ 
% 			\midrule
% 			CloudRD~\cite{li2024yolox} & 87.90  & 87.66 &  2.49  & No & - \\
% 			EdgeRD~\cite{saha2024federated} & 82.13 & 82.10 & 0.054 &  No &  - \\
% 			EcRD~\cite{EcRD} & 92.51 & 92.05  & \textbf{0.003}  &  No & 292.97 \\
% 			FedRD~\cite{FedRD}  & 91.64 & 91.25 & 0.0326 & \textbf{Yes} & 1003.34\\
% 			\midrule
% 			RoadFed (our) & \textbf{96.42} & \textbf{96.61} & 0.0351 & \textbf{Yes} & \textbf{3.64} \\
% 			\bottomrule
%             \end{tabular}
% \vspace{-1mm}
% \end{table}
% 		\end{tabular}
% 	\end{center}
% 	{\raggedright
% 		Accuracy and F1-score are in \%. 
% 		\par}
% 		\vspace{-2mm}
% \end{table*} 


\subsection{Displaying the road danger detection results on Google Maps}
After identifying potential hazards on the road, alerts regarding these risks (including their danger types, GPS coordinates, and a timestamp) are forwarded to the edge server. The server displays them on Google Maps. 
It is dynamically refreshed whenever new road hazards are encountered.
Armed with this hazard map, road users can capture the current condition of the road network and determine the most secure routes for their journeys while road management authorities can provide timely road maintenance.
A dedicated webpage has been crafted to present the detected road hazards. As depicted in Fig. \ref{fig:display}, the detected road hazards are seamlessly integrated onto Google Maps. 
In the map, green GPS markers signify areas that are deemed safe (indicating no detected hazards), whereas red GPS markers highlight sections that are considered hazardous (suggesting the presence of one or multiple hazards). 
By clicking on a red marker, one can see details about the identified dangers, including the type of the detected road danger and a timestamp.

\section{Conclusion} \label{sec:conclusion}
This paper addresses the dual challenges of low efficiency and high privacy risk associated with data-driven IoT applications, using road hazard monitoring as a case study. Specifically, we introduce the RoadFed framework for cost-effective, efficient, and private detection and alerting of road hazards.
In RoadFed, we present a Multimodal Road Hazard Detector that incorporates a new loss function that considers inter-class and intra-class correlation to enhance the classification of road hazards across different data modalities (i.e., images and texts). An effective FL method is also designed to bolster the accuracy of local road hazard detection models on the edge servers, drastically minimizing communication and computational expenses while ensuring model convergence. A multimodal LDP-based scheme is proposed to safeguard private information before transmitting it to the edge servers. This method addresses the high dimensionality challenges associated with LDP.
Experimental outcomes show that RoadFed can rapidly respond to road hazards, achieving high accuracy with minimal communication costs while protecting data privacy. The proposed framework is well-suited for integration into advanced cooperative ITSs. Specifically, RoadFed can alert drivers and pedestrians of impending hazards, providing details and locations to help prevent accidents. It can offer dynamic route guidance to improve travel times, contributing to environmental benefits. Alerts about collisions, breakdowns ahead, and adverse road conditions because of weather, such as icy roads, can also be provided. Ultimately, road administration authorities can focus on areas with statistically higher occurrences of collisions and incidents. The proposed framework enhances ITSs’ data collection, storage, and analysis capabilities, supporting future policy development and improving traffic management.
In future work, we aim to explore additional data modalities and further enhance the privacy features of the IoT-based system.

\section*{Acknowledgment}
The authors would like to thank MD Samiur Rahman for his help in the experiments.
This work was supported in part by the National Natural Science Foundation of China (Grant No. 62406215).
% and in part by the supported by the "Fundamental Research Funds for the Central Universities".


\bibliographystyle{elsarticle-num} 
\bibliography{main}

\end{document}