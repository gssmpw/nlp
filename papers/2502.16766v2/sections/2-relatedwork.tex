\section{Related Work}
\subsection{Text Embedding Models}

Representing text as dense vectors with neural networks gained prominence through word2vec \citep{mikolov2013distributed}, which generated semantically meaningful word embeddings. Subsequently, models like BERT \citep{devlin2019bert} and the contrastively trained SimCSE \citep{gao2021simcse} solidified encoder-only transformers as the predominant architecture for producing text embeddings. More recently, decoder-only transformers have advanced significantly in both capability and efficiency \citep{brown2020language, gemmateam2024gemmaopenmodelsbased, llama3modelcard, jiang2023mistral}, making it logical to utilize their pretrained knowledge for embedding tasks. This approach was successfully demonstrated by \cite{neelakantan2022}, who initiated embedder training from decoder-only GPT models and has been adopted by recent leading open-source models on the MTEB leaderboard \citep{behnamghader2024llmvec, lee2024nvembed, meng2024sfrembedding}.

\subsection{Text Embedding Evaluation}

Because embedding models are applied in diverse scenarios, there is a need for broad and heterogeneous benchmarks to thoroughly evaluate their performance. The pioneering effort in this domain was BEIR \citep{thakur2021beir}, which comprises nine distinct information retrieval tasks—such as duplicate-question retrieval and citation prediction—across 18 datasets. More recently, Muennighoff et al. (2023) introduced MTEB (Massive Text Embedding Benchmark) \citep{muennighoff2023mteb}, an extensive evaluation framework that surpasses BEIR in scale and includes more diverse task categories such as classification and reranking. 

\subsection{Advanced Model Capabilities}

Recent advances in natural language processing (NLP) have seen the emergence of a variety of specialized tasks aimed at evaluating model safety \citep{bai-etal-2022-hhrlhf}, factuality \citep{dziri-etal-2022-faithdial}, reasoning, instruction-following \citep{pmlr-v162-shp}, and document-level understanding, which are crucial capabilities for the most recent foundation models \citep{reid-etal-2024-gemini, openai-2024-gpt4o, llama3modelcard}. Safety tasks focus on mitigating harmful, biased, or unethical outputs, ensuring models uphold socially responsible standards \citep{bai-etal-2022-hhrlhf}. Factuality tasks emphasize grounding responses in reliable information and reducing fabrication or misinformation, as exemplified by research efforts on factual consistency in summarization and truthful QA (Maynez et al., 2020; Lin et al., 2022). Reasoning-oriented challenges push models beyond surface-level pattern recognition by encouraging deeper inference and logical deduction \citep{xiao2024rarbreasoningretrievalbenchmark}. Instruction-following tasks further refine models’ ability to adhere closely to user directives and align with human intent \citep{ouyang-etal-2022-training}. In parallel, document-level understanding \citep{yin-etal-2021-docnli, dipper} tests models' capabilities to process long-form texts beyond sentences.