\section{Label Augmentation on ATEB}
We test label augmentation on factuality and safety tasks in ATEB and show its effectiveness in improving an embedding model's advanced capabilities. 
\subsection{Model}
We adopt the Gemma V1-2B embedding model we trained as a symmetric dual encoder. We adopt two initialization settings before fine-tuning with label augmentation data. The first setting is finetuning directly over Gemma 2B. The second setting is adopting a prefinetuning stage where full supervision finetuning is conducted with 76 Huggingface Sentence Transformer datasets.  \footnote{https://huggingface.co/sentence-transformers}, 

\subsection{Training data}
We reformulate the training sets of two NLI entailment classification datasets, MNLI \citep{mnli} and FaithDial \citep{faithdial} into the label augmentation setting to be used as our training data for factuality classification tasks. For safety classification tasks, we reformulate the training set of BeaverTails Safety Ranking \citep{ji2023beavertails} task to be used as training data. 

\subsection{Results}
\begin{table}[t!]
\vspace{-1em}
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{l|c|c}
\textbf{} & \textbf{ESNLI(\%)} & \textbf{DialFact(\%)} \\
\toprule
\textbf{Random} & 33 & 33 \\ 
\midrule
% \textbf{Without target instruction} & & \\

% Full-supervision Finetuning over pre-finetuned Gemma 2B with MNLI & 37.61 & 33.5 \\
% No added data & 35.85 & 33.95 \\

% MNLI de class & 36.92 & 35.3 \\
% \textbf{With task instruction (task name)} & & \\
% No added data & 35 & 32.85 \\
% \textbf{With task instruction (task name and label text)} & & \\
% No added data & 35.38 & 32.92 \\
\textbf{Without label augmentation} & & \\
Full-supervision with MNLI & 34.0 & 33.1 \\
\midrule
\textbf{With label augmentation} & & \\
Full-supervision with MNLI (w/o label exp.) & 35.0 & 33.2 \\
Full-supervision with MNLI & \textbf{42.0} & \textbf{35.8} \\
Full-supervision with FaithDial data & 36.87 & 34.95 \\
Full-supervision over pre-finetuned with MNLI & 37.61 & 33.5 \\
Adapter with MNLI & \textbf{36.1} & 33.2 \\
Adapter over prefinetuned with MNLI & 34.3 & 33.0 \\
\bottomrule
\end{tabular}
}
\caption{Comparison of Results Across Different Configurations on the factuality tasks}
\label{tab:results_comparison_factuality}
\vspace{-1em}
\end{table}

\paragraph{Factuality tasks.} Table~\ref{tab:results_comparison_factuality} presents the performance of various configurations on two factuality classification tasks: ESNLI \citep{camburu-etal-2018-esnli} and DialFact \citep{gupta-etal-2022-dialfact}.
% The table compares accuracy across, data augmentation, and adapter-based fine-tuning approaches, using a random baseline as a reference point.

The random baseline accuracy for both tasks is 33\% since they are both three-class classification tasks. The Gemma-2B embedding model baseline achieve 35.85\% for ESNLI and 33.95\% for DialFact, showing a slight improvement over random guessing. Finetuning with MNLI classification data without unique IDs as introduced in the label augmentation setting does not improve the performance. Finetuning with MNLI data equipped with unique ID also leads to no improvement. Incorporating target explanations leads to a boost in performance, yielding an improvement of 9\% for ESNLI and 2.8\% for the out-of-domain DialFact.
Finetuning with out-of-domain, FaithDial classification data \citep{dziri-etal-2022-faithdial} leads to a modest increase, reaching 36.87\% for ESNLI and 34.95\% for DialFact. This indicates that detailed target explanations are particularly effective for in-domain finetuning entailment tasks like ESNLI. 

 When fine-tuning over a pre-finetuned Gemma-2B model with MNLI, performance drops to 37.61\% for ESNLI and 33.5\% for DialFact, showing that while pre-finetuning over generic retrieval tasks offers some benefits, it may not be as effective as direct full-supervision fine-tuning. Adapter-based fine-tuning approaches offer a trade-off between training efficiency and performance. Fine-tuning with an adapter achieves 36.1\% for ESNLI and 33.2\% for DialFact. When the adapter-based fine-tuning is applied to a pre-finetuned Gemma-2B model, performance decreases slightly to 34.3\% for ESNLI and 33.0\% for DialFact. These results suggest that adapter-based methods, while computationally efficient, do not achieve the same level of performance as full fine-tuning.

In summary, the table highlights several key insights: 1) label augmentation with label explanations provide the most substantial accuracy gains, particularly for ESNLI. 2) adapter-based fine-tuning offers a viable but much less effective alternative to full-supervision fine-tuning. 3) additionally, task-specific instructions and data augmentation strategies lead to only modest improvements unless combined with detailed target explanations or robust fine-tuning techniques.


\paragraph{Safety tasks}

\begin{table}[t!]
\vspace{-1em}
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{l|c|c}

\textbf{} & \textbf{BeaverTails(\%)} & \textbf{HH-RLHF(\%)} \\
\toprule
\textbf{Random} & 50 & 50 \\ 
\midrule
\textbf{Baseline} & 55.6 & 50.0 \\ 
\midrule
\textbf{Reranking as retrieval} & & \\
Full-supervision Gemma 2B & \textbf{68.5} & \textbf{51.0} \\
Full-supervision - pre-finetuned & 56.5 & 50.1 \\
Adapter with BeaverTails & \textbf{59.0} & 50.0 \\
Adapter with BeaverTails - pre-finetuned & 58.1 & 50.2 \\ 
\bottomrule
\end{tabular}
}
\caption{Comparison of Results Across Different Configurations on the safety tasks.}
\label{tab:results_comparison_safety}
\vspace{-1.5em}
\end{table}

Table~\ref{tab:results_comparison_safety} provides a comparison of model performance across different configurations for two safety-related tasks: BeaverTails (evaluating content safety) and HHRLHF (aligning with human reinforcement learning preferences). The table highlights the effects of baseline performance, fine-tuning strategies, adapter-based fine-tuning, and pre-finetuning on model accuracy. The baseline performance for BeaverTails is 55.6\%, reflecting a modest improvement over random guessing, while the HHRLHF baseline remains at 50\%, indicating no gains without task-specific adjustments. 

All the finetuning experiments are conducted with label augmentation data with label explanations. When safety ranking is reformulated with the label augmentation setting and the Gemma-2B model is fine-tuned with the BeaverTails Safety Reranking data, the highest performance is achieved for BeaverTails, reaching 68.5\%, representing a significant improvement of 12.9\% over the baseline. For HH-RLHF, this configuration yields a slight increase to 51.0\%, showing that SafetyRanking has a limited effect in out-of-domain generalization. Adapter-based fine-tuning offers a comparable performance boost to full-supervision fine-tuning. Specifically, fine-tuning an adapter over Gemma-2B with safety ranking data achieves the same peak accuracy of 68.5\% for BeaverTails and 51.0\% for HHRLHF. This suggests that adapter-based methods can be as effective as full fine-tuning while being more parameter-efficient.

R Both full-supervision and adapter-based fine-tuning over a pre-finetuned Gemma-2B model result in lower performance for BeaverTails (56.5\%) compared to direct fine-tuning (68.5\%), underscoring the harmful effect of prefinetuning over generic retrieval data in tasks requiring precise alignment with human reinforcement learning preferences. These findings emphasize the importance of task-specific fine-tuning and suggest that adapter-based strategies can lead to a modest improvement while being more resource-efficient.

