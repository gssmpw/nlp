
\section{Conclusion} In conclusion, we propose a novel benchmark, ATEB, to highlight the limitations of existing embedding models in handling advanced NLP tasks. By reformulating classification and reasoning tasks as retrieval problems with label augmentation, our approach enables embedding models to leverage their strengths in capturing semantic relationships, thereby extending their capabilities. Through extensive experimentation, we demonstrate that our fine-tuning method can significantly enhance performance on tasks involving factuality and safety. These results underscore the importance of tailored benchmarks and innovative training strategies in advancing the development of more capable embedding models.

\section{Limitations} While we included 21 tasks in our benchmark, many other safety, reasoning, and factuality tasks could be incorporated to increase the diversity and complexity of the benchmark. Additionally, we evaluated our proposed data reformulation method only on factuality and safety tasks and did not test it on other task categories.

\section{Acknowledgement} We thank Zhuyun Dai, Jianmo Ni, Blair Chen, Xiaoqi Ren and Jinhyuk Lee for useful feedback and discussions on embedding models and task formulation. 