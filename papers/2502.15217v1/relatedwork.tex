\section{Related Works}
\subsection{Formal Methods and Specifications}
Hoare's axiomatic basis for computer programming~\cite{hoare1969axiomatic} established the foundation for reasoning about program correctness through preconditions and postconditions, while Dijkstra's weakest precondition calculus~\cite{dijkstra1976discipline} provided systematic approaches for deriving specifications. These theoretical frameworks influenced the development of specification languages like JML~\cite{leavens2008jml} and modern verification-oriented programming languages such as \formal{Dafny}~\cite{leino2010Dafny}. Meyer's design by contract~\cite{meyer1992design} further popularized the use of preconditions and postconditions in software development. However, the manual effort required to write formal specifications has historically limited their widespread adoption in industrial practice~\cite{woodcock2009formal}.

\subsection{Automated Specification Inference}
The challenge of manual specification writing has motivated extensive research in automated specification inference. Early approaches like Daikon pioneered dynamic analysis techniques to infer likely program invariants\cite{ernst2007daikon}.
Static analysis methods, including abstract interpretation~\cite{cousot1977abstract} and symbolic execution~\cite{king1976symbolic}, provided more comprehensive approaches but faced scalability challenges with complex codebases~\cite{calcagno2011compositional}.

Recent research has demonstrated the potential of LLMs in generating specifications and code for formal verification languages like \formal{Dafny} \cite{misu2024towards} and Java \cite{ma2024specgen}. This trend aligns with broader efforts to leverage AI in software engineering tasks, particularly in areas requiring formal reasoning.

%Misu et al. \cite{misu2024towards} investigated the capabilities of LLMs in synthesizing verified \formal{Dafny} methods, showing that with appropriate prompting techniques, models like GPT-4 could generate correct and verifiable \formal{Dafny} code for a significant portion of test problems. Similarly, Ma et al. \cite{ma2024specgen} explored the use of LLMs for generating formal specifications in Java, demonstrating the models' ability to produce meaningful specifications for Java methods.

%The conversational prompt style, inspired by works like Xia et al. \cite{xia2024automated} has proven effective in eliciting more detailed and context-aware responses from LLMs. This approach allows for a more natural interaction with the model, potentially leading to more accurate and comprehensive code generation.

%The ability of GPT-4-turbo to generate executable code in a single attempt for all considered programs represents a significant advancement in LLM capabilities for code synthesis. This efficiency aligns with the growing body of research demonstrating the potential of LLMs in various software engineering tasks.

%The success in test case generation by LLMs, as shown by Siddiq et al. and Alshahwan et al. \cite{siddiq2024using,alshahwan2024automated}, further underscores the potential of these models in formal methods and software testing. These studies highlight how LLMs can be leveraged to automate and enhance critical aspects of the software development lifecycle, from specification writing to test case generation.