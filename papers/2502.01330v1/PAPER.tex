\documentclass{article}
\usepackage{titlesec}
\usepackage{xcolor}
\usepackage{microtype}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\usepackage{tikz}
\usepackage{xfrac}
\usepackage{multirow}
\usepackage[inline]{enumitem}
\usepackage{todonotes}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{caption}
\usepackage{subfigure}
\usepackage{bbm}
\usepackage{setspace}

\usepackage[utf8]{inputenc}  % For LaTeX (older versions)
\usepackage[T1]{fontenc}      % Recommended for special characters

%\usepackage{icml2024}
\usepackage[accepted]{icml2024} 


\pgfplotsset{compat=1.16}

\usetikzlibrary{patterns}
\usetikzlibrary{shapes, arrows.meta, positioning}
\DeclareSIUnit\token{tok}
\DeclareSIUnit\sample{sam}
\sisetup{
group-separator={\,},
group-minimum-digits=4
}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\macs}{MACs}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\DeclareSIUnit{\spike}{spike}
\DeclareSIUnit{\messages}{messages}

\DeclareSIUnit{\million}{M}
\DeclareSIUnit{\billion}{B}
\definecolor{color1}{HTML}{E41A1C}
\definecolor{color2}{HTML}{377EB8}
\definecolor{color3}{HTML}{4DAF4A}
\definecolor{color4}{HTML}{984EA3}
\definecolor{color5}{HTML}{FF7F00}

\definecolor{lightblue}{RGB}{119,170,221}
\definecolor{lightcyan}{RGB}{153,221,255}
\definecolor{mint}{RGB}{68,187,153}
\definecolor{pear}{RGB}{187,204,51}
\definecolor{olive}{RGB}{170,170,0}
\definecolor{lightyellow}{RGB}{238,221,136}
\definecolor{orange}{RGB}{238,136,102}
\definecolor{pink}{RGB}{255,170,187}
\definecolor{palegrey}{RGB}{221,221,221}

\icmltitlerunning{Accelerating Linear RNNs at the Edge with Unstructured Sparsity}
% Scalability of linear recurrent neural networks with unstructured sparsity
% Scalable and efficient linear recurrent neural networks with unstructured sparsity
% Scalable linear recurrent neural networks with 10x sparsity


%•  "Modern Linear RNNs for Streaming Inference: Fast and Energy-Efficient Solutions for Edge Devices"
%•  "Signal Processing with Modern RNNs: Low-Latency Streaming Inference on Neuromorphic Processors"
%•  "Unstructured Sparsity in Linear RNNs: Enabling Energy-Efficient Streaming Inference at the Edge"
%•  "Low-Latency and Energy-Efficient Signal Processing with Modern RNNs for Edge Applications"
%•  "Neuromorphic-Friendly Linear RNNs for Streaming Inference with Unstructured Sparsity"
%•  "Fast and Efficient Linear RNNs for Streaming Signal Processing on Edge Devices"
%•  "Streaming Signal Processing with Energy-Efficient Linear RNNs on Neuromorphic Hardware"
%•  "Unstructured Sparsity in Modern RNNs: Optimizing Low-Latency Edge Inference"
%•  "Energy-Efficient Linear RNNs: Streaming Signal Processing for Neuromorphic Processors"
%•  "Modern RNNs for Real-Time Edge Inference: Signal Processing with Low Latency and High Efficiency"
%•  "Modern Linear RNNs for Streaming Inference on Edge Devices with Unstructured Sparsity"
%•  "Energy-Efficient Signal Processing with Neuromorphic Processors and Low-Latency Modern RNNs"
%•  "Hardware-Aware Design of Linear RNNs for Fast, Low-Latency Streaming Inference"
%•  "Unstructured Sparsity in Modern RNNs for Energy-Efficient Edge Computing"
%•  "Neuromorphic Signal Processing: Leveraging Modern RNNs for Fast, Energy-Efficient Streaming"
%•  "Edge-Optimized Linear RNNs: A Hardware-Aware Approach to Low-Latency Signal Processing"
%•  "Energy-Efficient Streaming Inference with Linear RNNs and Unstructured Sparsity"
%•  "Hardware-Aware Modern RNNs for Low-Latency, Fast Streaming Inference on the Edge"
%•  "Signal Processing Meets Edge AI: Efficient Neuromorphic Linear RNNs for Streaming Tasks"
%•  "Unleashing Energy Efficiency and Speed: Linear RNNs for Neuromorphic Processors"

\begin{document}

\twocolumn[
\icmltitle{Accelerating Linear Recurrent Neural Networks for the Edge\\ with Unstructured Sparsity}
%\icmltitle{Unstructured Sparsity Accelerates Linear Recurrent Neural Networks for the Edge on Neuromorphic Processors}

\icmlsetsymbol{equal}{*}
\begin{icmlauthorlist}
\icmlauthor{Alessandro Pierro}{equal,intel,lmu}
\icmlauthor{Steven Abreu}{equal,intel,groningen}
\icmlauthor{Jonathan Timcheck}{intel}
\icmlauthor{Philipp Stratmann}{intel}
\icmlauthor{Andreas Wild}{intel}
\icmlauthor{Sumit Bam Shrestha}{intel}
\end{icmlauthorlist}

\icmlaffiliation{intel}{Neuromorphic Computing Lab, Intel Corporation, USA}
\icmlaffiliation{lmu}{Institute of Informatics, LMU Munich, Germany}
\icmlaffiliation{groningen}{Bernoulli Institute \& CogniGron, University of Groningen, Netherlands}

\icmlcorrespondingauthor{Alessandro Pierro}{alessandro.pierro@intel.com}

\icmlkeywords{recurrent neural network, sparsity, pruning, quantization, state space model, real-time processing, audio processing, model compression, hardware co-design}

\vskip 0.3in

\begin{abstract}
\input{0_Abstract}
\end{abstract}
]

\printAffiliationsAndNotice{\icmlEqualContribution} 


\section{Introduction}
\label{sec:introduction}
\input{1_Introduction.tex}



\section{Compressing linear RNNs}
\label{sec:background}\label{sec:methodology}
\input{2_Background.tex}



% \section{Methodology}
\input{3_Methodology.tex}



\section{Results}
\label{sec:results}
\input{4_Results.tex}



\section{Discussion}
\label{sec:discussion}
\input{5_Discussion.tex}



\section*{Author Contributions}

A.\ P.\ and S.A.\ drove the project conception, developed the initial codebase for training and analyzing sparse S5 models, run the training experiments, and developed the Loihi implementation.
A.\ P.\ implemented the sparsification methods and an early prototype on the chip, and collected benchmarking results on Loihi.
S.\ A.\ implemented the quantization methods and the fixed-point model and benchmarked the dense models on the Jetson board.
J.\ T.\ and P.\ S.\ helped evaluating the Loihi implementation.
J.\ T.\ integrated the audio denoising task in the training codebase.
A.\ W.\ provided general guidance on the scope of the project.
S.\ B.\ S.\ provided technical guidance for the fixed-point and Loihi implementations.
All authors contributed to writing and reviewing the paper.



\bibliography{BIBLIOGRAPHY}
\bibliographystyle{icml2024}

\clearpage
\appendix
\section{Supplemental Material}
\label{sec:appendix}
\input{A_Appendix.tex}

\end{document}