\section{Related Works}
Early research on chain-of-thought (CoT) reasoning can be traced back to ____, who first introduced a prompting strategy that guides LLMs through decomposed intermediate reasoning steps using few-shot exemplars. Concurrently, ____ demonstrated that LLMs are capable of zero-shot CoT reasoning by simply appending the phrase ``Let's think step by step'' to the prompt template. This discovery underscored the latent reasoning abilities of LLMs, even in the absence of explicit demonstrations.

Building upon these foundational works, the NLP community has extensively explored the potential of CoT reasoning. As summarized by ____, recent advancements in CoT methods can be broadly categorized into three areas: (1) {\it Prompt Construction}, which aims to optimize prompts for improved CoT reasoning ____; (2) {\it Topological Variants}, which leverage structured representations such as trees and graphs to enhance CoT reasoning____; and (3) {\it Enhancement Methods}, which introduce external strategies to further improve CoT reasoning, such as question decomposition____ and self-consistency decoding ____. Despite the effectiveness of these approaches, the majority of existing CoT methods rely on discrete token-by-token generation, which imposes inherent constraints and limits their expressiveness.

To address the limitations of discrete language space, an effective approach is to leverage continuous representation space for reasoning. Coconut____ introduces a Chain-of-Continuous-Thought, while CCoT____ employs Compressed Chain-of-Thought, generating content-rich and continuous contemplation tokens. Heima____ further advances this idea by utilizing a single continuous vector to represent compressed reasoning tokens in multi-modal tasks. However, both Coconut and CCoT rely on a language modeling objective for supervised fine-tuning, which is infeasible for state-of-the-art LLMs due to the catastrophic forgetting problem. Moreover, Heima underperforms compared to its backbone model, LLaVA-CoT____. These challenges underscore the need to develop methodologies that mitigate catastrophic forgetting in the application of continuous-space CoT reasoning.