\section{Related Work}
\label{sec2}


Object detection in computer vision is primarily categorized into one-stage and two-stage techniques. Two-stage methods, exemplified by R-CNN\cite{Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation} and Faster R-CNN\cite{Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, generate candidate bounding boxes and subsequently classify and refine them, achieving high accuracy at the expense of speed. Enhancements such as the integration of adversarial networks have been introduced to bolster robustness and expedite detection. In contrast, the main one-stage object detection algorithms include the YOLO family, which consists of YOLO \cite{redomnYOLO2016} that overcomes the shortcomings of two-stage detection networks. YOLOv2 \cite{YOLO9000} introduces batch normalization layers after each convolution and eliminates the use of dropout. YOLOv3 \cite{YOLOv3: An Incremental Improvement} marked a significant improvement, characterized by the introduction of the residual module Darknet-53 and FPN. There have been studies that added many techniques based on YOLOv3, such as YOLOv4 \cite{Yolov4: Optimal speed and accuracy of object detection}, YOLOv5 \cite{YOLOv5 by Ultralytics}, YOLOv6 \cite{YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications 2022}, and YOLOv7 \cite{YOLOv7: Trainable Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors}. The related code for YOLOv8 can be found on GitHub. SSD \cite{SSD: Single Shot MultiBox Detector} and RetinaNet \cite{Focal Loss for Dense Object Detection} are also part of this category. YOLO divides the entire image into a grid, with each cell predicting bounding boxes and classification confidence. Some studies have introduced modifications to YOLOv8 to achieve high-precision detection performance \cite{Underwater Object Detection Using TC-YOLO with Attention Mechanisms, Fish Detection under Occlusion Using Modified You Only Look Once v8 Integrating Real-Time Detection Transformer Features, Student Behavior Detection in the Classroom Based on Improved YOLOv8}

In computer vision, attention mechanisms such as channel attention, spatial attention, and combined channel-spatial attention dynamically adjust the weights of input features to focus on important areas, similar to the human visual system. Examples include CBAM\cite{CBAM: Convolutional Block Attention Module} and EMA for combined channel-spatial attention. The residual attention network\cite{Residual Attention Network for Image Classification}, an early implementation, generates a three-dimensional attention map but faces challenges with high computational cost and limited receptive fields. To improve efficiency, techniques like global average pooling and decoupling methods have been introduced. Additionally, the Feature Pyramid Network (FPN) constructs a hierarchical feature pyramid to represent objects of various sizes, enhancing multi-scale target detection by merging features from different network levels, thereby improving detection accuracy and capturing fine details. In underwater object detection, upsampling is crucial for reorganizing features to achieve higher detection performance. Methods like linear interpolation and deep learning-based upsampling, such as Meta-Upscale\cite{Meta-SR: A Magnification-Arbitrary Network for Super-Resolution} and CARAFE. While interpolation methods can increase image resolution, they may introduce noise and increase computational complexity. In contrast, deep learning-based methods like CARAFE offer a large receptive field and accurate detail restoration without significantly increasing computational complexity, making them effective for balancing detection performance improvement in the field of computer vision.