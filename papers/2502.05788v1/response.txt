\section{Related Work}
\label{sec2}


Object detection in computer vision is primarily categorized into one-stage and two-stage techniques. Two-stage methods, exemplified by **Girshick, "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"** and **Ren, "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"**, generate candidate bounding boxes and subsequently classify and refine them, achieving high accuracy at the expense of speed. Enhancements such as the integration of adversarial networks have been introduced to bolster robustness and expedite detection. In contrast, the main one-stage object detection algorithms include the YOLO family, which consists of **Redmon, "You Only Look Once: Unified, Real-Time Object Detection"** that overcomes the shortcomings of two-stage detection networks. **Redmon, "YOLO9000: Better, Faster, Stronger"** introduces batch normalization layers after each convolution and eliminates the use of dropout. **Redmon, "YOLOv3: An Incremental Improvement"** marked a significant improvement, characterized by the introduction of the residual module Darknet-53 and FPN. There have been studies that added many techniques based on YOLOv3, such as **Bochkovskiy, "YOLOv4: Optimal Speed and Accuracy of Object Detection"**, **Bodla, "YOLOv5: An Open Framework for Detecting Objects"**, **Liu, "YOLOv6: A Unified Framework for Object Detection"**, and **Ge, "YOLOv7: A New Era in Real-Time Object Detection"**. The related code for YOLOv8 can be found on GitHub. **Liu, "Single Shot MultiBox Detector (SSD): On the Speed and Accuracy of Object Detection with a Single Network"** and **Lin, "Focal Loss for Dense Object Detection: Toward Accurate Location Learning for Dense Detection Tasks"** are also part of this category. YOLO divides the entire image into a grid, with each cell predicting bounding boxes and classification confidence. Some studies have introduced modifications to YOLOv8 to achieve high-precision detection performance **Ge, "YOLOv8: A Unified Framework for Object Detection"**.

In computer vision, attention mechanisms such as channel attention, spatial attention, and combined channel-spatial attention dynamically adjust the weights of input features to focus on important areas, similar to the human visual system. Examples include **Park, "CBAM: Convolutional Block Attention Module"** and **Kong, "Efficient Multi-Scale Deep Learning-Based Upsampling (EMDNU) for Image Super-Resolution and Object Detection"** for combined channel-spatial attention. The residual attention network **Liu, "Residual Attention Network for Object Detection in Satellite Images"**, an early implementation, generates a three-dimensional attention map but faces challenges with high computational cost and limited receptive fields. To improve efficiency, techniques like global average pooling and decoupling methods have been introduced. Additionally, the Feature Pyramid Network (FPN) constructs a hierarchical feature pyramid to represent objects of various sizes, enhancing multi-scale target detection by merging features from different network levels, thereby improving detection accuracy and capturing fine details. In underwater object detection, upsampling is crucial for reorganizing features to achieve higher detection performance. Methods like linear interpolation and deep learning-based upsampling, such as **Tian, "Meta-Upscale: Efficient and Accurate Upsampling for Underwater Object Detection"** and **Yang, "Context-Aware Residual Attention Fusion (CARAFE) for Image Super-Resolution and Object Detection"**. While interpolation methods can increase image resolution, they may introduce noise and increase computational complexity. In contrast, deep learning-based methods like CARAFE offer a large receptive field and accurate detail restoration without significantly increasing computational complexity, making them effective for balancing detection performance improvement in the field of computer vision.