\iffalse
\begin{table}[tb]
\small
\centering
\setlength{\tabcolsep}{0.7mm}
\begin{tabular}{lcccc}
\toprule
\textbf{LLM} & \textbf{Acc}$\uparrow$ & \textbf{$\text{P-Acc}_{\text{A}}$}$\uparrow$ & \textbf{$\text{P-Acc}_{\text{M}}$}$\uparrow$ & \textbf{Not M\%}$\downarrow$ \\
\midrule
%Mistral & 2.00 & 32.59 & 62.67 & 48.00 \\
%Llama-3 & 5.00 & 49.56 & 73.98 & 33.00 \\
%\midrule
$\text{Mistral-FT}_{\text{Atom}}$ &1.00 &42.46 &68.49 &38.00 \\
%$\text{Mistral-FT}_{\text{ARC+Atom}}$ & 6.00&51.31 &71.27 &28.00 \\
%\midrule
$\text{Llama-3-FT}_{\text{Atom}}$ & 2.00&42.77 &71.28 &40.00 \\
%$\text{Llama-3-FT}_{\text{ARC+Atom}}$ &6.00 &51.81 &74.02 &30.00 \\
\bottomrule
\end{tabular}
\caption{Performances of LLMs fine-tuned on atomic operation data on ARAOC and the 100 ARC tasks. %\lemao{Reorg this table to show the performance gap between ARROC and ARC. Merge the finetuning results together.}
}
\label{tab:fine-tune arc performance}
\end{table}
\fi



\section{Challenge on Task Composition}
\label{sec:factor}
In this section, we assess the deficiency of LLM's fluid intelligence from a task composition perspective. %To be specific, we evaluate the task composition ability of LLMs from two aspects. 
First, we consider a simple composition experiment that controllably evaluates the composition for Move and Copy in ARAOC (\sref{sec:simple composition}). Moreover, we design a complex composition experiment utilizing ARC tasks to evaluate LLMs' abilities to compose all atomic operations (\sref{sec:complex composition}).



\subsection{Evaluation on Simple Composition}
\label{sec:simple composition}
%One possible reason why LLMs fine-tuned on atomic operation data still fail on ARC is that their abilities to compose multiple atomic operations are weak. 
We start from evaluating LLMs' compositional ability on a simple composition task. 
To be specific, we compose Move and Copy to create 100 new tasks for evaluation. Since Mistral and Llama-3 are facing severe challenges on inducting these two atomic operations, we fine-tune them on three types of data: 1) 3,000 Move tasks; 2) 3,000 Copy tasks ; 3) 1,500 Move tasks and 1,500 Copy tasks, while making sure that these tasks do not overlap with those in ARAOC. We evaluate these fine-tuned LLMs and the GPT models on the newly crafted Move and Copy tasks and list the results in~\tref{tab:composition}.

%To further investigate the above assumption, 
%we fine-tune Mistral and Llama-3 on 3000 Move and Copy tasks that do not overlap with ARAOC (ensuring the number of fine-tuning examples remains the same as~\tref{tab:fine-tune arc performance}), respectively. Then, we test these fine-tuned LLMs on both the Move and Copy tasks in ARAOC, as well as on 100 additional tasks composed of Move and Copy operations. 

As can be seen, fine-tuning on single atomic operation's data can boost LLMs' performances on corresponding tasks, while fine-tuning on both atomic operations can achieve enhancement on both tasks. However, all the fine-tuned LLMs as well as GPT models face severe challenges when dealing with the composition tasks, which is not a complex composition, indicating that the composition abilities of LLMs are limited.



%Nevertheless, fine-tuning on both atomic operations' data could lead to better performances on the compositional task, raising up a straightforward question: \textit{could fine-tune with all the atomic operations help LLMs handle complex compositions in general ARC tasks?}

%This experimental result demonstrates our previous assumption that LLMs lack the capability to compose atomic operations, thus leads to their poor performances on ARC.
%.\mo{Conclusion1: Failure of transfer and composition of SFT paradigm}


%\lemao{This section is too short, you should consider how to add some new experiments or some contents? For example, you can use gpt4 for experiments without finetuning on both table 4 \& 5. In addition, you can add composition for other operations such as Change Color and Fill without finetuning?}



\subsection{Evaluation on Complex Composition}
\label{sec:complex composition}
%\lemao{Reorganize this subsection. Note that ARC can be considered as the compositions of different atomic operations.}

%Given that LLMs still perform poorly on ARAOC, 
%Similar to Section \ref{sec:evaluate on original arc}, we fine-tune Mistral and Llama-3 on tasks built upon atomic operations to see if this could enhance their performances on ARAOC. 
Furthermore, we examine the LLMs' abilities to compose atomic operations in complex ways. As mentioned in~\sref{sec: atom operation}, the ARC tasks can be decomposed into atomic operations listed in Table \ref{tab:atom operations}. Therefore, we regard ARC tasks as complex compositions of atomic operations for evaluation. Here we evaluate Llama-3 and GPT-4o since they are the better open-sourced and close-sourced LLMs in~\tref{tab:composition}.
In addition, % to the LLMs in~\sref{evaluated llms}, 
we fine-tune Llama-3 on tasks built upon atomic operations (check fine-tune details in Appendix~\ref{appendix:lora}) to see if this leads to improvement on ARC (\textbf{FT-atomic}).
%, using the same strategy and configurations as described in Section \ref{sec:evaluate on original arc}. Specifically, we generated an additional 500 tasks for each atomic operation beyond the 100 tasks in ARAOC, resulting in a total of 3000 tasks for fine-tuning. %We fine-tuned Mistral and Llama-3 on these data using the same strategy and configurations as described in Section \ref{sec:evaluate on original arc} (FT-atomic). 
In addition, we apply three more strategies to fine-tune Llama-3 for comparison: 1) using both the aforementioned operation data and 400 ARC tasks that do not overlap with the 100 evaluation tasks (\textbf{FT-atomic-arc}); 2) using only the 400 ARC tasks (\textbf{FT-arc}).
  %We evaluated these LLMs on ARC, and also listed their results on ARAOC for extra comparison.

Results are show in~\tref{tab:fine-tune arc performance}. We observe that fine-tuning on atomic operation data largely improves the performance of Llama-3 on ARAOC~\footnote{\scriptsize{We perform an additional experiment in Appendix~\ref{appendix:further fine-tuning} to further support this point.
}}. In particular, both fine-tuned LLMs achieve high accuracy on Color, Fill Internal, and Scale tasks, which Llama-3 struggles with. However, Llama-3-FT-atomic performs even worse than Llama-3 on ARC tasks. This could be due to the loss of compositional ability after solely fine-tuning on atomic operations, an issue that Llama-3-FT-atomic-arc does not encounter. On the other hand, fine-tuning on ARC tasks enhances LLMs' performance on ARC, but the improvement on ARAOC tasks is relatively limited compared to fine-tuning on ARAOC tasks. This is likely because the transformation rules in ARC are highly complex, and LLMs struggle to decompose these rules into atomic operations. Nonetheless, all LLMs still perform poorly on ARC tasks, which is unsurprising given their difficulties with even the simple compositions presented in~\tref{tab:composition}.
 
 %Overall, the experiment outcome again suggests that even if LLMs have a good understanding of individual atomic operations, they have limited ability to compose these atomic operations, causing them to fail on complex inductive reasoning tasks.

\textbf{Overall, while fine-tuning on atomic operations may assist LLMs in understanding these operations, it does not enable them to infer such operations from in-context examples. This limitation explains LLMs' poor performance on compositional tasks and further highlights their lack of intrinsic mechanisms for abstract reasoning, a core characteristic of fluid intelligence.
}



%the reason LLMs struggle with ARC tasks may be due to their weak ability to compose different atomic operations into the complex transformation rules required for ARC tasks.
 %\mo{Composition is one of the important aspects. The problems left are: (1) the LLMs learned the six operations instead of induction (this is actually the problem of 1DARC design); (2) the six operations do not cover every operation in ARC.}



