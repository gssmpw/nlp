\section{Related Works}

\paragraph{Evaluating fluid intelligence of LLMs.}
As an essential aspect of intelligence~\cite{cattell1963theory, cattell1971abilities, jaeggi2008improving}, studying the fluid intelligence of LLMs offers deeper insights into their overall intelligence. \citet{chollet2019measure} and \citet{barak2024investigating} suggest that abstract inductive reasoning is an ideal method for evaluating LLMs' fluid intelligence. However, most existing benchmarks~\cite{honovich2023instruction, yang2024language, qiuphenomenal} fail to prevent memorization shortcuts, making them easier for LLMs to solve. In contrast, the ARC corpus~\cite{chollet2019measure} that challenges models to identify transformation rules between input-output grids, poses significant difficulty for LLMs, making it suitable for fluid intelligence assessment. 
Previous works have primarily focused on improving LLM performance on ARC tasks~\cite{min2023approach, tan2023large, xullms, mirchandani2023large, wang2024speak, huang2024anpl, wang2023hypothesis}, but the results remain far from optimal. This motivates us to explore the underlying reasons behind LLMs' limited fluid intelligence.

\paragraph{Matrix operations with LLMs.}
It has been shown that LLMs have abilities to understand matrix operations% like transpose and inverse, 
%and fine-tuning on matrix operation data can enhance LLMs' performances on matrix-related problems
~\cite{charton2021linear, collins2024evaluating, azerbayevllemma, shao2024deepseekmath}. However, \sref{sec:understand matrix} indicates that understanding the properties of matrix may not the key factor of LLMs' success on ARC and ARAOC, leading to further analyses.

