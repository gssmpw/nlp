
\begin{table}[tb]
\small
\centering
\setlength{\tabcolsep}{1.3mm}
\begin{tabular}{ll|cccc}
\toprule
& \textbf{Setting} & \textbf{Mistral} & \textbf{Llama-3} & \textbf{GPT-3.5} & \textbf{GPT-4o} \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Move}}& Ori & 2.00 & 1.00 & 4.00 & 13.00 \\
& Small & 12.00& 12.00 & 20.00 & 28.00\\
\midrule
\multirow{2}{*}{\textbf{Copy}}&Ori & 2.00 & 4.00 & 4.00 & 15.00 \\
&Small &12.00 &9.00 &14.00 & 34.00 \\
\bottomrule
\end{tabular}
\caption{Acc (in percentage) of LLMs with different input sizes. See~\tref{tab:large matrix_plus} for the Not M\% scores.}
\vspace{-0.1in}
\label{tab:large matrix}
\end{table}

\iffalse
\begin{table}[tb]
\small
\centering
\setlength{\tabcolsep}{1mm}
\begin{tabular}{ll|cccccc}
\toprule
& \multirow{2}{*}{\textbf{Setting}} & \multicolumn{2}{c}{\textbf{Mistral}} & \multicolumn{2}{c}{\textbf{Llama-3}} & \multicolumn{2}{c}{\textbf{GPT}} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8}
&~ & \textbf{7B} & \textbf{8*7B} & \textbf{8B} & \textbf{70B} &\textbf{3.5} &\textbf{4o}\\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Move}} & Ori & 2.00 && 1.00 && 4.00 & 13.00 \\
& Small & 12.00 & & 12.00 && 20.00 & 28.00 \\
\midrule
\multirow{2}{*}{\textbf{Copy}} & Ori & 2.00 && 4.00 && 4.00 & 15.00 \\
& Small & 12.00 && 9.00 && 14.00 & 34.00 \\
\bottomrule
\end{tabular}
\caption{Acc (in percentage) of LLMs with different input sizes. See~\tref{tab:large matrix_plus} for the Not M\% scores.}
\vspace{-0.1in}
\label{tab:large matrix}
\end{table}
\fi

\begin{table}[tb]
\small
\centering
\setlength{\tabcolsep}{2mm}
\begin{tabular}{lcc|cc}
\toprule
\textbf{LLM} &\textbf{Move} & \textbf{Copy} & \textbf{Comp} %& \textbf{Rank}
\\
\midrule
$\text{Mistral-FT}_{\text{Move}}$ & 19.00 & 4.00& 0.00  \\
$\text{Mistral-FT}_{\text{Copy}}$ &11.00 &32.00 & 2.00\\
$\text{Mistral-FT}_{\text{Move+Copy}}$ & 25.00& 32.00&4.00\\
\midrule
$\text{Llama-3-FT}_{\text{Move}}$ &21.00 &4.00 &0.00\\
$\text{Llama-3-FT}_{\text{Copy}}$ &12.00 &33.00 & 3.00\\
$\text{Llama-3-FT}_{\text{Move+Copy}}$ &26.00 & 27.00&5.00\\
\midrule
GPT-3.5 &4.00 &4.00 & 0.00\\
%GPT-4 &14.00 &13.00 & 4.00\\
GPT-4o &13.00 &15.00 & 2.00\\
\bottomrule
\end{tabular}
\caption{Acc (in percentage) on tasks composing Move and Copy (Comp).
%fine-tuned on single and multiple tasks. 
%Comp refers to tasks composed of Move and Copy. 
See~\tref{tab:composition_plus} for the Not M\% scores.}
\vspace{-0.2in}
\label{tab:composition}
\end{table}

\begin{table*}[tb]
\renewcommand\arraystretch{1.1}
\centering
\setlength{\tabcolsep}{2.5mm}
\small
\begin{tabular}{lcccccc|c}
\toprule[1pt]
\multirow{2}*{LLM} & \multicolumn{6}{c}{\textbf{Individual Atomic Operation}} & \multicolumn{1}{c}{\textbf{ Composition}} \\
\cmidrule{2-8}
& \multicolumn{1}{c}{\textbf{Move}} & \multicolumn{1}{c}{\textbf{Change Color}} & \multicolumn{1}{c}{\textbf{Copy}} & \multicolumn{1}{c}{\textbf{Mirror}} & \multicolumn{1}{c}{\textbf{Fill Internal}} & \multicolumn{1}{c}{\textbf{Scale}} & \multicolumn{1}{c}{\textbf{ARC}}  \\
% & Acc$\uparrow$ & Acc$\uparrow$ & Acc$\uparrow$ & Acc$\uparrow$ & Acc$\uparrow$ & Acc$\uparrow$ & Acc$\uparrow$ \\
\midrule[0.5pt]
%Mistral & 2.00 & 15.00 & 2.00 & 1.00 & 9.00 & 0.00 & 2.00 \\
%$\text{Mistral-FT-atomic}$ & 12.00 & 100.00 & 20.00 & 26.00 & 97.00 & 89.00 & 1.00 \\
%$\text{Mistral-FT-atomic-arc}$ &14.00 &99.00&14.00&24.00&97.00&87.00&6.00\\
%\midrule
Llama-3 & 1.00 & 39.00 & 4.00 & 2.00 & 63.00 & 1.00 & 5.00 \\
$\text{Llama-3-FT-arc}$ &2.00 &73.00 &5.00 &3.00 &88.00 &0.00 &9.00 \\
$\text{Llama-3-FT-atomic}$ & 13.00 & 98.00 & 14.00 & 27.00 & 97.00 & 78.00 & 2.00 \\
$\text{Llama-3-FT-atomic-arc}$ & 12.00 &97.00&17.00&28.00&98.00&79.00&6.00 \\
\midrule
%GPT-3.5 &4.00&48.00&4.00&6.00&58.00&1.00 &6.00 \\
%GPT-4 &14.00 &97.00&13.00&14.00&100.00&3.00&17.00 \\
GPT-4o & 13.00&98.00&15.00&12.00&96.00&2.00&19.00 \\
\bottomrule[1pt]
\end{tabular}
\caption{Results of LLMs on individual and composition of atomic operations. %FT refers to fine-tune on the atomic operation data. S
See~\tref{tab:fine-tune arc performance_plus} for the Not M\% scores.}
\vspace{-0.2in}
\label{tab:fine-tune arc performance}
\end{table*}

\begin{table}[tb]
\small
\centering
\setlength{\tabcolsep}{3mm}
\begin{tabular}{lcccc}
\toprule
\textbf{LLM} &\textbf{Size} & \textbf{Location} & \textbf{Transpose} %& \textbf{Rank}
\\
\midrule
Mistral &0.32 &0.00 &0.02 %&0.29 
\\
Llama-3 & 0.63&0.04 &0.04 %&0.86
\\
%Mistral 8*7B & & & %&0.29 
%\\
%Llama-3 70B & & & %&0.86
%\\
\midrule
GPT-3.5 &0.93 &0.43 &0.34 %&0.30
\\
%GPT-4o &\textbf{1.00} &\textbf{0.77} &\textbf{0.83} \\%s&0.95\\
GPT-4o &\textbf{1.00} &\textbf{0.91} &\textbf{0.91} \\
\bottomrule
\end{tabular}
\caption{LLMs' accuracy on matrix-related questions. The best results under each column are \textbf{boldfaced}.}
\vspace{-0.1in}
\label{tab:understand matrix}
\end{table}

\section{Challenge on Input Format}
\label{sec:matrix}



Since LLMs cannot process visual inputs, we follow~\citet{wang2023hypothesis} to convert the 2D visual input-output grids in ARAOC tasks into matrix-format before feeding them to the LLMs (\sref{sec:arc setting}). However, it remains uncertain that whether this conversion affects LLMs' performances on ARAOC, since LLMs are mostly trained on natural language data, and may not understand such matrix-format inputs well. In this section, we first try to answer this question (\sref{sec:understand matrix}), then investigate a strategy to remedy its potential challenges (\sref{sec:natural language}).


\subsection{Matrix-format Understanding}
\label{sec:understand matrix}
%We analyze this problem from two perspectives. First, 
We first investigate whether LLMs understand the input matrices well. Specifically, we select the testing input matrices from the 100 ARAOC Move tasks, and ask LLMs to output the size, transpose, and subgrid's corner elements' locations of each matrix (see the input prompt in~\fref{fig:matrix property prompt}). Our intuition is that if LLMs correctly answer these questions, they should have understood the matrix-format input. % and this should not affect their performances on ARAOC tasks. 
Results are shown in~\tref{tab:understand matrix}, where GPT-4o answers these questions with high accuracy, indicating that it comprehends such matrix-format inputs well. However, other LLMs perform poorly on these tasks, which may further affect their results on ARAOC. 



To further investigate the impact of matrix-format input, we re-evaluate $\text{Llama-3-FT}_{\text{Move+Copy}}$ from~\tref{tab:composition} and GPT-4o on the Move and Copy tasks without using the location information of subgrids, as detailed in Appendix~\ref{appendix:banning}. The results in Appendix~\ref{appendix:banning} show that prohibiting the use of location information do reduce LLMs' performances on both tasks, indicating that a fundamental understanding of matrices is crucial for completing ARAOC and ARC tasks. However, as the combined results from~\tref{tab:araoc results} and~\tref{tab:understand matrix} suggest, possessing matrix understanding alone does not guarantee good performance on these tasks.



\begin{table}[tb]
\small
\centering
\setlength{\tabcolsep}{0.5mm}
\begin{tabular}{ll|cccc}
\toprule
& \textbf{Method}& \textbf{Mistral}& \textbf{Llama-3} & \textbf{GPT-3.5}%& \textbf{GPT-4}
&\textbf{GPT-4o}\\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Move}}& w/o NL &2.00 &1.00 &4.00 & 13.00\\%&14.00 \\
& NL & 5.00 &12.00 &23.00 &53.00 \\%49.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Color}}& w/o NL &15.00 &39.00 &48.00 & 98.00\\%97.00 \\
& NL &3.00 &83.00 &59.00 &99.00 \\%92.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Copy}}& w/o NL &2.00 &4.00 &4.00 & 15.00\\%13.00 \\
& NL &2.00 &6.00 &14.00 &40.00 \\%45.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Mirror}}& w/o NL &1.00 &2.00 &6.00 & 12.00\\%14.00 \\
& NL &2.00 &8.00 &21.00 & 30.00\\%29.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Fill Internal}}& w/o NL &9.00 &63.00 &58.00 &96.00 \\%100.00 \\
& NL &0.00 &10.00 &35.00 & 72.00\\%85.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Scale}}& w/o NL &0.00 &1.00 &1.00 &2.00 \\%3.00 \\
& NL &0.00 &2.00 &0.00 &4.00 \\%6.00 \\
\bottomrule
\end{tabular}
\caption{Acc (in percentage) of LLMs with natural language inputs (NL). %w/o NL refers to the results in~\tref{tab:araoc results}. 
See Not M \% scores in~\tref{tab:natural language input_plus}.}
\vspace{-0.2in}
\label{tab:natural language input}
\end{table}


\iffalse
\begin{table}[tb]
\small
\centering
\setlength{\tabcolsep}{0.5mm}
\begin{tabular}{ll|cccccc}
\toprule
& \multirow{2}{*}{\textbf{Setting}} & \multicolumn{2}{c}{\textbf{Mistral}} & \multicolumn{2}{c}{\textbf{Llama-3}} & \multicolumn{2}{c}{\textbf{GPT}} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8}
&~ & \textbf{7B} & \textbf{8*7B} & \textbf{8B} & \textbf{70B} &\textbf{3.5} &\textbf{4o}\\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Move}}& w/o NL &2.00 &&1.00& &4.00 & 13.00\\%&14.00 \\
& NL & 5.00& &12.00& &23.00 &53.00 \\%49.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Color}}& w/o NL &15.00& &39.00& &48.00 & 98.00\\%97.00 \\
& NL &3.00& &83.00& &59.00 &99.00 \\%92.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Copy}}& w/o NL &2.00& &4.00& &4.00 & 15.00\\%13.00 \\
& NL &2.00& &6.00& &14.00 &40.00 \\%45.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Mirror}}& w/o NL &1.00& &2.00& &6.00 & 12.00\\%14.00 \\
& NL &2.00& &8.00& &21.00 & 30.00\\%29.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Fill Internal}}& w/o NL &9.00& &63.00& &58.00 &96.00 \\%100.00 \\
& NL &0.00& &10.00& &35.00 & 72.00\\%85.00 \\
\midrule[0.5pt]
\multirow{2}{*}{\textbf{Scale}}& w/o NL &0.00& &1.00& &1.00 &2.00 \\%3.00 \\
& NL &0.00& &2.00& &0.00 &4.00 \\%6.00 \\
\bottomrule
\end{tabular}
\caption{Acc (in percentage) of LLMs with natural language inputs (NL). %w/o NL refers to the results in~\tref{tab:araoc results}. 
See Not M \% scores in~\tref{tab:natural language input_plus}.}
\vspace{-0.2in}
\label{tab:natural language input}
\end{table}
\fi


%\subsection{Fine-tuning on Matrix Data}
%\label{sec:fine tune on matrix}
%Given that both open-sourced LLMs have difficulties understanding matrix-format inputs, we first investigate whether fine-tuning LLMs on matrix property-related questions could improve their performances on tasks in ARAOC. Specifically, we generate 3000 extra input grids of the Move task and calculate the size, transpose, and locations of the subgrid's corner elements for these matrices as ground truths. Furthermore, since correctly recognizing the location of the subgrid may contribute more to finish the Move and Copy tasks compared to other properties, we create additional ground truths only with the gold locations of the subgrid's corner elements. We fine-tune Mistral and Llama-3 on these two sets of matrix property data using the same strategy and configuration described in~\sref{sec:evaluate on original arc}, and evaluate them on the Move and Copy tasks in ARAOC, respectively.

%As shown in~\tref{tab:fine-tune on matrix}, fine-tuning solely with the locations of subgrids provides more benefits than fine-tuning with all three matrix properties. This indicates that different atomic operations require a specific understanding of matrices, and acquiring this understanding can better enhance performance on specific atomic operations. However, compared to the results in~\tref{tab:araoc results}, all matrix-property data appear to decrease LLMs' performance on ARAOC tasks. This demonstrates that simply fine-tuning LLMs on matrix property data may not be an effective solution for improving their inductive reasoning abilities on ARAOC.


\subsection{Switching Matrix into Natural Language}
\label{sec:natural language}
%Finally, we propose an approach to relieve the challenge on input understanding, which is inspired by our previous finding that GPT-4 struggles to derive correct transformation rules from ARAOC's input matrices (\tref{tab:araoc results}) despite its excellent understanding of these matrices (\tref{tab:understand matrix}). 
%From previous sections we conclude that the challenges of ARAOC and ARC tasks is not due to LLMs' understanding of matrix-format inputs.
%Therefore, a new type of inputs for representing such tasks is necessary. 
Since LLMs are predominantly trained on natural language rather than matrix-format data, we further propose to convert the matrix-format input-output grids into natural language with the aid of a coordinate system-based prompt (listed in~\fref{fig:natural language prompt}). We evaluate LLMs using this new prompt on ARAOC, and the results are presented in~\tref{tab:natural language input}.

Notably, we find that on tasks that LLMs originally cannot answer well (Move, Copy, Mirror, and Scale), using natural language inputs can largely boost their performances. As for tasks that are relatively easy for LLMs, converting matrix-format input to natural language still keep the good performances. %These results illustrate the effectiveness of our proposed approach. 
One exception appears to be the Mistral model, whose performance decreases with the natural language prompt. This is probably because this model is not strong enough to encode the natural language input that can be handled by other LLMs, which makes its results not indicative.

\textbf{Overall, we conclude that LLMs' failure on fluid intelligence tests is not mainly due to their understanding of the specific matrix-format inputs, but their limitations on encoding such inputs for obtaining global representations of the input tasks.}









