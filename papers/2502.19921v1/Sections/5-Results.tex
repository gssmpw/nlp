\section{Results and Discussion}
\label{ref:results}
We present the main results of our approach compared to state-of-the-art methods across the six time series tasks on nine datasets.
Overall, our method has demonstrated a substantial performance improvement, reaching up to 10--15\% in some tasks, while increasing the shift consistency up to 50--60\% compared to previous techniques.
\begin{table*}[h]
\caption{Performance comparison of our method and other techniques for HR estimation}
\begin{adjustbox}{width=1\columnwidth,center}
\label{tab:performance_ppg}
\renewcommand{\arraystretch}{0.8}
\begin{tabular}{@{}lllllllllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{4}{l}{IEEE SPC22} & \multicolumn{4}{l}{DaLiA}  \\ 
\cmidrule(r{15pt}){2-5}  \cmidrule(r{15pt}){6-10}  
& S-Cons (\%) $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & $\rho$ (\%) $\uparrow$ & S-Cons (\%) $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & $\rho$ (\%) $\uparrow$ \\
\midrule
Baseline & 61.99\small$\pm$1.19 & 18.39\small$\pm$2.96 & 10.28\small$\pm$1.41 & 62.64\small$\pm$5.74 & 32.08\small$\pm$0.22 & 9.86\small$\pm$0.23 & 4.40\small$\pm$0.03 & 86.01\small$\pm$0.51 \\
Aug. & 76.48\small$\pm$1.77 & 18.73\small$\pm$1.15 & 10.42\small$\pm$0.40 & 64.06\small$\pm$3.70 & 52.77\small$\pm$0.39 & 9.85\small$\pm$0.21 & 4.47\small$\pm$0.06 & 85.99\small$\pm$0.49 & \\
LPF & 76.88\small$\pm$0.73 & 20.20\small$\pm$1.54  & 13.44\small$\pm$0.82 & 65.40\small$\pm$1.92 & 38.67\small$\pm$0.30 & 10.01\small$\pm$0.30 & 4.67\small$\pm$0.12 & 85.68\small$\pm$0.51 & \\
APS & 73.99\small$\pm$1.06 & 19.42\small$\pm$0.60 & 12.98\small$\pm$0.29 & 65.27\small$\pm$1.32 & 44.33\small$\pm$0.16 & 10.45\small$\pm$0.40 & 5.01\small$\pm$0.17 & 84.69\small$\pm$0.85 & \\

WaveletNet & 51.71\small$\pm$1.95 & 21.56\small$\pm$1.01 & 14.61\small$\pm$0.34 & 60.74\small$\pm$4.37 & 36.71\small$\pm$3.04 & 15.46\small$\pm$0.64 & 7.67\small$\pm$0.23 & 76.13\small$\pm$1.86 & \\

Canonicalize & 63.52\small$\pm$1.20 & 19.02\small$\pm$0.62 & 10.40\small$\pm$0.69 & 61.27\small$\pm$1.07 & 32.01\small$\pm$0.33 & 9.77\small$\pm$0.12 & 4.39\small$\pm$0.05 & 86.02\small$\pm$0.30 & \\
\midrule

Ours & \textbf{100\small$\pm$0.00} & \textbf{16.25\small$\pm$0.72} & \textbf{9.45\small$\pm$0.03} & \textbf{70.12\small$\pm$2.10}& \textbf{100\small$\pm$0.00} & \textbf{9.75\small$\pm$0.15} & \textbf{4.39\small$\pm$0.03} & \textbf{86.06\small$\pm$0.19} \\
Ours\small+\scriptsize LPF & 100\small$\pm$0.00 & 20.34\small$\pm$1.62 & 13.77\small$\pm$0.84 & 65.60\small$\pm$2.31 & 100\small$\pm$0.00 & 10.72\small$\pm$0.11 & 5.30\small$\pm$0.03  & 84.12\small$\pm$0.23 \\
Ours\small+\scriptsize APS & 100\small$\pm$0.00 & 18.81\small$\pm$1.59 & 12.32\small$\pm$0.84 & 67.01\small$\pm$3.79 & 100\small$\pm$0.00 & 10.47\small$\pm$0.09 & 5.10\small$\pm$0.03 & 84.62\small$\pm$0.31 & \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

\begin{table*}[t]
\caption{Performance comparison of ours and other techniques in \textit{ECG} datasets for CVD classification}
\begin{adjustbox}{width=1\columnwidth,center}
\label{tab:performance_ecg}
\renewcommand{\arraystretch}{0.8}
\begin{tabular}{@{}lllllllllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{4}{l}{Chapman} & \multicolumn{4}{l}{PhysioNet 2017}  \\ 
\cmidrule(r{15pt}){2-5}  \cmidrule(r{15pt}){6-10}  
& S-Cons (\%) $\uparrow$ & Acc $\uparrow$ & F1 $\uparrow$ & AUC (\%)$\uparrow$ & S-Cons (\%) $\uparrow$ & Acc $\uparrow$ & F1 $\uparrow$ & AUC $\uparrow$ \\
\midrule
Baseline & 98.53\small$\pm$0.17 & 91.32\small$\pm$0.23 & 91.22\small$\pm$0.24 & 98.34\small$\pm$0.16 & 98.37\small$\pm$0.15 & 83.22\small$\pm$0.72 & 73.50\small$\pm$1.99 & 93.21\small$\pm$0.30 \\
Aug. & 99.00\small$\pm$0.16 & 91.96\small$\pm$0.19 & 91.89\small$\pm$0.22 & 98.45\small$\pm$0.18 & 98.96\small$\pm$0.17 & 82.28\small$\pm$1.18 & 72.32\small$\pm$2.20 & 93.20\small$\pm$0.42  \\
LPF & 98.69\small$\pm$0.14 & 92.01\small$\pm$0.23  & 91.94\small$\pm$0.58 & 98.50\small$\pm$0.24 & 98.94\small$\pm$0.39 & 84.40\small$\pm$0.16 & 75.68\small$\pm$0.76 & 93.80\small$\pm$0.32 & \\
APS & 98.60\small$\pm$0.17 & 90.69\small$\pm$0.89 & 89.44\small$\pm$1.00 & 98.31\small$\pm$0.24 & --- & --- & --- & --- \\

WaveletNet & 91.02\small$\pm$1.14 & 90.87\small$\pm$1.02 & 90.02\small$\pm$1.00 & 97.94\small$\pm$0.21 & 65.03\small$\pm$0.71 & 76.06\small$\pm$0.64 & 63.35\small$\pm$3.40 & 87.02\small$\pm$0.29\\

Canonicalize & 98.80\small$\pm$0.24 & 91.93\small$\pm$0.13 & 90.87\small$\pm$0.18 & 98.42\small$\pm$0.15 & 98.26\small$\pm$0.31 & 83.34\small$\pm$0.46 & 73.97\small$\pm$0.67 & 93.68\small$\pm$0.31\\

\midrule
Ours & \textbf{100\small$\pm$0.00} & \textbf{92.10\small$\pm$0.25} & 91.93\small$\pm$0.85 & 98.47\small$\pm$0.15 & \textbf{100\small$\pm$0.00} & 83.15\small$\pm$0.65 & 74.12\small$\pm$1.80 & 93.28\small$\pm$0.31 \\
Ours\small+\small LPF & 100\small$\pm$0.00 & 92.05\small$\pm$0.52 & \textbf{91.96\small$\pm$0.54} & \textbf{98.51\small$\pm$0.10} & 100\small$\pm$0.00 & \textbf{85.20\small$\pm$0.40} & \textbf{77.50\small$\pm$1.21} & \textbf{94.20\small$\pm$0.19} \\
Ours\small+\small APS & 100\small$\pm$0.00 & 91.61\small$\pm$1.11 & 91.10\small$\pm$0.56 & 98.36\small$\pm$0.20 & --- & --- & --- & --- \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

The experimental results from all the time series tasks are given in Tables~\ref{tab:performance_ppg},~\ref{tab:performance_ecg},~\ref{tab:performance_eeg} and~\ref{tab:performance_imu}.
These tables demonstrate that the previous techniques fail to provide shift-invariant models when applied to time series without limiting shifts.
Additionally, the models exhibit extremely low consistency (as low as 32\%) in HR prediction. 
More importantly, applying state-of-the-art methods to enhance shift consistency in deep learning models for predicting the heart rate results in performance degradation.


We believe the main reason for the small improvements in the consistency of previous techniques is that the research to date has tended to focus on limited shifts rather than considering the whole shift space as literature is mostly concerned about images.
While restricting shifts can be a valid assumption in computer vision, where the main reasoning is that the object being classified should not be near the boundary.
This assumption does not apply to time series, where the whole signal carries the information~\citep{demirel2023chaos} additional to local waveform features, and as such, there is no explicit boundary condition or input area to consider for limiting the range of shifts.
% \begin{wraptable}[10]{r}{0.55\textwidth}
% \vspace{-4mm}
% \caption{\label{tab:eeg_main}Performance comparison of ours with other techniques in \textit{EEG} for sleep stage classification}
% \begin{adjustbox}{width=0.55\textwidth}
% \label{tab:appendix_sleep}
% \renewcommand{\arraystretch}{0.9}
% \begin{tabular}{@{}lllllll@{}}
% \toprule
% \multirow{2}{*}{Method} & \multicolumn{4}{l}{Sleep-EDF}   \\ 
% \cmidrule(r{15pt}){2-6}  
% & S-Cons $\uparrow$ & Acc $\uparrow$ &  W-F1 $\uparrow$ & $\kappa$ $\uparrow$ \\
% \midrule
% Baseline & 95.06\small$\pm$0.61 & 75.41\small$\pm$2.01 &  74.87\small$\pm$1.92 & 67.12\small$\pm$2.96  \\
% % Baseline (2$\times$) & 91.09\small$\pm$1.26 & 73.88\small$\pm$2.10 &  74.32\small$\pm$2.86 & 65.14\small$\pm$2.94  \\
% Aug. & 99.00\small$\pm$0.17 & 74.89\small$\pm$1.11 & 74.03\small$\pm$1.46 & 65.89\small$\pm$1.81  \\
% LPF & 92.43\small$\pm$1.24 & 73.56\small$\pm$2.93  & 76.01\small$\pm$1.98 & 65.68\small$\pm$3.46  \\
% APS & --- & --- & --- & ---  \\

% WaveletNet & 84.40\small$\pm$5.90 & 73.54\small$\pm$4.78 & 72.74\small$\pm$3.45 & 64.66\small$\pm$4.12  \\

% Canonicalize & 93.95\small$\pm$0.51 & 77.12\small$\pm$2.21 & 70.14\small$\pm$2.25 & 69.81\small$\pm$2.76  \\

% \midrule
% Ours & \textbf{100\small$\pm$0.00} & \textbf{77.90\small$\pm$1.92}  & \textbf{76.77\small$\pm$2.58} & \textbf{70.01\small$\pm$1.10} \\
% Ours\small+\small LPF & 100\small$\pm$0.00 & 73.12\small$\pm$1.89 & 75.34\small$\pm$1.61 & 64.98\small$\pm$2.27 & \\
% \bottomrule
% \end{tabular}
% \end{adjustbox}
% \end{wraptable}
\begin{table*}[b]
\caption{Performance comparison of our method with other techniques on an \textit{EEG} dataset for sleep stage classification and an \textit{audio} dataset for lung sound classification in respiratory health assessment}
\begin{adjustbox}{width=1\columnwidth,center}
\label{tab:performance_eeg}
\renewcommand{\arraystretch}{0.8}
\begin{tabular}{@{}lllllllllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{4}{l}{Sleep-EDF} & \multicolumn{4}{l}{Respiratory}  \\ 
\cmidrule(r{15pt}){2-5}  \cmidrule(r{15pt}){6-9}  
& S-Cons (\%) $\uparrow$ & Acc $\uparrow$ & W-F1 $\uparrow$ & $\kappa$ $\uparrow$ & S-Cons (\%) $\uparrow$ & Acc $\uparrow$ & F1 $\uparrow$ & W-F1 $\uparrow$  \\
\midrule
Baseline & 95.06\small$\pm$0.61 & 75.41\small$\pm$2.01 & 74.87\small$\pm$1.92 & 67.12\small$\pm$2.96 &  99.10\small$\pm$0.43 & 25.21\small$\pm$5.60 & 57.01\small$\pm$3.62 & 21.21\small$\pm$5.98 \\
Aug. & 99.00\small$\pm$0.17 & 74.89\small$\pm$1.11 & 74.03\small$\pm$1.46 & 65.89\small$\pm$1.81 & 99.68\small$\pm$0.42 & 20.32\small$\pm$5.18 & 45.81\small$\pm$3.51 & 15.31\small$\pm$6.07  \\
LPF & 92.43\small$\pm$1.24 & 73.56\small$\pm$2.93  & 76.01\small$\pm$1.98 & 65.68\small$\pm$3.46 & 99.50\small$\pm$0.42 & 19.47\small$\pm$9.78  & 46.53\small$\pm$3.04 & 11.89\small$\pm$4.98  \\

WaveletNet & 84.40\small$\pm$5.90 & 73.54\small$\pm$4.78 & 72.74\small$\pm$3.45 & 64.66\small$\pm$4.12 & 91.38\small$\pm$2.40 & 28.57\small$\pm$10.81 & 44.23\small$\pm$7.12 & 17.10\small$\pm$7.81 \\

Canonicalize & 93.95\small$\pm$0.51 & 77.12\small$\pm$2.21 & 70.14\small$\pm$2.25 & 69.81\small$\pm$2.76 & 98.28\small$\pm$0.64 & 22.68\small$\pm$10.52 & 45.33\small$\pm$5.75 & 15.30\small$\pm$5.33 \\

\midrule
Ours & \textbf{100\small$\pm$0.00} & \textbf{77.90\small$\pm$1.92}  & \textbf{76.77\small$\pm$2.58} & \textbf{70.01\small$\pm$1.10} & \textbf{100\small$\pm$0.00} & \textbf{33.10\small$\pm$5.12} & \textbf{60.13\small$\pm$4.67} & \textbf{28.33\small$\pm$6.55} \\
Ours\small+\small LPF & 100\small$\pm$0.00 & 73.12\small$\pm$1.89 & 75.34\small$\pm$1.61 & 64.98\small$\pm$2.27 & 100\small$\pm$0.00 & 25.77\small$\pm$2.12 & 51.82\small$\pm$2.10 & 17.99\small$\pm$4.15 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

The empirical results support our motivation for proposing a differentiable bijective function that maps samples with different shifts to the same point on the data manifold, avoiding the limited shift assumption.
Additionally, applying low-pass filtering to prevent aliasing can degrade performance for certain tasks, where the interaction between frequencies plays a critical role~\citep{Science_EEG}.
\begin{table*}[t]
\centering
\caption{Performance comparison of our method with others in \textit{IMU} datasets for Activity and Step}
\begin{adjustbox}{width=1\columnwidth,center}
\label{tab:performance_imu}
\renewcommand{\arraystretch}{0.7}
\begin{tabular}{@{}lllllllllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{l}{UCIHAR} & \multicolumn{3}{l}{HHAR} & \multicolumn{3}{l}{Clemson} \\ 
\cmidrule(r{15pt}){2-4}  \cmidrule(r{15pt}){5-7}  \cmidrule(r{15pt}){8-10} \\ 
& S-Cons (\%) $\uparrow$ & Acc $\uparrow$ & F1 $\uparrow$ & S-Cons (\%) $\uparrow$ & Acc $\uparrow$ & F1 $\uparrow$ 
& S-Cons (\%) $\uparrow$ & MAPE $\downarrow$ & MAE $\downarrow$ \\
\midrule
Baseline & 94.07\small$\pm$1.38 & 85.39\small$\pm$2.30 & 83.20\small$\pm$2.94 & 98.27\small$\pm$0.33 &  91.87\small$\pm$1.36 & 91.16\small$\pm$1.38 & 54.31\small$\pm$4.40 & 4.76\small$\pm$0.11 & 2.74\small$\pm$0.08 \\
Aug. & 96.55\small$\pm$0.80 & 85.42\small$\pm$4.50 & 83.69\small$\pm$6.74 & 98.38\small$\pm$0.28 & 91.97\small$\pm$0.44 &91.31\small$\pm$0.49& 61.01\small$\pm$4.88 & 4.08\small$\pm$0.14 & 2.29\small$\pm$0.07  \\
LPF & 95.05\small$\pm$0.21 & 83.96\small$\pm$3.44 & 81.08\small$\pm$4.21 & 98.10\small$\pm$0.10 & 92.10\small$\pm$0.80 &91.43\small$\pm$0.94& 59.77\small$\pm$4.40 & 4.16\small$\pm$0.16 & 2.35\small$\pm$0.11  \\
APS & 96.40\small$\pm$0.03 & 81.75\small$\pm$4.11 & 79.01\small$\pm$5.33 & 98.30\small$\pm$0.24 & 91.83\small$\pm$1.35 &91.01\small$\pm$1.47 & 45.50\small$\pm$2.69 & 4.74\small$\pm$0.16 & 2.69\small$\pm$0.07 \\

WaveletNet & 94.56\small$\pm$1.31 & 82.78\small$\pm$4.62 & 80.73\small$\pm$5.59 & 96.76\small$\pm$0.15 & 90.72\small$\pm$0.38 & 90.71\small$\pm$0.39 & 59.14\small$\pm$3.10 & 5.20\small$\pm$0.66 & 2.95\small$\pm$0.41 \\


Canonicalize & 97.72\small$\pm$0.37 & 84.10\small$\pm$2.10 & 81.89\small$\pm$2.89 & 98.27\small$\pm$0.07 & 91.56\small$\pm$1.18 & 90.73\small$\pm$1.10 & 55.47\small$\pm$4.87 & 4.54\small$\pm$0.46 & 2.59\small$\pm$0.29 \\

\midrule
Ours & \textbf{100\small$\pm$0.00} & \textbf{87.71\small$\pm$1.98} & \textbf{85.67\small$\pm$2.47} & \textbf{100\small$\pm$0.00} & 91.93\small$\pm$1.14 & 91.12\small$\pm$1.03 & \textbf{100\small$\pm$0.00} & 4.28\small$\pm$0.34 & 2.43\small$\pm$0.21 \\
Ours\small+\small LPF & 100\small$\pm$0.00 & 84.78\small$\pm$2.46 & 82.58\small$\pm$2.62 & 100\small$\pm$0.00 & \textbf{92.51\small$\pm$0.55} &\textbf{91.80\small$\pm$0.62} & 100\small$\pm$0.00 & \textbf{3.75\small$\pm$0.33} & \textbf{2.12\small$\pm$0.18}  \\
Ours\small+\small APS & 100\small$\pm$0.00 & 82.96\small$\pm$1.79 & 81.10\small$\pm$1.73 & 100\small$\pm$0.00 & 91.38\small$\pm$0.32 & 90.64\small$\pm$0.32 & 100\small$\pm$0.00 & 3.87\small$\pm$0.19 & 2.19\small$\pm$0.11  \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}
\paragraph{Time delay as adversary?}
% Another interesting outcome from the results is the significant consistency decrease of models as the number of output classes increases.
An interesting finding from our experiments is the notable decline in model consistency as the number of output classes increases.
This behavior in the models is similar to previous findings on adversarial examples, indicating that the robustness decreases with a higher number of classes~\citep{adversary_output}.
During our experiments, we observed the same phenomenon where the small shifts of the input change the output to another class, particularly when the task complexity increased with a higher number of classes.
For example, in the case of HR estimation (Table~\ref{tab:performance_ppg}), even short shifts (as low as 10--100\,ms) can lead to a change in the prediction by over 80\,bpm, despite no alteration in the periodicity of the signal, which is the main feature for this task.


Normally, it is expected that models learn the periodicities in these signals and infer the heart rate. 
However, our results indicate that the models learn something else or in a different way, because as the signal undergoes a slight shift, the model prediction jumps more than 100\%, even though the periodicity of the waveform remains unchanged with the shift operation.


We believe these drastic output changes arise from the model's sensitivity to (shortcut) features~\citep{geirhos_shortcut_2020, zhang_21}, resulting in a performance decrease when evaluated on samples different from those encountered during training.
Since our proposed transformation function works as an adaptive linear constraint in the data space, it reduces the potential points where samples can exist, thereby enhancing overall performance.


One distinct result from our experiments is that when previous shift-invariancy techniques are applied to the heart rate prediction task, the average error rate of the models increases by 7--10\%.
This performance decrease can be easily observed in the DaLiA (Table~\ref{tab:performance_ppg}) for the adaptive sampling technique.
The performance discrepancy between tasks can be attributed to the dataset and signal characteristics.
Since DaLiA contains impulse random noise with multiple periodicities, the norm-based subsampling can inadvertently emphasize the noisy waveforms instead of the desired pattern during the subsampling of feature maps, leading to a decrease in prediction performance. 
% Overall, results from our experiments imply that the effectiveness of the methods should be evaluated across diverse time series tasks with several datasets to understand and evaluate their true generalization, consistency, and performance.


We conduct detailed ablation experiments to further investigate the impact of various components, with a particular focus on the effect of the proposed mapping function under different modifications, i.e., modified loss for optimization, on the overall model's performance across time series tasks.



% -------------------------------------------------- %

\subsection{Ablation Study}
\label{sec:ablation}
We present a comprehensive investigation of our method and the effect of its components on the performance.
Mainly, we investigate the effect of guiding the proposed transformation with different loss functions and without any guidance.
First, we map all samples to a single manifold $\mathcal{M}^{\phi_0}$, i.e., $\mathcal{T}(\mathbf{x}, \phi)$ is applied with a constant $\phi = 0$ instead of learning the angle for each sample.
We experimented with different values of $\phi \sim (-\pi, \pi]$, but observed no significant change in the performance when the mapped manifold is constant for samples.
Second, we modify the loss for training the guidance network to increase the variance of angles---increasing the possible manifolds where data can be found---without changing the cross-entropy loss from the classification network as in Equation~\ref{eq:ablation_loss}, $(\hat{\mathcal{L}}_G)$.
Finally, we train both networks only with the cross-entropy loss $(\mathcal{L}^{\prime}_G = \mathcal{L}_C)$.
\begin{table}[b]
\centering
\caption{\label{tab:performance_hr_ablation} Ablation experiments for \textit{HR} (left) and \textit{IMU} (right) tasks}
\vspace{-2mm}
 \begin{subtable}[t]{0.47\linewidth}
    \centering
  \begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{@{}lllllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{l}{IEEE SPC22} & \multicolumn{3}{l}{DaLiA$_{PPG}$} \\ 
\cmidrule(r{15pt}){2-4}  \cmidrule(r{15pt}){5-7} \\ 
&  MAE $\downarrow$ & RMSE $\downarrow$ & $\rho$ $\uparrow$ & MAE $\downarrow$ & RMSE $\downarrow$ & $\rho$ $\uparrow$ \\
\midrule
$\mathcal{T}(\mathbf{x}, \phi)$  & 11.15  & 19.18  & 62.07 & 4.77 & 10.13 & 85.35 \\
$\mathcal{L}^{\prime}_G$ & 9.80 & 17.16 & 66.80 & 4.60 & 10.10 & 85.52  \\
$\hat{\mathcal{L}}_G$ & 9.45 & 17.00 & 69.10 & 4.41 & \textbf{9.63} & \textbf{86.35}  \\
Ours  &\textbf{9.45} & \textbf{16.25} & \textbf{70.12} & \textbf{4.39} & 9.75 & 86.06 \\
\midrule
Change  & \textcolor{Green}{+1.70} & \textcolor{Green}{+2.97} & \textcolor{Green}{+8.05} & \textcolor{Green}{+0.38} & \textcolor{Green}{+0.38} & \textcolor{Green}{+0.71} \\
\bottomrule
\end{tabular}
\end{adjustbox}
    \end{subtable}%
    \quad \quad
 \begin{subtable}[b]{0.47\linewidth}
        \begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{@{}lllllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{2}{l}{UCIHAR} & \multicolumn{2}{l}{HHAR} & \multicolumn{2}{l}{Clemson} \\ 
\cmidrule(r{15pt}){2-3} \cmidrule(r{15pt}){4-5}  \cmidrule(r{15pt}){6-7} \\ 
&  Acc $\uparrow$ & F1 $\uparrow$ & Acc $\uparrow$ & F1 $\uparrow$ & MAPE $\downarrow$ & MAE $\downarrow$ \\
\midrule
$\mathcal{T}(\mathbf{x}, \phi)$ & 84.67 & 82.65 & \textbf{92.33} & \textbf{91.56} & 4.64  & 2.67 \\
$\mathcal{L}^{\prime}_G$ & 84.30 & 82.49 & 91.98 & 91.18  & 4.42 & 2.52 \\
$\hat{\mathcal{L}}_G$ & 84.82 & 81.99 & 91.51 & 90.83  & 4.31 & 2.45 \\
Ours  &\textbf{85.81} & \textbf{83.81} & 91.83 & 91.12 & \textbf{4.28} & \textbf{2.43} \\
\midrule
Change (\%)  & \textcolor{Green}{+1.14} & \textcolor{Green}{+1.16} & \textcolor{WildStrawberry}{-0.50} & \textcolor{WildStrawberry}{-0.44} & \textcolor{Green}{+0.36} & \textcolor{Green}{+0.24}  \\
\bottomrule
\end{tabular}
        \end{adjustbox}
    \end{subtable}
\end{table}
We compared these three variants of the learning techniques with the original proposed implementation as each represents distinct approaches for manipulating the data space.
For example, when all samples are mapped to a single manifold, the variations in samples decrease significantly since there is only one possible phase angle for the chosen harmonic with period $\mathrm{T}_0$.
Additionally, the relationships among all sinusoidal components remain invariant, given that the proposed transformation is a linear function of the frequency.
Conversely, optimizing the guidance network to increase the variance of angles, thereby favoring a greater sample diversity, expands the possible variations for samples.
\begin{equation}\label{eq:ablation_loss}
    \hat{\mathcal{L}}_G = \mathcal{L}_C - \sqrt{\text{Var}_{\mathbf{x} \sim \mathcal{B}} \left( f_{\theta_G}\left(|\mathcal{F}(\mathbf{x})|\right) \right)}
\end{equation}
Tables~\ref{tab:performance_hr_ablation} and~\ref{tab:performance_sleep_ablation} summarize the results where we exclude the consistency metric from the tables as the models that include the proposed transformation are always completely shift-invariant.
The first row ($\mathcal{T}(\mathbf{x}, \phi)$) in the tables shows the performance when all the samples are mapped to a single manifold i.e., without a guidance network for learning the mapping.
The second row ($\mathcal{L}^{\prime}_G$) represents the performance when the guidance network is only optimized using the categorical cross-entropy loss.
The third row ($\hat{\mathcal{L}}_G $) presents the performance when the variance of angles is optimized to increase during training.
And, the last row (Ours) is the original implementation of the proposed method.
% \begin{wraptable}[9]{R}{7cm}
% \vspace{-4mm}
% \centering
% \caption{Ablation experiments for \textit{CVD} task}
% \begin{adjustbox}{width=0.5\columnwidth,center}
% \label{tab:performance_ecg_ablation}
% \renewcommand{\arraystretch}{0.7}
% \begin{tabular}{@{}lllllll@{}}
% \toprule
% \multirow{2}{*}{Method} & \multicolumn{3}{l}{Chapman} & \multicolumn{3}{l}{PhysioNet} \\ 
% \cmidrule(r{15pt}){2-4}  \cmidrule(r{15pt}){5-7} \\ 
% &  Acc $\uparrow$ & F1 $\uparrow$ & AUC $\uparrow$ & Acc $\uparrow$ & F1 $\uparrow$ & AUC $\uparrow$ \\
% \midrule
% $\mathcal{T}(\mathbf{x}, \phi)$  & 91.82  & 90.76 & 98.36 & 83.12 & 73.67  & 93.24 \\
% $\mathcal{L}^{\prime}_G$ & 91.27 & 90.10 & 98.38 & 82.81 & 73.75 & 93.45 \\
% $\hat{\mathcal{L}}_G$ & 91.88 & 90.84 & 98.44 & \textbf{83.30}  & 73.90 & \textbf{93.51} \\
% Ours  &\textbf{92.10} & \textbf{91.93} & \textbf{98.40} & 83.15 & \textbf{74.12} & 93.30 \\
% \midrule
% Change (\%)  & \textcolor{Green}{+0.28} & \textcolor{Green}{+1.17} & \textcolor{Green}{+0.04} & \textcolor{Green}{+0.03} & \textcolor{Green}{+0.45} & \textcolor{Green}{+0.06} \\
% \bottomrule
% \end{tabular}
% \end{adjustbox}
% \end{wraptable}
We also report the change when the mapping function is guided using the network $f_{G_{\theta}}$ and optimized using the loss defined in Equation~\ref{eq:lossess}, as opposed to being a fixed, non-learnable function.
\begin{table}[t]
\vspace{-3mm}
\centering
\caption{\label{tab:performance_sleep_ablation} Ablation experiments for \textit{EEG} (left) and \textit{ECG} (right) tasks}
\renewcommand{\arraystretch}{0.9}
 \begin{subtable}[b]{0.47\linewidth}
    \centering
  \begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{@{}lllllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{l}{Sleep-EDF}   \\ 
\cmidrule(r{15pt}){2-5}  
& Acc $\uparrow$ & F1 $\uparrow$ & W-F1 $\uparrow$ & $\kappa$ $\uparrow$ \\
\midrule
$\mathcal{T}(\mathbf{x}, \phi)$ & 75.54\small$\pm$2.39 & 66.96\small$\pm$1.78 & 75.53\small$\pm$2.29 & 67.08\small$\pm$0.03  \\
$\mathcal{L}^{\prime}_G$ & 77.21\small$\pm$1.51 & 67.67\small$\pm$1.67 & 76.89\small$\pm$1.71 & 69.39\small$\pm$0.02  \\
$\hat{\mathcal{L}}_G$ & 77.75\small$\pm$1.23 & \textbf{68.04}\small$\pm$1.16 & \textbf{77.01}\small$\pm$1.07 & 69.94\small$\pm$0.01  \\
Ours & \textbf{77.80}\small$\pm$1.95 & 67.01\small$\pm$2.65 & 76.77\small$\pm$2.58 & \textbf{70.01\small$\pm$1.10} \\
\midrule
Change &  \textcolor{Green}{+2.26}  &  \textcolor{Green}{+0.05}  & \textcolor{Green}{+1.24}  & \textcolor{Green}{+2.93}  \\
\bottomrule
\end{tabular}
\end{adjustbox}
    \end{subtable}%
    \quad \quad
 \begin{subtable}[b]{0.47\linewidth}
        \begin{adjustbox}{width=\columnwidth,center}
\label{tab:performance_ecg_ablation}
\renewcommand{\arraystretch}{0.7}
\begin{tabular}{@{}lllllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{l}{Chapman} & \multicolumn{3}{l}{PhysioNet} \\ 
\cmidrule(r{15pt}){2-4}  \cmidrule(r{15pt}){5-7} \\ 
&  Acc $\uparrow$ & F1 $\uparrow$ & AUC $\uparrow$ & Acc $\uparrow$ & F1 $\uparrow$ & AUC $\uparrow$ \\
\midrule
$\mathcal{T}(\mathbf{x}, \phi)$  & 91.82  & 90.76 & 98.36 & 83.12 & 73.67  & 93.24 \\
$\mathcal{L}^{\prime}_G$ & 91.27 & 90.10 & 98.38 & 82.81 & 73.75 & 93.45 \\
$\hat{\mathcal{L}}_G$ & 91.88 & 90.84 & 98.44 & \textbf{83.30}  & 73.90 & \textbf{93.51} \\
Ours  &\textbf{92.10} & \textbf{91.93} & \textbf{98.40} & 83.15 & \textbf{74.12} & 93.30 \\
\midrule
Change (\%)  & \textcolor{Green}{+0.28} & \textcolor{Green}{+1.17} & \textcolor{Green}{+0.04} & \textcolor{Green}{+0.03} & \textcolor{Green}{+0.45} & \textcolor{Green}{+0.06} \\
\bottomrule
\end{tabular}
        \end{adjustbox}
    \end{subtable}
\end{table}



As can be seen from the tables, when the models are trained by guiding the transformation function (with $f_{G_{\theta}}$), the performance of the models increases significantly up to 8\%, except for the HHAR dataset with a marginal performance decrease of 0.5\%.
Importantly, adding the guidance network does not bring any additional parameters that help the learning, meaning that the model achieves improved generalization with the same capacity.
Furthermore, the additional model parameters introduced to the overall framework approximately amount to one percent of those in the classifier.
\begin{wraptable}{r}{0.45\textwidth}
\caption{Ablation experiments for \textit{Audio}}
\begin{adjustbox}{width=0.45\columnwidth,center}
\centering
\begin{tabular}{@{}llllll@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{l}{Respiratory}   \\ 
\cmidrule(r{15pt}){2-4}  
& Acc $\uparrow$ & F1 $\uparrow$ & W-F1 $\uparrow$  \\
\midrule
$\mathcal{T}(\mathbf{x}, \phi)$ & 21.28\small$\pm$7.43 & 55.03\small$\pm$2.89 & 18.14\small$\pm$6.39   \\
$\mathcal{L}^{\prime}_G$ & 27.17\small$\pm$6.71 & 55.58\small$\pm$9.18 & 21.46\small$\pm$4.07  \\
$\hat{\mathcal{L}}_G$ & 28.57\small$\pm$8.31 & 54.28\small$\pm$6.56 & 23.73\small$\pm$4.65   \\
Ours & \textbf{33.10\small$\pm$5.12} & \textbf{60.13\small$\pm$4.67} & \textbf{28.33\small$\pm$6.55}  \\
\midrule
Change &  \textcolor{Green}{+11.82}  &  \textcolor{Green}{+5.10}  & \textcolor{Green}{+10.19}  \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{wraptable}
While the performance increase can be associated with the decreased possible variations in the signals, our ablation experiments show that decreasing the variations blindly using the transformation with the same angle, decreases performance. 
Therefore, it is important to guide the transformation function for reducing the dimensionality, i.e., the space and time variations of a signal, of the whole data space. 
Overall, the results obtained from the ablation study and main experiments support the previous propositions and our motivation for introducing a novel diffeomorphism for preventing the inconsistency of deep learning models to the time shifts while increasing the generalization capability.


Additional results (i.e., the extended experiments and ablations) regarding the performance of the proposed method can be found in Appendix~\ref{appendix:Additional_Results}.
Investigations regarding the performance improvements of the proposed diffeomorphism with different model networks are given in Appendix~\ref{appendix:other_networks}.
Detailed analysis of the guidance network with its effect is given in Appendix~\ref{appendix:visual_examples}.
We provide an extended discussion of related work in Appendix~\ref{appendix:extensive_related_work} and outline limitations and future directions in Appendix~\ref{appendix:limitations}.

% We extended the related work section in Appendix~\ref{appendix:extensive_related_work}.
% We discussed the limitations and future work in Appendix~\ref{appendix:limitations}.



