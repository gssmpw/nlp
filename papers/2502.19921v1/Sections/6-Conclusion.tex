\section {Conclusion}
\label{sec:Conclusion}
The inadequacy of shift-invariance in deep learning models, particularly in the context of temporal data, remains a significant challenge.
Existing solutions designed for images not only prove ineffective for time series but also result in performance deterioration for some tasks.
To address this, we have introduced a novel differentiable bijective function.
Our approach builds on the insight from Proposition~\ref{prop:shift_change}, which states that the shift operation forms an Abelian group for each harmonic of a sample.
Leveraging this property, we uniquely represent each point in the shift space using the phase angle of a harmonic whose period is at least as long as the sample length.
Our approach ensures that samples, under various shifts, are mapped to a unique point in the data manifold without reducing dimensions, preserving task-related information without any loss.
We validated our method theoretically and empirically, showing that it establishes shift-invariance in deep learning models without constraints on the shift range. 
In extensive experiments across six tasks, our approach consistently outperforms state-of-the-art methods, demonstrating its effectiveness in achieving complete shift-invariance without limitations on the model topology.


% In this paper, we proposed a set of regularizers for detecting desired periodic patterns in time series without requiring any label information.
% Theoretically, we proved that an optimized learner trained with the proposed loss will detect the periodic pattern in the sequence while preventing degenerate solutions.
% In contrast to previous methods that rely on optimistic assumptions on batch statistics to prevent the collapse of unsupervised models, we presented a novel approach that guarantees representations to preserve information from the original samples, thus relaxing assumptions on the batch.
% Empirically, we show that our method outperforms the prior works, achieving significant performance gains of up to 40-45\%, in three real-world tasks that involve diverse noisy conditions.
% % By conducting experiments on contrastive and supervised learning settings, we show that our approach is agnostic to the choice of learning paradigm. 
% % Thus, it holds the potential for utilization in generating augmented data for different learning paradigms as well.
% We believe that the methods introduced in this work have the potential to significantly improve learning solutions for a wide variety of time series tasks.


% \section*{Broader Impact}
% This paper introduces a novel method to address the lack of shift-invariance in deep learning models, particularly focusing on time series data where existing techniques designed for images fall short.
% Unlike previous methods, our solution guarantees shift-invariance without limiting the shift, thus enhancing performance across multiple tasks without modifying the model's topology.
% By bridging this gap in shift variance, our work opens avenues for more robust and reliable deep learning applications in diverse domains, including health monitoring and behavior analysis of humans.