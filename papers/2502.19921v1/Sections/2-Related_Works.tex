\section{Related Work}
\label{sec:related_work}
\paragraph{Shift-invariant networks}
Modern deep learning architectures use strided convolution or pooling to decrease the variance to a certain extent~\citep{fukushima_neocognitron}. 
However, Azulay and Weiss have demonstrated that a shift of one pixel in an image can lead to a significant alteration in the output probability of a trained classifier~\citep{Azulay2018WhyDD}. 
Previous works showed that the downsampling caused aliasing and used low-pass filtering before the downsampling to prevent information loss~\citep{zhang2019shiftinvar, NIPS2014_81ca0262}.
However, the used filters have suboptimal frequency responses, and realizing the ideal filter in practice is unfeasible. 
This leads to persistent aliasing, becoming a more significant concern for time series where high-frequency components are crucial for classification.

Adaptive subsampling methods have been recently explored for shift-invariancy~\citep{aps, group_grid}.
Mainly, these methods perform subsampling on a constant~\citep{aps} or input dependent~\citep{learnable_polyphase} grid. 
This approach has a notable limitation in time series, particularly when nonlinear activation functions are involved.
The methods tend to overlook variations in boundaries arising from the translation of samples, thereby imposing additional constraints on invariance~\citep{learnable_polyphase}.
Consequently, the evaluation of these methods is restricted to a narrow range of shifts, covering only a limited subset of the shift space. 
Moreover, their reliance on a grid scheme for sampling introduces a sensitivity to sampling rates, leading to performance gaps across the entire shift space~\citep{Fractional_CVPR}.
Therefore, we \textit{shift the paradigm} and present a bijective transformation to modify the data space.
Moreover, unlike existing methods that change network topology by modifying the pooling or adding extra filters without achieving complete shift-invariancy, our method guarantees invariance in neural network models without imposing any restrictions on the model topology or shift range.




\paragraph{Time-delay neural networks}
Efforts to design shift-invariant models for time series predate modern deep learning methods~\citep{shift_invariant_old, TDNN}.
For example, a time-delay neural network (TDNN) network is designed to have the ability to represent relationships between events in time frames where the learned features by the network are aimed to be invariant under translation in time~\citep{TDNN}.
TDNN is trained with all time-shifted copies of samples and weights are updated by the average of all corresponding time-delayed error values.
This is similar to the supervised training of a network with randomly shifted versions of samples.
Although this strategy achieved shift-invariance for the first type of networks, as they do not include a pooling layer, it was shown that this approach is ineffective for modern architectures where pooling and derivatives are used~\citep{pooling_effect}, and the network's invariance is limited to patterns seen during training and fails generalization~\citep{Azulay2018WhyDD}. 
In this work, as we learn the mapping for each sample, the proposed transformation ensures that all shifted variants of a sample are mapped to a single point.
Hence, a single data point effectively represents all the augmented variants.


% \paragraph{Diffeomorphisms in Deep Learning}
% The Spatial Transformer Net (STN) was introduced to learn transformation functions for invariant image classification~\citep{Spatial_transformer_nets}.
% Temporal Transformer Networks (TTN), an adaptation of STNs for time series applications, were introduced to predict the parameter of warp functions and align time series~\citep{Lohit2019TemporalTN, ICML_diffemor}.
% Recent methods have focused on optimizing a known family of diffeomorphism, known as diffeomorphic warping functions~\citep{closed_form_diffeomorphic} for time series alignment, through deep learning~\citep{Deep_Diffeomorphic, Diffeomorphic_TAN}.
% Thus, a significant distinction between our approach and previous techniques lies in the fact that we introduce a novel tailored diffeomorphism that is capable of mapping samples subjected to shifts to the same point in the high-dimensional data manifold, to ensure shift-invariancy.
% Subsequently, we optimize the presented transformation together with deep learning models. 

% However, as previous works used feature maps for guiding or learning the transformation functions~\citep{}, these methods failed to provide shift-invariancy.


% Skafte et al. [49] showed it is possible to explicitly incorporate flexible and efficient
% diffeomorphisms [19, 20] within DL architectures via an STN; particularly, they focused on image
% recognition and classification and their framework was supervised. 