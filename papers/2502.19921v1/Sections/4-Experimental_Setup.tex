\section{Experiments}
\label{sec:Exp_setup}	
% We evaluate our proposed method against and together with previous techniques designed for shift-invariant neural networks, including both applying a low-pass filter before downsampling to prevent aliasing and subsampling from a grid using the max norms of the feature maps.
% Complete training details and hyper-parameter settings for datasets and baselines are provided in Appendix~\ref{appendix:implementation_details}.

% -------------------------------------------------- %
\subsection{Datasets}
\label{ref:datasets}
We conducted experiments on nine datasets across six tasks, including heart rate (HR) estimation from photoplethysmography (PPG), step counting and activity recognition using inertial measurements (IMUs), cardiovascular disease classification from electrocardiogram (ECG), sleep stage classification from electroencephalography (EEG) and lung sound classification from audio.
We provide short descriptions of each dataset below, and further details can be found in Appendix~\ref{appen:experiments}.

\paragraph{\textit{Heart rate}}
We used the IEEE Signal Processing Cup in 2015 (IEEE SPC)~\citep{TROIKA}, and DaLia~\citep{DeepPPG} for PPG-based heart rate prediction.
We used the leave-one-session-out (LOSO) cross-validation, which evaluates models on subjects/sessions that were not used for training. 

\paragraph{\textit{Activity recognition}}
We used UCIHAR~\citep{UCIHAR}, and HHAR~\citep{hhar} for activity recognition from inertial measurement units from smartphones.
We evaluate the cross-person generalization performance of the models, i.e., the model is evaluated on previously unseen subjects. 

\paragraph{\textit{Cardiovascular disease (CVD) classification}}
We used Chapman University, Shaoxing People’s Hospital ECG~\citep{chapman} and PhysioNet 2017~\citep{Physio_AF, Physio} datasets.
We selected the same four leads for the Chapman as in~\citep{Physio_2021}.
We split the datasets into training, validation, and test sets according to the patient ID (each patient's recordings appear in only one set) using a 60, 20, 20 ratio as in~\citet{demirel2023chaos, chapman}.

\paragraph{Step counting}
We used the Clemson dataset~\citep{clemson}, which released for pedometer evaluation. 
We conducted experiments using wrist IMUs where labels are available through videos.

\paragraph{\textit{Sleep stage classification}}
We used the Sleep-EDF dataset, from PhysioBank~\citep{Physio}, which includes whole-night PSG sleep recordings, where we used a single EEG channel (i.e., Fpz-Cz) with a sampling rate of 100\,Hz, following the same setup as in~\citet{tstcc}.

\paragraph{\textit{Lung sound classification}}
We used the Respiratory@TR, which contains lung sounds recorded with two digital stethoscopes~\citep{Altan2017MultimediaRD}.
Two pulmonologists validated and labeled the recordings based on X-rays, pulmonary function tests (PFTs), and auscultation.
The labels correspond to five COPD severity levels (COPD0–COPD4) as described in prior work~\citep{zhang2024towards}.

\subsection{Baselines}
\label{ref:baseline}
We compared our method and existing approaches including low-pass filtering (LPF)~\citep{zhang2019shiftinvar}, and adaptive subsampling grids (APS)~\citep{aps}.
In addition to shift-invariance techniques, we evaluated our method against shift-equivariant Wavelet Networks~\citep{Wavelet_Networks} and canonical representation learning techniques for equivariance~\citep{canonical,mondal2023equivariant}.
Moreover, since our method can be integrated with any existing approaches, we investigate the performance of previous techniques for shift-invariancy when combined with our algorithm.


\subsection{Implementation}
\label{ref:implementation}
We follow a similar implementation setup as previous work on shift-invariancy~\citep{zhang2019shiftinvar} in supervised learning, making architectural adjustments for time series.
Specifically, we employed ResNet~\citep{ResNet} with eight blocks designed for time series~\citep{resnet1d}, excluding signals from inertial measurement units with a single dimension. 
For the latter, we observed a better performance with fully connected networks (FCN).
Therefore, we used a three-layer FCN for the single dimensional IMU-based task, i.e., step counting. 
Similarly, for guiding the transformation function, we used an FCN with a single output, which is the angle for the chosen sinusoidal. 
% The downsampling operations, including pooling and strided convolutions, for architectures are set to two.
% We set the length of the Fourier transform to the signal length for each dataset as the Fourier transformation of the same length already covers sinusoidal with periods equal to or longer than the signal length.
For each dataset, we set the Fourier transform length equal to the signal length, as the Fourier transformation of the same size inherently includes sinusoids with periods equal to or longer than the signal length.
% As our experiments cover a wide range of time series with different lengths, we aimed for consistency for operations, in particular, the number of residual blocks or pooling layers to ensure comparability across diverse scenarios.
We use categorical cross-entropy loss, which is optimized using Adam~\citep{Adam}.
The learning rate is determined through grid search for each dataset and set to the same value for all baselines given in the Appendix.
During training, it was halved when the validation loss stops improving for 15 consecutive epochs.
The training is terminated when 90 successive epochs show no validation performance improvements. 
The best model is chosen as the lowest loss on the validation set.
Detailed hyperparameters and architecture specifications can be found in the Appendix~\ref{appendix:Implementation_Details}.

%%%%%% Mention batch size 


\subsection{Evaluation}
\label{ref:Evaluation}
We evaluate the performance of the models using the common evaluation metrics, i.e., accuracy,  F1, for each task. 
For shift-invariancy, we used the shift consistency (S-Cons.) metric which measures how often the network outputs the same classification, given the same time series with two different shifts, similar to~\citep{zhang2019shiftinvar} as in Equation~\ref{eq:eval_shift}.
We applied shifts across the entire space in contrast to previous approaches where the range of shift is heavily limited~\citep{learnable_polyphase}.

\begin{equation}\label{eq:eval_shift}
    \mathbb{E}_{X, t_1, t_2} \mathbbm{1} \left[ \hat{f}_{C}(\mathrm{x}(t-t_1)) = \hat{f}_{C}(\mathrm{x}(t-t_2)) \right],
\end{equation}

where $\hat{f}_{C}$ represents the classifier's output following the arg max operation.
$t_{1,2}$ are uniformly sampled integers from the interval $[1, t]$, with $t$ denoting the length of the sample.
%%%%%%%%%%%%%%%%%%%%% ALL appendix %%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{equation}\label{eq:MAE}
%     \text{MAE} = \frac{1}{W} \sum_{w=1}^{W} |\text{HR}_{est}(w) - \text{HR}_{ref}(w)| ,
% \end{equation}

% where W is the total number of segments, and $\text{HR}_{est}(w)$ and $\text{HR}_{ref}(w)$ denote the estimated and reference heart rate value in beats-per-minute on the $w^{th}$ segment, respectively. 
% This performance metric is widely used in PPG-based HR estimation~\citep{DeepPPG, sch_original}. 
% The $\text{HR}_{est}(w)$ is obtained using our model and the $\text{HR}_{ref}(w)$ values are directly used from datasets that share HR values corresponding to segments~\citep{DeepPPG, TROIKA}. 
% For the datasets that HR values are not available for the segmented PPG signals~\citep{WESAD}, we extracted HR information from ECG signals using Pan-Tompkins algorithm~\citep{Pan_Tompkins}.
