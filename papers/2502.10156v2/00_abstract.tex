We propose a novel model for the prediction of robot trajectories on rough offroad terrain from the onboard camera images.
This model enforces the laws of classical mechanics through a physics-aware neural symbolic layer while preserving the ability
to learn from large-scale data as it is end-to-end differentiable.
The proposed hybrid model integrates a black-box component that predicts robot-terrain interaction forces with a neural-symbolic layer.
This layer includes a differentiable physics engine that computes the robotâ€™s trajectory by querying these forces at
the points of contact with the terrain.
As the proposed architecture comprises substantial geometrical and physics priors,
the resulting model can also be seen as a learnable physics engine conditioned on real images that
delivers $10^4$ trajectories per second.
We argue and empirically demonstrate that this architecture reduces the sim-to-real gap and mitigates out-of-distribution sensitivity.
The differentiability, in conjunction with the rapid simulation speed, makes the model well-suited for various applications
including model predictive control, trajectory shooting, supervised and reinforcement learning, or SLAM.
%The codes and data will be made publicly available.
The codes and data are publicly available\footnote{\url{https://github.com/ctu-vras/monoforce}}.

% for learning to navigate autonomously in unstructured outdoor environments with rough terrain.
% Towards this goal, we design a physics-informed end-to-end differentiable model that takes as input
% RGB data and control commands and produces interpretable intermediate representations
% in the form of terrain properties (including but not limited to its shape, friction, and stiffness),
% as well as interaction forces between the robot and the terrain for each possible position that the robot can take
% within the prediction horizon.
% Thanks to an efficient implementation of the MonoForce model and GPU parallelization of the predicted trajectories,
% we demonstrate the effectiveness of the approach in outdoor navigation scenarios.
%Our experiments additionally show that our physics-informed approach outperforms pure data-driven methods
%in terms of the accuracy of the predicted trajectories.



% In this paper, we propose MonoForce, a robot-terrain interaction predictor,
% for learning to navigate autonomously in unstructured outdoor environments with rough terrain.
% Towards this goal, we design a physics-informed end-to-end differentiable model that takes as input
% RGB data and control commands and produces interpretable intermediate representations
% in the form of terrain properties (including but not limited to its shape, friction, and stiffness),
% as well as interaction forces between the robot and the terrain for each possible position that the robot can take
% within the prediction horizon.
% Thanks to an efficient implementation of the MonoForce model and GPU parallelization of the predicted trajectories,
% we demonstrate the effectiveness of the approach in outdoor navigation scenarios.
% Our experiments additionally show that our physics-informed approach outperforms pure data-driven methods
% in terms of the accuracy of the predicted trajectories.
% The codes and data are publicly available\footnote{\url{https://github.com/ctu-vras/monoforce}}.
