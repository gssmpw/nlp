@inproceedings{azuma2023defense,
  title={Defense-Prefix for Preventing Typographic Attacks on CLIP},
  author={Azuma, Hiroki and Matsui, Yusuke},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision, Workshop on Adversarial Robustness in the Real World},
  pages={3644--3653},
  year={2023}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2021},
}
%pages={8748--8763}

@inproceedings{dai2023instructblip,
title={Instruct{BLIP}: Towards General-purpose Vision-Language Models with Instruction Tuning},
author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi},
booktitle={Advances in Neural Information Processing Systems},
volume = {36},
year={2023},
pages = {49250–49267}
}

@inproceedings{figstep,
    author = {Gong, Yichen and Ran, Delong and Liu, Jinyuan and Wang, Conglei and Cong, Tianshuo and Wang, Anyu and Duan, Sisi and Wang, Xiaoyun},
    title = {{FigStep}: Jailbreaking large vision-language models via typographic visual prompts},
    booktitle = {Proceedings of the Association for the Advancement of Artificial Intelligence},
    year = {2025}
}

@inproceedings{jailbreakinpieces,
  title={Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models},
  author={Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2023}
}

@inproceedings{llava,
    author = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae}, 
    title = {Visual instruction tuning},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2024},
    volume = {36},
    pages = {34892–34916}
}

@article{multi_neurons,
  author = {Goh, Gabriel and †, Nick Cammarata and †, Chelsea Voss and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Radford, Alec and Olah, Chris},
  title = {Multimodal Neurons in Artificial Neural Networks},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2021/multimodal-neurons},
  doi = {10.23915/distill.00030}
}

@article{noever2021reading,
  title={Reading Isn't Believing: Adversarial Attacks On Multi-Modal Neurons},
  author={Noever, David A and Noever, Samantha E Miller},
  journal={arXiv preprint arXiv:2103.10480},
  year={2021}
}

@inproceedings{safetybench,
    author = {Liu, Xin and Zhu, Yichen and Lan, Yunshi and Yang, Chao and Qiao, Yu},
    title = {MM-SafetyBench: A Benchmark for Safety
     Evaluation of Multimodal Large Language Models},
    booktitle = {Proceedings of the European Conference on Computer Vision},
    year = {2024}
}

@inproceedings{self_typo,
  title={Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks},
  author={Qraitem, Maan and Tasnim, Nazia and Saenko, Kate and Plummer, Bryan A},
  booktitle={Advances in Neural Information Processing Systems, Workshop on Multimodal Algorithmic Reasoning},
  year={2024}
}

@inproceedings{typo_mllms,
    author = {Cheng, Hao and Xiao, Erjia and Xu, Renjing},
    title = {Unveiling Typographic Deceptions: Insights of the Typographic Vulnerability in Large Vision-Language Models},
    booktitle = {Proceedings of the European Conference on Computer Vision} ,
    year = {2024}
}

