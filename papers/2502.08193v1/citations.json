[
  {
    "index": 0,
    "papers": [
      {
        "key": "clip",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "multi_neurons",
        "author": "Goh, Gabriel and \u2020, Nick Cammarata and \u2020, Chelsea Voss and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Radford, Alec and Olah, Chris",
        "title": "Multimodal Neurons in Artificial Neural Networks"
      },
      {
        "key": "azuma2023defense",
        "author": "Azuma, Hiroki and Matsui, Yusuke",
        "title": "Defense-Prefix for Preventing Typographic Attacks on CLIP"
      },
      {
        "key": "noever2021reading",
        "author": "Noever, David A and Noever, Samantha E Miller",
        "title": "Reading Isn't Believing: Adversarial Attacks On Multi-Modal Neurons"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "multi_neurons",
        "author": "Goh, Gabriel and \u2020, Nick Cammarata and \u2020, Chelsea Voss and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Radford, Alec and Olah, Chris",
        "title": "Multimodal Neurons in Artificial Neural Networks"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "dai2023instructblip",
        "author": "Wenliang Dai and Junnan Li and Dongxu Li and Anthony Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi",
        "title": "Instruct{BLIP}: Towards General-purpose Vision-Language Models with Instruction Tuning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "llava",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "self_typo",
        "author": "Qraitem, Maan and Tasnim, Nazia and Saenko, Kate and Plummer, Bryan A",
        "title": "Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks"
      },
      {
        "key": "typo_mllms",
        "author": "Cheng, Hao and Xiao, Erjia and Xu, Renjing",
        "title": "Unveiling Typographic Deceptions: Insights of the Typographic Vulnerability in Large Vision-Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "typo_mllms",
        "author": "Cheng, Hao and Xiao, Erjia and Xu, Renjing",
        "title": "Unveiling Typographic Deceptions: Insights of the Typographic Vulnerability in Large Vision-Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "self_typo",
        "author": "Qraitem, Maan and Tasnim, Nazia and Saenko, Kate and Plummer, Bryan A",
        "title": "Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "self_typo",
        "author": "Qraitem, Maan and Tasnim, Nazia and Saenko, Kate and Plummer, Bryan A",
        "title": "Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "figstep",
        "author": "Gong, Yichen and Ran, Delong and Liu, Jinyuan and Wang, Conglei and Cong, Tianshuo and Wang, Anyu and Duan, Sisi and Wang, Xiaoyun",
        "title": "{FigStep}: Jailbreaking large vision-language models via typographic visual prompts"
      },
      {
        "key": "jailbreakinpieces",
        "author": "Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael",
        "title": "Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models"
      },
      {
        "key": "safetybench",
        "author": "Liu, Xin and Zhu, Yichen and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "MM-SafetyBench: A Benchmark for Safety\nEvaluation of Multimodal Large Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "figstep",
        "author": "Gong, Yichen and Ran, Delong and Liu, Jinyuan and Wang, Conglei and Cong, Tianshuo and Wang, Anyu and Duan, Sisi and Wang, Xiaoyun",
        "title": "{FigStep}: Jailbreaking large vision-language models via typographic visual prompts"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "jailbreakinpieces",
        "author": "Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael",
        "title": "Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "safetybench",
        "author": "Liu, Xin and Zhu, Yichen and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "MM-SafetyBench: A Benchmark for Safety\nEvaluation of Multimodal Large Language Models"
      }
    ]
  }
]