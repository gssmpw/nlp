@article{federatedscopellm,
  title={FederatedScope-LLM: A comprehensive package for fine-tuning large language models in federated learning},
  author={Kuang, Weirui and Qian, Bingchen and Li, Zitao and Chen, Daoyuan and Gao, Dawei and Pan, Xuchen and Xie, Yuexiang and Li, Yaliang and Ding, Bolin and Zhou, Jingren},
  journal={arXiv preprint arXiv:2309.00363},
  year={2023}
}

@inproceedings{fedopt,
  title={Adaptive Federated Optimization},
  author={Reddi, Sashank J and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, Hugh Brendan},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}

@article{fedavgm,
  title={Measuring the effects of non-identical data distribution for federated visual classification},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal={arXiv preprint arXiv:1909.06335},
  year={2019}
}

@inproceedings{li2019convergence,
  title={On the Convergence of FedAvg on Non-IID Data},
  author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{fedfm,
  title={Fedfm: Anchor-based feature matching for data heterogeneity in federated learning},
  author={Ye, Rui and Ni, Zhenyang and Xu, Chenxin and Wang, Jianyu and Chen, Siheng and Eldar, Yonina C},
  journal={IEEE Transactions on Signal Processing},
  year={2023},
  publisher={IEEE}
}

@article{li2023revisiting,
  title={Revisiting weighted aggregation in federated learning with neural networks},
  author={Li, Zexi and Lin, Tao and Shang, Xinyi and Wu, Chao},
  journal={arXiv preprint arXiv:2302.10911},
  year={2023}
}

@article{karimireddy2021breaking,
  title={Breaking the centralized barrier for cross-device federated learning},
  author={Karimireddy, Sai Praneeth and Jaggi, Martin and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian U and Suresh, Ananda Theertha},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={28663--28676},
  year={2021}
}

@inproceedings{dropout,
  title={Dordis: Efficient Federated Learning with Dropout-Resilient Differential Privacy},
  author={Jiang, Zhifeng and Wang, Wei and Chen, Ruichuan},
  booktitle={Proceedings of the Nineteenth European Conference on Computer Systems},
  pages={472--488},
  year={2024}
}

@article{mobilesurvey,
	doi = {10.20944/preprints202501.0413.v1},
	url = {https://doi.org/10.20944/preprints202501.0413.v1},
	year = 2025,
	month = {January},
	publisher = {Preprints},
	author = {William Liu and Liang Liu and Yaxuan Guo and Han Xiao and Weifeng Lin and Yuxiang Chai and Shuai Ren and Xiaoyu Liang and Linghao Li and Wenhao Wang and Tianze Wu and Yong Liu and Hao Wang and Hongsheng Li and Guanjing Xiong},
	title = {LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects},
	journal = {Preprints}
}

@misc{lu2024omniparserpurevisionbased,
      title={OmniParser for Pure Vision Based GUI Agent}, 
      author={Yadong Lu and Jianwei Yang and Yelong Shen and Ahmed Awadallah},
      year={2024},
      eprint={2408.00203},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.00203}, 
}

@inproceedings{lai2024autowebglm,
    author = {Lai, Hanyu and Liu, Xiao and Iong, Iat Long and Yao, Shuntian and Chen, Yuxuan and Shen, Pengbo and Yu, Hao and Zhang, Hanchen and Zhang, Xiaohan and Dong, Yuxiao and Tang, Jie},
    title = {AutoWebGLM: A Large Language Model-based Web Navigating Agent},
    booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
    pages = {5295–-5306},
    year = {2024}
}

@inproceedings{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={ICLR},
  year={2021}
}

% BLEU
@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

% ROUGE
@inproceedings{lin2004rouge,
  title={ROUGE: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out: Proceedings of the ACL-04 workshop},
  pages={74--81},
  year={2004}
}

% TF-IDF
@article{salton1988term,
  title={Term-weighting approaches in automatic text retrieval},
  author={Salton, Gerard and Buckley, Christopher},
  journal={Information processing \& management},
  volume={24},
  number={5},
  pages={513--523},
  year={1988},
  publisher={Elsevier}
}

@article{gpt4,
  title={GPT-4: A Large-Scale Multimodal Model},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023},
  url={https://arxiv.org/abs/2303.08774}
}

@inproceedings{2023GPT4VisionSC,
  title={GPT-4V(ision) System Card},
  author={},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:263218031}
}

@inproceedings{chen2024spa,
  title={SPA-Bench: A Comprehensive Benchmark for SmartPhone Agent Evaluation},
  author={Chen*, Jingxuan and Yuen*, Derek and Xie, Bin and Yang, Yuhao and Chen, Gongwei and Wu, Zhihao and Yixing, Li and Zhou, Xurui and Liu, Weiwen and Wang, Shuai and Shao, Rui and Nie, Liqiang and Wang, Yasheng and Hao, Jianye and Wang, Jun and Shao, Kun},
  booktitle={NeurIPS 2024 Workshop on Open-World Agents},
  year={2024}
}

@misc{2023lmdeploy,
    title={LMDeploy: A Toolkit for Compressing, Deploying, and Serving LLM},
    author={LMDeploy Contributors},
    howpublished = {\url{https://github.com/InternLM/lmdeploy}},
    year={2023}
}

@inproceedings{vllm,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}


@inproceedings{mobilegpt,
author = {Lee, Sunjae and Choi, Junyoung and Lee, Jungjae and Wasi, Munim Hasan and Choi, Hojun and Ko, Steve and Oh, Sangeun and Shin, Insik},
title = {MobileGPT: Augmenting LLM with Human-like App Memory for Mobile Task Automation},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690682},
doi = {10.1145/3636534.3690682},
abstract = {The advent of large language models (LLMs) has opened up new opportunities in the field of mobile task automation. Their superior language understanding and reasoning capabilities allow users to automate complex and repetitive tasks. However, due to the inherent unreliability and high operational cost of LLMs, their practical applicability is quite limited. To address these issues, this paper introduces MobileGPT1, an innovative LLM-based mobile task automator equipped with a human-like app memory. MobileGPT emulates the cognitive process of humans interacting with a mobile app---explore, select, derive, and recall. This approach allows for a more precise and efficient learning of a task's procedure by breaking it down into smaller, modular sub-tasks that can be re-used, re-arranged, and adapted for various objectives. We implement MobileGPT using online LLMs services (GPT-3.5 and GPT-4) and evaluate its performance on a dataset of 185 tasks across 18 mobile apps. The results indicate that MobileGPT can automate and learn new tasks with 82.7\% accuracy, and is able to adapt them to different contexts with near perfect (98.75\%) accuracy while reducing both latency and cost by 62.5\% and 68.8\%, respectively, compared to the GPT-4 powered baseline.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1119–1133},
numpages = {15},
keywords = {AI agent, task automation, large language models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@article{vlmsurver,
  author={Zhang, Jingyi and Huang, Jiaxing and Jin, Sheng and Lu, Shijian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Vision-Language Models for Vision Tasks: A Survey}, 
  year={2024},
  volume={46},
  number={8},
  pages={5625-5644},
  keywords={Task analysis;Visualization;Training;Deep learning;Surveys;Data models;Predictive models;Big Data;big model;deep learning;deep neural network;knowledge distillation;object detection;pre-training;semantic segmentation;transfer learning;vision-language model;visual recognition;image classification},
  doi={10.1109/TPAMI.2024.3369699}}


@misc{wang2021minivlmsmallerfastervisionlanguage,
      title={MiniVLM: A Smaller and Faster Vision-Language Model}, 
      author={Jianfeng Wang and Xiaowei Hu and Pengchuan Zhang and Xiujun Li and Lijuan Wang and Lei Zhang and Jianfeng Gao and Zicheng Liu},
      year={2021},
      eprint={2012.06946},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2012.06946}, 
}

@misc{lu2024guiodysseycomprehensivedataset,
      title={GUI Odyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices}, 
      author={Quanfeng Lu and Wenqi Shao and Zitao Liu and Fanqing Meng and Boxuan Li and Botong Chen and Siyuan Huang and Kaipeng Zhang and Yu Qiao and Ping Luo},
      year={2024},
      eprint={2406.08451},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.08451}, 
}

@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}


@inproceedings{fedavg,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@misc{zheng2024gpt4visiongeneralistwebagent,
      title={GPT-4V(ision) is a Generalist Web Agent, if Grounded}, 
      author={Boyuan Zheng and Boyu Gou and Jihyung Kil and Huan Sun and Yu Su},
      year={2024},
      eprint={2401.01614},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2401.01614}, 
}

@article{fedprox,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={Proceedings of Machine Learning and Systems},
  volume={2},
  pages={429--450},
  year={2020}
}

@misc{baiDigiRLTrainingInTheWild2024,
  title = {{{DigiRL}}: {{Training In-The-Wild Device-Control Agents}} with {{Autonomous Reinforcement Learning}}},
  shorttitle = {{{DigiRL}}},
  author = {Bai, Hao and Zhou, Yifei and Cemri, Mert and Pan, Jiayi and Suhr, Alane and Levine, Sergey and Kumar, Aviral},
  year = {2024},
  month = jun,
  number = {arXiv:2406.11896},
  eprint = {2406.11896},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.11896},
  urldate = {2024-12-01},
  archiveprefix = {arXiv},
  annotation = {NIPS 2024}
}

@misc{chaiAMEXAndroidMultiannotation2024,
  title = {{{AMEX}}: {{Android Multi-annotation Expo Dataset}} for {{Mobile GUI Agents}}},
  shorttitle = {{{AMEX}}},
  author = {Chai, Yuxiang and Huang, Siyuan and Niu, Yazhe and Xiao, Han and Liu, Liang and Zhang, Dingyu and Gao, Peng and Ren, Shuai and Li, Hongsheng},
  year = {2024},
  month = jul,
  number = {arXiv:2407.17490},
  eprint = {2407.17490},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.17490},
  urldate = {2024-10-29},
  archiveprefix = {arXiv}
}

@inproceedings{chengSeeClickHarnessingGUI2024,
  title = {{{SeeClick}}: {{Harnessing GUI Grounding}} for {{Advanced Visual GUI Agents}}},
  shorttitle = {{{SeeClick}}},
  booktitle = {Proceedings of the 62nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Cheng, Kanzhi and Sun, Qiushi and Chu, Yougang and Xu, Fangzhi and YanTao, Li and Zhang, Jianbing and Wu, Zhiyong},
  editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
  year = {2024},
  month = aug,
  pages = {9313--9332},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.acl-long.505},
  urldate = {2024-12-03},
  annotation = {ACL 2024}
}

@misc{dingMobileAgentEnhancingMobile2024,
  title = {{{MobileAgent}}: Enhancing Mobile Control via Human-Machine Interaction and {{SOP}} Integration},
  shorttitle = {{{MobileAgent}}},
  author = {Ding, Tinghe},
  year = {2024},
  month = jan,
  number = {arXiv:2401.04124},
  eprint = {2401.04124},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.04124},
  urldate = {2024-12-03},
  archiveprefix = {arXiv}
}

@misc{dorkaTrainingVisionLanguage2024,
  title = {Training a {{Vision Language Model}} as {{Smartphone Assistant}}},
  author = {Dorka, Nicolai and Marecki, Janusz and Anwar, Ammar},
  year = {2024},
  month = apr,
  number = {arXiv:2404.08755},
  eprint = {2404.08755},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.08755},
  urldate = {2024-12-01},
  archiveprefix = {arXiv}
}

@misc{heEmergedSecurityPrivacy2024,
  title = {The {{Emerged Security}} and {{Privacy}} of {{LLM Agent}}: {{A Survey}} with {{Case Studies}}},
  shorttitle = {The {{Emerged Security}} and {{Privacy}} of {{LLM Agent}}},
  author = {He, Feng and Zhu, Tianqing and Ye, Dayong and Liu, Bo and Zhou, Wanlei and Yu, Philip S.},
  year = {2024},
  month = jul,
  number = {arXiv:2407.19354},
  eprint = {2407.19354},
  publisher = {arXiv},
  urldate = {2024-10-20},
  archiveprefix = {arXiv}
}

@misc{hongCogAgentVisualLanguage2023,
  title = {{{CogAgent}}: {{A Visual Language Model}} for {{GUI Agents}}},
  shorttitle = {{{CogAgent}}},
  author = {Hong, Wenyi and Wang, Weihan and Lv, Qingsong and Xu, Jiazheng and Yu, Wenmeng and Ji, Junhui and Wang, Yan and Wang, Zihan and Zhang, Yuxuan and Li, Juanzi and Xu, Bin and Dong, Yuxiao and Ding, Ming and Tang, Jie},
  year = {2023},
  month = dec,
  number = {arXiv:2312.08914},
  eprint = {2312.08914},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.08914},
  urldate = {2024-12-03},
  archiveprefix = {arXiv},
  annotation = {CVPR 2024}
}

@inproceedings{hongMetaGPTMetaProgramming2023,
  title = {{{MetaGPT}}: {{Meta Programming}} for {{A Multi-Agent Collaborative Framework}}},
  shorttitle = {{{MetaGPT}}},
  booktitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  author = {Hong, Sirui and Zhuge, Mingchen and Chen, Jonathan and Zheng, Xiawu and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and Ran, Chenyu and Xiao, Lingfeng and Wu, Chenglin and Schmidhuber, J{\"u}rgen},
  year = {2023},
  month = oct,
  urldate = {2024-10-22},
  langid = {english},
  annotation = {ICLR 2024}
}

@misc{liEffectsDataScale2024,
  title = {On the {{Effects}} of {{Data Scale}} on {{Computer Control Agents}}},
  shorttitle = {{{AndroidControl}}},
  author = {Li, Wei and Bishop, William and Li, Alice and Rawles, Chris and {Campbell-Ajala}, Folawiyo and Tyamagundlu, Divya and Riva, Oriana},
  year = {2024},
  month = aug,
  number = {arXiv:2406.03679},
  eprint = {2406.03679},
  publisher = {arXiv},
  urldate = {2024-10-30},
  archiveprefix = {arXiv}
}

@misc{liFerretUI2Mastering2024,
  title = {Ferret-{{UI}} 2: {{Mastering Universal User Interface Understanding Across Platforms}}},
  shorttitle = {Ferret-{{UI}} 2},
  author = {Li, Zhangheng and You, Keen and Zhang, Haotian and Feng, Di and Agrawal, Harsh and Li, Xiujun and Moorthy, Mohana Prasad Sathya and Nichols, Jeff and Yang, Yinfei and Gan, Zhe},
  year = {2024},
  month = oct,
  number = {arXiv:2410.18967},
  eprint = {2410.18967},
  publisher = {arXiv},
  urldate = {2024-11-05},
  archiveprefix = {arXiv}
}

@misc{linSPHINXJointMixing2023,
  title = {{{SPHINX}}: {{The Joint Mixing}} of {{Weights}}, {{Tasks}}, and {{Visual Embeddings}} for {{Multi-modal Large Language Models}}},
  shorttitle = {{{SPHINX}}},
  author = {Lin, Ziyi and Liu, Chris and Zhang, Renrui and Gao, Peng and Qiu, Longtian and Xiao, Han and Qiu, Han and Lin, Chen and Shao, Wenqi and Chen, Keqin and Han, Jiaming and Huang, Siyuan and Zhang, Yichi and He, Xuming and Li, Hongsheng and Qiao, Yu},
  year = {2023},
  month = nov,
  number = {arXiv:2311.07575},
  eprint = {2311.07575},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.07575},
  urldate = {2024-11-04},
  archiveprefix = {arXiv}
}

@misc{liPersonalLLMAgents2024,
  title = {Personal {{LLM Agents}}: {{Insights}} and {{Survey}} about the {{Capability}}, {{Efficiency}} and {{Security}}},
  shorttitle = {Personal {{LLM Agents}}},
  author = {Li, Yuanchun and Wen, Hao and Wang, Weijun and Li, Xiangyu and Yuan, Yizhen and Liu, Guohong and Liu, Jiacheng and Xu, Wenxing and Wang, Xiang and Sun, Yi and Kong, Rui and Wang, Yile and Geng, Hanfei and Luan, Jian and Jin, Xuefeng and Ye, Zilong and Xiong, Guanjing and Zhang, Fan and Li, Xiang and Xu, Mengwei and Li, Zhijun and Li, Peng and Liu, Yang and Zhang, Ya-Qin and Liu, Yunxin},
  year = {2024},
  month = jan,
  number = {arXiv:2401.05459},
  eprint = {2401.05459},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-01-25},
  archiveprefix = {arXiv}
}

@misc{liuAutoGLMAutonomousFoundation2024,
  title = {{{AutoGLM}}: {{Autonomous Foundation Agents}} for {{GUIs}}},
  shorttitle = {{{AutoGLM}}},
  author = {Liu, Xiao and Qin, Bo and Liang, Dongzhu and Dong, Guang and Lai, Hanyu and Zhang, Hanchen and Zhao, Hanlin and Iong, Iat Long and Sun, Jiadai and Wang, Jiaqi and Gao, Junjie and Shan, Junjun and Liu, Kangning and Zhang, Shudan and Yao, Shuntian and Cheng, Siyi and Yao, Wentao and Zhao, Wenyi and Liu, Xinghan and Liu, Xinyi and Chen, Xinying and Yang, Xinyue and Yang, Yang and Xu, Yifan and Yang, Yu and Wang, Yujia and Xu, Yulin and Qi, Zehan and Dong, Yuxiao and Tang, Jie},
  year = {2024},
  month = oct,
  number = {arXiv:2411.00820},
  eprint = {2411.00820},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.00820},
  urldate = {2024-11-29},
  archiveprefix = {arXiv}
}

@misc{liuSPHINXXScalingData2024,
  title = {{{SPHINX-X}}: {{Scaling Data}} and {{Parameters}} for a {{Family}} of {{Multi-modal Large Language Models}}},
  shorttitle = {{{SPHINX-X}}},
  author = {Liu, Dongyang and Zhang, Renrui and Qiu, Longtian and Huang, Siyuan and Lin, Weifeng and Zhao, Shitian and Geng, Shijie and Lin, Ziyi and Jin, Peng and Zhang, Kaipeng and Shao, Wenqi and Xu, Chao and He, Conghui and He, Junjun and Shao, Hao and Lu, Pan and Li, Hongsheng and Qiao, Yu and Gao, Peng},
  year = {2024},
  month = jun,
  number = {arXiv:2402.05935},
  eprint = {2402.05935},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.05935},
  urldate = {2024-11-01},
  archiveprefix = {arXiv},
  annotation = {ICML 2024}
}

@misc{mialonGAIABenchmarkGeneral2023,
  title = {{{GAIA}}: A Benchmark for {{General AI Assistants}}},
  shorttitle = {{{GAIA}}},
  author = {Mialon, Gr{\'e}goire and Fourrier, Cl{\'e}mentine and Swift, Craig and Wolf, Thomas and LeCun, Yann and Scialom, Thomas},
  year = {2023},
  month = nov,
  number = {arXiv:2311.12983},
  eprint = {2311.12983},
  publisher = {arXiv},
  urldate = {2024-10-12},
  archiveprefix = {arXiv}
}

@misc{nongMobileFlowMultimodalLLM2024,
  title = {{{MobileFlow}}: {{A Multimodal LLM For Mobile GUI Agent}}},
  shorttitle = {{{MobileFlow}}},
  author = {Nong, Songqin and Zhu, Jiali and Wu, Rui and Jin, Jiongchao and Shan, Shuo and Huang, Xiutian and Xu, Wenhao},
  year = {2024},
  month = aug,
  number = {arXiv:2407.04346},
  eprint = {2407.04346},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.04346},
  urldate = {2024-12-03},
  archiveprefix = {arXiv}
}

@misc{rawlesAndroidWildLargeScale2023,
  title = {Android in the {{Wild}}: {{A Large-Scale Dataset}} for {{Android Device Control}}},
  shorttitle = {Android in the {{Wild}}},
  author = {Rawles, Christopher and Li, Alice and Rodriguez, Daniel and Riva, Oriana and Lillicrap, Timothy},
  year = {2023},
  month = oct,
  number = {arXiv:2307.10088},
  eprint = {2307.10088},
  publisher = {arXiv},
  urldate = {2024-10-16},
  archiveprefix = {arXiv}
}

@misc{rawlesAndroidWorldDynamicBenchmarking2024,
  title = {{{AndroidWorld}}: {{A Dynamic Benchmarking Environment}} for {{Autonomous Agents}}},
  shorttitle = {{{AndroidWorld}}},
  author = {Rawles, Christopher and Clinckemaillie, Sarah and Chang, Yifan and Waltz, Jonathan and Lau, Gabrielle and Fair, Marybeth and Li, Alice and Bishop, William and Li, Wei and {Campbell-Ajala}, Folawiyo and Toyama, Daniel and Berry, Robert and Tyamagundlu, Divya and Lillicrap, Timothy and Riva, Oriana},
  year = {2024},
  month = jun,
  number = {arXiv:2405.14573},
  eprint = {2405.14573},
  publisher = {arXiv},
  urldate = {2024-10-16},
  archiveprefix = {arXiv}
}

@inproceedings{shaoCharacterLLMTrainableAgent2023,
  title = {Character-{{LLM}}: {{A Trainable Agent}} for {{Role-Playing}}},
  shorttitle = {Character-{{LLM}}},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Shao, Yunfan and Li, Linyang and Dai, Junqi and Qiu, Xipeng},
  editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
  year = {2023},
  month = dec,
  pages = {13153--13187},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  urldate = {2024-10-23},
  annotation = {EMNLP 2023}
}

@misc{songAgentBankGeneralizedLLM2024,
  title = {{{AgentBank}}: {{Towards Generalized LLM Agents}} via {{Fine-Tuning}} on 50000+ {{Interaction Trajectories}}},
  shorttitle = {{{AgentBank}}},
  author = {Song, Yifan and Xiong, Weimin and Zhao, Xiutian and Zhu, Dawei and Wu, Wenhao and Wang, Ke and Li, Cheng and Peng, Wei and Li, Sujian},
  year = {2024},
  month = oct,
  number = {arXiv:2410.07706},
  eprint = {2410.07706},
  publisher = {arXiv},
  urldate = {2024-10-23},
  archiveprefix = {arXiv}
}

@misc{sunOSGenesisAutomatingGUI2024,
  title = {{{OS-Genesis}}: {{Automating GUI Agent Trajectory Construction}} via {{Reverse Task Synthesis}}},
  shorttitle = {{{OS-Genesis}}},
  author = {Sun, Qiushi and Cheng, Kanzhi and Ding, Zichen and Jin, Chuanyang and Wang, Yian and Xu, Fangzhi and Wu, Zhenyu and Jia, Chengyou and Chen, Liheng and Liu, Zhoumianze and Kao, Ben and Li, Guohao and He, Junxian and Qiao, Yu and Wu, Zhiyong},
  year = {2024},
  month = dec,
  number = {arXiv:2412.19723},
  eprint = {2412.19723},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.19723},
  urldate = {2025-01-04},
  archiveprefix = {arXiv}
}

@misc{wangDistRLAsynchronousDistributed2024,
  title = {{{DistRL}}: {{An Asynchronous Distributed Reinforcement Learning Framework}} for {{On-Device Control Agents}}},
  shorttitle = {{{DistRL}}},
  author = {Wang, Taiyi and Wu, Zhihao and Liu, Jianheng and Hao, Jianye and Wang, Jun and Shao, Kun},
  year = {2024},
  month = nov,
  number = {arXiv:2410.14803},
  eprint = {2410.14803},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.14803},
  urldate = {2024-12-01},
  archiveprefix = {arXiv}
}

@misc{wangMobileAgentAutonomousMultiModal2024,
  title = {Mobile-{{Agent}}: {{Autonomous Multi-Modal Mobile Device Agent}} with {{Visual Perception}}},
  shorttitle = {Mobile-{{Agent}}},
  author = {Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},
  year = {2024},
  month = apr,
  number = {arXiv:2401.16158},
  eprint = {2401.16158},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.16158},
  urldate = {2024-12-03},
  archiveprefix = {arXiv}
}

@misc{wangMobileAgentBenchEfficientUserFriendly2024,
  title = {{{MobileAgentBench}}: {{An Efficient}} and {{User-Friendly Benchmark}} for {{Mobile LLM Agents}}},
  shorttitle = {{{MobileAgentBench}}},
  author = {Wang, Luyuan and Deng, Yongyu and Zha, Yiwei and Mao, Guodong and Wang, Qinmin and Min, Tianchen and Chen, Wei and Chen, Shoufa},
  year = {2024},
  month = jun,
  number = {arXiv:2406.08184},
  eprint = {2406.08184},
  publisher = {arXiv},
  urldate = {2024-10-14},
  archiveprefix = {arXiv},
  annotation = {ACL 2024}
}

@misc{wangScreen2WordsAutomaticMobile2021,
  title = {{{Screen2Words}}: {{Automatic Mobile UI Summarization}} with {{Multimodal Learning}}},
  shorttitle = {{{Screen2Words}}},
  author = {Wang, Bryan and Li, Gang and Zhou, Xin and Chen, Zhourong and Grossman, Tovi and Li, Yang},
  year = {2021},
  month = aug,
  number = {arXiv:2108.03353},
  eprint = {2108.03353},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2108.03353},
  urldate = {2024-11-29},
  archiveprefix = {arXiv},
  annotation = {UIST 2021}
}

@inproceedings{xingUnderstandingWeaknessLarge2024,
  title = {Understanding the {{Weakness}} of {{Large Language Model Agents}} within a {{Complex Android Environment}}},
  booktitle = {Proceedings of the 30th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Xing, Mingzhe and Zhang, Rongkai and Xue, Hui and Chen, Qi and Yang, Fan and Xiao, Zhen},
  year = {2024},
  month = aug,
  series = {{{KDD}} '24},
  pages = {6061--6072},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3637528.3671650},
  urldate = {2024-10-13},
  isbn = {9798400704901},
  annotation = {KDD 2024}
}

@misc{xuExploringLargeLanguage2023,
  title = {Exploring {{Large Language Models}} for {{Communication Games}}: {{An Empirical Study}} on {{Werewolf}}},
  shorttitle = {Exploring {{Large Language Models}} for {{Communication Games}}},
  author = {Xu, Yuzhuang and Wang, Shuo and Li, Peng and Luo, Fuwen and Wang, Xiaolong and Liu, Weidong and Liu, Yang},
  year = {2023},
  month = sep,
  number = {arXiv:2309.04658},
  eprint = {2309.04658},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.04658},
  urldate = {2024-01-03},
  archiveprefix = {arXiv}
}

@misc{yanGPT4VWonderlandLarge2023,
  title = {{{GPT-4V}} in {{Wonderland}}: {{Large Multimodal Models}} for {{Zero-Shot Smartphone GUI Navigation}}},
  shorttitle = {{{GPT-4V}} in {{Wonderland}}},
  author = {Yan, An and Yang, Zhengyuan and Zhu, Wanrong and Lin, Kevin and Li, Linjie and Wang, Jianfeng and Yang, Jianwei and Zhong, Yiwu and McAuley, Julian and Gao, Jianfeng and Liu, Zicheng and Wang, Lijuan},
  year = {2023},
  month = nov,
  number = {arXiv:2311.07562},
  eprint = {2311.07562},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.07562},
  urldate = {2024-12-05},
  archiveprefix = {arXiv}
}

@misc{zhangAgentOhanaDesignUnified2024,
  title = {{{AgentOhana}}: {{Design Unified Data}} and {{Training Pipeline}} for {{Effective Agent Learning}}},
  shorttitle = {{{AgentOhana}}},
  author = {Zhang, Jianguo and Lan, Tian and Murthy, Rithesh and Liu, Zhiwei and Yao, Weiran and Zhu, Ming and Tan, Juntao and Hoang, Thai and Liu, Zuxin and Yang, Liangwei and Feng, Yihao and Kokane, Shirley and Awalgaonkar, Tulika and Niebles, Juan Carlos and Savarese, Silvio and Heinecke, Shelby and Wang, Huan and Xiong, Caiming},
  year = {2024},
  month = nov,
  number = {arXiv:2402.15506},
  eprint = {2402.15506},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.15506},
  urldate = {2024-12-05},
  archiveprefix = {arXiv}
}

@misc{zhangAndroidZooChainofActionThought2024,
  title = {Android in the {{Zoo}}: {{Chain-of-Action-Thought}} for {{GUI Agents}}},
  shorttitle = {Android in the {{Zoo}}},
  author = {Zhang, Jiwen and Wu, Jihao and Teng, Yihua and Liao, Minghui and Xu, Nuo and Xiao, Xiao and Wei, Zhongyu and Tang, Duyu},
  year = {2024},
  month = jul,
  number = {arXiv:2403.02713},
  eprint = {2403.02713},
  publisher = {arXiv},
  urldate = {2024-10-23},
  archiveprefix = {arXiv}
}

@misc{zhangAppAgentMultimodalAgents2023,
  title = {{{AppAgent}}: {{Multimodal Agents}} as {{Smartphone Users}}},
  shorttitle = {{{AppAgent}}},
  author = {Zhang, Chi and Yang, Zhao and Liu, Jiaxuan and Han, Yucheng and Chen, Xin and Huang, Zebiao and Fu, Bin and Yu, Gang},
  year = {2023},
  month = dec,
  number = {arXiv:2312.13771},
  eprint = {2312.13771},
  publisher = {arXiv},
  urldate = {2024-10-14},
  archiveprefix = {arXiv}
}

@article{zhangPrivacyAsstSafeguardingUser2024,
  title = {{{PrivacyAsst}}: {{Safeguarding User Privacy}} in {{Tool-Using Large Language Model Agents}}},
  shorttitle = {{{PrivacyAsst}}},
  author = {Zhang, Xinyu and Xu, Huiyu and Ba, Zhongjie and Wang, Zhibo and Hong, Yuan and Liu, Jian and Qin, Zhan and Ren, Kui},
  year = {2024},
  journal = {IEEE Transactions on Dependable and Secure Computing},
  pages = {1--16},
  issn = {1941-0018},
  doi = {10.1109/TDSC.2024.3372777},
  urldate = {2024-10-20},
  annotation = {TDSC 2024}
}

@book{zhangUIHawkUnleashingScreen2024,
  title = {{{UI-Hawk}}: {{Unleashing}} the {{Screen Stream Understanding}} for {{GUI Agents}}},
  shorttitle = {{{UI-Hawk}}},
  author = {Zhang, Jiwen and Yu, Yaqi and Liao, Minghui and Li, Wentao and Wu, Jihao and Wei, Zhongyu},
  year = {2024},
  month = aug,
  doi = {10.20944/preprints202408.2137.v1}
}

@misc{zhangYouOnlyLook2024,
  title = {You {{Only Look}} at {{Screens}}: {{Multimodal Chain-of-Action Agents}}},
  shorttitle = {Auto-{{UI}}},
  author = {Zhang, Zhuosheng and Zhang, Aston},
  year = {2024},
  month = jun,
  number = {arXiv:2309.11436},
  eprint = {2309.11436},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.11436},
  urldate = {2024-12-03},
  archiveprefix = {arXiv},
  annotation = {ACL 2024 Findings}
}

@misc{zhouWebArenaRealisticWeb2024,
  title = {{{WebArena}}: {{A Realistic Web Environment}} for {{Building Autonomous Agents}}},
  shorttitle = {{{WebArena}}},
  author = {Zhou, Shuyan and Xu, Frank F. and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and Alon, Uri and Neubig, Graham},
  year = {2024},
  month = apr,
  number = {arXiv:2307.13854},
  eprint = {2307.13854},
  publisher = {arXiv},
  urldate = {2024-10-12},
  archiveprefix = {arXiv},
  annotation = {ICLR 2024}
}


@misc{zhao2024swiftascalablelightweightinfrastructure,
      title={SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning},
      author={Yuze Zhao and Jintao Huang and Jinghan Hu and Xingjun Wang and Yunlin Mao and Daoze Zhang and Zeyinzi Jiang and Zhikai Wu and Baole Ai and Ang Wang and Wenmeng Zhou and Yingda Chen},
      year={2024},
      eprint={2408.05517},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.05517},
}

@inproceedings{ye2024openfedllm,
  title={Openfedllm: Training large language models on decentralized private data via federated learning},
  author={Ye, Rui and Wang, Wenhao and Chai, Jingyi and Li, Dihan and Li, Zexi and Xu, Yinda and Du, Yaxin and Wang, Yanfeng and Chen, Siheng},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6137--6147},
  year={2024}
}

@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24185--24198},
  year={2024}
}

@misc{zhang2024summactuncoveringuserintentions,
      title={SummAct: Uncovering User Intentions Through Interactive Behaviour Summarisation}, 
      author={Guanhua Zhang and Mohamed Ahmed and Zhiming Hu and Andreas Bulling},
      year={2024},
      eprint={2410.08356},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2410.08356}, 
}