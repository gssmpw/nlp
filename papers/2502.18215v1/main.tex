% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx} 
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Connecting Voices: LoReSpeech as a Low-Resource Speech Parallel Corpus}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Samy Ouzerrout \\
  Université d'Orléans, France \\
  Yanantic AI, France \\
  \texttt{samy.ouzerrout@etu.univ-orleans.fr} \\\
 }

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
Aligned audio corpora are fundamental to NLP technologies such as ASR and speech translation, yet they remain scarce for under-represented languages, hindering their technological integration. This paper introduces a methodology for constructing LoReSpeech,  a low-resource speech-to-speech translation corpus. Our approach begins with LoReASR, a sub-corpus of short audios aligned with their transcriptions, created through a collaborative platform. Building on LoReASR, long-form audio recordings, such as biblical texts, are aligned using tools like the MFA. LoReSpeech delivers both intra- and inter-language alignments, enabling advancements in multilingual ASR systems, direct speech-to-speech translation models, and linguistic preservation efforts, while fostering digital inclusivity. \\
This work is conducted within \textbf{Tutlayt AI} project
 (\url{https://tutlayt.fr}).
\end{abstract}

\section{Introduction}
Aligned corpora, whether textual or audio, are essential for the development of language technologies such as machine translation and automatic speech recognition (ASR). They enable the training of models capable of handling a wide variety of languages, including under-represented ones. While aligned textual corpora, such as Bible translations, are relatively accessible for some minority languages, aligned audio corpora remain scarce, thereby limiting advancements in voice-centered applications.\\

The primary challenge lies in the lack of precise alignment for audio data. For instance, aligned Bible translations exist for many minority languages at the verse level, but their audio versions are aligned at macroscopic levels (chapters or books), rendering these long sequences unusable for machine learning models that require short and accurately segmented data.

Tools such as the Montreal Forced Aligner (MFA) can align segmented texts with long audio recordings, but they require pre-aligned audio-text corpora for calibration, which are often unavailable for under-represented languages.\\

In this article, we propose a methodology to create a parallel audio corpus for under-represented languages, named LoReSpeech (Low-Resource Speech Parallel Corpus). This work is part of the \textbf{Tutlayt AI} project, which aims to develop speech and language resources for low-resource languages. The LoReASR dataset is collected through a dedicated web-based system designed for collaborative speech data collection (\url{https://tutlayt.fr}).


This approach begins with the creation of a sub-corpus, called LoReASR (Low-Resource Automatic Speech Recognition), consisting of short alignments (audio-transcriptions) for languages lacking such resources. Unlike approaches based on massive data collection, this sub-corpus emphasizes quality by leveraging a dedicated vocalization platform, carefully selected speakers, and collaborations with local organizations.

LoReASR serves as a critical foundation for aligning existing long audio recordings with their segmented translations, thereby paving the way for the development of LoReSpeech. To ensure alignment accuracy, we adopt a two-step validation process: a subset of the alignments is manually reviewed, and an automatic verification step is performed using ASR transcription and TER scoring.

Our approach provides a key initial step for under-represented languages by enabling the creation of intra- and inter-language aligned audio corpora. We aim to bridge the gap between over-resourced and under-resourced languages in terms of audio resources, thereby paving the way for new linguistic applications.

\section{Introduction}


Aligned corpora, whether textual or audio, are essential for the development of language technologies such as machine translation and automatic speech recognition (ASR). They enable the training of models capable of handling a wide variety of languages, including under-represented ones. While aligned textual corpora, such as Bible translations, are relatively accessible for some minority languages, aligned audio corpora remain scarce, thereby limiting advancements in voice-centered applications.\\


The primary challenge lies in the lack of precise alignment for audio data. For instance, aligned Bible translations exist for many minority languages at the verse level, but their audio versions are aligned at macroscopic levels (chapters or books), rendering these long sequences unusable for machine learning models that require short and accurately segmented data.

Tools such as the Montreal Forced Aligner (MFA) can align segmented texts with long audio recordings, but they require pre-aligned audio-text corpora for calibration, which are often unavailable for under-represented languages.\\

In this article, we propose a methodology to create a parallel audio corpus for under-represented languages, named LoReSpeech (Low-Resource Speech Parallel Corpus).

This approach begins with the creation of a sub-corpus, called LoReASR (Low-Resource Automatic Speech Recognition), consisting of short alignments (audio-transcriptions) for languages lacking such resources. Unlike approaches based on massive data collection, this sub-corpus emphasizes quality by leveraging a dedicated vocalization platform, carefully selected speakers, and collaborations with local organizations.

LoReASR serves as a critical foundation for aligning existing long audio recordings with their segmented translations, thereby paving the way for the development of LoReSpeech.\\

Our approach provides a key initial step for under-represented languages by enabling the creation of intra- and inter-language aligned audio corpora. We aim to bridge the gap between over-resourced and under-resourced languages in terms of audio resources, thereby paving the way for new linguistic applications.



\section{Context and Motivation}

Advancements in ASR and speech-to-speech translation rely on rich and aligned data resources. However, under-represented languages face a critical shortage of aligned audio corpora, which are essential for training advanced models.

\subsection{The Importance of Under-Represented Languages in NLP}

Under-represented languages, often minority languages, are crucial for preserving global linguistic and cultural diversity. Their integration into NLP technologies is essential for several reasons:

\begin{itemize}

\item \textbf{Linguistic Equity and Digital Inclusion:} Providing tailored technologies to these communities helps bridge the digital divide and ensures equitable access to information for millions of speakers \citep{bird2020decolonising}.

\item \textbf{Preservation of Linguistic Heritage:} Digitizing and developing tools for these languages contributes to their preservation and the intergenerational transmission of their cultural richness.

\item \textbf{Enhancement of Multilingual Models:} Integrating under-represented languages strengthens the generalization and robustness of multilingual models by enriching their ability to understand linguistic diversity \citep{conneau2020unsupervised}.

\item \textbf{Scientific Advancements:} Working on low-resource languages, which face data scarcity and complex morphologies, drives the development of innovative methodologies such as transfer learning and multilingual approaches.

\end{itemize}


In summary, the inclusion of under-represented languages in NLP is an essential technological, cultural, scientific, and social challenge.

\subsection{Current State of Aligned Corpora}

Parallel audio corpora (speech-to-speech) remain scarce and are primarily limited to a few major languages, such as those found in SpeechMatrix \citep{speechmatrix2022} and CVSS \citep{cvss2022}.\\

Corpora associating aligned audio with its transcription and translation have become more widespread, often based on TEDx talks, such as MUST-C \citep{must2019} and mTEDx \citep{mtedx2021}, or European Parliament debates, such as Europarl-ST \citep{europarl-st}. However, they remain limited to certain languages.\\


ASR corpora have seen a notable expansion in availability and linguistic diversity, driven by major projects such as Common Voice \citep{commonvoice2020}, which covers over 100 languages, the Pangloss Collection \citep{pangloss2020}, dedicated to endangered languages, and Lingua Libre \citep{lingualibre2020}, a collaborative platform for recording speech data in under-represented languages.

Additionally, targeted initiatives, often tailored to regional or specific contexts, continue to emerge. However, despite these advancements, linguistic coverage remains limited, leaving many languages without resources.\\

Finally, textual translation corpora are the most developed for low-resource languages, with resources covering hundreds of languages, such as NLLB \citep{nllb2022}, OPUS \citep{opus}, and JW300 \citep{jw300}, or even nearly 2,000 languages for the Bible \citep{bible1600}.\\


These translation corpora could serve as a foundation for creating a parallel audio corpus through the synthesis of aligned translations using TTS models. However, training such models requires ASR corpora, which remain insufficient for many languages, and the quality of synthetic audio will depend on the size and quality of the ASR corpora.

Another option is to leverage the substantial audio resources available for the Bible, which include languages without ASR corpora. The textual translations are aligned at the verse level, whereas the audio recordings are typically aligned at a broader granularity, corresponding to chapters or books, with segments ranging from several minutes to a few hours. These recordings can, however, be segmented at the verse level using an alignment tool. While its effectiveness also depends on the availability of ASR corpora, this approach requires fewer data and computational resources than a TTS model and allows for the production of natural audio.\\

It is therefore essential to develop ASR corpora that encompass a broader diversity of under-represented languages. From this perspective, our methodology begins with the creation of the LoReASR corpus, which incorporates previously overlooked languages.

\section{Methodology}

The proposed methodology aims to overcome the limitations associated with the lack of aligned audio corpora for under-represented languages. This section outlines the key steps involved in creating the LoReASR and LoReSpeech corpora.

\subsection{Construction of the LoReASR Corpus}

LoReASR represents the first step of our approach. It is an ASR corpus designed to provide short and precise alignments (audio-transcription) in under-represented languages. The initial version of this corpus focuses on 10 languages: Chechen, Cham, Comorian, Dzongkha, Kabyle, Inuktitut, Malagasy, Yucatec Maya, Navajo, Khumzari, and Soninke.\\

The construction of this corpus relies on collecting disparate data and using a dedicated platform for text vocalization. Recordings are made via Tutlayt AI (\url{https://tutlayt.fr}), a collaborative system that facilitates speech data collection for low-resource languages. The platform enables native speakers to provide audio recordings based on predefined texts, ensuring precise speech-text alignment.


The content to be vocalized is sourced from existing resources, newspapers, and, when available, universal texts such as the Declaration of Human Rights. Once vocalized in multiple languages, these texts will serve as the foundation for a preliminary parallel audio corpus.

Speakers are carefully selected based on their linguistic proficiency and native accent. Additionally, collaborations with local organizations (e.g., schools) are established to ensure that they actively participate in the preservation and promotion of their own language.

\begin{figure}[h]  % 'h' signifie 'ici' pour placer l'image à cet endroit
    \centering  % Centre l'image
    \includegraphics[width=1\columnwidth]{plateforme.png}  % Image avec largeur de 50% de la colonne
    \caption{vocalization interface for chechen}  % Légende de l'image
   
\end{figure}

\subsection{Training an Aligner}

Training an alignment model begins with the creation of a phonetic dictionary, which is essential in the absence of a pre-existing model. This dictionary maps each word in the corpus to its phonetic transcription. If a specific dictionary is not available, it can be created manually or generated using automated tools.\\

The model is then trained using tools like the Montreal Forced Aligner (MFA) \citep{mfa2017} with a pre-aligned audio-text corpus. The model learns to accurately associate audio segments with their phonetic transcriptions, enabling the alignment of new audio files by providing only the corresponding transcriptions and recordings.

\subsection{Creation of the LoReSpeech Corpus}

LoReSpeech builds on the data collected through LoReASR to train an audio-text alignment model. The process leverages text and audio corpora, such as Bible translations, where short texts (verses) are aligned across different languages. For many languages, long audio recordings corresponding to collections of short texts (such as chapters or books) are widely available.

\textbf{Granularity of Alignments:} The alignment is performed at the verse level. Since existing audio recordings are typically structured at the chapter or book level, this granularity is too coarse for machine learning. Our approach segments the audio into smaller units corresponding to individual verses.

\textbf{Alignment Process:} The alignment procedure consists of two main steps:
\begin{enumerate}
    \item \textbf{Training the aligner:} The Montreal Forced Aligner (MFA) is first trained on the LoReASR dataset, which contains short  audio-text pairs. This ensures that the aligner is optimized for the target languages before being applied to longer recordings.
    \item \textbf{Segmenting long recordings:} The trained aligner then processes long-form recordings (chapter-level audio) using pre-segmented textual references at the verse level. The aligner generates time-stamped segments for each verse, which are then extracted as independent audio clips.
\end{enumerate}

\textbf{Validation and Quality Control:} 
The alignment quality is assessed in two phases:
\begin{itemize}
    \item \textbf{Manual verification (Phase 1):} Before large-scale application, a subset of alignments is manually reviewed to identify common errors and determine whether further fine-tuning is required.
    
    \item \textbf{Automatic evaluation (Phase 2):} Once the alignment model is deemed reliable, verse-level audio-text pairs are automatically validated using speech recognition. We transcribe the segmented audio with a LoReASR-trained ASR model and compare it to the reference text using the Universal- Word Error Rate (\href{https://pypi.org/project/evalnlp/}{UWER}) metric. This quantifies alignment accuracy without requiring exhaustive manual review.
\end{itemize}

\textbf{Types of Alignments:} The final output of this methodology is the \textbf{LoReSpeech} corpus, which features two distinct levels of alignment:
\begin{itemize}
    \item \textbf{Intra-language alignments:} Each verse-level audio file is aligned with its corresponding transcription in the same language.
    \item \textbf{Inter-language alignments:} Each verse-level audio file in language A is paired with a corresponding verse-level audio file in language B. This results in speech-to-speech parallel data, enabling direct speech-to-speech translation models.
\end{itemize}

This methodology creates a high-quality parallel speech corpus for low-resource languages, advancing multilingual ASR, speech-to-speech translation, and linguistic preservation.


\section{Applications of the LoReSpeech Corpus}

The LoReSpeech corpus provides key opportunities to address essential needs in AI and linguistics.

\begin{itemize}
    \item \textbf{Speech-to-Speech Translation (S2S)} \
The LoReSpeech corpus represents a significant advancement for direct speech-to-speech (S2S) translation of under-represented languages. By aligning audio files with their corresponding translations, it enables the development of models that bypass intermediate steps (audio → text → translation → audio), thereby reducing cumulative errors and speeding up the translation process. This approach supports real-time voice systems, which are essential for communities relying on oral translation, while also promoting the inclusion of these languages in modern technologies.

 \item \textbf{Preservation and Promotion of Under-Represented Languages} \
The LoReSpeech corpus plays a vital role in preserving and promoting under-represented languages. It documents the phonetic and textual characteristics of endangered languages and supports their revitalization. These resources benefit linguists and local communities while facilitating the creation of educational content to raise awareness among younger generations about their linguistic heritage and encourage the digital use of their native languages.

    \item \textbf{Enhancement of Multilingual ASR Models} \
Parallel audio data, as translations sharing the same meaning, enhance multilingual ASR models by distinguishing phonetic and morphological variations while preserving semantic consistency. These models leverage similarities between related languages, reduce morphological errors, and facilitate transfer learning to under-represented languages. This enriches audio representations and strengthens transcription robustness for applications such as transcription or direct audio-to-text translation.

    \item \textbf{Cross-Language Linguistic Analysis} \
Multilingual audio-text alignment facilitates linguistic analysis by enabling comparisons of acoustic, phonetic, and rhythmic characteristics, as well as semantic and syntactic correspondences in spoken data. It provides unique opportunities to study phenomena such as intonation and prosody across different languages.

   

    \item \textbf{Applications in Sentiment Detection} \
By combining audio and textual data, it becomes possible to develop sentiment detection tools directly from audio and analyze emotions in speeches or conversations. These data can also be used to enhance or create sentiment detection models for text in languages that currently lack language models.
\end{itemize}


\section{Conclusion}

This article proposes a methodology to address the significant challenges posed by the lack of aligned audio corpora for under-represented languages. Through the creation of the LoReASR and LoReSpeech corpora, our approach combines precision with local collaboration to produce high-quality data while directly involving the communities concerned. These corpora open up new possibilities in areas such as direct speech-to-speech translation, the enhancement of multilingual ASR models, cross-language linguistic analysis, and the preservation of endangered languages.

By providing a solid foundation for the development of inclusive language technologies, this methodology represents a significant step toward reducing inequalities between languages in terms of digital resources. It also calls for collaboration among researchers, institutions, and native speakers to build a sustainable ecosystem that promotes the integration of under-represented languages into modern technologies.


\subsection{Work in Progress and Future Evaluation}

This work presents the methodology for constructing LoReSpeech, but the dataset is still under development. Future work will focus on collecting additional data and providing quantitative evaluations. Specifically, we will report corpus statistics such as total hours, number of sentences, and alignment rate. Additionally, quality assessments will be conducted through manual validation and automatic alignment evaluation using Translation Edit Rate (TER). These elements will be detailed in a follow-up publication.

We also aim to expand the dataset beyond the current 10 languages by incorporating more diverse linguistic varieties. Future research will explore how our methodology can be generalized to other structured and spontaneous speech domains.

\section{Limitations}

While the proposed LoReSpeech methodology addresses key challenges in creating aligned audio corpora for under-represented languages, several limitations remain:

\begin{itemize}
    \item \textbf{Dependence on Data Quality:} The methodology relies on the quality of the LoReASR corpus. Inconsistencies in short audio-transcription pairs could propagate errors in the final LoReSpeech corpus.
    
    \item \textbf{Scalability:} Extending the approach to additional languages depends on the availability of linguistic expertise and local partnerships, which may be challenging for highly endangered languages.
    
    \item \textbf{Alignment Accuracy:} Tools like the Montreal Forced Aligner (MFA) require phonetic dictionaries or pre-trained models, which are unavailable for many languages. Creating these resources is time-consuming.
    
    \item \textbf{Adaptation to Other Domains:} The methodology is primarily designed for structured texts (e.g., religious documents). Applying it to spontaneous speech or less structured content may require additional techniques.
\end{itemize}




\bibliography{main}

\end{document}
