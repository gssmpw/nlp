\section{Introduction}
\IEEEPARstart{A}{n} autonomous bicycle is a bicycle, equipped with electric motors, sensors, algorithms, and control systems that allow the bicycle to navigate and operate without human intervention. Autonomous bicycles are an exciting area of research and development with numerous potential applications that can improve transportation, safety, and efficiency. In bicycle-sharing systems, autonomous bicycles can enhance the user experience by autonomously traveling to a person who has requested one, eliminating the need for individuals to walk toward the bicycle~\cite{sanchez2020autonomous}. Additionally, autonomous bicycles can streamline fleet management by enabling bicycles to autonomously navigate to charging stations for recharging. This eliminates the need for operators to manually collect, load, and transport bicycles to charging stations, making the process more efficient. Similar applications of the self-balancing feature of autonomous bicycles include steering assistants for individuals with limited physical capabilities \cite{alizadehsaravi2023bicycle}, among others.

Another notable application of autonomous bicycles is their ability to replace conventional bicycles in test tracks for evaluating the performance of various autonomous safety features in vehicles. Bicycles are often forced to share road segments with other motorized vehicles, which places cyclists at a higher risk of injury~\cite {kutela2021mining}. One way to reduce the risk is to use autonomous emergency braking (AEB) and autonomous emergency steering (AES) systems in motorized vehicles. The sensors in the vehicles detect and classify vulnerable road users (VRUs), including pedestrians and cyclists, and brakes or steers to avoid a collision. When organizations like EuroNCAP evaluate the AEB and AES systems on test tracks, a bicycle target placed on a moving platform is utilized~\footnote{\href{https://www.euroncap.com/en/vehicle-safety/the-ratings-explained/vulnerable-road-user-vru-protection/aeb-cyclist/}{https://www.euroncap.com/en/vehicle-safety/the-ratings-explained/vulnerable-road-user-vru-protection/aeb-cyclist/}}. Since the target is mounted on the platform, its movements are also constrained by its linear motion. An autonomous bicycle, which can better represent a cyclist's maneuvers and sometimes unpredictable behavior, would enhance the testing area, thereby improving the reliability of safety tests in vehicles. 

A bicycle is a nonlinear system that becomes self-stabilized at sufficient forward speed but remains unstable at lower velocities~\cite{Meijaard2007}. A human rider can employ three different control actions to maintain bicycle stability: adjusting the forward velocity, steering, and shifting their center of gravity to control the lean angle. At fixed speeds, similar to human control of a bicycle, an autonomous bicycle can be balanced either by regulating the steering angle \cite{Yeh2024, PerssonECC, defoort2009sliding} or by directly controlling the lean angle \cite{zhang2014, wang2017tracking}. However, the latter approach requires mounting a flywheel or a moving mass on the bicycle, significantly altering its appearance, which may be undesirable for certain applications, i.e., at test tracks of safety features of vehicles, where it is important that the autonomous bicycle resembles an ordinary bicycle. In addition, as revealed by Kooijman~\etal~\cite{kooijman2009} and later confirmed by Moore~\etal~\cite{moore2011}, controlling the lean angle has only a minor effect on balance at typical riding velocities. Therefore, this paper focuses on balancing the bicycle through steering control. Like human control at relatively high speeds, the bicycle should be steered in the direction of the fall, i.e., if it leans to the right, it must be steered to the right. Moreover, balancing the bicycle through steering control offers a more energy-efficient alternative than flywheels or a moving mass~\cite{rodriguez2017improving}. 
 
A wide range of control approaches have been proposed for balancing autonomous bicycles based on the simple principle of steering in the direction of the fall. For example, PID and LQR controllers have been designed based on a linearized model around the upright equilibrium of the bicycle and are evaluated around this equilibrium~\cite{PerssonECC}. Both PID and LQR offer simple design methodologies; however, as a natural consequence of linearization, their performance may degrade as the system deviates from the equilibrium point used for linearization. One way to address this drawback is using a nonlinear controller, such as the sliding mode controller (SMC). The second order SMC proposed in the work of Defoort~\etal~\cite{defoort2009sliding} is designed using a nonlinear point-mass model of a bicycle and evaluated through both simulations and on an instrumented bicycle riding on a bicycle roller. However, SMC may induce chattering in the control signal due to the switching nature of the control law, potentially leading to high actuation efforts from the motors~\cite{slotine1991applied}. 

Active disturbance rejection control (ADRC) is proposed in~\cite{Baquero-Suarez2018} to handle unmodeled noise and disturbances. This control design is based on the so-called Whipple model~\cite{Meijaard2007}, a fourth-order model linearized around small lean and steering angles. The model requires 25 physical parameters to be measured or estimated from the bicycle~\cite{kooijman2008}. The ADRC is first evaluated in simulation using a detailed CAD model of their bicycle, imported into ADAMS, and controlled through co-simulation with MATLAB. Next, experiments were conducted. The results demonstrate that the bicycle can balance in both simulations and on straight asphalt tracks under varying forward velocities. However, noticeable oscillation was observed in both the lean and steering angles. Robustness against speed variations and disturbances is also considered in the recent work of Yeh~\etal~\cite{Yeh2024}, in which a linear-parameter-varying (LPV) controller is designed based on a point mass model of a bicycle~\cite{Astrom2005}. The controller was evaluated in both simulations and experiments conducted on an instrumented bicycle. 

However, all these control methods rely heavily on an accurate system model. While in practice, the mathematical models of autonomous bicycles are reasonably well understood~\cite{Meijaard2007, bruni2020state},  the uncertainties, such as external disturbances (e.g., wind, street slope), and internal variations (e.g., changes in friction, mechanical and electrical couplings, and shifts in the center of gravity), can significantly degrade the performance of model-based approaches over time.

There are also direct approaches to bicycle control design that bypass the requirement of an explicit model. A notable instance is policy optimization (PO), an essential approach of modern reinforcement learning (RL)~\cite{choi2019toward, chung2017, weyrer2024path}. By computing the policy gradient from system trajectories, the PO updates the control policy with gradient descent methods. The work by Choi \etal~\cite{choi2019toward} employs Deep Deterministic Policy Gradient (DDPG) to learn a policy for controlling the bicycle's speed, lean angle, and steering torque. This approach is evaluated on a nonlinear bicycle model; however, its real-world transferability is not tested in \cite{choi2019toward}. The work by Tuyen and Chung~\cite{chung2017} evaluates DDPG on a miniature bicycle. However, the limited computational power of the hardware is insufficient for the control algorithm. Another deep RL algorithm is proposed for stabilizing a Whipple model of a bicycle and tracking a predefined path~\cite{weyrer2024path}. While the bicycle is balanced at varying velocities, they require time-consuming training and lack experimental validation. 

Recently, there has been a growing trend of direct data-driven control methods motivated by behavioral system theory and subspace methods~\cite{willems2005note,de2019formulas, Coulson2019, berberich2020data,FlorianReg2022, van2020data}. For example, the seminal work~\cite{de2019formulas} proposes a data-based parameterization for linear systems and reformulates the LQR problem as a convex program with a batch of persistently exciting data. Thus, the optimal LQR gain can be found without any explicit model or identification.  To enhance adaptability, our previous work~\cite{zhao2023data, zhao2024data} proposes a covariance parameterization for the LQR problem, based on which a data-enabled policy optimization (DeePO) method is developed to learn the LQR gain directly from online closed-loop data. In contrast to the previous policy optimization methods \cite{choi2019toward, chung2017, weyrer2024path} that require multiple long trajectories to compute a single policy gradient, the DeePO method uses the covariance of online data to update the policy sample-by-sample. Besides its sample efficiency, the DeePO method is also computationally efficient, performing only a single step of gradient descent to update the policy per time step. Under persistently exciting input, the DeePO algorithm is shown to have non-asymptotic convergence guarantees to the optimal LQR gain. The covariance parameterization or the DeePO method has been extended to linear parameter-varying control~\cite{mejari2024direct}, model-reference control~\cite{mejari2024bias}, output-feedback control, and validated in a power converter system via simulations~\cite{zhao2024direct}.

This paper proposes a unified DeePO framework for nonlinear bicycle control. To deal with the nonlinearities, we first design an output feedback linearization (FL) controller using well-established parametric bicycle models. This controller partially cancels the nonlinearities of the bicycle system while simultaneously stabilizing it. It is important to note that although the current state-of-the-art bicycle models are accurate, the model-based controllers may fail to achieve the desired performance due to unmodeled dynamics, parametric uncertainty, various disturbances, and time-varying dynamics (e.g., wind, varying friction in different environments, mechanical wear and tear, and coupling aging). To compensate for these disturbances and uncertainties, we integrate a DeePO controller on top of the FL layer. This allows us to adaptively fine-tune the feedback gains and effectively handle time-varying dynamics, disturbances, and unmodeled effects. Our approach is evaluated on both a realistic multi-body dynamic model of the bicycle and in hardware experiments conducted on an instrumented bicycle in an indoor environment. 

To the best of our knowledge, this study is the first to report a real-world implementation of DeePO. While previous works have explored DeePO in simulations~\cite{zhao2024data, zhao2024direct}, our study demonstrates its feasibility in a practical setting, validating its effectiveness in handling real-world nonlinearities, uncertainties, disturbances, and unmodeled dynamics. This contribution marks an important step toward bridging the gap between theory and real-world deployment of adaptive data-driven control methods.


\subsection{Statement of Contributions}
The contributions of this paper are summarized below.
\begin{itemize}  
    \item We introduce a unified control framework, combining FL with DeePO, for controlling a nonlinear autonomous bicycle.  
    \item We integrate a forgetting factor into the conventional DeePO framework to effectively handle time-varying dynamics.  
    \item This study is the first to apply DeePO in a real-world case study, specifically showcasing its effectiveness in controlling a bicycle through steering.
    \item Through both high-fidelity simulations and hardware experiments, we demonstrate that updating the feedback gains at every iteration of the DeePO algorithm's execution is not necessary. In fact, updating the feedback gain in DeePO with lower frequencies can still maintain or even improve control performance.
\end{itemize}  

\subsection{Organization}
The rest of the paper is organized as follows: Section~\ref{sec:2} formally states the control problem and provides an overview of our unified control framework. Section~\ref{sec:3} outlines the details of the DeePO algorithm, including a regularizer for the initial policy and incorporating a forgetting factor into the framework. Section~\ref{sec:4} presents the simulation and experimental results. Finally, Section~\ref{sec:5} presents the concluding remarks. 


\subsection{Notation}
We use $I_n$ to denote the $n$-by-$n$ identity matrix. We use $\rho(\cdot)$ to denote the spectral radius of a square matrix. 
$A^\top$, $\text{Tr}(A)$, and $A^\dagger$ represent the transpose, trace, and pseudoinverse of matrix $A$, respectively. We use diag$(a, b, \dots, c)$ to denote a diagonal matrix with diagonal elements being $a,b,\dots,c$. The 2-norm of matrix $A$ is denoted $\|A\|$. We denote the continuous-time signal $x$ with $x(t)$ and discrete-time with $x\dt{t}$. 