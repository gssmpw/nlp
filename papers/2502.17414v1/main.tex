\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage{cvpr}

\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\todo}[1]{{\color{red}#1}}
\newcommand{\TODO}[1]{\textbf{\color{red}[TODO: #1]}}

\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}
\usepackage{multirow}
\usepackage{cuted}

\def\papername{X-Dancer}

\title{\papername: Expressive Music to Human Dance Video Generation }

\author{
    Zeyuan Chen$^{1,2}$ ~~~~
    Hongyi Xu$^{2}$~~~~
    Guoxian Song$^{2}$~~~~
    You Xie$^{2}$~~~~
    Chenxu Zhang$^{2}$~~~~\\
    Xin Chen$^{2}$~~~~
    Chao Wang$^{2}$~~~~
    Di Chang$^{2,3}$~~~~~
    Linjie Luo$^{2}$~~~~~
    \vspace{1.6pt}
    \\
    $^1$\normalsize UC San Diego~~~~$^2$\normalsize ByteDance~~~~
    $^3$\normalsize University of Southern California~~~~\\
}

\begin{document}
\maketitle

\begin{strip}
    \centering
    \vspace{-40pt}
    % \includegraphics[width=\textwidth]{figures/Teaser_ratio3.pdf}
    \includegraphics[width=1\textwidth]{figures/teaser_anonymized.pdf}
    \captionof{figure}{We present~\papername, a unified transformer-diffusion framework for zero-shot, music-driven human image animation from a single static image, capable of handling diverse body forms and appearances. Our method enables the synthesis of highly expressive and diverse full-body dance motions that are synchronized with music, including detailed movements at the head and hands, which are then seamlessly translated into vivid and lifelike dance videos. \textbf{Code and model will be available for research purposes.}}
    \label{fig:teaser}
    \vspace{-2mm}
\end{strip}


\input{sec/0_abstract}    
\input{sec/1_intro}
\input{sec/2_relatedwork}
\input{sec/3_method}
\input{sec/4_experiments}
\input{sec/5_conclusion}
{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}

\end{document}
