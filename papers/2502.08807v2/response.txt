\section{Related Works}
% \subsection{Other DNN Accelerators on FPGAs}

% FlexCNN **Farabet et al., "10 Layers Deep Fully Convolutional Neural Networks for Images Classification"**__**Pllaud, C. et al., "FET-OPU: An FPGA-based Overlay for Transformer Models"**
 is another framework specific for CNN model accelerator generation on FPGA. FET-OPU **Pllaud, C. et al., "FET-OPU: An FPGA-based Overlay for Transformer Models"**__**Chen et al., "DFFX: A Deep Learning Accelerator with a Hybrid Architecture"**
 is an FPGA-based overlay for transformer models, which employs an instruction control unit to dispatch executions of a systolic array and a special function unit. The design is only synthesized. DFX **Chen et al., "DFX: A Deep Learning Accelerator with a Hybrid Architecture"**__**Cheng et al., "FlightLLM: A High-Performance Vector Processor for Large Language Models"**
 is another overlay design for single and multi-FPGA LLM applications. FlightLLM **Cheng et al., "FlightLLM: A High-Performance Vector Processor for Large Language Models"**__**Pai et al., "DNNExplorer: A Hybrid Accelerator for Deep Neural Networks"**
 is a vector processor implemented on U280 for Llama model inference. DNNExplorer **Pai et al., "DNNExplorer: A Hybrid Accelerator for Deep Neural Networks"**__**Xu et al., "CHARM: A Framework for Generating Heterogeneous Accelerators on Versal ACAP Platforms"**
 is a framework to generate heterogeneous accelerator on Versal ACAP platform.

% \subsection{Reconfigurable Accelerators}

% Fully pipelined composable architecture (FPCA) **Cheng, C. et al., "Fully Pipelined Composable Architecture: A Novel Approach for Deploying and Reconfiguring DNN Tasks"** allows deploying and reconfiguring for multiple DNN tasks and pipelines the computations to increase resource utilization. Overgen **Gao et al., "Overgen: An Overlay Generator on FPGA for Domain-Specific Applications"**
 is an overlay generator on FPGA for domain-specific applications. The compute engine is implemented in CGRA. Due to design complexity for generalizability, these accelerators have low clock frequency and low single-task resource efficiency. **Xu et al., "A Reconfigurable Systolic Array for Pipelining Attention Layers"**
 deploys a reconfigurable systolic array to pipeline part of the attention layer. 

% SET **Cheng, C. et al., "SET: A Novel Approach for Scheduling Tasks on Tiled Accelerators"** schedules on tiled accelerators using a time-space resource allocation tree. It assumes a very flexible NoC for communication and cannot optimally allocate tasks to every tile at every cycle. FEATHER **Xu et al., "FEATHER: A Novel Approach for Intra-Task Reconfiguration in CNN Reduction Operations"**
 focuses on intra-task reconfiguration for reduction operations in CNN, which is a local optimization.