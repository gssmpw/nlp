\section{Related work}
\label{related}
Since their emergence, event-based cameras have gained significant attention in research, particularly in robotics and computer vision domains. Numerous recent studies have leveraged these cameras for various vision tasks, including object detection, pose estimation, and semantic segmentation. As our approach addresses semantic segmentation, this paper will delve into the current state-of-the-art achievements in this area using either ANNs or SNNs. Additionally, since we aim to leverage the high time resolution of events to enhance the processing of successive images—similar to video semantic segmentation—we will review the existing works in this domain, as well.
\subsection{Event-based semantic segmentation}
The pioneering work in event-based semantic segmentation is by Alonso et al. ____. They introduced the Davis Driven Dataset 2017 (DDD17), a novel event-based dataset, accompanied by semantic segmentation ground truth generated using an ANN trained on Cityscape ____. Their approach involved designing the Xception network, which accepts a $6$-channel input structure representing the mean, standard deviation, and accumulation of each polarity of events acquired over a $50ms$ interval which is $20Hz$. Subsequently, Gehrig et al. ____ addressed the limitations of the existing dataset by augmenting the training data with synthetic events from video sources, leading to performance improvements. Later, Wang et al. ____ innovatively transformed events into images and introduced knowledge distillation (KD), aiming to transfer knowledge from labelled images to unlabeled events ____. Pursuing a similar objective, Sun et al. ____ utilized unsupervised domain adaptation instead of KD. While these approaches primarily utilize ANNs for event processing, Zhang et al. ____ and Shristi et al. ____ employed hybrid networks comprising both SNN and ANN components. Zhang et al. ____ integrated ANNs into each block of their architecture, while Das et al. ____ fused events processed by SNN with images processed by ANN and fed the result to an ANN subnetwork. Finally, similarly to Kim et al. ____, we proposed fully spiking networks that process event accumulations acquired over a $50$ms interval ____
 
\subsection{Video semantic segmentation} %(Lundi)
As the demand for high accuracy and fast inference time increases, various techniques have been developed to perform video semantic segmentation more efficiently. These methods reuse features extracted by trained neural networks when there is minimal difference between consecutive video frames, thereby avoiding reprocessing every pixel in each frame using deep models. Before Transformers became widespread around $2019$, existing works such as ____, ____, ____ and ____ primarily used a two-part approach. If the similarity between the current frame and a keyframe is low, the current frame is processed by a deep neural network trained in semantic segmentation.
Conversely, if the similarity is high, a warp function is applied, which involves moving the semantic segmentation result of the keyframe based on the optical flow to the current frame, followed by a bilinear interpolation to determine the exact value of each pixel. These methods have been criticized for not considering temporal information, prompting researchers ____, ____, and ____ to introduce Transformers in their architectures to capture both spatial and temporal contexts. However, since Transformers rely heavily on matrix multiplications and extensive computations, they are unsuitable for spiking neural networks. Therefore, we focused on the first approach, particularly drawing inspiration from ____, since the other methods require an additional network for semantic segmentation on the current frame alongside the optical flow network, making the process slower and more computationally intensive. This method also uses dynamic video semantic segmentation, where the keyframes are changed dynamically over time rather than predefined.

\noindent Our approach addresses the semantic segmentation task using SNNs for their low power consumption. More particularly, we leverage the high time resolution from event-based cameras directly, unlike state-of-the-art methods that convert events into other formats like pseudo-frames or voxel grids ____ to process them similarly to dense images.