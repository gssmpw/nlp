% \section{Discussion}
% \label{sec:discussion}

%\subsection{Theoretical and Practical Implications}
%\label{subsec:implications}

%\paragraph{Implications in effectiveness.}
%Although previous studies explore the explainability of GEC, as detailed in Section~\ref{sec:related_works}, few of them investigate the interaction between the correction and the explanation tasks especially during the training process. Resorting to prompting LLMs, these studies usually rely heavily on the in-context abilities of LLMs and provide limited insights into the two tasks. However, our EXGEC represents the first attempt to combine the two tasks in a unified framework. By training multi-task EXGEC models in an end-to-end manner, the framework can often achieve significant improvement over the single-task baselines.%Moreover, we provide a thorough interpretation of the mutual influence between the two tasks when they are combined, along with a further discussion of their interactions.

%\paragraph{Implications in efficiency.}
%Additionally, as a multi-task framework, EXGEC models can concurrently solve the two tasks. We admit that the explanation performance of EXGEC is lower than that of BERT, but it can tremendously enhance the efficiency. Specifically, previous studies employ two respective systems for the correction and the explanation tasks, thus enlarging the training and deployment costs. In contrast, our method can execute the same tasks in a single model, thus significantly enhancing the efficiency.

% \subsection{Theoretical Implications}
% \label{subsec:theoretical_implications}

% From a theoretical perspective, the introduction of the EXGEC framework represents a pivotal contribution to the field of Grammatical Error Correction (GEC) by elucidating the interdependent relationship between correction and explanation tasks. In contrast to existing literature that typically treats these tasks in isolation, our research demonstrates that their integration fosters a synergistic effect, enhancing the overall efficacy of the correction process. This theoretical advancement not only enriches the understanding of explainability within GEC systems but also lays a robust foundation for future explorations into multi-task learning paradigms in natural language processing.

% \subsection{Practical Implications}
% \label{subsec:practical_implications}

% From a practical perspective, the EXGEC framework significantly optimizes the operational efficiency of GEC systems. By consolidating the explanation and correction tasks within a singular model architecture, our approach mitigates the resource-intensive demands associated with maintaining separate systems. Although there is a marginal decrease in explanation performance relative to benchmark models such as BERT, the resultant efficiencies are substantial. This integration reduces both training and deployment costs, rendering it a pragmatic solution for language learners who necessitate clear and actionable feedback on grammatical inaccuracies. Furthermore, the enhancements achieved with the refined EXPECT dataset underscore the framework's applicability in authentic educational settings, demonstrating its potential to provide high-quality corrections and explanations simultaneously.



% \subsection{Limitations}
% \label{subsec:limitations}

\section{Limitations}
\label{sec:limitations}

\paragraph{The limited nature of EXPECT.}
The explanations provided in the EXPECT and \Dataset{} datasets are confined to simple evidence words and types of grammatical errors. These may not be intuitive or comprehensive for L2 speakers, who are usually the primary users of educational GEC systems. However, our experiments demonstrate that the explanations can significantly aid the correction task by effectively utilizing the \Dataset{} dataset. In our future work, we aim to investigate more general free-text explanations in real-world GEC applications, presenting an encouraging direction for enhancing user-focused GEC systems.

EXPECT and \Dataset{} suppose only one grammatical error exists in a sentence, which is a less realistic setting. Due to the undeveloped research on the explainability of GEC, there are few high-quality datasets to study. Focusing on the \Dataset{} dataset, our experiments follow the setting even though the proposed EXGEC can flexibly adapt to other real-life settings.

\paragraph{Inherent nature of generative language models.}
It has been observed that the backbone models we employ, specifically BART, T5, and Llama3, exhibit deficiencies in classifying grammatical errors when compared to BERT-based models. This shortcoming can be ascribed to their fundamental characteristics as generative language models. Such limitations may adversely affect correction performance, especially in post-explanatory models that rectify sentences by relying on previously forecasted explanations. Our future research intends to explore more effective methodologies for managing and integrating both these tasks.


% \paragraph{Inflexibility of structured explanations.}
% In the era of large language models (LLMs), it has become increasingly practical and favorable to express explanations as free-form natural language texts. However, in this particular paper, we focus our studies on structured explanations due to the limited availability of free-form explanations in the field of GEC. Nevertheless, we are committed to advancing the development of explainable GEC datasets in our future work, aiming to incorporate more sophisticated and comprehensive approaches.

% \paragraph{No LLMs are studied in this work.}
% This work focuses on the improvement of explanations on GEC tasks using pre-trained language models (PLMs), rather than large language models (LLMs), due to temporary constraints in computation resources. Our proposed EXGEC framework formulates explainable GEC as a generative problem, which has become more prevalent in the era of LLMs. Despite its simplicity, EXGEC performs highly in the two tasks. We believe the current framework is flexible and adaptable for the evolution of LLMs, as EXGEC can be readily extended to miscellaneous explanations, including free-form rationales. Given the prosperity of LLMs, we are willing to conduct experiments using LLMs in our future work.

