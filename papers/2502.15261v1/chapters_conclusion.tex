\section{Conclusion}
\label{sec:conclusion}

This paper aims to improve the explainability of GEC systems. To this end, we introduce \Method{}, a unified generative framework that simultaneously performs correction and explanation tasks. The framework empirically explores and establishes the interaction between the two tasks. We then identify the potential drawback of EXPECT and propose \Dataset{}. Results on three language models reveal performance enhancement when multi-task learning correction and explanation tasks. In the future, we plan to extend our framework to free-text explanations.



% 2024-11-22 Deprecated
% This paper aims to improve the explainability of GEC. To this end, we introduce \Method{}, a unified generative framework that simultaneously performs correction and explanation tasks. The framework is adaptable to various training and inference settings, helping us empirically explore the interaction between the two tasks. When experimenting with the Infusion models, we reveal the impact of error types and evidence words on the correction task. Moreover, the self-Rationalization setting of \Method{} serves as a conduit between corrections and explanations, achieving positive effects in each task. We also pinpoint a limitation in EXPECT and present our own \Dataset{}, which offers a more unbiased and dependable training and evaluation dataset.

% We apply the proposed framework mainly in \Dataset{}. We showcase the frameworkâ€™s effectiveness in achieving strong experimental results across three language models. Our analysis emphasizes the considerable potential of \Method{}, attributing its effectiveness to the generative design prevailing in the era. In the future, we plan to extend our framework to free-text explanations, which are crucial for education applications.



% \section*{Ethics Statement}
% Our study revealed significant noise in the original EXPECT dataset, undermining model training and evaluation. To mitigate this, we refined the EXPECT dataset to eliminate the noise, ensuring an impartial training and evaluation system. We relied exclusively on publicly available data from authorized sources, guaranteeing the non-inclusion of sensitive information. Moreover, all baselines and datasets used in our research are publicly accessible, and appropriate credits have been given by citing the original authors.


% The source data for these methods is obtained exclusively from publicly available project resources on legitimate websites, without any involvement of sensitive information.
% Additionally, all the baselines and datasets used in our experiments are also publicly accessible, and we have acknowledged the corresponding authors by citing their work.