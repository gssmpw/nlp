\input{expect_examples}
\input{datasets}

\section{\Dataset{} Dataset}
\label{sec:dataset}
Our experiments employ the EXPECT dataset~\citep{fei-etal-2023-enhancing} with human-labeled explanations instead of other LLM-generated explanations~\citep{song-etal-2024-gee}, ensuring the reliability of explanations. The source and target sentences of EXPECT draw from W\&I+LOCNESS~\citep{bryant-etal-2019-bea}, an explanation-free GEC dataset encompassing a broader spectrum of English proficiency levels. EXPECT follows a unique methodology for task simplification. Specifically, for a W\&I+LOCNESS sentence with $n$ grammatical errors, the sentence is replicated $n$ times, each time keeping only one individual error. Considering the complexities of explainable GEC, this approach is sensible and preferred, as it simplifies the task by isolating and extracting evidence for one grammatical error at a time, thereby avoiding the confusion caused by multiple interacting errors within a single sentence.

However, we contend that the original EXPECT dataset includes unidentified grammatical errors, thus biasing the training and the evaluation process. For original sentences with $n$ $(n>1)$ grammatical errors from W\&I+LOCNESS, the authors of EXPECT correct a single error and leave the remaining $n-1$ errors uncorrected, as illustrated in Table~\ref{tab:expect_examples}. These uncorrected errors can confuse models, creating uncertainty about which error to correct and explain, thus complicating model training and evaluation.

% To solve this issue, we re-correct the uncorrected grammatical errors, maintaining the original single grammatical error in EXPECT. This rebuilding process is automated as we re-correct all uncorrected grammatical errors by comparing sentences from EXPECT and W\&I+LOCNESS. We first retrieve the original parallel samples of W\&I+LOCNESS using the open-source toolkit \texttt{TheFuzz}\footnote{\url{https://github.com/seatgeek/thefuzz}}, and then identify and correct the underlying grammatical errors using GEC evaluation tools \texttt{ERRANT}~\citep{bryant-etal-2017-automatic}. It is noteworthy that the grammatical errors, evidence words, and error types of EXPECT and the \Dataset{} datasets are preserved during the reconstruction, with the exception of a few extreme cases\footnote{One sample from the dev set and one sample from the test set lack evidence words since they overlap with the uncorrected grammatical errors.}. In total, 277 (1.82\%), 1,311 (54.33\%), and 1,323 (54.76\%) sentences in our reconstructed training, development, and test sets, respectively, differ from their original sentences in EXPECT. All these changed samples are detected with unidentified grammatical errors and they are re-corrected in \Dataset{}. \Dataset{} makes sure that the evidence words and the error types correspond to the single grammatical error, thus leading to unbiased training and evaluation. Detailed statistics of the datasets are provided in Table~\ref{tab:dataset}.


To address this issue, we re-correct the previously overlooked grammatical errors while preserving the original single error in EXPECT. This rebuilding process is fully automated. Specifically, we re-correct all uncorrected errors by comparing sentences from EXPECT with those in W\&I+LOCNESS. First, we retrieve the original parallel samples from W\&I+LOCNESS using the open-source toolkit TheFuzz\footnote{\url{https://github.com/seatgeek/thefuzz}}. Then, we identify and correct the underlying grammatical errors using GEC evaluation tools ERRANT~\citep{bryant-etal-2017-automatic} and CLEME~\citep{ye2023cleme}. Notably, during the reconstruction, the grammatical errors, evidence words, and error types in both the EXPECT and \Dataset{} datasets are preserved, except in a few extreme cases (one sample from the development set and one from the test set lack evidence words due to overlapping with the uncorrected errors). In total, 277 (1.82\%), 1,311 (54.33\%), and 1,323 (54.76\%) sentences in our reconstructed training, development, and test sets, respectively, differ from their originals in EXPECT. All these altered samples, initially detected with unidentified grammatical errors, are subsequently re-corrected in \Dataset{}. By ensuring that the evidence words and error types align with the single remaining grammatical error, \Dataset{} facilitates unbiased training and evaluation. Detailed dataset statistics are provided in Table~\ref{tab:dataset}.
