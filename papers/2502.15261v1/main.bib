@article{bryant2023grammatical,
  title={Grammatical error correction: A survey of the state of the art},
  author={Bryant, Christopher and Yuan, Zheng and Qorib, Muhammad Reza and Cao, Hannan and Ng, Hwee Tou and Briscoe, Ted},
  journal={Computational Linguistics},
  volume={49},
  number={3},
  pages={643--701},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@book{skehan1998cognitive,
  title={A cognitive approach to language learning},
  author={Skehan, Peter},
  year={1998},
  publisher={Oxford University Press}
}

@article{shichungui,
  title={A cognitive model of corpus-based analysis of Chinese learners' errors of English},
  author={Shichun Gui},
  journal={Modern Foreign Languages(Quarterly)},
  volume={27},
  number={2},
  pages={129--139},
  year={2004}
}

@inproceedings{li2022unifying,
  title={Unifying Model Explainability and Robustness for Joint Text Classification and Rationale Extraction},
  author={Li, Dongfang and Hu, Baotian and Chen, Qingcai and Xu, Tujie and Tao, Jingcong and Zhang, Yunan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={10947--10955},
  year={2022}
}

@inproceedings{wang2022recent,
  title={Recent Development on Extractive Rationale for Model Interpretability: A Survey},
  author={Wang, Hao and Dou, Yong},
  booktitle={2022 International Conference on Cloud Computing, Big Data and Internet of Things (3CBIT)},
  pages={354--358},
  year={2022},
  organization={IEEE}
}

@article{narang2020wt5,
  title={Wt5?! training text-to-text models to explain their predictions},
  author={Narang, Sharan and Raffel, Colin and Lee, Katherine and Roberts, Adam and Fiedel, Noah and Malkan, Karishma},
  journal={arXiv preprint arXiv:2004.14546},
  year={2020}
}

@inproceedings{majumder2022knowledge,
  title={Knowledge-Grounded Self-Rationalization via Extractive and Natural Language Explanations},
  author={Majumder, Bodhisattwa Prasad and Camburu, Oana and Lukasiewicz, Thomas and Mcauley, Julian},
  booktitle={International Conference on Machine Learning},
  pages={14786--14801},
  year={2022},
  organization={PMLR}
}

@article{zhao2023explainability,
  title={Explainability for Large Language Models: A Survey},
  author={Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
  journal={arXiv preprint arXiv:2309.01029},
  year={2023}
}

@article{vinyals2015pointer,
  title={Pointer networks},
  author={Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{
li2024explanations,
title={Explanations from Large Language Models Make Small Reasoners Better},
author={Shiyang Li and Jianshu Chen and yelong shen and Zhiyu Chen and Xinlu Zhang and Zekun Li and Hong Wang and Jing Qian and Baolin Peng and Yi Mao and Wenhu Chen and Xifeng Yan},
booktitle={2nd Workshop on Sustainable AI},
year={2024},
url={https://openreview.net/forum?id=rH8ZUcfL9r}
}

@article{kaneko2023controlled,
  title={Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction},
  author={Kaneko, Masahiro and Okazaki, Naoaki},
  journal={arXiv preprint arXiv:2309.11439},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ott2019fairseq,
  title={fairseq: A fast, extensible toolkit for sequence modeling},
  author={Ott, Myle and Edunov, Sergey and Baevski, Alexei and Fan, Angela and Gross, Sam and Ng, Nathan and Grangier, David and Auli, Michael},
  journal={arXiv preprint arXiv:1904.01038},
  year={2019}
}

@article{bitchener2005effect,
  title={The effect of different types of corrective feedback on ESL student writing},
  author={Bitchener, John and Young, Stuart and Cameron, Denise},
  journal={Journal of second language writing},
  volume={14},
  number={3},
  pages={191--205},
  year={2005},
  publisher={Elsevier}
}

@article{sheen2007effect,
  title={The effect of focused written corrective feedback and language aptitude on ESL learners' acquisition of articles},
  author={Sheen, Younghee},
  journal={TESOL quarterly},
  volume={41},
  number={2},
  pages={255--283},
  year={2007},
  publisher={Wiley Online Library}
}

@article{ye2023cleme,
  title={CLEME: Debiasing Multi-reference Evaluation for Grammatical Error Correction},
  author={Ye, Jingheng and Li, Yinghui and Zhou, Qingyu and Li, Yangning and Ma, Shirong and Zheng, Hai-Tao and Shen, Ying},
  journal={arXiv preprint arXiv:2305.10819},
  year={2023}
}

@article{chu2023survey,
  title={A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future},
  author={Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
  journal={arXiv preprint arXiv:2309.15402},
  year={2023}
}

@article{li2023symbolic,
  title={Symbolic Chain-of-Thought Distillation: Small Models Can Also" Think" Step-by-Step},
  author={Li, Liunian Harold and Hessel, Jack and Yu, Youngjae and Ren, Xiang and Chang, Kai-Wei and Choi, Yejin},
  journal={arXiv preprint arXiv:2306.14050},
  year={2023}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@misc{touvron2023llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{ye-etal-2023-mixedit,
    title = "{M}ix{E}dit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction",
    author = "Ye, Jingheng  and
      Li, Yinghui  and
      Li, Yangning  and
      Zheng, Hai-Tao",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.681",
    doi = "10.18653/v1/2023.findings-emnlp.681",
    pages = "10161--10175",
    abstract = "Data Augmentation through generating pseudo data has been proven effective in mitigating the challenge of data scarcity in the field of Grammatical Error Correction (GEC). Various augmentation strategies have been widely explored, most of which are motivated by two heuristics, i.e., increasing the distribution similarity and diversity of pseudo data. However, the underlying mechanism responsible for the effectiveness of these strategies remains poorly understood. In this paper, we aim to clarify how data augmentation improves GEC models. To this end, we introduce two interpretable and computationally efficient measures: Affinity and Diversity. Our findings indicate that an excellent GEC data augmentation strategy characterized by high Affinity and appropriate Diversity can better improve the performance of GEC models. Based on this observation, we propose MixEdit, a data augmentation approach that strategically and dynamically augments realistic data, without requiring extra monolingual corpora. To verify the correctness of our findings and the effectiveness of the proposed MixEdit, we conduct experiments on mainstream English and Chinese GEC datasets. The results show that MixEdit substantially improves GEC models and is complementary to traditional data augmentation methods. All the source codes of MixEdit are released at https://github.com/THUKElab/MixEdit.",
}


@article{ye2022focus,
  title={Focus is what you need for chinese grammatical error correction},
  author={Ye, Jingheng and Li, Yinghui and Ma, Shirong and Xie, Rui and Wu, Wei and Zheng, Hai-Tao},
  journal={arXiv preprint arXiv:2210.12692},
  year={2022}
}

@inproceedings{huang-etal-2023-frustratingly,
    title = "A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for {C}hinese Spelling Check",
    author = "Huang, Haojing  and
      Ye, Jingheng  and
      Zhou, Qingyu  and
      Li, Yinghui  and
      Li, Yangning  and
      Zhou, Feng  and
      Zheng, Hai-Tao",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.771",
    doi = "10.18653/v1/2023.findings-emnlp.771",
    pages = "11514--11525",
    abstract = "In recent years, Chinese Spelling Check (CSC) has been greatly improved by designing task-specific pre-training methods or introducing auxiliary tasks, which mostly solve this task in an end-to-end fashion. In this paper, we propose to decompose the CSC workflow into detection, reasoning, and searching subtasks so that the rich external knowledge about the Chinese language can be leveraged more directly and efficiently. Specifically, we design a plug-and-play detection-and-reasoning module that is compatible with existing SOTA non-autoregressive CSC models to further boost their performance. We find that the detection-and-reasoning module trained for one model can also benefit other models. We also study the primary interpretability provided by the task decomposition. Extensive experiments and detailed analyses demonstrate the effectiveness and competitiveness of the proposed module.",
}

@inproceedings{song-etal-2024-gee,
    title = "{GEE}! Grammar Error Explanation with Large Language Models",
    author = "Song, Yixiao  and
      Krishna, Kalpesh  and
      Bhatt, Rajesh  and
      Gimpel, Kevin  and
      Iyyer, Mohit",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.49",
    doi = "10.18653/v1/2024.findings-naacl.49",
    pages = "754--781",
    abstract = "Existing grammatical error correction tools do not provide natural language explanations of the errors that they correct in user-written text. However, such explanations are essential for helping users learn the language by gaining a deeper understanding of its grammatical rules (DeKeyser, 2003; Ellis et al., 2006).To address this gap, we propose the task of grammar error explanation, where a system needs to provide one-sentence explanations for each grammatical error in a pair of erroneous and corrected sentences. The task is not easily solved by prompting LLMs: we find that, using one-shot prompting, GPT-4 only explains 40.6{\%} of the errors and does not even attempt to explain 39.8{\%} of the errors.Since LLMs struggle to identify grammar errors, we develop a two-step pipeline that leverages fine-tuned and prompted large language models to perform structured atomic token edit extraction, followed by prompting GPT-4 to explain each edit. We evaluate our pipeline on German, Chinese, and English grammar error correction data. Our atomic edit extraction achieves an F1 of 0.93 on German, 0.91 on Chinese, and 0.891 on English. Human evaluation of generated explanations reveals that 93.9{\%} of German errors, 96.4{\%} of Chinese errors, and 92.20{\%} of English errors are correctly detected and explained. To encourage further research, we open-source our data and code.",
}

@inproceedings{kaneko-okazaki-2024-controlled,
    title = "Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction",
    author = "Kaneko, Masahiro  and
      Okazaki, Naoaki",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.350",
    pages = "3955--3961",
    abstract = "In Grammatical Error Correction (GEC), it is crucial to ensure the user{'}s comprehension of a reason for correction. Existing studies present tokens, examples, and hints for corrections, but do not directly explain the reasons in natural language. Although methods that use Large Language Models (LLMs) to provide direct explanations in natural language have been proposed for various tasks, no such method exists for GEC. Generating explanations for GEC corrections involves aligning input and output tokens, identifying correction points, and presenting corresponding explanations consistently. However, it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts. This study introduces a method called controlled generation with Prompt Insertion (PI) so that LLMs can explain the reasons for corrections in natural language. In PI, LLMs first correct the input text, and then we automatically extract the correction points based on the rules. The extracted correction points are sequentially inserted into the LLM{'}s explanation output as prompts, guiding the LLMs to generate explanations for the correction points. We also create an Explainable GEC (XGEC) dataset of correction reasons by annotating NUCLE, CoNLL2013, and CoNLL2014. Although generations from GPT-3.5 and ChatGPT using original prompts miss some correction points, the generation control using PI can explicitly guide to describe explanations for all correction points, contributing to improved performance in generating correction reasons.",
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@inproceedings{
    hu2022lora,
    title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
    author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=nZeVKeeFYf9}
}


@inproceedings{wang-etal-2024-improving-grammatical,
    title = "Improving Grammatical Error Correction via Contextual Data Augmentation",
    author = "Wang, Yixuan  and
      Wang, Baoxin  and
      Liu, Yijun  and
      Zhu, Qingfu  and
      Wu, Dayong  and
      Che, Wanxiang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.647",
    pages = "10898--10910",
    abstract = "Nowadays, data augmentation through synthetic data has been widely used in the field of Grammatical Error Correction (GEC) to alleviate the problem of data scarcity. However, these synthetic data are mainly used in the pre-training phase rather than the data-limited fine tuning phase due to inconsistent error distribution and noisy labels. In this paper, we propose a synthetic data construction method based on contextual augmentation, which can ensure an efficient augmentation of the original data with a more consistent error distribution. Specifically, we combine rule-based substitution with model-based generation, using the generation model to generate a richer context for the extracted error patterns. Besides, we also propose a relabeling-based data cleaning method to mitigate the effects of noisy labels in synthetic data. Experiments on CoNLL14 and BEA19-Test show that our proposed augmentation method consistently and substantially outperforms strong baselines and achieves the state-of-the-art level with only a few synthetic data.",
}

@article{ye2024cleme2,
  title={CLEME2. 0: Towards More Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction},
  author={Ye, Jingheng and Xu, Zishan and Li, Yinghui and Cheng, Xuxin and Song, Linlin and Zhou, Qingyu and Zheng, Hai-Tao and Shen, Ying and Su, Xin},
  journal={arXiv preprint arXiv:2407.00934},
  year={2024}
}

@article{li2024rethinking,
  title={Rethinking the Roles of Large Language Models in Chinese Grammatical Error Correction},
  author={Li, Yinghui and Qin, Shang and Ye, Jingheng and Ma, Shirong and Li, Yangning and Qin, Libo and Hu, Xuming and Jiang, Wenhao and Zheng, Hai-Tao and Yu, Philip S},
  journal={arXiv preprint arXiv:2402.11420},
  year={2024}
}

@inproceedings{ye2023system,
  title={System report for CCL23-eval task 7: THU KELab (sz)-exploring data augmentation and denoising for Chinese grammatical error correction},
  author={Ye, Jingheng and Li, Yinghui and Zheng, Haitao},
  booktitle={Proceedings of the 22nd Chinese National Conference on Computational Linguistics (Volume 3: Evaluations)},
  pages={262--270},
  year={2023}
}

@inproceedings{davis-etal-2024-prompting,
    title = "Prompting open-source and commercial language models for grammatical error correction of {E}nglish learner text",
    author = "Davis, Christopher  and
      Caines, Andrew  and
      Andersen, O  and
      Taslimipoor, Shiva  and
      Yannakoudakis, Helen  and
      Yuan, Zheng  and
      Bryant, Christopher  and
      Rei, Marek  and
      Buttery, Paula",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.711",
    pages = "11952--11967",
    abstract = "Thanks to recent advances in generative AI, we are able to prompt large language models (LLMs) to produce texts which are fluent and grammatical. In addition, it has been shown that we can elicit attempts at grammatical error correction (GEC) from LLMs when prompted with ungrammatical input sentences. We evaluate how well LLMs can perform at GEC by measuring their performance on established benchmark datasets. We go beyond previous studies, which only examined GPT* models on a selection of English GEC datasets, by evaluating seven open-source and three commercial LLMs on four established GEC benchmarks. We investigate model performance and report results against individual error types. Our results indicate that LLMs do not always outperform supervised English GEC models except in specific contexts {--} namely commercial LLMs on benchmarks annotated with fluency corrections as opposed to minimal edits. We find that several open-source models outperform commercial ones on minimal edit benchmarks, and that in some settings zero-shot prompting is just as competitive as few-shot prompting.",
}


@inproceedings{dalal-etal-2024-inference,
    title = "Inference to the Best Explanation in Large Language Models",
    author = "Dalal, Dhairya  and
      Valentino, Marco  and
      Freitas, Andre  and
      Buitelaar, Paul",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.14",
    pages = "217--235",
    abstract = "While Large Language Models (LLMs) have found success in real-world applications, their underlying explanatory process is still poorly understood. This paper proposes \textit{IBE-Eval}, a framework inspired by philosophical accounts on \textit{Inference to the Best Explanation (IBE)} to advance the interpretation and evaluation of LLMs{'} explanations. \textit{IBE-Eval} estimates the plausibility of natural language explanations through a combination of explicit logical and linguistic features including: \textit{consistency}, \textit{parsimony}, \textit{coherence}, and \textit{uncertainty}. Extensive experiments are conducted on \textit{Causal Question Answering (CQA)}, where \textit{IBE-Eval} is tasked to select the most plausible causal explanation amongst competing ones generated by LLMs (i.e., GPT 3.5 and Llama 2). The experiments reveal that \textit{IBE-Eval} can successfully identify the best explanation with up to 77{\%} accuracy ($\approx 27\%$ above random), improving upon a GPT 3.5-as-a-Judge baseline ($\approx+17\%$) while being intrinsically more efficient and interpretable. Additional analyses suggest that, despite model-specific variances, LLM-generated explanations tend to conform to IBE criteria and that \textit{IBE-Eval} is significantly correlated with human judgment, opening up opportunities for future development of automated explanation verification tools.",
}

@inproceedings{hu2024learning,
  title={Learning Robust Rationales for Model Explainability: A Guidance-Based Approach},
  author={Hu, Shuaibo and Yu, Kui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={18243--18251},
  year={2024}
}

@article{saeed2024sumex,
  title={SUMEX: A hybrid framework for Semantic textUal siMilarity and EXplanation generation},
  author={Saeed, Sumaira and Rajput, Quratulain and Haider, Sajjad},
  journal={Information Processing \& Management},
  volume={61},
  number={5},
  pages={103771},
  year={2024},
  publisher={Elsevier}
}

@article{zhang2024elad,
  title={ELAD: Explanation-Guided Large Language Models Active Distillation},
  author={Zhang, Yifei and Pan, Bo and Ling, Chen and Hu, Yuntong and Zhao, Liang},
  journal={arXiv preprint arXiv:2402.13098},
  year={2024}
}

@inproceedings{madsen-etal-2024-self,
    title = "Are self-explanations from Large Language Models faithful?",
    author = "Madsen, Andreas  and
      Chandar, Sarath  and
      Reddy, Siva",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.19",
    doi = "10.18653/v1/2024.findings-acl.19",
    pages = "295--337",
    abstract = "Instruction-tuned Large Language Models (LLMs) excel at many tasks and will even explain their reasoning, so-called self-explanations. However, convincing and wrong self-explanations can lead to unsupported confidence in LLMs, thus increasing risk. Therefore, it{'}s important to measure if self-explanations truly reflect the model{'}s behavior. Such a measure is called interpretability-faithfulness and is challenging to perform since the ground truth is inaccessible, and many LLMs only have an inference API. To address this, we propose employing self-consistency checks to measure faithfulness. For example, if an LLM says a set of words is important for making a prediction, then it should not be able to make its prediction without these words. While self-consistency checks are a common approach to faithfulness, they have not previously been successfully applied to LLM self-explanations for counterfactual, feature attribution, and redaction explanations. Our results demonstrate that faithfulness is explanation, model, and task-dependent, showing self-explanations should not be trusted in general. For example, with sentiment classification, counterfactuals are more faithful for Llama2, feature attribution for Mistral, and redaction for Falcon 40B.",
}

@inproceedings{huang-etal-2024-chatgpt,
    title = "{C}hat{GPT} Rates Natural Language Explanation Quality like Humans: But on Which Scales?",
    author = "Huang, Fan  and
      Kwak, Haewoon  and
      Park, Kunwoo  and
      An, Jisun",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.277",
    pages = "3111--3132",
    abstract = "As AI becomes more integral in our lives, the need for transparency and responsibility grows. While natural language explanations (NLEs) are vital for clarifying the reasoning behind AI decisions, evaluating them through human judgments is complex and resource-intensive due to subjectivity and the need for fine-grained ratings. This study explores the alignment between ChatGPT and human assessments across multiple scales (i.e., binary, ternary, and 7-Likert scale). We sample 300 data instances from three NLE datasets and collect 900 human annotations for both informativeness and clarity scores as the text quality measurement. We further conduct paired comparison experiments under different ranges of subjectivity scores, where the baseline comes from 8,346 human annotations. Our results show that ChatGPT aligns better with humans in more coarse-grained scales. Also, paired comparisons and dynamic prompting (i.e., providing semantically similar examples in the prompt) improve the alignment. This research advances our understanding of large language models{'} capabilities to assess the text explanation quality in different configurations for responsible AI development.",
}


@article{lyu-etal-2024-towards,
    title = "Towards Faithful Model Explanation in {NLP}: A Survey",
    author = "Lyu, Qing  and
      Apidianaki, Marianna  and
      Callison-Burch, Chris",
    journal = "Computational Linguistics",
    volume = "50",
    number = "2",
    month = jun,
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.cl-2.6",
    doi = "10.1162/coli_a_00511",
    pages = "657--723",
    abstract = "End-to-end neural Natural Language Processing (NLP) models are notoriously difficult to understand. This has given rise to numerous efforts towards model explainability in recent years. One desideratum of model explanation is faithfulness, that is, an explanation should accurately represent the reasoning process behind the model{'}s prediction. In this survey, we review over 110 model explanation methods in NLP through the lens of faithfulness. We first discuss the definition and evaluation of faithfulness, as well as its significance for explainability. We then introduce recent advances in faithful explanation, grouping existing approaches into five categories: similarity-based methods, analysis of model-internal structures, backpropagation-based methods, counterfactual intervention, and self-explanatory models. For each category, we synthesize its representative studies, strengths, and weaknesses. Finally, we summarize their common virtues and remaining challenges, and reflect on future work directions towards faithful explainability in NLP.",
}

@inproceedings{nagata2020creating,
  title={Creating corpora for research in feedback comment generation},
  author={Nagata, Ryo and Inui, Kentaro and Ishikawa, Shin’ichiro},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={340--345},
  year={2020}
}

@article{DBLP:journals/patterns/LiuLTLZ22,
  author       = {Ruiyang Liu and
                  Yinghui Li and
                  Linmi Tao and
                  Dun Liang and
                  Hai{-}Tao Zheng},
  title        = {Are we ready for a new paradigm shift? {A} survey on visual deep {MLP}},
  journal      = {Patterns},
  volume       = {3},
  number       = {7},
  pages        = {100520},
  year         = {2022},
  url          = {https://doi.org/10.1016/j.patter.2022.100520},
  doi          = {10.1016/J.PATTER.2022.100520},
  timestamp    = {Fri, 29 Jul 2022 14:21:51 +0200},
  biburl       = {https://dblp.org/rec/journals/patterns/LiuLTLZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/acl/LiZLLLSWLCZ22,
  author       = {Yinghui Li and
                  Qingyu Zhou and
                  Yangning Li and
                  Zhongli Li and
                  Ruiyang Liu and
                  Rongyi Sun and
                  Zizhen Wang and
                  Chao Li and
                  Yunbo Cao and
                  Hai{-}Tao Zheng},
  editor       = {Smaranda Muresan and
                  Preslav Nakov and
                  Aline Villavicencio},
  title        = {The Past Mistake is the Future Wisdom: Error-driven Contrastive Probability
                  Optimization for Chinese Spell Checking},
  booktitle    = {Findings of the Association for Computational Linguistics: {ACL} 2022,
                  Dublin, Ireland, May 22-27, 2022},
  pages        = {3202--3213},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.findings-acl.252},
  doi          = {10.18653/V1/2022.FINDINGS-ACL.252},
  timestamp    = {Wed, 07 Dec 2022 23:10:02 +0100},
  biburl       = {https://dblp.org/rec/conf/acl/LiZLLLSWLCZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2307-09007,
  author       = {Yinghui Li and
                  Haojing Huang and
                  Shirong Ma and
                  Yong Jiang and
                  Yangning Li and
                  Feng Zhou and
                  Hai{-}Tao Zheng and
                  Qingyu Zhou},
  title        = {On the (In)Effectiveness of Large Language Models for Chinese Text
                  Correction},
  journal      = {CoRR},
  volume       = {abs/2307.09007},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.09007},
  doi          = {10.48550/ARXIV.2307.09007},
  eprinttype    = {arXiv},
  eprint       = {2307.09007},
  timestamp    = {Wed, 28 Aug 2024 10:14:15 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2307-09007.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/emnlp/MaLSZHZLLLCZS22,
  author       = {Shirong Ma and
                  Yinghui Li and
                  Rongyi Sun and
                  Qingyu Zhou and
                  Shulin Huang and
                  Ding Zhang and
                  Yangning Li and
                  Ruiyang Liu and
                  Zhongli Li and
                  Yunbo Cao and
                  Haitao Zheng and
                  Ying Shen},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {Linguistic Rules-Based Corpus Generation for Native Chinese Grammatical
                  Error Correction},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022},
  pages        = {576--589},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.findings-emnlp.40},
  doi          = {10.18653/V1/2022.FINDINGS-EMNLP.40},
  timestamp    = {Sun, 06 Oct 2024 21:00:51 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/MaLSZHZLLLCZS22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/emnlp/LiMZLLHLLC022,
  author       = {Yinghui Li and
                  Shirong Ma and
                  Qingyu Zhou and
                  Zhongli Li and
                  Yangning Li and
                  Shulin Huang and
                  Ruiyang Liu and
                  Chao Li and
                  Yunbo Cao and
                  Haitao Zheng},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {Learning from the Dictionary: Heterogeneous Knowledge Guided Fine-tuning
                  for Chinese Spell Checking},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022},
  pages        = {238--249},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.findings-emnlp.18},
  doi          = {10.18653/V1/2022.FINDINGS-EMNLP.18},
  timestamp    = {Thu, 10 Aug 2023 12:35:40 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/LiMZLLHLLC022.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/emnlp/YeLZLM0023,
  author       = {Jingheng Ye and
                  Yinghui Li and
                  Qingyu Zhou and
                  Yangning Li and
                  Shirong Ma and
                  Hai{-}Tao Zheng and
                  Ying Shen},
  editor       = {Houda Bouamor and
                  Juan Pino and
                  Kalika Bali},
  title        = {{CLEME:} Debiasing Multi-reference Evaluation for Grammatical Error
                  Correction},
  booktitle    = {Proceedings of the 2023 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2023, Singapore, December 6-10, 2023},
  pages        = {6174--6189},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.emnlp-main.378},
  doi          = {10.18653/V1/2023.EMNLP-MAIN.378},
  timestamp    = {Sun, 06 Oct 2024 21:00:54 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/YeLZLM0023.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/acl/LiXC0LMJLZZS24,
  author       = {Yinghui Li and
                  Zishan Xu and
                  Shaoshen Chen and
                  Haojing Huang and
                  Yangning Li and
                  Shirong Ma and
                  Yong Jiang and
                  Zhongli Li and
                  Qingyu Zhou and
                  Hai{-}Tao Zheng and
                  Ying Shen},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {Towards Real-World Writing Assistance: {A} Chinese Character Checking
                  Benchmark with Faked and Misspelled Characters},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {8656--8668},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.469},
  doi          = {10.18653/V1/2024.ACL-LONG.469},
  timestamp    = {Tue, 24 Sep 2024 10:55:52 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/LiXC0LMJLZZS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icassp/ZhangLZMLCZ23,
  author       = {Ding Zhang and
                  Yinghui Li and
                  Qingyu Zhou and
                  Shirong Ma and
                  Yangning Li and
                  Yunbo Cao and
                  Hai{-}Tao Zheng},
  title        = {Contextual Similarity is More Valuable Than Character Similarity:
                  An Empirical Study for Chinese Spell Checking},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing
                  {ICASSP} 2023, Rhodes Island, Greece, June 4-10, 2023},
  pages        = {1--5},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/ICASSP49357.2023.10095675},
  doi          = {10.1109/ICASSP49357.2023.10095675},
  timestamp    = {Sun, 19 Jan 2025 13:18:24 +0100},
  biburl       = {https://dblp.org/rec/conf/icassp/ZhangLZMLCZ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/emnlp/DuW0D0LZVZSZGL024,
  author       = {Jiangshu Du and
                  Yibo Wang and
                  Wenting Zhao and
                  Zhongfen Deng and
                  Shuaiqi Liu and
                  Renze Lou and
                  Henry Peng Zou and
                  Pranav Narayanan Venkit and
                  Nan Zhang and
                  Mukund Srinath and
                  Haoran Zhang and
                  Vipul Gupta and
                  Yinghui Li and
                  Tao Li and
                  Fei Wang and
                  Qin Liu and
                  Tianlin Liu and
                  Pengzhi Gao and
                  Congying Xia and
                  Chen Xing and
                  Cheng Jiayang and
                  Zhaowei Wang and
                  Ying Su and
                  Raj Sanjay Shah and
                  Ruohao Guo and
                  Jing Gu and
                  Haoran Li and
                  Kangda Wei and
                  Zihao Wang and
                  Lu Cheng and
                  Surangika Ranathunga and
                  Meng Fang and
                  Jie Fu and
                  Fei Liu and
                  Ruihong Huang and
                  Eduardo Blanco and
                  Yixin Cao and
                  Rui Zhang and
                  Philip S. Yu and
                  Wenpeng Yin},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {LLMs Assist {NLP} Researchers: Critique Paper (Meta-)Reviewing},
  booktitle    = {Proceedings of the 2024 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2024, Miami, FL, USA, November 12-16,
                  2024},
  pages        = {5081--5099},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.emnlp-main.292},
  timestamp    = {Thu, 20 Feb 2025 07:33:49 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/DuW0D0LZVZSZGL024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/eswa/LiMCHHLZS25,
  author       = {Yinghui Li and
                  Shirong Ma and
                  Shaoshen Chen and
                  Haojing Huang and
                  Shulin Huang and
                  Yangning Li and
                  Hai{-}Tao Zheng and
                  Ying Shen},
  title        = {Correct like humans: Progressive learning framework for Chinese text
                  error correction},
  journal      = {Expert Syst. Appl.},
  volume       = {265},
  pages        = {126039},
  year         = {2025},
  url          = {https://doi.org/10.1016/j.eswa.2024.126039},
  doi          = {10.1016/J.ESWA.2024.126039},
  timestamp    = {Sat, 25 Jan 2025 23:34:56 +0100},
  biburl       = {https://dblp.org/rec/journals/eswa/LiMCHHLZS25.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2407-00924,
  author       = {Jingheng Ye and
                  Shang Qin and
                  Yinghui Li and
                  Xuxin Cheng and
                  Libo Qin and
                  Hai{-}Tao Zheng and
                  Peng Xing and
                  Zishan Xu and
                  Guo Cheng and
                  Zhao Wei},
  title        = {{EXCGEC:} {A} Benchmark of Edit-wise Explainable Chinese Grammatical
                  Error Correction},
  journal      = {CoRR},
  volume       = {abs/2407.00924},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2407.00924},
  doi          = {10.48550/ARXIV.2407.00924},
  eprinttype    = {arXiv},
  eprint       = {2407.00924},
  timestamp    = {Sun, 06 Oct 2024 21:25:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2407-00924.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2407-00934,
  author       = {Jingheng Ye and
                  Zishan Xu and
                  Yinghui Li and
                  Xuxin Cheng and
                  Linlin Song and
                  Qingyu Zhou and
                  Hai{-}Tao Zheng and
                  Ying Shen and
                  Xin Su},
  title        = {{CLEME2.0:} Towards More Interpretable Evaluation by Disentangling
                  Edits for Grammatical Error Correction},
  journal      = {CoRR},
  volume       = {abs/2407.00934},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2407.00934},
  doi          = {10.48550/ARXIV.2407.00934},
  eprinttype    = {arXiv},
  eprint       = {2407.00934},
  timestamp    = {Sun, 06 Oct 2024 21:25:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2407-00934.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/sigir/LiLHYS022,
  author       = {Yinghui Li and
                  Yangning Li and
                  Yuxin He and
                  Tianyu Yu and
                  Ying Shen and
                  Hai{-}Tao Zheng},
  editor       = {Enrique Amig{\'{o}} and
                  Pablo Castells and
                  Julio Gonzalo and
                  Ben Carterette and
                  J. Shane Culpepper and
                  Gabriella Kazai},
  title        = {Contrastive Learning with Hard Negative Entities for Entity Set Expansion},
  booktitle    = {{SIGIR} '22: The 45th International {ACM} {SIGIR} Conference on Research
                  and Development in Information Retrieval, Madrid, Spain, July 11 -
                  15, 2022},
  pages        = {1077--1086},
  publisher    = {{ACM}},
  year         = {2022},
  url          = {https://doi.org/10.1145/3477495.3531954},
  doi          = {10.1145/3477495.3531954},
  timestamp    = {Wed, 06 Nov 2024 14:03:37 +0100},
  biburl       = {https://dblp.org/rec/conf/sigir/LiLHYS022.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/coling/HuangMLHZ0Z24,
  author       = {Shulin Huang and
                  Shirong Ma and
                  Yinghui Li and
                  Mengzuo Huang and
                  Wuhe Zou and
                  Weidong Zhang and
                  Haitao Zheng},
  editor       = {Nicoletta Calzolari and
                  Min{-}Yen Kan and
                  V{\'{e}}ronique Hoste and
                  Alessandro Lenci and
                  Sakriani Sakti and
                  Nianwen Xue},
  title        = {LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete
                  Information from Lateral Thinking Puzzles},
  booktitle    = {Proceedings of the 2024 Joint International Conference on Computational
                  Linguistics, Language Resources and Evaluation, {LREC/COLING} 2024,
                  20-25 May, 2024, Torino, Italy},
  pages        = {10186--10197},
  publisher    = {{ELRA} and {ICCL}},
  year         = {2024},
  url          = {https://aclanthology.org/2024.lrec-main.889},
  timestamp    = {Fri, 26 Jul 2024 07:36:18 +0200},
  biburl       = {https://dblp.org/rec/conf/coling/HuangMLHZ0Z24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/LiZLML0HY24,
  author       = {Yinghui Li and
                  Qingyu Zhou and
                  Yuanzhen Luo and
                  Shirong Ma and
                  Yangning Li and
                  Hai{-}Tao Zheng and
                  Xuming Hu and
                  Philip S. Yu},
  editor       = {Amir Globersons and
                  Lester Mackey and
                  Danielle Belgrave and
                  Angela Fan and
                  Ulrich Paquet and
                  Jakub M. Tomczak and
                  Cheng Zhang},
  title        = {When LLMs Meet Cunning Texts: {A} Fallacy Understanding Benchmark
                  for Large Language Models},
  booktitle    = {Advances in Neural Information Processing Systems 38: Annual Conference
                  on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver,
                  BC, Canada, December 10 - 15, 2024},
  year         = {2024},
  url          = {http://papers.nips.cc/paper\_files/paper/2024/hash/cbfbf1a9adbcc29783475d2767f218e8-Abstract-Datasets\_and\_Benchmarks\_Track.html},
  timestamp    = {Thu, 13 Feb 2025 16:56:44 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/LiZLML0HY24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icassp/LiCLXCZ23,
  author       = {Yangning Li and
                  Jiaoyan Chen and
                  Yinghui Li and
                  Yuejia Xiang and
                  Xi Chen and
                  Hai{-}Tao Zheng},
  title        = {Vision, Deduction and Alignment: An Empirical Study on Multi-Modal
                  Knowledge Graph Alignment},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing
                  {ICASSP} 2023, Rhodes Island, Greece, June 4-10, 2023},
  pages        = {1--5},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/ICASSP49357.2023.10094863},
  doi          = {10.1109/ICASSP49357.2023.10094863},
  timestamp    = {Sun, 19 Jan 2025 13:18:24 +0100},
  biburl       = {https://dblp.org/rec/conf/icassp/LiCLXCZ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/tkde/LiHZZLLCZS23,
  author       = {Yinghui Li and
                  Shulin Huang and
                  Xinwei Zhang and
                  Qingyu Zhou and
                  Yangning Li and
                  Ruiyang Liu and
                  Yunbo Cao and
                  Hai{-}Tao Zheng and
                  Ying Shen},
  title        = {Automatic Context Pattern Generation for Entity Set Expansion},
  journal      = {{IEEE} Trans. Knowl. Data Eng.},
  volume       = {35},
  number       = {12},
  pages        = {12458--12469},
  year         = {2023},
  url          = {https://doi.org/10.1109/TKDE.2023.3275211},
  doi          = {10.1109/TKDE.2023.3275211},
  timestamp    = {Tue, 28 Nov 2023 20:05:28 +0100},
  biburl       = {https://dblp.org/rec/journals/tkde/LiHZZLLCZS23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/aaai/YuJLHWLCLLTZZXH24,
  author       = {Tianyu Yu and
                  Chengyue Jiang and
                  Chao Lou and
                  Shen Huang and
                  Xiaobin Wang and
                  Wei Liu and
                  Jiong Cai and
                  Yangning Li and
                  Yinghui Li and
                  Kewei Tu and
                  Hai{-}Tao Zheng and
                  Ningyu Zhang and
                  Pengjun Xie and
                  Fei Huang and
                  Yong Jiang},
  editor       = {Michael J. Wooldridge and
                  Jennifer G. Dy and
                  Sriraam Natarajan},
  title        = {SeqGPT: An Out-of-the-Box Large Language Model for Open Domain Sequence
                  Understanding},
  booktitle    = {Thirty-Eighth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2024, Thirty-Sixth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2024, Fourteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2014, February 20-27, 2024, Vancouver,
                  Canada},
  pages        = {19458--19467},
  publisher    = {{AAAI} Press},
  year         = {2024},
  url          = {https://doi.org/10.1609/aaai.v38i17.29917},
  doi          = {10.1609/AAAI.V38I17.29917},
  timestamp    = {Wed, 06 Nov 2024 14:03:37 +0100},
  biburl       = {https://dblp.org/rec/conf/aaai/YuJLHWLCLLTZZXH24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/aaai/LiL0LHYY024,
  author       = {Yangning Li and
                  Tingwei Lu and
                  Hai{-}Tao Zheng and
                  Yinghui Li and
                  Shulin Huang and
                  Tianyu Yu and
                  Jun Yuan and
                  Rui Zhang},
  editor       = {Michael J. Wooldridge and
                  Jennifer G. Dy and
                  Sriraam Natarajan},
  title        = {{MESED:} {A} Multi-Modal Entity Set Expansion Dataset with Fine-Grained
                  Semantic Classes and Hard Negative Entities},
  booktitle    = {Thirty-Eighth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2024, Thirty-Sixth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2024, Fourteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2014, February 20-27, 2024, Vancouver,
                  Canada},
  pages        = {8697--8706},
  publisher    = {{AAAI} Press},
  year         = {2024},
  url          = {https://doi.org/10.1609/aaai.v38i8.28715},
  doi          = {10.1609/AAAI.V38I8.28715},
  timestamp    = {Wed, 06 Nov 2024 14:03:37 +0100},
  biburl       = {https://dblp.org/rec/conf/aaai/LiL0LHYY024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/coling/XuLD0CJZLXH25,
  author       = {Zhikun Xu and
                  Yinghui Li and
                  Ruixue Ding and
                  Xinyu Wang and
                  Boli Chen and
                  Yong Jiang and
                  Haitao Zheng and
                  Wenlian Lu and
                  Pengjun Xie and
                  Fei Huang},
  editor       = {Owen Rambow and
                  Leo Wanner and
                  Marianna Apidianaki and
                  Hend Al{-}Khalifa and
                  Barbara Di Eugenio and
                  Steven Schockaert},
  title        = {Let LLMs Take on the Latest Challenges! {A} Chinese Dynamic Question
                  Answering Benchmark},
  booktitle    = {Proceedings of the 31st International Conference on Computational
                  Linguistics, {COLING} 2025, Abu Dhabi, UAE, January 19-24, 2025},
  pages        = {10435--10448},
  publisher    = {Association for Computational Linguistics},
  year         = {2025},
  url          = {https://aclanthology.org/2025.coling-main.695/},
  timestamp    = {Sun, 09 Feb 2025 10:52:29 +0100},
  biburl       = {https://dblp.org/rec/conf/coling/XuLD0CJZLXH25.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ye2025position,
  title={Position: LLMs Can be Good Tutors in Foreign Language Education},
  author={Ye, Jingheng and Wang, Shen and Zou, Deqing and Yan, Yibo and Wang, Kun and Zheng, Hai-Tao and Xu, Zenglin and King, Irwin and Yu, Philip S and Wen, Qingsong},
  journal={arXiv preprint arXiv:2502.05467},
  year={2025}
}
@article{yu2024mind,
  title={Mind Scramble: Unveiling Large Language Model Psychology Via Typoglycemia},
  author={Yu, Miao and Mao, Junyuan and Zhang, Guibin and Ye, Jingheng and Fang, Junfeng and Zhong, Aoxiao and Liu, Yang and Liang, Yuxuan and Wang, Kun and Wen, Qingsong},
  journal={arXiv preprint arXiv:2410.01677},
  year={2024}
}
@article{yan2025position,
  title={Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning},
  author={Yan, Yibo and Wang, Shen and Huo, Jiahao and Ye, Jingheng and Chu, Zhendong and Hu, Xuming and Yu, Philip S and Gomes, Carla and Selman, Bart and Wen, Qingsong},
  journal={arXiv preprint arXiv:2502.02871},
  year={2025}
}
@article{zou2025revisiting,
  title={Revisiting Classification Taxonomy for Grammatical Errors}, 
  author={Deqing Zou and Jingheng Ye and Yulu Liu and Yu Wu and Zishan Xu and Yinghui Li and Hai-Tao Zheng and Bingxu An and Zhao Wei and Yong Xu},
  journal={arXiv preprint arXiv:2502.11890},
  year={2025},
}
