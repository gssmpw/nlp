\section{Related Work}
\label{sec:related_works}

\subsection{Explainable GEC}
Many GEC systems focus solely on correction without offering explanations____. To address this limitation, recent research has investigated multiple techniques to enhance the explainability of GEC. One technique is Example-based GEC____, which boosts explainability by retrieving examples that are similar to the input instance based on defined grammar rules. GEE____ develops a two-step pipeline for GEC explanation generation.____ explore the generation of natural language explanations by prompting large language models (LLMs). Another relevant task is feedback comment generation (FCG)____, which aims to automatically create feedback comments, like hints or explanatory notes, to aid in writing learning. However, it suffers from expensive costs associated with data annotation____. Furthermore, it is often explored with limited access to only a subset of English grammatical error types due to the complexity of the task____.

Despite these efforts, no research has comprehensively examined the positive interaction between correction and explanation tasks during training. In contrast, our work focuses on studying whether learning a multi-task model can outperform the respective single-task models.


\subsection{Learning with Explanations}
Explainability of NLP tasks is a critical research direction and has been given serious attention recently, especially due to the ``black box'' nature of LLMs____. Prior studies have shown that training models to produce task predictions and explanations concurrently can boost performance in vision-language tasks____ and several downstream NLP tasks, including text classification____, commonsense reasoning____, and complaint detection____. An essential aspect of this research is the development of self-Rationalization models that generate task predictions along with corresponding explanations to enhance the explainability or task performance of neural networks. There are two main methods for building self-Rationalization models: 1) \textit{extracting key input tokens responsible for task predictions}, referred to as extractive rationales____, and 2) \textit{creating natural language explanations}____, which serve as a natural interface between models and human users. To refine the performance and trustworthiness of Seq2Seq models,____ developed an extractive fusion-in-decoder architecture within the ERASER benchmark____, a well-known benchmark for rationale extraction across various datasets and tasks.____ introduced a combined text classification and rationale extraction model to improve explainability and robustness. Recognizing the synergy between extractive rationales and natural language explanations,____ integrated both components into a self-Rationalization framework.

\paragraph{Explanation-augmented knowledge distillation.}
Leveraging in-context learning____ and the chain-of-thought (CoT) reasoning____ of LLMs, many recent studies employ the natural language explanations produced by LLMs with chain-of-thought prompting____ to enhance the development of smaller reasoning models using knowledge distillation____, thereby boosting task performance____ or improving faithfulness____.
However, convincing and wrong explanations generated by LLMs can foster unwarranted confidence in tackling NLP tasks____, particularly in educational contexts emphasizing faithfulness____ and correctness____. Consequently, this paper emphasizes model training with human-annotated datasets.