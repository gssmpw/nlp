\section{Related Works}
\label{Related Works}

Our work adopts the notion of cross-domain knowledge transfer in the context of few-shot object detection. We review the related works in this research areas.

\subsection{Few-shot Object Detection}
\label{sec:FSOD}

 

Two prominent training paradigms dominate the FSOD methods: fine-tuning-based methods and meta-learning-based approaches. Fine-tuning methods typically involve a two-stage process. First, a model is pre-trained on a base dataset where ample labeled samples are available for each category. Following this, the model is fine-tuned directly on the novel categories, leveraging the few available labeled samples to adapt its detection capabilities. Notable works in this domain include TFA____, FSCE____, FSRC____, and DeFRCN____, each of which introduces innovations to improve fine-tuning performance on novel tasks.
Meta-learning methods, often referred to as ``learning to learn,'' take a fundamentally different approach. Instead of focusing on specific categories, these methods aim to train models to acquire a generalizable metric learning ability. The training process is structured into tasks, or episodes, each designed to mimic the few-shot scenario. By employing architectures like Siamese networks____, they measure the similarity between support and query features, enabling classification based on learned, class-agnostic knowledge____. During training, the model is exposed to episodic tasks comprising a support set and a query set. The support set typically represents an \(n\)-way \(k\)-shot setup, where \(n\) categories are included, each with \(k\) labeled examples. These tasks enable the model to generalize across a wide range of unseen categories. 
A few examples of meta-learning-based FSOD methods include Meta-FRCN____ and Meta-DETR____, which leverage this episodic framework to enhance detection performance on novel categories.  

A FSOD is addressing catastrophic forgetting, where models lose their ability to recognize base categories when fine-tuned on novel categories. To mitigate this issue, researchers have explored strategies that incorporate both base and novel data during training. This balanced approach ensures that the model retains its performance on base categories while adapting to novel ones.
Fine-tuning and meta-learning methods adopt distinct strategies for handling this challenge. Fine-tuning methods generally focus on directly transferring the model’s learning to novel data in a class-specific manner. These methods leverage the pre-trained model’s knowledge and adapt it to new categories through targeted adjustments. Conversely, meta-learning approaches take a broader perspective, aiming to produce class-agnostic models. By learning a generalizable metric scheme that measures the similarity between query and support features, meta-learning enables models to adapt to novel categories without requiring class-specific knowledge.
Meta-learning methods offer a notable advantage in their ability to rapidly adapt to new tasks, attributed to their task-level feature representation. This adaptability often results in higher precision when confronted with diverse and unfamiliar scenarios. However, fine-tuning methods are not without merit. For instance, TFA____ demonstrates that fine-tuning methods have the potential to surpass meta-learning approaches in detection performance under certain conditions. On the other hand, studies such as FCT____ highlight the enduring strengths of meta-learning, emphasizing its power in FSOD scenarios and its superior capability for rapid task adaptation due to its reliance on task-level feature representations.
These contrasting characteristics illustrate the trade-offs between fine-tuning and meta-learning in FSOD. While fine-tuning excels in leveraging pre-trained knowledge for specific categories, meta-learning shines in its flexibility and robustness in rapidly adapting to novel tasks. Both paradigms continue to shape the evolving landscape of FSOD research.


In FSOD research, traditional backbone networks have played a foundational role in driving progress. Well-established architectures such as Faster R-CNN____, YOLO____, and Vision Transformers (ViT)____ are widely utilized due to their proven effectiveness in various detection tasks. These models have provided strong baselines for tackling FSOD challenges, offering robust feature extraction and prediction capabilities.
In recent years, the Detection Transformer (DETR)____ has emerged as a compelling alternative for the traditional backbones, gaining traction for its impressive performance compared to classical frameworks. Unlike traditional architectures, DETR leverages a transformer-based design that excels at modeling global context and long-range dependencies, making it particularly advantageous for complex detection scenarios. Additionally, its transformer foundation seamlessly supports integration with natural language processing (NLP) tasks, enabling multi-modal capabilities that align with evolving FSOD requirements.
Given DETR's advantages, our work adopts the meta-learning framework provided by Meta-DETR____. Our approach combines the strengths of the transformer-based architecture with the adaptability of meta-learning paradigms, allowing us to effectively address the challenges of few-shot detection.  

\subsection{Prompt Learning and Multi-modal Few-shot Object Detection}
\label{sec:MM-FSOD}

Multi-modal object detection (MM-OD) expands the conventional object detection paradigm by integrating additional sources of information beyond visual data, enabling more nuanced and robust detection capabilities. In our approach, language serves as the supplementary modality, transforming the task into training a model on paired image-text data. This integration allows the model to leverage linguistic context alongside visual cues, opening new avenues for detecting and understanding objects in diverse scenarios.
A common strategy in MM-OD networks involves utilizing pre-trained vision-language representations, with CLIP____ being a prominent choice. These representations, derived from extensive training on paired image-text data, are particularly effective for tasks such as open-vocabulary detection (OVD). In OVD, the model is expected to recognize novel object classes solely through image-text pairs, even without explicit class-specific training. This ability to generalize beyond the training set is a hallmark of multi-modal representations. However, current approaches often rely on relatively simple language inputs, such as class names or basic attributes____, which may limit the richness of the model's understanding.
The advent of large language models (LLMs) has further accelerated advancements in MM-OD, enabling more sophisticated interactions between vision and language. For instance, Next-Chat____ introduces a Q\&A-based framework that combines object detection with instance segmentation, allowing the model to interactively answer questions about detected objects. Similarly, YOLO-World____ employs a region-text contrastive learning approach to build a visual-linguistic interactive model, emphasizing the dynamic interplay between textual prompts and localized visual regions.

 

Multi-modal few-shot object detection (MM-FSOD) remains a relatively underexplored area within the broader domain of object detection. The task extends the principles of few-shot learning to multi-modal contexts, aiming to train models capable of detecting objects with minimal examples while leveraging both visual and linguistic information. Recent efforts, such as the framework proposed by Han et al.____, introduce innovative approaches to this problem. Their method incorporates soft prompt tokens to achieve low-shot object detection by embedding language cues directly into the learning process. 
However, current methods often rely on simplistic text inputs, such as image-level descriptions or category names, as the language label for objects within an image. While effective in some scenarios, this limited textual representation poses challenges when significant domain gaps exist between the base and novel datasets. In such cases, the sparse linguistic information fails to provide the nuanced context needed for effective knowledge transfer, potentially hindering the model’s ability to generalize to novel categories.
To address these limitations, our work builds upon the foundational scheme of incorporating linguistic information into MM-FSOD frameworks. We propose using richer and more semantically complex language descriptions, which provide deeper contextual understanding and better alignment between visual and textual modalities. By employing diverse and detailed textual inputs, our multi-modal network is designed to bridge the domain gap more effectively, enabling superior generalization from base classes to novel datasets. Our approach represents a significant step forward in leveraging the synergy between vision and language for few-shot object detection, particularly in scenarios with challenging domain shifts.

\subsection{Cross-domain Few-shot Object Detection}
Cross-domain few-shot object detection (CD-FSOD) addresses the challenges of performing FSOD when the source and target feature domains exhibit significant differences____. This scenario is particularly relevant in real-world applications where models trained on one domain must adapt to detect objects in a vastly different domain. For example, a model pre-trained on natural images may need to detect objects in medical images or aerial photographs.
To simulate such cross-domain scenarios, MoFSOD____ introduces a multi-domain FSOD benchmark comprising 10 datasets from diverse domains, offering a comprehensive framework to evaluate CD-FSOD performance. Their approach defines \( k \)-shot sampling as \( k \) images per class and highlights the critical role of leveraging pre-training datasets effectively to boost model performance. By focusing on diverse domains, MoFSOD provides insights into the challenges of domain adaptation in FSOD.
Expanding on this approach, CD-FSOD____ presents a cross-domain FSOD benchmark with balanced data per category, where each category is represented by \( k \) instances. This design aligns more closely with standard \( k \)-shot FSOD benchmark protocols, such as those proposed in____. Additionally, CD-FSOD introduces a novel distillation-based baseline, further advancing the field by addressing the knowledge transfer challenges between domains.
Acrofod____ takes a different approach by designing an adaptive optimization strategy to select appropriate augmented data for cross-domain training. This method enhances the model's ability to generalize across domains by strategically leveraging data augmentations.

Building upon these prior works, our research seeks to mitigate the degradation often observed in CD-FSOD performance by utilizing multi-modal feature alignment. By integrating complementary information from multiple modalities, we aim to enhance the model's capacity to bridge domain gaps. Our evaluation primarily follows the benchmark provided by Acrofod____, ensuring that our approach is rigorously tested against established cross-domain FSOD scenarios. This combination of multi-modal alignment and robust benchmarking represents a promising step toward addressing the unique challenges of CD-FSOD.