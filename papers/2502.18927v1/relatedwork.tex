\section{Literature review}
\label{literature}
\subsection{Review-based brand comparison}
Review-based comparison of multiple brands can help consumers make more informed purchasing decisions and help marketers understand their brand's position in the market \citep{colladon2018semantic,mitra2020obim}. 
Recent researches mainly aim to derive brand-associated polarities from user-generated reviews. 
%therefore a ranking of the polarities indicates respective positions of different brands in the market.
Several works considered a two-stage procedure \citep{zhang2015dynamic,barry2018alcohol,sajid2022using}, which first detects brand-associated evaluation aspects from reviews by implementing probabilistic topic models \citep{lda, vayansky2020review}, and subsequently tracks customers' orientations to the extracted aspects or topics of different brands via sentiment analysis. 
In the first stage, the hierarchical topic models (HTMs; \citealt{liu2016overview}) can be applied to derive the hierarchical comparative aspects among brands.
Commonly used HTMs include two mainstream structures: Hierarchical latent Dirichlet allocation (hLDA; \citealt{blei2010nested}) and hierarchical Pachinko allocation model (hPAM; \citealt{hPAM}). 
Specifically, hLDA defines a tree-structure hierarchy where each child topic node has only one parent, and hPAM is built on a directed acyclic multilevel graph where a lower-level topic correlates with multiple upper-level topics.
An obvious limitation of the two-stage method is that the topic extraction is unsupervised and separated from the subsequent sentiment analysis, leading to reduced predictive power for customers' brand-associated polarities \citep{slda}.

Joint sentiment-topic modeling of review texts and ratings provides a powerful solution to the problem of two-stage methods \citep{Tech2023}.
There are also several works using a joint approach that derives brand-associated comparative aspects and customer polarities towards the brands simultaneously. 
For example, the text-based ideal point (TBIP) model \citep{vafa2020text} is constructed based on an unsupervised Poisson factorisation  to infer brand-level polarity scores that influence the word distributions of polarity-bearing topics shared among brands. Moreover, the brand topic model (BTM) by \citet{zhao-etal-2021-adversarial} extended the TBIP model by incorporating supervision from the document-level sentiment labels, leading to improved performance in brand ranking. And \citet{zhao2023tracking} further proposed a dynamic variant of BTM for tracking the latent brand polarity scores over time. 
However, these joint models often focus on the overall brand polarity comparison. They do not provide brand rankings under multiple aspects directly, which is less informative for the decision making of brand market strategies.




\subsection{P\'olya urn scheme in topic modeling}
The simple P\'olya urn scheme (SPU) can be naturally combined with topic modeling for enhancing the topic-word association \citep{mahmoud2008polya}.
The SPU scheme presents a self-reinforcing property known as “the rich get richer”, which helps to capture the word burstiness in a document, i.e., if a word appears once, it is more likely to appear again \citep{doyle2009accounting}.
This property enables SPU to show superior performance in the topic modeling of text documents \citep{wordburstiness}.
Recently, some enhanced P\'olya urn schemes have been proposed for improving the topic-word associations in topic inference, such as generalized P\'olya urn (GPU; \citealt{gpu-li2016topic}) and weighted P\'olya urn (WPU; \citealt{wpu-wang2020optimising}). But these methods are mainly designed for non-hierarchical topic models. 

For adaption to hierarchical topic relations, \citet{xu2018hierarchical} combined GPU with hierarchical topic sampling to produce a topic hierarchy with improved coherence and reasonable structure. 
However, it relies on the prior knowledge extracted from multiple domains' corpora.
%which are not often available, and the extraction of prior knowledge requires much manual work
\citet{Liang2023} developed an enhanced P\'olya urn scheme by adapting the sampling weights of words to their general-to-specific characteristics in hierarchy without requiring any external knowledge. However, it still adopts equal burstiness of words across hierarchy following the assumption of SPU.
In comparison, our proposed HPU scheme considers different burstiness of words in topic hierarchy relying only on their general-to-specific characteristics, namely, a general word is more bursty around the root topic, and a specific word is more bursty around a leaf topic.