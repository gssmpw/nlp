\section{Emergence of analogical reasoning}
\label{sec:analogies}

\def\vdelta{\boldsymbol{\delta}}
\def\vxi{\boldsymbol{\xi}}

\begin{figure*}[t]
  \includegraphics[width=\textwidth]{plots/fig3.jpg}
  \caption{\textbf{(A) Success on downstream tasks begins at a critical model size.} We train a \wem\ on $\losssym$ and plot $\mathrm{acc}(d;\mathcal{F})$, i.e., the final accuracy on four analogy completion subtasks as a function of model size. We observe that performance remains approximately at chance level ($\mathrm{acc}<5\%$) until some critical model size $d_\mathrm{crit}(\mathcal{F})$ (vertical dotted lines) at which steady improvement begins. \textbf{(B) Our proposed theoretical estimator predicts the critical model size.} We plot numerical evaluations of our estimator (solid line) and the true empirical performance (dots). Our estimator depends only on linear algebraic operations on the corpus statistics (see \cref{appdx:derivations} for details). \textbf{(C) Our estimator exploits universality in linear representations.} Since the $\vdelta_i$ align within a given $\mathcal{F}$, we replace them with Gaussian random vectors $\vxi(t)$ with matching moments. We estimate $\tilde\vxi(t)\approx\vxi(t)$ using \cref{thm:sigmoidal}.
  }
  \label{fig:fig3}
\end{figure*}

If two word embeddings $\va$ and $\vb$ are semantically closely related (e.g., synonyms, or linguistic collocations like ``KL divergence'') then we expect $\cos(\va, \vb) \approx 1$. This pairwise geometric structure is explicitly induced by the loss. An analogy, stated ``$\va$ is to $\vb$ as $\va'$ is to $\vb'$,'' is thus a semantic relation \textit{between} pairs. Surprisingly, although there is no four-word interaction in the loss, such structure emerges nonetheless: empirically, the embeddings typically satisfy
\begin{equation}
    % \arg\max_{\vw\in\mW} \left(\T{\hat\vw}( \hat\va_2 + \hat\vb_1 - \hat\va_1)\right) = \vb_2,
    \arg\!\!\!\!\!\min_{\vw\in\{\vw_i\}_i\setminus\{\va,\vb,\va'\}} \left\lVert \frac{\va}{\norm{\va}} - \frac{\vb}{\norm{\vb}} - \frac{\va'}{\norm{\va'}} + \frac{\vw}{\norm{\vw}}\right\rVert = \vb_2.
\end{equation}
The exact relation obeyed by analogy embeddings is relatively unimportant -- the salient point is that simple models trained with simple optimizers on simple objective functions \textit{automatically} learn structure that is typically associated with abstract reasoning. Deeply understanding this behavior is therefore crucial to understand how and when sophisticated language models acquire expert-level skill with relatively little effort (apart from the technical challenges involved in architecting the required computational scale).

Many previous works have attempted to explain why word embeddings succeed on analogy completion \citep{gittens2017skip,ethayarajh2018towards,allen2019analogies}. However, these explanations remain unsatisfying because they do not resolve the gap between learned embeddings (which are governed by the corpus statistics) and analogies (which lack an accepted statistical definition). Until a statistical definition of analogies is established, attempts to explain \textit{why} models can complete analogies will likely rely on assumptions that amount to circular reasoning. To avoid this, we instead study \textit{how} and \textit{when} analogical reasoning develops. The results established in \cref{thm:sigmoidal,thm:anisotropic} provide the necessary tools to answer these questions.

Define a \textit{family of analogies} to be a set of $N$ word pairs $\mathcal{F}\defn\{(\va_n,\vb_n)\}_{n\leq N}$ where any two distinct pairs in the set form a valid analogy. The Google analogy benchmark has this structure, consisting of 14 such families \citep{mikolov2013distributed}. To enable fine-grained analysis, we evaluate analogy completion accuracy separately for each family. This reveals a striking empirical observation: for a given family, accuracy does not increase smoothly with model size; instead, the models perform at chance-level until some $d_\mathrm{crit}$ at which the model begins to learn that family. Furthermore, $d_\mathrm{crit}$ varies dramatically across different analogy families. This is analogous to the observation that LLMs evaluated on reasoning tasks with the top-1 accuracy metric exhibit sudden jumps in performance at some unpredictable model size \citep{wei2022emergent}. However, when we use a smooth scoring function instead, the model performance smoothly increases with model size, consistent with the findings in \cite{schaeffer2024emergent} (\cref{fig:z-appdx-analogy-smooth}).

To investigate this behavior, we train a \wem\ from small initialization with $\losssym$. We reparameterize the analogy pair embeddings as $(\va,\vb) = (\vmu-\half\vdelta,\vmu+\half\vdelta)$, where $\vmu$ is their mean and $\vdelta$ is their difference. Thus the $\vdelta_n$ align with the linear representation corresponding to the analogy class (e.g., the ``feminine direction'' for male/female analogies). Note that the $\vmu_n$ and $\vdelta_n$ are dynamical variables that depend on both training time $t$ and model size $d$. However, due to the greedy sequential low-rank learning dynamics, a large-$d$ model at early $t$ behaves identically to a small-$d$ model at late $t$. As a result, without loss of generality, we can study the dynamics of model performance at large $d$ as a reliable proxy for the model performance as a function of $d$ at $t\to\infty$.

Note that we can estimate all the word embeddings in terms of corpus statistics by evaluating the equations in \cref{thm:sigmoidal}. This provides a theoretical handle on analogy completion accuracy. We denote the theoretical estimate of a vector $\vv$ using $\tilde\vv$.

If we expect the model to successfully solve analogies by embedding addition, then we should expect that the linear representations $\tilde\vdelta_n$ in a particular $\mathcal{F}$ should all roughly align. Therefore, to estimate the aggregate analogy score across all pairs in $\mathcal{F}$, we posit that we may replace any individual $\tilde\vdelta_n$ with a random Gaussian random vector $\vxi$ with matching mean and covariance. This is akin to a Gaussian universality assumption on the $\tilde\vdelta_n$. 
This simplification enables numerical estimates of the analogy accuracy from the corpus statistics:
\begin{equation}
    \mathrm{acc}(t, \mathcal{F}) \approx \E_{\substack{\vxi\sim\mathcal{N}_{\tilde\vdelta}\\ (\tilde\va,\tilde\vb)\in\mathcal{\tilde F}}} \! \bigg[ \mathbf{1}_{\tilde\vb}\left(\arg\max_{\vw\in\tilde\mW} \frac{\T\vw}{\norm{\vw}}(\tilde\va+\vxi) \right) \bigg],
    \label{eq:analogy_estimator}
\end{equation}
where $\mathbf{1}$ is the indicator function, $\tilde\mW$ is the set containing the theoretically predicted word embeddings, and $\mathcal{\tilde F}$ is the subset of $\tilde\mW$ corresponding to the family of interest. We notationally suppress the time dependence of all quantities. For further discussion of this estimator, see \cref{appdx:derivations}.

This estimate gives accurate predictions for the $d_\mathrm{crit}$ at which a given family of analogies begins to be learned (see \cref{fig:fig3}). The mechanisms by which analogy structure forms are therefore determined primarily by the dynamics of the random vector $\vxi$. We leave it to future work to derive efficient algorithms for evaluating \cref{eq:analogy_estimator} and to develop other theoretical estimators that can be evaluated with limited access to the ground-truth corpus statistics.