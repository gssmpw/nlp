\section{Proposed Method}
\label{sec:method}


The core idea behind \sys is to leverage knowledge graphs to achieve fine-grained and comprehensive test coverage, while rigorously eliminating redundancy between the forgetting and retain objectives. 
As illustrated in \autoref{fig:overview}, \sys comprises three sequential stages. 
During the \textit{Knowledge Graph Construction} stage, unstructured textual data is systematically transformed into structured knowledge representations. This enables the explicit modeling of atomic knowledge units and their semantic interconnections.
Subsequently, the \textit{Redundancy Removal} stage meticulously identifies and eliminates knowledge facts that are simultaneously present in both forget and retain datasets.
This process helps prevent inaccurate assessments by ensuring the audit doesn't mistakenly flag knowledge meant for retain as candidates for removal. 
Finally, in the \textit{Question Synthesis} stage, \sys employs LLMs to generate targeted questions and corresponding reference answers, guided by specific knowledge facts from the pruned knowledge graph. 
This approach provides an automated and holistic evaluation framework for assessing LLM knowledge unlearning efficacy.

\input{tfsrc/algo_method.tex}

\subsection{Stage 1: Knowledge Graph Construction}
Our framework transforms unstructured text corpora into structured knowledge graphs to enable fine-grained knowledge evaluation. This transformation is crucial for capturing semantic relationships and facilitating precise knowledge auditing. Specifically, we construct two distinct knowledge graphs from the forget and retain datasets: \(\mathcal{G}_{\text{fgt}}\) and \(\mathcal{G}_{\text{ret}}\), respectively. Each knowledge graph represents a structured network of entities and their relationships, allowing for systematic analysis of knowledge units.
For implementation, following standard practices, we first segment the input text and perform coreference resolution preprocessing~\cite{lee2017end}, to ensure accurate entity identification and relationship mapping. We then employ the REBEL-large model~\cite{huguet-cabot-navigli-2021-rebel-relation}, which has been specifically fine-tuned for entity and relation extraction. This model demonstrates robust performance in extracting structured knowledge from natural language text, making it particularly suitable for our knowledge graph construction pipeline.

\subsection{Stage 2: Redundancy Removal}

The intricate entanglement of information across retain and forget datasets complicates the identification of specific elements requiring audit.
To address this challenge, we implement a graph alignment strategy to detect shared information between  \(\mathcal{G}_{\text{fgt}}\) and \(\mathcal{G}_{\text{ret}}\). We identify redundancy through triples that match exactly or share equivalent structures across both graphs. Our method examines each triple \((e_1, r, e_2) \in \mathcal{G}_{\text{fgt}}\) to locate its potential counterpart in \(\mathcal{G}_{\text{ret}}\). We express the overlapping edges mathematically as:
\begin{equation}
E_{\text{conf}} = E(\mathcal{G}_{\text{fgt}}) \cap E(\mathcal{G}_{\text{ret}}).
\end{equation}
The refined test graph is then constructed by removing these intersecting elements:
\begin{equation}
\mathcal{G}_{\text{test}} = \mathcal{G}_{\text{fgt}} \setminus E_{\text{conf}}.
\end{equation}
This process yields \(\mathcal{G}_{\text{test}}\), which maintains the fundamental structure of \(\mathcal{G}_{\text{fgt}}\) but excludes direct knowledge overlap with \(\mathcal{G}_{\text{ret}}\). The resulting graph provides a clean foundation for assessing selective forgetting performance, preserving crucial network relationships while eliminating redundant elements.
It is important to note that this step provides an approximation rather than a perfectly precise identification of redundant knowledge. Even if two facts appear to be identical, their meanings may vary depending on the surrounding context, making exact equivalence challenging to determine. Nevertheless, the distant supervision strategy employed here has been shown to effectively capture the majority of overlapping knowledge~\cite{mintz2009distant}. 

% Selective forgetting is inherently challenging due to the semantic entanglement between information slated for removal and that which is to be retained. To mitigate this issue, we propose a knowledge graph alignment mechanism designed to systematically identify overlapping triples between \(\mathcal{G}_{\text{fgt}}\) and \(\mathcal{G}_{\text{ret}}\). Here, redundancy is defined as those triples—either identical or structurally analogous—that appear in both graphs.

% For each knowledge triple \(e_f = (h_f, r_f, t_f) \in \mathcal{G}_{\text{fgt}}\), we conduct a thorough search for a corresponding triple in \(\mathcal{G}_{\text{ret}}\). Formally, we define the set of redundancying edges as:
% \begin{equation}
% E_{\text{conf}} = E(\mathcal{G}_{\text{fgt}}) \cap E(\mathcal{G}_{\text{ret}}).
% \end{equation}
% Subsequently, by excising these redundancying edges from \(\mathcal{G}_{\text{fgt}}\), we derive a test knowledge graph:
% \begin{equation}
% \mathcal{G}_{\text{test}} = \mathcal{G}_{\text{fgt}} \setminus E_{\text{conf}}.
% \end{equation}
% The resulting graph \(\mathcal{G}_{\text{test}}\) retains the structural integrity of \(\mathcal{G}_{\text{fgt}}\) while ensuring the elimination of any direct semantic overlap with \(\mathcal{G}_{\text{ret}}\). This curated graph thus serves as an unbiased benchmark for evaluating the efficacy of selective forgetting mechanisms.

% By removing only the redundancying facts, the approach preserves the essential connectivity and semantic relationships inherent in the original graph.


\subsection{Stage 3: Question Synthesis}
Previous benchmarks generate QA pairs by directly feeding entire text segments to LLMs, making it difficult to ensure comprehensive coverage and quality control of the resulting questions.  
To address this limitation, we adopt a fine-grained, dual-input prompting strategy. Specifically, for each knowledge triple in \(\mathcal{G}_{\text{test}}\), we leverage an LLM to automatically generate targeted test questions. 
Our dual-input prompting strategy equips LLMs with two complementary information sources: structured knowledge triples and their corresponding source text passages. This approach guides the model to generate fact-anchoring questions while maintaining fidelity to the original context. 
By anchoring question generation in both structured knowledge and source text, we ensure the generated questions accurately reflect the intended specific facts while preserving contextual relevance.
By enumerating each edge in \(\mathcal{G}_{\text{test}}\) and instructing the LLM to generate corresponding QA questions, we can guarantee at least a lower bound on the audit adequacy.

Our prompt design is based on several key principles. First, we explicitly define the LLM's role as an expert quiz question generator to set clear expectations. Second, by providing structured inputs consisting of both the knowledge triple and its original context, we ensure that the generated questions are firmly grounded in the relevant information. Third, we impose strict criteria on the generated questions: each must be answerable solely from the provided context, specific enough to yield a unique answer, and directly assess the semantic relationship between target entities. To facilitate automated evaluation, we require that each question-answer pair be output in a structured JSON format.

Furthermore, we adopt the one-shot learning by incorporating carefully selected example question-answer pairs into the prompt. These examples illustrate the desired question format and level of specificity, guiding the LLM toward generating high-quality, targeted questions. This comprehensive prompting strategy ensures that the synthesized questions effectively evaluate selective forgetting while maintaining human interpretability. The specific prompt employed in our experiments is provided in \autoref{sec:appendix_dataset}.


