\section{Preliminaries and Motivation}
\label{sec:prelim}



\subsection{LLM Unlearning}

LLM unlearning refers to techniques that selectively remove specific behaviors or knowledge from a pre-trained language model while maintaining its overall functionality~\cite{yao2023large}. 
With the proliferation of LLMs, unlearning has gained significant attention due to its broad applications in safety alignment, privacy protection, and copyright compliance~\cite{eldan2023s,liu2024rethinking,jia-etal-2024-soul}. The evaluation and auditing of LLM unlearning spans from basic verbatim memorization to deeper knowledge memorization~\cite{shi2024muse}, with this work focusing on the latter.
As depicted in \autoref{fig:overalltask}, LLM unlearning operates as a targeted intervention within the model's knowledge representation framework. 
Its core objective is the selective removal of specific information while preserving the model's broader knowledge base (e.g, on retain set). 
This study focuses on the knowledge unlearning auditing that assesses unlearned models' behaviors through comprehensive audit cases. Given access to both forget and retain corpora, we generate a holistic set of test questions with reference answers to thoroughly evaluate whether an unlearned model exhibits any residual knowledge memorization.
% The effectiveness of unlearning is characterized by a distinctive performance pattern: the model should exhibit significantly reduced performance on tasks involving the targeted knowledge while maintaining competence across all other domains. This selective degradation in performance serves as a key indicator of successful unlearning.

% This paper focuses on auditing LLM knowledge une, specifically developing fine-grained test cases based on training data to identify instances where the unlearning process has failed to achieve its intended objectives.

% Formally, given a pre-trained language model $\mathcal{M}$ with parameters $\theta$, the unlearning process aims to derive a new model $\mathcal{M}'$ with parameters $\theta'$ that demonstrates forgetting of targeted information while preserving other capabilities.
% In the context of exact knowledge unlearning, we specifically focus on removing precise factual information or relationships from the model's knowledge base. Let $\mathcal{D}_{fgt}$ denote the forget dataset containing knowledge to be eliminated, and $\mathcal{D}_{ret}$ represent the retain dataset containing knowledge that should be preserved. The objective of exact knowledge unlearning can be formalized as:

% \begin{equation}
% \theta' = \argmin_{\theta'} \mathcal{L}_{fgt}(\mathcal{M}'(\theta'), \mathcal{D}_{fgt}) + \lambda \mathcal{L}_{ret}(\mathcal{M}'(\theta'), \mathcal{D}_{ret})
% \end{equation}

% where $\mathcal{L}_{fgt}$ measures the model's tendency to generate or recall information from $\mathcal{D}_{fgt}$, $\mathcal{L}_{ret}$ evaluates the preservation of knowledge in $\mathcal{D}_{ret}$, and $\lambda$ balances these competing objectives. A successfully unlearned model should satisfy:

% \begin{equation}
% P(\mathcal{M}'(\theta') \mid \mathcal{D}_{fgt}) \ll P(\mathcal{M}(\theta) \mid \mathcal{D}_{fgt})
% \end{equation}

% \begin{equation}
% P(\mathcal{M}'(\theta') \mid \mathcal{D}_{ret}) \approx P(\mathcal{M}(\theta) \mid \mathcal{D}_{ret})
% \end{equation}

% where $P(\mathcal{M} \mid \mathcal{D})$ represents the model's probability of generating or correctly responding to information in dataset $\mathcal{D}$. These conditions ensure that the unlearned model exhibits significantly reduced ability to recall forgotten knowledge while maintaining its performance on retained knowledge.



\subsection{Knowledge Graph}
\label{sec:pre_kg}

A knowledge graph (KG) is a structured multi-relational graph~\cite{bordes2013translating}, usually representing a collection of facts as a network of entities and the relationships between entities.
Formally, a KG \(\mathcal{G} = \langle \mathcal{E}, \mathcal{R}, \mathcal{F} \rangle\) could be considered a directed edge-labeled graph~\cite{ji2021survey}, which comprises a set \(\mathcal{E}\) of entities (e.g., \textit{Harry Potter}, \textit{Hogwarts School}), a set \(\mathcal{R}\) of relations (e.g., \textit{attends}), and a set $\mathcal{F}$ of facts. A fact is a triple containing the head entity \(e_1 \in \mathcal{E}\), the relation $r \in \mathcal{R}$, and the tail entity \(e_2 \in \mathcal{E}\) to show that there exists the relation from the tail entity to the head entity, denoted as \((e_1, r, e_2) \in \mathcal{F}\)~\cite{hogan2021knowledge}. To illustrate, the fact (\textit{Harry Potter}, \textit{attends}, \textit{Hogwarts School}) shows that there exists the \textit{attends} relation between \textit{Harry Potter} and \textit{Hogwarts School}, which indicates``Harry Potter attends Hogwarts School''.

\input{tfsrc/fig_overview.tex}

\subsection{Motivation}
This section aims to illustrate why and how we consider employing KG to facilitate the holistic LLM unlearning audit. 
Two critical factors underpin this task.
\ding{182}\textbf{Audit Adequacy}: The Forget Dataset is an extensive, unstructured corpus. Existing approaches typically rely on the LLM's prior knowledge to directly generate QA pairs or segment the corpus and feed these segments to ChatGPT for automated QA pair generation. Such methods often fail to intuitively reflect or guarantee the sufficiency of the generate dataset.
\ding{183}\textbf{Knowledge Redundancy}: A more subtle and easily overlooked issue is that the Retain Dataset and Forget Dataset may contain overlapping knowledge. As illustrated in \autoref{fig:overalltask}, this overlapping knowledge should be retained by the unlearned model and, therefore not be treated as candidates for the unlearning efficacy audit. Existing evaluation benchmarks like MUSE often neglect this aspect, as evidenced by \autoref{fig:musecase}.



A KG can offer an effective solution to address these two challenges. 
First, the KG inherently captures the knowledge facts within the Forget Dataset at a fine-grained level, with each edge representing a minimal testable unit. 
By ensuring coverage of every edge in the KG, one can achieve a more intuitive and relatively comprehensive audit. 
Moreover, the structured data provided by the KG can facilitate the identification of identical knowledge facts present in both the Retain and Forget Datasets.
This capability allows for refinement of the initial forget knowledge graph by removing potentially retained information.
Finally, owing to recent advances in KG extraction technology, numerous automated extraction models and pipelines are available to support the automated construction of an audit dataset.

