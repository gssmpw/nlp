
%\fy{general comment: it doesn't }

We now compute the \idRRs \eqref{eqn:PI-robust-loss} and derive a lower bound for  the minimax quantity \eqref{eqn:minimax-quantity} in the linear additive shift setting of \cref{sec:training-data}.
%\fy{don't actually understand previous sentence}
%linear structural model setting that is achievable for large shifts. 
We then compare the \idRRs of some existing robustness methods and ordinary least squares (OLS) with the minimizer of the \idRRs both theoretically and empirically.
%on synthetic as well as Based on this, we describe a failure scenario of previous robustness methods and propose a method that partially mitigates their drawbacks.
% the general partially identifiable robustness framework, define the notion of partially identifiable robust risk \fy{adapt}and derive its lower bound. We use our results to compare existing robust estimators 



\subsection{Minimax robustness results for the linear setting}\label{sec:main-results-minimax}
%\subsection{Idenfitiability of the robust risk and robust predictor for linear SCMs}
\label{sec:identifiability-linear-SCM}
%\fy{point of this section: In this section, we explicitly characterize \idset and the set of identifiable robust predictors for the linear SCM \cref{eqn:SCM} and show how in previous works the latter set is just a singleton}
%When the data is generated by the linear structural causal model \cref{eqn:SCM}, we can compute the \idset explicitly. 

The degree to which the model parameters $\thetastar$  in the linear additive shift setting \eqref{eqn:SCM} can be identified depends on the number of environments and the total rank of the moments of the additive shifts. For structural causal models, this is well-studied, for instance, in the instrumental variable (IV) regression literature \citep{ amemiya1985advanced, bowden1990instrumental}. 
% JULIA: this is now assumed earlier in the text.
% Without loss of generality, we assume $0 \in \Ecaltrain$ and denote the chosen reference environment by $(X^0, Y^0)$. Note that we do not pose any assumptions on the distribution of the reference environment â€“ in particular, $\Sigma_0$ and $\mu_0$ are allowed to be arbitrary. 
%We first explicitly characterize the set-identifiability of the model parameters \idset and the corresponding set of identifiable robust predictors. 
As we show in \Cref{prop:invariant-set}, the true parameter $\betastar$ can \emph{only} be identified along the directions of the training-time mean and variance shifts $\mue$ and $\Sigmae$. 
Therefore, if not enough shift directions are observed, $\betastar$ is merely \emph{set-identifiable}, leading to 
%In the following, we show how set-identifiability of the model parameters translates into 
%has implications for 
 set-identifiability of the robust prediction model \eqref{eqn:formula-robust-predictor}. 
%We formalize this in the following proposition where we denote by
More formally, we denote by $\cS$ the subspace consisting of all \emph{additive shift directions seen during training}:
\begin{align}\label{eqn:def-S}
    \cS := \range \left[ \sum_{e \in \Ecaltrain} \left( \Sigma_e + \mu_e \mu_e^\top\right) \right],
\end{align} 
and by $\cSperp$ its orthogonal complement.
The definition of the space $\cS$ induces an orthogonal decomposition of the true parameter $\betastar = \betastarS + \betastarperp$. The \emph{identifiable part} $\betastarS$ then uniquely defines a set of \emph{identified model parameters} that reads 
%\fy{still unsure if it should be in prop. shorter prop just make it seem less important as a result} also define the following set of parameters projected onto S ... 
\begin{align*}
    \thetastarS := (\betaS, \noisecovxxS, \noisecovxyS, \noisecovyyS) = (\betastarS, \noisecovxxstar, \noisecovxystar + \noisecovxxstar \betastarS, \noisecovyystar + 2 \langle \noisecovxystar, \betastarS\rangle + \langle \betastarS, \noisecovxxstar \betastarS\rangle)
\end{align*}
that can be computed from the training distributions. For the following results, we assume a similar decomposition of the test shift upper bound $\Mtest$ which is essentially a decomposition into "seen" and "unseen" directions.
\begin{assumption}[Structure of $\Mtest$]\label{as:Mtest-structure}
   We assume that $\Mtest = \gamma \Mseen + \gammaprime R R^\top$, where $\gamma, \gammaprime \geq 0$, $\Mseen$ is a PSD matrix satisfying $\range(\Mseen) \subset \cS$ and $R$ is a semi-orthogonal matrix satisfying $\range(R) \subset \cSperp$.
\end{assumption}
%\fy{polish the next three, i copy-pasted up} Further use the orthogonal decomposition of the causal parameter $\betastar = \betastarS + \betastarperp$ into onto $\cS$ and $\cSperp$, respectively.
% Consider the decomposition of the test shift upper bound into "observed directions" $S$ contained in $\cS$ and "unobserved directions" $R$ contained in $\cSperp$:
% \begin{align}\label{eqn:Mtestdecomposition}
%  \betastar = \betastarS + \betastarperp, \quad  \text{and } \quad  \projM \preceq S S^\top + R R^\top,\end{align}
% where $S$ and $R$ are matrices with orthonormal columns such that $\range S \subset \cS$, $\range R \subset \cSperp$ and $\range S$, $\range R$ are the smallest subspaces satisfying \Cref{eqn:Mtestdecomposition}\footnote{The choice of $S$ and $R$ is not unique, but the subspaces $\range S$, $\range R$, which matter for our results, are.}. The matrix $S$ corresponds to test shift directions along the model can be identified. Conversely, $R$ corresponds to test shift directions, along which the model is non-identified. 
In the next proposition, we show that the model parameters and robust predictor can be identified up to a neighborhood around $\thetastarS$. %which can be interpreted as the set's geometric center. 


%In the following proposition, we explicitly describe the set-identifiability of the model parameters in the linear SCM setting \cref{eqn:SCM}. 
% Correspondingly, we denote by $\cS^\perp$ the orthogonal complement of $\cS$. Let $\betastar = \betastarS + \betastarperp$ be the orthogonal decomposition of the causal parameter $\betastar$ on $\cS$ and $\cSperp$, respectively. We will refer to $\betastarS$ as the \emph{identified causal parameter} since it is computable from training data (see proof of \cref{lm:invariant-set}). The identified causal parameter $\betastarS$ induces a unique tuple of model parameters $\thetacS$ which is observationally equivalent to $\thetastar$. We compute it to be\footnote{One first identifies $\betastarS$. The rest of the model parameters then follows by computing $\Cov(X^0, Y^0)$ and $\Cov(Y^0)$.} 
% \fy{a bit unclear to me what you put in lemma and what you put outside}
% \begin{align}\label{eqn:identified-model-parameter}
%     \thetacS := (\betastarS, \noisecovxxstar, \noisecovxyS, \noisecovyyS) := (\betastarS, \noisecovxxstar, \noisecovxystar + \noisecovxxstar \betastarperp, \noisecovyystar + 2 \noisecovxystar^\top \betastarperp + \betastarperp^\top \noisecovxxstar \betastarperp).
% \end{align}
 
% % \julia{what is better for exposition: using the "M" parameters or just using betastar and hiding the "M" ones in the proof}

% \fy{in the main text we probably only have space for one of lemma or proposition or can they be merged? into a), b)?}
\begin{proposition}[Identifiability of model parameters and robust predictor]
\label{prop:invariant-set} Suppose that the set of training and test distributions is generated according to \cref{sec:training-data} and Assumption~\ref{as:Mtest-structure} holds.
Then,
\begin{enumerate}[(a)]
 \item %\textbf{Identifiability of the model parameters.} 
 the model parameters %$\theta = (\beta, \noisecovxx, \noisecovxy, \noisecovyy)$ 
 generating the training distribution \eqref{eqn:SCM} can be identified up to the following \idset: 
\begin{align}\label{eqn:def-invariant-set}
  \Invset =  \Theta \cap \{ \betastarS + \alpha, \noisecovxxstar, \noisecovxyS - \noisecovxxstar \alpha, \noisecovyyS - 2 \alpha^\top \noisecovxyS + \alpha^\top \noisecovxx \alpha \colon \alpha \in \cSperp \}  \ni \thetastar;
\end{align}
\item %\textbf{Identifiability of the robust predictor.}
the robust predictor $\betarob_\theta$ as defined in \cref{eqn:formula-robust-predictor} is identified up to the set
    \begin{align}\label{eqn:def-rob-pred-identif}
    \cBrobfull \cap \{ \betastarS + (\Mtest + \noisecovxxstar)^{-1} \noisecovxyS +  (\Mtest + \noisecovxxstar)^{-1} \alpha\colon \, \alpha \in \range(R)  \}   \ni \betarob_{\theta}, 
    \end{align}
\end{enumerate}
where $\cBrobfull = \{ \betarob_{\theta}: \theta \in \Invset \}$. 
\end{proposition}
The proof of \cref{prop:invariant-set} is provided in \cref{sec:apx-proof-invariant-set}. 
% \fy{i think one can shorten this a bit - this section shouldn't feel super long}
% \fy{moved this outside the theorem:}
% The result shows that although the causal parameter can be only identified up to the subspace $\cSperp$ after observing the training data, the robust predictor can be identified up to the subspace $\range R \subset \cS$\fy{you just said above its in Sperp?}, independent of whether $\thetastar$ is identified.
% In particular, the robust predictor is uniquely identifiable from training data if and only if $R = 0$, \fy{i.e. there are no new directions during test time}
% %which can be much smaller \fy{than what?}, depending on how much prior knowledge one has on the test shift. 
% Thus, under structural assumptions on the test shift, one might need fewer environments to identify the robust predictor than the causal parameter.  
\cref{prop:invariant-set} covers two well-known settings: If we observe a rich enough set $\probtrain$ of training environments such that $\cS = \R^d$, the model parameters are uniquely identified, corresponding to the setting of full-rank instruments \cite{amemiya1985advanced}. From a dual perspective, for a given set of training environments, \emph{the robust predictor is  identifiable whenever the test shifts are in the same direction as the training shifts}, i.e. $\range (\Mtest) \subset \cS$ and $R=0$ -- this holds even  when the invariant parameters are not identifiable and $\cS \neq \R^d$.
%that is \emph{regardless of the identifiability of the model parameters}.
%However, even in the under-identified case $\cS \neq \R^d$, if the test shift directions are contained in the space $\cS$ of training-time shifts, i.e. $R = 0$,  the robust prediction model is identifiable from training data \emph{regardless of the identifiability of the model parameters}. 
This is the setting considered e.g. in anchor regression \cite{rothenhausler2021anchor} and discussed again in~\Cref{sec:comp-with-finite-robustness-methods} and \cref{sec:apx-anchor-connections}.
%  \cref{lm:invariant-set} shows that the causal parameter $\betastar$ is identified up to a subspace of dimension $r := \dim \cSperp$. 
% %In particular, 
% If we observe a rich enough set $\probtrain$ of training environments such that $\cS = \R^d$, the model parameters are uniquely identified, which is well known from the IV literature \citep{bowden1990instrumental, angrist1995identification, angrist1996identification, wang2018bounded}. % \citep{angrist1995identification, wang2018bounded}. 
% %However, 
% \fy{However that may not be necessary if our only goal is to be robust. }
% In the following proposition, we show that 
% the identifiability of the robust predictor \cref{eqn:formula-robust-predictor} additionally depends on the structure of the test shift $\Mtest$. In particular, if $\Mtest$ only consists of directions observed during training, i.e., if $\range \Mtest \subset \cS$, the robust predictor is identifiable \emph{regardless of the identifiability of the model parameters}. However, if $\Mtest$ contains new directions which were not observed in any of the training environments, the robust predictor is not identifiable from the multi-environment training distribution alone. 
% \begin{proposition}\label{prop:betarob-invariant-set}
%     Consider training data $\{(\Xe, \Ye): e \in \Ecaltrain \}$ generated according to \cref{eqn:SCM} and test data $(\Xtest, \Ytest)$ generated according to \cref{eqn:testSCM}. Suppose that the maximum test shift is bounded according to \cref{eqn:testAbound}. Denote by $ \thetacS = (\betastarS, \noisecovxxstar, \noisecovxyS, \noisecovyyS)$ the identified model parameter as defined in \cref{eqn:identified-model-parameter}. Recall that $\Mtest = \gamma \cP_\cM$. Let $M = (S, R)$ be a basis of the subspace $\cM$ where $\range S \subset \cS$ and $\range R \subset \cSperp$.
%     Consider the orthogonal decomposition 
%     \begin{align}\label{eqn:Mtest-decomposition}
%         \Mtest = \gamma \cP_{\cM} = \gamma S S^\top + \gamma R R^\top. 
%     \end{align}
%     Then the robust predictor $\betarob$ as defined in \cref{eqn:formula-robust-predictor} is identified up to the set
%     \begin{align}
%       \betarob \in \betastarS + (\Mtest + \noisecovxxstar)^{-1} \noisecovxyS + \{ (\Mtest + \noisecovxxstar)^{-1} \alpha: \: \alpha \in \range R  \}.
%     \end{align}
% \end{proposition}
% Thus, the robust predictor $\betarob$ is identified up to a subspace of dimension $r' := \dim \range R$, which is lower than the dimension of the non-identified subspace $\cSperp$. Informally, the result states that under any structural assumptions on the test shifts, one needs fewer environments to identify the robust predictor than the causal parameter. 



%\subsection{Lower bound for the best-possible achievable robustness in the linear SCM setting}\label{sec:PI-lower-bound}

%\subsection{Partially identifiable robust loss}
So far, we have described how the identifiability of the robust prediction model depends on the structure of both the training environments (via the space $\cS$) and the test environments (via $\Mtest$). 
%(via the decomposition $\gamma \projM = \gamma S S^\top + \gamma R R^\top$ into training and new directions), and listed two examples in which the robust predictor is computable from training data.  
We now aim to compute the smallest achievable robust loss for the general partially identifiable setting, which allows for $R \neq 0$.
In particular, we provide a lower bound on the \emph{best-possible achievable distributional robustness} formalized by the minimax quantity \eqref{eqn:minimax-quantity}.
%However, it remains unclear what best robust loss is \emph{always achievable} from training data in case $\betarob$ is not identifiable \fy{and how large the gap to existing methods}. In this section, we aim to answer this question by providing a lower bound on the \emph{best-possible achievable distributional robustness}, given by the minimax quantity \cref{eqn:minimax-quantity} \fy{so that we can compare the rates between different estimators}. 
%For that purpose, we 
First observe that without further assumptions on the parameter space $\Theta$, the \idset is unbounded, and the \idRRs \eqref{eqn:PI-robust-loss} can be infinite.
%However, in practice, the model parameters cannot be arbitrarily large. 
%In order 
The following boundedness assumption allows us to provide a fine-grained analysis of robustness in a partially identified setting.
%, we therefore impose the following assumption: 
\begin{assumption}[Boundedness of the causal parameter]\label{as:bounded-betastar}
    There exists a constant $C > 0$ such that any parameter $\beta$ in the DGP  \eqref{eqn:SCM} is norm-bounded by $C$, i.e.  $\norm{\beta}_2 \leq C$. 
\end{assumption}
%Under Assumption~\ref{as:bounded-betastar}, the set of possible model parameters is given by $\Theta = \cB^d(C) \times \R^{(d+1) \times (d+1)}$, and the \idset is compact. In particular, the \idRRs$\Lossrobpi(\cdot, \Invset; \gamma, \cM): \R^d \to \R$ is well-defined.
% To answer this question, we first need to establish what \emph{best possible} even means in case the ground-truth robust loss is unknown. The "finest-grain" notion of the robust risk which is identifiable from the training data is the set $\{\Lossrob(\probsettestarg{\theta}): \, \theta \in \Invset  \}$ induced by the observationally equivalent model parameters. Thus, in a set-identified setting, one should aim to be robust with respect to the worst-case robust risk from the set. 
% However, as we have seen in \cref{lm:invariant-set} and \cref{prop:betarob-invariant-set}, the causal parameter and the robust predictor are only identified up to a linear subspace of $\dim \cSperp$ and $\dim \range R$, respectively. This can potentially lead to an infinite robust loss across the \idset. To be able to quantify the effects of non-identifiability, we assume that there exists an upper bound on the norm of the causal parameter: 
% With \cref{as:bounded-betastar} we can now define a real-valued risk measure which describes the \emph{best robustness achievable from multi-environment training data}:
% \begin{definition}[PI-robust loss]\label{def:PI-robust-loss}
%     Consider the data model described by \cref{eqn:SCM} and \cref{eqn:testSCM}. The partially identified robust loss (PI-robust loss) is defined as
%     \begin{align}\label{eqn:PI-robust-loss}
%         \Lossrobpi(\Mtest, \beta) = \sup_{\theta \in \InvsetC} \Lossrob (\probsettestarg{\theta} , \beta). 
%     \end{align}
% We denote by $\betarobpi$ any minimizer of the partially identified robust loss:
% \begin{align}
%     \betarobpi := \argmin_{\beta \in \R^d} \Lossrobpi(\Mtest, \beta). 
% \end{align}
% \end{definition}
% The definition of the PI-robust loss reflects the absence of knowledge of the model parameters in test shift directions which were not observed during training. In this case, given the training data, the ``best-possible'' robustness is robustness against the ``hardest-possible'' model-generating parameters which induce the training distribution. 
% Since the \idset is always computable from training data, the PI-robust loss is by definition computable as well. Hence, we can compute the minimizer of the PI-robust loss for any combination of the identified space $\cS$ and test shifts $\Mtest$. 
% For instance, it becomes evident from \cref{lm:invariant-set} and \cref{def:PI-robust-loss} that if the test shift $\Mtest$ consists only of identified directions, the PI-robust loss coincides with the conventional robust loss.
% \fy{maybe can write somewhere (dunno where):}
% Note that in the causality literature, the shifts can be potentially unbounded. However, this would disallow us to make a quantitative statement and comparison across scenarios. Having bounded perturbations allows us to make a more fine-grained statement... \fy{this needs to be hammered to be the main motivation - and i think if we write the story in the way of: understanding what happens when in a more fine-grained manner than just 0 vs. infinity (done until now) this is better than saying "we assume limited strength perturbation and get a method that does well} 
% \julia{Talk about finite robustness. Talk about assumption on boundedness of betastar.  define form of Mtest. Lower bound proposition.  }
% To be able to study the effect of unseen test shifts analytically, we impose additional structure on the test shift $\Mtest$: 
% \begin{assumption}[Structure of $\Mtest$]\label{as:structure-Mtest}
%     Let $\gamma > 0$ and $R \in \R^{d \times r}$ be a semi-orthogonal matrix spanning a subspace $\cR \subset \cSperp$. Let $S^{d \times q}$ be a semi-orthogonal matrix spanning the training subspace $\cS$. We assume that $\Mtest$ can be written as 
% \begin{align}\label{eqn:structure-of-Mtest}
%     \Mtest = \gamma M M^\top =: \gamma (S + R)(S + R)^\top. 
% \end{align}
% \end{assumption}
% The structure in \cref{eqn:structure-of-Mtest} models the fact that the test-time mean and variance shifts can consist of a mixture of "identified" directions $S$ and "new", previously unobserved,  directions $R$. 
%In the following theorem, we derive an expression for the \idRRs in the linear SCM setting and establish a population-level lower bound on the minimax quantity describing the \emph{best achievable robustness} as a function of test shift strength as well as the "amount of non-identifiability" in the test shift \julia{rephrase}. 
Furthermore, we denote by $\Cker \coloneqq \sqrt{C^2 - \| \betastarS\|^2}$ the maximum norm of the non-identified part of the true parameter $\betastar$. Finally, recall that the reference distribution $\PoXYarg{\thetastar}$ is observed and hence identifiable. 

\begin{theorem}\label{thm:pi-loss-lower-bound}
    Assume that the training and test data follow the data-generating process as in \cref{sec:training-data} 
    and $\Mtest$ satisfies Assumption~\ref{as:Mtest-structure} for some $\Mseen,R$ with $\range (\Mseen) \subset \cS$, $\range (R) \subset \cSperp$. 
    %\fy{can we skip whats next?}
    %with orthogonal columns s.t. $\range S \subseteq \cS$, $\range R \subseteq \cSperp$.
    %$\projM =  S S^\top + R R^\top$ as in \cref{eqn:Mtestdecomposition} and $\Stot= \R^d - \range R$, where $\rnk R > 0$. 
    Further, let Assumption~\ref{as:bounded-betastar} hold with parameter $C$.
    %as in \cref{sec:training-data}. Assume that the distribution shift during test time is bounded by $\gamma \projM$ as in \cref{eqn:testAbound}. 
    %Recall the orthogonal decomposition $\gamma \projM = \gamma S S^\top + R R^\top$ into training-time shifts $S$ and unobserved shifts $R$. 
    %Further, define by $\Stot = \R^d - \range R$ the space of directions which are either identified or unperturbed during test time. Denote by $\Cker = \sqrt{C^2 - \| \betastarS\|^2}$ the maximum norm of the non-identified part of the causal parameter $\betastar$. \par 
    %\begin{enumerate}[(a)]
    %\item 
    The \idRRs \eqref{eqn:PI-robust-loss}
    %, computable from training distributions, 
    is then given by 
    \begin{equation}\label{eqn:ID-robust-risk-formula}
        \Lossrobpi(\beta;\Invset,\Mtest) = \gammaprime  (\Cker + \| R^\top \beta \|_2)^2 + \gamma (\betastarS - \beta)^\top \Mseen (\betastarS - \beta) + \Loss(\beta;\PoXYarg{\thetastar}).
    \end{equation}
The minimax quantity in \cref{eqn:minimax-quantity} is lower bounded as follows:
\begin{align} 
    &\minimaxPIloss\begin{cases}
            = \gammaprime \Cker^2 + \min_{R^\top \beta = 0} \Lossrob(\beta;\thetacS, \gamma \Mseen), & \text{if} \: \gammaprime \geq \gammath;\\
            \geq \gammaprime  \Cker^2 + \min_{\beta \in \R^d} \Lossrob(\beta;\thetacS,\gamma \Mseen) , & \text{else},  %\nolabel
            %\text{if} \: \gamma < \gammath,
            %if} \: \gamma \geq \gammath.
        \end{cases}\label{eqn:thm-minimax} 
\end{align}
where $\gammath = \frac{(\kappa(\noisecovxxstar) + 1) \norm{R R^\top \noisecovxyS}}{\Cker}$\footnote{$\kappa$ denotes the condition number of the covariance matrix $\noisecovxxstar$.}. 
\begin{comment}
Further, for $\gamma \geq \gammath$, %equality holds and
one can identify 
%there exists a prediction model 
a model $\betarobpi$ %computable from training data,
that achieves this minimax value. 
\fy{see question on slack, this seems clear from the results}
\end{comment}
Moreover, for small unseen shifts % it holds that
\begin{align}\label{eqn:minimax-limit}
    \lim_{\gammaprime \to 0} \frac{\minimaxPIloss}{\gammaprime} = (\Cker + \| R R^\top {\noisecovxxstar}^{-1} \noisecovxyS\| )^2.
\end{align}
% \end{enumerate}
%for   $\gamma \geq \gammath$.
%and $c = \Cker \| R R^\top {\noisecovxxstar}^{-1} \| + \| {\noisecovxxstar}^{-1} \|^2$.
%For $\gamma \geq \gammath$, the lower bound achieves equality. 

%\item If $\gamma \geq \gammath$, the PI-robust estimator is given by 
%\begin{align}\label{eqn:PI-estimator-closed-form}
%     \betarobpi = \min_{\substack{\beta \in \R^d \\ R^\top \beta = 0}} \Lossrob(\Robsetarganchor, \beta) =   \betastarS + \Stot [ \Stot^\top (\gamma S S^\top + \noisecovxx) \Stot ]^{-1} \Stot^\top \noisecovxyS.
%\end{align}
%\end{enumerate}
\end{theorem}
%     \begin{figure}
%     \centering
%     \includegraphics[width = 0.4\textwidth]{paper/contents/images/synthetic_plot_paper.pdf}
%     \caption{Mean-squared error on the worst-case test distribution for synthetic Gaussian data. }
%     \label{fig:synthetic-experiments}    
% \end{figure}
%\fy{moved down from theorem:}
%In particular, it holds that  $\Lossrobpi(\beta, \Invset;\gamma, \cM) \geq \gamma \Cker^2$. \fy{why is this here?} 
We prove \cref{thm:pi-loss-lower-bound} in \cref{sec:apx-proof-of-main-prop}. First, in the case of no new test shifts where $\gammaprime = 0$ (as it appears in prior work \citep{rothenhausler2021anchor,shen2023causalityoriented}) we can plug in the robust risk \Cref{eqn:robust-risk} into \Cref{eqn:thm-minimax} to observe the following: as the strength $\gamma$ of the shift grows, the optimal robust risk saturates.
%\fy{i still don't know what this means - is upper bounded? i don't even understand which result you're referring to here}.\julia{quickly prove?}
On the other hand, 
%Our result shows that 
if $\gammaprime \neq 0$, i.e., the test shift contains new directions w.r.t. to the training data, the best achievable robustness $\minimaxPIloss$ grows linearly with $\gammaprime$.
%, and thus no infinite robustness is possible. 
\begin{comment}
\paragraph{Comparing $R \neq 0$ with $R=0$} This stands in stark contrast to the setting of  $\rnk R = 0$, where 
using \fy{ equation bla} and minimizing with respect to $\beta$ we obtain by simple calculation that
, 
the minimax quantity is equal to the minimum of the test loss with test shift covariance $\Sigmatest = \gamma SS^\top$
%\fy{identifiable robust loss is equal to the test loss on a particular distribution}
\begin{equation*}
    \min_\beta \Lossrobpi(\beta, \Invset;\gamma, \cM)  =
    %\min_\beta \Lossrob(\beta, \thetacS; \gamma, S) = 
    \min_\beta   (\betastar - \beta)^\top (\noisecovxxstar + \gamma SS^\top ) (\betastar-\beta) +  2\noisecovxystar (\betastar - \beta) + c
    %\Loss(\probtestXY, \beta)
\end{equation*}
where c is independent of gamma and beta.
\fy{or maybe call this probS}
%where $\probtestXY$ \fy{has} the test shift distribution $\probtestA$ has covariance $\Sigmatest = \gamma SS^\top$
%where the 
and the minimax quantity is equal to the minimum robust risk and by simple calculation \fy{also in previous work yields}
% i.e. the test shift contains no new directions w.r.t. to the training distributions, where it holds that 
\begin{align*}
    \minimaxPIloss = \min_{\beta \in \R^d} \Lossrob( \beta, \thetacS;\gamma, S) = \noisecovyyS - {\noisecovxyS}^\top (\noisecovxxstar + \gamma S S^\top)^{-1} \noisecovxyS,
\end{align*}
is bounded for all $\gamma$ and infinite robustness is achievable (compare Figure~\ref{fig:sub1}).
In the next section we discuss how methods for this setting (assuming $\rnk R=0$) fare in the setting when $\rnk R>0$.
\end{comment}
Further note that for $\gammaprime \geq \gammath$, we have a  tight expression for the minimax quantity
%equals the optimal \idRRs and thus is tight. 
%Moreover, when $\gammaprime \geq \gammath$, 
and the worst-case robust predictor $\betarobpi$ can be explicitly computed 
%from the training distributions 
(cf. \Cref{sec:apx-proof-of-main-prop}) and is \emph{orthogonal} to the space $\range (R)$ of new test shift directions. 
% in closed form:
% \begin{align}\label{eqn:abstaining}
%     \betarobpi &= \betastarS + \Stot [ \Stot^\top (\gamma S S^\top + \noisecovxx) \Stot ]^{-1} \Stot^\top \noisecovxyS.
% \end{align}
In other words, for large shifts in new directions, the optimal robust model would "abstain" from prediction in those directions. For smaller shifts $\gammaprime$, $\betarobpi$ gradually utilizes more information in the non-identified directions, thus interpolating between maximum predictive power (OLS) and robustness w.r.t. new directions (abstaining). 
%Note that 
The model $\betarobpi$ is a population quantity that is identifiable from the collection of training \emph{distributions}. When only finite samples are available, we discuss in \cref{sec:apx-empirical-estimation}
how we can compute the worst-case robust estimator by minimizing
%we discuss how the \idRRs gives rise to the
an empirical loss function
%\eqref{eqn:rob-loss-ell-sample} 
that can be computed from multi-environment data. 
% Additionally, in \cref{sec:apx-empirical-estimation}, we provide details on the computation of the empirical \idRRs and the corresponding estimator. 


\subsection{Theoretical analysis of existing finite robustness methods}\label{sec:comp-with-finite-robustness-methods}
%We now discuss how previous analyses of finite robustness relate to our partial identifiability framework. We show how, when $R = 0$, our framework reduces to existing robustness settings.  \fy{from how i read it we already showed it?} In contrast, 
We now evaluate existing finite robustness methods in our partial identifiability framework and 
characterize their (sub)optimality in different scenarios.
%discuss in which scenarios they are far from the best achievable robustness. 
A spiritually similar systematic comparison of domain adaptation methods is presented in \cite{chen2021domain}, however, in our setting, the robust risk is not identifiable from data. 
%\paragraph{Theoretical analysis} 
Concretely, we compare discrete anchor regression \cite{rothenhausler2021anchor} and pooled OLS estimators \footnote{In \cref{sec:apx-anchor-connections}  we show that analogous results hold for continuous anchor regression and the method of distributionally robust invariant gradients (DRIG) \cite{shen2023causalityoriented}.} with the minimax quantity in \Cref{thm:pi-loss-lower-bound}. We consider the same scenario as in discrete anchor regression, which is a the specific case of the setting in \Cref{eqn:SCM}, where for each environment $e$, $\Ae$ is just a mean shift with variance $0$.
%we observe data $(\Xe, \Ye)$ according to the model $\Xe= \mue + \eta; \: \Ye = {\betastar}^\top \Xe + \xi$, where $\mue \in \R^d$ are mean shifts and the noise is distributed like in \cref{eqn:SCM}. 
In addition, discrete anchor regression assumes that the environment variable $E \in \Ecaltrain$ follows a probability distribution with $\prob[E = e] = w_e$. % for comparability with previous frameworks such as anchor regression,
%which allows us to compare to the anchor regression framework and similar, 
%where the environment weights are required to \fy{define? - its part of the definition its not for the sake of estimating} obtain an estimate of $\Mtest$.
The discrete anchor setting then corresponds to setting a test shift upper bound $\Mtest = \gamma\Manchor$ for some $\gamma>0$ (cf. \Cref{eqn:testAbound}) with  $\Manchor = \sum_{e \in \Ecaltrain} w_e \mue \mue^\top$. 
The (oracle) discrete anchor regression estimator minimizes the robust risk and reads 
\begin{align}
\label{eq:betaanchor}
    \betaa = \argmin_{\beta \in \R^d} \Lossrob(\beta; \thetastar, \gamma \Manchor).
\end{align}
%where $\Manchor = \sum_{e \in \Ecaltrain} w_e \mue \mue^\top$. 
The pooled ordinary least squares (OLS) estimator $\betaOLS$ corresponds to $\betaa$ with $\gamma = 1$.  We observe that the test shifts bounded by $\gamma \Manchor$ are fully contained in the space of identified directions $\cS$, since $\cS = \range (\cup_{e \in \Ecaltrain} \mue \mue^\top) = \range (\Manchor)$.  Thus, according to \cref{prop:invariant-set}, the robust risk and robust predictor $\betaa$ are identifiable for all $\gamma > 0$. In the next corollary, we compute worst-case robust risk of both $\betaa$ and $\betaOLS$
%We now evaluate the robustness performance of $\betaa$ and $\betaOLS$ 
with respect to the more general shifts bounded by $\Mtest := \gamma \Manchor + \gammaprime R R^\top$, thus possibly including unseen shifts consisting of additional unseen shifts $\range (R) \subset \cSperp$.
%training-identified shifts $\Manchor$ and a possibly smaller share \fy{why smaller share? is this necessary?} of previously unseen shifts in $\range R \subset \cSperp$. 
\begin{corollary}[Worst-case robust risk of the anchor regression estimator]\label{cor:estimators}
Assume that the test shift upper bound is given by $\Mtest := \gamma \Manchor + \gammaprime R R^\top$. Let %$\prob^{X,Y}_{\mathrm{train}} = \EE_E [\PeXY]$ \fy{looks weird} 
$\prob^{X,Y}_{\mathrm{train}} = \sum_{e\in\Ecaltrain} w_e \PeXY$ be the pooled training distribution. 
Then the general worst-case robust risk is given by 
\begin{align*}
    \Lossrobpi(\beta; \Invset, \Mtest) = \gammaprime (\Cker + \| R^\top \beta \|_2)^2 + (\gamma-1)(\betastarS-\beta)^\top \Manchor (\beta - \betastarS) + \Loss(\beta,\ptrain).
\end{align*}
Furthermore, for the anchor and OLS predictor, respectively, it holds that there exist functions  $c_1(\gamma),c_2(\gamma),c_3(\gamma)$ independent of $\gamma'$ such that %\fy{should this o() be universal constants?}
% With respect to $\Mtest$, the robust risk is only partially identified, and the identifiable robust risk \eqref{eqn:PI-robust-loss} given by \julia{write id. robust risk in the pooled form, in terms of anchor risk}\julia{in the corollary, write it more in the style of anchor risk}
% %in the anchor setting is given by
% %this is not anchor anymore?
% \begin{align*}
%     \Lossrobpi(\beta; \Invset, \Mtest) = \gammaprime (\Cker + \| R^\top \beta \|_2)^2 + \Lossrob(\beta;\thetastar, \gamma \Manchor). 
% \end{align*}
% We evaluate how the identifiable robust risks \eqref{eqn:ID-robust-risk-formula} of both previous methods depend on the strength $\gammaprime$ of the previously unseen shift\footnote{Here, we only vary $\gammaprime$, whereas $\gamma$ is fixed.}: 
\begin{equation*}
    \begin{aligned}
        \Lossrobpi(\betaa; \Invset, \Mtest) &= (\Cker + \| R R^\top (\noisecovxxstar + \gamma \Manchor)^{-1} \noisecovxyS \| )^2\gammaprime + c_1(\gamma); \\ 
        \Lossrobpi(\betaOLS; \Invset,\Mtest) &= (\Cker + \| R R^\top (\noisecovxxstar + \Manchor)^{-1} \noisecovxyS \| )^2\gammaprime + c_2(\gamma).
    \end{aligned}
\end{equation*}
In contrast, the best achievable robustness reads
%in the \fy{extended? - not so sure I'd refer to it as anchor setting if we have unseen shifts?} anchor setting it holds
\begin{equation*}
\begin{aligned}
%\label{eqn:optimality-of-anchor}
    \minimaxPIlossarg{\Mtest} &= \Cker^2 \gammaprime + c_3(\gamma), \: \text{ if } \gammaprime \geq \gammath; \\  \lim_{\gammaprime \to 0} \minimaxPIlossarg{\Mtest} / \gammaprime &= (\Cker + \| R R^\top (\noisecovxxstar + \gamma \Manchor)^{-1} \noisecovxyS\| )^2.
    \end{aligned}
\end{equation*}
\end{corollary}
%\julia{add proof if time permits} 
Observe that the \idRRs in the extended anchor regression setting is equal to the anchor regression risk with an additional non-identifiability penalty term $\gammaprime (\Cker + \| R^\top \beta \|_2)^2$.
% \fy{shouldn't these have equation numbers and corresponding proofs somewhere in the appendix?}
The anchor regression estimator is optimal in the limit of vanishing unseen shifts but, for any $\gamma$, significantly deviates\footnote{Notice that the term $ \| R R^\top (\noisecovxxstar + \gamma \Manchor)^{-1} \noisecovxyS\|$ is only zero (yielding the minimax risk) if $\Manchor$ is full-rank (implying $R = 0$), or if $(\noisecovxxstar + \gamma \Manchor)^{-1} \noisecovxyS \perp R$, implying that there is no meaningful confounding in the unseen test shift directions. Otherwise, it can be strictly bounded from below as $\noisecovxxstar$ is full-rank.} from the best achievable robustness for larger unseen shifts $\gammaprime \geq \gammath$. 
%. However, for larger shift strengths, the identifiable robust risk of both estimators significantly deviates from the best achievable robustness. 
Moreover, in case of completely new shifts ($\gamma = 0$), pooled OLS and the anchor estimator achieve the same rate in $\gammaprime$, showcasing how finite robustness methods can perform similarly to empirical risk minimization if the assumptions on the robustness set are not met. We provide additional performance comparisons for the more general shift in \Cref{sec:apx-anchor-connections} and the proof of the corollary in \Cref{sec:apx-proof-of-corollary}.


% \fy{sth like that:} We now discuss how previous works/analyses relate to our framework / our framework reduces to previous settings for R=0 and how these methods achieve worse robustness in the partial identifiability setting, close to OLS/ERM.
% Intuitively, they're obliviously using info you don't actually know hurts whereas we abstain.

% \begin{itemize}
%     \item Relate to pooled setting 
%     \item Define anchor test upper bound, robust loss
%     \item identified robust loss + suboptimal 
% \end{itemize}

% \label{sec:comparison}
% \begin{example}[Anchor regression \cite{rothenhausler2021anchor}]
%     In the continuous anchor regression setting, during training we 
%     observe the distribution %the training data are observed 
%     according to the SCM $X = M A + \eta$; $Y = \betastar^\top X + \xi$, where $A \sim \cN(0, \Sigma_A)$ is an observed $q$-dimensional anchor variable and $M \in \R^{d \times q}$ is a known matrix. \fy{i.e. we have this as reference environment?} The test shifts are assumed to be bounded by $\Mtest = \gamma M \Sigma_A M^\top$. Since $\range \Mtest \subset \cS = \range M$, no new directions are observed during test time, in other words, $R = 0$. 
%     The anchor regression estimator corresponds to the minimizer of the robust risk as in ~\Cref{eqn:def-rob-pred-identif}
%     %Thus, the robust predictor corresponding to the anchor regression estimator can be identified \fy{can we write a loss rather than formula? since for beta-robID we don't have a formula now either}
% %     \begin{align*}
% % \betarob = \betastarS + (\gamma M \Sigma_A M^\top + \noisecovxxstar)^{-1} \noisecovxyS = \betastar + (\gamma M \Sigma_A M^\top + \noisecovxxstar)^{-1} \noisecovxystar
% %     \end{align*}
% %     \fy{changed to betastarS in first equality... last equality didn't quite get, does betastarperp not come in with a trafo thats not identity?}
% is uniquely determined from the training data. 
% \end{example}

% The second example is close to the anchor setting but also allows variance shifts.

% \begin{example}[Distributionally robust invariant gradients (DRIG) \cite{shen2023causalityoriented}]
% \cite{shen2023causalityorientedorientedoriented} consider the setting of general additive Gaussian shifts $\delta_e \sim \cN(\mu_e, \Sigma_e)$, and the data are given by the SCM $\Xe = \delta_e + \eta$; $\Ye= \betastar^\top \Xe+ \xi$, similarly to \cref{eqn:SCM}. \fy{do you want to use Atest throughout or delta?}
% The DRIG estimator is robust with respect to test shifts $\Atest$ s.t. $\EE[\Atest {\Atest}^\top ] \preceq \gamma \sum_{e \in \Ecaltrain} w_e (\Sigma_e + \mu_e \mu_e^\top) =: \Mtest$, where $w_e > 0$ are probabilistic weights of the training environments. We observe that $\range \Mtest \subset \cS = \range \bigcup_{e \in \Ecaltrain} \left( \Sigma_e + \mu_e \mu_e^\top\right)$ (see \cref{lm:upper-bound}). Thus, no unidentified test directions are observed: $R = 0$ and the DRIG estimator also corresponds to the minimizer of the robust risk as in ~\Cref{eqn:def-rob-pred-identif}.
% %is also uniquely identifiable from training data. 
% \end{example}

% \fy{We now derive the \idRRs for these two estimators and the pooled OLS/ERM estimator}
% We derive the \idRRs of two common estimators and show in which regimes they are suboptimal compared to the best achievable robustness. We consider the (reference environment) OLS estimator $\betaOLS = \argmin_{\beta \in \R^d}\Loss(\PoXYarg{\thetacS}, \beta) =  \betastarS + {\noisecovxxstar}^{-1} \noisecovxyS$ and the oracle version of the existing finite robustness methods, $\betaprior =\argmin_{\beta \in \R^d} \Lossrob(\Robsetarganchor, \beta) = \betastarS + (\noisecovxxstar+\gamma S S^\top)^{-1} \noisecovxyS$. The estimator $\betaprior$ only protects against bounded shifts in directions on which the causal parameter has been identified. In case of mean shifts, $\betaprior$ is the discrete anchor regression estimator \cite{rothenhausler2021anchor}, and in case of equally weighted environments with variance shifts, it corresponds to the DRIG estimator \cite{shen2023causalityorientedorientedoriented}. We obtain \julia{fix margin}
% \begin{equation}\label{eqn:rates-of-estimators}
%     \begin{aligned}
%         \Lossrobpi(\betaOLS, \Invset;\gamma, \cM) / \gamma  &= \left[(\Cker + \| R R^\top {\noisecovxxstar}^{-1} \noisecovxyS\| )^2 + {\noisecovxyS}^\top{\noisecovxxstar}^{-1} S S^\top {\noisecovxxstar}^{-1} \noisecovxyS \right] + o(\gamma); \\
%         %\\ &+ \noisecovyyS - {\noisecovxyS}^\top {\noisecovxxstar}^{-1} \noisecovxyS; \\
%         \Lossrobpi(\betaprior, \Invset;\gamma, \cM)/ \gamma &= (\Cker + \| R R^\top (\noisecovxxstar + \gamma S S^\top)^{-1} \noisecovxyS  \| )^2 + o(\gamma),
%     \end{aligned}
% \end{equation}
% % (\Rtilde^\top \noisecovxxstar \Rtilde)^{-1} \Rtilde^\top
% where $\Rtilde = \R^d - S$. 
% We note that the \idRRs of $\betaprior$ is strictly better than that of $\betaOLS$ in case multiple training environments are available ($\cS \neq 0$). However, both methods exhibit the same robustness if the test distribution shifts only in previously unseen directions. We observe that in the limit $\gamma \to 0$, the finite robustness method $\betaprior$ exhibits a minimax-optimal rate (compare \cref{eqn:minimax-limit}).  However, for larger shifts $\gamma \geq \gammath$, it holds that $\minimaxPIloss / \gamma = \Cker^2 + o(\gamma)$, and thus both estimators are suboptimal (compare \cref{fig:sub2}). \par
\section{Experimental results}\label{sec:exp-results}
In this section, we provide empirical evidence of our theoretical conclusions in \Cref{sec:main-results-minimax,sec:comp-with-finite-robustness-methods}.
% and \Cref{sec:comp-with-finite-robustness-methods}.
In particular, we compare the prediction performance of multiple existing robustness methods to the (estimated) minimax robustness in identifiable and partially identifiable settings.
%estimated by the \fy{worst-case?} identifiable robust predictor \fy{do we want to mention finite-sample?} -- including partially identifiable settings in which the test data contains shifts in \emph{previously unseen} directions.
%\emph{identifiable robust predictor}.
We observe that both on synthetic and real-world data, in the partially identified setting, empirical risk minimization and invariance-based robustness methods not only have significantly sub-optimal test loss but also perform similarly, thereby aligning with our theoretical results in \Cref{sec:comp-with-finite-robustness-methods}. This stands in contrast to the identifiable setting, where the anchor predictor is optimal up to finite-sample effects. Furthermore, we observe that even though the minimizer of the worst-case robust risk is optimal only for the linear causal setting in \Cref{sec:training-data},  it surprisingly outperforms existing methods in a real-world experiment.
%The gap between existing methods and the optimal robust performance grows rapidly as the proportion of unseen shifts during test time increases.
%the identifiable robust predictor has a significantly better test loss. Thus, we demonstrate that vanilla ERM and multiple existing robustness methods are suboptimal in a partially identified setting,
\label{sec:experiments}
\paragraph{Experiments on synthetic Gaussian data}
We simulate Gaussian covariates according to \cref{eqn:SCM} with multiple environments differing by linearly independent randomly selected mean shifts. For a randomly sampled collection of mean shifts, we evaluate a proxy for the worst-case robust risk by picking the most adversarial $(\betastar,\noisecovxxstar)$ for the shifts, and then computing its robust risk \eqref{eqn:robust-risk}.
We describe the full details of the data generation and loss evaluation in \cref{sec:apx-synthetic-exps}.
We consider two shift scenarios: in the 
%first one, corresponding to the 
identifiable case (see \Cref{fig:sub1-identified}), the test environment is only perturbed by bounded shifts in training directions with increasing strength $\gamma$, as considered in prior work \citep{rothenhausler2021anchor,shen2023causalityoriented}. In the 
%second scenario, corresponding to the 
non-identifiable case (see \Cref{fig:sub2-nonidentified}), the test environment is perturbed by a mixture of training shifts and shifts in previously unobserved directions, where $\gamma$ is fixed and $\gamma'$ varies (cf. Assumption~\ref{as:Mtest-structure}). 
%with respect to the confounding and the directions of the mean shifts. 
%We now compare estimators $\betaOLS$, $\betaa$ and $\betarobpi$ in a finite-sample experiment \fy{where the estimators are computed according to Appendix D?}. 
We compute the empirical minimizers $\betaOLShat,\betaahat$ and $\betarobpihat$ of the OLS, anchor regression and worst-case robust losses, respectively, and compare their worst-case robust risk (mean squared error) in Figure~\ref{fig:synthetic-experiments}. In the identifiable setting -- \cref{fig:synthetic-experiments} (left) --  he robust risk is asymptotically constant across $\gamma$ for both robust methods, while the error for the OLS, or vanilla ERM, estimator increases linearly. In contrast, in the second, partially identified, setting -- \cref{fig:synthetic-experiments} (right) -- all estimators exhibit linearly increasing test errors; however the slopes of the anchor and OLS estimator
are much steeper and lead to larger errors than the empirical minimizer of \eqref{eqn:ID-robust-risk-formula} that 
closely matches the analytic theoretical %essentially matches the 
lower bound.
%such as $\betaa$ are suboptimal, 
% \fy{define beta-prior-best (macro) then discuss how its the same as drig/anchor in certain settings. then corollary - that also includes achievability - or above?}
% \paragraph{Discussion.}
% \cref{thm:pi-loss-lower-bound} describes the best achievable robustness in multiple regimes. As summarized in  \cref{tab:rates-of-estimators}, we note that the OLS estimator is minimax-optimal for small perturbations in unidentified directions. However, for larger shifts, both OLS and anchor\footnote{In this section, we use the name "anchor" to describe the optimal estimator w.r.t. identified shift directions, i.e. $\beta_{\text{anchor}} = \argmin_{\beta \in \R^d} \gamma \| S^\top (\betastarS - \beta) \|_2^2 + \Loss(\PoXYarg{\thetacS}, \beta)$. The real anchor regression estimator might exhibit a worse rate.} estimators become increasingly suboptimal (compare \cref{fig:sub2}), whereas the \idpreds gradually "abstains" from using unseen directions for prediction. Finally, for $\gamma \geq \gammath$, the optimal estimator fully projects out data on previously unobserved directions and does not utilize it for prediction.
% \begin{table}[h!]
%     \centering
%     \caption{Best achievable robustness of common estimators. \fy{make corollary} }\label{tab:rates-of-estimators}
%     \begin{tabular}{c|c}
%         Estimator &  Rate \\
%         \hline
%        OLS  & $\gamma (\Cker + \| R R^\top {\noisecovxxstar}^{-1} \noisecovxyS\| )^2$ \\
       
%        anchor  & $\gamma (\Cker + \| R R^\top {\noisecovxxstar}^{-1} \noisecovxyS\| )^2$ \\
       
%        ID-robust  & $\gamma (\Cker + \| R R^\top {\noisecovxxstar}^{-1} \noisecovxyS\| )^2 \text{ if } \gamma \text{ small},\, \gamma \Cker^2 \text{ for }\, \gamma \geq \gammath$\\
%        \hline
%     \end{tabular}
% \end{table}
%     1. results for the other estimators and comparison in plots 
% 2. Interpretation in terms "abstention" on what you don't know and what isn't changing. \fy{sounds a bit trivial} 
% In contrast to the commonly considered setting where the test shifts are assumed to be in the span of the identified directions from training (e.g. \cite{rothenhausler2021anchor} or \cite{shen2023causalityoriented}), in the partially identified setting, no infinite robustness is possible, since the best achievable robustness grows linearly with the shift strength $\gamma$. Additionally, it scales quadratically with $\Cker$, which is a measure of non-identifiability of the causal parameter. 
% For large enough shift strengths $\gamma \geq \gammath$, the \idRRs landscape corresponds to minimization of the "identified part" of the robust loss $\Lossrob(\Robsetarganchor, \beta)$ subject to the constraint $\beta \in \range \Stot$. Thus, if large shifts in  previously unobserved directions are expected, the optimal estimator should be constrained to the "safe space" $\Stot$ consisting of identified and unperturbed directions. 
\begin{figure}[ht]
\centering
% \begin{subfigure}{.5\textwidth}
%   \centering
%   \includegraphics[height=4cm]{paper/contents/images/final_anchor_plot.png}
%   \caption{No new test directions.}
%   \label{fig:sub1anchor}
% \end{subfigure}%
% \begin{subfigure}{.5\textwidth}
%   \centering
%   \includegraphics[height=4cm]{paper/contents/images/final_plot_non_id_new_directions.png}
%   \caption{A small proportion of unseen test directions.}
%   \label{fig:sub2nonid}
% \end{subfigure}
\includegraphics[width=\textwidth]{contents/images/synthetic_noref.pdf}
\caption{\small{Worst-case robust risk 
%Test error under a partially unidentified distribution shift $\Atest$ 
of the baseline estimators $\betaOLS, \betaa$ (using the "correct" $\gamma$),  
%for shifts with bounded strengths $\gamma,\gamma'$ for finite robustness 
the worst-case robust predictor in (mean-shifted) multi-environment finite-sample experiments and theoretical population lower bound in the classical identified setting with varying shift strength $\gamma$ (left) and the partially identifiable setting with fixed $\gamma$ but varying $\gamma'$ (right).  The details of the experimental setting can be found in \Cref{sec:apx-experiments}}. }
\label{fig:synthetic-experiments}
\end{figure}
% \subsection{Optimal estimator}\label{sec:optimal-estimator}


% \begin{proposition}\label{lm:empirical-pi-robust-loss}
% Let $\{ (X^e, Y^e) \}_{e \in \Ecaltrain}$ be the multi-environment training data, where $X^e \in \R^{n_e \times d}, Y^e \in \R^{n_e}$. Define $\cS$ and $\cSperp$ as previously.  Let $\Mtest = \gamma \cP_cM = \gamma (S S^\top + R R^\top)$ be the assumed direction and strength of the test shift. Let $\betastarS \in \R^d$ be the identified causal parameter. Let $C > 0$ be an upper bound on the norm of the true causal parameter and $\Cker = \sqrt{C^2 - \| \betastarS \|^2}$. Then
% \begin{align}\label{eqn:population-PI-robust-loss}
%     \betarobpi = \min_{\beta \in \R^d} \left[ \gamma (\Cker + \| R^\top \beta \|_2)^2 + \gamma \| S^\top (\betastarS - \beta) \|_2^2 + \frac{1}{n_0} \| Y^0 - X^0 \beta \|_2^2  \right].
% \end{align}
% If $\gamma \geq \frac{(\kappa(\noisecovxxstar) + 1) \norm{\noisecovxyS}}{\Cker}$, it holds that
% \begin{align}\label{eqn:PI-estimator-closed-form}
%    \betarobpi = \min_{\substack{\beta \in \R^d \\ R^\top \beta = 0}} \Lossrob (\cP^{\gamma S S^\top}, \beta) =   \betastarS + \Stot [ \Stot^\top (\gamma S S^\top + \noisecovxx) \Stot ]^{-1} \Stot^\top \noisecovxyS,
% \end{align}
% where $\Stot = \cS \cup (\cSperp - \range R)$. 
% \end{proposition}


% \subsection{Robust estimator}
% - Theorem: proposed estimator [NAME] achieves the following population lower bound (for large gamma). \\
% - Discuss identifiability of the estimator [NAME]. \\
% - Theorem: finite sample / regularized / small gamma version of the estimator. \\
% - Comparison to existing estimators. 
% - population lower bound, justification of regularization, comparison to above for small and large gamma 
\paragraph{Real-world data experiments} 
We evaluate the performance of OOD methods using single-cell gene expression data from \cite{replogle2022mapping}, consisting of $d = 622$ genes across observational and interventional environments.
% We now consider the Causalbench single-cell dataset introduced by \citep{chevalley2022causalbench}.
% The dataset consists of single-cell observations of 622 genes.
% The interventional environments arise by knocking down a single gene at a time using the CRISPR interference method \citep{qi2013repurposing}. 
As in \citep{schultheiss2024assessing}, we focus on 28 genes active in the observational environment.
%, resulting in the total of $28$ genes.
For each gene $j = 1, \ldots, 28$, we define the target variable $Y := X_j$ and select the three genes most strongly correlated with $Y$ as covariates. This yields 28 prediction problems indexed by $j$,
%$D_j$ 
each consisting of data from an observational environment $\mathcal{O}$ and three interventional environments $\mathcal{I}_{j1}$, $\mathcal{I}_{j2}$, $\mathcal{I}_{j3}$ representing the gene knockout on a single covariate.
% For each gene $j = 1, \ldots, 28$, 
% we generate a dataset $D_j$ where $Y\coloneqq X_j$ is the target variable and the covariates are the three genes most strongly correlated with $Y$.
%For each of the resulting datasets, 
For each prediction problem, we consider three training datasets $D_{j1}$, $D_{j2}$, $D_{j3}$, obtained by combining data from $\mathcal{O}$ with a single interventional environment $\mathcal{I}_{j1}$, $\mathcal{I}_{j2}$, $\mathcal{I}_{j3}$, respectively.
For each training dataset $D_{jk}$, $k = 1, 2, 3$, we evaluate the mean-squared error (MSE) at test time using four datasets consisting of varying proportions of unseen shifts (e.g., ``$33\%$ unseen directions'' in \Cref{fig:genes-res-weights} represents a test dataset with $67\%$ observations sampled from $\mathcal{I}_{jk}$ and $33\%$ from $\mathcal{I}_{j\ell}$ with $\ell \neq k$).
Hence, for each prediction problem predicting a gene $j$, we evaluate on
%This setup ensures that each $D_j$ \fy{don't really know what it means to say a dataset is evaluated} is evaluated across 
12 configurations (three training and four test datasets).\footnote{An illustration of the training and test setups can be found in \cref{fig:genes}.}
\Cref{fig:genes-res-weights} illustrates the test MSE of the worst-case robust estimator (Worst-case Rob.) alongside anchor regression, invariant causal prediction (ICP) \cite{peters2016causal}, DRIG, and OLS, as a function of perturbation strength 
$s$. \footnote{Details on the tuning parameter for each method are in \Cref{sec:apx-real-world}.}
% \fy{gives refs to appendix where we should briefly say how they're used?}
For a given proportion of unseen shifts, $s$ controls the distance of the test data points from the observational mean, acting as a proxy for shift strengths $\gamma$ and $\gamma'$. \footnote{More details on the shift strength can be found in \Cref{sec:apx-real-world}.}
% For each $D_j$, we perform three experiments -- every experiment uses a different interventional environment besides the observational data as training data (an illustration of the data structure can be found in \cref{fig:genes}).
%picking as training data the observational data and subsampled data from \emph{one} interventional environment. 
% We then separately compute the mean-squared error on subsets of samples from all three interventional environments (including held-out samples from the interventional environment used for training). 
% The subsets are picked according to 
% a proxy for the desired shift strength of the test environment ($\gamma>0$ in previous sections):
% As a proxy for shift strength $\gamma > 0$, 
% for each test environment, we pick the fraction $s \in (0, 1)$ of data points closest to the observational mean. More details on this process can be found in \Cref{sec:apx-experiments}. 
% We describe the computation of the identifiable robust estimator in \Cref{sec:apx-empirical-estimation}.
% In \cref{fig:genes-res-weights}, we show the test MSE of various OOD methods and the identifiable robust estimator as a function of $s$, presented in four different scenarios: no unseen shifts (left), some proportion of unseen shifts (middle panels) and $100\%$ unseen shift directions (right).  \fy{describe what this means, maybe also in caption}
% We compare the performance of anchor regression \citep{rothenhausler2021anchor}, invariant causal prediction (ICP) \citep{peters2016causal},  Distributional Robustness via Invariant Gradients (DRIG) \cite{shen2023causalityoriented}, and OLS with our estimated lower bound Rob-ID. 
We observe that 
the performance ranking of the robustness methods significantly
%optimality of robustness methods 
varies with the proportion of new test shift directions. As expected, when no new shift 
% \rmnico{information  is present} 
directions are present at test time (0\%), 
anchor regression and DRIG are optimal, 
since they protect against shifts observed at training time. However, as soon as some unseen directions are present, their performance
becomes inferior to OLS/ERM and the gap to the worst-case robust predictor (in the linear setting described in \Cref{sec:setting})
% \Nicola{don't understand ``in the setting in ...''} \fy{in or of or sth?}
grows with the proportion of unseen shifts.
Further, while the MSE of the previous invariant methods increases significantly with 
%The gap grows with both 
the strength of the test shift $s$,
%and. In contrast, 
the test loss of the worst-case robust predictor remains relatively stable.
%as the proportion of unseen test shift direction grows.
% \begin{figure}[!h]
%     \centering
%     \begin{subfigure}[b]{0.45\textwidth}
%         \centering
%         \includegraphics[scale=.65]{paper/contents/images/lines.pdf}
%         \caption{}
%         \label{fig:fig1}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.45\textwidth}
%         \centering
%         \includegraphics[scale=.65]{paper/contents/images/line_dominates.pdf}
%         \caption{}
%         \label{fig:fig2}
%     \end{subfigure}
%     \caption{
%     The figures show the performance of the \emph{identifiable robust predictor} (Rob-ID) compared to other methods as a function of perturbation strength $s$ ($s \%$ of datapoints closest to the obs. mean).
%     Panel~(a) shows the test MSE for each method.
%     Panel~(b) shows the percentage of times Rob-ID outperforms the other methods.
%     In both panels, for each perturbation strength $s$, each point represents an average over the 28 target genes, 3 training environments $\Dtrain_i$ for $i \in \{1, 2, 3\}$,  and 3 test environments $\Dtest_{j, s}$ for $j \in \{1, 2, 3\}$.
%     }
%     \label{fig:genes-res}
% \end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{contents/images/lines_settings.pdf}
    \caption{
    \small{ 
    %\fy{dotted line between 0 and others, say what the numbres 33, 67\% etc. mean} 
    %\Nicola{I don't think we have space I already explained in main text}
    The figures show the performance of the \emph{worst-case robust predictor} (Worst-case Rob.) compared to other methods as a function of perturbation strength $s$.
    Different panels correspond to the proportion of unseen shift directions at test time.
    For each panel and perturbation strength $s$, each point represents an average over the 28 target genes and three experiments (i.e., training environments).}
    }
    \label{fig:genes-res-weights}
\end{figure}