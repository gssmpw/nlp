\subsection{The setting of continuous anchor regression \cite{rothenhausler2021anchor}}\label{subsec:anchor}
In this section, we evaluate the \idRRs of the continuous anchor regression estimator.
    In the continuous anchor regression setting, during training we 
    observe the distribution %the training data are observed 
    according to the process $X = M A + \eta$; $Y = {\betastar}^\top X + \xi$, where $A$ is an observed $q$-dimensional anchor variable with mean $0$ and covariance $\Sigma_A$ and $M \in \R^{d \times q}$ is a known matrix. Note that in this setting, we do not have a reference environment, but, since the anchor variable is observed, the distribution of the additive shift $M A$ is known.  The test shifts are assumed to be bounded by $\Mtest = \gamma M \Sigma_A M^\top$. Since $\range(\Mtest )\subset \cS = \range(M)$, no new directions are observed during test time, in other words, $R = 0$. Thus, both the corresponding robust loss and the anchor regression estimator can be determined from training data. It holds that
\begin{align*}
    \betaa = \argmin_{\beta \in \R^d} \Lossrob(\beta; \thetastar,\gamma M \Sigma_A M^\top).
\end{align*}
Again, the pooled OLS estimator corresponds to $\betaa$ with $\gamma = 1$. Similar to the discrete anchor case, in case the test shifts are given by $\Mnew = \gamma M \Sigma_A M^\top + \gammaprime R R^\top$, the worst-case robust risk \eqref{eqn:PI-robust-loss} is given by
\begin{align*}
    \Lossrobpi(\beta; \Invset, \Mnew) = \gammaprime (\Cker + \| R^\top \beta \|_2)^2 + \Lossrob(\beta; \thetastar,\gamma M \Sigma_A M^\top) 
\end{align*}
and for the best worst-case robustness of the anchor estimator it holds 
\begin{align*}
    \Lossrobpi(\betaa, \Invset; \Mtest)&= (\Cker + \| R R^\top (\noisecovxxstar + \gamma M \Sigma_A M^\top )^{-1} \noisecovxyS \| )^2 \gammaprime + \text{const}; \\
    \lim_{\gammaprime \to 0} \Lossrobpi(\betaa, \Invset;\Mnew)/\gammaprime &= \lim_{\gammaprime \to 0} \minimaxPIlossarg{\Mnew}/ {\gammaprime}.
\end{align*}
The above results follow by analogy with \cref{sec:apx-proof-of-corollary}.

\subsection{Distributionally robust invariant gradients (DRIG) \cite{shen2023causalityoriented}}\label{subsec:drig}
DRIG \cite{shen2023causalityoriented} introduce a more general additive shift framework, where a collection of additive shifts $\Ae$ is given with moments $(\mue,\Sigmae)$. For each environment $e$, we observe data $(\Xe, \Ye)$ distributed according to the equations $\Xe= \Ae + \eta; \: \Ye = {\betastar}^\top \Xe + \xi$, where the noise is distributed like in \cref{eqn:SCM}. This DGP arises from the structural causal model assumption as described in \cref{fig:ex-scm}.  DRIG consider more a more general intervention setting, additionally allowing additive shifts of $Y$ and hidden confounders $H$. However, their identifiability results can only be shown for the case of interventions on $X$, and since identifiability of the causal parameter is a crucial part of our analysis, we only consider shifts on the covariates. DRIG assumes existence of a reference environment  $e = 0$ with $\mu_0 = 0$ and for which it is required that the second moment of the reference environment is dominated by the second moment of the training mixture: 
\begin{align*}
    \Sigma_0 \preceq \sum_{e \in [m]} w_e (\Sigma_e + \mu_e \mu_e^\top).
\end{align*}
This assumption allows \cite{shen2023causalityoriented} to derive the DRIG estimator which is robust against test shifts upper bounded by $\Mdrig :=  \gamma \sum_{e \in [m]} w_e (\Sigma_e - \Sigma_0 + \mu_e \mu_e^\top)$. The following lemma allows us to make further statements about $\Mdrig$:
\begin{lemma}\label{lm:span-inclusion}
    Let $A$ and $B$ be positive semidefinite matrices such that $B \preceq A$. Then it holds that $\range(B) \subset \range(A)$. 
\end{lemma}
\begin{proof}
    It suffices to show that $\ker(A) \subset \ker(B)$. ($\ker(A) \subset \ker (B)$ implies that $\range(A) = \ker (A)^\perp  \subset \ker(B)^\perp = \range(B)  $.) Consider $x \in \ker(A)$, $x \neq 0$. Then it holds that $x^\top (A - B) x = x^\top A x - x^\top B x = 0 - x^\top B x \geq 0$, from which it follows that $x^\top B x = 0$ and thus $x \in \ker(B)$. 
\end{proof}
Because of the assumption $\Sigma_0 \preceq \sum_{e \in [m]} w_e (\Sigma_e + \mue \mue^\top)$, by \cref{lm:span-inclusion} it follows that $\range(\Sigma_0) \subset \range \sum_{e \geq 1} ( \Sigma_e + \mu_e \mu_e^\top )$  and thus 
\begin{align*}
\range(\Mdrig) \subseteq \range\left( \sum_{e \geq 1} w_e (\Sigma_e + \mu_e \mu_e^\top) \right). 
\end{align*}
Hence, the robustness directions achievable by DRIG in the "dominated reference environment" setting are the same as the ones under the assumption $\Sigma_0 = 0$. \\
Again, we observe that the test shifts bounded by $\gamma \Mdrig$ are fully contained in the space of identified directions $\cS$. If the test shifts are instead bounded by $\Mnew := \gamma \Mdrig + \gammaprime R R^\top$,  including some unseen directions $\range(R) \subset \cSperp$, the robust risk in the DRIG setting is only partially identified. The worst-case robust risk \eqref{eqn:PI-robust-loss} is given by 
\begin{align*}
    \Lossrobpi(\beta; \Invset, \Mnew) = \gammaprime (\Cker + \| R^\top \beta \|_2)^2 + \Lossrob(\beta; \thetastar, \gamma \Mdrig),
\end{align*}
and again, the DRIG estimator is optimal for infinitesimal shifts $\gammaprime$ and suboptimal for larger $\gammaprime$:
\begin{equation*}
    \begin{aligned}
        \Lossrobpi(\betaDRIG; \Invset,\Mnew) &= (\Cker + \| R R^\top (\noisecovxxstar + \gamma \Mdrig)^{-1} \noisecovxyS \| )^2 \gammaprime + \text{const}; \\ 
\text{whereas }\frac{\minimaxPIlossarg{\Mnew}}{\gammaprime} &= \Cker^2, \: \text{ if } \gammaprime \geq \gammath; \\  \lim_{\gammaprime \to 0} \frac{\minimaxPIlossarg{\Mnew}}{\gammaprime} &= (\Cker + \| R R^\top (\noisecovxxstar + \gamma \Mdrig)^{-1} \noisecovxyS\| )^2.
    \end{aligned}
\end{equation*}
The above results follow by plugging $\Mnew$ with $M := \Mdrig$ into the proof of \cref{cor:estimators} in \cref{sec:apx-proof-of-corollary}.

% Thus, the anchor regression estimator is optimal in the limit of small unseen shifts. However, for larger shift strengths, the worst-case robust risk of both estimators significantly deviates from the best achievable robustness. Moreover, under some conditions on the covariance matrix\footnote{E.g., if $\noisecovxxstar$ is block-diagonalizable w.r.t. $\cS$ and $\cSperp$.}, pooled OLS and the anchor estimator achieve the same rate in $\gammaprime$, showcasing how a finite robustness method can perform similarly to empirical risk minimization if the assumptions on the robustness set are not met.




% We discuss how to extend our results to the general additive shift setting described in \cite{shen2023causalityoriented}. We consider a discrete training environment variable $\Etrain$, which takes values in $[m]$ with probability mass function $\prob(\{\Etrain = e\}) = w_e$ for some positive weights $w_e > 0$. Conditioned on the event $\Etrain = e$, 
% % We denote the data $(X, Y) \in \R^{d+1}$ conditioned on $\Etrain = e$ by $(\Xe, \Ye)$. For each environment $\Etrain = e$, 
% the data are generated according to the SCM~\eqref{eqn:SCM}.
% % \begin{align}\label{eqn:generalSCM}
% %     \Xe &= \Ae + \eta, \\
% %     \Ye &= \betastar^\top X^e + \xi,
% % \end{align}
% % where $\Ae \sim \cN(\mu_e, \Sigma_e)$ and $U = (\eta, \xi) \sim \cN(0, \Sigma_U)$.
% We now discuss how the assumption that there exists a reference environment $e = 0$ for which it holds that $\mu_0 = 0$ and $\Sigma_0 = 0$ relates to the conditions in \citep{shen2023causalityoriented}. First, notice that the first restriction is met by centering all data around $\mu_0$. The second condition is formulated weaker in \cite{shen2023causalityoriented}, where it is solely required that the second moment of the reference environment is dominated by the second moment of the training mixture: 
% \begin{align}
%     \Sigma_0 \preceq \sum_{e \in [m]} w_e (\Sigma_e + \mu_e \mu_e^\top).
% \end{align}

% This assumption allows \cite{shen2023causalityoriented} to derive the DRIG estimator which is robust against test shifts upper bounded by $ \gamma \sum_{e \in [m]} w_e (\Sigma_e - \Sigma_0 + \mu_e \mu_e^\top)$. However, since $\Sigma_0 \preceq \sum_{e \in [m]} w_e \Sigma_e$, it follows that $\range\ \Sigma_0 \subset \cup_{e \geq 1} \range\(\Sigma_e + \mu_e \mu_e^\top )$ (see \cref{lm:span-inclusion}) and thus 
% \begin{align*}
% \range\ \left( \sum_{e \in [m]} w_e (\Sigma_e - \Sigma_0 + \mu_e \mu_e^\top) \right) \subset \range\ \left( \sum_{e \geq 1} w_e (\Sigma_e + \mu_e \mu_e^\top) \right). 
% \end{align*}
% Hence, the robustness directions achievable by DRIG in the $\Sigma_0 = 0$ setting are the same as in the general reference environment setting. 
