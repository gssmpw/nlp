This paper introduces the
\idRRs â€“ a quantity that is well-defined
% and can be computed 
even in settings where the usual robust risk is not computable from training distributions,
%new minimax quantity that quantifies the non-identifiability of the robust risk given multiple environments and provides its lower bound. The introduced identifiable robust risk
and in identifiable scenarios \citep{rothenhausler2021anchor,shen2023causalityoriented} reduces to the conventional robust risk.
%and expands these frameworks to more general conditions on the test shift. 
We instantiate our general framework for linear models with additive distribution shifts and compute tight lower bounds for this setting.
% and show how existing robustness methods are suboptimal. 
Further, we demonstrate how i) the benefits of invariance-based robustness methods strongly decrease in the partially identifiable setting; and ii) this suboptimality increases with perturbation strength and proportion of previously unobserved test shifts.
%\fy{this doesn't seem our main point anymore-rewrite}
%We demonstrate that in 
%partially identifiable settings,
%some ill-posed identifiability settings, 
%ERM and existing robust methods might have similar performance
%rates, supporting claims that ERM might be state-of-the-art under unseen test distribution shifts. 

The main limitation of our paper is its reliance on a linear setting to explicitly compute the \idRRs and the corresponding minimax quantity. However, we expect that the results and intuition developed in this paper  can be extended to linear shifts in a 
%utilized beyond linear models, since realistic distribution shifts can be often reduced to linear shifts in a 
lower-dimensional latent space via a suitable parametric or non-linear map \citep{thams2022evaluating, buchholz2024learning}. Important future directions include extending our results to more general shift models, non-linear functional relationships and the classification setting. 
Further, a potential use of our work is in the field of \emph{active intervention selection} (e.g, \citep{zhang2023active, gamella2020active}). By computing the most adversarial model parameter for a given estimator, e.g., OLS, we can obtain an intervention which minimizes the \idRRs of the estimator on the next unseen shift. 
