%In this section, we revise the relevant literature and how it relates with our findings. 

% Given a set of multi-environment training data we study algorithmic-independent limits of robustness to unseen perturbations at test time.
% To do so, we consider a worst-case risk optimization.
% In this paper, we combine structural assumptions on the test distribution with the notion of partial identifiability and quantify robustness limitations caused by both variables. 
\begin{table}[tbp]
    \centering
    \caption{Comparison of various distributional robustness frameworks and what kind of assumptions their analysis can account for (with an incomplete list of examples for each framework). % on identifiability.
    }\label{tab:rw}
    \vspace{1pt}
\resizebox{.8\columnwidth}{!}{%
% \setlength{\tabcolsep}{0.5pt}
\begin{tabular}{@{}cccc@{}}
\toprule
Framework accounts for~ &
  \begin{tabular}[c]{@{}c@{}}~bounded~~\\ shifts\end{tabular} & 
  \begin{tabular}[c]{@{}c@{}}partial identifiability of\\  ~~model parameters ~~\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}partial identifiability of\\  ~~robustness set\end{tabular} \\ 
  \toprule
\begin{tabular}[c]{@{}c@{}}DRO\\ \citep{bental2013robust, duchi2021learning, sinha2017certifying, mohajerin2018data, sagawa2019distributionally} \end{tabular} & \cmark & $-$  & \xmark  \\ \midrule
\begin{tabular}[c]{@{}c@{}}Infinite robustness \\
\citep{peters2016causal, fan2023environment, magliacane2018domain, rojas2018invariant,arjovsky2020invariant, ahuja2020invariant,
shi2021gradient, 
xie2020risk, krueger2021out, ahuja2021invariance}\\

\end{tabular}
& \xmark  & \xmark & \xmark \\ \midrule
\begin{tabular}[c]
{@{}c@{}}Finite robustness \\
\citep{rothenhausler2021anchor, jakobsen2022distributional, christiansen2021causal, kook2022distributional, shen2023causalityoriented}
\end{tabular} &\cmark  & \cmark  & \xmark  \\ \midrule
\begin{tabular}[c]
{@{}c@{}}
Partially id. robustness\\
(this work)~~
\phantom{~}
\end{tabular} & \cmark & \cmark & \cmark \\ \bottomrule
\end{tabular}}
% \vspace{-15pt}
\end{table} 
To put our work into context,
% To contextualize our findings,
first, we discuss relevant distributional robustness literature organized according to structural assumptions on the desired robustness set (see \cref{tab:rw}). Second, we summarize existing views on partial identifiability in the causality and econometrics literature and how our findings connect to their perspective.

\textbf{\textit{No structural assumptions on the shift.}}
\textbf{DRO:} Distributionally robust optimization (DRO) tackles the problem of domain generalization when the robustness set is a ball around the training distribution w.r.t. some probability distance measure, e.g., Wasserstein distance \cite{sinha2017certifying, mohajerin2018data} or $f$-divergences \citep{bental2013robust, duchi2021learning}.
Considering all test distributions in a discrepancy ball can lead to overly conservative predictions, and therefore, alternatives have been proposed in, e.g., the Group DRO literature \citep{sagawa2019distributionally,frogner2019incorporating, liu2022distributionally}.
However, these methods cannot protect against perturbations larger than the ones seen during training time and do not provide a clear interpretation of the perturbations class \cite{shen2023causalityoriented}.
% this is because realistic distribution shifts often exhibit strong structure or lie in a low-dimensional manifold \citep{belkin2003laplacian, block2022intrinsic}. Follow-up work try to mitigate this
% \fy{merge- to say that these are modified versions of DRO by limiting the neighborhood}
% Group DRO \cite{sagawa2019distributionally} and \cite{liu2022distributionally} modify the DRO framework to limit the ... However, we're still not happy (why? - need this to motivate next paragraphs)
%Group DRO offers a partial solution to this problem \cite{sagawa2019distributionally} by considering the the convex hull of multiple observed training distributions and thus making use of spurious correlations in the data \fy{didn't understand logic here}. However, since group DRO only protects against the convex hull of training distributions, it cannot utilize structural environment information to generalize to stronger distribution shifts. \cite{liu2022distributionally} try to mitigate the problem of overly pessimistic robustness by incorporating geometry of the data and consider the intersection of the data manifold and a Wasserstein ball as the robustness set. 
%\textbf{Covariate and label shift: } \julia{do we want this?} \nico{not sure as this seems an independent dimension. However, we could say some (all?) of the works whether they fall into one of these categories?}. \fy{i probably wouldn't?}


\textbf{\textit{Structural assumptions on the shift.}}
%\textbf{Distributionally Robust Optimization}: 
Robustness from the lens of causality takes a step further, by assuming a structural causal model \cite{pearl2009causality} generating the observed data $(X, Y)$. 
% ( assumptions on the goes one step further in structural assumptions at the expense of assuming 
%a causal DAG the covariates, that is
%his notion of \emph{invariance} can be particularly well-formalized if  one assumes 
% that the observed data $(X,Y)$ are generated by a structural causal model (the so-called \emph{causality assumption}) \cite{pearl2009causality}.
% \fy{I almost wonder if we can move some of this very relevant discussion to when we define DAG structure and robust risks etc. where it might fit in the main text}
\textbf{Infinite robustness methods:} 
% \fy{shouldn't we have one section on unbounded shifts irrespective of invariance-methods? like IV also deals with unbounded shifts?}
The motivation of causal methods for robustness is that the causal function is worst-case optimal to predict the response under interventions of arbitrary direction and strength on the covariates \citep{meinshausen2018causality, buhlmann2020invariance}. For this reason, causal models achieve what we call \emph{infinite robustness}.
Depending on the assumptions of the SCM, there are different ways to achieve infinite robustness.
When there are no latent confounders, several works \citep{peters2016causal, fan2023environment, magliacane2018domain, rojas2018invariant, ahuja2020invariant, arjovsky2020invariant, shi2021gradient, xie2020risk, krueger2021out, ahuja2021invariance}  aim to identify the causal parents and achieve infinite robustness by exploiting the heterogeneity across training environments.
In the presence of latent confounders, it is possible to achieve infinite robustness by identifying the causal function with, e.g., the instrumental variable method \cite{angrist1996identification, hartford2017deep, singh2019kernel, bennett2019deep, muandet2020dual}.
% When the shifted distributions during test time can have  arbitrary shifts in all covariates, we typically refer to robust models in such a setting having \emph{infinite robustness} \citep{meinshausen2018causality, buhlmann2020invariance}. \fy{this formulation doesn't sound that clear to me and not clearly separated from infinite strength robustness?}
% A recent line of work tries to achieve robustness by leveraging multiple environments %etting by 
% and disregard components of the data which are not invariant across datasets
%An important observation is that under the causality assumption, 
%is robust to arbitrary shifts in all covariates, typically referred to as \emph{infinite robustness} \citep{meinshausen2018causality, buhlmann2020invariance} 
% \citep{peters2016causal, fan2023environment, magliacane2018domain, rojas2018invariant, arjovsky2020invariant} and extensions \cite{shi2021gradient,krueger2021out, xie2020risk}. 
% Under a fully observed SCM, it's sufficient to learn a model that is based solely on the (observed or unobserved) \emph{causal parents} of the target variable as it is then both invariant and "infinitely" robust. 
% If we allow latent confounding \fy{is IRM allowing latent confounding??}, then the only possibility to be robust against infinite additive shifts on any covariate is to identify the causal parameter between X and Y like in the IV framework\fy{that also seems to require learning parents?}
% \fy{i would put all of the below together and not distinguish more finely} One group of invariance-based works \citep{peters2016causal, fan2023environment, magliacane2018domain, rojas2018invariant} assume that the data are generated by a fully observed directed acyclic graph (DAG), and aim to find a subset of observed covariates (usually the \emph{parents} of the target variable) which yields invariant predictions across training environments. \cite{arjovsky2020invariant} extend the invariant prediction setting to the case in which the observed covariates can be a nonlinear transformation of some latent invariant features. Extensions of \cite{arjovsky2020invariant} develop further methods to achieve invariance, e.g., matching the gradients across environments \cite{shi2021gradient} or using higher moments \cite{krueger2021out, xie2020risk}.
% , 
% \cite{bellot2020accounting}, \cite{mahajan2021domain}.
% \cite{ahuja2020invariant} game-theoretic IRM
There are several limitations to  \emph{infinitely robust} methods. First, the identifiability conditions of the causal parents and/or causal function are often challenging to verify in practice.
Second, ERM can outperform these methods when the interventions (read shifts) at test time are not arbitrarily strong or act directly on the response or latent variable \citep{ahuja2020empirical, gulrajani2021in}.
% Often, the identifiability conditions are h
% they rely on full identifiability of the local DAG structure around Y? \fy{if we want to include IV}.
%the latent invariant representation, 
% Such identifiability often requires restrictive assumptions to hold and sufficient heterogeneity in the training distributions \cite{arjovsky2020invariant, kamath2021does, rosenfeld2020risks,rosenfeld2022online}, which is unlikely in real-world data. In fact in practice, it seems that ERM usually outperforms invariance-based methods \citep{ahuja2020empirical, gulrajani2020search}. For IV related methods, it requires full-rank IV which is also difficult to find in practice. 
% \fy{shortened}
% Further, infinitely robust predictors such as the vector of causal parents, the causal parameter, the invariant representation also yield suboptimal predictions when the shifts are small and are mostly outperformed by ERM in this regime. 
%the number of environments to scale with the number of latent invariant features \cite{chen2022iterative}, and additionally poses strict assumptions on the geometry of the training environments \cite{arjovsky2020invariant}. These assumptions are often impossible to verify in practice, and if they are violated, invariant methods have been shown to pick up spurious features and perform on par on or worse than empirical risk minimization \cite{kamath2021does, rosenfeld2020risks,rosenfeld2022online}, with similar observations in practice \citep{ahuja2020empirical, gulrajani2020search}.
%From similar observations, it has been postulated that ERM might be the state-of-the-art domain generalization algorithm in some settings \citep{ahuja2020empirical, gulrajani2020search}.
% The main limitation of \emph{infinitely robust invariant} methods is that they usually require the number of environments to scale with the number of latent invariant features \cite{chen2022iterative}, and often come with few or no theoretical guarantees \cite{kamath2021does, rosenfeld2020risks, rosenfeld2022online, ahuja2020empirical}.
% The robustness set then corresponds to \emph{interventions} on the covariates, while the data-generating process remains unchanged \citep{meinshausen2018causality, buhlmann2020invariance}. The framework of causality has turned out particularly useful for describing realistic distribution shifts in the data, with many papers achieving \emph{infinite robustness} with respect to shifts on covariates, provided that a sufficiently rich set of training environments is observed \citep{peters2016causal, arjovsky2020invariant} [causal dantzig, more]. 
% However, infinite robustness is typically tied to full identifiability of the latent invariant representation of the data, which is only guaranteed under strict assumptions on the training environments \citep{peters2016causal, arjovsky2020invariant}. 
% These assumptions are often impossible to verify in practice, and if they are violated, invariant methods have been shown to pick up spurious features and perform on par on or worse than empirical risk minimization [CITE]. 
\textbf{Finite robustness methods:} 
%Besides the fact that these assumptions for full identifiability are hard to fulfill in practice, 
In real data, shifts of arbitrary direction and strength in the covariates are unrealistic. Thus, different methods \citep{rothenhausler2021anchor, jakobsen2022distributional, kook2022distributional, shen2023causalityoriented, christiansen2021causal}
trade-off robustness against predictive power to achieve what we call \emph{finite robustness}. 
% Recent \emph{finite robustness methods} take a shift in perspective:
The main idea of finite robustness methods is to learn a function that is as predictive as possible while protecting against shifts up to some strength in the directions observed during training time.
These methods, however, only provide robustness guarantees that depend on the heterogeneity of the training data and do not offer insights into the limits of \emph{algorithm-independent robustness} under shifts in new directions. 


% Given an algorithm/estimator and the training distribution, ((in some settings interpolate between ERM and causal predictors,)) they find the set of bounded shifts such that the estimator is robust \citep{rothenhausler2021anchor, jakobsen2022distributional, kook2022distributional, shen2023causalityoriented, christiansen2021causal}. \fy{rephrase}
%They seek to learn predictive functions which are robust to shifts up to certain strengths and limited in direction, and in some settings interpolate between ERM and causal predictors . 
%\fy{put all these references to the batch above, the most relevant we'll relate to in the other sections anyway} 
%Anchor regression \cite{rothenhausler2021anchor} is the first work to treat finite robustness under causality assumptions. \cite{christiansen2021causal} extend this framework to some nonlinear settings. \cite{kook2022distributional} studies an extension of anchor regression to conditional probabilities. \cite{shen2023causalityoriented} extend the setting of anchor regression to general additive shifts with finite second moments and develop a gradient invariance-based method for finite robustness for a more general class of data-generating DAGs. The aforementioned works 
% These 
% %In other words, they prove the robustness of their methods with respect to certain 
% \emph{algorithm-dependent robustness sets} 
% %of possible test shifts 
% are mostly comprised of the same shift directions that were observed during training. 
% In other words, these methods only achieve finite robustness on shift directions, on which the (invariant) causal predictor can be identified. However, 
% It remains unclear \emph{whether} and \emph{how} finite robustness can be achieved with respect to previously unobserved test directions, and more generally, which guarantees can be given for finite robustness on an \emph{algorithm-independent robustness set} of additive shifts.   
%here the robustness set is modeled as the convex hull of training distributions among training environments.
%However, this approach disregards the structural information of the shifts and does not protect against distribution shifts beyond the convex hull of the training distributions.

% In contrast to the methods described above, we use the language of structural causal models to describe distributional shifts as interventions on the covariates. From a practitioner's perspective, this gives greater interpretability to the shifts. Moreover, given the presence of hidden confounders, our model can describe not only shifts in the covariates' distribution  $\prob_X$ but also in the conditional $\prob_{Y \mid X}$, and we consider settings where the test distribution lies outside of the convex hull of the training distributions. 


% \textbf{Causality-oriented robustness}: In recent years, there has been growing attention to causality-oriented robustness methods. These methods rest on the idea that a causal model is robust to arbitrary large shifts in the covariates 
% % !!! use interventions?
% \citep{meinshausen2018causality, buhlmann2020invariance}.
% Causality-oriented robustness methods can be divided into two categories, finite and infinite robustness methods.

% \emph{Infinite robustness methods}:
% On one side, some methods aim at infinite robustness by assuming the existence of predictive functions that are invariant to arbitrary shifts in the covariates. 
% The first methods along this line of work, consider an observed directed acyclic graphs over the covariates and targets variables, and assume the existence of a subset of observed predictors to achieve invariant predictions across training environments \cite{peters2016causal, fan2023environment, magliacane2018domain, rojas2018invariant}.
% As a follow-up, \cite{arjovsky2020invariant} extend the invariant prediction setting to the case where the invariant features are nonlinear transformation of the observed covariates, and not subsets.
% Extensions to \cite{arjovsky2020invariant} consider alternative notions of invariance, relying on matching the gradients across environments \cite{shi2021gradient} or using higher moments \cite{krueger2021out, xie2020risk}.
% % , 
% % \cite{bellot2020accounting}, \cite{mahajan2021domain}.
% % \cite{ahuja2020invariant} game-theoretic IRM
% The main limitation of these methods is that they usually require the number of environments to scale with the number of latent invariant features \cite{chen2022iterative}, and they often come with few or no theoretical guarantees \cite{kamath2021does, rosenfeld2020risks, rosenfeld2022online, ahuja2020empirical}.


% !!! consider citing Yuansi paper on domain adaptation here
% \emph{Finite robustness methods}:
% On the other hand, there exist methods that seek to learn predictive functions that are robust to shift up to a certain strength and direction, i.e., finite robustness methods \cite{rothenhausler2021anchor, jakobsen2022distributional, shen2023causalityoriented, christiansen2021causal}.

% Among these, the work closest to our setting is \cite{shen2023causalityoriented}. 
% Their goal is to learn a function that is robust to finite-sized shifts in the directions of the training data.
% In contrast, we study the problem of learning a function that is robust to shifts that can fall outside of the training heterogeneity. 
% % !!! mention they also consider interventions on Y?



% \textbf{Causal representation learning.} \cite{sturma2024unpaired} \cite{wu2023prominent} \cite{heinze2021conditional} 
 % \fy{note to self: it should be clear that its about population level identifiability not just finite sample}
\textit{\textbf{Partial identifiability}}:
The problem of identification is at the center of the causal and econometric literature \citep{peters2017elements, amemiya1985advanced}. It studies the conditions under which the (population) training distribution uniquely determines the causal parameters of the underlying SCM.
Often, the training distribution only offers partial information about the causal parameters and, therefore, determines a set of observational equivalent parameters. This setting is known as \emph{partial} or \emph{set identification} and is used in causality and econometrics to learn intervals within which the true causal parameter lies \citep{tamer2010partial}.
In this work, we borrow the notion of partial identification to study the problem of distributional robustness when the robustness set itself is only partially identified. 


% Identifiability from the observed distribution is a well-discussed problem in terms of identifiability of parameters is standard when latent variables exist in the distribution \fy{also includes CATE/ATE but this is a very general phenomenon, could add more}. In many cases when some latent parameters of the distributions are not identifiable, they are at least \emph{set-identifiable} - up to a \emph{set of observationally equivalent} model parameters (\emph{"identified set"}), i.e., parameters which could have induced the observed distribution. 
% %Various communities have introduced different approaches to deal with non-identifiability -
% %The problem of robustness on previously unobserved test environments (such as the aforementioned additive shifts) is closely connected to the problem of identification of the data-generating process (DGP), a question central in causality \cite{peters2017elements}. In many applications, full identification of the DGP is infeasible \cite{ogburn2021causal}, and instead, the underlying model could be merely \emph{set-identifiable}. 
% %This setting is also known as  \emph{partial identification (PI)} and has a long tradition especially in causal inference and econometrics \cite{tamer2010partial}. 
% %The main idea is that from observing one (or multiple) population-level data distributions, one can only identify the parameters of the DGP up to a \emph{set of observationally equivalent} model parameters (\emph{"identified set"}), i.e. parameters which could have induced the observed distribution. In contrast to identifiability in causality, set-identification is not an "all-or-nothing" quality, but instead lies on a spectrum. 
% %In causality and econometrics, 
% In causal inference and econometrics \cite{tamer2010partial}, this \emph{partial identification} of the causal effect has been used to 
% %has been mostly proposed for set-estimation of the causal effect: it moves the practitioner away from the question of whether the causal effect can be identified and instead 
% describe what can be inferred about the direction or strength of the causal effect given the data \cite{frake2023perfect}. This observationally equivalent set also occurs in our framework but is used in a different way: In \prettyref{sec:main-results}, we frame the partially identifiable distributional robustness problem as a robust optimization problem over the identified set.  \fy{instead of outputting a set} 

%Although we borrow some concepts from the PI literature, our objective, robust estimation on an unseen distribution shift, is different from the PI objective of set-estimating the (causal) parameter of interest.   
% On the one hand, the problem of identification is central in causality \cite{peters2017elements}. On the other hand, in several applied problems it is hard to justify full identification of the data generating process \cite{ogburn2021causal}, and it is more reasonable to think in terms of sets of models that are compatible with the observed distribution. This setting, also known as partial identification, has a long tradition in econometrics \cite{tamer2010partial} and was originally motivated by the fact that that the identification problem is not a all-or-nothing question but rather lies on a spectrum. 

% \fy{if we reference  these works later, i think this can be left out here}
% In the context of robustness, %The aforementioned finite robustness works 
% (\cite{rothenhausler2021anchor, jakobsen2022distributional, gnecco2023boosted}) also tackle the setting where the causal parameters are only partially identifiable
% %, in which the causal parameter (infinitely robust predictor) is not fully identifiable from multi-environment data. 
% However, as we describe in \prettyref{sec:main-results} and \prettyref{sec:apx-anchor-connections}, these works only consider algorithm-dependent robustness sets with respect to which the robust objective and the perfectly robust predictor are fully identifiable from training data. In contrast, our question [ref question from intro] concerns algorithm-independent robustness sets which include non-identified directions. 

% While  partial identification has been developed to solve problems in causality and econometrics, it has recently been used to tackle the problem of domain generalization \cite{rothenhausler2021anchor, jakobsen2022distributional, gnecco2023boosted}. In particular, when the data generating mechanism is not identifiable from the training distribution, it is not possible to learn the causal function and thus being robust to arbitrary shifts. However, it is still possible to protect against a subset of shifts observed during training time, that only partially identify the causal function.

% In contrast, we argue that it's not always realistic to protect only against shifts observed during training, even in a partially identifiable setting. Additionally, we demonstrate how to consider the partial identification of the model when analyzing the optimal performance that any model can achieve when trained on a specific set of training distributions and deployed on the 'worst-case' distribution that may be different from the training heterogeneity.

% \textbf{Other works to categorize}:

% \cite{saengkyongam2022exploiting}
% \cite{kong2023partial} \cite{zhang2023all} %\textbf{Invariant methods.} \cite{} (multi-environment invariant linear regression). 

% \paragraph{Non-worst case evaluation of the model.} \paragraph{Set-prediction and uncertainty quantification.}

% \subsection{Our contribution}
% In causality-oriented domain generalization methods, the common approach is to design an (invariance-based) method and then compute a "robustness set" $\cS$ such that the suggested method is the optimal predictor with respect to this robustness set \cite{rothenhausler2021anchor,shen2023causalityoriented}. In this paper, we pose and answer the opposite question: \emph{given a specified set of test distributions, what is the optimal predictor with respect to this set and how can it be computed}? By reversing the question, we can consider a broader class of test shifts, including ones not observed during training, and thus are generalize on the setting of anchor regression-based methods. 

% In addition to considering a broad class of distribution shifts, we do not require full identifiability of the model or a minimum number of training environments. Instead, we quantify the best possible robustness achievable for a given structure of training and test environments, even when few training environments are present and the causal structural model is not identifiable. To the best of our knowledge, we are the first to study distributional robustness under arbitrary bounded additive shifts in a partially identifiable setting. 
% In \prettyref{sec:prop-invariant-set}, we explicitly describe non-identifiability of the data-generating model in a multi-environment setting and connect it to the notion of \emph{observational equivalence} from the partial identifiability literature [cite]. As a consequence, we show that the robust predictor with respect to a specified robustness set can be computed from training data if and only if the robustness set does not contain "unseen" directions on which the model has not been identified. In \prettyref{sec:PI-lower-bound}, we introduce a new risk measure, which we call partially identified (PI)-robust loss. This minimax notion quantifies the worst-case robust risk under partial identifiability of the data-generating model. We derive a lower bound on this measure and show that no infinite robustness is possible for distribution shifts in \emph{any} direction not covered by the training data. In 
% \prettyref{sec:optimal-estimator}, we discuss the PI-robust loss and propose a new estimator which is optimal with respect to a bounded set distribution shifts under partial identifiability. Finally, in \prettyref{sec:experiments}, we conduct synthetic and semi-synthetic experiments that confirm our findings. 




% \nico{Maybe also mention the following. Like other methods, we start with an SCM. i) Existing causal-invariance/robust methods ask the following: given the (partial) identifiability of the SCM's parameters, to which shifts $S$  are we robust against? ii) On the other hand, we ask: given a set of shifts $S$, how do we achieve robustness?}
% \julia{Contrary to most causality-oriented robustness methods, we start with a set of directions and assumptions on Mtest, and then based on that derive a robust method and robustness guarantees/lower bound. }