

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% EXPERIMENTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments and Discussion}\label{sec:expdisc}
The experiments were carried out in a multicore platform with the following architectural configuration: a dual-socket Intel Xeon Silver 4210 clocked at 2.2GHz, with ten cores per socket totaling 20 cores (40 with Hyper-Threading). Regarding memory, it contains 640KiB of private L1, 20MiB of private L2, 27.5MiB shared L3, and 148GB of RAM. The system is a Linux Ubuntu 20.04.6 LTS. The following compilers were utilized for Rust, C++, and Fortran, respectively: \texttt{rustc} 1.81.0, \texttt{clang} 10.0.0 and \texttt{gfortran} 9.4. The reliability of the results uses the benchmark-specified maximum error range compared to the stored reference values. %All experiments use the NPB class C workload, a typical workload for multicore platforms \cite{NPB-CPP-2021}. Each test was executed 10 times, and the reported results represent the arithmetic mean and the standard deviation of the execution times.

Our set of experiments was guided by the following question: \textit{Does the Rust language provide sufficient performance and expressiveness for the NPB algorithms?} To answer this question we test two hypotheses: 1) The Rust language enables the expression of sequential algorithms for NPB with superior performance to Fortran and C++; and 2) The Rayon framework enables the expression of parallel algorithms for NPB with equal performance to OpenMP. In Section \ref{sec:seq} we present the the sequential version analyses, including a comparison between the unsafe and safe versions of NPB-Rust. Finally, in Section \ref{sec:par} we compare the parallel implementations in terms of execution time, scalability, speedup, memory consumption, and programmability. 

All experiments use the NPB class C, a typical workload for better granularity on multi-core platforms. Each test was executed 10 times, and the reported results represent the arithmetic mean and the standard deviation. We also leverage statistical tests using a 95\% confidence level to compare the differences in the execution times for sequential and parallel versions, following a previously applied methodology \cite{NPB-CPP-2021}. For compiling the benchmarks in Fortran and C++, we specified \texttt{-std=c++20} and \texttt{-O3}. In Rust we used the \texttt{--release}, this flag enables high-level optimizations, similar to the \texttt{-O3} option in Fortran and C++.

% We first present the performance of the sequential version by comparing the execution time of the NPB, NPB-CPP, and NPB-Rust. At this stage, a comparison is also made between the unsafe and safe versions of the sequential NPB-Rust. Finally, we compare the parallel versions of the NPB and NPB-CPP with OpenMP with the NPB-Rust with Rayon. Each experiment was executed 10 times, and the reported results represent the arithmetic mean and the standard deviation of the execution times.

% Our research seeks to answer the following question: Does the Rust language provide sufficient performance and expressiveness for the NPB algorithms? To answer this question, we will test the following hypotheses: 1) The Rust language enables the expression of sequential algorithms for NPB with equal performance to Fortran/C++; and 2) The Rayon framework enables the expression of parallel algorithms for NPB with equal performance to OpenMP.

    \subsection{Sequential Version}\label{sec:seq}

    \begin{figure}[t]
        \centering
        \includegraphics[width=0.5\textwidth]{Images/G-SER-C.pdf}
        \caption{Sequential versions execution time.}
        %\vspace{-0.15cm}
        \label{fig:sertimes}
        \end{figure}

        \begin{table}[t]
        \scriptsize
        \centering
        \caption{Sequential relative differences in execution time.}
        \begin{tabular}{C{1.5cm}|C{2.5cm}C{2.5cm}} 
            \toprule
            Benchmark & Rust to Fortran & Rust to C++ \\ % Cabeçalho
            \midrule
            EP  & \cellcolor{pastelred} + 3.23\% & \cellcolor{pastelred} + 5.77\%  \\
            CG  & \cellcolor{pastelgreen} - 2.92\% & \cellcolor{pastelgreen} - 29.92\%  \\
            FT  & \cellcolor{pastelred} + 18.18\% & \cellcolor{pastelred} + 12.93 \%  \\
            IS  & \cellcolor{pastelgreen} - 1.62\% & \cellcolor{pastelred} + 4.57e-5\%  \\
            MG  & \cellcolor{pastelred} + 1,67\% & \cellcolor{pastelgreen} - 11.54\%  \\
            BT  & \cellcolor{pastelgreen} - 7.31\% & \cellcolor{pastelred} + 2.44\%  \\
            SP  & \cellcolor{pastelred} + 0.75\% & \cellcolor{pastelgreen} - 3.91\%  \\
            LU  & \cellcolor{pastelgreen} - 6.54\% & \cellcolor{pastelgreen} - 19.21\%  \\
            \bottomrule
        \end{tabular}
        %\vspace{-0.5cm}
        \label{tab:relativeseq}
        \end{table}

    Figure \ref{fig:sertimes} compares the sequential NPB, NPB-CPP, and NPB-Rust versions. The X-axis lists the benchmarks, while the Y-axis represents execution time in seconds on a logarithmic scale. To statistically determine whether the outputs of each NPB-Rust benchmark were equivalent to those of the NPB in Fortran and C++, we consider the \texttt{p-value} obtained on a hypothesis test. To that end, we first have to understand the distribution of each sample to be compared. We ran a Shapiro–Wilk homogeneity test, which is used to identify which kind of hypothesis test to perform (parametric or non-parametric), even with a small sample (10 executions). If both samples were normally distributed, we applied a paired T-test; otherwise, we used the Wilcoxon test. In this analysis, the null hypothesis ($H_0$) is that the outputs from the different implementations are equivalent, while the alternative hypothesis ($H_1$) is that they are significantly different. If the resulting \texttt{p-value} from the statistical test is less than 0.05 (commonly used threshold in the literature for software experiments) we reject $H_0$ with a 95\% confidence level. Since almost all executions in our experiments set have a very low standard deviation on execution time, we fail to reject the $H_0$ hypothesis only when comparing the IS from Rust to C++.


    
    %using a 95\% confidence level. Before testing, we assessed the distribution of each sample to be compared, using the Shapiro-Wilk test. If both distributions were normal, we applied a T-test; otherwise, we used the Wilcoxon test. 

    Table \ref{tab:relativeseq} illustrates the Rust relative differences in execution time to Fortran and C++. A negative value indicates that Rust is faster (green), while a positive value signifies that Rust is slower (red). The results from the unsafe Rust implementation were used. The most considerable performance differences were observed in the CG, FT, MG, and LU kernels, each varying by over 10\% in at least one implementation compared to Rust. The slower performance of the LU and MG kernels in C++ when using the \texttt{clang} compiler was previously reported \cite{NPB-CPP-2021}. Fortran outperformed C++ and Rust for the FT kernel, potentially due to differences in the C++ porting process that were reflected in the Rust version. Fortran also benefits from an intrinsic complex number type, absent in C++ and Rust. Additionally, FT showed a higher standard deviation in execution times for C++ and Rust. The CG kernel in C++ had a longer execution time than in Fortran and Rust. Further analysis showed that, while cache misses were comparable, the C++ version of CG had a higher number of cache references, suggesting increased I/O activity.

%a batch mechanism for increasing granularity or

    The sequential unsafe version of IS has a total of 3 unsafe blocks, while the FT kernel has 9 unsafe regions. When comparing the performance gain on execution time we observed a difference of 11.2\% on IS and 21.35\% on FT, compared to the safe version. In MG, due to the sequential porting, almost all array access in the computationally intensive functions is based on arithmetic calculations, which results in excessive bound checks. When removing it, we achieved a difference of 56.94\% compared to the safe version.
    The statistical test shows that the results are majority not equivalent between Rust and the other versions. Also, the geometric mean of the execution times indicates that Rust is 1.23\% slower than Fortran and 5.59\% faster than C++ in our experiments on the NPB suite. We then concluded that our hypothesis that Rust enables the expression of sequential algorithms for NPB with superior performance to Fortran and C++ is partially correct.

        %The geometric mean indicates that Rust is 1.23\% slower than Fortran and 5.59\% faster than C++ in our experiments on the NPB suite. Since the statistical test indicates that the results are majority not equivalent between Rust and the other versions, and Rust outperformed C++ but was slower than Fortran, we concluded that our hypothesis that Rust enables the expression of sequential algorithms for NPB with superior performance to Fortran and C++ is partially correct.

    %Therefore, our hypothesis that Rust enables the expression of sequential algorithms for NPB with superior performance to Fortran and C++ is partially correct. 

    
    %The unsafe versions of FT and IS achieve a difference of 21.35\% and 11.2\%, respectively, compared to the safe version. In MG, due to the sequential porting, almost all array access in the computationally intensive functions is based on arithmetic calculations, which results in excessive bound checks. When removing it, we achieved a difference of 56.94\% compared to the safe version. The geometric mean indicates that Rust is 1.23\% slower than Fortran and 5.59\% faster than C++ in the NPB suite. Therefore, our hypothesis that Rust enables the expression of sequential algorithms for NPB with superior performance to Fortran and C++ is partially correct. 


    \begin{figure*}[t]
         \centering
          \vspace{0.2cm}
         \subfloat[EP]{\includegraphics[width=0.33\textwidth]{Images/G-EP-C.pdf}\label{fig:fortranvscpp_ep_b}}
         \subfloat[CG]{\includegraphics[width=0.33\textwidth]{Images/G-CG-C.pdf}\label{fig:fortranvscpp_cg_b}}
         \subfloat[FT]{\includegraphics[width=0.33\textwidth]{Images/G-FT-C.pdf}\label{fig:fortranvscpp_ft_b}}\\
         %\vspace{-0.3cm}
         \subfloat[IS]{\includegraphics[width=0.33\textwidth]{Images/G-IS-C.pdf}\label{fig:fortranvscpp_is_b}}
         \subfloat[MG]{\includegraphics[width=0.33\textwidth]{Images/G-MG-C.pdf}\label{fig:fortranvscpp_mg_b}}
         \subfloat[BT]{\includegraphics[width=0.33\textwidth]{Images/G-BT-C.pdf}\label{fig:fortranvscpp_bt_b}}\\
         %\vspace{-0.3cm}
         \subfloat[SP]{\includegraphics[width=0.33\textwidth]{Images/G-SP-C.pdf}\label{fig:fortranvscpp_sp_b}}
         \subfloat[LU]{\includegraphics[width=0.33\textwidth]{Images/G-LU-C.pdf}\label{fig:fortranvscpp_lu_b}}
         %\subfloat[Relative SLOC from serial to parallel]{\includegraphics[width=0.33\textwidth]{IEEE_Conference/Images/G-SLOC-PAR-p100.pdf}\label{fig:slocfig}}
         %\vspace{-0.2cm}
         \caption{Execution time of NPB with OpenMP, NPB-CPP with OpenMP, and NPB-Rust with Rayon for workload class C.}%, and SLOC.}
         \label{fig:graficoslegais}
         %\vspace{-0.2cm}
        \end{figure*}
        %\vspace{-0.3cm}

        %\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
        %\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
        \begin{table}[!ht]
        \fontsize{7}{7}\selectfont
        \centering
        \caption{Experimental results showing the best execution time and speedup for each parallel version.}
        \begin{tabular}{C{1.4cm}C{1.4cm}C{1.2cm}C{1.2cm}C{1.2cm}} 
            \toprule
            Benchmark & Metrics & C++ OpenMP & Fortran OpenMP & Rust Rayon \\ % fixed header line
            \midrule
            EP & 
            \makecell{N Threads\\Time (s)\\Speedup\\Std. Dev.} & 
            \makecell{40\\11.058\\27.677\\0.073} & 
            \makecell{40\\11.132\\28.172\\0.06} & 
            \cellcolor{pastelgreen}\makecell{40\\10.913\\29.666\\0.028}  \\
            \midrule
            CG & 
            \makecell{N Threads\\Time (s)\\Speedup\\Std. Dev.} & 
            \cellcolor{pastelgreen}\makecell{40\\13.682\\22.504\\0.27} & 
            \makecell{40\\12.904\\17.224\\0.408} & 
            \makecell{40\\20.646\\10.45\\0.436}   \\
            \midrule
            FT & 
            \makecell{N Threads\\Time (s)\\Speedup\\Std. Dev.} & 
            \makecell{39\\16.585\\20.163\\1.134} & 
            \makecell{40\\17.646\\18.093\\0.335} & 
            \cellcolor{pastelgreen}\makecell{40\\18.18\\22.152\\0.414}  \\
            \midrule
            IS & 
            \makecell{N Threads\\Time (s)\\Speedup\\Std. Dev.} & 
            \cellcolor{pastelgreen}\makecell{40\\0.56\\14.944\\0.031} & 
            \makecell{39\\0.634\\13.481\\0.025} & 
            \makecell{40\\0.683\\12.308\\0.011}  \\
            \midrule
            MG & 
            \makecell{N Threads\\Time (s)\\Speedup\\Std. Dev.} & 
            \cellcolor{pastelgreen}\makecell{40\\5.239\\8.213\\0.097} & 
            \makecell{40\\5.517\\6.785\\0.229} & 
            \makecell{40\\7.459\\5.103\\0.234}   \\
            \midrule
            BT & 
            \makecell{N Threads\\Time (s)\\Speedup\\Std. Dev.} & 
            \makecell{40\\48.424\\15.367\\0.564} & 
            \cellcolor{pastelgreen}\makecell{40\\52.483\\15.672\\0.42} & 
            \makecell{40\\51.076\\14.925\\0.383}  \\
            \midrule
            SP & 
            \makecell{N Threads\\Time (s)\\Speedup\\Std. Dev.} & 
            \cellcolor{pastelgreen}\makecell{16\\65.573\\7.039\\0.499} & 
            \makecell{12\\66.182\\6.651\\1.137} & 
            \makecell{12\\90.916\\4.878\\2.402}  \\
            \midrule
            LU & 
            \makecell{N Threads\\Time (s)\\Speedup\\Std. Dev.} & 
            \cellcolor{pastelgreen}\makecell{20\\57.116\\11.631\\1.683} & 
            \makecell{32\\52.495\\10.939\\1.878} & 
            \makecell{40\\59.581\\9.007\\1.746}   \\
            \bottomrule
        \end{tabular}
        \vspace{-0.3cm}
        \label{tab:speed}
        \end{table}


    \subsection{Parallel Version}\label{sec:par}



    

    Figure \ref{fig:graficoslegais} shows the execution time in seconds on a logarithmic scale for each benchmark, varying the number of threads from 1 to 40. Since both NPB and NPB-CPP utilize the OpenMP framework, they exhibit similar results regarding time and scalability. These outputs align with previous tests \cite{NPB-CPP-2021}. In contrast, we observed distinct result patterns in Rust, since Rayon's implementation differs from that of OpenMP. We used the same methodology described in Section \ref{sec:seq} to statistically test the equivalence of the NPB-Rust with Rayon to Fortran and C++ versions with OpenMP. We applied it for each benchmark in each degree of parallelism. The statistical test results indicate that the Rust parallel version is equivalent to Fortran and C++ in 12.5\% and 17.81\% of the cases, respectively.
    
    Rayon's work-stealing and dynamic system scales considerably better compared to OpenMP when Hyper-Threading is enabled. On the other hand, for applications like MG and SP, which are known to stop scaling with fewer threads, Rayon scales similarly to OpenMP at first but hits a limit earlier. The reason stems from the combination of dynamic scheduling and small computation granularity. For the CG benchmark, \texttt{nowait} directives were implemented in the most computationally intensive function in the OpenMP version. Since Rayon does not offer a similar approach for those notations, OpenMP scales better overall in this benchmark. 

    \begin{figure*}[!ht]
         \centering
         \subfloat[1 thread]{\includegraphics[width=0.33\textwidth]{Images/G-MEM1-C.pdf}\label{fig:mem1}}
         \subfloat[20 threads]{\includegraphics[width=0.33\textwidth]{Images/G-MEM20-C.pdf}\label{fig:mem20}}
         \subfloat[40 threads]{\includegraphics[width=0.33\textwidth]{Images/G-MEM40-C.pdf}\label{fig:mem40}}
         \vspace{-0.1cm}
         \caption{Memory consumption in MB executing with 1, 20, and 40 threads.}
         \label{fig:mem}
         \vspace{-0.0cm}
        \end{figure*}
    
    Regarding the other applications, Rayon delivered competitive results. Considering the executions using 40 threads for EP, FT, IS, BT, and LU, the geometric mean indicates that Rust with Rayon was 2.74\% slower than the Fortran version and 7.7\% slower than the C++ version with OpenMP. Considering all benchmarks, the difference increases to 16.42\% slower than Fortran and 19.05\% slower than C++. Thus, our hypothesis that Rayon enables the expression of parallel algorithms for NPB with equal performance to OpenMP was refuted.



        %\begin{figure}[h]
        %\centering
        %\includegraphics[width=0.5\textwidth]{IEEE_Conference/Images/G-SLOC-delta.pdf}
        %\caption{Relative SLOC from sequential to parallel versions.}
        %\vspace{-0.5cm}
        %\label{fig:slocfig}
        %\end{figure}


    We extend the analyses with Table \ref{tab:speed}. It summarizes, for each application and version, the level of parallelism that achieves the best speedup, with green marks highlighting the top one for each benchmark. Rayon managed to reach the highest speedup in the embarrassingly parallel problem due to its work-stealing scheduling. FT is the most memory-intensive benchmark in the NPB suite, which may hide other sources of overhead depending on the platform. Rayon benefits from its dynamic scheduling and reaches the highest speedup on this kernel. As IS execution time is relatively smaller, any runtime overhead has more impact on the results. Although the execution time differences were in order of milliseconds, C++ achieves the best speedup in this kernel. BT was the only application where Fortran with OpenMP achieved the best speedup. All NPB versions presented similar results in this metric for this benchmark. The LU data dependencies in the OpenMP version are handled within the loop scope using flags and \texttt{flush} directives. In contrast, the Rayon version resolves them at the thread scope using locks and conditional variables. These divergent approaches explain the speedup differences.

        %\begin{figure}[t]
        %\centering
        %\includegraphics[width=0.51\textwidth]{IEEE_Conference/Images/G-MEM-C.pdf}
        %\vspace{-0.2cm}
        %\caption{Memory consumption using 1 and 40 threads.}
        %\label{fig:mem}
        %\vspace{-0.2cm}
        %\end{figure}


        

    %Figure \ref{fig:slocfig} reports the relative SLOC (significant source lines of code) difference from parallel to serial versions. The parallel implementation with Rayon adds on average 4.6\% more lines of code, while the OpenMP versions in Fortran and C++ add 4.58\% and 5.39\%, respectively. 

    %Figure \ref{fig:slocfig} shows the difference in significant source lines of code (SLOC) between the serial and parallel versions for each benchmark. The EP benchmark in Rust required relatively more lines of code because the reduction function needed to be manually implemented. For the LU benchmark, the additional lines stem from different implementation strategies.  IS has relatively more code because of the strategy of manual control over the array access, to avoid excessive unsafe code. As Rayon's parallel features rely on iterator-based constructs, similar to the sequential pattern, the other applications required minimal code modifications. 

    Figure \ref{fig:mem} shows the peak of memory consumption in megabytes for each benchmark when using 1, 20, and 40 threads. We observe that most applications maintain similar consumption levels when more threads are enabled. This behavior is expected since the NPB suite shares large data structures between threads in almost all cases. Due to its implementation, the CG kernel in Fortran shows consistently higher memory consumption. The EP kernel demonstrated a relatively higher increase in memory consumption across all versions. Although this kernel naturally has lower memory usage, its parallel version includes a private array to store the random numbers generated for each thread. The SP benchmark in Rust shows considerably higher memory consumption in its highly parallel version. This is related to the increased thread pool stack size configured for the Rust implementation. The OpenMP manages the stack allocation in the solver functions efficiently, while the Rayon version requires more memory.


       \begin{figure*}[t]
         \centering
         \subfloat[Relative SLOC from sequential to parallel versions]{\includegraphics[width=0.5\textwidth]{Images/G-SLOC-PAR-p100-last.pdf}\label{fig:SLOC}}
         \subfloat[Relative COCOMO schedule effort from sequential to parallel versions]{\includegraphics[width=0.5\textwidth]{Images/G-COCOMO-last.pdf}\label{fig:COCO}}
         \caption{Relative SLOC and COCOMO schedule effort from sequential to parallel versions.}
         \label{fig:sloocomo}
         \vspace{-0.3cm}
        \end{figure*}
        

    To assess the programmability of each framework, significant source lines of code (SLOC) and scheduling efforts based on the constructive cost model (COCOMO) are considered. The scheduling effort is determined based on the lines of code (LOC) and predefined constants customized according to the developer's experience level. In this assessment, we utilized a configuration suitable for developers with high experience. These metrics have already been studied for evaluating parallel programming applications and APIs \cite{program}, and we leverage them for analyzing both parallel and sequential implementations between the C++ and Rust versions. The Fortran version is excluded from this evaluation, as its sequential execution utilizes the same code as the parallel version, but without the OpenMP flag. Figure \ref{fig:SLOC} illustrates the relative SLOC differences between serial and parallel versions of each benchmark, while Figure \ref{fig:COCO} shows the relative differences in scheduling effort. Since COCOMO considers LOC in its calculation, the results for both metrics demonstrate similar patterns. In Rust, EP required a relatively higher effort due to the manual implementation of the reduction function. In the case of LU, the different implementation strategies used to provide organized access to data result in more complexity for Rust with Rayon. IS has relatively more code because of the strategy of manual control over the array access, made to avoid excessive unsafe code. Meanwhile, the other applications needed minimal modifications, as Rayon's iterator-based parallel features align closely with the sequential pattern. The general overview indicates that in the NPB suite, Rayon adds on average 4.6\% more significant source lines of code, while the OpenMP versions in C++ add 5.39\%, respectively. In terms of scheduling effort, Rayon incurs an overhead of 1.75\%, whereas OpenMP introduces an overhead of 2.09\% in C++. From the NPB perspective, Rayon and OpenMP frameworks have a minimal impact on the programmability efforts.


    
    %Lastly, we report the memory usage across different versions. 
    
   


    
    
    %This behavior is expected, since the NPB suite mainly uses the heap allocation to handle large data structures. CG kernel in Frotran presented a constantly higher consumption,


    

    %We also conducted experiments to measure the memory usage for the different applications. Most of the benchmarks maintain the same memory consumption. We observed higher usage for CG kernel in Fortran and EP and SP.


    


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
