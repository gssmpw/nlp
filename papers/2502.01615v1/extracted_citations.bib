@INPROCEEDINGS{Aurnhammer2019-fu,
  title     = "{Comparing gated and simple recurrent neural network
               architectures as models of human sentence processing}",
  booktitle = "Proceedings of {CogSci}",
  author    = "Aurnhammer, C and Frank, S L",
  pages     = "112--118",
  year      =  2019,
  url = "https://repository.ubn.ru.nl/bitstream/handle/2066/213724/213724.pdf?sequence=1&isAllowed=y"
}

@INPROCEEDINGS{Banino2021-oq,
  title     = "{PonderNet}: Learning to Ponder",
  author    = "Banino, Andrea and Balaguer, Jan and Blundell, Charles",
  booktitle = "8th ICML Workshop on Automated Machine Learning (AutoML)",
  abstract  = "In standard neural networks the amount of computation used grows
               with the size of the inputs, but not with the complexity of the
               problem being learnt. To overcome this limitation we introduce
               PonderNet, a new algorithm that learns to adapt the amount of
               computation based on the complexity of the problem at hand.
               PonderNet learns end-to-end the number of computational steps to
               achieve an effective compromise between training prediction
               accuracy, computational cost and generalization. On a complex
               synthetic problem, PonderNet dramatically improves performance
               over previous adaptive computation methods and additionally
               succeeds at extrapolation tests where traditional neural networks
               fail. Also, our method matched the current state of the art
               results on a real world question and answering dataset, but using
               less compute. Finally, PonderNet reached state of the art results
               on a complex task designed to test the reasoning capabilities of
               neural networks.",
  month     =  jul,
  year      =  2021,
  URL   =   "https://openreview.net/forum?id=1EuxRTe0WN"
}

@article{Boyce2023AmazeON,
  title={A-maze of Natural Stories: Comprehension and surprisal in the Maze task},
  author={Veronica Boyce and Roger Philip Levy},
  journal={Glossa Psycholinguistics},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:258086581}
}

@article{Caucheteux2023-tx,
  title={Evidence of a predictive coding hierarchy in the human brain listening to speech},
  author={Caucheteux, Charlotte and Gramfort, Alexandre and King, Jean-R{\'e}mi},
  journal={Nature human behaviour},
  volume={7},
  number={3},
  pages={430--441},
  year={2023},
  publisher={Nature Publishing Group UK London},
  url={https://www.nature.com/articles/s41562-022-01516-2}
}

@article{Crocker2010-cp,
  title={Computational Psycholinguistics},
  author={Crocker, Matthew W},
  journal={The Handbook of Computational Linguistics and Natural Language Processing},
  year={2007},
  url={https://www.coli.uni-saarland.de/~crocker/documents/crocker-nlp-handbook.pdf}
}

@article{Dimigen2011-gt,
  title={Coregistration of eye movements and EEG in natural reading: analyses and review.},
  author={Dimigen, Olaf and Sommer, Werner and Hohlfeld, Annette and Jacobs, Arthur M and Kliegl, Reinhold},
  journal={Journal of experimental psychology: General},
  volume={140},
  number={4},
  pages={552},
  year={2011},
  publisher={American Psychological Association},
  URL = {https://psycnet.apa.org/record/2011-14094-001}
}

@ARTICLE{Forster2009-dp,
  title     = "The maze task: measuring forced incremental sentence processing
               time",
  author    = "Forster, Kenneth I and Guerrera, Christine and Elliot, Lisa",
  journal   = "Behavior research methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  41,
  number    =  1,
  pages     = "163--171",
  abstract  = "The maze task is an online measure of sentence processing time
               that provides an alternative to the standard moving window
               version of self-paced reading. Rather than each word of the
               sentence being presented in succession, two words are presented
               at the same time, and the participant must choose which word is a
               grammatical continuation of the sentence. This procedure forces
               the reader into an incremental mode of processing in which each
               word must be fully integrated with the preceding context before
               the next word can be considered. Previous research with this
               technique has not considered whether it is sufficiently sensitive
               to syntactic complexity effects or to garden path effects. Four
               experiments are reported demonstrating that reliable differences
               in processing time for subject relatives and object relatives can
               be obtained, and that this technique generates garden path
               effects that correspond closely with the data from eyetracking
               experiments, but without the spillover effects that are sometimes
               obtained with eyetracking. It is also shown that the task is
               sensitive to word frequency effects, producing estimates well in
               excess of those found with eyetracking.",
  month     =  feb,
  year      =  2009,
  language  = "en",
  URL = "https://link.springer.com/article/10.3758/brm.41.1.163"
}

@inproceedings{Goodkind2018PredictiveQuality,
    title = {{Predictive power of word surprisal for reading times is a linear function of language model quality}},
    year = {2018},
    booktitle = {Proceedings of CMCL},
    author = {Goodkind, Adam and Bicknell, Klinton},
    pages = {10--18},
    doi = {10.18653/v1/w18-0102}
}

@ARTICLE{Graves2016-dp,
  title    = "Adaptive Computation Time for Recurrent Neural Networks",
  author   = "Graves, Alex",
  abstract = "This paper introduces Adaptive Computation Time (ACT), an
              algorithm that allows recurrent neural networks to learn how many
              computational steps to take between receiving an input and
              emitting an output. ACT requires minimal changes to the network
              architecture, is deterministic and differentiable, and does not
              add any noise to the parameter gradients. Experimental results are
              provided for four synthetic problems: determining the parity of
              binary vectors, applying binary logic operations, adding integers,
              and sorting real numbers. Overall, performance is dramatically
              improved by the use of ACT, which successfully adapts the number
              of computational steps to the requirements of the problem. We also
              present character-level language modelling results on the Hutter
              prize Wikipedia dataset. In this case ACT does not yield large
              gains in performance; however it does provide intriguing insight
              into the structure of the data, with more computation allocated to
              harder-to-predict transitions, such as spaces between words and
              ends of sentences. This suggests that ACT or other adaptive
              computation methods could provide a generic method for inferring
              segment boundaries in sequence data.",
  month    =  mar,
  year     =  2016,
  journal = "arXiv preprint",
  URL = "https://arxiv.org/abs/1603.08983"
}

@inproceedings{Hale2018FindingSearch,
    title = {{Finding Syntax in Human Encephalography with Beam Search}},
    year = {2018},
    booktitle = {Proceedings of ACL 2018},
    author = {Hale, John and Dyer, Chris and Kuncoro, Adhiguna and Brennan, Jonathan R.},
    pages = {2727--2736},
    isbn = {9781948087322},
    doi = {10.18653/v1/p18-1254},
    arxivId = {1806.04127}
}

@ARTICLE{Hosseini2024-jf,
  title     = "Artificial neural network language models predict human brain
               responses to language even after a developmentally realistic
               amount of training",
  author    = "Hosseini, Eghbal A and Schrimpf, Martin and Zhang, Yian and
               Bowman, Samuel and Zaslavsky, Noga and Fedorenko, Evelina",
  journal   = "Neurobiology of Language",
  publisher = "MIT Press",
  volume    =  5,
  number    =  1,
  pages     = "43--63",
  abstract  = "Artificial neural networks have emerged as computationally
               plausible models of human language processing. A major criticism
               of these models is that the amount of training data they receive
               far exceeds that of humans during language learning. Here, we use
               two complementary approaches to ask how the models' ability to
               capture human fMRI responses to sentences is affected by the
               amount of training data. First, we evaluate GPT-2 models trained
               on 1 million, 10 million, 100 million, or 1 billion words against
               an fMRI benchmark. We consider the 100-million-word model to be
               developmentally plausible in terms of the amount of training data
               given that this amount is similar to what children are estimated
               to be exposed to during the first 10 years of life. Second, we
               test the performance of a GPT-2 model trained on a
               9-billion-token dataset to reach state-of-the-art next-word
               prediction performance on the human benchmark at different stages
               during training. Across both approaches, we find that (i) the
               models trained on a developmentally plausible amount of data
               already achieve near-maximal performance in capturing fMRI
               responses to sentences. Further, (ii) lower perplexity-a measure
               of next-word prediction performance-is associated with stronger
               alignment with human data, suggesting that models that have
               received enough training to achieve sufficiently high next-word
               prediction performance also acquire representations of sentences
               that are predictive of human fMRI responses. In tandem, these
               findings establish that although some training is necessary for
               the models' predictive ability, a developmentally realistic
               amount of training (∼100 million words) may suffice.",
  month     =  apr,
  year      =  2024,
  keywords  = "ANN-neural data alignment; artificial neural network;
               development; human behavior; language network",
  language  = "en",
  url = "https://direct.mit.edu/nol/article/5/1/43/119156/Artificial-Neural-Network-Language-Models-Predict"
}

@ARTICLE{Huang2024-qe,
  title    = "Large-scale benchmark yields no evidence that language model
              surprisal explains syntactic disambiguation difficulty",
  author   = "Huang, Kuan-Jung and Arehalli, Suhas and Kugemoto, Mari and
              Muxica, Christian and Prasad, Grusha and Dillon, Brian and Linzen,
              Tal",
  journal  = "Journal of Memory and Language",
  volume   =  137,
  pages    =  104510,
  abstract = "Prediction has been proposed as an overarching principle that
              explains human information processing in language and beyond. To
              what degree can processing difficulty in syntactically complex
              sentences – one of the major concerns of psycholinguistics – be
              explained by predictability, as estimated using computational
              language models, and operationalized as surprisal (negative log
              probability)? A precise, quantitative test of this question
              requires a much larger scale data collection effort than has been
              done in the past. We present the Syntactic Ambiguity Processing
              Benchmark, a dataset of self-paced reading times from 2000
              participants, who read a diverse set of complex English sentences.
              This dataset makes it possible to measure processing difficulty
              associated with individual syntactic constructions, and even
              individual sentences, precisely enough to rigorously test the
              predictions of computational models of language comprehension. By
              estimating the function that relates surprisal to reading times
              from filler items included in the experiment, we find that the
              predictions of language models with two different architectures
              sharply diverge from the empirical reading time data, dramatically
              underpredicting processing difficulty, failing to predict relative
              difficulty among different syntactic ambiguous constructions, and
              only partially explaining item-wise variability. These findings
              suggest that next-word prediction is most likely insufficient on
              its own to explain human syntactic processing.",
  month    =  aug,
  year     =  2024,
  keywords = "Sentence processing; Prediction; Surprisal; Language models",
  url = "https://www.sciencedirect.com/science/article/abs/pii/S0749596X24000135"
}

@article{Levy2008Expectation-basedComprehension,
    title = {{Expectation-based syntactic comprehension}},
    year = {2008},
    journal = {Journal of Cognition},
    author = {Levy, Roger},
    number = {3},
    pages = {1126--1177},
    volume = {106},
    doi = {10.1016/j.cognition.2007.05.006},
    issn = {00100277},
    pmid = {17662975},
    keywords = {Frequency, Information theory, Parsing, Prediction, Sentence processing, Syntactic complexity, Syntax, Word order}
}

@ARTICLE{Lewis2005-hp,
  title    = "An activation-based model of sentence processing as skilled
              memory retrieval",
  author   = "Lewis, Richard L and Vasishth, Shravan",
  abstract = "We present a detailed process theory of the moment-by-moment
              working-memory retrievals and associated control structure that
              subserve sentence comprehension. The theory is derived from the
              application of independently motivated principles of memory and
              cognitive skill to the specialized task of sentence parsing. The
              resulting theory construes sentence processing as a series of
              skilled associative memory retrievals modulated by
              similarity-based interference and fluctuating activation. The
              cognitive principles are formalized in computational form in the
              Adaptive Control of Thought-Rational (ACT-R) architecture, and
              our process model is realized in ACT-R. We present the results of
              6 sets of simulations: 5 simulation sets provide quantitative
              accounts of the effects of length and structural interference on
              both unambiguous and garden-path structures. A final simulation
              set provides a graded taxonomy of double center embeddings
              ranging from relatively easy to extremely difficult. The
              explanation of center-embedding difficulty is a novel one that
              derives from the model' complete reliance on discriminating
              retrieval cues in the absence of an explicit representation of
              serial order information. All fits were obtained with only 1 free
              scaling parameter fixed across the simulations; all other
              parameters were ACT-R defaults. The modeling results support the
              hypothesis that fluctuating activation and similarity-based
              interference are the key factors shaping working memory in
              sentence processing. We contrast the theory and empirical
              predictions with several related accounts of sentence-processing
              complexity.",
  journal  = "Cogn. Sci.",
  volume   =  29,
  number   =  3,
  pages    = "375--419",
  month    =  may,
  year     =  2005,
  language = "en",
  url="https://www.ling.uni-potsdam.de/~vasishth/pdfs/Lewis-VasishthCogSci2005.pdf"
}

@INPROCEEDINGS{McCurdy2024-ix,
  title     = "Lossy Context Surprisal Predicts Task-Dependent Patterns in
               Relative Clause Processing",
  author    = "McCurdy, Kate and Hahn, Michael",
  booktitle = "Proceedings of CoNLL 2024",
  pages     = "36--45",
  abstract  = "Kate McCurdy, Michael Hahn. Proceedings of the 28th Conference on
               Computational Natural Language Learning. 2024.",
  month     =  nov,
  year      =  2024,
  url = "https://aclanthology.org/2024.conll-1.4/"
}

@inproceedings{Merkx2020ComparingData,
    title = "Human Sentence Processing: Recurrence or Attention?",
    author = "Merkx, Danny  and
      Frank, Stefan L.",
    booktitle = "Proceedings of CMCL",
    month = jun,
    year = "2021",
    url = "https://aclanthology.org/2021.cmcl-1.2",
    doi = "10.18653/v1/2021.cmcl-1.2",
    pages = "12--22",
    abstract = "Recurrent neural networks (RNNs) have long been an architecture of interest for computational models of human sentence processing. The recently introduced Transformer architecture outperforms RNNs on many natural language processing tasks but little is known about its ability to model human language processing. We compare Transformer- and RNN-based language models{'} ability to account for measures of human reading effort. Our analysis shows Transformers to outperform RNNs in explaining self-paced reading times and neural activity during reading English sentences, challenging the widely held idea that human sentence processing involves recurrent and immediate processing and provides evidence for cue-based retrieval.",
}

@INPROCEEDINGS{Oh2021-ln,
  title     = "Surprisal Estimators for Human Reading Times Need Character
               Models",
  booktitle = "Proceedings of ACL-IJCNLP 2021",
  author    = "Oh, Byung-Doh and Clark, Christian and Schuler, William",
  abstract  = "While the use of character models has been popular in NLP
               applications, it has not been explored much in the context of
               psycholinguistic modeling. This paper presents a character model
               that can be applied to a structural parser-based processing
               model to calculate word generation probabilities. Experimental
               results show that surprisal estimates from a structural
               processing model using this character model deliver
               substantially better fits to self-paced reading, eye-tracking,
               and fMRI data than those from large-scale language models
               trained on much more data. This may suggest that the proposed
               processing model provides a more humanlike account of sentence
               processing, which assumes a larger role of morphology,
               phonotactics, and orthographic complexity than was previously
               thought.",
  pages     = "3746--3757",
  month     =  aug,
  year      =  2021,
  url = "https://aclanthology.org/2021.acl-long.290/"
}

@ARTICLE{Oh2022-ss,
  title     = "Comparison of structural parsers and neural language models as
               surprisal estimators",
  author    = "Oh, Byung-Doh and Clark, Christian and Schuler, William",
  journal   = "Frontiers in Artificial Intelligence",
  publisher = "Frontiers Media SA",
  volume    =  5,
  pages     =  777963,
  abstract  = "Expectation-based theories of sentence processing posit that
               processing difficulty is determined by predictability in context.
               While predictability quantified via surprisal has gained
               empirical support, this representation-agnostic measure leaves
               open the question of how to best approximate the human
               comprehender's latent probability model. This article first
               describes an incremental left-corner parser that incorporates
               information about common linguistic abstractions such as
               syntactic categories, predicate-argument structure, and
               morphological rules as a computational-level model of sentence
               processing. The article then evaluates a variety of structural
               parsers and deep neural language models as cognitive models of
               sentence processing by comparing the predictive power of their
               surprisal estimates on self-paced reading, eye-tracking, and fMRI
               data collected during real-time language processing. The results
               show that surprisal estimates from the proposed left-corner
               processing model deliver comparable and often superior fits to
               self-paced reading and eye-tracking data when compared to those
               from neural language models trained on much more data. This may
               suggest that the strong linguistic generalizations made by the
               proposed processing model may help predict humanlike processing
               costs that manifest in latency-based measures, even when the
               amount of training data is limited. Additionally, experiments
               using Transformer-based language models sharing the same primary
               architecture and training data show a surprising negative
               correlation between parameter count and fit to self-paced reading
               and eye-tracking data. These findings suggest that large-scale
               neural language models are making weaker generalizations based on
               patterns of lexical items rather than stronger, more humanlike
               generalizations based on linguistic structure.",
  month     =  mar,
  year      =  2022,
  keywords  = "eye-tracking; fMRI; incremental parsers; language models;
               self-paced reading; sentence processing; surprisal theory",
  language  = "en",
  url = "https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2022.777963/full"
}

@INPROCEEDINGS{Oh2023-hj,
  title     = "Transformer-based language model surprisal predicts human reading
               times best with about two billion training tokens",
  author    = "Oh, Byung-Doh and Schuler, William",
  booktitle = "Findings of EMNLP 2023",
  pages     = "1915--1921",
  abstract  = "Byung-Doh Oh, William Schuler. Findings of the Association for
               Computational Linguistics: EMNLP 2023. 2023.",
  month     =  dec,
  year      =  2023,
  url = "https://aclanthology.org/2023.findings-emnlp.128/"
}

@ARTICLE{Oh2023-zw,
  title     = "Why does surprisal from larger Transformer-based language models
               provide a poorer fit to human reading times?",
  author    = "Oh, Byung-Doh and Schuler, William",
  abstract  = "Abstract This work presents a linguistic analysis into why
               larger Transformer-based pre-trained language models with more
               parameters and lower perplexity nonetheless yield surprisal
               estimates that are less predictive of human reading times.
               First, regression analyses show a strictly monotonic, positive
               log-linear relationship between perplexity and fit to reading
               times for the more recently released five GPT-Neo variants and
               eight OPT variants on two separate datasets, replicating earlier
               results limited to just GPT-2 (Oh et al., 2022). Subsequently,
               analysis of residual errors reveals a systematic deviation of
               the larger variants, such as underpredicting reading times of
               named entities and making compensatory overpredictions for
               reading times of function words such as modals and conjunctions.
               These results suggest that the propensity of larger
               Transformer-based models to `memorize' sequences during training
               makes their surprisal estimates diverge from humanlike
               expectations, which warrants caution in using pre-trained
               language models to study human language processing.",
  journal   = "TACL",
  publisher = "MIT Press",
  volume    =  11,
  pages     = "336--350",
  month     =  mar,
  year      =  2023,
  copyright = "https://creativecommons.org/licenses/by/4.0/",
  language  = "en",
  url = "https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00548/115371/Why-Does-Surprisal-From-Larger-Transformer-Based"
}

@INPROCEEDINGS{Oh2024-cc,
  title     = "Frequency Explains the Inverse Correlation of Large Language
               Models{'} Size, Training Data Amount, and Surprisal{'}s Fit to
               Reading Times",
  author    = "Oh, Byung-Doh and Yue, Shisen and Schuler, William",
  editor    = "Graham, Yvette and Purver, Matthew",
  booktitle = "Proceedings of EACL 2024",
  pages     = "2644--2663",
  abstract  = "Recent studies have shown that as Transformer-based language
               models become larger and are trained on very large amounts of
               data, the fit of their surprisal estimates to naturalistic human
               reading times degrades. The current work presents a series of
               analyses showing that word frequency is a key explanatory factor
               underlying these two trends. First, residual errors from four
               language model families on four corpora show that the inverse
               correlation between model size and fit to reading times is the
               strongest on the subset of least frequent words, which is driven
               by excessively accurate predictions of larger model variants.
               Additionally, training dynamics reveal that during later training
               steps, all model variants learn to predict rare words and that
               larger model variants do so more accurately, which explains the
               detrimental effect of both training data amount and model size on
               fit to reading times. Finally, a feature attribution analysis
               demonstrates that larger model variants are able to accurately
               predict rare words based on both an effectively longer context
               window size as well as stronger local associations compared to
               smaller model variants. Taken together, these results indicate
               that Transformer-based language models' surprisal estimates
               diverge from human-like expectations due to the superhumanly
               complex associations they learn for predicting rare words.",
  month     =  mar,
  year      =  2024,
  url = "https://aclanthology.org/2024.eacl-long.162/"
}

@ARTICLE{Rayner1998-rw,
  title     = "Eye movements in reading and information processing: 20 years of
               research",
  author    = "Rayner, Keith",
  journal   = "Psychological bulletin",
  publisher = "American Psychological Association (APA)",
  volume    =  124,
  number    =  3,
  pages     = "372--422",
  abstract  = "APA PsycNet DoiLanding page",
  year      =  1998,
  language  = "en",
  URL = "https://psycnet.apa.org/record/1998-11174-004"
}

@ARTICLE{Rayner2009-aw,
  title     = "Language processing in reading and speech perception is fast and
               incremental: implications for event-related potential research",
  author    = "Rayner, Keith and Clifton, Jr, Charles",
  journal   = "Biological Psychology",
  publisher = "Elsevier BV",
  volume    =  80,
  number    =  1,
  pages     = "4--9",
  abstract  = "An overview of language processing during reading and listening
               is provided. Evidence is reviewed indicating that language
               processing in both domains is fast and incremental. We also
               discuss some aspects of normal reading and listening that are
               often obscured in event-related potential (ERP) research. We also
               discuss some apparent limitations of ERP techniques, as well as
               some recent indications that electroencephalographic (EEG)
               measures can be used to probe how lexical knowledge and lexical
               or structural expectations can contribute to the incremental
               process of language comprehension.",
  month     =  jan,
  year      =  2009,
  language  = "en",
  url = "https://www.sciencedirect.com/science/article/abs/pii/S0301051108001245"
}

@article{Shain2022-qv,
  title={Large-scale evidence for logarithmic effects of word predictability on reading time},
  author={Shain, Cory and Meister, Clara and Pimentel, Tiago and Cotterell, Ryan and Levy, Roger},
  journal={Proceedings of the National Academy of Sciences},
  volume={121},
  number={10},
  pages={e2307876121},
  year={2024},
  publisher={National Acad Sciences},
  url={https://www.pnas.org/doi/abs/10.1073/pnas.2307876121}
}

@ARTICLE{Smith2013-ap,
  title     = "The effect of word predictability on reading time is logarithmic",
  author    = "Smith, Nathaniel J and Levy, Roger",
  journal   = "Cognition",
  publisher = "Elsevier BV",
  volume    =  128,
  number    =  3,
  pages     = "302--319",
  abstract  = "It is well known that real-time human language processing is
               highly incremental and context-driven, and that the strength of a
               comprehender's expectation for each word encountered is a key
               determinant of the difficulty of integrating that word into the
               preceding context. In reading, this differential difficulty is
               largely manifested in the amount of time taken to read each word.
               While numerous studies over the past thirty years have shown
               expectation-based effects on reading times driven by lexical,
               syntactic, semantic, pragmatic, and other information sources,
               there has been little progress in establishing the quantitative
               relationship between expectation (or prediction) and reading
               times. Here, by combining a state-of-the-art computational
               language model, two large behavioral data-sets, and
               non-parametric statistical techniques, we establish for the first
               time the quantitative form of this relationship, finding that it
               is logarithmic over six orders of magnitude in estimated
               predictability. This result is problematic for a number of
               established models of eye movement control in reading, but lends
               partial support to an optimal perceptual discrimination account
               of word recognition. We also present a novel model in which
               language processing is highly incremental well below the level of
               the individual word, and show that it predicts both the shape and
               time-course of this effect. At a more general level, this result
               provides challenges for both anticipatory processing and semantic
               integration accounts of lexical predictability effects. And
               finally, this result provides evidence that comprehenders are
               highly sensitive to relative differences in predictability - even
               for differences between highly unpredictable words - and thus
               helps bring theoretical unity to our understanding of the role of
               prediction at multiple levels of linguistic structure in
               real-time language comprehension.",
  month     =  sep,
  year      =  2013,
  keywords  = "Expectation; Information theory; Probabilistic models of
               cognition; Psycholinguistics; Reading",
  language  = "en",
  url = "https://www.sciencedirect.com/science/article/pii/S0010027713000413"
}

@INPROCEEDINGS{Tenney2019-bb,
  title     = "{BERT} rediscovers the classical {NLP} pipeline",
  author    = "Tenney, Ian and Das, Dipanjan and Pavlick, Ellie",
  booktitle = "Proceedings of ACL 2019",
  pages     = "4593--4601",
  abstract  = "Ian Tenney, Dipanjan Das, Ellie Pavlick. Proceedings of the 57th
               Annual Meeting of the Association for Computational Linguistics.
               2019.",
  year      =  2019,
  url = "https://aclanthology.org/P19-1452/"
}

@ARTICLE{Toneva2019-ul,
  title    = "Interpreting and improving natural-language processing (in
              machines) with natural language-processing (in the brain)",
  author   = "Toneva, Mariya and Wehbe, Leila",
  journal  = "NeurIPS 2019",
  pages    = "14928--14938",
  abstract = "Neural networks models for NLP are typically implemented without
              the explicit encoding of language rules and yet they are able to
              break one performance record after another. This has generated a
              lot of research interest in interpreting the representations
              learned by these networks. We propose here a novel interpretation
              approach that relies on the only processing system we have that
              does understand language: the human brain. We use brain imaging
              recordings of subjects reading complex natural text to interpret
              word and sequence embeddings from 4 recent NLP models - ELMo, USE,
              BERT and Transformer-XL. We study how their representations differ
              across layer depth, context length, and attention type. Our
              results reveal differences in the context-related representations
              across these models. Further, in the transformer models, we find
              an interaction between layer depth and context length, and between
              layer depth and attention type. We finally hypothesize that
              altering BERT to better align with brain recordings would enable
              it to also better understand language. Probing the altered BERT
              using syntactic NLP tasks reveals that the model with increased
              brain-alignment outperforms the original model. Cognitive
              neuroscientists have already begun using NLP networks to study the
              brain, and this work closes the loop to allow the interaction
              between NLP and cognitive neuroscience to be a true
              cross-pollination.",
  month    =  may,
  year     =  2019,
  url = "https://proceedings.neurips.cc/paper/2019/hash/749a8e6c231831ef7756db230b4359c8-Abstract.html"
}

@ARTICLE{Van_Schijndel2021-sm,
  title    = "{Single-Stage} Prediction Models Do Not Explain the Magnitude of
              Syntactic Disambiguation Difficulty",
  author   = "van Schijndel, Marten and Linzen, Tal",
  abstract = "The disambiguation of a syntactically ambiguous sentence in favor
              of a less preferred parse can lead to slower reading at the
              disambiguation point. This phenomenon, referred to as a
              garden-path effect, has motivated models in which readers
              initially maintain only a subset of the possible parses of the
              sentence, and subsequently require time-consuming reanalysis to
              reconstruct a discarded parse. A more recent proposal argues that
              the garden-path effect can be reduced to surprisal arising in a
              fully parallel parser: words consistent with the initially
              dispreferred but ultimately correct parse are simply less
              predictable than those consistent with the incorrect parse. Since
              predictability has pervasive effects in reading far beyond
              garden-path sentences, this account, which dispenses with
              reanalysis mechanisms, is more parsimonious. Crucially, it
              predicts a linear effect of surprisal: the garden-path effect is
              expected to be proportional to the difference in word surprisal
              between the ultimately correct and ultimately incorrect
              interpretations. To test this prediction, we used recurrent
              neural network language models to estimate word-by-word surprisal
              for three temporarily ambiguous constructions. We then estimated
              the slowdown attributed to each bit of surprisal from human
              self-paced reading times, and used that quantity to predict
              syntactic disambiguation difficulty. Surprisal successfully
              predicted the existence of garden-path effects, but drastically
              underpredicted their magnitude, and failed to predict their
              relative severity across constructions. We conclude that a full
              explanation of syntactic disambiguation difficulty may require
              recovery mechanisms beyond predictability.",
  journal  = "Cognitive Science",
  volume   =  45,
  number   =  6,
  pages    = "e12988",
  month    =  jun,
  year     =  2021,
  keywords = "Garden paths; Information theory; Neural networks; Self-paced
              reading; Surprisal",
  language = "en",
  url="https://pubmed.ncbi.nlm.nih.gov/34170031/"
}

@ARTICLE{Vani2021-aj,
  title    = "Using the Interpolated Maze Task to Assess Incremental Processing
              in English Relative Clauses",
  author   = "Vani, Pranali and Wilcox, Ethan Gotlieb and Levy, Roger",
  journal  = "Proceedings of the Annual Meeting of the Cognitive Science Society",
  volume   =  43,
  number   =  43,
  abstract = "Author(s): Vani, Pranali; Wilcox, Ethan Gotlieb; Levy, Roger |
              Abstract: In English, Subject Relative Clauses are processed more
              quickly than Object Relative Clauses, but open questions remain
              about where in the clause slowdown occurs. The surprisal theory of
              incremental processing, under which processing difficulty
              corresponds to probabilistic expectations about upcoming material,
              predicts that slowdown should occur immediately on material that
              disambiguates the subject from object relative clause. However,
              evidence from eye tracking and self-paced reading studies suggests
              that slowdown occurs downstream of RC-disambiguating material, on
              the relative clause verb. These methods, however, suffer from
              well-known spillover effects which makes their results difficult
              to interpret. To address these issues, we introduce and deploy a
              novel variant of the Maze task for reading times (Forster,
              Guerrera, \& Elliot, 2009), called the Interpolated Maze in two
              English web-based experiments. In Experiment 1, we find that the
              locus of reading-time differences between SRCs and ORCs falls on
              immediate disambiguating definite determiner. Experiment 2
              provides a control, showing that ORCs are read more slowly than
              lexically-matching, non-anomalous material. These results provide
              new evidence for the locus of processing difficulty in relative
              clauses and support the surprisal theory of incremental
              processing.",
  year     =  2021,
  keywords = "Social and Behavioral Sciences",
  url="https://escholarship.org/uc/item/3x34x7dz"
}

@inproceedings{Wilcox2020OnBehavior,
    title = {{On the Predictive Power of Neural Language Models for Human Real-Time Comprehension Behavior}},
    year = {2020},
    booktitle = {Proceedings of CogSci},
    author = {Wilcox, Ethan Gotlieb and Gauthier, Jon and Hu, Jennifer and Qian, Peng and Levy, Roger},
    pages = {1707--1713},
    url = {http://arxiv.org/abs/2006.01912},
    arxivId = {2006.01912},
    keywords = {deep learning, eye-tracking, hension, language modeling, real-time language compre-, self-paced reading}
}

@INPROCEEDINGS{Wilcox2023-bb,
  title     = "Language Model Quality Correlates with Psychometric Predictive
               Power in Multiple Languages",
  author    = "Wilcox, Ethan and Meister, Clara and Cotterell, Ryan and
               Pimentel, Tiago",
  editor    = "Bouamor, Houda and Pino, Juan and Bali, Kalika",
  booktitle = "Proceedings of EMNLP 2023",
  pages     = "7503--7511",
  abstract  = "Surprisal theory (Hale, 2001; Levy, 2008) posits that a word's
               reading time is proportional to its surprisal (i.e., to its
               negative log probability given the proceeding context). Since we
               are unable to access a word's ground-truth probability, surprisal
               theory has been empirically tested using surprisal estimates from
               language models (LMs). Under the premise that surprisal theory
               holds, we would expect that higher quality language models
               provide more powerful predictors of human reading behavior---a
               conjecture we dub the quality--power (QP) hypothesis.
               Unfortunately, empirical support for the QP hypothesis is mixed.
               Some studies in English have found correlations between LM
               quality and predictive power, but other studies using Japanese
               data, as well as using larger English LMs, find no such
               correlations. In this work, we conduct a systematic
               crosslinguistic assessment of the QP hypothesis. We train LMs
               from scratch on small- and medium-sized datasets from 13
               languages (across five language families) and assess their
               ability to predict eye tracking data. We find correlations
               between LM quality and power in eleven of these thirteen
               languages, suggesting that, within the range of model classes and
               sizes tested, better language models are indeed better predictors
               of human language processing behaviors.",
  month     =  dec,
  year      =  2023,
  url = "https://aclanthology.org/2023.emnlp-main.466/"
}

@ARTICLE{Wilcox2024-qx,
  title    = "Bigger is not always better: The importance of human-scale
              language modeling for psycholinguistics",
  author   = "Wilcox, Ethan Gotlieb and Hu, Michael and Mueller, Aaron and
              Linzen, Tal and Warstadt, Alex and Choshen, Leshem and Zhuang,
              Chengxu and Cotterell, Ryan and Williams, Adina",
  journal  = "PsyArXiv",
  abstract = "Neural network language models can learn a surprising amount about
              language by predicting upcoming words in a corpus. Recent language
              technologies work has demonstrated that large performance
              improvements can arise from simply increasing (``scaling'') the
              size of the data sets they are trained on (and, correspondingly,
              the number of parameters in those models); accordingly, many
              contemporary systems are trained on trillions of words. While
              largely beneficial to performance on language applications,
              scaling has several downsides for both computational
              psycholinguistics and natural language processing research. We
              discuss the scientific challenges presented by scaling, as well as
              the benefits that would result from human-scale language modeling
              research. In the second half of this paper, we report on takeaways
              from two efforts to bring about human-scale language model
              pretraining. First, we report on the first iteration of the BabyLM
              Challenge, a shared task organized by the authors that asked
              participants to train a language model on 100 million words or
              less. Second, we present experiments to answer open questions from
              the findings of the BabyLM Challenge: namely, are a significant
              amount of computational resources required to achieve high
              performance, even at such small scales? We find that high
              performance can be achieved at small data scales and with typical
              academic-scale computational resources.",
  month    =  jul,
  year     =  2024,
  language = "en",
  url="https://osf.io/preprints/psyarxiv/rfwgd"
}

@ARTICLE{Witzel2012-nr,
  title     = "Comparisons of online reading paradigms: eye tracking,
               moving-window, and maze",
  author    = "Witzel, Naoko and Witzel, Jeffrey and Forster, Kenneth",
  journal   = "Journal of Psycholinguistic Research",
  publisher = "Springer Science and Business Media LLC",
  volume    =  41,
  number    =  2,
  pages     = "105--128",
  abstract  = "This study compares four methodologies used to examine online
               sentence processing during reading. Specifically, self-paced,
               non-cumulative, moving-window reading (Just et al. in J Exp
               Psychol Gen 111:228-238, 1982), eye tracking (see e.g., Rayner in
               Q J Exp Psychol 62:1457-1506, 2009), and two versions of the maze
               task (Forster et al. in Behav Res Methods 41:163-171, 2009)--the
               lexicality maze and the grammaticality maze--were used to
               investigate the processing of sentences containing temporary
               structural ambiguities. Of particular interest were (i) whether
               each task was capable of revealing processing differences on
               these sentences and (ii) whether these effects were indicated
               precisely at the predicted word/region. Although there was
               considerable overlap in the general pattern of results from the
               four tasks, there were also clear differences among them in terms
               of the strength and timing of the observed effects. In
               particular, excepting sentences that tap into clause-closure
               commitments, both maze task versions provided robust,
               ``localized'' indications of incremental sentence processing
               difficulty relative to self-paced reading and eye tracking.",
  month     =  apr,
  year      =  2012,
  language  = "en",
  url = "https://link.springer.com/article/10.1007/s10936-011-9179-x"
}

@inproceedings{Yoshida2021-rc,
    title = "Modeling Human Sentence Processing with Left-Corner Recurrent Neural Network Grammars",
    author = "Yoshida, Ryo  and
      Noji, Hiroshi  and
      Oseki, Yohei",
    booktitle = "Proceedings of EMNLP 2021",
    month = nov,
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.235",
    doi = "10.18653/v1/2021.emnlp-main.235",
    pages = "2964--2973",
    abstract = "In computational linguistics, it has been shown that hierarchical structures make language models (LMs) more human-like. However, the previous literature has been agnostic about a parsing strategy of the hierarchical models. In this paper, we investigated whether hierarchical structures make LMs more human-like, and if so, which parsing strategy is most cognitively plausible. In order to address this question, we evaluated three LMs against human reading times in Japanese with head-final left-branching structures: Long Short-Term Memory (LSTM) as a sequential model and Recurrent Neural Network Grammars (RNNGs) with top-down and left-corner parsing strategies as hierarchical models. Our computational modeling demonstrated that left-corner RNNGs outperformed top-down RNNGs and LSTM, suggesting that hierarchical and left-corner architectures are more cognitively plausible than top-down or sequential architectures. In addition, the relationships between the cognitive plausibility and (i) perplexity, (ii) parsing, and (iii) beam size will also be discussed.",
}

@ARTICLE{Zhou2020-vz,
  title    = "{BERT} loses Patience: Fast and robust inference with Early Exit",
  author   = "Zhou, Wangchunshu and Xu, Canwen and Ge, Tao and McAuley, Julian
              and Xu, Ke and Wei, Furu",
  journal  = "NeurIPS 2020",
  volume   = "abs/2006.04152",
  abstract = "In this paper, we propose Patience-based Early Exit, a
              straightforward yet effective inference method that can be used as
              a plug-and-play technique to simultaneously improve the efficiency
              and robustness of a pretrained language model (PLM). To achieve
              this, our approach couples an internal-classifier with each layer
              of a PLM and dynamically stops inference when the intermediate
              predictions of the internal classifiers remain unchanged for a
              pre-defined number of steps. Our approach improves inference
              efficiency as it allows the model to make a prediction with fewer
              layers. Meanwhile, experimental results with an ALBERT model show
              that our method can improve the accuracy and robustness of the
              model by preventing it from overthinking and exploiting multiple
              classifiers for prediction, yielding a better accuracy-speed
              trade-off compared to existing early exit methods.",
  month    =  jun,
  year     =  2020,
  url = "https://proceedings.neurips.cc/paper/2020/hash/d4dd111a4fd973394238aca5c05bebe3-Abstract.html"
}

@article{belrose2023eliciting,
  title={Eliciting Latent Predictions from Transformers with the Tuned Lens},
  author={Belrose, Nora and Furman, Zach and Smith, Logan and Halawi, Danny and McKinney, Lev and Ostrovsky, Igor and Biderman, Stella and Steinhardt, Jacob},
  year={2023},
  journal={arXiv preprint.},
  URL={https://arxiv.org/abs/2303.08112}
}

@inproceedings{dar-etal-2023-analyzing,
    title = "Analyzing Transformers in Embedding Space",
    author = "Dar, Guy  and
      Geva, Mor  and
      Gupta, Ankit  and
      Berant, Jonathan",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of ACL 2023",
    month = jul,
    year = "2023",
    url = "https://aclanthology.org/2023.acl-long.893",
    doi = "10.18653/v1/2023.acl-long.893",
    pages = "16124--16170",
}

@article{frank2011insensitivity,
    title = {Insensitivity of the Human Sentence-Processing System to Hierarchical Structure},
    year = {2011},
    journal = {Psychological Science},
    author = {Frank, Stefan L and Bod, Rens},
    number = {6},
    pages = {829--834},
    volume = {22},
    publisher = {Sage Publications Sage CA: Los Angeles, CA},
    url = {https://www.researchgate.net/publication/51140976_Insensitivity_of_the_Human_Sentence-Processing_System_to_Hierarchical_Structure}
}

@inproceedings{hale-2001-probabilistic,
    title = {A Probabilistic {Earley} Parser as a Psycholinguistic Model},
    year = {2001},
    booktitle = {Proceedings of NAACL 2001},
    author = {Hale, John},
    pages = {159--166},
    url = {https://www.aclweb.org/anthology/N01-1021}
}

@inproceedings{icml19shallowdeepnetworks,
  Title = {{Shallow-Deep Networks}: Understanding and Mitigating Network Overthinking},
  Author = {Yi\u{g}itcan Kaya and Sanghyun Hong and Tudor Dumitras},
  Booktitle = {Proceedings of ICML 2019},
  Month = {Jun},
  Year = {2019},
  url = {https://proceedings.mlr.press/v97/kaya19a.html}
}

@inproceedings{kuribayashi-etal-2021-lower,
    title = "Lower Perplexity is Not Always Human-Like",
    author = "Kuribayashi, Tatsuki  and
      Oseki, Yohei  and
      Ito, Takumi  and
      Yoshida, Ryo  and
      Asahara, Masayuki  and
      Inui, Kentaro",
    booktitle = "Proceedings of ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    url = "https://aclanthology.org/2021.acl-long.405",
    doi = "10.18653/v1/2021.acl-long.405",
    pages = "5203--5217",
    abstract = "In computational psycholinguistics, various language models have been evaluated against human reading behavior (e.g., eye movement) to build human-like computational models. However, most previous efforts have focused almost exclusively on English, despite the recent trend towards linguistic universal within the general community. In order to fill the gap, this paper investigates whether the established results in computational psycholinguistics can be generalized across languages. Specifically, we re-examine an established generalization {---}\textit{the lower perplexity a language model has, the more human-like the language model is}{---} in Japanese with typologically different structures from English. Our experiments demonstrate that this established generalization exhibits a surprising lack of universality; namely, lower perplexity is not always human-like. Moreover, this discrepancy between English and Japanese is further explored from the perspective of (non-)uniform information density. Overall, our results suggest that a cross-lingual evaluation will be necessary to construct human-like computational models.",
}

@inproceedings{kuribayashi-etal-2022-context,
    title = "Context Limitations Make Neural Language Models More Human-Like",
    author = "Kuribayashi, Tatsuki  and
      Oseki, Yohei  and
      Brassard, Ana  and
      Inui, Kentaro",
    booktitle = "Proceedings of EMNLP 2022",
    month = dec,
    year = "2022",
    url = "https://aclanthology.org/2022.emnlp-main.712",
    doi = "10.18653/v1/2022.emnlp-main.712",
    pages = "10421--10436",
    abstract = "Language models (LMs) have been used in cognitive modeling as well as engineering studies{---}they compute information-theoretic complexity metrics that simulate humans{'} cognitive load during reading. This study highlights a limitation of modern neural LMs as the model of choice for this purpose: there is a discrepancy between their context access capacities and that of humans. Our results showed that constraining the LMs{'} context access improved their simulation of human reading behavior. We also showed that LM-human gaps in context access were associated with specific syntactic constructions; incorporating syntactic biases into LMs{'} context access might enhance their cognitive plausibility.",
}

@inproceedings{kuribayashi-etal-2024-psychometric,
    title = "Psychometric Predictive Power of Large Language Models",
    author = "Kuribayashi, Tatsuki  and
      Oseki, Yohei  and
      Baldwin, Timothy",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of NAACL 2024",
    month = jun,
    year = "2024",
    url = "https://aclanthology.org/2024.findings-naacl.129",
    doi = "10.18653/v1/2024.findings-naacl.129",
    pages = "1983--2005",
}

@misc{logitlens,
title= "interpreting gpt: the logit lens.",
author="nostalgebraist",
year="2020",
url="https://www.lesswrong.
com/posts/AcKRB8wDpdaN6v6ru/
interpreting-gpt-the-logit-lens"
}

@book{marr1982,
author = {Marr, David},
title = {Vision: A Computational Investigation into the Human Representation and Processing of Visual Information},
year = {1982},
isbn = {0716715678},
publisher = {Henry Holt and Co., Inc.},
address = {USA},
url ={https://academic.oup.com/mit-press-scholarship-online/book/13528?sid=oup:oxfordacademic&genre=book&aulast=Marr&aufirst=David&title=Vision%3A+A+Computational+Investigation+into+the+Human+Representation+and+Processing+of+Visual+Information&date=2010-07-09}
}

@inproceedings{nair2023words,
  title={Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship?},
  author={Nair, Sathvik and Resnik, Philip},
  booktitle={Findings of EMNLP2023},
  year={2023},
  url={https://arxiv.org/abs/2310.17774}
}

