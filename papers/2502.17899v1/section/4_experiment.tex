% \begin{figure*}[ht]
%     \centering
%     \includegraphics[width=0.8\linewidth]{figures/image/Rplot01.pdf}
%     \caption{LLMs Comparison Metrics on Implicit Suicide Data. 
%     This figure illustrates the performance of various LLMs on implicit suicide-related content. The results indicate that most models struggle to detect implicit suicidal intent, with average response scores clustering around 75 and relatively low suitability scores. Gemini-1.5 performs competitively across metrics. Adding context consistently reduces the harmful response rate (HRR) for almost all models. Response patterns remain stable after context introduction, except for DeepSeek, which shows more variation without notable performance gains.}
%     \label{fig:comparison}
% \end{figure*}
\input{tables/main_result_table}

\begin{figure*}[htbt]
    \centering
    \includegraphics[width=\linewidth]{figures/image/density.pdf}
    \caption{Effect of Cognitive Issues and Context on Model Performance. The left panel compares score distributions across scenarios, showing that responses to some input with cognitive issues consistently score higher. The right panel presents density distributions before and after a more explicit context introduction, demonstrating that implicit suicidal signals pose challenges for models.}
    \label{fig:comparison3}
\end{figure*}

\section{Experiment}
In this section, we present an empirical study evaluating eight widely used LLMs on \ourdata to assess their ability to identify relevant cases and provide supportive advice.
\subsection{Expeirment Setup}

We conducted a comprehensive evaluation of eight Large Language Models (LLMs): DeepSeek-R1, DeepSeek-R1-Distill-Llama-70B, Llama-3.1-70B, Llama-3.1-8B, Mistral-7B, Gemini-1.5-Pro, GPT-3.5-Turbo, and GPT-4o-Mini. To evaluate Response Quality and Suitability Determination, we used GPT-4 as our reference model, applying the metric introduced in Section~\ref{sec: eva pipeline}. This allowed us to assess the alignment between human labelers and the model's judgments. A detailed analysis of this alignment is provided in Appendix~\ref{sec:human}, where we validate the GPT-4 generated scores against human annotations.

% \noindent \textbf{2. LLM Assessment}.
% \begin{itemize}
%     \item Response Quality Assessment: The GPT-4 scores responses on a 100-point scale on five psychological dimensions: emotional sensitivity, relevance, ethical safety, constructiveness, and clarity. 
%     \item Suitability Determination: Responses were considered “suitable” only if they avoided escalating distress, provided meaningful engagement, and encouraged real-world support. 
% \end{itemize}

\subsection{Main Results}
This section evaluates the overall performance of LLMs on the implicit suicide dataset across multiple metrics. Table~\ref{tab:llm-evaluation} highlights the following key findings:
\textbf{(i)} Most LLMs demonstrate limited sensitivity in detecting implicit suicidal ideation. Most LLMs struggle to detect implicit suicidal ideation, showing limited sensitivity and low suitability scores. While average response scores remain around 75, suggesting structured and coherent outputs, they often fail to provide meaningful support. Among the tested models, Gemini-1.5 demonstrates more stable recognition and response capabilities across different parts of the dataset.
\textbf{(ii)} Models perform better when provided with explicit potential suicidal warnings. Explicit cues significantly reduce harmful response rates, particularly in Llama and GPT-4. However, cryptic expressions remain challenging, often leading to inappropriate or harmful responses when the context is unclear.
\textbf{(iii)} Response patterns exhibit stability despite contextual modifications. Most of the models maintain consistent generation patterns after contextual cue changes. While the Deepseek family of models shows more variability, this does not translate into significant performance improvements.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.80\linewidth]{figures/image/radar_charts.pdf}
    \caption{Comparison of  LLMs' performance across different stress-related scenarios.}
    \label{fig:comparison2}
\end{figure}
\subsection{Discussion}
\paragraph{Performance Across Different Scenarios}
We analyze LLM performance across various scenarios (e.g., education pressure, relationship problems, financial crisis, depression) based on average response score and appropriate response success rate. Figure~\ref{fig:comparison2} reveals the following key insights: Scores are relatively consistent across scenarios, indicating minimal bias toward specific psychological stressors. However, certain scenarios, such as educational stress, relationship problems, and financial crises, yield higher scores, suggesting LLMs handle explicit social and economic stressors more effectively. The "Unknown" category, representing subtle implicit suicidal intent (derived from D/S-IAT without a specific scenario), consistently receives lower scores. This highlights models' difficulty in detecting suicidal intent without explicit contextual cues. While average scores remain stable, fluctuations in inappropriate response success rates are more pronounced. This indicates that even when responses are coherent and relevant, ensuring they are psychologically supportive and safe remains a significant challenge.

\paragraph{Effect of ANT Factors and Warning Information}
We examine the impact of ANT factors and contextual cues on model performance. Figure~\ref{fig:comparison3} shows: Models perform better when cognitive distortions are present. Responses generated under cognitive issues consistently score higher, as LLMs are more sensitive to cognitive distortions and better at redirecting such expressions. Contextual cues with explicit suicide warnings improve score distributions for most models. This effect is particularly notable in Gemini-pro and Llama-3-70B, where additional explicit information leads to more focused distribution and higher-quality responses.

These findings underscore the challenges LLMs face in detecting and responding to implicit suicidal intent. While cognitive distortions, social stressors, and explicit guidance can enhance response quality, they are insufficient to fully address real-world suicidal ideation. This highlights the need for deeper psychological reasoning and a more nuanced understanding of human emotions to ensure LLMs provide reliable and supportive responses in mental health applications.
% Our experiment consists of two key components: data construction** and LLM assessment of implicit suicide ideation. 

% \noindent \textbf{1. Data Construction}.  
% \begin{itemize}
%     \item Cognitive and Thought Pattern Modeling: LLM extends suicidal ideation patterns from D/S-IAT and ANT to implicit expressions. 
%     \item Expansion of psychological barriers, triggers, and scenarios: LLMs incorporate psychological conditions, social triggers, and distressing real-world scenarios into their generation, in addition to simulating from real structured data.
% \end{itemize} 

% \begin{figure*}[ht]
%     \centering
%     \begin{subfigure}{0.69\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/image/Rplot01.pdf}
%         % \caption{Performance of LLMs on implicit suicide-related content. Most models struggle to detect implicit suicidal intent, with response scores clustering around 75 and relatively low suitability scores. Gemini-1.5 performs competitively across metrics. Adding context reduces the harmful response rate (HRR) for nearly all models, though response patterns remain stable except for DeepSeek, which shows higher variability without significant performance improvements.}
%         \label{fig:comparison}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}{0.30\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/image/radar_charts.pdf}
%         % \caption{Comparison of LLMs' performance across different stress-related scenarios. The left radar plot shows average response scores, which remain consistent but slightly higher in social and financial stress contexts. The right radar plot highlights appropriate response success rates, revealing greater variability. The "Unknown" category scores the lowest, indicating difficulty in detecting suicidal intent without explicit context. Red dots indicate the lowest-performing models, while green dots denote the best performers.}
%         \label{fig:comparison2}
%     \end{subfigure}
%     \caption{Comparison of LLMs' ability to detect and respond to implicit suicide-related content and stress-related scenarios. (a) Evaluates detection performance and response suitability. (b) Analyzes variations in response scores and success rates across different stress contexts.}
%     \label{fig:comparison_overall}
% \end{figure*}
