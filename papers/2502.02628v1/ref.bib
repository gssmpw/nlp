@article{etesam2024deep,
  title={Deep Generative Model for Mechanical System Configuration Design},
  author={Etesam, Yasaman and Cheong, Hyunmin and Ataei, Mohammadmehdi and Jayaraman, Pradeep Kumar},
  journal={arXiv preprint arXiv:2409.06016},
  year={2024}
}

@article{hejna2023contrastive,
  title={Contrastive prefence learning: Learning from human feedback without rl},
  author={Hejna, Joey and Rafailov, Rafael and Sikchi, Harshit and Finn, Chelsea and Niekum, Scott and Knox, W Bradley and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2310.13639},
  year={2023}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{leerlaif,
  title={RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Mesnard, Thomas and Ferret, Johan and Lu, Kellie Ren and Bishop, Colton and Hall, Ethan and Carbune, Victor and Rastogi, Abhinav and others},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{gulcehre2023reinforced,
  title={Reinforced self-training (rest) for language modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023}
}

@inproceedings{zhang2023wisdom,
  title={The wisdom of hindsight makes language models better instruction followers},
  author={Zhang, Tianjun and Liu, Fangchen and Wong, Justin and Abbeel, Pieter and Gonzalez, Joseph E},
  booktitle={International Conference on Machine Learning},
  pages={41414--41428},
  year={2023},
  organization={PMLR}
}

@article{liu2023rltf,
  title={Rltf: Reinforcement learning from unit test feedback},
  author={Liu, Jiate and Zhu, Yiqin and Xiao, Kaiwen and Fu, Qiang and Han, Xiao and Yang, Wei and Ye, Deheng},
  journal={arXiv preprint arXiv:2307.04349},
  year={2023}
}

@article{jha2024rlsf,
  title={RLSF: Reinforcement Learning via Symbolic Feedback},
  author={Jha, Piyush and Jana, Prithwish and Arora, Arnav and Ganesh, Vijay},
  journal={arXiv preprint arXiv:2405.16661},
  year={2024}
}

@article{yang2024rewards,
  title={Rewards-in-context: Multi-objective alignment of foundation models with dynamic preference adjustment},
  author={Yang, Rui and Pan, Xiaoman and Luo, Feng and Qiu, Shuang and Zhong, Han and Yu, Dong and Chen, Jianshu},
  journal={arXiv preprint arXiv:2402.10207},
  year={2024}
}

@article{rame2024rewarded,
  title={Rewarded soups: towards pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards},
  author={Rame, Alexandre and Couairon, Guillaume and Dancette, Corentin and Gaya, Jean-Baptiste and Shukor, Mustafa and Soulier, Laure and Cord, Matthieu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{zhou2024beyond,
  title={Beyond one-preference-fits-all alignment: Multi-objective direct preference optimization},
  author={Zhou, Zhanhui and Liu, Jie and Shao, Jing and Yue, Xiangyu and Yang, Chao and Ouyang, Wanli and Qiao, Yu},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={10586--10613},
  year={2024}
}

@article{guo2024controllable,
  title={Controllable preference optimization: Toward controllable multi-objective alignment},
  author={Guo, Yiju and Cui, Ganqu and Yuan, Lifan and Ding, Ning and Sun, Zexu and Sun, Bowen and Chen, Huimin and Xie, Ruobing and Zhou, Jie and Lin, Yankai and others},
  journal={arXiv preprint arXiv:2402.19085},
  year={2024}
}

@inproceedings{lee2025parrot,
  title={Parrot: Pareto-optimal multi-reward reinforcement learning framework for text-to-image generation},
  author={Lee, Seung Hyun and Li, Yinxiao and Ke, Junjie and Yoo, Innfarn and Zhang, Han and Yu, Jiahui and Wang, Qifei and Deng, Fei and Entis, Glenn and He, Junfeng and others},
  booktitle={European Conference on Computer Vision},
  pages={462--478},
  year={2025},
  organization={Springer}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{xu2024perfect,
  title={The perfect blend: Redefining RLHF with mixture of judges},
  author={Xu, Tengyu and Helenowski, Eryk and Sankararaman, Karthik Abinav and Jin, Di and Peng, Kaiyan and Han, Eric and Nie, Shaoliang and Zhu, Chen and Zhang, Hejia and Zhou, Wenxuan and others},
  journal={arXiv preprint arXiv:2409.20370},
  year={2024}
}

@article{williams2024multi,
  title={Multi-objective Reinforcement learning from AI Feedback},
  author={Williams, Marcus},
  journal={arXiv preprint arXiv:2406.07295},
  year={2024}
}

@article{wu2023fine,
  title={Fine-grained human feedback gives better rewards for language model training},
  author={Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={59008--59033},
  year={2023}
}

@article{haimes1971bicriterion,
  title={On a bicriterion formulation of the problems of integrated system identification and system optimization},
  author={Haimes, Yacov},
  journal={IEEE transactions on systems, man, and cybernetics},
  number={3},
  pages={296--297},
  year={1971},
  publisher={Institute of Electrical and Electronics Engineers (IEEE)}
}

@inproceedings{zitzler1998multiobjective,
  title={Multiobjective optimization using evolutionary algorithmsâ€”a comparative case study},
  author={Zitzler, Eckart and Thiele, Lothar},
  booktitle={International conference on parallel problem solving from nature},
  pages={292--301},
  year={1998},
  organization={Springer}
}

@article{regenwetter2022deep,
  title={Deep generative models in engineering design: A review},
  author={Regenwetter, Lyle and Nobari, Amin Heyrani and Ahmed, Faez},
  journal={Journal of Mechanical Design},
  volume={144},
  number={7},
  pages={071704},
  year={2022},
  publisher={American Society of Mechanical Engineers}
}

@article{peschl2021moral,
  title={MORAL: Aligning AI with human norms through multi-objective reinforced active learning},
  author={Peschl, Markus and Zgonnikov, Arkady and Oliehoek, Frans A and Siebert, Luciano C},
  journal={arXiv preprint arXiv:2201.00012},
  year={2021}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{glaese2022improving,
  title={Improving alignment of dialogue agents via targeted human judgements},
  author={Glaese, Amelia and McAleese, Nat and Tr{\k{e}}bacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and others},
  journal={arXiv preprint arXiv:2209.14375},
  year={2022}
}

@article{zhong2024panacea,
  title={Panacea: Pareto alignment via preference adaptation for llms},
  author={Zhong, Yifan and Ma, Chengdong and Zhang, Xiaoyuan and Yang, Ziran and Chen, Haojun and Zhang, Qingfu and Qi, Siyuan and Yang, Yaodong},
  journal={arXiv preprint arXiv:2402.02030},
  year={2024}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@inproceedings{azar2024general,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Guo, Zhaohan Daniel and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4447--4455},
  year={2024},
  organization={PMLR}
}

@article{ethayarajh2024kto,
  title={Kto: Model alignment as prospect theoretic optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}

@article{xu2024perfect,
  title={The perfect blend: Redefining RLHF with mixture of judges},
  author={Xu, Tengyu and Helenowski, Eryk and Sankararaman, Karthik Abinav and Jin, Di and Peng, Kaiyan and Han, Eric and Nie, Shaoliang and Zhu, Chen and Zhang, Hejia and Zhou, Wenxuan and others},
  journal={arXiv preprint arXiv:2409.20370},
  year={2024}
}

@incollection{deb2016multi,
  title={Multi-objective optimization},
  author={Deb, Kalyanmoy and Sindhya, Karthik and Hakanen, Jussi},
  booktitle={Decision sciences},
  pages={161--200},
  year={2016},
  publisher={CRC Press}
}

@article{deb2002fast,
  title={A fast and elitist multiobjective genetic algorithm: NSGA-II},
  author={Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, TAMT},
  journal={IEEE transactions on evolutionary computation},
  volume={6},
  number={2},
  pages={182--197},
  year={2002},
  publisher={IEEE}
}