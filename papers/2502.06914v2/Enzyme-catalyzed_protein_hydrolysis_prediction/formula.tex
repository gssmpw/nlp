
各层各头参数共享
%采用两个一维高斯分别处理Energy与Distance，暂定使用的方案
\[
\psi_{\text{dist},(i,j)}^{k} = \frac{1}{\sqrt{2\pi} \sigma_D^k} 
\exp\left( 
-\frac{1}{2} \left( \frac{D_{(i,j)} + b_D^k  - \mu_D^k}{\sigma_D^k} \right)^2
\right),\tag{1}
\]
\[
\psi_{\text{energy},(i,j)}^{k} = \frac{1}{\sqrt{2\pi} \sigma_E^k} 
\exp\left( 
-\frac{1}{2} \left( \frac{E_{(i,j)} + b_E^k - \mu_E^k}{\sigma_E^k} \right)^2
\right),\tag{2}
\]


\[
D_{(i,j)} = \frac{1}{1 + \|r_i - r_j\|},\tag{3}
\]

\[
E_{(i,j)} = \frac{E_{\text{actual,{(i,j)}}} - \mu_{\text{random,{(i,j)}}}}{\sigma_{\text{random,{(i,j)}}}},\tag{4}
\]

% 参数说明
其中：
\begin{itemize}
    \item \(D_{(i,j)} + b_r^k\): 带有偏置项 \(b_r\) 的距离项。
    \item \(E_{(i,j)} + b_E^k\): 带有偏置项 \(b_E\) 的能量项。
    \item \(\mu_D^k, \mu_E^k\): 分别表示距离和能量的高斯核中心。
    \item \(\sigma_D^k, \sigma_E^k\): 分别表示距离和能量的标准差。
    \item \(\psi_{\text{dist}}^k\): distance的第k个高斯基函数
    \item     \(\psi_{\text{energy}}^k\): energy的第k个高斯基函数
    \item     \( E_{\text{actual}} \)：残基对的实际相互作用能量
    \item \( \mu_{\text{random}} \)：将残基对的配对关系或位置进行随机打乱，得到的随机构象中相互作用能量的平均值 
    \item \( \sigma_{\text{random}} \)：是基于这些随机构象的相互作用能量的标准差，用于衡量能量分布的离散程度
\end{itemize}


\[
\Phi_{ij} = \text{GELU} \left( \psi_{(i,j)}^{} \mathbf{W}_D^1 \right) \mathbf{W}_D^2,\tag{5}
\]
\[
\psi_{(i,j)} = 
\begin{bmatrix}
\psi_{(i,j)}^1 ; \, \dots ; \, \psi_{(i,j)}^K
\end{bmatrix}^\top, \quad
\mathbf{W}_D^1 \in \mathbb{R}^{K \times K}, \, \mathbf{W}_D^2 \in \mathbb{R}^{K \times 1}
\]

% 注意力加权，Enzyme
\[
\mathbf{A}^h(\mathbf{X}^{(l)}) = \text{softmax} \left(
\frac{\mathbf{X}^{(l)} \mathbf{W}_Q^{l,h} \left( \mathbf{X}^{(l)} \mathbf{W}_K^{l,h} \right)^\top}{\sqrt{d}} +\Phi_{\text{dist}}+\Phi_{\text{energy}}
\right), \tag{6}
\]

% 注意力加权，Substrate
\[
\mathbf{A}^h(\mathbf{X}^{(l)}) = \text{softmax} \left(
\frac{\mathbf{X}^{(l)} \mathbf{W}_Q^{l,h} \left( \mathbf{X}^{(l)} \mathbf{W}_K^{l,h} \right)^\top}{\sqrt{d}} +\text{ReLU} \left( \Phi_{\text{dist}} \mathbf{W}^{l,h}_\text{adapter,1} \right) \mathbf{W}^{l,h}_\text{adapter,2}
\right), \tag{7}
\]

\[
\mathbf{X}^{(0)}  = \text{ESM}(\mathbf{S}),\tag{8}
\]

% Transformer Output
\[
\hat{\mathbf{X}}^{(l)} = \mathbf{X}^{(l)} + \sum_{h=1}^H \mathbf{A}^h(\mathbf{X}^{(l)}) \mathbf{X}^{(l)} \mathbf{W}_V^{l,h} \mathbf{W}_O^{l,h},\tag{9}
\]

% Feed-forward layer
\[
\mathbf{X}^{(l+1)} = \hat{\mathbf{X}}^{(l)} + \text{GELU} \left( \hat{\mathbf{X}}^{(l)} \mathbf{W}_1^l \right) \mathbf{W}_2^l, \tag{10}
\]

% Parameter explanation
其中，\(\mathbf{W}_O^{l,h} \in \mathbb{R}^{d_H \times d}, \mathbf{W}_Q^{l,h}, \mathbf{W}_K^{l,h}, \mathbf{W}_V^{l,h} \in \mathbb{R}^{d \times d_H}\),
\(\mathbf{W}_1^l \in \mathbb{R}^{d \times r}, \mathbf{W}_2^l \in \mathbb{R}^{r \times d}\)，
\(H\) 是注意力头的数量，\(d_H\) 是每个头的维度，\(r\) 是隐藏层的维度。
\(\mathbf{W}_\text{adapter,1} \in \mathbb{R}^{d \times d}\)：第一层线性变换权重。
\(\mathbf{W}_\text{adapter,2} \in \mathbb{R}^{d \times d}\)：第二层线性变换权重。
\(\text{ReLU}\): 激活函数，作用在第一层的输出上。
\(\mathbf{S}\): 输入的蛋白质序列。
\(\text{ESM}(\cdot)\): 蛋白质语言模型（Evolutionary Scale Modeling）。
\(\text{X}\): 语言模型提取的蛋白质特征。





1、Activation Sites预测:

给定Enzyme的ESM输出特征 \(\mathbf{X} \in \mathbb{R}^{l \times d}\)，通过\(\text{MLP}_{\text{Activation}}得到 \text{Activation Sites }预测结果 \(\mathbf{A} \in \mathbb{R}^{l \times 1}\)：

\[
\mathbf{A} = \text{Sigmoid} \left( \text{MLP}_{\text{Activation}} (\mathbf{X}_{\text{Enzyme}}) \right),\tag{11}
\]
其中：
- \(\mathbf{X}_{Enzyme}\in \mathbb{R}^{l \times d}\): Enzyme Feature。
- \(\mathbf{A} \in \mathbb{R}^{l \times 1}\)：Activation Sites 权重。


2、Site-Aware Pooling:

将 Activation Sites \(\mathbf{A}\) 作为权重，对酶特征矩阵 \(\mathbf{E} \in \mathbb{R}^{l \times d}\) 进行加权池化:

\[
\\\overset{\cdot}{A}_{i}^{k} = \frac{1}{\sqrt{2\pi} \sigma_A^k} 
\exp\left( 
-\frac{1}{2} \left( \frac{A_{i} + b_A^k  - \mu_A^k}{\sigma_A^k} \right)^2
\right),\tag{}
\]


\[
\\\overset{\sim}A_{i} = \text{GELU} \left( \\\overset{\cdot}{A}_{i} \mathbf{W}_A^1 \right) \mathbf{W}_A^2,\tag{}
\]
\[
\\\overset{\cdot}A_{i} = 
\begin{bmatrix}
\overset{\cdot}A_{i}^1 ; \, \dots ; \, \overset{\cdot}A_{i}^{k}
\end{bmatrix}^\top, \quad
\mathbf{W}_A^1 \in \mathbb{R}^{K \times K}, \, \mathbf{W}_A^2 \in \mathbb{R}^{K \times 1}
\]
\[
\mathbf{E}_{\text{pool}} = \sum_{i=1}^l \overset{\sim}A_i \mathbf{E}_i,\tag{12}
\]
其中：
- \( A_i \)：第i个氨基酸的Activation Sites预测值
- \(\mathbf{E}_i\)：\(\mathbf{E}\) 中第i个氨基酸的特征。

3、特征拼接:

将池化后的酶特征 \(\mathbf{E}_{\text{pool}} \in \mathbb{R}^d\) 与底物特征 \(\mathbf{S} \in \mathbb{R}^{l \times d}\) 进行拼接：

\[
\mathbf{F}_{\text{combined}} = \text{cat}(\mathbf{S}, \mathbf{E}_{\text{pool}}),\tag{13}
\]
其中 \(\mathbf{F}_{\text{combined}} \in \mathbb{R}^{l \times 2d}\)。

4. MLP 输出: 

将拼接后的特征 \(\mathbf{F}_{\text{combined}}\) 输入到 MLP 网络，得到最终预测结果：

\[
C =\text{Sigmoid}( \text{MLP}_{\text{Cleavage}}(\mathbf{F}_{\text{combined}})),\tag{14}
\]
其中：
- MLP 包括多层线性变换、Dropout 和激活函数（如 ReLU 和 Sigmoid）。
- 输出 \(C \in \mathbb{R}^{l\times 1}\) 是水解位点预测结果。

5、Loss计算

激活位点损失:

\[
\mathcal{L}_{\text{active}} = \text{BCE}(\mathbf{A}, \text{True}_{\text{active}}),\tag{15}
\]
其中:
- \(\mathbf{A}\)：预测的激活位点概率。
- \(\text{True}_{\text{active}}\)：真实激活位点标签。

切割位点损失:

\[
\mathcal{L}_{\text{cleavage}} = \text{BCE}(\mathbf{C}, \text{True}_{\text{cleavage}}),\tag{16}
\]
其中：
- \(\mathbf{C}\)：预测的切割位点概率。
- \(\text{True}_{\text{cleavage}}\)：真实水解位点标签。

3. Total Loss:
\[
\mathcal{L} = \mathcal{L}_{\text{cleavage}} + \mathcal{L}_{\text{active}},\tag{17}
\]
其中：
- \(\mathcal{L}_{\text{active}}\)：激活位点的二元交叉熵损失。
- \(\mathcal{L}_{\text{cleavage}}\)：切割位点的二元交叉熵损失。
- \(\mathcal{L}\)：总损失值。

