

\begin{table*}[t]
\scriptsize
\centering
\caption{Comparison of protein cleavage site prediction in a supervised setting. All values are mean $\pm$ std (\%). Note that ScreenCap3 and CAT3 are specialized models for the C14.003 enzyme family, which are not applicable to C14.005 and M10.003.}
\begin{tabularx}{0.98\linewidth}{llRRRRRRR}
\toprule
Enzymes & Metric & ScreenCap3 & CAT3 & ProsperousPlus & Procleave & ReactZyme & ClipZyme & UniZyme \\
\midrule

\multirow{2}{*}{C14.003} 
& ROC-AUC
& 74.6$\pm$10.2 
& 74.9$\pm$10.1 
& \cellcolor{gray!20}{93.7$\pm$0.6}
& 69.4$\pm$0.9 
& 93.3$\pm$0.2 
&  {93.5$\pm$0.1} 
& \underline{\bf97.3$\pm$0.1} \\
& PR-AUC  
& 29.2$\pm$16.0 
& 18.5$\pm$6.2  
& 26.6$\pm$2.1 
& 4.4$\pm$3.7 
&  \cellcolor{gray!20}{43.8$\pm$0.8} 
& 35.3$\pm$0.9 
& \underline{\bf45.9$\pm$1.2} \\
    
\midrule
\multirow{2}{*}{C14.005}
& ROC-AUC 
& NA            
& NA            
& 86.6$\pm$0.6 
& 73.0$\pm$0.9 
& \cellcolor{gray!20}{92.9$\pm$0.2}
& 92.3$\pm$0.4 
& \underline{\bf96.2$\pm$0.1} \\
& PR-AUC 
& NA            
& NA            
& 15.9$\pm$0.5 
& 3.5$\pm$0.3 
& \cellcolor{gray!20}{47.6$\pm$0.9}
& 43.2$\pm$1.0 
& \underline{\bf52.2$\pm$0.9} \\
\midrule
    
\multirow{2}{*}{M10.003}
& ROC-AUC 
& NA            
& NA            
& 79.7$\pm$0.8 
& 65.9$\pm$1.1 
& 81.4$\pm$0.3 
&  \cellcolor{gray!20}{82.5$\pm$0.3} 
& \underline{\bf87.0$\pm$0.2} \\
& PR-AUC 
& NA            
& NA            
& 5.6$\pm$0.5 
& 2.6$\pm$0.1 
& \cellcolor{gray!20}{6.4$\pm$0.3}
& 5.8$\pm$0.2 
& \underline{\bf7.3$\pm$0.4} \\
    
\bottomrule
\end{tabularx}
\label{Table:comparemodels}
\end{table*}

\section{Experiments}
In this section, we conduct experiments to answer the following research questions:
\begin{itemize}[leftmargin=*]
    \item \textbf{RQ1}: How does the performance of UniZyme compared to existing models in supervised cleavage site prediction?
     \item \textbf{RQ2}: How well does {\method} generalize to cleavage site prediction for zero-shot enzymes?
    \item \textbf{RQ3}: How do the design of biochemically-informed enzyme encoder and utilization of active-site knowledge contribute to the performance of {\method}?
   
\end{itemize}

\subsection{Experimental Setup}
% \subsection{Data Curation and Preprocessing}

\paragraph{Dataset Collection.} 
The cleavage site dataset $\mathcal{D}_c$ is sourced from the \textbf{MEROPS} database, which provides annotations for roughly 10,000 substrate cleavage sites across 876 enzymes. To ensure manageable sequence lengths, we exclude any enzyme or substrate sequences exceeding 1,500 residues\cite{dai2021labeleddatagenerationinexact}. We then perform a standard dataset expansion procedure commonly used in cleavage site prediction, yielding approximately 220,000 valid enzyme–substrate pairs.
The supplemented dataset $\mathcal{D}_a$ is constructed by combining enzyme active-site annotations from in \textbf{MEROPS}~\cite{Merops} and \textbf{UniProt}~\cite{Uniprot}. Specifically,  MEROPS provides active-site information for the enzymes already included in $\mathcal{D}_c$. We further expand the active site data by retrieving hydrolase enzymes from UniProt with the EC number of 3.4.*.*, resulting to around 10K enzymes with active sites in total.
The dataset statistics and dataset collection details can be found in Appendix~\ref{sec:app_dataset}.


\textbf{Evaluation.} To demonstrate the generalization ability of {\method}, we evaluate its performance on protein cleavage site prediction for both seen enzymes (supervised) and unseen enzymes (zero-shot). 
\begin{itemize}[leftmargin=*]
    \item  \textbf{Supervised Setting}: In this scenario, target enzymes are paired with training substrates whose cleavage sites are available. Following~\cite{ProsperousPlus,DeepCleave}, we use enzyme family M10.003, C14.003, and C14.005 as supervised benchmarks, and we randomly split their enzyme–substrate pairs in an 8:2 ratio for training and test.
    \item \textbf{Zero-shot Setting}: In this setting, the target enzymes have no labeled cleavage sites in the training data. To rigorously examine generalization, we construct three zero-shot benchmarks from the hydrolase families ,i.e., A01.009 and M10.004. We select 20\% of enzymes in each family with $\leq$80\% sequence similarity to any training samples with Needleman-Wunsch global alignment~\cite{needleman1970general}.
\end{itemize}
\vskip -1em


% \textbf{Zero-Shot Evaluation Set:} 
% For rigorous generalization assessment, we constructed a zero-shot benchmark from three hydrolase families (\textit{A01.009}, \textit{M10.004}, \textit{M10.008}). Using Needleman-Wunsch global alignment (BLOSUM62 matrix, gap penalty=-10), we selected 20\% of enzyme instances per family with $\leq$80\% sequence similarity to any training sample, ensuring divergence. This protocol yielded ... enzyme-substrate pairs strictly excluded from model training.


% \textbf{Training Data Curation:} 
% We first removed all zero-shot enzymes of A01.009/M10.004/M10.008 and their associated pairs. To prevent information leakage from multiclass enzymes, any enzyme appearing in zero-shot sets was recursively pruned from training data. All remaining data are split into training and test sets in an 80:20 ratio. The final training corpus contained ...... unique enzyme-substrate interactions across ...... distinct hydrolase families.





\paragraph{Baseline Methods.}

% \textbf{Procleave / ProsperousPlus / ScreenCap 3 / CAT3:} ScreenCap 3 offers a online server for predicting cleavage sites of enzyme C14.003, while CAT3 provides a software. Since the datasets and source code for these two methods are currently unavailable, we directly used their platforms to make predictions on our test data of C14.003. In contrast, Procleave and ProsperousPlus provide accessible code, allowing us to retrain both models alongside our own using the same training set for comparison on the test data. None of these models support zero-shot capabilities for previously unseen enzymes.

% Here’s the revised paragraph, following the structure and style of the provided example, with adjustments for conciseness and precision:

To evaluate the performance of our model, 
we compare against two specialized models: \textbf{CAT3}~\cite{CAT3}, which predicts caspase-3 cleavage sites based on position-specific scoring matrices (PSSM), and \textbf{ScreenCap3}~\cite{ScreenCap3}, which focuses on caspase-3 cleavage site prediction by filtering high-quality data to improve prediction accuracy. 
We also compare with several deep-learning methods for cleavage site prediction on a single enzyme. \textbf{Procleave}~\cite{procleave} introduces substrate structural features to account for structural biases in cleavage sites. \textbf{ProsperousPlus}~\cite{ProsperousPlus} integrates multiple methods to comprehensively evaluate cleavage site predictions. 
Additionaly, we also compare two SOTA enzyme–substrate interaction models, i.e., \textbf{ClipZyme}~\cite{ClipZyme} and \textbf{ReactZyme}~\cite{ReactZyme}, which are originally designed for predicting reactions catalyzed by enzymes. We extend them to the cleavage site prediction task for comparisons. 
For ClipZyme, we utilize their pretrained EGNN enzyme encoder to the cleavage site prediction framework to demonstrate the superiority using active-site information in enzyme encoding. For ReactZyme, it deploys a ESM-2+MLP architecture for enzyme encoding. We retrain it on our data since its trained weights are unavailable. See Appendix~\ref{sec:app_baseline} for more details.


\paragraph{Implementation Details.}
We utilized the esm2-t12-35M-UR50D model to generate 480-dimensional input features for both enzymes and substrates. These features are then fed into the transformer-based enzyme encoder and protein encoder. 
The hyperparameter $\lambda$ is selected based on the validation performance. Each experiment is conducted with 5 runs with different random seeds. To ensure a fair evaluation, hyperparameters of trainable baselines were selected by validation set. More details are in Appendix~\ref{sec:app_imp}.




\subsection{Supervised Cleavage Site Prediction}

% \begin{figure}[t!]
%     \small
%     \centering
%     \includegraphics[width=0.98 \linewidth]{figure/compare_models.png}
%     \vskip -3 em
%     \vspace{2 em}
%     \caption{comparemodels}
%     \vskip -1 em
%     \label{fig:comparemodels}
% \end{figure}




% \begin{table*}[ht]
% \centering
% \caption{Comparison of model performance on ROC and PR AUC for M10.003, C14.005, and C14.003.}
% \begin{tabular}{lcccccc}
% \toprule
% \textbf{Model} & \multicolumn{2}{c}{\textbf{C14.003}} & \multicolumn{2}{c}{\textbf{C14.005}} & \multicolumn{2}{c}{\textbf{M10.003}} \\
% \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
%  & \textbf{ROC} & \textbf{PR} & \textbf{ROC} & \textbf{PR} & \textbf{ROC} & \textbf{PR} \\
% \midrule
% \textbf{UniZyme} &  0.9725 $\$ 0.0009& 0.4593 ± 0.0120& 0.9620 ± 0.0014& 0.5220 ± 0.0093& 0.8702 ± 0.0020& 0.0729 ± 0.0035\\
% \textbf{ReactZyme}& 0.9326 ± 0.0016& 0.4381 ± 0.0077& 0.9288 ± 0.0019& 0.4758 ± 0.0093& 0.8141 ± 0.0028& 0.0641 ± 0.0029\\
% \textbf{ClipZyme} & 0.9354 ± 0.0013& 0.3533 ± 0.0088& 0.9232 ± 0.0044& 0.4324 ± 0.0101& 0.8246 ± 0.0026& 0.0577 ± 0.0017\\
% \textbf{ProsperousPlus} & 0.9372 ± 0.0061& 0.2662 ± 0.0210& 0.8664 ± 0.0064& 0.1593 ± 0.0050& 0.7973 ± 0.0077& 0.0560 ± 0.0047\\
% \textbf{Procleave} & 0.6942 ± 0.0087& 0.0442 ± 0.0373& 0.7304 ± 0.0092& 0.0351 ± 0.0031& 0.6590 ± 0.0114& 0.0264 ± 0.0010\\

% \textbf{ScreenCap3} & 0.7463 ± 0.1015& 0.2915 ± 0.1599& None& None& None& None\\
% \textbf{CAT3} & 0.7485 ± 0.1006& 0.1852 ± 0.0616& None& None& None& None\\
% \bottomrule
% \end{tabular}
% \label{Table:comparemodels}
% \end{table*}
% \begin{table*}[ht]
% \small
% \centering
% \caption{Comparison of model performance (in \%) on ROC and PR AUC under the supervised setting.}

To answer \textbf{RQ1}, we compare our {\method} with various existing methods in supervised cleavage site prediction, where annotations for training substrates are available. The compared methods include two specialized models, i.e., ScreenCap3 and CAT3, which are designed exclusively for C14.003. ProsperousPlus and Procleave are recent deep learning methods focusing a single enzyme-substrate system, thus are trained solely with the supervised benchmarks.  ReactZyme and ClipZyme are extensions of enzyme-substrate interaction models and utilize the same training data as {\method}. Notably, ClipZyme employs enzyme encoder weights that were pretrained on the enzyme-substrate reaction task. The results on the supervised benchmarks are given in the Tab.~\ref{Table:comparemodels}, where we observe:
\begin{itemize} [leftmargin=*]
    \item Methods focusing on a single enzyme generally show poor performance; whereas those trained on multiple enzymes achieve significantly better results. This highlights the advantage of developing a unified cleavage site predictor across diverse proteolytic enzymes.
    \item Compared with ClipZyme which adopts an enzyme encoder pretrained with the enzyme-substrate reaction task, the proposed {\method} achieves much better  performance. In implies the effectiveness of active-active information in enhancing the enzyme encoder.
    \item Our {\method} consistently outperforms the ReactZyme by a large margin. This is because of the deployment of biochemically-informed enzyme encoder and the active-site knowledge.
\end{itemize}
The ROC/PR curves are presented in Appendix~\ref{sec:app_exp}, which shows the similar observations.

% The comprehensive evaluation across three hydrolase families (C14.003, C14.005, M10.003) demonstrates UniZyme's consistent superiority in both ROC and PR AUC metrics. UniZyme achieves groundbreaking ROC AUC values of 0.9725 for C14.003 and 0.9620 for C14.005, surpassing ReactZyme by 4.3\% and ClipZyme by 4.2\% respectively. This performance dominance is most evident in the challenging M10.003 family, where UniZyme attains a 0.8702 ROC AUC – 6.8\% higher than ClipZyme. PR AUC analysis reinforces this advantage, with UniZyme outperforming baselines, particularly in low-prevalence scenarios (M10.003 PR AUC: 0.0729 vs ReactZyme's 0.0641). Traditional methods like Procleave show fundamental limitations (ROC AUC <0.73 across families), while modern architectures like ClipZyme and ReactZyme exhibit 7-12\% performance gaps compared to our framework. The minimal standard deviations (±<0.01 across metrics) confirm experimental stability, and the ROC/PR curve separation (Appendix ) visually validates UniZyme's enhanced discrimination capacity across all decision thresholds.













\begin{table}[h!]
\scriptsize
\centering
\caption{Cleavage site prediction in zero-shot setting.}
% \resizebox{0.95\linewidth}{!}
{
\begin{tabular}{llccc}
\toprule
Enzyme & Metric (\%) & ReactZyme & ClipZyme & UniZyme  \\
\midrule
% \multirow{2}{*}{M10.008}
% & ROC & 99.37$\pm$0.04 & 99.40$\pm$0.02 & \underline{99.43$\pm$0.04} \\
% & PR  & 56.12$\pm$1.20 &  \cellcolor{gray!20}{59.96$\pm$1.41} & \underline{66.68$\pm$1.37} \\

\multirow{2}{*}{M10.004}
& ROC-AUC &  \cellcolor{gray!20}{99.20$\pm$0.09} & 98.65$\pm$0.15 & \underline{\bf 99.43$\pm$0.06} \\
& PR-AUC   & \cellcolor{gray!20}{71.04$\pm$2.80} & 56.54$\pm$3.49 & \underline{\bf 82.82$\pm$1.77} \\
\midrule
\multirow{2}{*}{A01.009}
& ROC-AUC  & 98.59$\pm$0.03 & \cellcolor{gray!20}{98.92$\pm$0.03} & \underline{\bf 99.14$\pm$0.03}\\
& PR-AUC   & 18.06$\pm$0.31 & \cellcolor{gray!20}{25.24$\pm$0.58} & \underline{\bf 37.51$\pm$0.63} \\
\bottomrule
\end{tabular}
}
\label{tab:zeroshot}
\vskip -1em
\end{table}


\subsection{Cleavage Site Prediction for Zero-Shot Enzymes}
To answer \textbf{RQ2}, we evaluate the performance of {\method} on the zero-shot benchmarks, where enzymes are unseen during the training phase.
Since enzyme-specific models cannot handle new enzymes, we only compare {\method} to ReactZyme and ClipZyme, both of which can predict cleavage sites for novel enzymes. The results on the zero-shot benchmarks are given in Tab.~\ref{tab:zeroshot}. The ROC/PR curves can be found in Appendix~\ref{sec:app_exp}. From the table, we can observe that our {\method} consistently outperform the baseline methods. In particular, {\method} exceeds ReactZyme and ClipZyme by more than 10\% in PR-AUC across both enzyme families. This gap is much larger than that of supervised benchmarks. This improvement stems from the utilization of redundant active-site knowledge in the enzyme modeling, promoting the generalization ability of {\method} to unseen enzymes. 
% \begin{itemize}[leftmargin=*]
%     \item 
% \end{itemize}

% The zero-shot evaluation reveals nuanced performance patterns across held-out hydrolase families (Fig. \ref{fig:ablation zero-shot} , Table. \ref{tab:zeroshot} ). While UniZyme achieves exceptional ROC AUC (>0.99) across all families, its PR AUC in M10.008 (0.5612) underperforms ReactZyme (0.5996) and ClipZyme (0.6668). This apparent paradox stems from M10.008's limited hydrolysis data (73\% fewer samples than A01.009), which critically constrains the training efficacy of the structural-energy frustration module. The data scarcity manifests through two key mechanisms: (1) Distance-dependent energetic interactions require dense conformational sampling to establish robust correlations, a condition unmet in sparse datasets; (2) Insufficient positive examples impair the model's capacity to establish robust correlations in multi-scale structural-energy relationships (including both conformational preferences and energy frustration landscapes) , especially for rare substrate-enzyme interactions. The ablation studies corroborate this analysis: Removing structural-energy features (-S\&E) paradoxically improves M10.008 PR AUC to 0.6777, suggesting these features may capture dataset-specific noise when training data is scarce. Conversely, pretraining removal (-Pretrain) causes catastrophic PR AUC degradation (0.4823), highlighting its essential role in mitigating data scarcity through transfer learning. Strikingly, the full UniZyme model maintains superior performance in better-sampled families (M10.004 PR AUC: 0.8282 vs 0.7104 for ReactZyme), demonstrating our architecture's adaptive capacity to data availability.





% \begin{figure}[t!]
%     \small
%     \centering
%     \includegraphics[width=0.98 \linewidth]{figure/ablation_zeroshot.png}
%     \vskip -3 em
%     \vspace{2 em}
%     \caption{zeroshot, \enyan{ For the ablation in the main content, we can have two categories in }
%     \vskip -1 em
%     \label{fig:zeroshot}
% \end{figure}

% \begin{table}[ht]
% \centering
% \begin{tabular}{lcccccc}
% \toprule
% \textbf{Model} & \multicolumn{2}{c}{\textbf{M10.008}} & \multicolumn{2}{c}{\textbf{M10.004}} & \multicolumn{2}{c}{\textbf{A01.009}} \\
% \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
%  & \textbf{ROC} & \textbf{PR} & \textbf{ROC} & \textbf{PR} & \textbf{ROC} & \textbf{PR} \\
% \midrule
% \textbf{UniZyme} & 0.9937 ± 0.0004& 0.5612 ± 0.0120& 0.9943 ± 0.0006& 0.8282 ± 0.0177& 0.9914 ± 0.0003& 0.3751 ± 0.0063\\
% \textbf{ReactZyme} & 0.9940 ± 0.0002& 0.5996 ± 0.0141& 0.9920 ± 0.0009& 0.7104 ± 0.0280& 0.9859 ± 0.0003& 0.1806 ± 0.0031\\
% \textbf{ClipZyme} & 0.9943 ± 0.0004& 0.6668 ± 0.0137& 0.9865 ± 0.0015& 0.5654 ± 0.0349& 0.9892 ± 0.0003& 0.2524 ± 0.0058\\
%  \textbf{UniZyme -ALL}
% & 0.9946 ± 0.0004& 0.6276 ± 0.0140& 0.9911 ± 0.0011& 0.7529 ± 0.0249& 0.9891 ± 0.0004&0.3389 ± 0.0071\\
%  \textbf{UniZyme -S\&E}
% & 0.9955 ± 0.0003& 0.6777 ± 0.0158& 0.9940 ± 0.0009& 0.8168 ± 0.0174& 0.9892 ± 0.0004&0.3260 ± 0.0095\\
%  \textbf{UniZyme -Pretrain}
% & 0.9901 ± 0.0005& 0.4823 ± 0.0178& 0.9876 ± 0.0015& 0.6858 ± 0.0323& 0.9898 ± 0.0002&0.3364 ± 0.0050\\
%  \textbf{UniZyme -ActSites}& 0.9936 ± 0.0004& 0.6275 ± 0.0191& 0.9872 ± 0.0007& 0.6537 ± 0.0247& 0.9882 ± 0.0005&0.2864 ± 0.0063\\
% \end{tabular}
% \caption{Comparison of model performance on ROC and PR AUC for datasets M10.003, C14.005, and C14.003. \enyan{Chenao, UniZyme-ALL is the best in M10.008?}}
% \end{table}





% \begin{figure}[t]
%     \small
%     \centering
%     \includegraphics[width=0.98 \linewidth]{figure/ablation_testset.png}
%     \caption{Ablation studies.}
%     \vskip -1 em
%     \label{fig:ablation_testset}
% \end{figure}
% \begin{table*}[ht]
% \centering
% \begin{tabular}{lcccccc}
% \toprule
% \textbf{Model} & \multicolumn{2}{c}{\textbf{M10.003}} & \multicolumn{2}{c}{\textbf{C14.005}} & \multicolumn{2}{c}{\textbf{C14.003}} \\
% \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
%  & \textbf{ROC} & \textbf{PR} & \textbf{ROC} & \textbf{PR} & \textbf{ROC} & \textbf{PR} \\
% \midrule
% \textbf{UniZyme}& 0.8702 ± 0.0020& 0.0729 ± 0.0035& 0.9620 ± 0.0014& 0.5220 ± 0.0093& 0.9725 ± 0.0009& 0.4593 ± 0.0120\\
% \textbf{UniZyme -ALL}& 0.8340 ± 0.0018&  0.0592 ± 0.0014& 0.9240 ± 0.0024& 0.4517 ± 0.0138& 0.9308 ± 0.0019& 0.3457 ± 0.0110\\
% \textbf{UniZyme -S\&E}& 0.8210 ± 0.0030& 0.0611 ± 0.0024& 0.9437 ± 0.0027& 0.4873 ± 0.0107& 0.9479 ± 0.0015& 0.4488 ± 0.0122\\
% \textbf{UniZyme -Pretrain}& 0.8242 ± 0.0022& 0.0571 ± 0.0023& 0.9367 ± 0.0040& 0.4659 ± 0.0144& 0.9544 ± 0.0017& 0.4270 ± 0.0106\\
% \textbf{UniZyme -ActSites}& 0.8254 ± 0.0028& 0.0608 ± 0.0023& 0.9474 ± 0.0022& 0.4852 ± 0.0135& 0.9316 ± 0.0018& 0.3979 ± 0.0123\\
% \bottomrule
% \end{tabular}
% \caption{Ablation study on model performance with different components removed, evaluated on ROC and PR AUC for datasets M10.003, C14.005, and C14.003.}
% \end{table*}



 \begin{figure}[h]
    \small
    \centering
    \begin{subfigure}{0.49\linewidth}
        \includegraphics[width=0.8\linewidth]{figure/redwhite_P62157.png}
        \vskip -1em
        \caption{Protein Substrate P62157}
    \end{subfigure}
    \begin{subfigure}{0.49\linewidth}
        \includegraphics[width=0.7\linewidth]{figure/redwhite_P00698.png}
        \vskip -1em
        \caption{Protein Substrate P00698}
    \end{subfigure}
    \vskip -1em
    \caption{Visualizations of predicted substrate cleavage sites for HIV-1 enzymes. Predicted cleavage sites are in red color.  }
    % \enyan{for each setting, report two enzymes ROC or PR  using the figure. Also be careful about the figure color. Your current version is ugly.}}
    \vskip -1.5em
    \label{fig:HIV-1}
\end{figure}


\subsection{Exploring Substrates of HIV‑1 Enzymes}




% To further demonstrate the effectiveness of our model, we applied it to the task of identifying potential HIV-1 protease substrates and predicting their hydrolysis sites. In Fig. ~\ref{fig:HIV-1}, the red residues correspond to high probability hydrolysis sites. We present the model’s performance on an unseen HIV-1 protease (MER0019850) to a substrate P62157, demonstrating that our model can make accurate predictions even for new, previously unseen enzymes. The predicted hydrolysis sites on this unseen enzyme show a similar pattern to those observed in other HIV-1 proteases\cite{DAUBE1991892,https://doi.org/10.1002/prot.340100102}, further supporting the generalizability and robustness of our model for enzyme-substrate interaction tasks. Besides, our model successfully predicts the cleavage sites for a potential HIV-1 substrate (Uniprot: P00698), showing that it can be used to explore possible HIV-1 protease substrates and their hydrolysis products. This capability is crucial for the development of inhibitors and drugs targeting HIV-1 protease, as it allows for the identification of key hydrolysis sites and potential substrate interactions, providing valuable insights for therapeutic intervention.



To further demonstrate the generalization ability of our model on unseen enzymes, we applied it to identify potential HIV-1 enzyme substrates and predict their cleavage sites. In Fig.~\ref{fig:HIV-1}, the red residues correspond to high-probability cleavage sites. We present the model’s prediction on an unseen HIV-1 enzyme (MER0019850) acting on a substrate (P62157). This demonstrates that our {\method} can make accurate predictions even for new, previously unseen enzymes. The predicted cleavage sites on this unseen enzyme show a similar pattern to those observed in other HIV-1 enzymes~\cite{DAUBE1991892,https://doi.org/10.1002/prot.340100102}, further supporting the generalizability of our model for enzyme-substrate interaction tasks. Additionally, our model demonstrates the ability to analyze cleavage sites for any substrate protein interacting with HIV-1 enzymes. For example, as a random test case, our model successfully predicts the cleavage sites of a substrate protein (Uniprot: P00698). This result highlights the model’s capability to explore potential interactions between HIV-1 enzymes and various substrate proteins, providing valuable insights for therapeutic intervention and the development of inhibitors targeting HIV-1 enzymes.











% \begin{figure}[t!]
%     \small
%     \centering
%     \includegraphics[width=0.98 \linewidth]{figure/HIV-1.png}
%     \vskip -3 em
%     \vspace{2 em}
%     \caption{HIV‑1 \enyan{@Chenao, the color of sites are not that clear, can you revise the color? Also the table caption should be complete and clear.} }
%     \vskip -1 em
%     \label{fig:HIV‑1 }
% \end{figure}



%\enyan{@Shuo, can you help me revise the ablation studies following the format of my previous papers. Chenao emphasized too much on the numbers. Sometimes, we do need to mention this, but we actually need to demonstrate our motivation of the design is right. Also, @Chenao, I have renamed these variants, when you draw the figure, please take care of the new name.}

\begin{figure}[h]
\small
\centering
\begin{subfigure}{0.49\linewidth}
    \includegraphics[width=\linewidth]{figure/ablation_PR_testset.pdf}
    \vskip -0.5em
    \caption{Supervised}
\end{subfigure}
\begin{subfigure}{0.49\linewidth}
    \includegraphics[width=\linewidth]{figure/pr_zeroshot_ablation.pdf}
    \vskip -0.5em
    \caption{Zero-shot}
\end{subfigure}
\vskip -0.5em
\caption{Ablation studies on supervised and zero-shot settings.}
\vskip -0.5em
\label{fig:ablation zero-shot}
\end{figure}


\subsection{Ablation Studies}
To answer \textbf{RQ3}, we conduct an ablation study to understand the contributions of biochemically-informed enzyme encoder and the active-site knowledge. To demonstrate the effectiveness of the biochemically-informed enzyme encoder, we remove energy frustration and 3D structure, resulting in a variant named \textbf{ UniZyme$\backslash$SE}. To show the benefits brought by pretraining on general enzymes with active site prediction, we trained a variant, \textbf{UniZyme$\backslash$P}, which excludes the enzyme pretraining phase. To further demonstrate the enhancement of active-site knowledge to the model, we remove the active site prediction in the pretraining/training phase. Additionally, the active site-aware pooling is replaced with average pooling, resulting in a variant named \textbf{UniZyme$\backslash$A}. Fig.  \ref{fig:ablation zero-shot} show the PR-AUC scores across different enzyme families in both zero-shot and supervised settings. More details can be found in the Tab.~\ref{tab:ablation_study} From these results, we observe:
\begin{itemize}[leftmargin=*]
    \item {UniZyme} consistently achieves better results than UniZyme$\backslash$SE, which indicates that structural-energy features in the biochemically-informed enzyme encoder enable stronger generalization and performance.
    \item {UniZyme$\backslash$P} performs worse than {UniZyme}, especially on smaller datasets like M10.003. This verifies that pretraining on a supplemented enzyme set produces a more transferable enzyme encoder for cleavage site prediction.
    \item {\method} outperforms {UniZyme$\backslash$A} by a large margin. This demonstrates that the active-site knowledge can enhance the enzyme-catalyzed cleavage site prediction. 
\end{itemize}

%\textbf{UniZyme$\backslash$SE} A variant that removes the dual-channel attention mechanism for energy frustration and structural features. This configuration isolates the effects of structure and energy.

%\textbf{UniZyme$\backslash$A} The Activate-Site knowledge ablation variant, where catalytic site-informed pooling is disabled,  was trained without the large-scale enzyme pretraining phase, and its optimization objective excluded the active site loss, testing the necessity of explicit active site modeling. 

%\textbf{UniZyme$\backslash$P} A pretraining-free variant initialized with random weights, excluding the large-scale enzyme pretraining phase. This setup evaluates the contribution of transfer learning from general enzyme patterns.

% \textbf{UniZyme\textsubscript{ALL}} The minimal baseline configuration, 
% removing both structure/energy information and active-site knowledge. This serves as our lower-bound reference for ablation comparisons. \enyan{I feel it is unnecessary to have this model.}

%The systematic ablation analysis (Fig. , Table ) reveals critical insights into our architecture's functional components. Three key patterns emerge:  

%\textbf{Structural-Energy Module for Complex Substrates}: Removing structural-energy features alone (-S\&E) reduces C14.005 ROC AUC by 1.9\% (0.9620 → 0.9437), while its combined removal with active site knowledge (-S\&E+Act) amplifies this degradation to 4.3\% (0.9620 → 0.9240). This demonstrates the module's dual role: directly modeling conformational preferences and synergizing with active site information.  

%\textbf{Pretraining for Data Efficiency}: The -Pretrain variant suffers severe PR AUC declines in low-data regimes (M10.003: 0.0729 → 0.0571, -21.6\%), where training data is 30\% sparser than C14.005, significantly exceeding its ROC AUC loss (-5.3\%). This performance gap highlights pretraining's critical role in compensating for data scarcity through transferable representations of rare interaction patterns.

%\textbf{Active Site Knowledge Drives Precision}: Disabling catalytic site pooling (-ActSites) disproportionately impacts PR metrics (C14.003: 0.4593 → 0.3979, -13.4\%) with minimal ROC changes (<0.5\%), validating its role in substrate positioning accuracy.  

%The paradoxical 2.9\% PR improvement in M10.003 when removing structural-energy features (-S\&E) reinforces our zero-shot findings – these high-dimensional descriptors require minimum data thresholds to avoid noise amplification. Collectively, these results establish:  
%\begin{itemize}
%    \item Structural-energy modeling enables robust handling of complex substrates
%    \item Pretraining compensates for data scarcity through transferable representations
%    \item Active site knowledge is indispensable for precise interaction mapping
%\end{itemize}


% \begin{figure}[t]
%     \small
%     \centering
%     \begin{subfigure}{0.49\linewidth}
%         \includegraphics[width=\linewidth]{figure/ablation_ROC_testset.png}
%         \vskip -0.5em
%         \caption{ROC}
%     \end{subfigure}
%     \begin{subfigure}{0.49\linewidth}
%         \includegraphics[width=\linewidth]{figure/ablation_PR_testset.png}
%         \vskip -0.5em
%         \caption{PR}
%     \end{subfigure}
%     \vskip -0.5em
%     \caption{Ablation studies on supervised enzymes.}
%     \vskip -0.5em
%     \label{fig:ablation supervised}
% \end{figure}





% \enyan{for each setting, report two enzymes ROC or PR  using the figure. Also be careful about the figure color. Your current version is ugly.}

\begin{figure}[h]
    \small
    \centering
    \begin{subfigure}{0.49\linewidth}
        \includegraphics[width=\linewidth]{figure/hyperparamROC.pdf}
        \vskip -0.5em
        \caption{ROC-AUC}
    \end{subfigure}
    \begin{subfigure}{0.49\linewidth}
        \includegraphics[width=\linewidth]{figure/hyperparamPR.pdf}
        \vskip -0.5em
        \caption{PR-AUC}
    \end{subfigure}
    \vskip -1em
    \caption{Hyperparameter sensitivity analysis.}
    \vskip -0.2em
    \label{fig:Hyperparam}
\end{figure}


\subsection{Hyperparameter Analysis}




In this subsection, we investigate how the hyperparameter $\lambda$ affects the {\method}. $\lambda$ controls to contribution of active site prediction loss to the training of {\method}. To explore the hyperparameter analysis, we vary $\lambda$ as \{100, 10, 1, 0.1, 0.01\} in the training phase of {\method}. Due to the expensive computational cost in training on the full dataset $\mathcal{D}_c$, we conduct the hyperparameter analysis with 3\% of training data in various enzyme families. Performance on these enzymes are given in Fig.~\ref{fig:Hyperparam}. We can find that while \(\lambda=100\) produces competitive ROC-AUC results, it leads to suboptimal PR-AUC. Small values like 0.1 and 0.01 cause a noticeable drop in ROC AUC (e.g. M10.003). Among the tested values, \(\lambda=10\) demonstrates the most consistent performance, achieving strong PR-AUC (e.g., M10.004) while maintaining competitive ROC AUC across datasets such as C14.003 and A01.009. Thus, we selected \(\lambda=10\) as the optimal choice for final training.





% \enyan{@Chenao, this should be shown in line chart. Also, can your show the results of multiple enzymes in one line chart? Then, we will have two line charts, one for ROC-AUC and other for PR AUC. Also the current color is very ugly. Generally, if you are using the default color platte of matplotlib, it should be very nice. See figure 3 and figure 4 in https://arxiv.org/pdf/2303.01263 as reference. The code is given in our academic writing channel.}
% To determine the optimal weight for the regularization term in our loss function, we conducted a series of experiments with different hyperparameter values ($\lambda = 100, 10, 1, 0.1, 0.01$). Due to the large size of the training set and the associated computational cost, we initially evaluated model performance on a smaller subset of data. We maintained the same experimental settings as described earlier, training and testing the model on the six benchmark datasets mentioned in 4.2. The overall performance was measured using both ROC AUC and PR AUC, as shown in Figure . Based on the results, $\lambda = 10$ achieved the best balance between ROC AUC (0.9893) and PR AUC (0.5319), demonstrating superior performance compared to other weight values. This configuration was subsequently used for the final model training on the full dataset.
