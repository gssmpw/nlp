\documentclass[sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style 

%%%% Standard Packages
\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%%%%

%%%% Additional Packages
\usepackage[nolist]{acronym}
\usepackage{tikz}
\usetikzlibrary{shapes,decorations,arrows,calc,arrows.meta,fit,positioning}
\tikzset{
    -Latex,auto,node distance =1 cm and 1 cm,semithick,
    state/.style ={circle, draw, minimum width = 0.7 cm},
}
\usepackage{svg}
\usepackage{caption}
\usepackage{subcaption}
\captionsetup[table]{position=top}

% for scientific numbers i.e. 1e-3
\usepackage{siunitx}
\sisetup{output-exponent-marker=\ensuremath{\mathrm{e}}}

% for github link
%\usepackage{hyperref}

\raggedbottom

%%% Define any new commands you require here.

%% Self-defined macros

\newcommand{\domain}{\mathcal{D}} % Domain
\newcommand{\loss}{\mathcal{L}} % Loss
\newcommand{\inputspace}{\mathcal{X}} % Input space
\newcommand{\outputspace}{\mathcal{Y}} % Output space
\newcommand{\jointdistribution}{P} % Joint Distribution of Random Variable X
\def\*#1{\mathbf{#1}} % note: this seems to overwrite sth!
\newcommand{\invpairs}{\mathcal{I}} % Set of invariant input pairs
\newcommand{\invpairsbatch}{\mathbf{I}} % Set of invariant input pairs
\newcommand{\R}{\*{R}} % Mean rationale of input set 
\newcommand{\Rmean}{\mathbf{\overline{R}}} % Mean rationale of input set $S$
\newcommand{\invpred}{\tilde{\textbf{y}}}
\newcommand{\RDist}{d(\invpairsbatch)}
\newcommand{\corrGrad}{\*g_d}
\newcommand{\lossGrad}{\*g_\loss}
\newcommand{\invcond}{c(\invpairsbatch)}
\newcommand{\stepSize}{\alpha}
\newcommand{\modelParameters}{\mathbf{\theta}}
\newcommand{\optim}{\sigma}

\begin{acronym}
    \acro{HMM}{Human Mental Model}
    \acro{ERM}{Empirical Risk Minimization}
    \acro{i.i.d.}{independent and identically distributed}
    \acro{IRM}{Invariant Risk Minimization}
    \acro{XAI}{Explainable AI}
    \acro{CCE}{Counterfactual Concept Explanations}
    \acro{EPG}{Energy-based Pointing Game}
\end{acronym}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Use this command to specify the title of your paper.
\title{
    Invariance Pair-Guided Learning: Enhancing Robustness in Neural Networks
}

\author*[1,2]{\fnm{Martin} \sur{Surner}}\email{Martin.Surner@haw-landshut.de}

\author[1,2]{\fnm{Abdelmajid} \sur{Khelil}}\email{Abdelmajid.Khelil@haw-landshut.de}

\author[3,4]{\fnm{Ludwig} \sur{Bothmann}}\email{Ludwig.Bothmann@lmu.de}

\affil*[1]{\orgdiv{Institute for Data and Process Science}, \orgname{Landshut University of Applied Sciences}, \orgaddress{\street{Am Lurzenhof 1}, \city{Landshut}, \postcode{84036}, \state{Bavaria}, \country{Germany}}}

\affil[2]{\orgdiv{Computer Science Department}, \orgname{Landshut University of Applied Sciences}, \orgaddress{\street{Am Lurzenhof 1}, \city{Landshut}, \postcode{84036}, \state{Bavaria}, \country{Germany}}}

\affil[3]{\orgdiv{Department of Statistics}, \orgname{LMU Munich}, \orgaddress{\street{Ludwigstra√üe 33}, \city{80539 Munich}, \country{Germany}}}
\affil[4]{\orgdiv{Munich
Center for Machine Learning (MCML)}, \orgaddress{\city{Munich}, \country{Germany}}}

\abstract{
Out-of-distribution generalization of machine learning models remains challenging since the models are inherently bound to the training data distribution. 
This especially manifests, when the learned models rely on spurious correlations. 
Most of the existing approaches apply data manipulation, representation learning, or learning strategies to achieve generalizable models. 
Unfortunately, these approaches usually require multiple training domains, group labels, specialized augmentation, or pre-processing to reach generalizable models. 
We propose a novel approach that addresses these limitations by providing a technique to guide the neural network through the training phase. 
We first establish input pairs, representing the spurious attribute and describing the invariance, a characteristic that should not affect the outcome of the model. 
Based on these pairs, we form a corrective gradient complementing the traditional gradient descent approach. 
We further make this correction mechanism adaptive based on a predefined invariance condition. 
Experiments on ColoredMNIST, Waterbird-100, and CelebA datasets demonstrate the effectiveness of our approach and the robustness to group shifts.
}
\keywords{Machine Learning, Robustness, Domain Generalization, Gradient Operation, Spurious Correlations, Representation Learning, Out-of-distribution Generalization}


\maketitle

\section{Introduction}
\label{sec:introduction}
he ability to learn representations from data makes neural networks highly applicable to various tasks.
However, models are inherently limited by the distribution of the training data. 
In training machine learning models, we usually assume that training data and test data are \ac{i.i.d.} samples from the same data-generating process, yet this assumption often does not hold in real-world scenarios. 
For instance, in autonomous driving, it is impractical and almost impossible to ensure that the input data strictly satisfies the \ac{i.i.d.} assumption, as unknown situations may arise \cite{kohli_enabling_2020}.
In such scenarios, it is essential that models generalize well to unseen data by being independent of biased features.
Thus, it is important to develop methods that support generalization to unseen distributions (out-of-distribution generalization) \cite{wang_generalizing_2023}.

\begin{figure}
    \centering
    \begin{minipage}[b][][b]{0.705\textwidth}
        \begin{subfigure}[b]{\textwidth}
         \includegraphics[width=\textwidth]{fig/schematic_overview.pdf}
        \caption{}
        \label{fig:grad_corr}
        \end{subfigure}
    \end{minipage}
    \hfill
    \begin{minipage}[b][][b]{0.285\textwidth}%
        \vspace{0.285cm}%
        \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{fig/cmnist-1.png}
            \caption{}
            \label{fig:colored_mnist_invariance_pair}
        \end{subfigure}%
        
        \vspace{0.1cm}%
        
        \begin{subfigure}[b]{\textwidth}%
            \includegraphics[width=\textwidth]{fig/waterbird_1.png}%
            \caption{}%
            \label{fig:waterbird_invariance_pair}
        \end{subfigure}%
        %
        \vspace{0.1cm}%
        
        \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{fig/celeba_1.png}
            \caption{}
            \label{fig:celeba_invariance_pair}
        \end{subfigure}
    \end{minipage}
    \caption{
        Schematic visualization (a) of our optimization approach. 
        The first two loss gradients are scaled to two-thirds the length of the corrective gradient due to the violation of the invariance condition.
        Invariance pairs for (b) ColoredMNIST, (c) Waterbird-100, and (d) CelebA are used for the invariance condition and corrective gradient formulation.
    }
    \label{fig:comparison}
\end{figure}

To effectively generalize to unseen domains or distributions, models should maintain consistent representations across all training environments \cite{ben-david_analysis_2006}. 
Maintaining consistent representations involves identifying and internalizing consistent characteristics from the available sources.
Inconsistent characteristics that should not affect the predicted label (such as the color in ColoredMNIST, see Fig.~\ref{fig:colored_mnist_invariance_pair}), should have no impact on the learned representation. 
However, if these inconsistent characteristics are poorly represented in the training data, the model may rely on them, if not prevented from doing so \cite{wimmer_trust_2025}. 
Examples of models relying on such characteristics, resulting in poor performance, include animal detection in unfamiliar environments \cite{beery_recognition_2018, bothmann_automated_2023}, 
COVID-19 detection on radiographic images when changing the hospital \cite{degrave_ai_2021}, 
and the substantial accuracy disparities in gender classification for minority groups, especially regarding skin color \cite{buolamwini_gender_2018}. 

To mitigate such risks, we aim at separating consistent characteristics that define a class from spurious attributes, which are only correlated with the class label in the training data but do not define the class.
Inspired by contrastive approaches \cite{le-khac_contrastive_2020}, we define ``invariance pairs'' as pairs of data points that differ in a single characteristic -- e.g., the color -- while belonging to the same class -- e.g., the digit.
Note that the term invariance is sometimes used differently in the field of domain generalization. 
We denote by invariance the transformations, such as a color change in ColoredMNIST, that do not influence the class (Fig.~\ref{fig:colored_mnist_invariance_pair}).
This notion is in contrast to domain-invariance, which refers to the characteristics of a domain (and typically not a class).
%
We utilize these data pairs to define the desired invariance.
The pairs enable us to assess the extent to which the model learned the invariance.
If the output of the model varies for such pairs, the model suffers from inconsistency in the representations.
The model is considered to have incorporated the invariance when its output remains identical for both elements of the pair.

Although the selection and creation of pairs requires manual effort, \ac{XAI} techniques can assist in identifying candidates. 
To identify spurious correlations, misclassified samples can be analyzed.
\ac{XAI} methods enable the discovery of counterfactual explanations, i.e., instances that are semantically similar but receive different classifications \cite{wachter_counterfactual_2017, dandl_multi-objective_2020}. 
Specific techniques exist to generate counterfactual explanations in images \cite{goyal_counterfactual_2019}, as well as more advanced \ac{CCE} \cite{abid_meaningfully_2022}. 
The user can apply these methods and compare the model‚Äôs learned concepts with their mental model and identify spuriously correlated features. 
Such pairs can expose attributes like skin color \cite{buolamwini_gender_2018}, animal photo backgrounds \cite{beery_recognition_2018, sagawa_distributionally_2020}, or orientation in radiographs \cite{degrave_ai_2021}. 
The process helps reveal misconceptions internalized by the model, which are used to derive invariance pairs for our method.

In this work, we introduce \underline{I}nvariance \underline{P}air-\underline{G}uided learning (IPG) that incorporates the invariances during training.\footnote{
%Code will be available at GitHub.
Our code will be made available upon publication.
}
In order to guide the neural network, we extend the standard gradient descent-based approach with an additional corrective step, the corrective gradient inspired by van Baelen \cite{van_baelen_constraint_2022}. 
The corrective gradient is specified by pairs of input data, the invariance pairs, which define the desired invariance properties of the model. 
Furthermore, adaptive scaling preserves the corrective effect depending on the extent of invariance internalized by the model.
The adaptation is realized by the invariance pairs and an invariance condition, which we introduce, to converge to a generalizable representation.
%
We examine out-of-distribution generalization and robustness of models trained with IPG on three datasets: ColoredMNIST, Waterbird-100, and CelebA. 
The datasets represent scenarios with strong, including perfect, spurious correlations, either synthetically generated or naturally occurring in real-world data.
%
Fig.~\ref{fig:grad_corr} illustrates how the described corrective gradient helps to avoid a region that violates the invariance condition without any gradient momentum. 
%
Our key contributions consist in:
\begin{itemize}
    \item A novel corrective gradient method (IPG) using invariance pairs with adaptive scaling via an invariance condition to improve out-of-distribution generalization.
    \item An invariance pair generation approach that extends IPG, i.e., IPG with adversarial augmentation (IPG-AA).
\end{itemize}

The remainder of the paper is structured as follows. 
Section~\ref{sec:related_work} discusses related work. 
In Section~\ref{sec:methodology}, we present IPG and IPG-AA.
Section~\ref{sec:experiments} evaluates the performance, 
Section~\ref{sec:conclusion} concludes. 

\section{Related Work}
\label{sec:related_work}
%
The generalization of machine learning models to unseen distributions has been studied in the fields of robustness \cite{sagawa_distributionally_2020}, domain generalization \cite{wang_generalizing_2023}, spurious correlations in machine learning \cite{ye_spurious_2024, steinmann_navigating_2024}, and causality \cite{ye_spurious_2024}.
We categorize related methods into data manipulation, representation learning, and learning strategies, similar to \cite{wang_generalizing_2023, ye_spurious_2024}.
Our approach integrates representation learning with an adaptive learning strategy.

\textbf{Data manipulation} addresses the problem by either augmenting existing data, generating new data, or adding further information about the underlying concepts. 
The goal of data augmentation and data generation approaches is to expand the dataset so that the training distribution(s) and the target distribution(s) are closer.
For instance, Wang~\cite{wang_learning_2021} implements augmentation techniques to vary image style, while Prakash~\cite{prakash_structured_2019} embodies synthetic data augmentation to enrich the dataset.
Along domain randomization, another method applied in \cite{yue_domain_2019, prakash_structured_2019}, adversarial augmentation \cite{huang_robustness_2023, von_kugelgen_self-supervised_2021, puli_nuisances_2024} is a technique to improve model robustness.
%
Among the adversarial augmentation methods, the DAIR approach reports high performance on ColoredMNIST.
The DAIR approach applies regularization based on adversarial augmentation to achieve consistency \cite{huang_robustness_2023}.
%
Further, a small group of techniques instead aims to provide information about the underlying concepts. 
For example, methods that complement the estimation with the use of pseudo-labels \cite{nam_spread_2022, srivastava_robustness_2020} or concept banks \cite{wu_discover_2023, koh_concept_2020}.
In addition, a mixup-based technique \cite{yao_improving_2022} utilizes class and domain (or group) labels to generate inputs. 
%
In Section~\ref{sec:accuracy_comparison}, we compare our IPG approach with DAIR. Hereby, we consider two variants of IPG: (a) IPG using adversarial augmentation, and (b) IPG incorporating invariance pairs. 
In both cases, IPG shows comparable results. 
Replacing specialized augmentation techniques with invariance pairs improves data efficiency, without needing extra labels for spurious attributes as contained in concept banks.

\textbf{Representation learning} involves feature disentanglement or domain-invariant representation learning.
Domain-invariant representation learning uses techniques such as explicit feature alignment \cite{jin_style_2022, fan_adversarially_2021, chen_domain_2023}, domain adversarial learning \cite{luo_scale_2021, matsuura_domain_2020}, or \ac{IRM} \cite{arjovsky_invariant_2019}. 
The main intuition of \ac{IRM} is to enforce an optimal classifier across all training environments.
IRM is particularly interesting when faced with strong spurious correlations, such as those observed in the ColoredMNIST dataset \cite{arjovsky_invariant_2019}.
Further approaches promoting domain-invariant feature learning are EIIL \cite{creager_environment_2021} and also SFB \cite{eastwood_spuriosity_2023}, which use test-time adaptation.
In addition, feature disentanglement is another representation learning strategy that aims to separate spurious and general representations within the latent space.
%
Rao \cite{rao_studying_2023} examines an 
explanation-guided learning approach, which we refer to as EGL.
The approach uses a bounding box to formulate a regularization term in the form of an energy pointing game penalizing the attribution of pixels outside the bounding box, i.e., in the background.
EGL applies different \ac{XAI} methods to calculate the attribution: B-cos \cite{bohle_b-cos_2022}, $\mathcal{X}$-DNN \cite{hesse_fast_2021}, and IxG \cite{shrikumar_learning_2017}.
Similarly, GALS \cite{petryk_guiding_2022} applies language-guided learning.
GALS uses text encodings of an additional text input to also regularize on the attribution of the model.
Both approaches are applicable in the presence of perfect spurious correlation. 
%
Our approach is founded on the notion of invariance and aims to learn generalizable models by encoding invariance information in the training process.
We evaluate our method against IRM-based approaches on the ColoredMNIST dataset and compare it with GALS and EGL on the Waterbird-100 dataset, which has a perfect spurious correlation in the training set.
Other representation learning methods are excluded from the comparison as they require multiple training domains or depend on the availability of bias-conflicting groups.
%
We test IPG in these scenarios in Sections \ref{sec:accuracy_comparison} and \ref{sec:latent_representation_analysis}.

\textbf{Learning strategies} can be adopted to achieve robustness and domain generalization. 
These strategies include ensemble learning \cite{wu_collaborative_2021, nam_learning_2020}, meta-learning \cite{zhao_learning_2021, qiao_uncertainty-guided_2021}, optimization-based methods \cite{sagawa_distributionally_2020}, and self-supervised learning \cite{kim_selfreg_2021, carlucci_domain_2019}.
Additionally, gradient operation methods \cite{shi_gradient_2022, tian_neuron_2023}, among others, have gained prominence. 
One approach is Shock Graph, which transforms images into shock graphs representing the shape content, thus ignoring color- and texture-based features and associated spurious correlations \cite{narayanan_shape-biased_2021}.
%
Further, self-supervised learning and gradient operation methods can encode invariances during training. 
Some approaches use contrastive input pairs to promote domain-invariance by pairing similar classes across different domains as positive pairs, and dissimilar classes as negative pairs \cite{kim_selfreg_2021, jeon_feature_2021}.
Another line of research adopts an "Identification then Mitigation" strategy to address spurious correlations.
Examples include JTT~\cite{liu_just_2021} or LfF~\cite{nam_learning_2020}.
JTT identifies misclassified samples, typically bias-conflicting, and up-weights them during a second training phase.
Similarly, LfF trains an intentionally biased model to up-weight minority samples when training a second model.
Moreover, GroupDRO offers an optimization-based strategy that focuses on minimizing the loss of the worst-performing group \cite{sagawa_distributionally_2020}.
Additionally, Shi~\cite{shi_gradient_2022} proposed a gradient matching scheme for domain generalization by maximizing the inner products of gradients across different domains, aligning gradient directions to promote consistency.
%
Several methods also aim for domain-invariant gradients.
One approach regularizes gradients to maintain similarity between original and augmented samples \cite{tian_neuron_2023}. 
Fishr \cite{rame_fishr_2022} applies covariance-based gradient matching across domains, as proposed by Sun \cite{sun_return_2016}, to achieve invariant gradients.
Methods targeting domain-invariant gradients have shown strong performance on datasets like ColoredMNIST, suggesting their effectiveness when faced with strong spurious correlations. 
In Section~\ref{sec:accuracy_comparison}, we compare our IPG approach with Fishr, JTT, LfF, GroupDRO, and Shock Graph.
IPG's invariance pair formulation does not rely on the support of bias-conflicting groups. 
Furthermore, its invariance definition goes beyond color- and texture-based information, overcoming the limitations of approaches like Shock Graph.

\section{IPG: Invariance Pair-Guided Learning} 
\label{sec:methodology}
In this section, we describe our approach to formulating the invariance pairs, the corrective gradient, and the adaptive scaling by the invariance condition.

\subsection{Preliminaries and Overview}
A training set $\mathcal{D}_{tr} := \{(\*x_j, y_j)\}^n_{j=1}$ consists of input samples $\*x_j \in \inputspace$ and labels $y_j \in \mathcal{Y}$ of $K$ classes that are distributed according to the joint distribution $P_{\mathcal{D}_{tr}}$.
For each data point $\*x_j$ with class label $y_j$, there is a spurious attribute $a_j$, where $a_j$ is non-predictive of $y_j$. 
Let $\mathcal{A}$ denote the set of all possible spurious attributes.
We define a combination of values of $a$ and $y$ as a group $g := (a, y) \in \mathcal{A} \times \mathcal{Y}$. 
In $\mathcal{D}_{tr}$, groups are typically imbalanced, so that the co-occurrence of values of $a$ and values of $y$ induces a spurious correlation, denoted as $\langle a,y \rangle$.
In extreme cases, which we also consider, a group is completely missing in $\mathcal{D}_{tr}$, resulting in a perfect spurious correlation.
A test set $\mathcal{D}_{te}$ shows a different correlation of  $a$ and $y$, typically by a reduction or inversion of the correlation. 
Therefore, the distributions differ $P_{\mathcal{D}_{tr}} \neq P_{\mathcal{D}_{te}}$. 
Let $P_{\mathcal{D}_{te}^g }$ denote the distribution of the test samples of group $g$. 
Our goal is to learn a generalizable model $f_\theta$ independent of $\langle a,y \rangle$ resulting in comparable performance in each group and, accordingly group robustness.
Therefore, we investigate the worst-group accuracy $\text{Acc}_{wg}(f_\theta)$ \cite{idrissi_simple_2022}, defined as the minimum accuracy across groups of test samples:

\begin{equation*}
    \text{Acc}_{wg}(f_\theta) := \min_{g \in \mathcal{A} \times \mathcal{Y}} \mathbb{E}_{(x,y) \sim P_{\mathcal{D}_{te}^g }}[\mathbf{1}_{y = f_\theta(x)}].
\end{equation*}

Our method extends the stochastic mini-batch gradient descent method \cite{dekel_optimal_2012} by incorporating the following key components.
First, we introduce a set of invariance pairs, denoted $\invpairs$, describing the invariance that the model should respect. 
Utilizing $\invpairs$ and batches $\invpairsbatch$ sampled from $\invpairs$, we derive a corrective gradient, referred to as $\*g_d$, that is applied before each gradient step. 
Finally, we use an invariance condition $\invcond$ to adaptively scale the loss gradient.
An overview is given in Fig.~\ref{fig:system_model}.
We detail each of those components in the following.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=.5\linewidth]{fig/system_model.pdf}
    \caption{
    Schematic overview of the IPG training method (dotted) as an extension to the traditional approach using the example of ColoredMNIST.
    }
    \label{fig:system_model}
\end{figure}

\subsection{Rationale and Invariance Pair Definition}
To compare the learned characteristics and formulate a corrective gradient $\corrGrad$, we use a form of latent representation, a rationale matrix.
The rationale, as proposed by Chen \cite{chen_domain_2023}, represents the concepts learned by the model.
To this end, a neural network used for classification is divided into two parts. 
First, we have the feature extractor $f$, consisting of the first up to the last hidden layer, which maps inputs $\*x$ to features $\*z := f(\*x)$.
Second, the classifier $h$ maps $\*z$ to logits $\*o$, defined as $\*o := h(\*z)$.
The rationale $\*R$ connects $\*z$ and the weights of $h$.
The matrix $\*R$ represents the concepts that the neural network has learned from the training data in an accessible way \cite{chen_domain_2023}.
Specifically, we define the rationale as a matrix consisting of the products of the weights $\*W_{i,j}$ of $h$ and their corresponding feature $z_i$: 
\begin{equation*}
    \R := \begin{bmatrix}
    \mathbf{W}_{\{1, 1\}} z_1 &\mathbf{W}_{\{1, 2\}} z_1  &\dots &\mathbf{W}_{\{1, K\}} z_1 \\
    \mathbf{W}_{\{2, 1\}} z_2 &\mathbf{W}_{\{2, 2\}} z_2 &\dots &\mathbf{W}_{\{2, K\}} z_2 \\
    \vdots &\vdots & \ddots &\vdots \\
    \mathbf{W}_{\{D, 1\}} z_D &\mathbf{W}_{\{D, 2\}} z_D  &\dots&\mathbf{W}_{\{D, K\}} z_D \\
    \end{bmatrix} . 
\end{equation*}
We use the subscripts to indicate that $\R_{\*x}$ was generated by inference on the input $\*x$.
The number of the features $D$ and the number of the classes $K$ determine the shape of the matrix $\R \in \mathbb{R}^{D\times K}$.
The outputs of the neural network $\mathbf{\hat{y}}$ are defined by applying the softmax function to the logits, $\mathbf{\hat{y}} := softmax(\*o)$.
We select $\*R$ for our method because it is fine-grained and incorporates the weights of the final layer.
We use the rationale matrix to compare the learned characteristics of the input to guide the model during the training process.

To identify undesired learned concepts, we contrast rationale matrices derived from invariant input pairs.
We use a set $\invpairs$ of invariant pairs $(\*x_1, \*x_2) \in \invpairs$ to define a specific invariance.
Each pair $(\*x_1, \*x_2)$ consists of elements contrasting a difference that should be invariant to the final classification. 
Although $\*x_1$ and $\*x_2$ are different, the defined characteristic should not affect the classification result. 
For example, the ColoredMNIST dataset consists of colored digits, with color serving as the spurious attribute. 
Therefore, $\*x_1$ and $\*x_2$ represent the same digit in different colors (Fig.~\ref{fig:colored_mnist_invariance_pair}).
These input pairs are either generated by augmentation or manually selected, e.g., based on \ac{CCE} \cite{abid_meaningfully_2022}.
Multiple pairs are used to describe one invariance.
In each training step, we randomly sample a batch of invariance pairs $\invpairsbatch$ from $\invpairs$ with replacement using the same batch size as for the training data.
We refer to the set of all the first elements of the invariance pairs as $\invpairs_1$ and all second elements as $\invpairs_2$.
Similarly, we apply the notation for $\invpairsbatch_1$ and $\invpairsbatch_2$.
These pairs define the invariance that the model should internalize during the learning process based on rationales. 

We also consider IPG with adversarial augmentation (IPG-AA), which replaces $\invpairsbatch$ with pairs generated for the current data batch.
Specifically, for each input batch, we generate a corresponding set of $\invpairsbatch$ based on the input batch.
The set $\invpairsbatch$ is generated following the original methodology, except that $\invpairsbatch$ is updated for each step.

\subsection{Corrective Gradient and Invariance Condition}
We combine the rationales of the invariance pairs to formulate a distance measure. 
With this measure, we quantify the level of internalization of the specified invariance.
As we have multiple pairs describing one invariance, we have multiple rationales for each element in those pairs.
In order to achieve one representation of the rationales for $\invpairsbatch_1$, we calculate a mean rationale: 
\begin{equation*}
    \Rmean_1 := \frac{1}{|\invpairsbatch_1|}\sum_{\*x \in \invpairsbatch_1} \R_{\*x} .
\end{equation*}
In this mean rationale $\Rmean_1$, shared concepts in all data points in $\invpairsbatch_1$ are aggregated, whereby rationales that are only local in data points vanish.
We calculate $\Rmean_2$ analogously.
Note that we expect ordered pairs such that the elements in $\invpairsbatch_1$ share the same characteristic, which should be invariant to the shared characteristic of the elements in $\invpairsbatch_2$.
For example, in the case of ColoredMNIST, all elements in $\invpairsbatch_1$ are red, while all elements in $\invpairsbatch_2$ are green.
Since pairs are invariant by definition, $\Rmean_1$ and $\Rmean_2$ should be similar to encode this invariance.
To verify the learning of this invariance, we formulate a distance measure:
\begin{equation*}
    d(\invpairsbatch) := ||\Rmean_1 - \Rmean_2 ||_2.
\end{equation*}
The distance $\RDist$ is induced by the spectral norm.
Therefore, $\RDist$ refers to the largest singular value of the difference in mean rationales, capturing the most prominent characteristic.
Based on the distance in rationales, we can encode the invariance.

To guide the neural network towards robust representations during the training process, we use the distance measure $\RDist$ to incorporate the invariance information.
To this end, we extend the mini-batch gradient descent by introducing a two-step update mechanism.
As a first step, we perform a correction step based on the instances in $\invpairsbatch$.
We update the weights $\modelParameters$ of the model according to the gradient of the rationale distance $\corrGrad := \nabla_\modelParameters\RDist$ using a weight update function $\optim$. 
The step $\corrGrad$ aims to minimize the distance between different elements in $\invpairsbatch$.
%
As a second step, we update the weights $\modelParameters$ of the model based on $\nabla_\modelParameters \loss$. 
However, the compatibility of both updates must be maintained to preserve a corrective effect of $\corrGrad$. 
For this reason, $\nabla_\modelParameters \loss$ is scaled adaptively.
We scale according to length of the gradient measured by the Euclidean norm or $\ell_2$ norm.
The length of $\nabla_\modelParameters \loss$ is adjusted based on an invariance condition and the length of $\corrGrad$.
To this end, we introduce an invariance condition by a symmetric version of the Kullback-Leibler (KL) divergence between the model outputs $\invpred_1$ and $\invpred_2$ of $\invpairsbatch_1$ and $\invpairsbatch_2$, respectively:
\begin{equation*}
    \invcond := \frac{1}{2}\big(KL(\invpred_1 || \invpred_2) + KL(\invpred_2 || \invpred_1)\big).
\end{equation*}
A violation occurs when $c(\invpairsbatch)$ exceeds a predefined threshold $t$.
In order to adjust the influence of the gradients, we define the rescaling function:
\begin{equation*}
    s(\*g_1, \*g_2) := \frac{\*g_1}{||\*g_1||_2}\max\{\varepsilon, || \*g_2 ||_2\},
\end{equation*}
which scales a vector $\*g_1$ to the length of $\*g_2$ based on the Euclidean norm or a minimum length of $\varepsilon$ \cite{van_baelen_constraint_2022}.
In case of a violation ($c(\invpairsbatch)> t$), we scale $\nabla_\modelParameters \loss$ to a fraction $\stepSize \in \left[0,1\right]$ of the length of $\corrGrad$ or $\varepsilon$. 
Otherwise, we apply $\nabla_\modelParameters \loss$, whereas the vector length is limited by twice the length of $\corrGrad$:
\begin{equation}
    \lossGrad := \begin{cases}
        \stepSize \cdot s(\nabla_\modelParameters \loss, \corrGrad ) & \textbf{if } c(\invpairsbatch) > t \\[1ex]
        \underset{\*g \in \big\{\nabla_\modelParameters \loss, s(\nabla_\modelParameters \loss, 2\cdot\corrGrad )\big\}}{\arg\min}||\*g||_2  & \textbf{else}
    \end{cases}.
    \label{eq:loss_grad}
\end{equation}
Eq.~\ref{eq:loss_grad} rescales $\nabla_\modelParameters \loss$ based on the length determined by the Euclidean norm of $\lossGrad$ (or a minimum value of $\varepsilon$), when the invariance condition is violated. 
The rescaling of the corrective gradient based on the invariance condition allows for an adaptive regulation of the learned invariance, when necessary.
In addition, the length of $\lossGrad$ is limited to a maximum length of $2\cdot||\corrGrad||_2$ to homogenize the gradient-magnitude in regions where $2\cdot||\corrGrad||_2<||\nabla_\modelParameters \loss||_2$.  
In such regions, the corrective effect may be undermined, as convergence to a subspace satisfying the invariance condition may result in a sudden large step.
For both updates, the same learning rate $\eta$ is used.
% 
We apply a KL divergence of the outputs as an invariance condition as it is more sensitive than defining a threshold on $\RDist$.
Therefore, correction is applied earlier when the model tends to rely on invariant features.
In addition, the training process is less constrained when the invariance condition is met.
We update the weights using the optimization function $\optim$ that can involve momentum-based techniques allowing for a stabilizing effect. 
The additional corrective update step via $\*g_d$ reduces $\RDist$, corrects the overall rationale, and thus encodes the invariance.

\newcommand{\rightcomment}[1]{\hfill\Comment{#1}}

An overview of the presented method is shown in Alg. \ref{alg:approach} defining the extended update function for one gradient descent step for a training-data batch given by $(\*X, \*y)$.

\begin{algorithm}
\caption{IPG update step}
\label{alg:approach}
\begin{algorithmic}[1]
\Require $\modelParameters$, $\*X$, $\*y$, $\invpairsbatch$, $\stepSize$, $\eta$, $t$, $\varepsilon$

\For{$i \in \{1, 2\}$} \rightcomment{calculate distance measure $d$}
    \State $\*z_i \leftarrow f(\invpairsbatch_i;\modelParameters_f)$
    \For{$k \in \{1, 2\}$}
        \State $\*R_{i,k} \leftarrow \modelParameters_{h, k} \cdot \*z_i$ 
    \EndFor
    \State $\Rmean_{i,k,c} \leftarrow \frac{1}{N}\sum^N_{n = 1} \*R_{i,k,c,n}$
    \State $\invpred_i \leftarrow softmax(h(\*z_i; \modelParameters_h))$
\EndFor

\State $d \leftarrow ||\Rmean_1 - \Rmean_2||_2$

\State $\*g_d \leftarrow \nabla_\modelParameters d$ \rightcomment{calculate corrective gradient}

\State $\modelParameters \leftarrow \optim(\modelParameters, \eta,\*g_d)$
\rightcomment{update weights}

\State $\hat{\*y} \leftarrow softmax(h(f(\*x; \modelParameters_f);\modelParameters_h))$ \rightcomment{classify} 

\State $\lossGrad \leftarrow \nabla_\modelParameters \loss(\*y, \hat{\*y})$ \rightcomment{calculate loss gradient}

\State $c \leftarrow \frac{1}{2}(KL(\invpred_1 || \invpred_2) + KL(\invpred_2 || \invpred_1))$ \rightcomment{scale $\lossGrad$ on invariance condition violation}
\If{$c > t$}
    \State $\lossGrad \leftarrow \stepSize \cdot \frac{\lossGrad}{||\lossGrad||_2}\max\{\varepsilon, || \*g_d ||_2\}$
\Else
    \If{$||\lossGrad||_2> 2 \cdot \max\{\varepsilon, || \corrGrad ||_2\}$}
        \State $\lossGrad \leftarrow 2 \cdot \frac{\lossGrad}{||\lossGrad||_2}\max\{\varepsilon, || \*g_d ||_2\}$
    \EndIf
\EndIf

\State $\modelParameters \leftarrow \optim(\modelParameters, \eta,\lossGrad)$ \rightcomment{update weights}

\end{algorithmic}
\end{algorithm}

\section{Experiments}
\label{sec:experiments}

In this section, we present the evaluation method and the results.

We evaluate IPG using the following three datasets: 
ColoredMNIST \cite{arjovsky_invariant_2019}, Waterbird-100 \cite{petryk_guiding_2022}, and CelebA \cite{sagawa_distributionally_2020}.
These datasets exhibit a strong binary spurious correlation attribute. 
The attributes are color (red or green), background (water or land), and gender (female or male) for the ColoredMNIST, Waterbird-100, and CelebA datasets, respectively. 
The classes are binary in each dataset: In ColoredMNIST, they consist of digit groups 0-4 and 5-9. In Waterbird-100, the classes are waterbird and landbird. In CelebA, they are blond and non-blond hair.
ColoredMNIST is structured as a domain generalization dataset, while Waterbird-100 and CelebA are motivated by group robustness. 
Therefore, ColoredMNIST is evaluated on a test dataset, where the spurious correlation is opposite to the training dataset, representing an out-of-distribution domain. 
ColoredMNIST has a label noise of $25\%$.
Waterbird-100, and CelebA are typically evaluated based on the entire test dataset, focusing on the worst-group accuracy to measure group robustness.
Waterbird-100 is a special case, where the training dataset contains only perfectly correlated pairs.
For this dataset, we also test the reversed setting, predicting the background as a label instead of the bird type.

In order to guide the gradient in the learning phase, we select a set of invariance pairs, denoted as $\invpairs$.
These pairs are crucial as they define the specific invariance that the model is expected to learn.
Specifically, for the ColoredMNIST dataset, we choose pairs of different colors, as illustrated in Fig.~\ref{fig:colored_mnist_invariance_pair}. 
For the Waterbird-100 dataset, we use pairs with the same bird but backgrounds from different environments (Fig.~\ref{fig:waterbird_invariance_pair}). 
The complementary image in each pair is created by flipping the color of the original image in ColoredMNIST.
For the Waterbird-100 dataset, we generate a pair by exchanging the background randomly with one of the other type. 
For the reversed version, we substitute the bird in a similar way. 
For CelebA, we apply a GAN-based latent space modification, to generate a gender-swapped version of a given CelebA-HQ image \cite{dalva_image--image_2023}.
We order the generated images by the Mahalobis distance \cite{mahalanobis_generalised_1936} of the latent representation of a trained ERM model to other female (or male) images in the training dataset and manually select the images (Fig.~\ref{fig:celeba_invariance_pair}).

We train the models with the following specifications.
The model architecture for experiments based on ColoredMNIST is a convolutional neural network and follows the DomainBed framework \cite{gulrajani_search_2021}, commonly used for benchmarking.
For Waterbird-100 and CelebA, we use a ResNet-50 \cite{he_deep_2016}.
Accuracy is evaluated over $10$ trials, with different model initializations.
Model selection is based on the highest mean validation accuracy for ColoredMNIST and maximum worst-case validation accuracy for Waterbird-100 and CelebA.
The hyperparameters (Tab.~\ref{tab:hyper-params}) are selected using the Tree-structured Parzen Estimator with $100$ trials per dataset \cite{bergstra_algorithms_2011}. 
This setup supports our accuracy comparison and latent representation analysis.

\begin{table}[]
    \centering
    \caption{Hyper-parameter configuration of IPG in experiments.}
    \begin{tabular}{r|ccccccc}
        \toprule
        Dataset & Model & $\alpha$ & $t$ & $|\invpairs|$ & $\eta$ & Batch Size & Nr. Epochs\\
        \midrule
        ColoredMNIST & IPG, IPG-AA & \num{1e-1} & \num{2e-6} & $300$ & \num{1e-3} & 128 & 18 \\
        Waterbird-100 & IPG & \num{5e-1} & \num{2e-4} & $300$ & \num{1e-4} & 32 & 10 \\
        CelebA & IPG & \num{1e-2} & \num{1e-4} & $271$ & \num{1e-3} & 128 & 10 \\
        CelebA & GroupDRO+IPG & \num{85e-2} & \num{1e-1} & $271$ & \num{1e-3} & 128 & 10 \\
        \bottomrule
    \end{tabular}
    \label{tab:hyper-params}
\end{table}

\subsection{Accuracy Comparison}
\label{sec:accuracy_comparison}
\textbf{ColoredMNIST:}
For ColoredMNIST, we examine IPG based on the accuracy on the test dataset. 
In this dataset, the correlation of color and label inverses relative to the samples observed during the training phase.
Our approach achieves a mean test accuracy of $72.7\%$.
Due to the inherent labeling noise in the dataset, the theoretical maximum accuracy is limited to $75\%$ \cite{arjovsky_invariant_2019}.
Tab.~\ref{tab:perf_coloredmnist} shows an overview of the accuracy and the standard error for the test dataset compared to state of the art approaches. 
It should be noted that the performance comparison may not be entirely fair, as both the IRM approaches as well as the Fishr method lack access to external information, such as $\invpairs$, which IPG uses \cite{rame_fishr_2022, bae_meta-learned_2021, arjovsky_invariant_2019}. 
Further, the Shock Graph approach derives a shape-based representation of the digit and therefore removes the color information \cite{narayanan_shape-biased_2021}. 
We argue that the transformation serves as a method for encoding dataset-specific knowledge about invariant representations. 
Additionally, we also list an \ac{ERM} approach as a baseline and another \ac{ERM}-based approach learning on grayscale images, serving as an oracle \cite{arjovsky_invariant_2019}. 
IPG shows the highest mean accuracy compared to other methods, benefiting from the explicit incorporation of invariances provided by $\invpairs$.

\begin{table*}[h]
    \caption{Accuracy comparison on ColoredMNIST without (a) and with (b) adversarial or random augmentation.}
    \label{tab:colored_mnist_perf}
    \begin{subtable}[h]{0.45\textwidth}
        \centering
        \caption{}
        \label{tab:perf_coloredmnist}
        \begin{tabular}{rl}
            \toprule 
            Approach & 
            Accuracy \\
            \midrule 
            ERM & \textcolor{black}{$16.1 \pm 0.8$}\\
            IRM \cite{arjovsky_invariant_2019} & $66.9 \pm 2.5$ \\ 
            meta-IRM \cite{bae_meta-learned_2021} & $70.4\pm 0.9$\\
            Fishr \cite{rame_fishr_2022} & $68.8 \pm 1.4$ \\
            Shock Graph \cite{narayanan_shape-biased_2021} & $71.6$ \\
            IPG (ours) & $\mathbf{72.7 \pm 0.3 }$ \\
            \midrule 
            Random & $50.0 \pm 0.0$ \\
            ERM grayscale (oracle) & $73.1\pm 0.4$\\
            Optimal & $75.0 \pm 0.0$\\
            \bottomrule 
        \end{tabular}
    \end{subtable}
    \hfill
    \begin{subtable}[h]{0.45\textwidth}
        \centering
        \caption{}
        \label{tab:perf_coloredmnist_adv_aug}
        \begin{tabular}{rl}
            \toprule 
            Approach & 
            Accuracy \\
            \midrule 
            DAIR-AA \cite{huang_robustness_2023} 
            & $72.6 \pm 0.1$\\
            DAIR-RA \cite{huang_robustness_2023}  
            & $73.1 \pm 0.1$\\
            IPG-AA (ours) & 
            $\mathbf{73.3 \pm 0.4}$ \\
            \midrule 
            Random & $50.0 \pm 0.0$ \\
            ERM grayscale (oracle) & $73.1\pm 0.4$\\
            Optimal & $75.0 \pm 0.0$\\
            \bottomrule 
        \end{tabular}
     \end{subtable}
\end{table*}

As an additional performance comparison, we examine DAIR by using adversarial augmentation.
DAIR encodes augmented inputs in the loss function. 
Both, the original and the augmented input are processed by the neural network in a feed-forward step. 
In this way, the spurious correlation is effectively mitigated within the ColoredMNIST dataset.
For comparison, we extend our IPG approach with adversarial augmentation, i.e., IPG-AA, representing perfect invariance information. 
We then compare IPG-AA with two variants of DAIR: 
one that uses adversarial augmentation (DAIR-AA) and another using random augmentation (DAIR-RA) \cite{huang_robustness_2023}.
The accuracy on the test environment is shown in Tab.~\ref{tab:perf_coloredmnist_adv_aug}.
We conclude that IPG-AA achieves a higher mean test accuracy than DAIR-based approaches or the ERM-grayscale approach. 
Summarizing, IPG and IPG-AA reach state of the art results in both test scenarios.

\textbf{Waterbird-100:}
We further evaluate the performance of IPG on the Waterbird-100 dataset, which has a perfect spurious correlation in the training set: every waterbird image has a water background, while every landbird image shows land or forest.
Additionally, multiple bird species represent each class, making it more complex to learn the defining characteristics of the birds compared to the simpler background features.
%
The test dataset includes instances from all groups, with a particular focus on the worst-group accuracy. 
We also examine a reversed setting, where labels and spurious attributes are swapped, following prior studies by Rao~\cite{rao_studying_2023} and Petryk~\cite{petryk_guiding_2022}.
%
Unlike the digits in ColoredMNIST, birds show more complex patterns, there is only one training domain, and the training dataset lacks bias-conflicting samples. 
We compare our approach to the explanation-guided learning method, which we refer to as EGL \cite{rao_studying_2023}, and the language-guided learning method GALS \cite{petryk_guiding_2022}. 
EGL applies different \ac{XAI} methods: B-cos \cite{bohle_b-cos_2022}, $\mathcal{X}$-DNN \cite{hesse_fast_2021}, and IxG \cite{shrikumar_learning_2017}, to calculate feature attributions.
Additionally, we apply an ERM based approach as baseline. 
%
Tab.~\ref{tab:perf_waterbird} summarizes the results. 
%
ERM achieves the highest overall accuracy for both Waterbird-100 versions, mainly at the expense of the minority classes. 
IPG achieves higher worst-group accuracy compared to GALS, EGL, and ERM. 
These findings indicate that invariance-pair guidance effectively encodes the desired invariance.
We conclude that IPG achieves higher worst-group accuracy compared to the baselines on both versions of the Waterbird-100 dataset, representing a state of the art result to the best of our knowledge.

\begin{table}[ht]
    \centering
    \caption{Accuracy comparison on Waterbird-100 and Waterbird-100-reverse.}
    \label{tab:perf_waterbird}
    \begin{tabular}{l|ll|ll}
        \toprule
        &\multicolumn{2}{c|}{Waterbird-100} & \multicolumn{2}{c}{Waterbird-100-reverse} \\
        Model & Overall Acc. ‚Üë & $\text{Acc}_{wg}$ ‚Üë & Overall Acc. ‚Üë & $\text{Acc}_{wg}$ ‚Üë \\
        \midrule
        EGL B-cos \cite{rao_studying_2023}     & $71.1 \pm 0.9$ & $41.0 \pm 2.1$ & $83.6 \pm 1.1$ & $62.8 \pm 2.1$ \\
        EGL $\mathcal{X}$-DNN \cite{rao_studying_2023}     & $73.1 \pm 3.4$ & $47.0 \pm 9.1$ & $82.6 \pm 2.0$ & $63.9 \pm 3.6$ \\
        EGL IxG \cite{rao_studying_2023}   & $78.1 \pm 2.6$ & $56.1 \pm 7.0$ & $78.9 \pm 1.9$ & $56.5 \pm 3.7$ \\
        GALS \cite{petryk_guiding_2022}    & $79.7$ & $56.7$ & $86.8$ & $72.9$ \\
        ERM & $\mathbf{99.4 \pm 0.1}$ & $37.2 \pm 0.2$ & $\mathbf{99.4 \pm 0.1}$ & $56.6 \pm 2.4$ \\
        IPG (ours) & $85.92 \pm 2.29$ & $\mathbf{68.62 \pm 3.37}$  & $92.13 \pm 1.03$ & $\mathbf{84.53 \pm 2.63}$ \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{CelebA:}
Finally, we evaluate the performance of our approach on the CelebA dataset, which exhibits gender as a spurious attribute.
Compared to ColoredMNIST and Waterbird-100, the formulation of pairs is more challenging, since the spurious attribute is not synthetic.
We use the image-to-image translation technique \cite{dalva_image--image_2023} to generate pairs.
IPG is compared to several established methods.
We evaluate GroupDRO \cite{sagawa_distributionally_2020}, a technique that uses group information during training, along with a combined approach integrating both IPG and GroupDRO. 
Additionally, we evaluate JTT \cite{liu_just_2021} and LfF \cite{nam_learning_2020}, which operate without requiring additional information, relying instead on intentionally biased models.
We also examine ERM as a baseline approach without guidance.
Our findings reveal that ERM achieves the highest overall accuracy. 
The worst-case accuracy of IPG alone ($73.2\%$) is lower than that of JTT or GroupDRO. 
However, when combined with GroupDRO, IPG achieves slightly higher worst-case accuracy and exhibits reduced variance compared to GroupDRO alone. 
In general, the corrective gradient introduced by IPG helps to improve worst-case performance, as shown by its superior worst-case accuracy compared to ERM.
Nonetheless, JTT achieves higher worst-case accuracy than IPG without the need for additional information. 
Tab.~\ref{tab:celeba} summarizes the results and compares requirements for additional group labels or pairs. 
A notable challenge in using IPG lies in the definition of effective pairs, which is crucial for maintaining compatibility with the dataset domain. 
The applied image-to-image translation technique, for instance, can produce outputs that deviate in unwanted characteristics from the original image domain, such as generating blonder hair for women (Fig.~\ref{fig:celeba_invariance_pair}).
The results indicate that while IPG enhances worst-case performance, it still falls short of the state of the art results achieved by GroupDRO or JTT, primarily due to difficulties in defining effective pairs.

\begin{table}[]
    \centering
    \caption{Accuracy comparison on CelebA.}
    \label{tab:perf_celeba}
    \begin{tabular}{llll}
        \toprule
        Model & Additional Info & Overall Acc. ‚Üë  & $\text{Acc}_{wg}$ ‚Üë \\
        \midrule
        GroupDRO \cite{sagawa_distributionally_2020} & $g$ & $92.9 \pm 0.2$ & $88.9 \pm 2.3$\\
        JTT \cite{liu_just_2021} & - &$88.0$ & $81.1$ \\
        LfF \cite{nam_learning_2020}& - &$86.0$ & $70.6$ \\
        ERM & - &$\mathbf{94.9 \pm 0.2}$ & $47.8 \pm 3.7$ \\
        IPG (ours) & $\mathcal{I}$ & $89.9 \pm 3.2$ & $73.2 \pm 7.5$ \\
        GroupDRO+IPG (ours) & $\mathcal{I}$, $g$ & $92.3 \pm 0.3$ & $\mathbf{89.6 \pm 1.3}$ \\
        \bottomrule
    \end{tabular}
    \label{tab:celeba}
\end{table}

\subsection{Latent Representation Analysis}
\label{sec:latent_representation_analysis}
We inspect the latent representation of models trained with IPG and \ac{ERM}, focusing on their ability to learn the invariance.
To analyze and compare the internal representation of the neural network, we trained two different models. 
A model $M_{IPG}$ is trained with IPG encoding the invariance, while a model $M_{ERM}$ is trained with \ac{ERM} without explicit invariance information. 
For both trained models, we compute the rationale $\*R_{\*x}$ from an input $\*x$ for random samples of the test sets of ColoredMNIST, Waterbird-100, and CelebA. 
Then, to reduce the dimension of the rationale to two, t-SNE \cite{maaten_visualizing_2008} is applied to the (vectorized) rationales $\*R_{\*x}$ with a perplexity of $200$.
The resulting illustration, as shown in Fig.~\ref{fig:tsne-comparison}, exhibits differences in the latent representation. 
Since all instances represent the same class, they are ideally represented in one cluster without separation based on the spurious attribute.
Especially for ColoredMNIST, a clear separation based on the spurious attribute color for $M_{ERM}$ is visible as of the inherent label noise.
In contrast, for $M_{IPG}$, the model shows a mixture of red and green instances without a clear color-based separation. 
For the Waterbird-100 and CelebA results, we find a higher overlap of instances differing in spurious attributes for $M_{IPG}$, while $M_{ERM}$ shows a clearer separation of these instances. 
Thus, the rationales of $M_{IPG}$ seem to better reflect the underlying structure associated with $y$, in contrast to the rationales of $M_{ERM}$, which appear to be more influenced by the spurious attribute.
Fig.~\ref{fig:tsne-comparison} depicts the representations for a single class, but similar characteristics are observed for all classes.
From these observations, we conclude that the latent representation of $M_{IPG}$ shows visible signs of internalized invariance through the invariance correction of IPG.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1.\textwidth]{fig/tsne_rational.pdf}
    \caption{
    Visualization of the rationales for $y = 1$ of an \ac{ERM}- and an IPG-based approach for ColoredMNIST (a-b), Waterbird-100 (c-d), and CelebA (e-f). 
    }
    \label{fig:tsne-comparison}
\end{figure}

\subsection{Discussion and Limitations}
In the previous experiments, we examined the characteristics of IPG. 
We found that IPG and IPG-AA reach state of the art performance on ColoredMNIST (Tab.~\ref{tab:perf_coloredmnist} and \ref{tab:perf_coloredmnist_adv_aug}). 
We showed that IPG outperforms current approaches on the Waterbird-100 dataset and its reversed version (Tab.~\ref{tab:perf_waterbird}), which is particularly challenging because of its inherent perfect spurious correlation. 
We also found that IPG can improve performance on the real-world dataset CelebA without the need for the group labels (Tab.~\ref{tab:perf_celeba}).
However, there are efficient methods, such as JTT that perform better. 
Only when combined with GroupDRO, IPG can reach state of the art results.
For real-world datasets, the explicit pair formulation might be interesting, whereas the implicit formulation, as in JTT, is imprecise.
In addition, we have shown that the resistance to the inherent spurious correlation comes along with well-represented latents (Fig.~\ref{fig:tsne-comparison}).
These results show that the proposed approach effectively encodes invariance in the presence of significant spurious correlation. 

Despite the successful encoding of invariance, some limitations still need to be addressed. 
First, the invariance condition and the corrective gradient based on rationale matrices are associated with a task outputting logits, such as classification.
Using other tasks, such as regression, is worth investigating. 
Second, the computational complexity is increased primarily due to the additional pair calculation of $2|\invpairs|$ inference steps and the corrective gradient step.
Future work could investigate, whether corrective gradients can be omitted in certain steps.
%
Third, the results on CelebA indicate that the method is highly dependent on the quality of invariance pairs. 
Future work could explore ways to ensure quality.
In addition, while image-to-image translation techniques can help to produce the pairs, they can also suffer from bias, which needs to be mitigated by manual inspection. 
Finally, we plan to extend to multiple invariances, e.g., by combining the correction gradients, e.g., by averaging or addition.

\section{Conclusion}
\label{sec:conclusion}
This work proposes a novel method to define and learn invariance through the IPG approach, which allows to specify invariance pairs.
Based on the pairs, we define an invariance condition and a corrective gradient.
These components allow for an adaptive regulation of the training phase of the neural network. 
In this way, invariance is encoded while maintaining the flexibility of the models. 
With IPG, spurious correlations can be compensated to improve the out-of-distribution performance and thus make the models more robust. 
IPG (i) operates on a single domain, (ii) utilizes data-efficient pair formulation without requiring specialized augmentation, (iii) applies to datasets without bias-conflicting groups, and (iv) eliminates the need for pre-processing of the dataset.
We validated the effectiveness of IPG on the ColoredMNIST, the Waterbirds-100(-reversed), and the CelebA datasets.
For Waterbirds-100, IPG demonstrated a notable improvement of $11.91$ percentage points in mean worst-case accuracy. 
On the real-world CelebA dataset, IPG is limited by pair quality, however, IPG proved beneficial when combined with GroupDRO.
In the future, we plan to apply IPG to datasets with multiple invariances.

\bibliography{references}

\end{document}