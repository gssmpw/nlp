\section{Related works}
\label{sec:related}

\subsection{Hand pose estimation}

% TODO：罗列最近的单目手部工作
Mainstream research in hand pose estimation concentrates on estimating hand poses from single-view RGB images or videos ____. ViTPose____ successfully integrates Vision Transformer____ into the pose estimation domain, achieving real-time performance and high precision in 2D pose estimation. Furthermore, the application of advanced architectures such as HRNet____ in 3D hand pose estimation has resulted in significant progress.

A substantial body of work addresses specific challenges in hand pose estimation. For instance, InterWild____ targets the estimation of inter-hand poses in in-the-wild scenarios, ____ tackles pose estimation in blurred settings, and ____ emphasizes first-person hand pose estimation. Concurrently, recent methodologies have emerged that utilize self-supervised learning for hand pose estimation tasks. For example, ____ adopts a 2D pose detector for retrieving similar pose images, allowing the backbone to focus on extracting pose-related features. PeCLR____ constructs positive samples through geometric transformations, yielding higher accuracy compared to the traditional contrastive learning method for images____. Other approaches exploit the projection relationship between 3D poses and 2D poses, training networks for pose estimation via self-supervised learning ____.
% 主流的手部姿态估计工作聚焦于从单视图RGB图象或视频中估计手部姿态____。ViTPose____将ViT____引入到姿态估计领域实现了实时高精度的二维姿态估计。将HRNet____等改进的网络架构应用到三维手部姿态估计中的工作也取得了令人影响深刻的进展。一方面大量的工作聚焦于解决手部姿态估计容易遇到的问题。例如InterWild____关注in-the-wild场景下的双手姿态的估计问题，____处理了模糊场景下的姿态估计问题，____着重于第一人称的手部姿态估计问题。另一方面，近期涌现出了基于自监督方式进行学习的手部姿态估计方案。例如____使用2D pose detector进行相似姿态图象检索，使得backbone聚焦于提取姿态特征。PeCLR____利用几何变换构造正样本，取得了相比于vanilla的图像对比学习方法SimCLR____更高的精度。另一类方法利用3D姿态和2D姿态之间的投影关系直接利用自监督学习训练网络获得姿态估计的能力____。

Our work, in contrast, adopts a data-driven approach utilizing a purely classical architecture, ResNet____. By exploiting the isomorphism between input space and latent space, we achieve state-of-the-art (SOTA) performance without employing task-specific pruning designs.

\subsection{Representation learning}

Representation learning seeks to automatically extract valuable latent or representations from raw data. This process allows models to transform complex, high-dimensional data---such as images, text, or audio---into low-dimensional, compact representations that can be effectively utilized for tasks including classification, regression, and clustering. According to ____, mainstream representation learning methods can be broadly classified into masked image modeling (MIM) methods and contrastive learning methods.
% 表示学习旨在从原始数据中自动提取有效特征或表示。通过表示学习，模型能够将复杂的高维数据（如图像、文本或音频）转换为低维的、紧凑的表示，这些表示可以用于分类、回归、聚类等任务。根据____，主流的表示学习方法分为基于Masked Image Modeling的方法和基于Contrastive Learning的方法。

MIM methods enable models to learn the relationships among different regions of an image by reconstructing masked areas based on unmasked regions ____. MAE____ synergizes masked image modeling with ViT ____ to facilitate efficient masked pretraining. Building on the approach established in ____, numerous representation learning strategies have emerged using masked models. For instance, iBOT ____ incorporates contrastive learning into MIM to capture high-level semantic features, while P-STMO ____ extends masked modeling from image space to pose space to learn pose sequence priors.
% 基于MIM的方法使模型通过未被mask的区域恢复mask区域的方式学习图象不同区域之间的关联信息____。例如____将图像块mask与ViT____结合进行高效率的掩码预训练。基于____延伸出了更多利用掩码模型进行表示学习的工作，例如iBOT____在MIM学习的基础上引入了对比学习的思想以学习高层语义特征，P-STMO____将掩码模型从图像空间引入到了姿态空间以学习姿态序列先验。

Contrastive learning methods enable models to learn features beneficial for downstream tasks by bringing closer the representations for positive samples with similar properties ____. ____ proposes a foundational framework for contrastive learning within image domain, establishing a baseline for visual contrastive learning. ____ treats images belonging to the same class, rather than merely different transformations of the same image, as positive samples for contrastive learning, thus enhancing the model's ability to extract high-level semantic features. Furthermore, ____ employs 2D poses in contrastive learning, thereby aligning it more effectively with pose estimation tasks. ____ applies contrastive learning to dense prediction tasks, achieving improvements in object detection, semantic segmentation, and instance segmentation.
% 基于CL的方法使得模型对具有相同性质的正样本产生的特征接近来学习对下游任务有利的特征____。____提出了一种在图像空间上进行对比学习的简单框架，奠定了视觉对比学习的baseline。____将相同类别的图象而不是一张图像的不同变换结果作为正样本进行对比学习，提升网络的高层语义提取能力。____将2D pose用于对比学习，使其更适用于姿态估计领域。____提出将CL应用于稠密预测任务，在对object detection、semantic seg.和instance seg.任务上取得了提升。

% 得益于重建任务对低层信息的抽取能力和CL任务对data-specific特征的学习能力，我们提出将这两点特征结合，在重建任务学习抽取丰富的低层特征的同时利用CL任务构造更加合理的特征空间结构。

% \begin{figure*}[th]
%     \centering
%     \includegraphics[width=\linewidth]{figs/overview.pdf}
%     \caption{Overview of transformation isomorphism. \textbf{Left}: The relationships among three transformations in the image space: horizontal flip, rotation, and the horizontal flip + rotation. Any two of these transformations can be composed to form another transformation, and the rotation inherently includes the identity transformation. \textbf{Right}: In the pose space, there are three transformations that correspond exactly to the three transformations in the image space, and they satisfy the same composite relationships. We refer to this perfect correspondence as transformation isomorphism. \textbf{Center}: TI-Net ensures that the feature embeddings in the latent space have transformations that correspond exactly to the three transformations in the image space. Due to the equivalence property of the isomorphism, the transformations in the latent space also correspond to those in the pose space, satisfying the same composite relationships.}
%     % Overview of transformation isomorphism. \textbf{左}：图象关于水平翻转、旋转和水平翻转加旋转三种变换的关系，这三种变换的任意两种可以复合形成另外一种变换，同时旋转变换隐含了恒等变换。\textbf{右}：姿态空间中存在与图像上的三种变换完全对应的三种变换，他们也满足与图像空间上的变换完全相同的复合关系。这种完全对应的关系我们称为transformation isomorphism。\textbf{中}：TI-Net使得隐空间上的特征向量也存在与图像空间上的三种变换完全对应的变换，由于同构关系的等价性，隐空间中的变换也与姿态空间中的变换完全对应，且满足完全相同的复合关系。
%     \label{img:overview}
% \end{figure*}

\subsection{Learning invariant attributes}

Contrastive learning-based representation learning frameworks generally incorporate a set of transformations applied to the input data, aimed at ensuring that the resulting latent capture information highly relevant to the task. Taking image input as an example, in a contrastive learning framework for high-level tasks (\eg, classification, REID, understanding), this set of transformations often consists of low level transformations like rotations, cropping, scaling, color jittering, noise addition and others. These transformations are crafted to preserve the high-level semantic information contained within the images. Consequently, we expect the backbone to extract \emph{invariant} latent with respect to such transformations under these training frameworks.
% 基于CL的表示学习框架通常包含一组对输入的变换，这一组变换与框架的设计旨在让特征中包含与任务强相关的信息。以图象输入为例，在面向高层次任务（如分类、理解）的对比学习中这一组变换通常由旋转、裁切、缩放、色彩打乱、添加噪点等变换组成，这样的变换对于图象中的高层语义信息不产生影响，相应地在这些框架中也希望backbone对于这样的图象产生\emph{不变invariant}的特征。

Research by ____ advocates enabling the network to estimate rotation angles directly from images, while ____ suggests that the network extract directionally and rotation-invariant features simultaneously. These approaches allow the network to extract high-level semantic information that invariant to rotation, thereby enhancing classification performance. HandCLR ____, which targeting the pose estimation backbone, introduces the concept of constructing positive samples by retrieving images with analogous poses using a 2D pose detector. This strategy allows the latent extraction network to capture more critical pose information. The aforementioned works concentrating on extracting \textit{transformation invariant} latent, extracting \textit{similar} latent for images subject to different augmentations.

PeCLR____, contrarily to ____, posits that augmentations applied to the image should distinctly affect the corresponding latent representations, resulting in \textit{different} latent for images with varying augmentations. We propose that these different latent should maintain the same structure as images under pre-defined transformations. As shown in (III) of \cref{img:compare}, latent and image compel to same structure with respect to ``flip'', ``rot'' and ``flip+rot''. We refer to this property on latent as \textit{transformation consistency}.

% ____ proposes enabling the network to directly estimate rotation angles from images, while ____ further suggests that the network should extract direction and rotation-invariant features simultaneously. These approaches allow the network to extract high-level semantic information that is invariant to rotation, improving performance on classification tasks. HandCLR ____, targeting the pose estimation backbone, proposes constructing positive samples by retrieving images with similar poses using a 2D pose detector, enabling the feature extraction network to capture more essential pose information. PeCLR ____ introduces the idea that the augmentations on the image should also affect the corresponding latent. Such innovation enhanced accuracy in hand pose estimation tasks.
% ____提出让网络直接从图像中估计旋转角度，____进一步地提出让网络学习图象的旋转角度和旋转无关的特征，从而使得网络提取旋转无关的高层语义信息，提升了在分类任务上的表现性能。PeCLR____提出让特征抽取网络$\mathcal F$对于图象变换$A$是``可交换的''：$\mathcal F\circ A'=A\circ\mathcal F$，提升在手部姿态任务的准确度。HandCLR____针对姿态估计backbone，提出了利用2D pose detector检索相似的姿态图象构造正样本，使得更加特征抽取网络能够抽取更加本质的姿态信息。

% ____ focus on extracting \emph{transformation invariant} features, which are beneficial for high-level tasks. However, regression tasks are more closely related to low-level image features, as the orientation and direction of the image are strongly associated with the target of the regression task. For example, a 15° image rotation results in a corresponding 15° rotation of the root joint of hand within the image. We claim this property as ``\textit{transformation consistent}''.% PeCLR____, considering this characteristic, combines it with features extracted by backbone to construct \emph{transformation consistent} features, leading to improved performance in pose estimation tasks.
% ____等工作都是在抽取对于一组\emph{变换不变（transformation invariant）的特征}，这一类特征对于高层次任务是有益的。但是回归任务与图象的低层特征更加密切，图象的朝向、方向与回归任务的目标密切相关，例如图象旋转15°会导致图像中手部跟关节也旋转15°，所以他们的方法可能不适用于回归任务。而PeCLR____在工作中考虑到了这一特征，并将之与CNN抽取的特征结合，构造了\emph{变换一致（transformation consistency）的特征}，在姿态估计任务上取得了提升。

Transformation-consistent latent are capable of better capturing the structure of the hand pose space compared to transformation-invariant features, owing to the transformation-consistency relationship between the image and pose space. By enforcing transformation invariance on latent, the vision backbone inadvertently discard pose-relevant information during the pretraining, leading to inferior estimation accuracy. TI-Net addresses this issue by enforcing transformation isomorphism constraints through the integration of masked image modeling (MIM) and contrastive learning, thereby producing features imbued with transformation consistency and achieving improved accuracy.
% trans cons的特征比trans inv的特征能够更好地刻画手部姿态空间的性质，因为目标空间和输入空间之间本身就存在trans cons。强制特征trans inv可能使得姿态相关的信息在extract的过程中丢失，而丢失的信息无法再使用网络恢复，从而降低手部姿态估计的精确度。TI-Net通过结合MIM和对比学习实现trans iso约束，使得提取的特征具有trans cons的性质，以取得更好的手部姿态估计精度。

%Benefiting from the advantage of reconstruction task that enabling the backbone to extract low-level information and the the advantage of contrastive learning task that enabling the backbone to learn task-specific features, TI-Net is able to learn extracting features with rich and compact information about hand pose effectively. While the reconstruction task extracts rich low-level features, the contrastive learning task ensures a more rational feature space structure. Specifically, the key to representation learning is to identify and construct \emph{invariants}. For regression tasks, constructing \emph{transformation-invariant} features neglects low-level information, while \emph{transformation consistency} of the feature space can accurately capture the properties of the feature space desired by regression tasks. By integrating contrastive learning, we construct and learn a latent space based on transformation isomorphism. Compared to PeCLR ____, the latent space we learn is more rational and offers better interpretability.
% 得益于重建任务对低层信息的抽取能力和CL任务对data-specific特征的学习能力，我们提出将这两点特征结合，在重建任务学习抽取丰富的低层特征的同时利用CL任务构造更加合理的特征空间结构。具体而言，表示学习的关键在于寻找和构造\emph{不变量}。而对于回归任务而言，构造\emph{变换不变的特征}忽略了低层信息，而\emph{特征空间的结构不变/变换一致}则能够准确刻画回归任务所希望的特征空间的性质。结合对比学习的方式，我们了在变换同构的基础上构造和学习隐空间。相比于PeCLR____，我们学习的隐空间更加完备且具有更好的可解释性。

%------------------------------------------------------------------------