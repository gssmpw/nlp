\section{Related works}
\label{sec:related}

\subsection{Hand pose estimation}

Mainstream research in hand pose estimation concentrates on estimating hand poses from single-view RGB images or videos **Zhou, "Deep Learning for Hand Pose Estimation"** __**Wang, "ViTPose: Vision Transformer for 2D Hand Pose Estimation"**. ViTPose____ successfully integrates Vision Transformer____ into the pose estimation domain, achieving real-time performance and high precision in 2D pose estimation. Furthermore, the application of advanced architectures such as HRNet____ in 3D hand pose estimation has resulted in significant progress.

A substantial body of work addresses specific challenges in hand pose estimation. For instance, InterWild____ targets the estimation of inter-hand poses in in-the-wild scenarios, ____ tackles pose estimation in blurred settings, and ____ emphasizes first-person hand pose estimation. Concurrently, recent methodologies have emerged that utilize self-supervised learning for hand pose estimation tasks. For example, ____ adopts a 2D pose detector for retrieving similar pose images, allowing the backbone to focus on extracting pose-related features. PeCLR____ constructs positive samples through geometric transformations, yielding higher accuracy compared to the traditional contrastive learning method for images____. Other approaches exploit the projection relationship between 3D poses and 2D poses, training the network with a loss function that enforces transformation consistency____.

Research by **Zhou, "Deep Learning for Hand Pose Estimation"** advocates enabling the network to estimate rotation angles directly from images, while ____ suggests that the network extract directionally and rotation-invariant features simultaneously. These approaches allow the network to extract high-level semantic information that invariant to rotation, thereby enhancing classification performance. HandCLR____, which targeting the pose estimation backbone, introduces the concept of constructing positive samples by retrieving images with analogous poses using a 2D pose detector. This strategy allows the latent extraction network to capture more critical pose information.

PeCLR____, contrarily to ____ and others who focus on extracting \emph{transformation invariant} features, posits that augmentations applied to the image should distinctly affect the corresponding latent representations, resulting in \textit{different} latent for images with varying augmentations. We propose that these different latent should maintain the same structure as images under pre-defined transformations. As shown in (III) of \cref{img:compare}, latent and image compel to same structure with respect to ``flip'', ``rot'' and ``flip+rot''. We refer to this property on latent as \textit{transformation consistency}.

Transformation-consistent latent are capable of better capturing the structure of the hand pose space compared to transformation-invariant features, owing to the transformation-consistency relationship between the image and pose space. By enforcing transformation invariance on latent, the vision backbone inadvertently discard pose-relevant information during the pretraining, leading to inferior estimation accuracy. TI-Net addresses this issue by enforcing transformation isomorphism constraints through the integration of masked image modeling (MIM) and contrastive learning, thereby producing features imbued with transformation consistency and achieving improved accuracy.

Benefiting from the advantage of reconstruction task that enabling the backbone to extract low-level information and the the advantage of contrastive learning task that enabling the backbone to learn task-specific features, TI-Net is able to learn extracting features with rich and compact information about hand pose effectively. While the reconstruction task extracts rich low-level features, the contrastive learning task ensures a more rational feature space structure. Specifically, the key to representation learning is to identify and construct \emph{invariants}. For regression tasks, constructing \emph{transformation-invariant} features neglects low-level information, while \emph{transformation consistency} of the feature space can accurately capture the properties of the feature space desired by regression tasks. By integrating contrastive learning, we construct and learn a latent space based on transformation isomorphism. Compared to PeCLR____, the latent space we learn is more rational and offers better interpretability.