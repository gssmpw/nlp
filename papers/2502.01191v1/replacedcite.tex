\section{Related Work}
\textbf{Concept Bottleneck Models} ____ have emerged as a promising approach to bridge the gap between interpretability and performance in deep learning. CBMs operate by first predicting high-level, human-understandable concepts, which are then used as intermediates to make final task predictions. 
Building upon CBMs, Concept Embedding Models ____ extend the framework by introducing high-dimensional embeddings for concepts. By characterizing each concept with a pair of positive and negative embeddings, CEMs aim to represent the variability within concepts. Post-hoc Concept Bottleneck Models (PCBM) ____ employ a residual fitting mechanism to refine concept predictions, thereby enhancing task accuracy. Probabilistic Concept Bottleneck Models (ProbCBMs) ____ incorporate uncertainty estimates into concept predictions, allowing the model to account for ambiguity in the input data. However, some recent work ____ has pointed out that many of the learned concepts of CBMs do not learn exactly as intended, thus weakening the interpretability of CBMs, but current work is limited to visualising examples or requiring complete changes to the reasoning process of CBMs, and we urgently need an architecture and learning strategy that can effectively mitigate this problem in order to move CBMs forward.

\textbf{Disentangled Representation Learning} Disentangled Representation Learning (DRL) aims to learn representations that separate underlying factors of variation in data into independent, semantically meaningful variables. By doing so, DRL improves explainability, generalizability, and controllability across various tasks such as computer vision____, natural language processing____, and graph learning____. Common approaches include generative models like VAEs____and GANs____, which incorporate additional regularizers to enforce independence among latent factors, as well as methods based on causal inference and group theory____. DRL has been successfully applied in synthetic datasets for dimension-wise disentanglement____ and real-world applications for vector-wise disentanglement____, with the former focusing on fine-grained factors and the latter on coarse-grained ones. Despite significant progress, challenges remain, such as balancing disentanglement quality and task performance, as well as addressing dependencies among generative factors____.