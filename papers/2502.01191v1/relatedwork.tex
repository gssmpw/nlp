\section{Related Work}
\textbf{Concept Bottleneck Models} \cite{koh2020concept, kim2023probabilistic, yuksekgonul2022post} have emerged as a promising approach to bridge the gap between interpretability and performance in deep learning. CBMs operate by first predicting high-level, human-understandable concepts, which are then used as intermediates to make final task predictions. 
Building upon CBMs, Concept Embedding Models \cite{zarlenga2022concept} extend the framework by introducing high-dimensional embeddings for concepts. By characterizing each concept with a pair of positive and negative embeddings, CEMs aim to represent the variability within concepts. Post-hoc Concept Bottleneck Models (PCBM) \cite{yuksekgonul2022post} employ a residual fitting mechanism to refine concept predictions, thereby enhancing task accuracy. Probabilistic Concept Bottleneck Models (ProbCBMs) \cite{kim2023probabilistic} incorporate uncertainty estimates into concept predictions, allowing the model to account for ambiguity in the input data. However, some recent work \cite{margeloiu2021concept} has pointed out that many of the learned concepts of CBMs do not learn exactly as intended, thus weakening the interpretability of CBMs, but current work is limited to visualising examples or requiring complete changes to the reasoning process of CBMs, and we urgently need an architecture and learning strategy that can effectively mitigate this problem in order to move CBMs forward.

\textbf{Disentangled Representation Learning} Disentangled Representation Learning (DRL) aims to learn representations that separate underlying factors of variation in data into independent, semantically meaningful variables. By doing so, DRL improves explainability, generalizability, and controllability across various tasks such as computer vision~\cite{cheng2023disentangled}, natural language processing~\cite{wu2020improving}, and graph learning~\cite{wang2024disentangling}. Common approaches include generative models like VAEs~\cite{xu2021multi}and GANs~\cite{liu2020oogan,tran2017disentangled}, which incorporate additional regularizers to enforce independence among latent factors, as well as methods based on causal inference and group theory~\cite{bengio2013representation, higgins2018towards}. DRL has been successfully applied in synthetic datasets for dimension-wise disentanglement~\cite{chen2016infogan,jeon2021ib} and real-world applications for vector-wise disentanglement~\cite{liu2021activity,cheng2023disentangled}, with the former focusing on fine-grained factors and the latter on coarse-grained ones. Despite significant progress, challenges remain, such as balancing disentanglement quality and task performance, as well as addressing dependencies among generative factors~\cite{suter2019robustly}.