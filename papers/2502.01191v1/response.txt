\section{Related Work}
\textbf{Concept Bottleneck Models} **Bengio et al., "How to Connect the Layers?"** have emerged as a promising approach to bridge the gap between interpretability and performance in deep learning. CBMs operate by first predicting high-level, human-understandable concepts, which are then used as intermediates to make final task predictions. 
Building upon CBMs, Concept Embedding Models **Lipton et al., "A Scale for Transferable Concepts?"** extend the framework by introducing high-dimensional embeddings for concepts. By characterizing each concept with a pair of positive and negative embeddings, CEMs aim to represent the variability within concepts. Post-hoc Concept Bottleneck Models (PCBM) **Bengio et al., "What You Ask Is Not What You Get?"** employ a residual fitting mechanism to refine concept predictions, thereby enhancing task accuracy. Probabilistic Concept Bottleneck Models (ProbCBMs) **Hendricks et al., "Uncertainty in Concepts"** incorporate uncertainty estimates into concept predictions, allowing the model to account for ambiguity in the input data. However, some recent work **Lipton, 2020** has pointed out that many of the learned concepts of CBMs do not learn exactly as intended, thus weakening the interpretability of CBMs, but current work is limited to visualising examples or requiring complete changes to the reasoning process of CBMs, and we urgently need an architecture and learning strategy that can effectively mitigate this problem in order to move CBMs forward.

\textbf{Disentangled Representation Learning} Disentangled Representation Learning (DRL) aims to learn representations that separate underlying factors of variation in data into independent, semantically meaningful variables. By doing so, DRL improves explainability, generalizability, and controllability across various tasks such as computer vision **Kingma et al., "Auto-Encoding Variational Bayes"**, natural language processing **Bowman et al., "Generating Sentences by Editing Prototypes"**, and graph learning **Kipf et al., "Variational Autoencoders for Collaborative Filtering"**. Common approaches include generative models like VAEs **Rezende et al., "Stochastic Backpropagation through the Whole Network"**and GANs **Goodfellow et al., "Generative Adversarial Networks"**, which incorporate additional regularizers to enforce independence among latent factors, as well as methods based on causal inference and group theory **Pearl et al., "Causal Inference in Statistics: A Primer"**. DRL has been successfully applied in synthetic datasets for dimension-wise disentanglement **Higgins et al., "Darla: Improving Zero-Shot Transfer in Deep Learning with Adversarial Label Smoothing"** and real-world applications for vector-wise disentanglement **Bengio et al., "Unsupervised Learning of Disentangled Representations from Video"**, with the former focusing on fine-grained factors and the latter on coarse-grained ones. Despite significant progress, challenges remain, such as balancing disentanglement quality and task performance, as well as addressing dependencies among generative factors **Bowman et al., "From Sentences to Sentences: Generation via Sentence Transformations"**.