\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{EllisFinger_compressed.pdf}
    \caption{(a) The multi-material 3D printed finger alongside a photo of one of the embedded flex-PCBs. (b) Each joint in the TPU flexure holds an embedded optical fiber bending sensor enabling light loss-based pose estimation for each joint.}
    \label{fig:opening_figure}
    \vspace{-1.5em}
\end{figure}

Soft robots have attracted a wide interest among the robotics community. They can be used effectively in unstructured environments because of the inherent safety and adaptability afforded to them by their mechanical compliance. This makes them promising in applications such as human-robot interaction, manipulation, and exploration~\cite{polygerinos2017soft, shorthose2022design, becker2022active, brown2010universal, ng2023untethered, zhang2023progress}. However, while progress has been made in these domains, soft robots are still limited by their sensing capabilities as their virtually infinite degrees of freedom require sensors to be distributed throughout the robot body~\cite{toward_perceptive_soft_robots_wang}. This creates a two-fold challenge: sensors must be sufficiently flexible to survive the high strains experienced by soft robots while maintaining good performance, and they need to be easily integrable at the manufacturing stage~\cite{flexible_sensing_qu}.

To tackle this challenge, researchers have developed a host of sensors of wide-ranging nature, such as resistive, capacitive, and optics-based ones~\cite{Truby2019,Toshimitsu2021,Georgopoulou2023,optoelectronically_innervated_hand_zhao}. Optical sensors in particular show potential because of their low hysteresis, high sensitivity, high strain performance, and their insensitivity to electromagnetic interference and temperature~\cite{flexible_sensing_qu,Hegde2023}. However well these sensors may perform, their fabrication and integration into soft robots remains cumbersome, especially when it comes to the necessary electronics. For example, Sareh et al. attach their macrobend stretch sensor onto the outside of a soft arm by sewing plastic optical fibers (POFs) in a looping pattern to the strain-limiting braided sleeve~\cite{macrobend_optical_sensing_sareh}, and Yang et al. externally route POFs to each of the sensing locations in their soft robotic finger~\cite{Yang2020}. Both approaches achieve sensing of the multidimensional state of a soft robot, but are unable to scale to distributed sensing or provide an untethered solution without external optical wiring because they do not integrate the readout electronics, hindering robot movement and durability~\cite{Rich2018}. 
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{Fabrication_compressed.pdf}
    \caption{Schematic representation of the manufacturing and integration process of the sensorized multi-material finger. There are three main steps to the process: embedding of the optical fiber, embedding of the flex-PCBs, and printing of the finger. All the embedding steps are conducted during the printing process by temporarily pausing filament extrusion.}
    \label{fig:fabrication_figure}
    \vspace{-1em}
\end{figure*}

An alternative method that achieves a higher degree of integration is to use the optical waveguides as part of the structure of the soft robot, either by direct fabrication of soft optical waveguides into the robot body~\cite{Yun2021,Jung2020,DelBono2024} or using the waveguides as a structural component~\cite{optoelectronically_innervated_hand_zhao,Kang2023}. Direct fabrication approaches usually entail complicated multi-step mechanical processes including molding and casting, laser micromachining, or layer deposition of expensive reflective materials. In contrast, using the optical waveguides as a structural component leads to simpler integration. This idea lends itself particularly well to tendon-driven robotic fingers, where the actuation tendon itself can be made from an optical waveguide. In \cite{Yi2023}, Yi et al. implement force sensing employing a fiber Bragg grating (FBG) in series with the tendon, while in \cite{Han2024} Han et al. train a neural network to predict the pose of a finger from the optical power loss in the finger's soft optical tendon. Despite both of these robotic fingers achieving a design that elegantly integrates one sensor into their structure, they lack the distributed sensing required to disentangle proprioception and exteroception: the FBG tendon is only used for exteroception, whilst the soft optical tendon is only able to predict poses if there are no external forces. Moreover, despite making use of 3D printing techniques, neither approach achieves monolithic integration at the manufacturing step, which remains an exciting and very recent development in additive manufacturing for sensorized soft robots~\cite{Lipson2015,Rus2015,Muth2014,Shih2019,Ntagios2020}.

This study aims to apply fused filament fabrication (FFF) 3D printing, a cheap and widely accessible technology, to implement an optical sensing solution that is both distributed and highly integrated in order to achieve proprioception in the presence of external disturbances. We contribute a method of reliably embedding POFs into a multi-material 3D printed finger with optical bending sensors embedded in each compliant joint (Fig. \ref{fig:opening_figure}). To achieve distributed sensing, we also completely embed the LEDs and readout electronics with the POFs to produce a monolithically manufactured sensorized flexure, contributing to the largely unexplored area of embedding circuitry into soft robots~\cite{Woodman2024}. These electronics cost a total of \$10 per finger with a low power consumption of \qty{188}{mW}, providing scalability especially when compared to FBG-based sensors. By embedding during the 3D printing stage, we eliminate both the need for manual assembly of parts after printing and the presence of any external wiring or optics, resulting in a tendon-actuated finger with fully self-contained sensing. This research represents a step towards the integrated, distributed sensing necessary for fully autonomous soft robots \cite{Soter2018,Thuruthel2019,Truby2020}. 

The remainder of this paper is structured as follows: in section \ref{sec:materials_and_methods}, we provide details of the embedding method and multi-material finger design. In section \ref{sec:experimental_calibration}, we describe our sensor characterization procedure and results. In section \ref{sec:experimental_validation}, we describe two validation experiments and discuss their results. In the first experiment, we compare the sensors' ability to predict fingertip position in the presence of varying static forces compared to a baseline finger with only one optical bending sensor along its length. In the second experiment, we train a model on sensor data in the absence of external contact and use it to predict contact. We provide our final remarks in section \ref{sec:conclusion}. 